# æ ¸å¿ƒæ¦‚å¿µ 3: ReAct Framework æ¨ç†è¡ŒåŠ¨æ¡†æ¶

## ä¸€å¥è¯å®šä¹‰

**ReAct Framework æ˜¯"æ¨ç†(Reasoning) + è¡ŒåŠ¨(Acting)"çš„å¾ªç¯æ¡†æ¶,è®© AI ä»£ç†åœ¨æ€è€ƒå’Œæ‰§è¡Œä¹‹é—´äº¤æ›¿è¿­ä»£,åœ¨ Agentic RAG ä¸­å®ç°è‡ªä¸»å†³ç­–å’ŒåŠ¨æ€æ£€ç´¢ã€‚**

---

## è¯¦ç»†è§£é‡Š

### ä»€ä¹ˆæ˜¯ ReAct Framework?

ReAct æ˜¯ 2022 å¹´ç”± Yao ç­‰äººæå‡ºçš„ä»£ç†æ¡†æ¶,æ ¸å¿ƒæ€æƒ³:
- **Reasoning**: AI å…ˆæ€è€ƒä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ
- **Acting**: åŸºäºæ€è€ƒæ‰§è¡Œå…·ä½“è¡ŒåŠ¨
- **Observing**: è§‚å¯Ÿè¡ŒåŠ¨ç»“æœ
- **Reflecting**: åæ€ç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥

**æ ¸å¿ƒä»·å€¼**: è®© AI åƒäººç±»ä¸“å®¶ä¸€æ ·"è¾¹æƒ³è¾¹åš",è€Œéä¸€æ¬¡æ€§ç”Ÿæˆç­”æ¡ˆã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ ReAct Framework?

ä¼ ç»Ÿ RAG çš„é—®é¢˜:
```python
# ä¼ ç»Ÿ RAG: ä¸€æ¬¡æ£€ç´¢,ä¸€æ¬¡ç”Ÿæˆ
query = "Transformer çš„æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•å·¥ä½œ?"
docs = retriever.search(query)  # ä¸€æ¬¡æ£€ç´¢
answer = llm.generate(docs)     # ä¸€æ¬¡ç”Ÿæˆ
# é—®é¢˜: å¦‚æœæ£€ç´¢ç»“æœä¸å¤Ÿ,æ— æ³•è¡¥å……
```

**å¤æ‚æŸ¥è¯¢éœ€è¦è¿­ä»£**:
```python
# ReAct: æ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ åæ€ â†’ å¾ªç¯
query = "Transformer çš„æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•å·¥ä½œ?"

# Thought 1: å…ˆæ£€ç´¢åŸºç¡€æ¦‚å¿µ
action_1 = "æœç´¢ Transformer åŸºç¡€"
observation_1 = retriever.search(action_1)

# Thought 2: ç»“æœä¸å¤Ÿè¯¦ç»†,éœ€è¦æ›´å…·ä½“çš„ä¿¡æ¯
action_2 = "æœç´¢ Self-Attention è®¡ç®—å…¬å¼"
observation_2 = retriever.search(action_2)

# Thought 3: ç°åœ¨ä¿¡æ¯è¶³å¤Ÿäº†,å¯ä»¥ç”Ÿæˆç­”æ¡ˆ
answer = llm.generate(observation_1 + observation_2)
```

### ReAct Framework å¦‚ä½•å·¥ä½œ?

**æ ¸å¿ƒå¾ªç¯**:
```
ç”¨æˆ·æŸ¥è¯¢
    â†“
[Thought] æ€è€ƒ: æˆ‘éœ€è¦ä»€ä¹ˆä¿¡æ¯?
    â†“
[Action] è¡ŒåŠ¨: æ‰§è¡Œæ£€ç´¢/å·¥å…·è°ƒç”¨
    â†“
[Observation] è§‚å¯Ÿ: è·å¾—ç»“æœ
    â†“
[Reflection] åæ€: ç»“æœæ˜¯å¦è¶³å¤Ÿ?
    â†“
    â”œâ”€ æ˜¯ â†’ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    â””â”€ å¦ â†’ å›åˆ° [Thought]
```

---

## æ ¸å¿ƒåŸç†

### åŸç†å›¾è§£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ReAct å¾ªç¯ç¤ºä¾‹                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  æŸ¥è¯¢: "æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹"      â”‚
â”‚                                         â”‚
â”‚  [Thought 1]                            â”‚
â”‚  æˆ‘éœ€è¦å…ˆäº†è§£ BERT çš„ç‰¹ç‚¹               â”‚
â”‚       â†“                                 â”‚
â”‚  [Action 1]                             â”‚
â”‚  search("BERT æŠ€æœ¯ç‰¹ç‚¹")                â”‚
â”‚       â†“                                 â”‚
â”‚  [Observation 1]                        â”‚
â”‚  BERT æ˜¯åŒå‘ç¼–ç å™¨,æ“…é•¿ç†è§£ä»»åŠ¡...      â”‚
â”‚       â†“                                 â”‚
â”‚  [Thought 2]                            â”‚
â”‚  ç°åœ¨éœ€è¦äº†è§£ GPT çš„ç‰¹ç‚¹                â”‚
â”‚       â†“                                 â”‚
â”‚  [Action 2]                             â”‚
â”‚  search("GPT æŠ€æœ¯ç‰¹ç‚¹")                 â”‚
â”‚       â†“                                 â”‚
â”‚  [Observation 2]                        â”‚
â”‚  GPT æ˜¯å•å‘è§£ç å™¨,æ“…é•¿ç”Ÿæˆä»»åŠ¡...       â”‚
â”‚       â†“                                 â”‚
â”‚  [Thought 3]                            â”‚
â”‚  ä¿¡æ¯è¶³å¤Ÿäº†,å¯ä»¥å¯¹æ¯”åˆ†æ                â”‚
â”‚       â†“                                 â”‚
â”‚  [Action 3]                             â”‚
â”‚  generate_answer()                      â”‚
â”‚       â†“                                 â”‚
â”‚  æœ€ç»ˆç­”æ¡ˆ: BERT vs GPT å¯¹æ¯”åˆ†æ         â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å·¥ä½œæµç¨‹

**Step 1: Thought (æ€è€ƒ)**
```python
def think(query: str, context: List[str]) -> str:
    """æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
    prompt = f"""
    æŸ¥è¯¢: {query}
    å·²çŸ¥ä¿¡æ¯: {context}

    æ€è€ƒ: ä¸‹ä¸€æ­¥æˆ‘åº”è¯¥åšä»€ä¹ˆ?
    """
    thought = llm.predict(prompt)
    return thought
```

**Step 2: Action (è¡ŒåŠ¨)**
```python
def act(thought: str) -> Dict:
    """åŸºäºæ€è€ƒæ‰§è¡Œè¡ŒåŠ¨"""
    # è§£ææ€è€ƒ,å†³å®šè¡ŒåŠ¨ç±»å‹
    if "æœç´¢" in thought:
        action = {"type": "search", "query": extract_query(thought)}
    elif "è®¡ç®—" in thought:
        action = {"type": "calculate", "expression": extract_expr(thought)}
    elif "ç”Ÿæˆç­”æ¡ˆ" in thought:
        action = {"type": "finish", "answer": generate_answer()}

    return action
```

**Step 3: Observation (è§‚å¯Ÿ)**
```python
def observe(action: Dict) -> str:
    """æ‰§è¡Œè¡ŒåŠ¨å¹¶è§‚å¯Ÿç»“æœ"""
    if action["type"] == "search":
        result = retriever.search(action["query"])
    elif action["type"] == "calculate":
        result = calculator.run(action["expression"])
    elif action["type"] == "finish":
        result = action["answer"]

    return result
```

**Step 4: Reflection (åæ€)**
```python
def reflect(observation: str, query: str) -> bool:
    """åæ€æ˜¯å¦éœ€è¦ç»§ç»­"""
    prompt = f"""
    åŸå§‹æŸ¥è¯¢: {query}
    å½“å‰ç»“æœ: {observation}

    é—®é¢˜: ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿå›ç­”æŸ¥è¯¢? (æ˜¯/å¦)
    """
    decision = llm.predict(prompt)
    return "æ˜¯" in decision
```

### å…³é”®æŠ€æœ¯

**1. Prompt è®¾è®¡ (2022 åŸç‰ˆ)**
```python
REACT_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”é—®é¢˜:

Question: ç”¨æˆ·çš„é—®é¢˜
Thought: ä½ åº”è¯¥æ€è€ƒä¸‹ä¸€æ­¥åšä»€ä¹ˆ
Action: æ‰§è¡Œçš„è¡ŒåŠ¨ [search/calculate/finish]
Action Input: è¡ŒåŠ¨çš„è¾“å…¥
Observation: è¡ŒåŠ¨çš„ç»“æœ
... (é‡å¤ Thought/Action/Observation)
Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆç­”æ¡ˆ

Question: {query}
"""
```

**2. å·¥å…·é›†æˆ (2025 å¢å¼º)**
```python
from langchain.agents import Tool

tools = [
    Tool(
        name="Search",
        func=vector_search,
        description="æœç´¢ç›¸å…³æ–‡æ¡£,è¾“å…¥æŸ¥è¯¢å­—ç¬¦ä¸²"
    ),
    Tool(
        name="Calculator",
        func=calculator,
        description="æ‰§è¡Œæ•°å­¦è®¡ç®—,è¾“å…¥è¡¨è¾¾å¼"
    ),
    Tool(
        name="WebSearch",
        func=web_search,
        description="æœç´¢å®æ—¶ä¿¡æ¯,è¾“å…¥æŸ¥è¯¢"
    )
]
```

**3. è‡ªæˆ‘çº é”™ (2026 æœ€æ–°)**
```python
def self_correction_react(query: str, max_retries: int = 3):
    """å¸¦è‡ªæˆ‘çº é”™çš„ ReAct"""
    for attempt in range(max_retries):
        try:
            result = react_loop(query)

            # éªŒè¯ç»“æœ
            if is_valid(result):
                return result

            # è‡ªæˆ‘çº é”™
            feedback = f"ç»“æœä¸æ­£ç¡®,åŸå› : {validate_error(result)}"
            query = f"{query}\nåé¦ˆ: {feedback}"

        except Exception as e:
            continue

    return "æ— æ³•ç”Ÿæˆæ»¡æ„ç­”æ¡ˆ"
```

---

## æ‰‹å†™å®ç°

```python
"""
ReAct Framework ä»é›¶å®ç°
æ¼”ç¤º: Thought â†’ Action â†’ Observation å¾ªç¯
"""

from typing import List, Dict, Optional
from openai import OpenAI
import os
import re

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===== 1. å·¥å…·å®šä¹‰ =====
class SearchTool:
    """æœç´¢å·¥å…·(æ¨¡æ‹Ÿ)"""
    def run(self, query: str) -> str:
        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        knowledge_base = {
            "bert": "BERT æ˜¯åŒå‘ç¼–ç å™¨,ä½¿ç”¨ Masked LM é¢„è®­ç»ƒ,æ“…é•¿ç†è§£ä»»åŠ¡",
            "gpt": "GPT æ˜¯å•å‘è§£ç å™¨,ä½¿ç”¨è‡ªå›å½’é¢„è®­ç»ƒ,æ“…é•¿ç”Ÿæˆä»»åŠ¡",
            "transformer": "Transformer ä½¿ç”¨ Self-Attention æœºåˆ¶,å¹¶è¡Œå¤„ç†åºåˆ—"
        }

        for key, value in knowledge_base.items():
            if key in query.lower():
                return value

        return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

class CalculatorTool:
    """è®¡ç®—å·¥å…·"""
    def run(self, expression: str) -> str:
        try:
            result = eval(expression)
            return f"è®¡ç®—ç»“æœ: {result}"
        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {e}"

# ===== 2. ReAct Agent =====
class ReActAgent:
    """ReAct ä»£ç†"""

    def __init__(self):
        self.search_tool = SearchTool()
        self.calculator_tool = CalculatorTool()
        self.max_iterations = 5

    def run(self, query: str) -> str:
        """æ‰§è¡Œ ReAct å¾ªç¯"""
        print(f"\n{'='*50}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*50}\n")

        context = []
        iteration = 0

        while iteration < self.max_iterations:
            iteration += 1
            print(f"--- è¿­ä»£ {iteration} ---\n")

            # Step 1: Thought
            thought = self._think(query, context)
            print(f"ğŸ’­ Thought: {thought}\n")

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if "finish" in thought.lower() or "æœ€ç»ˆç­”æ¡ˆ" in thought:
                final_answer = self._generate_final_answer(query, context)
                print(f"âœ… Final Answer: {final_answer}\n")
                return final_answer

            # Step 2: Action
            action = self._parse_action(thought)
            print(f"âš¡ Action: {action['type']}({action['input']})\n")

            # Step 3: Observation
            observation = self._execute_action(action)
            print(f"ğŸ‘ï¸  Observation: {observation}\n")

            # ä¿å­˜ä¸Šä¸‹æ–‡
            context.append({
                "thought": thought,
                "action": action,
                "observation": observation
            })

        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°,æ— æ³•ç”Ÿæˆç­”æ¡ˆ"

    def _think(self, query: str, context: List[Dict]) -> str:
        """æ€è€ƒä¸‹ä¸€æ­¥"""
        context_str = "\n".join([
            f"Thought: {c['thought']}\nAction: {c['action']}\nObservation: {c['observation']}"
            for c in context
        ])

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:

Thought: æ€è€ƒä¸‹ä¸€æ­¥åšä»€ä¹ˆ
Action: search(æŸ¥è¯¢) æˆ– calculate(è¡¨è¾¾å¼) æˆ– finish

å·²æœ‰ä¸Šä¸‹æ–‡:
{context_str}

åŸå§‹æŸ¥è¯¢: {query}

ä¸‹ä¸€æ­¥ Thought:
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )

        return response.choices[0].message.content.strip()

    def _parse_action(self, thought: str) -> Dict:
        """è§£æè¡ŒåŠ¨"""
        # æå– search(...)
        search_match = re.search(r'search\((.*?)\)', thought, re.IGNORECASE)
        if search_match:
            return {"type": "search", "input": search_match.group(1).strip('"\'').strip()}

        # æå– calculate(...)
        calc_match = re.search(r'calculate\((.*?)\)', thought, re.IGNORECASE)
        if calc_match:
            return {"type": "calculate", "input": calc_match.group(1).strip()}

        # é»˜è®¤æœç´¢
        return {"type": "search", "input": thought}

    def _execute_action(self, action: Dict) -> str:
        """æ‰§è¡Œè¡ŒåŠ¨"""
        if action["type"] == "search":
            return self.search_tool.run(action["input"])
        elif action["type"] == "calculate":
            return self.calculator_tool.run(action["input"])
        else:
            return "æœªçŸ¥è¡ŒåŠ¨ç±»å‹"

    def _generate_final_answer(self, query: str, context: List[Dict]) -> str:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
        observations = "\n".join([c["observation"] for c in context])

        prompt = f"""
åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜:

é—®é¢˜: {query}

ä¿¡æ¯:
{observations}

ç­”æ¡ˆ:
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        return response.choices[0].message.content.strip()

# ===== 3. æµ‹è¯• =====
if __name__ == "__main__":
    agent = ReActAgent()

    test_queries = [
        "ä»€ä¹ˆæ˜¯ BERT?",
        "æ¯”è¾ƒ BERT å’Œ GPT",
        "Transformer çš„æ ¸å¿ƒæœºåˆ¶æ˜¯ä»€ä¹ˆ?"
    ]

    for query in test_queries:
        answer = agent.run(query)
        print(f"\n{'='*50}\n")
```

---

## åœ¨ RAG ä¸­çš„åº”ç”¨

### åº”ç”¨åœºæ™¯ 1: è¿­ä»£æ£€ç´¢

**é—®é¢˜**: åˆæ¬¡æ£€ç´¢ç»“æœä¸å¤Ÿå®Œæ•´

**ReAct æ–¹æ¡ˆ**:
```python
def iterative_rag(query: str):
    """è¿­ä»£å¼ RAG"""
    context = []

    # Thought 1: å…ˆæ£€ç´¢åŸºç¡€ä¿¡æ¯
    docs_1 = retriever.search(query)
    context.extend(docs_1)

    # Reflection: ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿ?
    if not is_sufficient(docs_1, query):
        # Thought 2: éœ€è¦æ›´å…·ä½“çš„ä¿¡æ¯
        refined_query = refine_query(query, docs_1)
        docs_2 = retriever.search(refined_query)
        context.extend(docs_2)

    # Generate answer
    return llm.generate(context)
```

### åº”ç”¨åœºæ™¯ 2: å¤šå·¥å…·åä½œ

**é—®é¢˜**: éœ€è¦ç»“åˆæ£€ç´¢å’Œè®¡ç®—

**ReAct æ–¹æ¡ˆ**:
```python
def multi_tool_rag(query: str):
    """å¤šå·¥å…· RAG"""
    # Thought: å…ˆæ£€ç´¢æ•°æ®
    if "æ•°æ®" in query:
        data = retriever.search(query)

    # Thought: éœ€è¦è®¡ç®—
    if "è®¡ç®—" in query or "å¢é•¿ç‡" in query:
        result = calculator.run(extract_formula(data))

    # Thought: ç”Ÿæˆç­”æ¡ˆ
    return llm.generate(f"æ•°æ®: {data}, è®¡ç®—: {result}")
```

### åº”ç”¨åœºæ™¯ 3: è‡ªæˆ‘éªŒè¯

**é—®é¢˜**: ç”Ÿæˆçš„ç­”æ¡ˆå¯èƒ½ä¸å‡†ç¡®

**ReAct æ–¹æ¡ˆ**:
```python
def self_verify_rag(query: str):
    """è‡ªæˆ‘éªŒè¯ RAG"""
    # Generate initial answer
    answer = rag_pipeline(query)

    # Verify answer
    verification = verify_answer(answer, query)

    if not verification["correct"]:
        # Re-search with feedback
        feedback = verification["reason"]
        refined_query = f"{query} (æ³¨æ„: {feedback})"
        answer = rag_pipeline(refined_query)

    return answer
```

---

## ä¸»æµæ¡†æ¶å®ç°

### LangChain å®ç° (æ¨è)

```python
from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain import hub

# å®šä¹‰å·¥å…·
tools = [
    Tool(
        name="Search",
        func=vector_search,
        description="æœç´¢ç›¸å…³æ–‡æ¡£"
    ),
    Tool(
        name="Calculator",
        func=calculator,
        description="æ‰§è¡Œæ•°å­¦è®¡ç®—"
    )
]

# è·å– ReAct Prompt
prompt = hub.pull("hwchase17/react")

# åˆ›å»º ReAct Agent
llm = ChatOpenAI(model="gpt-4o", temperature=0)
agent = create_react_agent(llm, tools, prompt)

# æ‰§è¡Œ
executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=5
)

result = executor.invoke({"input": "æ¯”è¾ƒ BERT å’Œ GPT"})
```

### LangGraph å®ç°

```python
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor

# å®šä¹‰çŠ¶æ€
class AgentState(TypedDict):
    input: str
    agent_outcome: Union[AgentAction, AgentFinish]
    intermediate_steps: List[Tuple[AgentAction, str]]

# å®šä¹‰èŠ‚ç‚¹
def run_agent(state: AgentState):
    """è¿è¡Œä»£ç†(Thought + Action)"""
    agent_outcome = agent.invoke(state)
    return {"agent_outcome": agent_outcome}

def execute_tools(state: AgentState):
    """æ‰§è¡Œå·¥å…·(Observation)"""
    agent_action = state["agent_outcome"]
    output = tool_executor.invoke(agent_action)
    return {"intermediate_steps": [(agent_action, output)]}

# æ„å»ºå›¾
workflow = StateGraph(AgentState)
workflow.add_node("agent", run_agent)
workflow.add_node("tools", execute_tools)

workflow.set_entry_point("agent")
workflow.add_conditional_edges(
    "agent",
    lambda x: "continue" if isinstance(x["agent_outcome"], AgentAction) else "end",
    {
        "continue": "tools",
        "end": END
    }
)
workflow.add_edge("tools", "agent")

app = workflow.compile()
```

### LlamaIndex å®ç°

```python
from llama_index.core.agent import ReActAgent
from llama_index.core.tools import QueryEngineTool

# åˆ›å»ºæŸ¥è¯¢å¼•æ“å·¥å…·
query_engine = index.as_query_engine()
query_tool = QueryEngineTool.from_defaults(
    query_engine=query_engine,
    name="search",
    description="æœç´¢æ–‡æ¡£"
)

# åˆ›å»º ReAct Agent
agent = ReActAgent.from_tools(
    [query_tool],
    llm=llm,
    verbose=True,
    max_iterations=5
)

# æ‰§è¡Œ
response = agent.chat("æ¯”è¾ƒ BERT å’Œ GPT")
print(response)
```

---

## æœ€ä½³å®è·µ (2025-2026)

### æ€§èƒ½ä¼˜åŒ–

**1. é™åˆ¶è¿­ä»£æ¬¡æ•°**
```python
# é¿å…æ— é™å¾ªç¯
agent = ReActAgent(max_iterations=5)
```

**2. ç¼“å­˜å·¥å…·ç»“æœ**
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_search(query: str):
    return retriever.search(query)
```

**3. å¹¶è¡Œå·¥å…·è°ƒç”¨**
```python
import asyncio

async def parallel_tools(actions: List[Dict]):
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·"""
    tasks = [execute_tool_async(action) for action in actions]
    return await asyncio.gather(*tasks)
```

### æˆæœ¬æ§åˆ¶

**1. ä½¿ç”¨å°æ¨¡å‹æ€è€ƒ**
```python
# Thought ç”¨å°æ¨¡å‹
thought_llm = ChatOpenAI(model="gpt-4o-mini")

# Final Answer ç”¨å¤§æ¨¡å‹
answer_llm = ChatOpenAI(model="gpt-4o")
```

**2. æ—©åœç­–ç•¥**
```python
def early_stop_react(query: str):
    """æ—©åœç­–ç•¥"""
    for i in range(max_iterations):
        thought = think(query, context)

        # å¦‚æœç½®ä¿¡åº¦é«˜,æå‰ç»“æŸ
        if confidence(thought) > 0.9:
            return generate_answer(context)

        # ç»§ç»­è¿­ä»£
        action = act(thought)
        observation = observe(action)
        context.append(observation)
```

### é”™è¯¯å¤„ç†

**1. å·¥å…·è°ƒç”¨å¤±è´¥**
```python
def safe_tool_call(tool: Tool, input: str):
    """å®‰å…¨çš„å·¥å…·è°ƒç”¨"""
    try:
        return tool.run(input)
    except Exception as e:
        return f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}, è¯·å°è¯•å…¶ä»–æ–¹æ³•"
```

**2. æ— é™å¾ªç¯æ£€æµ‹**
```python
def detect_loop(context: List[Dict]):
    """æ£€æµ‹é‡å¤è¡ŒåŠ¨"""
    recent_actions = [c["action"] for c in context[-3:]]

    if len(recent_actions) == 3 and len(set(recent_actions)) == 1:
        raise Exception("æ£€æµ‹åˆ°é‡å¤è¡ŒåŠ¨,åœæ­¢å¾ªç¯")
```

---

## å¸¸è§é—®é¢˜

### é—®é¢˜ 1: ReAct å¤ªæ…¢æ€ä¹ˆåŠ?

**åŸå› **: æ¯æ¬¡è¿­ä»£éƒ½è°ƒç”¨ LLM

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å‡å°‘è¿­ä»£æ¬¡æ•°
agent = ReActAgent(max_iterations=3)

# 2. ä½¿ç”¨è§„åˆ™ä¼˜å…ˆ
def fast_react(query: str):
    # ç®€å•æŸ¥è¯¢ç›´æ¥å›ç­”
    if is_simple(query):
        return direct_answer(query)

    # å¤æ‚æŸ¥è¯¢ç”¨ ReAct
    return react_agent(query)
```

### é—®é¢˜ 2: å¦‚ä½•æé«˜ ReAct å‡†ç¡®ç‡?

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. æ”¹è¿› Prompt
BETTER_PROMPT = """
ä½ æ˜¯ä¸“å®¶åŠ©æ‰‹ã€‚ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼:

Thought: è¯¦ç»†æ€è€ƒä¸‹ä¸€æ­¥(å¿…é¡»å…·ä½“)
Action: æ˜ç¡®çš„è¡ŒåŠ¨[search/calculate/finish]
Action Input: ç²¾ç¡®çš„è¾“å…¥

ç¤ºä¾‹:
Thought: æˆ‘éœ€è¦äº†è§£ BERT çš„é¢„è®­ç»ƒæ–¹æ³•
Action: search
Action Input: BERT é¢„è®­ç»ƒ Masked LM
"""

# 2. æ·»åŠ ç¤ºä¾‹
FEW_SHOT_EXAMPLES = [
    {
        "query": "ä»€ä¹ˆæ˜¯ Transformer?",
        "thought": "éœ€è¦æœç´¢ Transformer åŸºç¡€æ¦‚å¿µ",
        "action": "search(Transformer æ¶æ„)",
        "observation": "Transformer ä½¿ç”¨ Self-Attention..."
    }
]
```

### é—®é¢˜ 3: ReAct vs Planning Agent å¦‚ä½•é€‰æ‹©?

**å¯¹æ¯”**:
```python
# ReAct: è¾¹æƒ³è¾¹åš,çµæ´»ä½†å¯èƒ½ä½æ•ˆ
react_agent(query)  # åŠ¨æ€å†³ç­–,é€‚åˆä¸ç¡®å®šä»»åŠ¡

# Planning: å…ˆè§„åˆ’å†æ‰§è¡Œ,é«˜æ•ˆä½†ä¸çµæ´»
planning_agent(query)  # é¢„å…ˆè§„åˆ’,é€‚åˆæ˜ç¡®ä»»åŠ¡

# é€‰æ‹©å»ºè®®:
# - æ¢ç´¢æ€§ä»»åŠ¡ â†’ ReAct
# - æ˜ç¡®ä»»åŠ¡ â†’ Planning
# - å¤æ‚ä»»åŠ¡ â†’ ReAct + Planning æ··åˆ
```

---

## å‚è€ƒèµ„æº

### è®ºæ–‡
- "ReAct: Synergizing Reasoning and Acting in Language Models" (arXiv 2210.03629, 2022)
- "Reflexion: Language Agents with Verbal Reinforcement Learning" (arXiv 2303.11366, 2023)

### åšå®¢
- IBM: "What is Agentic RAG?" (2026) - ReAct åœ¨ RAG ä¸­çš„åº”ç”¨
  https://www.ibm.com/think/topics/agentic-rag
- "ReAct Framework Explained" (Medium, 2026)
  https://medium.com/@linz07m/react-reasoning-and-acting-framework-03e71aff1877
- LangChain: "ReAct Agent" (2026)
  https://python.langchain.com/docs/modules/agents/agent_types/react

### æ¡†æ¶æ–‡æ¡£
- LangChain ReAct: https://python.langchain.com/docs/modules/agents/
- LangGraph ReAct: https://langchain-ai.github.io/langgraph/
- LlamaIndex ReAct: https://docs.llamaindex.ai/en/stable/examples/agent/react_agent/

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-17
**å­—æ•°**: ~450 è¡Œ
