# å®æˆ˜ä»£ç  - åœºæ™¯4ï¼šHPAè‡ªåŠ¨æ‰©ç¼©å®¹

## åœºæ™¯æè¿°

**ç›®æ ‡ï¼š**é…ç½®HPAï¼ˆHorizontal Pod Autoscalerï¼‰å®ç°åŸºäºè´Ÿè½½çš„è‡ªåŠ¨æ‰©ç¼©å®¹

**ç‰¹ç‚¹ï¼š**
- æ ¹æ®CPU/å†…å­˜è‡ªåŠ¨è°ƒæ•´å‰¯æœ¬æ•°
- é…ç½®æ‰©ç¼©å®¹ç­–ç•¥ï¼ˆå¿«é€Ÿæ‰©å®¹ã€ç¼“æ…¢ç¼©å®¹ï¼‰
- æ”¯æŒè‡ªå®šä¹‰æŒ‡æ ‡æ‰©ç¼©å®¹
- æ¨¡æ‹Ÿæµé‡æµ‹è¯•æ‰©ç¼©å®¹æ•ˆæœ

**é€‚ç”¨åœºæ™¯ï¼š**
- æµé‡æ³¢åŠ¨å¤§çš„RAGç³»ç»Ÿ
- éœ€è¦æˆæœ¬ä¼˜åŒ–
- éœ€è¦è‡ªåŠ¨åº”å¯¹çªå‘æµé‡

---

## å®Œæ•´é…ç½®è„šæœ¬

### 1. åŸºäºCPUçš„HPAé…ç½®

```yaml
# hpa-cpu.yaml - åŸºäºCPUçš„è‡ªåŠ¨æ‰©ç¼©å®¹

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: milvus-querynode-hpa
  namespace: milvus-prod
spec:
  # ç›®æ ‡Deployment
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: milvus-querynode

  # å‰¯æœ¬æ•°èŒƒå›´
  minReplicas: 2   # æœ€å°‘2ä¸ªå‰¯æœ¬
  maxReplicas: 20  # æœ€å¤š20ä¸ªå‰¯æœ¬

  # æ‰©ç¼©å®¹æŒ‡æ ‡
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPUè¶…è¿‡70%æ‰©å®¹

  # æ‰©ç¼©å®¹è¡Œä¸º
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60  # æ‰©å®¹å‰ç­‰å¾…60ç§’
      policies:
      - type: Percent
        value: 50  # æ¯æ¬¡æ‰©å®¹50%
        periodSeconds: 60
      - type: Pods
        value: 2   # æˆ–æ¯æ¬¡æ‰©å®¹2ä¸ªPod
        periodSeconds: 60
      selectPolicy: Max  # é€‰æ‹©æ‰©å®¹æ›´å¤šçš„ç­–ç•¥

    scaleDown:
      stabilizationWindowSeconds: 300  # ç¼©å®¹å‰ç­‰å¾…5åˆ†é’Ÿ
      policies:
      - type: Percent
        value: 10  # æ¯æ¬¡ç¼©å®¹10%
        periodSeconds: 60
      - type: Pods
        value: 1   # æˆ–æ¯æ¬¡ç¼©å®¹1ä¸ªPod
        periodSeconds: 60
      selectPolicy: Min  # é€‰æ‹©ç¼©å®¹æ›´å°‘çš„ç­–ç•¥
```

### 2. åŸºäºå†…å­˜çš„HPAé…ç½®

```yaml
# hpa-memory.yaml - åŸºäºå†…å­˜çš„è‡ªåŠ¨æ‰©ç¼©å®¹

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: milvus-querynode-memory-hpa
  namespace: milvus-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: milvus-querynode

  minReplicas: 2
  maxReplicas: 20

  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # å†…å­˜è¶…è¿‡80%æ‰©å®¹

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Pods
        value: 3  # å†…å­˜å‹åŠ›å¤§æ—¶å¿«é€Ÿæ‰©å®¹
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 600  # å†…å­˜ç¼©å®¹æ›´ä¿å®ˆ
      policies:
      - type: Pods
        value: 1
        periodSeconds: 120
```

### 3. å¤šæŒ‡æ ‡HPAé…ç½®

```yaml
# hpa-multi-metrics.yaml - å¤šæŒ‡æ ‡è‡ªåŠ¨æ‰©ç¼©å®¹

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: milvus-querynode-multi-hpa
  namespace: milvus-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: milvus-querynode

  minReplicas: 2
  maxReplicas: 20

  metrics:
  # CPUæŒ‡æ ‡
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

  # å†…å­˜æŒ‡æ ‡
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

  # è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆéœ€è¦Prometheus Adapterï¼‰
  - type: Pods
    pods:
      metric:
        name: milvus_search_latency_p99
      target:
        type: AverageValue
        averageValue: "1000"  # P99å»¶è¿Ÿè¶…è¿‡1ç§’æ‰©å®¹

  - type: Pods
    pods:
      metric:
        name: milvus_search_qps
      target:
        type: AverageValue
        averageValue: "100"  # æ¯ä¸ªPod QPSè¶…è¿‡100æ‰©å®¹

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

### 4. éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy-hpa.sh - éƒ¨ç½²HPA

set -e

echo "=== éƒ¨ç½²HPAè‡ªåŠ¨æ‰©ç¼©å®¹ ==="

# æ£€æŸ¥metrics-serveræ˜¯å¦å®‰è£…
echo "ğŸ“¦ æ£€æŸ¥metrics-server..."
if ! kubectl get deployment metrics-server -n kube-system &> /dev/null; then
    echo "âŒ metrics-serveræœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…..."
    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

    # ç­‰å¾…metrics-serverå°±ç»ª
    kubectl wait --for=condition=available deployment/metrics-server \
      -n kube-system \
      --timeout=300s

    echo "âœ… metrics-serverå®‰è£…å®Œæˆ"
else
    echo "âœ… metrics-serverå·²å®‰è£…"
fi

# éƒ¨ç½²HPA
echo "ğŸ“¦ éƒ¨ç½²HPA..."
kubectl apply -f hpa-cpu.yaml

echo "âœ… HPAéƒ¨ç½²å®Œæˆ"

# æŸ¥çœ‹HPAçŠ¶æ€
echo ""
echo "=== HPAçŠ¶æ€ ==="
kubectl get hpa -n milvus-prod

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
echo ""
echo "=== HPAè¯¦ç»†ä¿¡æ¯ ==="
kubectl describe hpa milvus-querynode-hpa -n milvus-prod
```

---

## å‹åŠ›æµ‹è¯•è„šæœ¬

### Pythonå‹æµ‹å·¥å…·

```python
"""
load_test.py - Milvuså‹åŠ›æµ‹è¯•å·¥å…·

åŠŸèƒ½ï¼š
1. ç”ŸæˆæŒç»­çš„æŸ¥è¯¢è´Ÿè½½
2. è§‚å¯ŸHPAæ‰©ç¼©å®¹è¡Œä¸º
3. è®°å½•æ€§èƒ½æŒ‡æ ‡
"""

from pymilvus import connections, Collection
import numpy as np
import time
import threading
from concurrent.futures import ThreadPoolExecutor
import argparse
from datetime import datetime

class LoadTester:
    def __init__(self, host, port, collection_name, dim=128):
        self.host = host
        self.port = port
        self.collection_name = collection_name
        self.dim = dim
        self.collection = None
        self.running = False
        self.stats = {
            "total_queries": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "total_latency": 0,
            "latencies": []
        }

    def connect(self):
        """è¿æ¥åˆ°Milvus"""
        connections.connect(
            alias="default",
            host=self.host,
            port=self.port
        )
        self.collection = Collection(self.collection_name)
        print(f"âœ… è¿æ¥åˆ°Milvus: {self.host}:{self.port}")

    def search_once(self):
        """æ‰§è¡Œä¸€æ¬¡æœç´¢"""
        try:
            query_vector = np.random.random(self.dim).tolist()
            search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

            start_time = time.time()
            results = self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param=search_params,
                limit=10
            )
            latency = (time.time() - start_time) * 1000

            self.stats["successful_queries"] += 1
            self.stats["total_latency"] += latency
            self.stats["latencies"].append(latency)

            return True, latency
        except Exception as e:
            self.stats["failed_queries"] += 1
            return False, 0

    def run_load_test(self, qps, duration, num_workers=10):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"\n=== å¼€å§‹å‹åŠ›æµ‹è¯• ===")
        print(f"ç›®æ ‡QPS: {qps}")
        print(f"æŒç»­æ—¶é—´: {duration}ç§’")
        print(f"å¹¶å‘æ•°: {num_workers}")

        self.running = True
        self.stats = {
            "total_queries": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "total_latency": 0,
            "latencies": []
        }

        start_time = time.time()
        interval = 1.0 / qps  # æ¯æ¬¡æŸ¥è¯¢çš„é—´éš”

        def worker():
            while self.running and (time.time() - start_time) < duration:
                self.search_once()
                self.stats["total_queries"] += 1
                time.sleep(interval * num_workers)  # è°ƒæ•´é—´éš”ä»¥è¾¾åˆ°ç›®æ ‡QPS

        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = [executor.submit(worker) for _ in range(num_workers)]

            # å®šæœŸæ‰“å°ç»Ÿè®¡ä¿¡æ¯
            last_print = time.time()
            while self.running and (time.time() - start_time) < duration:
                time.sleep(5)
                if time.time() - last_print >= 5:
                    self.print_stats()
                    last_print = time.time()

            self.running = False

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for future in futures:
            future.result()

        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        print("\n=== å‹åŠ›æµ‹è¯•å®Œæˆ ===")
        self.print_final_stats()

    def print_stats(self):
        """æ‰“å°å½“å‰ç»Ÿè®¡ä¿¡æ¯"""
        if self.stats["successful_queries"] > 0:
            avg_latency = self.stats["total_latency"] / self.stats["successful_queries"]
            print(f"[{datetime.now().strftime('%H:%M:%S')}] "
                  f"æŸ¥è¯¢æ•°: {self.stats['total_queries']}, "
                  f"æˆåŠŸ: {self.stats['successful_queries']}, "
                  f"å¤±è´¥: {self.stats['failed_queries']}, "
                  f"å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")

    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        if self.stats["successful_queries"] > 0:
            latencies = sorted(self.stats["latencies"])
            avg_latency = self.stats["total_latency"] / self.stats["successful_queries"]
            p50 = latencies[int(len(latencies) * 0.5)]
            p95 = latencies[int(len(latencies) * 0.95)]
            p99 = latencies[int(len(latencies) * 0.99)]

            print(f"æ€»æŸ¥è¯¢æ•°: {self.stats['total_queries']}")
            print(f"æˆåŠŸæŸ¥è¯¢: {self.stats['successful_queries']}")
            print(f"å¤±è´¥æŸ¥è¯¢: {self.stats['failed_queries']}")
            print(f"æˆåŠŸç‡: {self.stats['successful_queries']/self.stats['total_queries']*100:.2f}%")
            print(f"å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
            print(f"P50å»¶è¿Ÿ: {p50:.2f}ms")
            print(f"P95å»¶è¿Ÿ: {p95:.2f}ms")
            print(f"P99å»¶è¿Ÿ: {p99:.2f}ms")

def main():
    parser = argparse.ArgumentParser(description='Milvuså‹åŠ›æµ‹è¯•å·¥å…·')
    parser.add_argument('--host', default='localhost', help='Milvusä¸»æœºåœ°å€')
    parser.add_argument('--port', default='19530', help='Milvusç«¯å£')
    parser.add_argument('--collection', required=True, help='Collectionåç§°')
    parser.add_argument('--qps', type=int, default=100, help='ç›®æ ‡QPS')
    parser.add_argument('--duration', type=int, default=300, help='æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--workers', type=int, default=10, help='å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°')
    parser.add_argument('--dim', type=int, default=128, help='å‘é‡ç»´åº¦')

    args = parser.parse_args()

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = LoadTester(
        host=args.host,
        port=args.port,
        collection_name=args.collection,
        dim=args.dim
    )

    # è¿æ¥å¹¶è¿è¡Œæµ‹è¯•
    tester.connect()
    tester.run_load_test(
        qps=args.qps,
        duration=args.duration,
        num_workers=args.workers
    )

if __name__ == "__main__":
    main()
```

### ä½¿ç”¨å‹æµ‹å·¥å…·

```bash
# å®‰è£…ä¾èµ–
pip install pymilvus numpy

# ä½è´Ÿè½½æµ‹è¯•ï¼ˆä¸è§¦å‘æ‰©å®¹ï¼‰
python load_test.py \
  --host localhost \
  --port 19530 \
  --collection test_collection \
  --qps 50 \
  --duration 300 \
  --workers 5

# é«˜è´Ÿè½½æµ‹è¯•ï¼ˆè§¦å‘æ‰©å®¹ï¼‰
python load_test.py \
  --host localhost \
  --port 19530 \
  --collection test_collection \
  --qps 500 \
  --duration 600 \
  --workers 20

# çªå‘æµé‡æµ‹è¯•
python load_test.py \
  --host localhost \
  --port 19530 \
  --collection test_collection \
  --qps 1000 \
  --duration 180 \
  --workers 50
```

---

## ç›‘æ§HPAè¡Œä¸º

### å®æ—¶ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor-hpa.sh - å®æ—¶ç›‘æ§HPAè¡Œä¸º

echo "=== å®æ—¶ç›‘æ§HPAè¡Œä¸º ==="

# åœ¨åå°æŒç»­ç›‘æ§
while true; do
    clear
    echo "=== $(date '+%Y-%m-%d %H:%M:%S') ==="
    echo ""

    # HPAçŠ¶æ€
    echo "ğŸ“Š HPAçŠ¶æ€ï¼š"
    kubectl get hpa milvus-querynode-hpa -n milvus-prod

    echo ""
    echo "ğŸ“¦ PodçŠ¶æ€ï¼š"
    kubectl get pods -n milvus-prod -l app.kubernetes.io/component=querynode

    echo ""
    echo "ğŸ“ˆ èµ„æºä½¿ç”¨ï¼š"
    kubectl top pods -n milvus-prod -l app.kubernetes.io/component=querynode

    echo ""
    echo "ğŸ“ æœ€è¿‘äº‹ä»¶ï¼š"
    kubectl get events -n milvus-prod \
      --field-selector involvedObject.name=milvus-querynode-hpa \
      --sort-by='.lastTimestamp' \
      | tail -5

    sleep 10
done
```

### PrometheusæŸ¥è¯¢

```promql
# CPUä½¿ç”¨ç‡
rate(container_cpu_usage_seconds_total{pod=~"milvus-querynode-.*"}[5m]) * 100

# å†…å­˜ä½¿ç”¨ç‡
container_memory_working_set_bytes{pod=~"milvus-querynode-.*"} /
container_spec_memory_limit_bytes{pod=~"milvus-querynode-.*"} * 100

# Podå‰¯æœ¬æ•°
count(kube_pod_info{pod=~"milvus-querynode-.*"})

# æœç´¢QPS
rate(milvus_search_total[1m])

# æœç´¢å»¶è¿ŸP99
histogram_quantile(0.99, rate(milvus_search_latency_bucket[5m]))
```

---

## æ‰©ç¼©å®¹åœºæ™¯æµ‹è¯•

### åœºæ™¯1ï¼šé€æ­¥å¢åŠ è´Ÿè½½

```bash
#!/bin/bash
# test-gradual-scale.sh - é€æ­¥å¢åŠ è´Ÿè½½æµ‹è¯•

echo "=== åœºæ™¯1ï¼šé€æ­¥å¢åŠ è´Ÿè½½ ==="

# é˜¶æ®µ1ï¼šä½è´Ÿè½½ï¼ˆ50 QPSï¼‰
echo "ğŸ“Š é˜¶æ®µ1ï¼šä½è´Ÿè½½ï¼ˆ50 QPSï¼‰- 5åˆ†é’Ÿ"
python load_test.py --qps 50 --duration 300 &
PID1=$!
sleep 300

# é˜¶æ®µ2ï¼šä¸­è´Ÿè½½ï¼ˆ200 QPSï¼‰
echo "ğŸ“Š é˜¶æ®µ2ï¼šä¸­è´Ÿè½½ï¼ˆ200 QPSï¼‰- 5åˆ†é’Ÿ"
python load_test.py --qps 200 --duration 300 &
PID2=$!
sleep 300

# é˜¶æ®µ3ï¼šé«˜è´Ÿè½½ï¼ˆ500 QPSï¼‰
echo "ğŸ“Š é˜¶æ®µ3ï¼šé«˜è´Ÿè½½ï¼ˆ500 QPSï¼‰- 5åˆ†é’Ÿ"
python load_test.py --qps 500 --duration 300 &
PID3=$!
sleep 300

# é˜¶æ®µ4ï¼šå›åˆ°ä½è´Ÿè½½ï¼ˆ50 QPSï¼‰
echo "ğŸ“Š é˜¶æ®µ4ï¼šå›åˆ°ä½è´Ÿè½½ï¼ˆ50 QPSï¼‰- 10åˆ†é’Ÿ"
python load_test.py --qps 50 --duration 600 &
PID4=$!
sleep 600

echo "âœ… æµ‹è¯•å®Œæˆ"
```

### åœºæ™¯2ï¼šçªå‘æµé‡

```bash
#!/bin/bash
# test-burst-traffic.sh - çªå‘æµé‡æµ‹è¯•

echo "=== åœºæ™¯2ï¼šçªå‘æµé‡ ===

"

# æ­£å¸¸è´Ÿè½½
echo "ğŸ“Š æ­£å¸¸è´Ÿè½½ï¼ˆ100 QPSï¼‰- 5åˆ†é’Ÿ"
python load_test.py --qps 100 --duration 300 &
sleep 300

# çªå‘æµé‡
echo "ğŸ“Š çªå‘æµé‡ï¼ˆ1000 QPSï¼‰- 3åˆ†é’Ÿ"
python load_test.py --qps 1000 --duration 180 --workers 50 &
sleep 180

# æ¢å¤æ­£å¸¸
echo "ğŸ“Š æ¢å¤æ­£å¸¸ï¼ˆ100 QPSï¼‰- 10åˆ†é’Ÿ"
python load_test.py --qps 100 --duration 600 &
sleep 600

echo "âœ… æµ‹è¯•å®Œæˆ"
```

### åœºæ™¯3ï¼šå‘¨æœŸæ€§æ³¢åŠ¨

```bash
#!/bin/bash
# test-periodic-load.sh - å‘¨æœŸæ€§è´Ÿè½½æµ‹è¯•

echo "=== åœºæ™¯3ï¼šå‘¨æœŸæ€§è´Ÿè½½ ==="

for i in {1..5}; do
    echo "ğŸ“Š å‘¨æœŸ $i - é«˜è´Ÿè½½ï¼ˆ500 QPSï¼‰- 3åˆ†é’Ÿ"
    python load_test.py --qps 500 --duration 180 &
    sleep 180

    echo "ğŸ“Š å‘¨æœŸ $i - ä½è´Ÿè½½ï¼ˆ50 QPSï¼‰- 3åˆ†é’Ÿ"
    python load_test.py --qps 50 --duration 180 &
    sleep 180
done

echo "âœ… æµ‹è¯•å®Œæˆ"
```

---

## éªŒè¯å’Œåˆ†æ

### éªŒè¯HPAå·¥ä½œ

```bash
#!/bin/bash
# verify-hpa.sh - éªŒè¯HPAæ˜¯å¦æ­£å¸¸å·¥ä½œ

echo "=== éªŒè¯HPAé…ç½® ==="

# 1. æ£€æŸ¥HPAæ˜¯å¦å­˜åœ¨
if kubectl get hpa milvus-querynode-hpa -n milvus-prod &> /dev/null; then
    echo "âœ… HPAå·²åˆ›å»º"
else
    echo "âŒ HPAä¸å­˜åœ¨"
    exit 1
fi

# 2. æ£€æŸ¥metrics-server
if kubectl get deployment metrics-server -n kube-system &> /dev/null; then
    echo "âœ… metrics-serverå·²å®‰è£…"
else
    echo "âŒ metrics-serveræœªå®‰è£…"
    exit 1
fi

# 3. æ£€æŸ¥HPAæŒ‡æ ‡
echo ""
echo "ğŸ“Š HPAå½“å‰çŠ¶æ€ï¼š"
kubectl get hpa milvus-querynode-hpa -n milvus-prod

# 4. æ£€æŸ¥Podèµ„æºé…ç½®
echo ""
echo "ğŸ“¦ æ£€æŸ¥Podèµ„æºé…ç½®ï¼š"
kubectl get deployment milvus-querynode -n milvus-prod -o jsonpath='{.spec.template.spec.containers[0].resources}'

# 5. æ£€æŸ¥å½“å‰å‰¯æœ¬æ•°
echo ""
echo "ğŸ“Š å½“å‰å‰¯æœ¬æ•°ï¼š"
kubectl get deployment milvus-querynode -n milvus-prod -o jsonpath='{.spec.replicas}'

echo ""
echo "âœ… HPAéªŒè¯å®Œæˆ"
```

### åˆ†ææ‰©ç¼©å®¹æ—¥å¿—

```bash
#!/bin/bash
# analyze-scaling-events.sh - åˆ†ææ‰©ç¼©å®¹äº‹ä»¶

echo "=== åˆ†ææ‰©ç¼©å®¹äº‹ä»¶ ==="

# è·å–HPAäº‹ä»¶
echo "ğŸ“ HPAæ‰©ç¼©å®¹äº‹ä»¶ï¼š"
kubectl get events -n milvus-prod \
  --field-selector involvedObject.name=milvus-querynode-hpa \
  --sort-by='.lastTimestamp'

echo ""
echo "ğŸ“ Deploymentæ‰©ç¼©å®¹äº‹ä»¶ï¼š"
kubectl get events -n milvus-prod \
  --field-selector involvedObject.name=milvus-querynode \
  --sort-by='.lastTimestamp'

# ç»Ÿè®¡æ‰©ç¼©å®¹æ¬¡æ•°
echo ""
echo "ğŸ“Š æ‰©ç¼©å®¹ç»Ÿè®¡ï¼š"
SCALE_UP=$(kubectl get events -n milvus-prod \
  --field-selector involvedObject.name=milvus-querynode-hpa \
  | grep "Scaled up" | wc -l)
SCALE_DOWN=$(kubectl get events -n milvus-prod \
  --field-selector involvedObject.name=milvus-querynode-hpa \
  | grep "Scaled down" | wc -l)

echo "æ‰©å®¹æ¬¡æ•°: $SCALE_UP"
echo "ç¼©å®¹æ¬¡æ•°: $SCALE_DOWN"
```

---

## ä¼˜åŒ–å»ºè®®

### 1. æ‰©ç¼©å®¹ç­–ç•¥ä¼˜åŒ–

```yaml
# ä¼˜åŒ–åçš„HPAé…ç½®
behavior:
  scaleUp:
    # å¿«é€Ÿæ‰©å®¹
    stabilizationWindowSeconds: 30  # ç¼©çŸ­ç­‰å¾…æ—¶é—´
    policies:
    - type: Percent
      value: 100  # æ¯æ¬¡ç¿»å€
      periodSeconds: 30
    selectPolicy: Max

  scaleDown:
    # ä¿å®ˆç¼©å®¹
    stabilizationWindowSeconds: 600  # å»¶é•¿ç­‰å¾…æ—¶é—´
    policies:
    - type: Pods
      value: 1  # æ¯æ¬¡åªç¼©å®¹1ä¸ª
      periodSeconds: 120
    selectPolicy: Min
```

### 2. èµ„æºé…ç½®ä¼˜åŒ–

```yaml
# ç¡®ä¿Podæœ‰åˆç†çš„èµ„æºé…ç½®
resources:
  requests:
    cpu: 4
    memory: 16Gi
  limits:
    cpu: 8
    memory: 32Gi

# HPAåŸºäºrequestsè®¡ç®—ä½¿ç”¨ç‡
# å¦‚æœrequestså¤ªä½ï¼Œä¼šå¯¼è‡´é¢‘ç¹æ‰©å®¹
# å¦‚æœrequestså¤ªé«˜ï¼Œä¼šå¯¼è‡´èµ„æºæµªè´¹
```

### 3. ç›‘æ§å‘Šè­¦é…ç½®

```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
- name: hpa-alerts
  rules:
  # HPAè¾¾åˆ°æœ€å¤§å‰¯æœ¬æ•°
  - alert: HPAMaxedOut
    expr: kube_hpa_status_current_replicas >= kube_hpa_spec_max_replicas
    for: 5m
    annotations:
      summary: "HPAå·²è¾¾åˆ°æœ€å¤§å‰¯æœ¬æ•°"

  # HPAé¢‘ç¹æ‰©ç¼©å®¹
  - alert: HPAFlapping
    expr: rate(kube_hpa_status_current_replicas[30m]) > 0.1
    for: 10m
    annotations:
      summary: "HPAé¢‘ç¹æ‰©ç¼©å®¹"
```

---

## æ€»ç»“

### HPAè‡ªåŠ¨æ‰©ç¼©å®¹çš„ä»·å€¼

| ç»´åº¦ | ä»·å€¼ |
|------|------|
| **æˆæœ¬ä¼˜åŒ–** | ä½å³°æœŸè‡ªåŠ¨ç¼©å®¹ï¼ŒèŠ‚çœ60-80%æˆæœ¬ |
| **æ€§èƒ½ä¿éšœ** | é«˜å³°æœŸè‡ªåŠ¨æ‰©å®¹ï¼Œä¿è¯æœåŠ¡è´¨é‡ |
| **è‡ªåŠ¨åŒ–** | æ— éœ€äººå·¥å¹²é¢„ï¼Œè‡ªåŠ¨åº”å¯¹è´Ÿè½½å˜åŒ– |
| **å¼¹æ€§** | å¿«é€Ÿå“åº”çªå‘æµé‡ |

### é…ç½®è¦ç‚¹

1. **æ‰©å®¹å¿«ï¼Œç¼©å®¹æ…¢**ï¼šé¿å…é¢‘ç¹æ³¢åŠ¨
2. **åˆç†çš„èµ„æºé…ç½®**ï¼šrequestsä¸èƒ½å¤ªä½æˆ–å¤ªé«˜
3. **å¤šæŒ‡æ ‡ç»“åˆ**ï¼šCPU + å†…å­˜ + è‡ªå®šä¹‰æŒ‡æ ‡
4. **ç›‘æ§å‘Šè­¦**ï¼šåŠæ—¶å‘ç°HPAå¼‚å¸¸

### é€‚ç”¨åœºæ™¯

- âœ… æµé‡æ³¢åŠ¨å¤§çš„RAGç³»ç»Ÿ
- âœ… éœ€è¦æˆæœ¬ä¼˜åŒ–
- âœ… éœ€è¦è‡ªåŠ¨åº”å¯¹çªå‘æµé‡
- âœ… 7x24å°æ—¶è¿è¡Œçš„æœåŠ¡

### ä¸‹ä¸€æ­¥

å®ŒæˆHPAé…ç½®åï¼Œç»§ç»­å­¦ä¹ ï¼š
- **åœºæ™¯5ï¼šç°åº¦å‘å¸ƒ** - é›¶åœæœºå‡çº§
- **ç›‘æ§å‘Šè­¦** - Prometheus + Grafana
- **æˆæœ¬ä¼˜åŒ–** - èµ„æºåˆ©ç”¨ç‡åˆ†æ
