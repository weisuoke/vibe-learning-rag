# 最小可用

掌握以下内容，就能开始使用流式响应：

## 4.1 StreamingResponse 基础用法

**核心：** 用 `StreamingResponse` 包装生成器函数

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

async def generate_data():
    """异步生成器：逐步生成数据"""
    for i in range(5):
        yield f"数据块 {i}\n"

@app.get("/stream")
async def stream_endpoint():
    return StreamingResponse(
        generate_data(),
        media_type="text/plain"
    )
```

**关键点：**
- 使用 `async def` + `yield` 定义异步生成器
- `StreamingResponse` 包装生成器
- 指定 `media_type`（内容类型）

---

## 4.2 生成器函数（yield 关键字）

**核心：** `yield` 让函数变成生成器，逐个返回值

```python
# 普通函数：一次性返回
def normal_function():
    return [1, 2, 3]

# 生成器函数：逐个返回
def generator_function():
    yield 1
    yield 2
    yield 3

# 使用
for value in generator_function():
    print(value)  # 1, 2, 3（逐个输出）
```

**为什么用生成器？**
- ✅ 内存占用低（不需要缓存所有数据）
- ✅ 可以处理无限序列
- ✅ 天然支持流式处理

---

## 4.3 异步生成器（async + yield）

**核心：** 结合 `async def` 和 `yield`，支持异步操作

```python
import asyncio

async def async_generator():
    """异步生成器：可以在生成过程中执行异步操作"""
    for i in range(3):
        await asyncio.sleep(0.5)  # 异步等待
        yield f"数据 {i}"

# 使用
async for data in async_generator():
    print(data)
```

**何时用异步生成器？**
- ✅ 需要调用异步 API（如数据库查询、HTTP 请求）
- ✅ 需要异步等待（如延迟、定时器）
- ✅ FastAPI 流式响应（推荐使用异步生成器）

---

## 4.4 AI 流式输出（OpenAI 示例）

**核心：** 调用 LLM 的流式 API，逐 token 返回

```python
from openai import AsyncOpenAI
from fastapi.responses import StreamingResponse

client = AsyncOpenAI()

async def stream_chat(prompt: str):
    """流式调用 OpenAI API"""
    stream = await client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        stream=True  # 开启流式输出
    )

    async for chunk in stream:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

@app.post("/chat")
async def chat(prompt: str):
    return StreamingResponse(
        stream_chat(prompt),
        media_type="text/plain"
    )
```

**关键点：**
- `stream=True` 开启流式模式
- `async for` 遍历流式响应
- 提取 `delta.content`（增量内容）

---

## 4.5 Server-Sent Events (SSE) 格式

**核心：** 使用 SSE 协议，前端可以用 EventSource 接收

```python
async def sse_generator():
    """SSE 格式的流式响应"""
    for i in range(5):
        # SSE 格式：data: 内容\n\n
        yield f"data: {i}\n\n"
        await asyncio.sleep(0.5)

@app.get("/sse")
async def sse_endpoint():
    return StreamingResponse(
        sse_generator(),
        media_type="text/event-stream"  # SSE 专用 MIME 类型
    )
```

**前端接收（JavaScript）：**
```javascript
const eventSource = new EventSource('/sse');
eventSource.onmessage = (event) => {
    console.log(event.data);  // 0, 1, 2, 3, 4
};
```

**SSE 格式规范：**
- 每条消息以 `data: ` 开头
- 以 `\n\n` 结尾（两个换行符）
- `media_type` 必须是 `text/event-stream`

---

## 这些知识足以：

- ✅ 实现基础的流式响应端点
- ✅ 集成 OpenAI/Anthropic 的流式 API
- ✅ 使用 SSE 协议与前端通信
- ✅ 理解生成器和异步生成器的区别
- ✅ 为后续学习打基础（错误处理、性能优化）

---

## 快速对比表

| 特性 | 普通函数 | 生成器 | 异步生成器 |
|------|---------|--------|-----------|
| 定义 | `def func()` | `def func()` | `async def func()` |
| 返回 | `return` | `yield` | `yield` |
| 调用 | `func()` | `for x in func()` | `async for x in func()` |
| 异步操作 | ❌ | ❌ | ✅ |
| 内存占用 | 高（缓存所有） | 低（逐个生成） | 低（逐个生成） |
| 适用场景 | 小数据集 | 大数据集 | 异步流式处理 |

---

## 最小可用代码模板

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI
import asyncio

app = FastAPI()
client = AsyncOpenAI()

# 1. 基础流式响应
async def basic_stream():
    for i in range(10):
        await asyncio.sleep(0.1)
        yield f"数据 {i}\n"

@app.get("/basic")
async def basic():
    return StreamingResponse(basic_stream(), media_type="text/plain")

# 2. AI 流式输出
async def ai_stream(prompt: str):
    stream = await client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        stream=True
    )
    async for chunk in stream:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

@app.post("/chat")
async def chat(prompt: str):
    return StreamingResponse(ai_stream(prompt), media_type="text/plain")

# 3. SSE 格式
async def sse_stream():
    for i in range(10):
        await asyncio.sleep(0.5)
        yield f"data: {i}\n\n"

@app.get("/sse")
async def sse():
    return StreamingResponse(sse_stream(), media_type="text/event-stream")
```

**这就是你需要的最小可用知识！** 掌握这些，就可以开始在项目中使用流式响应了。
