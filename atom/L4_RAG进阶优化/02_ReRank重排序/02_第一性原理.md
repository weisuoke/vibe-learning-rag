# 第一性原理

### 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题

### ReRank 的第一性原理

#### 1. 最基础的定义

**ReRank = 对候选结果重新计算相关性分数并排序**

仅此而已！没有更基础的了。

核心就是：给定一个 Query 和一组候选 Documents，为每个 Document 计算一个相关性分数，然后按分数排序。

```python
# ReRank 的本质
def rerank(query: str, documents: list[str]) -> list[tuple[str, float]]:
    scored_docs = []
    for doc in documents:
        score = compute_relevance(query, doc)  # 核心：计算相关性
        scored_docs.append((doc, score))
    return sorted(scored_docs, key=lambda x: x[1], reverse=True)
```

#### 2. 为什么需要 ReRank？

**核心问题：向量检索的"先天缺陷"**

向量检索（Bi-Encoder）的工作方式：

```
Query  ──→ [Encoder] ──→ Query向量
                              ↓
                         余弦相似度 ──→ 排序
                              ↑
Doc    ──→ [Encoder] ──→ Doc向量
```

**问题在哪？**

1. **Query 和 Doc 独立编码，没有交互**
   - Query 不知道 Doc 的内容
   - Doc 不知道 Query 在问什么
   - 只能通过向量"隔空比较"

2. **向量是"压缩表示"，信息有损**
   - 一段 500 字的文本压缩成 768 维向量
   - 必然丢失细节信息
   - 语义相似 ≠ 问题相关

3. **ANN 索引是"近似搜索"**
   - HNSW/IVF 为了速度牺牲精度
   - 可能漏掉真正相关的文档
   - 排序不够精确

**举个例子：**

```
Query: "Python 如何读取 JSON 文件？"

向量检索可能返回：
1. "Python 是一种编程语言..." (语义相似，但不相关)
2. "JSON 是一种数据格式..." (语义相似，但不相关)
3. "使用 json.load() 读取文件" (真正相关！但可能排在后面)
```

#### 3. ReRank 的三层价值

##### 价值1：深度语义理解

**Cross-Encoder 让 Query 和 Doc 深度交互**

```
Bi-Encoder（向量检索）：
Query: "Python读取JSON"  ──→ [0.1, 0.2, ...]
Doc:   "用json.load()"   ──→ [0.15, 0.18, ...]
                              ↓
                         余弦相似度 = 0.85

Cross-Encoder（ReRank）：
"[CLS] Python读取JSON [SEP] 用json.load() [EOS]"
                              ↓
                         [Transformer 深度交互]
                              ↓
                         相关性分数 = 0.95
```

Cross-Encoder 能理解：
- "读取" 和 "load" 是同一个意思
- "JSON" 在 Query 和 Doc 中指的是同一个东西
- 这个 Doc 确实在回答这个问题

##### 价值2：精确排序

**从"大概相关"到"精确排序"**

```
向量检索 Top-5：
1. Doc_A (相似度 0.92) - 实际相关度：中
2. Doc_B (相似度 0.90) - 实际相关度：高 ← 应该排第一
3. Doc_C (相似度 0.88) - 实际相关度：低
4. Doc_D (相似度 0.87) - 实际相关度：高 ← 应该排第二
5. Doc_E (相似度 0.85) - 实际相关度：中

ReRank 后：
1. Doc_B (分数 0.95) ← 正确！
2. Doc_D (分数 0.93) ← 正确！
3. Doc_A (分数 0.78)
4. Doc_E (分数 0.65)
5. Doc_C (分数 0.42)
```

##### 价值3：提升 RAG 最终效果

**检索质量直接影响生成质量**

```
没有 ReRank：
- LLM 收到的上下文可能包含不相关内容
- 生成的回答可能偏离主题
- 甚至产生幻觉

有 ReRank：
- LLM 收到的都是高度相关的内容
- 生成的回答更准确、更聚焦
- 减少幻觉风险
```

#### 4. 从第一性原理推导 ReRank 的设计

**推理链：**

```
1. 向量检索速度快，但精度有限
   ↓
2. 我们需要更精确的相关性判断
   ↓
3. 精确判断需要 Query 和 Doc 深度交互
   ↓
4. 深度交互需要把 Query 和 Doc 放在一起处理
   ↓
5. 这就是 Cross-Encoder 的设计思路
   ↓
6. Cross-Encoder 慢，不能用于全量检索
   ↓
7. 所以先用向量检索粗筛，再用 Cross-Encoder 精排
   ↓
8. 这就是 ReRank 的两阶段检索架构
```

**两阶段检索的必然性：**

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   全量文档（100万）                                           │
│        ↓                                                    │
│   [Bi-Encoder 向量检索] ← 快速，O(log N)                      │
│        ↓                                                    │
│   候选文档（Top 50-100）                                      │
│        ↓                                                    │
│   [Cross-Encoder ReRank] ← 精确，O(N)                        │
│        ↓                                                    │
│   最终结果（Top 5-10）                                        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 5. 一句话总结第一性原理

**ReRank 是用 Cross-Encoder 的深度交互能力，弥补向量检索的精度不足，实现"先召回、后精排"的两阶段检索架构。**

---

## 第一性原理的启示

理解了 ReRank 的第一性原理，你就能回答这些问题：

| 问题 | 答案 |
|------|------|
| 为什么不直接用 Cross-Encoder 检索？ | 太慢，无法处理百万级文档 |
| ReRank 候选数量选多少？ | 太少可能漏掉相关文档，太多会变慢，通常 50-100 |
| ReRank 能提升多少效果？ | 通常能提升 5-15% 的检索准确率 |
| 什么时候不需要 ReRank？ | 数据量小、对精度要求不高、延迟敏感的场景 |

---

**下一步：** [03_核心概念](./03_核心概念.md) - 掌握 Cross-Encoder、Bi-Encoder、相关性分数三个核心概念
