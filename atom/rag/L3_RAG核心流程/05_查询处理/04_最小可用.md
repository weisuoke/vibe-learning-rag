# 最小可用知识

## 核心理念：20% 知识解决 80% 问题

在查询处理领域，掌握核心技术可以快速提升 RAG 系统性能。本文聚焦最实用的查询处理技术，帮助你用最少的时间获得最大的效果。

---

## 一、最重要的一个技术：查询改写

### 为什么查询改写最重要？

根据 StackAI 2026 年的调查，**查询改写（Query Rewriting）是最常用的 RAG 优化技术**，原因如下：

1. **实现简单**：只需一次 LLM 调用
2. **效果显著**：可提升 15-30% 的检索准确率
3. **成本低**：相比多查询生成，只需一次改写
4. **适用广**：几乎所有 RAG 场景都能受益

**引用来源：**
- [Advanced RAG Techniques (Updated 2026)](https://www.stack-ai.com/blog/advanced-rag-techniques) - StackAI

---

### 查询改写的核心原理

**本质：** 将用户的口语化、模糊的查询转化为更适合检索的专业表达。

**转换逻辑：**

```
用户查询（口语化、模糊）
    ↓
LLM 改写（专业化、精确）
    ↓
向量检索（更好的语义匹配）
    ↓
高质量文档召回
```

**示例对比：**

| 原始查询 | 改写后查询 | 改进点 |
|----------|------------|--------|
| "Python 怎么跑得快？" | "Python 性能优化方法和最佳实践" | 专业术语、明确意图 |
| "RAG 不准怎么办？" | "提升 RAG 系统准确性的优化策略" | 具体化、可操作 |
| "这个报错啥意思？" | "Python ImportError 错误原因和解决方案" | 明确错误类型 |

---

### 最小可用实现（5 分钟上手）

**步骤 1：准备改写 Prompt**

```python
REWRITE_PROMPT = """你是一个查询优化专家。请将用户的原始查询改写为更适合检索的形式。

要求：
1. 使用专业术语替换口语化表达
2. 明确查询意图
3. 保持查询的核心含义不变
4. 输出简洁的改写结果，不要解释

原始查询：{query}

改写后的查询："""
```

**步骤 2：实现改写函数**

```python
from openai import OpenAI

client = OpenAI()

def rewrite_query(query: str) -> str:
    """改写用户查询"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # 使用便宜的模型即可
        messages=[
            {"role": "user", "content": REWRITE_PROMPT.format(query=query)}
        ],
        temperature=0.3  # 低温度保证稳定性
    )
    return response.choices[0].message.content.strip()
```

**步骤 3：集成到 RAG 流程**

```python
def rag_with_rewrite(query: str, vector_store):
    """带查询改写的 RAG"""
    # 1. 改写查询
    rewritten_query = rewrite_query(query)
    print(f"原始查询: {query}")
    print(f"改写查询: {rewritten_query}")

    # 2. 使用改写后的查询检索
    docs = vector_store.similarity_search(rewritten_query, k=5)

    # 3. 生成答案
    context = "\n\n".join([doc.page_content for doc in docs])
    answer = generate_answer(query, context)

    return answer
```

**完整示例：**

```python
from openai import OpenAI
import chromadb

client = OpenAI()

# 初始化向量数据库
chroma_client = chromadb.Client()
collection = chroma_client.create_collection("docs")

# 添加示例文档
collection.add(
    documents=[
        "Python 性能优化的核心方法包括：使用内置函数、避免全局变量、使用列表推导式、缓存计算结果。",
        "Python GIL（全局解释器锁）限制了多线程的并行执行，可以使用多进程或异步编程绕过。",
        "使用 Cython 可以将 Python 代码编译为 C 代码，显著提升执行速度。"
    ],
    ids=["doc1", "doc2", "doc3"]
)

def rewrite_query(query: str) -> str:
    """改写查询"""
    prompt = f"""将以下查询改写为更适合检索的专业表达：

原始查询：{query}

改写后的查询："""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# 测试
original_query = "Python 怎么跑得快？"
rewritten_query = rewrite_query(original_query)

print(f"原始查询: {original_query}")
print(f"改写查询: {rewritten_query}")

# 检索
results = collection.query(
    query_texts=[rewritten_query],
    n_results=2
)

print("\n检索结果:")
for doc in results['documents'][0]:
    print(f"- {doc}")
```

**预期输出：**

```
原始查询: Python 怎么跑得快？
改写查询: Python 性能优化方法和技术

检索结果:
- Python 性能优化的核心方法包括：使用内置函数、避免全局变量、使用列表推导式、缓存计算结果。
- 使用 Cython 可以将 Python 代码编译为 C 代码，显著提升执行速度。
```

---

## 二、进阶技术：多查询生成（可选）

### 什么时候需要多查询生成？

当单一改写无法覆盖查询的多样性时，使用多查询生成：

**适用场景：**
- 复杂问题（包含多个子意图）
- 探索式搜索（不确定具体要找什么）
- 对比分析（需要多角度信息）

**不适用场景：**
- 简单事实查询（"Python 的 GIL 是什么？"）
- 明确的操作指导（"如何安装 pandas？"）
- 实时性要求高（多查询增加延迟）

---

### 最小可用实现

**步骤 1：生成多个查询变体**

```python
MULTI_QUERY_PROMPT = """你是一个查询扩展专家。请为以下查询生成 3 个不同角度的变体查询。

要求：
1. 每个变体从不同角度理解原始查询
2. 保持查询的核心意图
3. 使用专业术语
4. 每行一个查询，不要编号

原始查询：{query}

变体查询："""

def generate_multi_queries(query: str, num_queries: int = 3) -> list[str]:
    """生成多个查询变体"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": MULTI_QUERY_PROMPT.format(query=query)}
        ],
        temperature=0.7  # 稍高温度增加多样性
    )

    # 解析多行输出
    queries = response.choices[0].message.content.strip().split('\n')
    queries = [q.strip() for q in queries if q.strip()]

    return queries[:num_queries]
```

**步骤 2：并行检索并合并结果**

```python
def rag_with_multi_query(query: str, vector_store):
    """带多查询生成的 RAG"""
    # 1. 生成多个查询
    queries = generate_multi_queries(query)
    print(f"原始查询: {query}")
    print(f"生成的查询变体:")
    for i, q in enumerate(queries, 1):
        print(f"  {i}. {q}")

    # 2. 并行检索
    all_docs = []
    seen_content = set()  # 去重

    for q in queries:
        docs = vector_store.similarity_search(q, k=3)
        for doc in docs:
            if doc.page_content not in seen_content:
                all_docs.append(doc)
                seen_content.add(doc.page_content)

    # 3. 生成答案
    context = "\n\n".join([doc.page_content for doc in all_docs[:5]])
    answer = generate_answer(query, context)

    return answer
```

**完整示例：**

```python
# 测试多查询生成
query = "RAG 系统如何提升准确性？"
queries = generate_multi_queries(query)

print(f"原始查询: {query}\n")
print("生成的查询变体:")
for i, q in enumerate(queries, 1):
    print(f"{i}. {q}")
```

**预期输出：**

```
原始查询: RAG 系统如何提升准确性？

生成的查询变体:
1. RAG 检索准确性优化方法
2. 减少 RAG 系统幻觉的技术
3. RAG 评估指标和调优策略
```

---

## 三、核心参数配置

### 查询改写参数

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| `model` | `gpt-4o-mini` | 便宜且效果好 |
| `temperature` | `0.3` | 低温度保证稳定性 |
| `max_tokens` | `100` | 改写通常很短 |

### 多查询生成参数

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| `model` | `gpt-4o-mini` | 性价比高 |
| `temperature` | `0.7` | 稍高温度增加多样性 |
| `num_queries` | `3-5` | 平衡覆盖率和成本 |
| `k` (每个查询) | `3` | 避免检索过多文档 |

---

## 四、常见问题与解决方案

### 问题 1：改写后的查询偏离原意

**原因：** Prompt 不够明确，或 temperature 过高

**解决方案：**

```python
# 改进的 Prompt
REWRITE_PROMPT = """你是一个查询优化专家。请将用户的原始查询改写为更适合检索的形式。

重要规则：
1. 必须保持原始查询的核心意图不变
2. 只改写表达方式，不添加新的意图
3. 使用专业术语替换口语化表达
4. 输出简洁的改写结果，不要解释

原始查询：{query}

改写后的查询："""

# 降低 temperature
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": REWRITE_PROMPT.format(query=query)}],
    temperature=0.1  # 更低的温度
)
```

---

### 问题 2：多查询生成的变体太相似

**原因：** Temperature 过低，或 Prompt 不够引导多样性

**解决方案：**

```python
MULTI_QUERY_PROMPT = """你是一个查询扩展专家。请为以下查询生成 3 个不同角度的变体查询。

要求：
1. 每个变体必须从完全不同的角度理解原始查询
2. 第一个变体：关注技术实现
3. 第二个变体：关注问题诊断
4. 第三个变体：关注最佳实践
5. 使用专业术语
6. 每行一个查询，不要编号

原始查询：{query}

变体查询："""

# 提高 temperature
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": MULTI_QUERY_PROMPT.format(query=query)}],
    temperature=0.8  # 更高的温度
)
```

---

### 问题 3：查询改写增加了延迟

**原因：** 每次查询都需要额外的 LLM 调用

**解决方案：**

1. **使用更快的模型**：`gpt-4o-mini` 比 `gpt-4` 快 5-10 倍
2. **缓存常见查询**：对高频查询缓存改写结果
3. **异步处理**：改写和检索并行执行

```python
import asyncio
from openai import AsyncOpenAI

async_client = AsyncOpenAI()

async def rewrite_query_async(query: str) -> str:
    """异步改写查询"""
    response = await async_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": REWRITE_PROMPT.format(query=query)}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

async def rag_with_rewrite_async(query: str, vector_store):
    """异步 RAG"""
    # 改写和其他准备工作可以并行
    rewritten_query = await rewrite_query_async(query)

    # 检索
    docs = vector_store.similarity_search(rewritten_query, k=5)

    # 生成答案
    context = "\n\n".join([doc.page_content for doc in docs])
    answer = await generate_answer_async(query, context)

    return answer
```

---

## 五、效果评估

### 如何评估查询处理的效果？

**方法 1：对比实验**

```python
def compare_retrieval(query: str, vector_store):
    """对比原始查询和改写查询的检索效果"""
    # 原始查询检索
    original_docs = vector_store.similarity_search(query, k=5)

    # 改写查询检索
    rewritten_query = rewrite_query(query)
    rewritten_docs = vector_store.similarity_search(rewritten_query, k=5)

    print(f"原始查询: {query}")
    print(f"改写查询: {rewritten_query}\n")

    print("原始查询检索结果:")
    for i, doc in enumerate(original_docs, 1):
        print(f"{i}. {doc.page_content[:100]}...")

    print("\n改写查询检索结果:")
    for i, doc in enumerate(rewritten_docs, 1):
        print(f"{i}. {doc.page_content[:100]}...")
```

**方法 2：人工评估**

对比原始查询和改写查询的检索结果，评估：
- 相关性：检索到的文档是否更相关？
- 多样性：是否覆盖了更多角度？
- 准确性：是否包含了回答问题所需的信息？

**方法 3：端到端评估**

最终评估生成答案的质量：
- 准确性：答案是否正确？
- 完整性：答案是否完整？
- 流畅性：答案是否自然流畅？

---

## 六、成本分析

### 查询改写的成本

**假设：**
- 使用 `gpt-4o-mini`
- 输入：50 tokens（Prompt + 查询）
- 输出：20 tokens（改写后的查询）
- 价格：$0.15 / 1M input tokens, $0.60 / 1M output tokens

**单次改写成本：**
```
成本 = (50 * 0.15 + 20 * 0.60) / 1,000,000
     = 0.0000195 美元
     ≈ 0.00002 美元
```

**1000 次查询成本：** $0.02（2 分钱）

**结论：** 查询改写的成本极低，几乎可以忽略不计。

---

### 多查询生成的成本

**假设：**
- 生成 3 个查询变体
- 每个查询检索 3 个文档
- 总共检索 9 个文档（去重后约 5-6 个）

**成本对比：**

| 方法 | LLM 调用 | 检索次数 | 相对成本 |
|------|----------|----------|----------|
| 无优化 | 1 次（生成答案） | 1 次 | 1x |
| 查询改写 | 2 次（改写 + 生成） | 1 次 | 1.1x |
| 多查询生成 | 2 次（生成查询 + 生成答案） | 3 次 | 1.3x |

**结论：** 多查询生成的成本增加约 30%，但召回率可提升 20-40%，性价比高。

---

## 七、实战建议

### 从查询改写开始

**第一步：** 实现基础的查询改写（5 分钟）

```python
def rewrite_query(query: str) -> str:
    """最简单的查询改写"""
    prompt = f"将以下查询改写为更专业的表达：{query}"
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()
```

**第二步：** 集成到现有 RAG 流程（5 分钟）

```python
# 原来的代码
docs = vector_store.similarity_search(query, k=5)

# 改为
rewritten_query = rewrite_query(query)
docs = vector_store.similarity_search(rewritten_query, k=5)
```

**第三步：** 评估效果（10 分钟）

对比改写前后的检索结果，看是否有改进。

---

### 何时升级到多查询生成？

**升级条件：**
1. 查询改写效果不够好（召回率低于 60%）
2. 用户查询普遍较复杂（包含多个子意图）
3. 对召回率要求高（宁可多召回，不能漏召回）
4. 成本不敏感（可以接受 30% 的成本增加）

**不升级条件：**
1. 查询改写已经足够好（召回率 > 70%）
2. 用户查询简单明确
3. 对延迟敏感（多查询增加 2-3 倍延迟）
4. 成本敏感

---

## 八、2025-2026 最佳实践

### Elastic 的查询改写策略

根据 Elastic 2025 年的最佳实践，查询改写应遵循以下原则：

1. **保持意图一致**：改写后的查询不应偏离原始意图
2. **增加关键词密度**：包含更多相关术语
3. **避免过度泛化**：不要丢失原始查询的特定性
4. **使用领域术语**：根据应用领域使用专业术语

**引用来源：**
- [Query Rewriting Strategies for LLMs](https://www.elastic.co/blog/query-rewriting-llms) - Elastic 2025

---

### StackAI 的多查询生成建议

根据 StackAI 2026 年的报告，多查询生成的最佳实践：

1. **生成 3-5 个查询**：过多会增加成本，过少覆盖不足
2. **确保多样性**：每个查询从不同角度理解原始意图
3. **去重结果**：检索后需要对文档去重
4. **使用 ReRank**：对合并后的结果重新排序

**引用来源：**
- [Advanced RAG Techniques (Updated 2026)](https://www.stack-ai.com/blog/advanced-rag-techniques) - StackAI

---

## 九、总结：最小可用路径

### 快速上手（10 分钟）

1. **实现查询改写**（5 分钟）
   - 准备改写 Prompt
   - 实现改写函数
   - 集成到 RAG 流程

2. **测试效果**（5 分钟）
   - 对比改写前后的检索结果
   - 评估答案质量

### 进阶优化（30 分钟）

1. **优化改写 Prompt**（10 分钟）
   - 添加更明确的规则
   - 调整 temperature
   - 测试不同模型

2. **实现多查询生成**（20 分钟）
   - 生成多个查询变体
   - 并行检索
   - 去重和合并结果

### 生产部署（1 小时）

1. **添加缓存**（20 分钟）
   - 缓存常见查询的改写结果
   - 使用 Redis 或内存缓存

2. **异步处理**（20 分钟）
   - 改写和检索并行执行
   - 减少延迟

3. **监控和评估**（20 分钟）
   - 记录改写前后的查询
   - 统计召回率和准确率
   - 持续优化 Prompt

---

## 十、关键要点

### 记住这 5 点

1. **查询改写是最实用的优化技术**：实现简单，效果显著
2. **从简单开始**：先实现基础改写，再考虑多查询生成
3. **成本极低**：查询改写的成本几乎可以忽略不计
4. **持续评估**：对比改写前后的效果，持续优化
5. **根据场景选择**：简单查询用改写，复杂查询用多查询生成

### 避免这 3 个误区

1. **不要过度优化**：如果查询改写已经足够好，不要盲目升级到多查询生成
2. **不要忽略评估**：必须对比改写前后的效果，确保有改进
3. **不要忽略成本**：虽然成本低，但大规模应用时也要考虑

---

**记住：** 查询处理的目标是提升检索质量，而不是让系统变复杂。从最简单的查询改写开始，根据实际效果决定是否需要更复杂的技术。

---

**引用来源汇总：**
- [Advanced RAG Techniques (Updated 2026)](https://www.stack-ai.com/blog/advanced-rag-techniques) - StackAI
- [Query Rewriting Strategies for LLMs](https://www.elastic.co/blog/query-rewriting-llms) - Elastic 2025
