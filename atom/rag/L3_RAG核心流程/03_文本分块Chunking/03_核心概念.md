# æ ¸å¿ƒæ¦‚å¿µ

æŒæ¡ä¸‰ç§æœ€å¸¸ç”¨çš„åˆ†å—ç­–ç•¥ï¼Œè¦†ç›– 90% çš„ RAG å¼€å‘åœºæ™¯ã€‚

---

## æ ¸å¿ƒæ¦‚å¿µ1ï¼šå›ºå®šå¤§å°åˆ†å—ï¼ˆFixed-size Chunkingï¼‰

**æŒ‰å›ºå®šå­—ç¬¦æ•°æˆ– Token æ•°åˆ‡åˆ†æ–‡æœ¬ï¼Œæ˜¯æœ€ç®€å•ç›´æ¥çš„åˆ†å—æ–¹å¼ã€‚**

```python
def fixed_size_chunk(text: str, chunk_size: int = 500, overlap: int = 50) -> list[str]:
    """
    å›ºå®šå¤§å°åˆ†å—

    Args:
        text: åŸå§‹æ–‡æœ¬
        chunk_size: æ¯ä¸ªå—çš„å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
        overlap: ç›¸é‚»å—çš„é‡å éƒ¨åˆ†ï¼ˆå­—ç¬¦æ•°ï¼‰

    Returns:
        åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨
    """
    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap  # é‡å éƒ¨åˆ†

    return chunks

# ç¤ºä¾‹
text = "Pythonæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€..." * 100
chunks = fixed_size_chunk(text, chunk_size=200, overlap=20)
print(f"åŸæ–‡é•¿åº¦: {len(text)}, åˆ†å—æ•°: {len(chunks)}")
```

### æ ¸å¿ƒå‚æ•°

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `chunk_size` | æ¯ä¸ªå—çš„å¤§å° | 200-1000 å­—ç¬¦ |
| `overlap` | é‡å å¤§å° | chunk_size çš„ 10-20% |

### é‡å ï¼ˆOverlapï¼‰çš„ä½œç”¨

```
æ²¡æœ‰é‡å ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1 â”‚â”‚ Chunk 2 â”‚â”‚ Chunk 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘           â†‘
   è¾¹ç•Œå¤„çš„å¥å­å¯èƒ½è¢«åˆ‡æ–­

æœ‰é‡å ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chunk 1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚ é‡å 
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Chunk 2   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚ é‡å 
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Chunk 3   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘
   è¾¹ç•Œå¤„çš„å†…å®¹åœ¨ä¸¤ä¸ªå—ä¸­éƒ½æœ‰
```

### ä¼˜ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… å®ç°ç®€å• | âŒ å¯èƒ½åˆ‡æ–­å¥å­/æ®µè½ |
| âœ… å—å¤§å°å¯æ§ | âŒ ä¸è€ƒè™‘è¯­ä¹‰è¾¹ç•Œ |
| âœ… å¤„ç†é€Ÿåº¦å¿« | âŒ å¯èƒ½åˆ‡æ–­ä»£ç å— |

### åœ¨ RAG å¼€å‘ä¸­çš„åº”ç”¨

**é€‚ç”¨åœºæ™¯ï¼š**
- çº¯æ–‡æœ¬å†…å®¹ï¼ˆå°è¯´ã€æ–‡ç« ï¼‰
- å¯¹åˆ†å—è´¨é‡è¦æ±‚ä¸é«˜çš„å¿«é€ŸåŸå‹
- æ–‡æœ¬ç»“æ„ä¸æ˜æ˜¾çš„åœºæ™¯

**ä¸é€‚ç”¨åœºæ™¯ï¼š**
- ä»£ç æ–‡æ¡£ï¼ˆä¼šåˆ‡æ–­å‡½æ•°ï¼‰
- ç»“æ„åŒ–æ–‡æ¡£ï¼ˆä¼šç ´åè¡¨æ ¼ï¼‰
- é—®ç­”å¯¹ï¼ˆä¼šåˆ†ç¦»é—®é¢˜å’Œç­”æ¡ˆï¼‰

---

## æ ¸å¿ƒæ¦‚å¿µ2ï¼šé€’å½’å­—ç¬¦åˆ†å—ï¼ˆRecursive Character Splittingï¼‰

**æŒ‰å±‚çº§åˆ†éš”ç¬¦é€’å½’åˆ‡åˆ†ï¼Œä¼˜å…ˆåœ¨è‡ªç„¶è¾¹ç•Œï¼ˆæ®µè½ã€å¥å­ï¼‰å¤„åˆ‡åˆ†ï¼Œæ˜¯ LangChain çš„é»˜è®¤ç­–ç•¥ã€‚**

```python
def recursive_split(
    text: str,
    chunk_size: int = 500,
    separators: list[str] = None
) -> list[str]:
    """
    é€’å½’å­—ç¬¦åˆ†å—

    æŒ‰åˆ†éš”ç¬¦ä¼˜å…ˆçº§é€’å½’åˆ‡åˆ†ï¼š
    1. å…ˆå°è¯•æŒ‰æ®µè½åˆ‡åˆ†ï¼ˆ\n\nï¼‰
    2. æ®µè½å¤ªé•¿åˆ™æŒ‰æ¢è¡Œåˆ‡åˆ†ï¼ˆ\nï¼‰
    3. è¿˜æ˜¯å¤ªé•¿åˆ™æŒ‰å¥å­åˆ‡åˆ†ï¼ˆã€‚ï¼ï¼Ÿï¼‰
    4. æœ€åæŒ‰å­—ç¬¦åˆ‡åˆ†
    """
    if separators is None:
        separators = ["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", " ", ""]

    chunks = []

    def split_recursive(text: str, seps: list[str]) -> list[str]:
        if not seps:
            # æ²¡æœ‰åˆ†éš”ç¬¦äº†ï¼Œç›´æ¥æŒ‰å­—ç¬¦åˆ‡åˆ†
            return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

        sep = seps[0]
        if sep == "":
            # ç©ºåˆ†éš”ç¬¦ï¼ŒæŒ‰å­—ç¬¦åˆ‡åˆ†
            return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

        parts = text.split(sep)
        result = []
        current = ""

        for part in parts:
            if len(current) + len(part) + len(sep) <= chunk_size:
                current += part + sep
            else:
                if current:
                    result.append(current.strip())
                if len(part) > chunk_size:
                    # è¿™éƒ¨åˆ†è¿˜æ˜¯å¤ªé•¿ï¼Œç”¨ä¸‹ä¸€çº§åˆ†éš”ç¬¦ç»§ç»­åˆ‡
                    result.extend(split_recursive(part, seps[1:]))
                else:
                    current = part + sep

        if current:
            result.append(current.strip())

        return result

    return split_recursive(text, separators)
```

### åˆ†éš”ç¬¦ä¼˜å…ˆçº§

```
ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š

1. "\n\n"  â†’ æ®µè½è¾¹ç•Œï¼ˆæœ€è‡ªç„¶çš„åˆ‡åˆ†ç‚¹ï¼‰
2. "\n"    â†’ æ¢è¡Œè¾¹ç•Œ
3. "ã€‚"    â†’ å¥å­è¾¹ç•Œï¼ˆä¸­æ–‡ï¼‰
4. "."     â†’ å¥å­è¾¹ç•Œï¼ˆè‹±æ–‡ï¼‰
5. " "     â†’ å•è¯è¾¹ç•Œ
6. ""      â†’ å­—ç¬¦è¾¹ç•Œï¼ˆæœ€åæ‰‹æ®µï¼‰

ç¤ºä¾‹ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬ä¸€æ®µå†…å®¹...                           â”‚
â”‚                                        â”‚
â”‚ ç¬¬äºŒæ®µå†…å®¹...                           â”‚  â† ä¼˜å…ˆåœ¨ \n\n å¤„åˆ‡åˆ†
â”‚                                        â”‚
â”‚ ç¬¬ä¸‰æ®µæ˜¯ä¸€ä¸ªå¾ˆé•¿å¾ˆé•¿çš„æ®µè½ï¼Œè¶…è¿‡äº†       â”‚
â”‚ chunk_sizeï¼Œæ‰€ä»¥éœ€è¦åœ¨å¥å­è¾¹ç•Œåˆ‡åˆ†ã€‚     â”‚  â† æ®µè½å¤ªé•¿ï¼Œåœ¨å¥å·å¤„åˆ‡åˆ†
â”‚ è¿™æ˜¯ç¬¬äºŒå¥ã€‚è¿™æ˜¯ç¬¬ä¸‰å¥ã€‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LangChain å®ç°

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åˆ›å»ºåˆ†å—å™¨
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,           # ç›®æ ‡å—å¤§å°
    chunk_overlap=50,         # é‡å å¤§å°
    separators=["\n\n", "\n", "ã€‚", ".", " ", ""],  # åˆ†éš”ç¬¦ä¼˜å…ˆçº§
    length_function=len,      # é•¿åº¦è®¡ç®—å‡½æ•°
)

# åˆ†å—
text = """
ç¬¬ä¸€æ®µå†…å®¹ï¼Œä»‹ç»äº†Pythonçš„åŸºæœ¬æ¦‚å¿µã€‚

ç¬¬äºŒæ®µå†…å®¹ï¼Œè¯¦ç»†è®²è§£äº†å˜é‡å’Œæ•°æ®ç±»å‹ã€‚è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒé•¿çš„æ®µè½ï¼Œ
åŒ…å«äº†å¾ˆå¤šé‡è¦çš„çŸ¥è¯†ç‚¹ã€‚æˆ‘ä»¬éœ€è¦ç†è§£å˜é‡çš„æœ¬è´¨æ˜¯ä»€ä¹ˆã€‚

ç¬¬ä¸‰æ®µå†…å®¹ï¼Œè®²è§£äº†æ§åˆ¶æµç¨‹ã€‚
"""

chunks = splitter.split_text(text)
for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1} ({len(chunk)} chars): {chunk[:50]}...")
```

### ä¼˜ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ | âŒ å—å¤§å°ä¸å®Œå…¨å‡åŒ€ |
| âœ… åœ¨è‡ªç„¶è¾¹ç•Œåˆ‡åˆ† | âŒ éœ€è¦è°ƒæ•´åˆ†éš”ç¬¦åˆ—è¡¨ |
| âœ… é€‚ç”¨äºå¤šç§æ–‡æ¡£ | âŒ å¯¹ç‰¹æ®Šæ ¼å¼æ”¯æŒæœ‰é™ |

### åœ¨ RAG å¼€å‘ä¸­çš„åº”ç”¨

**é€‚ç”¨åœºæ™¯ï¼š**
- é€šç”¨æ–‡æ¡£ï¼ˆæ–‡ç« ã€æŠ¥å‘Šã€ä¹¦ç±ï¼‰
- Markdown æ–‡æ¡£
- å¤§å¤šæ•° RAG åº”ç”¨çš„é»˜è®¤é€‰æ‹©

**æœ€ä½³å®è·µï¼š**
- ä¸­æ–‡æ–‡æ¡£ï¼šæ·»åŠ ä¸­æ–‡æ ‡ç‚¹åˆ°åˆ†éš”ç¬¦åˆ—è¡¨
- ä»£ç æ–‡æ¡£ï¼šæ·»åŠ  `\n\n\n`ï¼ˆå‡½æ•°é—´ç©ºè¡Œï¼‰
- Markdownï¼šæ·»åŠ  `#`ï¼ˆæ ‡é¢˜ï¼‰ä½œä¸ºé«˜ä¼˜å…ˆçº§åˆ†éš”ç¬¦

---

## æ ¸å¿ƒæ¦‚å¿µ3ï¼šè¯­ä¹‰åˆ†å—ï¼ˆSemantic Chunkingï¼‰

**åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦åˆ‡åˆ†ï¼Œåœ¨è¯­ä¹‰å˜åŒ–çš„åœ°æ–¹åˆ‡åˆ†ï¼Œä¿è¯æ¯ä¸ªå—å†…å®¹è¯­ä¹‰ä¸€è‡´ã€‚**

```python
import numpy as np
from typing import Callable

def semantic_chunk(
    text: str,
    embed_func: Callable[[str], list[float]],
    threshold: float = 0.5,
    min_chunk_size: int = 100
) -> list[str]:
    """
    è¯­ä¹‰åˆ†å—

    åŸç†ï¼š
    1. å…ˆæŒ‰å¥å­åˆ‡åˆ†
    2. è®¡ç®—ç›¸é‚»å¥å­çš„è¯­ä¹‰ç›¸ä¼¼åº¦
    3. åœ¨ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„åœ°æ–¹åˆ‡åˆ†

    Args:
        text: åŸå§‹æ–‡æœ¬
        embed_func: å‘é‡åŒ–å‡½æ•°
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼åˆ™åˆ‡åˆ†
        min_chunk_size: æœ€å°å—å¤§å°
    """
    # 1. æŒ‰å¥å­åˆ‡åˆ†
    import re
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ.!?])', text)
    sentences = [s.strip() for s in sentences if s.strip()]

    if len(sentences) <= 1:
        return [text]

    # 2. è®¡ç®—æ¯ä¸ªå¥å­çš„å‘é‡
    embeddings = [embed_func(s) for s in sentences]

    # 3. è®¡ç®—ç›¸é‚»å¥å­çš„ç›¸ä¼¼åº¦
    def cosine_similarity(a, b):
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    similarities = []
    for i in range(len(embeddings) - 1):
        sim = cosine_similarity(embeddings[i], embeddings[i + 1])
        similarities.append(sim)

    # 4. åœ¨ç›¸ä¼¼åº¦ä½çš„åœ°æ–¹åˆ‡åˆ†
    chunks = []
    current_chunk = sentences[0]

    for i, sim in enumerate(similarities):
        if sim < threshold and len(current_chunk) >= min_chunk_size:
            # ç›¸ä¼¼åº¦ä½ï¼Œåˆ‡åˆ†
            chunks.append(current_chunk)
            current_chunk = sentences[i + 1]
        else:
            # ç›¸ä¼¼åº¦é«˜ï¼Œåˆå¹¶
            current_chunk += sentences[i + 1]

    if current_chunk:
        chunks.append(current_chunk)

    return chunks
```

### å·¥ä½œåŸç†

```
åŸæ–‡ï¼š
"Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒç®€å•æ˜“å­¦ã€‚  â† ç›¸ä¼¼åº¦é«˜ï¼Œä¸åˆ‡åˆ†

 æœºå™¨å­¦ä¹ æ˜¯AIçš„åˆ†æ”¯ã€‚æ·±åº¦å­¦ä¹ å¾ˆæµè¡Œã€‚" â† ç›¸ä¼¼åº¦é«˜ï¼Œä¸åˆ‡åˆ†
      â†‘
   è¿™é‡Œè¯­ä¹‰å˜åŒ–å¤§ï¼Œç›¸ä¼¼åº¦ä½ï¼Œåˆ‡åˆ†ï¼

ç»“æœï¼š
Chunk 1: "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒç®€å•æ˜“å­¦ã€‚"
Chunk 2: "æœºå™¨å­¦ä¹ æ˜¯AIçš„åˆ†æ”¯ã€‚æ·±åº¦å­¦ä¹ å¾ˆæµè¡Œã€‚"
```

### ç›¸ä¼¼åº¦é˜ˆå€¼çš„å½±å“

```
é˜ˆå€¼ = 0.8ï¼ˆé«˜ï¼‰ï¼š
- åˆ‡åˆ†ç‚¹å¤š
- å—æ›´å°
- æ¯ä¸ªå—è¯­ä¹‰æ›´çº¯ç²¹

é˜ˆå€¼ = 0.3ï¼ˆä½ï¼‰ï¼š
- åˆ‡åˆ†ç‚¹å°‘
- å—æ›´å¤§
- å¯èƒ½æ··åˆå¤šä¸ªä¸»é¢˜
```

### LangChain å®ç°

```python
from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai import OpenAIEmbeddings

# åˆ›å»ºè¯­ä¹‰åˆ†å—å™¨
embeddings = OpenAIEmbeddings()
semantic_splitter = SemanticChunker(
    embeddings=embeddings,
    breakpoint_threshold_type="percentile",  # ä½¿ç”¨ç™¾åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
    breakpoint_threshold_amount=95,          # 95% åˆ†ä½æ•°
)

# åˆ†å—
chunks = semantic_splitter.split_text(text)
```

### ä¼˜ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… è¯­ä¹‰å®Œæ•´æ€§æœ€å¥½ | âŒ éœ€è¦è°ƒç”¨ Embedding API |
| âœ… å—å†…å®¹ä¸»é¢˜ä¸€è‡´ | âŒ å¤„ç†é€Ÿåº¦æ…¢ |
| âœ… é€‚åˆä¸»é¢˜å¤šå˜çš„æ–‡æ¡£ | âŒ æˆæœ¬è¾ƒé«˜ |

### åœ¨ RAG å¼€å‘ä¸­çš„åº”ç”¨

**é€‚ç”¨åœºæ™¯ï¼š**
- ä¸»é¢˜é¢‘ç¹å˜åŒ–çš„æ–‡æ¡£
- å¯¹æ£€ç´¢è´¨é‡è¦æ±‚æé«˜çš„åœºæ™¯
- æ–‡æ¡£ç»“æ„ä¸è§„åˆ™çš„æƒ…å†µ

**ä¸é€‚ç”¨åœºæ™¯ï¼š**
- å¤§è§„æ¨¡æ–‡æ¡£å¤„ç†ï¼ˆæˆæœ¬é«˜ï¼‰
- å®æ—¶å¤„ç†åœºæ™¯ï¼ˆé€Ÿåº¦æ…¢ï¼‰
- é¢„ç®—æœ‰é™çš„é¡¹ç›®

---

## ä¸‰ç§ç­–ç•¥å¯¹æ¯”

| ç‰¹æ€§ | å›ºå®šå¤§å° | é€’å½’å­—ç¬¦ | è¯­ä¹‰åˆ†å— |
|------|----------|----------|----------|
| **å®ç°å¤æ‚åº¦** | â­ | â­â­ | â­â­â­ |
| **å¤„ç†é€Ÿåº¦** | ğŸš€ğŸš€ğŸš€ | ğŸš€ğŸš€ | ğŸš€ |
| **è¯­ä¹‰å®Œæ•´æ€§** | âŒ | âœ… | âœ…âœ… |
| **å—å¤§å°å¯æ§** | âœ…âœ… | âœ… | âŒ |
| **API æˆæœ¬** | æ—  | æ—  | é«˜ |
| **æ¨èåœºæ™¯** | å¿«é€ŸåŸå‹ | é€šç”¨åœºæ™¯ | é«˜è´¨é‡è¦æ±‚ |

---

## é€‰æ‹©ç­–ç•¥çš„å†³ç­–æ ‘

```
å¼€å§‹
  â”‚
  â”œâ”€ æ˜¯å¦éœ€è¦å¿«é€ŸåŸå‹ï¼Ÿ
  â”‚     â”‚
  â”‚     â”œâ”€ æ˜¯ â†’ å›ºå®šå¤§å°åˆ†å—
  â”‚     â”‚
  â”‚     â””â”€ å¦ â†“
  â”‚
  â”œâ”€ æ–‡æ¡£æ˜¯å¦æœ‰æ˜æ˜¾ç»“æ„ï¼ˆæ®µè½ã€æ ‡é¢˜ï¼‰ï¼Ÿ
  â”‚     â”‚
  â”‚     â”œâ”€ æ˜¯ â†’ é€’å½’å­—ç¬¦åˆ†å—ï¼ˆæ¨èï¼‰
  â”‚     â”‚
  â”‚     â””â”€ å¦ â†“
  â”‚
  â”œâ”€ æ˜¯å¦å¯¹è´¨é‡è¦æ±‚æé«˜ä¸”é¢„ç®—å……è¶³ï¼Ÿ
  â”‚     â”‚
  â”‚     â”œâ”€ æ˜¯ â†’ è¯­ä¹‰åˆ†å—
  â”‚     â”‚
  â”‚     â””â”€ å¦ â†’ é€’å½’å­—ç¬¦åˆ†å—
  â”‚
  â””â”€ é»˜è®¤æ¨èï¼šé€’å½’å­—ç¬¦åˆ†å—
```

---

**ä¸‹ä¸€æ­¥ï¼š** [04_æœ€å°å¯ç”¨](./04_æœ€å°å¯ç”¨.md) - æŒæ¡ 20% æ ¸å¿ƒçŸ¥è¯†è§£å†³ 80% é—®é¢˜
