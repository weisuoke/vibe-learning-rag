# 化骨绵掌

> 10个2分钟知识卡片，快速掌握 LCEL 核心知识

---

## 卡片1：LCEL 是什么？

**一句话：** LCEL 是用管道操作符 `|` 连接 LLM 调用的表达式语言，让 AI 流程像搭积木一样简单。

**举例：**
```python
# 传统方式：嵌套地狱
result = parser.invoke(llm.invoke(prompt.invoke(input)))

# LCEL 方式：线性管道
chain = prompt | llm | parser
result = chain.invoke(input)
```

**应用：** 在 FastAPI 后端中，用 LCEL 构建从简单问答到复杂 RAG 的各类 AI 应用。

---

## 卡片2：Runnable 接口

**一句话：** Runnable 是 LCEL 的核心接口，所有组件都实现这个接口，提供统一的调用方式。

**举例：**
```python
class Runnable:
    def invoke(self, input):      # 同步调用
        pass

    async def ainvoke(self, input):  # 异步调用
        pass

    def stream(self, input):      # 流式调用
        pass

    def __or__(self, other):      # 支持 | 操作符
        return RunnableSequence([self, other])
```

**应用：** 因为统一接口，所有组件都可以用 `|` 连接，实现真正的可组合性。

---

## 卡片3：管道操作符 `|`

**一句话：** `|` 是 LCEL 的核心语法，用于连接多个 Runnable 组件，数据从左到右流动。

**举例：**
```python
# a | b | c 等价于
RunnableSequence([a, b, c])

# 执行时
result = a.invoke(input)
result = b.invoke(result)
result = c.invoke(result)
```

**应用：** 构建线性的 AI 流程，如 Prompt → LLM → Parser。

---

## 卡片4：三大核心组件

**一句话：** PromptTemplate（格式化输入）+ ChatModel（调用 LLM）+ OutputParser（解析输出）= 完整的 AI 流程。

**举例：**
```python
# 1. PromptTemplate：格式化输入
prompt = ChatPromptTemplate.from_template("回答：{question}")

# 2. ChatModel：调用 LLM
llm = ChatOpenAI(model="gpt-3.5-turbo")

# 3. OutputParser：解析输出
parser = StrOutputParser()

# 组合
chain = prompt | llm | parser
```

**应用：** 这是最基础的问答链，90%的场景都基于这个模式。

---

## 卡片5：RunnablePassthrough

**一句话：** RunnablePassthrough 保留原始输入，常用于需要同时使用原始数据和处理后数据的场景。

**举例：**
```python
# RAG 场景：需要同时传递检索结果和原始问题
chain = {
    "context": retriever,              # 检索文档
    "question": RunnablePassthrough()  # 保留原始问题
} | prompt | llm | parser

# 如果不用 RunnablePassthrough，原始问题会丢失
```

**应用：** RAG 链中必不可少，用于保留原始问题传递给 Prompt。

---

## 卡片6：并行执行

**一句话：** 用字典语法 `{}` 自动触发并行执行，多个任务同时运行，显著提升性能。

**举例：**
```python
# 串行执行（慢）：6秒
summary = summarizer.invoke(text)      # 2秒
keywords = extractor.invoke(text)      # 2秒
sentiment = analyzer.invoke(text)      # 2秒

# 并行执行（快）：2秒
results = {
    "summary": summarizer,
    "keywords": extractor,
    "sentiment": analyzer
}.invoke(text)
```

**应用：** 多个独立任务（检索、总结、分析）同时执行，性能提升3倍。

---

## 卡片7：条件分支

**一句话：** RunnableBranch 根据条件选择不同的执行路径，类似于 if-elif-else。

**举例：**
```python
# 根据问题长度选择不同的链
router = RunnableBranch(
    (lambda x: len(x) < 100, simple_chain),    # 短问题 → 快速回答
    (lambda x: len(x) < 500, normal_chain),    # 中等问题 → 详细回答
    complex_chain                               # 长问题 → 深入分析
)

result = router.invoke(question)
```

**应用：** 根据用户类型、问题复杂度、语言等条件路由到不同的处理链。

---

## 卡片8：流式输出

**一句话：** 用 `astream()` 逐块返回结果，像 ChatGPT 一样逐字显示，提升用户体验。

**举例：**
```python
# 普通输出：等待10秒，一次性显示
result = chain.invoke(input)
print(result)

# 流式输出：立即开始显示
async for chunk in chain.astream(input):
    print(chunk, end="", flush=True)
```

**应用：** FastAPI 中用 StreamingResponse 返回流式数据，前端实时显示。

---

## 卡片9：错误处理

**一句话：** with_retry（重试）+ with_fallbacks（降级）= 生产级可靠性。

**举例：**
```python
# 先重试，再降级
llm = (
    ChatOpenAI(model="gpt-4")
    .with_retry(stop_after_attempt=3)  # 重试3次
    .with_fallbacks([                   # 失败后降级
        ChatOpenAI(model="gpt-3.5-turbo"),
        ChatOpenAI(model="gpt-3.5-turbo-16k")
    ])
)

chain = prompt | llm | parser
```

**应用：** 保证服务可用性，主模型失败时自动切换到备用模型。

---

## 卡片10：RAG 链

**一句话：** RAG 链 = 检索（Retriever）+ 保留问题（RunnablePassthrough）+ Prompt + LLM + Parser。

**举例：**
```python
# 完整的 RAG 链
rag_chain = (
    # 步骤1：并行执行检索和问题保留
    {
        "context": vectorstore.as_retriever() | format_docs,
        "question": RunnablePassthrough()
    }
    # 步骤2：构建 Prompt
    | ChatPromptTemplate.from_template(
        "基于以下上下文回答问题：\n\n{context}\n\n问题：{question}"
    )
    # 步骤3：LLM 生成
    | ChatOpenAI()
    # 步骤4：解析输出
    | StrOutputParser()
)

answer = rag_chain.invoke("什么是 LCEL？")
```

**应用：** 文档问答、知识库检索、智能客服等场景的核心实现。

---

## 知识卡片总结

### 核心概念（卡片1-4）

| 卡片 | 核心知识 | 关键语法 |
|------|---------|---------|
| 1 | LCEL 是什么 | `a \| b \| c` |
| 2 | Runnable 接口 | `invoke()`, `ainvoke()`, `stream()` |
| 3 | 管道操作符 | `\|` 连接组件 |
| 4 | 三大核心组件 | Prompt + LLM + Parser |

### 高级特性（卡片5-9）

| 卡片 | 核心知识 | 关键语法 |
|------|---------|---------|
| 5 | RunnablePassthrough | 保留原始输入 |
| 6 | 并行执行 | `{...}` 字典语法 |
| 7 | 条件分支 | `RunnableBranch` |
| 8 | 流式输出 | `astream()` |
| 9 | 错误处理 | `with_retry()`, `with_fallbacks()` |

### 实战应用（卡片10）

| 卡片 | 核心知识 | 应用场景 |
|------|---------|---------|
| 10 | RAG 链 | 文档问答、知识库检索 |

---

## 快速参考

### 最常用的5个模式

**1. 简单问答**
```python
chain = prompt | llm | parser
```

**2. RAG 检索**
```python
chain = {
    "context": retriever,
    "question": RunnablePassthrough()
} | prompt | llm | parser
```

**3. 并行执行**
```python
chain = {
    "task1": chain1,
    "task2": chain2,
    "task3": chain3
}
```

**4. 流式输出**
```python
async for chunk in chain.astream(input):
    print(chunk, end="")
```

**5. 错误处理**
```python
llm = llm.with_retry(...).with_fallbacks([...])
```

---

## 学习路径

### 第1天：基础概念（卡片1-4）
- 理解 LCEL 是什么
- 掌握 Runnable 接口
- 学会用 `|` 连接组件
- 构建第一个问答链

### 第2天：高级特性（卡片5-7）
- 使用 RunnablePassthrough
- 实现并行执行
- 添加条件分支

### 第3天：生产特性（卡片8-9）
- 实现流式输出
- 添加错误处理

### 第4天：实战应用（卡片10）
- 构建完整的 RAG 链
- 集成到 FastAPI

---

## 常见问题速查

### Q1: 什么时候用 invoke()，什么时候用 ainvoke()？
**A**: FastAPI 端点用 `ainvoke()`，脚本/命令行用 `invoke()`。

### Q2: 如何保留原始输入？
**A**: 使用 `RunnablePassthrough()`。

### Q3: 如何并行执行多个任务？
**A**: 使用字典语法 `{"task1": chain1, "task2": chain2}`。

### Q4: 如何实现流式输出？
**A**: 使用 `astream()` 方法。

### Q5: 如何处理错误？
**A**: 使用 `with_retry()` 重试，`with_fallbacks()` 降级。

### Q6: RAG 链的核心结构是什么？
**A**: `{"context": retriever, "question": RunnablePassthrough()} | prompt | llm | parser`

### Q7: 如何调试 LCEL 链？
**A**: 使用 `RunnableLambda` 插入打印语句，或使用 LangSmith 追踪。

### Q8: LCEL 和传统函数调用有什么区别？
**A**: LCEL 是声明式（描述做什么），传统是命令式（告诉怎么做）。

### Q9: 为什么要用 LCEL？
**A**: 可读性、可组合性、可流式、内置优化。

### Q10: LCEL 的性能开销大吗？
**A**: 几乎为零，主要开销来自 LLM 调用，LCEL 本身可忽略。

---

## 记忆口诀

**LCEL 核心三要素**：
- **管道**：`|` 连接组件
- **接口**：Runnable 统一调用
- **组合**：像搭积木一样

**RAG 链四步骤**：
1. **检索**：retriever
2. **保留**：RunnablePassthrough
3. **生成**：prompt | llm
4. **解析**：parser

**生产级三保障**：
1. **重试**：with_retry
2. **降级**：with_fallbacks
3. **流式**：astream

---

## 学习检查清单

完成10个知识卡片后，你应该能够：

- [ ] 用一句话解释 LCEL 是什么
- [ ] 理解 Runnable 接口的核心方法
- [ ] 使用 `|` 连接多个组件
- [ ] 构建 Prompt → LLM → Parser 的基础链
- [ ] 使用 RunnablePassthrough 保留原始输入
- [ ] 使用字典语法实现并行执行
- [ ] 使用 RunnableBranch 实现条件分支
- [ ] 使用 astream() 实现流式输出
- [ ] 使用 with_retry() 和 with_fallbacks() 处理错误
- [ ] 构建完整的 RAG 检索链

---

## 下一步学习

掌握了这10个知识卡片后，你已经具备了使用 LCEL 的核心能力。接下来可以：

1. **深入学习**：阅读完整的核心概念文档
2. **实战练习**：运行实战代码示例
3. **项目实践**：在实际项目中应用 LCEL
4. **进阶学习**：学习 LangGraph、Agent 等高级特性

---

**版本**: v1.0
**最后更新**: 2026-02-12
