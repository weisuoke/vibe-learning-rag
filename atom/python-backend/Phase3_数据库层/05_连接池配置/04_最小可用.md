# 最小可用

掌握以下内容，就能开始使用连接池配置：

## 4.1 创建带连接池的数据库引擎

**核心：** 使用 `create_engine()` 配置连接池参数

```python
from sqlalchemy import create_engine

# 最基础的连接池配置
engine = create_engine(
    "postgresql://user:password@localhost:5432/dbname",
    pool_size=5,              # 常驻连接数：5个
    max_overflow=10,          # 临时连接数：最多10个
    pool_timeout=30,          # 获取连接超时：30秒
    pool_recycle=3600,        # 连接回收时间：1小时
    pool_pre_ping=True,       # 连接前检测：防止使用失效连接
)
```

**前端类比：**
```javascript
// 类似 HTTP 连接池配置
const agent = new http.Agent({
  keepAlive: true,
  maxSockets: 5,        // 类似 pool_size
  maxFreeSockets: 10,   // 类似 max_overflow
  timeout: 30000,       // 类似 pool_timeout
});
```

**这个配置能做什么：**
- ✅ 自动管理5个常驻连接
- ✅ 高并发时最多创建15个连接（5+10）
- ✅ 获取连接超时自动报错
- ✅ 连接超过1小时自动回收
- ✅ 使用前自动检测连接是否有效

---

## 4.2 在 FastAPI 中集成连接池

**核心：** 使用依赖注入管理 Session 生命周期

```python
from fastapi import FastAPI, Depends
from sqlalchemy.orm import sessionmaker, Session

# 1. 创建 SessionLocal 类
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine  # 绑定到带连接池的引擎
)

# 2. 依赖注入函数
def get_db():
    db = SessionLocal()  # 从连接池获取连接
    try:
        yield db
    finally:
        db.close()  # 归还连接到池中

# 3. 在路由中使用
app = FastAPI()

@app.get("/users/{user_id}")
async def get_user(user_id: int, db: Session = Depends(get_db)):
    # db 会自动从连接池获取连接
    user = db.query(User).filter(User.id == user_id).first()
    return user
    # 请求结束后，连接自动归还到池中
```

**前端类比：**
```javascript
// 类似 Express 中间件管理数据库连接
app.use((req, res, next) => {
  req.db = pool.getConnection();  // 获取连接
  res.on('finish', () => {
    req.db.release();  // 归还连接
  });
  next();
});

app.get('/users/:id', (req, res) => {
  const user = req.db.query('SELECT * FROM users WHERE id = ?', [req.params.id]);
  res.json(user);
});
```

**这个配置能做什么：**
- ✅ 每个请求自动获取数据库连接
- ✅ 请求结束后自动归还连接
- ✅ 异常情况下也能正确归还连接
- ✅ 无需手动管理连接生命周期

---

## 4.3 配置连接池参数（根据并发量）

**核心：** 根据实际并发量调整 `pool_size` 和 `max_overflow`

```python
# 低并发场景（个人项目、内部工具）
engine = create_engine(
    DATABASE_URL,
    pool_size=5,       # 5个常驻连接
    max_overflow=5,    # 最多10个连接
)

# 中等并发场景（小型 API 服务）
engine = create_engine(
    DATABASE_URL,
    pool_size=10,      # 10个常驻连接
    max_overflow=20,   # 最多30个连接
)

# 高并发场景（生产环境 API）
engine = create_engine(
    DATABASE_URL,
    pool_size=20,      # 20个常驻连接
    max_overflow=30,   # 最多50个连接
)
```

**配置公式（经验值）：**
```python
# pool_size = 预期并发请求数 × 0.5
# max_overflow = pool_size × 1.5

# 示例：预期100个并发请求
pool_size = 100 * 0.5 = 50
max_overflow = 50 * 1.5 = 75
```

**日常生活类比：**
- **pool_size（常驻座位）**：餐厅固定座位数，根据平时客流量配置
- **max_overflow（临时座位）**：高峰期临时加座，应对突发流量
- **总连接数**：pool_size + max_overflow = 餐厅最大容纳人数

**这个配置能做什么：**
- ✅ 避免连接数过少导致请求排队
- ✅ 避免连接数过多浪费资源
- ✅ 根据实际负载动态调整

---

## 4.4 设置连接超时和回收

**核心：** 防止连接泄漏和失效连接

```python
engine = create_engine(
    DATABASE_URL,
    pool_timeout=30,       # 获取连接超时：30秒
    pool_recycle=3600,     # 连接回收时间：1小时
    pool_pre_ping=True,    # 连接前检测：防止使用失效连接
)
```

**参数说明：**

1. **pool_timeout（获取连接超时）**
   ```python
   # 如果30秒内无法获取连接，抛出异常
   # 防止请求无限等待
   pool_timeout=30
   ```

2. **pool_recycle（连接回收时间）**
   ```python
   # 连接使用超过1小时后，自动关闭并重新创建
   # 防止数据库主动断开连接导致的错误
   pool_recycle=3600  # 1小时 = 3600秒
   ```

3. **pool_pre_ping（连接前检测）**
   ```python
   # 使用连接前先发送一个简单查询（SELECT 1）
   # 如果连接失效，自动重新创建
   pool_pre_ping=True
   ```

**前端类比：**
```javascript
// 类似 HTTP 请求超时配置
fetch('https://api.example.com/users', {
  timeout: 30000,  // 类似 pool_timeout
  keepalive: true, // 类似连接复用
});

// 类似 WebSocket 心跳检测
ws.on('open', () => {
  setInterval(() => {
    ws.ping();  // 类似 pool_pre_ping
  }, 30000);
});
```

**这个配置能做什么：**
- ✅ 防止请求无限等待（pool_timeout）
- ✅ 防止使用失效连接（pool_recycle + pool_pre_ping）
- ✅ 自动处理数据库连接断开的情况

---

## 4.5 环境变量配置（生产最佳实践）

**核心：** 使用环境变量管理连接池配置

```python
import os
from sqlalchemy import create_engine

# 从环境变量读取配置
DATABASE_URL = os.getenv("DATABASE_URL")
POOL_SIZE = int(os.getenv("POOL_SIZE", "10"))
MAX_OVERFLOW = int(os.getenv("MAX_OVERFLOW", "20"))
POOL_TIMEOUT = int(os.getenv("POOL_TIMEOUT", "30"))
POOL_RECYCLE = int(os.getenv("POOL_RECYCLE", "3600"))

# 创建引擎
engine = create_engine(
    DATABASE_URL,
    pool_size=POOL_SIZE,
    max_overflow=MAX_OVERFLOW,
    pool_timeout=POOL_TIMEOUT,
    pool_recycle=POOL_RECYCLE,
    pool_pre_ping=True,
)
```

**.env 文件：**
```bash
# 开发环境
DATABASE_URL=postgresql://user:password@localhost:5432/dev_db
POOL_SIZE=5
MAX_OVERFLOW=5

# 生产环境
DATABASE_URL=postgresql://user:password@prod-db:5432/prod_db
POOL_SIZE=20
MAX_OVERFLOW=30
```

**前端类比：**
```javascript
// 类似前端环境变量配置
const API_URL = process.env.REACT_APP_API_URL;
const TIMEOUT = parseInt(process.env.REACT_APP_TIMEOUT || '30000');
```

**这个配置能做什么：**
- ✅ 不同环境使用不同配置（开发/测试/生产）
- ✅ 敏感信息不写在代码中
- ✅ 方便运维调整参数

---

## 这些知识足以：

### 能做什么

1. **创建生产级连接池配置**
   - 配置合理的连接数
   - 设置超时和回收参数
   - 防止连接泄漏和失效

2. **在 FastAPI 中正确使用连接池**
   - 使用依赖注入管理 Session
   - 自动获取和归还连接
   - 处理异常情况

3. **根据实际负载调优**
   - 根据并发量调整 pool_size
   - 根据数据库限制调整 max_overflow
   - 根据网络延迟调整 pool_timeout

### 为后续学习打基础

- **监控连接池状态**：查看连接池使用情况，发现性能瓶颈
- **处理连接池异常**：连接池耗尽、连接泄漏等问题
- **高级连接池配置**：自定义连接池类、连接池事件监听

---

## 快速检查清单

完成最小可用学习后，你应该能够：

- [ ] 创建带连接池的 SQLAlchemy 引擎
- [ ] 在 FastAPI 中使用依赖注入管理 Session
- [ ] 根据并发量配置 pool_size 和 max_overflow
- [ ] 设置 pool_timeout、pool_recycle、pool_pre_ping
- [ ] 使用环境变量管理连接池配置

---

## 最小可用代码模板

```python
# app/core/database.py
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from fastapi import Depends

# 1. 从环境变量读取配置
DATABASE_URL = os.getenv("DATABASE_URL")
POOL_SIZE = int(os.getenv("POOL_SIZE", "10"))
MAX_OVERFLOW = int(os.getenv("MAX_OVERFLOW", "20"))

# 2. 创建引擎（带连接池）
engine = create_engine(
    DATABASE_URL,
    pool_size=POOL_SIZE,
    max_overflow=MAX_OVERFLOW,
    pool_timeout=30,
    pool_recycle=3600,
    pool_pre_ping=True,
)

# 3. 创建 SessionLocal 类
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# 4. 依赖注入函数
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# 5. 在路由中使用
# from app.core.database import get_db
# @app.get("/users/{user_id}")
# async def get_user(user_id: int, db: Session = Depends(get_db)):
#     user = db.query(User).filter(User.id == user_id).first()
#     return user
```

**复制这个模板，修改环境变量，就能开始使用连接池！**
