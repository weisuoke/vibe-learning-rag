# 最小可用知识

> **20%的核心知识解决80%的幻觉检测问题**

---

## 核心原则

**幻觉检测的本质：验证生成内容 ⊆ 检索上下文**

```
检索上下文 = {文档1, 文档2, ..., 文档N}
生成内容 = {声明1, 声明2, ..., 声明M}

目标：∀ 声明i ∈ 生成内容, ∃ 文档j ∈ 检索上下文, 文档j ⊢ 声明i
```

---

## 必须掌握的4个核心技术

### 1. Faithfulness评估（入门首选）

**原理：** 使用LLM评估生成内容与检索上下文的事实一致性

**最小实现：**

```python
from ragas.metrics import faithfulness
from ragas import evaluate
from datasets import Dataset

# 准备评估数据
data = {
    "question": ["什么是Python?"],
    "contexts": [["Python是一种高级编程语言，由Guido van Rossum创建。"]],
    "answer": ["Python是由Guido创建的编程语言。"]
}

dataset = Dataset.from_dict(data)

# 评估Faithfulness
result = evaluate(dataset, metrics=[faithfulness])
print(f"Faithfulness分数: {result['faithfulness']}")
```

**判断标准：**
- **>0.9**：优秀，几乎无幻觉
- **0.7-0.9**：良好，可接受
- **<0.7**：需要优化或拒绝回答

---

### 2. NLI三分类验证（提升准确率）

**原理：** 判断检索上下文（前提）是否蕴含生成声明（假设）

**最小实现：**

```python
from transformers import pipeline

# 加载NLI模型
nli_model = pipeline(
    "text-classification",
    model="microsoft/deberta-v3-base-mnli-fever-anli"
)

def verify_claim(context: str, claim: str) -> dict:
    """验证声明是否被上下文蕴含"""
    result = nli_model(f"{context} [SEP] {claim}")
    return {
        "label": result[0]["label"],  # entailment/contradiction/neutral
        "score": result[0]["score"]
    }

# 使用示例
context = "Python是一种高级编程语言，由Guido van Rossum于1991年创建。"
claim = "Python是由Guido创建的。"

result = verify_claim(context, claim)
print(f"验证结果: {result['label']} (置信度: {result['score']:.2f})")
```

**判断标准：**
- **entailment + score>0.8**：声明被支持
- **contradiction**：声明与上下文矛盾（幻觉）
- **neutral**：上下文未提及（可能是幻觉）

---

### 3. 声明分解（细粒度检测）

**原理：** 将复杂句子拆分为原子声明，逐一验证

**最小实现：**

```python
from openai import OpenAI

client = OpenAI()

def decompose_claims(response: str) -> list[str]:
    """将回答拆分为原子声明"""
    prompt = f"""
将以下回答拆分为独立的原子声明（每个声明只包含一个可验证的事实）：

回答：{response}

要求：
1. 每个声明独立完整
2. 不包含推理或解释
3. 可以独立验证真伪

输出格式：每行一个声明
"""

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    claims = completion.choices[0].message.content.strip().split("\n")
    return [c.strip("- ").strip() for c in claims if c.strip()]

# 使用示例
response = "Python是一种高级编程语言，由Guido van Rossum于1991年创建，广泛用于数据科学和Web开发。"
claims = decompose_claims(response)

for i, claim in enumerate(claims, 1):
    print(f"{i}. {claim}")
```

**输出示例：**
```
1. Python是一种高级编程语言
2. Python由Guido van Rossum创建
3. Python于1991年创建
4. Python广泛用于数据科学
5. Python广泛用于Web开发
```

---

### 4. 引用溯源（提升可信度）

**原理：** 为每个声明标注源文档位置

**最小实现：**

```python
from sentence_transformers import SentenceTransformer, util

# 加载Embedding模型
model = SentenceTransformer('all-MiniLM-L6-v2')

def find_supporting_context(claim: str, contexts: list[str], threshold: float = 0.7) -> dict:
    """为声明找到支持的上下文"""
    claim_embedding = model.encode(claim, convert_to_tensor=True)
    context_embeddings = model.encode(contexts, convert_to_tensor=True)

    # 计算相似度
    similarities = util.cos_sim(claim_embedding, context_embeddings)[0]

    # 找到最相似的上下文
    best_idx = similarities.argmax().item()
    best_score = similarities[best_idx].item()

    if best_score >= threshold:
        return {
            "supported": True,
            "source_index": best_idx,
            "source_text": contexts[best_idx],
            "similarity": best_score
        }
    else:
        return {
            "supported": False,
            "similarity": best_score
        }

# 使用示例
claim = "Python由Guido van Rossum创建"
contexts = [
    "Python是一种高级编程语言。",
    "Python由Guido van Rossum于1991年创建。",
    "Python广泛用于数据科学。"
]

result = find_supporting_context(claim, contexts)
if result["supported"]:
    print(f"✅ 声明被支持")
    print(f"   来源: {result['source_text']}")
    print(f"   相似度: {result['similarity']:.2f}")
else:
    print(f"❌ 声明未被支持（相似度: {result['similarity']:.2f}）")
```

---

## 最小可用流程

### 完整检测流程（5步）

```python
def detect_hallucination(question: str, contexts: list[str], answer: str) -> dict:
    """完整的幻觉检测流程"""

    # 步骤1: Faithfulness评估（快速筛选）
    faithfulness_score = evaluate_faithfulness(question, contexts, answer)
    if faithfulness_score < 0.7:
        return {"has_hallucination": True, "reason": "Low faithfulness score"}

    # 步骤2: 声明分解
    claims = decompose_claims(answer)

    # 步骤3: 逐一验证声明
    verified_claims = []
    for claim in claims:
        # 步骤4: NLI验证
        nli_result = verify_claim_with_nli(contexts, claim)

        # 步骤5: 引用溯源
        attribution = find_supporting_context(claim, contexts)

        verified_claims.append({
            "claim": claim,
            "nli_label": nli_result["label"],
            "nli_score": nli_result["score"],
            "supported": attribution["supported"],
            "source": attribution.get("source_text", None)
        })

    # 计算支持率
    support_ratio = sum(1 for c in verified_claims if c["supported"]) / len(verified_claims)

    return {
        "has_hallucination": support_ratio < 0.8,
        "support_ratio": support_ratio,
        "verified_claims": verified_claims
    }
```

---

## 快速决策树

```
收到RAG生成结果
    ↓
是否需要高可信度？
    ├─ 否 → 直接返回（跳过检测）
    └─ 是 ↓
         运行Faithfulness评估
              ↓
         分数 >= 0.7？
              ├─ 是 → 返回结果
              └─ 否 ↓
                   声明分解 + NLI验证
                        ↓
                   支持率 >= 80%？
                        ├─ 是 → 添加引用后返回
                        └─ 否 → 拒绝回答或重新生成
```

---

## 20%核心配置

### 推荐模型选择

| 任务 | 推荐模型 | 原因 |
|------|----------|------|
| **Faithfulness评估** | RAGAS + GPT-4o-mini | 开箱即用，准确率高 |
| **NLI验证** | deberta-v3-base-mnli | 平衡准确率和速度 |
| **声明分解** | GPT-4o-mini | 理解能力强 |
| **Embedding** | all-MiniLM-L6-v2 | 速度快，效果好 |

### 关键阈值设置

```python
# 生产级推荐配置
THRESHOLDS = {
    "faithfulness_min": 0.7,      # Faithfulness最低分数
    "nli_entailment_min": 0.8,    # NLI蕴含最低概率
    "similarity_min": 0.7,         # 语义相似度最低值
    "support_ratio_min": 0.8       # 声明支持率最低值
}
```

---

## 常见错误避免

### ❌ 错误1：只用单一检测方法

```python
# 不推荐：只用Faithfulness
if faithfulness_score > 0.7:
    return answer  # 可能漏检
```

**正确做法：** 组合多种方法

```python
# 推荐：多层验证
if faithfulness_score > 0.7 and support_ratio > 0.8:
    return answer
```

### ❌ 错误2：检测粒度太粗

```python
# 不推荐：整段验证
verify_claim(context, entire_answer)
```

**正确做法：** 声明级验证

```python
# 推荐：拆分后逐一验证
claims = decompose_claims(answer)
for claim in claims:
    verify_claim(context, claim)
```

### ❌ 错误3：忽略边界情况

```python
# 不推荐：硬编码阈值
if score > 0.7:
    return True
```

**正确做法：** 根据场景调整

```python
# 推荐：场景化阈值
threshold = 0.9 if is_critical_domain else 0.7
if score > threshold:
    return True
```

---

## 快速上手步骤

### 第1天：基础Faithfulness检测

```bash
# 安装依赖
pip install ragas openai

# 运行示例
python examples/basic_faithfulness.py
```

### 第2天：添加NLI验证

```bash
# 安装依赖
pip install transformers torch

# 运行示例
python examples/nli_verification.py
```

### 第3天：实现声明分解

```bash
# 使用OpenAI API
python examples/claim_decomposition.py
```

### 第4天：集成引用溯源

```bash
# 安装依赖
pip install sentence-transformers

# 运行示例
python examples/attribution.py
```

### 第5天：构建完整系统

```bash
# 运行端到端示例
python examples/complete_detection_system.py
```

---

## 性能优化技巧

### 1. 批量处理

```python
# 批量NLI验证（提速3-5倍）
results = nli_model([f"{ctx} [SEP] {claim}" for ctx, claim in pairs])
```

### 2. 缓存结果

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def verify_claim_cached(context: str, claim: str):
    return verify_claim(context, claim)
```

### 3. 异步处理

```python
import asyncio

async def verify_claims_async(claims, contexts):
    tasks = [verify_claim_async(c, contexts) for c in claims]
    return await asyncio.gather(*tasks)
```

---

## 学习检查清单

- [ ] 理解Faithfulness评估原理
- [ ] 掌握NLI三分类验证
- [ ] 实现声明分解功能
- [ ] 添加引用溯源
- [ ] 设置合理阈值
- [ ] 处理边界情况
- [ ] 优化检测性能
- [ ] 构建监控系统

---

**记住：掌握这20%的核心知识，你就能构建一个基本可用的幻觉检测系统。剩下的80%是在生产环境中逐步优化。**
