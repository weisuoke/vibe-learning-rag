# 核心概念3：加权融合

> 如何融合多个检索结果（RRF、加权平均、归一化）

---

## 什么是加权融合？

**一句话定义：** 将多个向量字段的检索结果通过算法整合成一个统一的排序列表，常用算法包括 RRF（Reciprocal Rank Fusion）和加权平均。

```python
# 场景：融合 text_vector 和 image_vector 的检索结果

# 方法1：RRF 融合（Milvus 2.4+）
from pymilvus import RRFRanker

results = collection.hybrid_search(
    reqs=[text_req, image_req],
    rerank=RRFRanker(),  # 使用 RRF 算法
    limit=5
)

# 方法2：加权平均融合（手动实现）
def weighted_fusion(results1, results2, w1=0.6, w2=0.4):
    """加权平均融合"""
    scores = {}
    for hit in results1[0]:
        scores[hit.id] = hit.distance * w1
    for hit in results2[0]:
        scores[hit.id] = scores.get(hit.id, 0) + hit.distance * w2
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

---

## 核心算法

### 算法1：RRF（Reciprocal Rank Fusion）

**原理：** 只看排名，不看分数，通过倒数排名加权融合

**公式：**
```
RRF(d) = Σ 1 / (k + rank_i(d))

其中：
- d：文档
- rank_i(d)：文档 d 在第 i 个检索结果中的排名（从0开始）
- k：平滑参数（通常为60）
- Σ：对所有检索结果求和
```

**Python 实现：**
```python
def rrf_fusion(results_list, k=60):
    """
    RRF 融合算法

    Args:
        results_list: 多个检索结果的列表
        k: 平滑参数（默认60）

    Returns:
        融合后的文档列表 [(doc_id, score), ...]
    """
    scores = {}

    # 遍历每个检索结果
    for results in results_list:
        # 遍历每个文档及其排名
        for rank, hit in enumerate(results[0]):
            doc_id = hit.id
            # RRF 公式：1 / (k + rank)
            rrf_score = 1.0 / (k + rank + 1)
            scores[doc_id] = scores.get(doc_id, 0) + rrf_score

    # 按分数降序排序
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_docs

# 使用示例
results1 = collection.search(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

results2 = collection.search(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

# 融合
final_results = rrf_fusion([results1, results2], k=60)
print("RRF 融合后的 Top 5:")
for doc_id, score in final_results[:5]:
    print(f"  Doc {doc_id}: RRF Score = {score:.4f}")
```

**示例计算：**
```python
# 假设有2个检索结果

# text_vector 检索结果（排名）：
# Doc A: rank=0
# Doc B: rank=1
# Doc C: rank=2

# image_vector 检索结果（排名）：
# Doc B: rank=0
# Doc A: rank=1
# Doc D: rank=2

# RRF 计算（k=60）：
# Doc A: 1/(60+0) + 1/(60+1) = 0.0167 + 0.0164 = 0.0331
# Doc B: 1/(60+1) + 1/(60+0) = 0.0164 + 0.0167 = 0.0331
# Doc C: 1/(60+2) + 0 = 0.0161
# Doc D: 0 + 1/(60+2) = 0.0161

# 最终排序：Doc A ≈ Doc B > Doc C ≈ Doc D
```

**优点：**
- ✅ 不依赖原始相似度分数（适合不同度量方式）
- ✅ 简单鲁棒，无需调参
- ✅ 有理论保证

**缺点：**
- ❌ 无法精确控制权重比例
- ❌ 忽略了原始分数的信息

---

### 算法2：加权平均（Weighted Average）

**原理：** 对原始相似度分数进行加权平均

**公式：**
```
Score(d) = Σ w_i * score_i(d)

其中：
- d：文档
- w_i：第 i 个检索结果的权重
- score_i(d)：文档 d 在第 i 个检索结果中的相似度分数
- Σ w_i = 1（权重和为1）
```

**Python 实现：**
```python
def weighted_average_fusion(results_list, weights):
    """
    加权平均融合算法

    Args:
        results_list: 多个检索结果的列表
        weights: 权重列表（和为1）

    Returns:
        融合后的文档列表 [(doc_id, score), ...]
    """
    assert len(results_list) == len(weights), "结果数量和权重数量必须一致"
    assert abs(sum(weights) - 1.0) < 1e-6, "权重和必须为1"

    scores = {}

    # 遍历每个检索结果及其权重
    for results, weight in zip(results_list, weights):
        for hit in results[0]:
            doc_id = hit.id
            similarity = hit.distance  # 相似度分数
            scores[doc_id] = scores.get(doc_id, 0) + similarity * weight

    # 按分数降序排序
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_docs

# 使用示例
results1 = collection.search(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

results2 = collection.search(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

# 融合（text权重60%，image权重40%）
weights = [0.6, 0.4]
final_results = weighted_average_fusion([results1, results2], weights)
print("加权平均融合后的 Top 5:")
for doc_id, score in final_results[:5]:
    print(f"  Doc {doc_id}: Weighted Score = {score:.4f}")
```

**示例计算：**
```python
# 假设有2个检索结果（COSINE度量，分数范围0-1）

# text_vector 检索结果（分数）：
# Doc A: score=0.95
# Doc B: score=0.90
# Doc C: score=0.85

# image_vector 检索结果（分数）：
# Doc B: score=0.92
# Doc A: score=0.88
# Doc D: score=0.80

# 加权平均计算（w1=0.6, w2=0.4）：
# Doc A: 0.95*0.6 + 0.88*0.4 = 0.57 + 0.352 = 0.922
# Doc B: 0.90*0.6 + 0.92*0.4 = 0.54 + 0.368 = 0.908
# Doc C: 0.85*0.6 + 0*0.4 = 0.51
# Doc D: 0*0.6 + 0.80*0.4 = 0.32

# 最终排序：Doc A > Doc B > Doc C > Doc D
```

**优点：**
- ✅ 可以精确控制权重比例
- ✅ 利用了原始分数的信息
- ✅ 直观易理解

**缺点：**
- ❌ 要求相同的度量方式（或归一化）
- ❌ 需要调参（权重）

---

### 算法3：归一化加权平均

**原理：** 先归一化分数到[0,1]，再加权平均

**为什么需要归一化？**
```python
# 问题：不同度量方式的分数范围不同

# text_vector（COSINE）：分数范围 0-1
# Doc A: 0.95
# Doc B: 0.90

# image_vector（L2）：分数范围 0-∞（越小越相似）
# Doc A: 2.5
# Doc B: 3.0

# 直接加权平均会失真：
# Doc A: 0.95*0.6 + 2.5*0.4 = 1.57  # L2分数主导
# Doc B: 0.90*0.6 + 3.0*0.4 = 1.74

# 解决方案：先归一化
```

**Python 实现：**
```python
def normalize_scores(results, metric_type):
    """
    归一化分数到 [0, 1]

    Args:
        results: 检索结果
        metric_type: 度量方式（COSINE, L2, IP）

    Returns:
        归一化后的分数字典 {doc_id: normalized_score}
    """
    scores = {}

    if metric_type == "COSINE" or metric_type == "IP":
        # COSINE 和 IP：分数越大越相似，已经在 [0, 1] 或 [-1, 1]
        for hit in results[0]:
            scores[hit.id] = hit.distance

    elif metric_type == "L2":
        # L2：距离越小越相似，需要转换
        distances = [hit.distance for hit in results[0]]
        max_dist = max(distances) if distances else 1.0
        min_dist = min(distances) if distances else 0.0

        for hit in results[0]:
            # 归一化：1 - (dist - min) / (max - min)
            if max_dist > min_dist:
                normalized = 1.0 - (hit.distance - min_dist) / (max_dist - min_dist)
            else:
                normalized = 1.0
            scores[hit.id] = normalized

    return scores

def normalized_weighted_fusion(results_list, metric_types, weights):
    """
    归一化加权平均融合

    Args:
        results_list: 多个检索结果的列表
        metric_types: 度量方式列表
        weights: 权重列表

    Returns:
        融合后的文档列表
    """
    assert len(results_list) == len(metric_types) == len(weights)
    assert abs(sum(weights) - 1.0) < 1e-6

    scores = {}

    # 归一化并加权
    for results, metric_type, weight in zip(results_list, metric_types, weights):
        normalized = normalize_scores(results, metric_type)
        for doc_id, score in normalized.items():
            scores[doc_id] = scores.get(doc_id, 0) + score * weight

    # 排序
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_docs

# 使用示例
results1 = collection.search(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

results2 = collection.search(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "L2"},  # 不同度量方式
    limit=10
)

# 融合
metric_types = ["COSINE", "L2"]
weights = [0.6, 0.4]
final_results = normalized_weighted_fusion(
    [results1, results2],
    metric_types,
    weights
)
```

---

## 在实际应用中的使用

### 场景1：RAG 文档检索（RRF 融合）

```python
from pymilvus import Collection, AnnSearchRequest, RRFRanker
from openai import OpenAI

client = OpenAI()
collection = Collection("doc_qa")
collection.load()

def rag_search_with_rrf(user_query):
    """使用 RRF 融合的 RAG 检索"""

    # 1. 生成查询向量
    text_embedding = client.embeddings.create(
        model="text-embedding-3-small",
        input=user_query
    ).data[0].embedding

    # 2. 定义检索请求
    text_req = AnnSearchRequest(
        data=[text_embedding],
        anns_field="text_vector",
        param={"metric_type": "COSINE"},
        limit=20
    )

    image_req = AnnSearchRequest(
        data=[text_embedding],  # 复用文本向量
        anns_field="image_vector",
        param={"metric_type": "COSINE"},
        limit=10
    )

    # 3. RRF 融合检索
    results = collection.hybrid_search(
        reqs=[text_req, image_req],
        rerank=RRFRanker(),  # 使用 RRF
        limit=3,
        output_fields=["content", "image_url"]
    )

    # 4. 构建上下文
    context_parts = []
    for hit in results[0]:
        content = hit.entity.get("content")
        image_url = hit.entity.get("image_url")
        context_parts.append(f"文本：{content}")
        if image_url:
            context_parts.append(f"图表：{image_url}")

    context = "\n\n".join(context_parts)

    # 5. 调用 LLM
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是一个技术文档助手"},
            {"role": "user", "content": f"根据以下内容回答：{user_query}\n\n{context}"}
        ]
    )

    return response.choices[0].message.content

# 使用
answer = rag_search_with_rrf("如何安装 Python？")
print(answer)
```

---

### 场景2：电商搜索（动态权重）

```python
from pymilvus import Collection

collection = Collection("products")
collection.load()

def ecommerce_search_with_dynamic_weights(user_text, user_image=None):
    """根据用户输入动态调整权重"""

    # 1. 生成查询向量
    text_embedding = get_text_embedding(user_text)

    # 2. 检索
    text_results = collection.search(
        data=[text_embedding],
        anns_field="desc_vector",
        param={"metric_type": "COSINE"},
        limit=50
    )

    # 3. 动态权重
    if user_image is None:
        # 只有文字 → 文本权重100%
        final_results = text_results
    else:
        # 有文字和图片 → 动态权重
        image_embedding = get_image_embedding(user_image)
        image_results = collection.search(
            data=[image_embedding],
            anns_field="image_vector",
            param={"metric_type": "COSINE"},
            limit=50
        )

        # 根据文字长度调整权重
        text_length = len(user_text)
        if text_length < 10:
            # 文字很短 → 图片权重更高
            weights = [0.3, 0.7]
        elif text_length < 50:
            # 文字中等 → 均衡
            weights = [0.5, 0.5]
        else:
            # 文字很长 → 文字权重更高
            weights = [0.7, 0.3]

        # 加权融合
        final_results = weighted_average_fusion(
            [text_results, image_results],
            weights
        )

    return final_results[:10]

# 使用
# 场景1：只有文字
results1 = ecommerce_search_with_dynamic_weights("红色连衣裙")

# 场景2：文字 + 图片
results2 = ecommerce_search_with_dynamic_weights("红色", user_image="sketch.jpg")
```

---

### 场景3：A/B 测试优化权重

```python
import random

def ab_test_fusion_weights(user_query, variant="A"):
    """A/B 测试不同的融合权重"""

    # 生成查询向量
    text_embedding = get_text_embedding(user_query)
    image_embedding = get_image_embedding(user_query)

    # 检索
    text_results = collection.search(
        data=[text_embedding],
        anns_field="text_vector",
        param={"metric_type": "COSINE"},
        limit=50
    )

    image_results = collection.search(
        data=[image_embedding],
        anns_field="image_vector",
        param={"metric_type": "COSINE"},
        limit=50
    )

    # A/B 测试不同权重
    if variant == "A":
        # 变体A：文本权重70%
        weights = [0.7, 0.3]
    elif variant == "B":
        # 变体B：文本权重60%
        weights = [0.6, 0.4]
    elif variant == "C":
        # 变体C：均衡
        weights = [0.5, 0.5]
    else:
        # 默认：RRF
        return rrf_fusion([text_results, image_results])

    # 加权融合
    return weighted_average_fusion([text_results, image_results], weights)

# 随机分配用户到不同变体
def search_with_ab_test(user_query):
    variant = random.choice(["A", "B", "C", "RRF"])
    results = ab_test_fusion_weights(user_query, variant)

    # 记录日志用于分析
    log_ab_test(user_query, variant, results)

    return results
```

---

## 算法选择指南

### 决策树

```
是否需要精确控制权重比例？
├─ 是 → 使用加权平均
│      ├─ 度量方式相同？
│      │  ├─ 是 → 直接加权平均
│      │  └─ 否 → 归一化加权平均
│      └─ 需要 A/B 测试优化权重
│
└─ 否 → 使用 RRF
       ├─ 快速原型
       ├─ 不同度量方式
       └─ 不想调参
```

### 对比表

| 算法 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **RRF** | 简单鲁棒、无需调参、适合不同度量方式 | 无法精确控制权重 | 快速原型、不同度量方式 |
| **加权平均** | 精确控制权重、利用原始分数 | 需要调参、要求相同度量方式 | 生产优化、相同度量方式 |
| **归一化加权平均** | 支持不同度量方式、精确控制权重 | 实现复杂、需要调参 | 混合度量方式 + 精确权重 |

---

## 性能优化

### 优化1：缓存融合结果

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_rrf_fusion(results_tuple, k=60):
    """缓存 RRF 融合结果"""
    # 将 results 转换为可哈希的 tuple
    return rrf_fusion(list(results_tuple), k)

# 使用
results_tuple = (tuple(results1[0]), tuple(results2[0]))
final_results = cached_rrf_fusion(results_tuple)
```

---

### 优化2：并行计算归一化

```python
from concurrent.futures import ThreadPoolExecutor

def parallel_normalize(results_list, metric_types):
    """并行归一化多个检索结果"""
    with ThreadPoolExecutor(max_workers=len(results_list)) as executor:
        futures = [
            executor.submit(normalize_scores, results, metric_type)
            for results, metric_type in zip(results_list, metric_types)
        ]
        normalized_list = [future.result() for future in futures]
    return normalized_list
```

---

### 优化3：Top-K 剪枝

```python
def efficient_weighted_fusion(results_list, weights, top_k=10):
    """只计算 Top-K，不计算所有文档"""
    # 1. 收集所有候选文档
    all_doc_ids = set()
    for results in results_list:
        for hit in results[0][:top_k * 2]:  # 只看前 2*K 个
            all_doc_ids.add(hit.id)

    # 2. 只计算候选文档的分数
    scores = {}
    for results, weight in zip(results_list, weights):
        for hit in results[0]:
            if hit.id in all_doc_ids:
                scores[hit.id] = scores.get(hit.id, 0) + hit.distance * weight

    # 3. 返回 Top-K
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_docs[:top_k]
```

---

## 常见问题

### Q1：RRF 的 k 参数如何选择？

**答：** 通常使用默认值 60，无需调整

```python
# k 的影响：
# - k 越大：排名靠后的文档权重越小（差异更明显）
# - k 越小：排名靠后的文档权重越大（差异更平滑）

# 推荐值：
# - 默认：k=60（经验值，适合大多数场景）
# - 激进：k=30（强调排名靠前的文档）
# - 保守：k=100（更平滑的权重分布）
```

---

### Q2：加权平均的权重如何确定？

**答：** 通过 A/B 测试或领域知识

```python
# 方法1：A/B 测试
# 测试多组权重，选择效果最好的
weights_variants = [
    [0.7, 0.3],
    [0.6, 0.4],
    [0.5, 0.5],
]

# 方法2：领域知识
# 根据业务场景确定
# 例如：文本搜索为主 → [0.7, 0.3]
#      图片搜索为主 → [0.3, 0.7]
#      均衡 → [0.5, 0.5]
```

---

### Q3：如何评估融合效果？

**答：** 使用 NDCG、MRR 等指标

```python
def evaluate_fusion(fusion_results, ground_truth):
    """评估融合效果"""
    # NDCG@K
    ndcg = calculate_ndcg(fusion_results, ground_truth, k=10)

    # MRR（Mean Reciprocal Rank）
    mrr = calculate_mrr(fusion_results, ground_truth)

    # Precision@K
    precision = calculate_precision(fusion_results, ground_truth, k=10)

    return {
        "ndcg@10": ndcg,
        "mrr": mrr,
        "precision@10": precision
    }
```

---

## 总结

**加权融合的核心要点：**

1. **RRF**：只看排名，适合不同度量方式，无需调参
2. **加权平均**：精确控制权重，适合相同度量方式，需要调参
3. **归一化**：支持不同度量方式，但实现复杂
4. **选择指南**：根据场景选择合适的算法
5. **性能优化**：缓存、并行、剪枝
6. **评估**：使用 NDCG、MRR 等指标

---

**继续学习：** [09_实战代码_场景1_多字段向量定义.md](./09_实战代码_场景1_多字段向量定义.md)
