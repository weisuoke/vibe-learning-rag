# 大模型API调用 - 一句话总结

**大模型 API 是通过 HTTP 请求调用云端 LLM 的标准接口，核心是 Chat Completions 模式（messages + 参数控制），在 RAG 系统中作为生成模块，将检索结果转化为最终答案。**

---

## 核心要点回顾

| 维度 | 核心内容 |
|------|----------|
| 本质 | 远程函数调用：输入文本 → 输出文本 |
| 核心 API | Chat Completions（messages 数组） |
| 关键参数 | temperature（随机性）、max_tokens（长度） |
| 流式输出 | stream=True，提升用户体验 |
| 错误处理 | 重试 + 超时 + 熔断 |
| RAG 应用 | 生成模块：检索结果 + 问题 → 答案 |

---

## 速查代码

```python
# 最小可用
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "基于上下文回答"},
        {"role": "user", "content": f"上下文：{context}\n问题：{question}"}
    ],
    temperature=0.1,
    max_tokens=500
)

answer = response.choices[0].message.content
```

---

## 学习路径

```
✅ 大模型API调用（当前）
   ↓
→ Token与Context Window（理解限制）
   ↓
→ Prompt Engineering（优化输出）
   ↓
→ RAG核心流程（完整系统）
```

---

## 文件索引

| 文件 | 内容 |
|------|------|
| [01_30字核心.md](./01_30字核心.md) | 一句话定义 |
| [02_第一性原理.md](./02_第一性原理.md) | 为什么需要 API |
| [03_核心概念.md](./03_核心概念.md) | 3 个核心概念 |
| [04_最小可用.md](./04_最小可用.md) | 20% 知识解决 80% 问题 |
| [05_双重类比.md](./05_双重类比.md) | 前端 + 日常类比 |
| [06_反直觉点.md](./06_反直觉点.md) | 3 个常见误区 |
| [07_实战代码.md](./07_实战代码.md) | 完整可运行示例 |
| [08_面试必问.md](./08_面试必问.md) | 高频面试问题 |
| [09_化骨绵掌.md](./09_化骨绵掌.md) | 10 个知识卡片 |
| [10_一句话总结.md](./10_一句话总结.md) | 最终总结（本文） |

---

**版本：** v1.0
**最后更新：** 2025-02-05
**知识点：** L2_LLM核心 / 大模型API调用
