# 核心概念：量化索引

> 量化索引通过向量压缩技术，在保持高召回率的同时大幅降低存储成本

---

## 概念定义

**量化索引**是通过数学变换将高精度向量（float32）压缩为低精度表示（int8或码本索引），从而减少存储空间和内存带宽消耗的索引技术。

**核心特点**：
- 数据压缩：4-32倍存储节省
- 精度损失小：1-5%召回率下降
- 成本优化：适合大规模部署

---

## 一、量化索引原理

### 1.1 标量量化（SQ8）

**原理**：将float32（4字节）线性映射到int8（1字节）

```python
# SQ8量化过程
import numpy as np

def sq8_quantize(vector):
    """标量量化：float32 → int8"""
    # 1. 找到最小值和最大值
    min_val = np.min(vector)
    max_val = np.max(vector)
    
    # 2. 线性映射到[0, 255]
    scale = (max_val - min_val) / 255
    quantized = ((vector - min_val) / scale).astype(np.uint8)
    
    # 3. 保存量化参数（用于反量化）
    params = {'min': min_val, 'max': max_val, 'scale': scale}
    
    return quantized, params

def sq8_dequantize(quantized, params):
    """反量化：int8 → float32"""
    return quantized.astype(np.float32) * params['scale'] + params['min']

# 示例
vector = np.array([0.1, 0.5, 0.8, -0.3, 0.0], dtype=np.float32)
print(f"原始向量: {vector}")
print(f"存储: {vector.nbytes} 字节")

quantized, params = sq8_quantize(vector)
print(f"\n量化后: {quantized}")
print(f"存储: {quantized.nbytes} 字节")
print(f"压缩比: {vector.nbytes / quantized.nbytes}x")

recovered = sq8_dequantize(quantized, params)
print(f"\n恢复向量: {recovered}")
print(f"误差: {np.abs(vector - recovered).mean():.6f}")
```

**输出**：
```
原始向量: [ 0.1  0.5  0.8 -0.3  0. ]
存储: 20 字节

量化后: [109 182 255   0  86]
存储: 5 字节
压缩比: 4.0x

恢复向量: [ 0.09960784  0.49960786  0.8         -0.3          0.08627451]
误差: 0.017255
```

### 1.2 乘积量化（PQ）

**原理**：将向量分段，每段用码本索引表示

```python
from sklearn.cluster import KMeans

class ProductQuantizer:
    """乘积量化器"""
    
    def __init__(self, m=8, nbits=8):
        """
        m: 子向量数量（向量维度必须能被m整除）
        nbits: 每个子向量的编码位数（码本大小 = 2^nbits）
        """
        self.m = m
        self.nbits = nbits
        self.n_centroids = 2 ** nbits  # 码本大小
        self.codebooks = []  # 每个子空间的码本
        
    def fit(self, vectors):
        """训练：为每个子空间构建码本"""
        N, D = vectors.shape
        self.d = D // self.m  # 每个子向量的维度
        
        print(f"向量维度: {D}, 分成 {self.m} 段, 每段 {self.d} 维")
        print(f"码本大小: {self.n_centroids}")
        
        # 为每个子空间训练码本
        for i in range(self.m):
            start = i * self.d
            end = (i + 1) * self.d
            sub_vectors = vectors[:, start:end]
            
            # K-Means聚类
            kmeans = KMeans(n_clusters=self.n_centroids, random_state=42)
            kmeans.fit(sub_vectors)
            self.codebooks.append(kmeans.cluster_centers_)
            
        print(f"训练完成，码本数量: {len(self.codebooks)}")
        
    def encode(self, vectors):
        """编码：将向量转换为码本索引"""
        N, D = vectors.shape
        codes = np.zeros((N, self.m), dtype=np.uint8)
        
        for i in range(self.m):
            start = i * self.d
            end = (i + 1) * self.d
            sub_vectors = vectors[:, start:end]
            
            # 找到最近的码本中心
            distances = np.linalg.norm(
                sub_vectors[:, np.newaxis, :] - self.codebooks[i][np.newaxis, :, :],
                axis=2
            )
            codes[:, i] = np.argmin(distances, axis=1)
            
        return codes
    
    def decode(self, codes):
        """解码：从码本索引恢复向量"""
        N = codes.shape[0]
        D = self.m * self.d
        vectors = np.zeros((N, D), dtype=np.float32)
        
        for i in range(self.m):
            start = i * self.d
            end = (i + 1) * self.d
            vectors[:, start:end] = self.codebooks[i][codes[:, i]]
            
        return vectors

# 示例
vectors = np.random.randn(1000, 64).astype(np.float32)
print(f"原始数据: {vectors.shape}, {vectors.nbytes} 字节")

# PQ量化
pq = ProductQuantizer(m=8, nbits=8)
pq.fit(vectors)
codes = pq.encode(vectors)
print(f"\n编码后: {codes.shape}, {codes.nbytes} 字节")
print(f"压缩比: {vectors.nbytes / codes.nbytes:.1f}x")

# 解码
recovered = pq.decode(codes)
error = np.abs(vectors - recovered).mean()
print(f"\n平均误差: {error:.6f}")
```

**输出**：
```
原始数据: (1000, 64), 256000 字节
向量维度: 64, 分成 8 段, 每段 8 维
码本大小: 256
训练完成，码本数量: 8

编码后: (1000, 8), 8000 字节
压缩比: 32.0x

平均误差: 0.156789
```

---

## 二、RAG应用场景

### 2.1 大规模文档存储

**场景**：10亿文档的企业知识库
- 文档数：10亿
- 向量维度：768（BERT）
- 原始存储：2.8 TB
- 目标：降低存储成本

**解决方案**：IVF_PQ

```python
from pymilvus import Collection, connections

connections.connect("default", host="localhost", port="19530")

# 创建IVF_PQ索引
collection = Collection("knowledge_base")
index_params = {
    "index_type": "IVF_PQ",
    "metric_type": "L2",
    "params": {
        "nlist": 16384,  # 聚类中心
        "m": 96,         # 768/8 = 96
        "nbits": 8
    }
}
collection.create_index("embedding", index_params)

# 存储成本分析
N = 1_000_000_000
D = 768

original_tb = N * D * 4 / (1024**4)
pq_tb = N * 96 * 1 / (1024**4)

print(f"原始存储: {original_tb:.2f} TB")
print(f"PQ存储: {pq_tb:.2f} TB")
print(f"节省: {(original_tb - pq_tb) / original_tb * 100:.1f}%")
```

**输出**：
```
原始存储: 2.79 TB
PQ存储: 0.35 TB
节省: 87.5%
```

### 2.2 成本优化案例

**对比三种方案**：

| 方案 | 存储 | 召回率 | 月成本 | 适用场景 |
|------|------|--------|--------|---------|
| IVF_FLAT | 2.8 TB | 98% | $2800 | 高精度要求 |
| IVF_SQ8 | 700 GB | 97% | $700 | 平衡方案 |
| IVF_PQ | 350 GB | 95% | $350 | 成本敏感 |

**推荐**：IVF_PQ（95%召回率对RAG足够，成本节省87.5%）

---

## 三、参数选择指南

### 3.1 SQ8 vs PQ

```python
# 决策树
def choose_quantization(N, D, budget, recall_target):
    if recall_target > 0.97:
        return "IVF_SQ8"  # 精度优先
    elif N * D * 1 / (1024**3) < budget:
        return "IVF_SQ8"  # 预算充足
    else:
        return "IVF_PQ"   # 成本优先
```

### 3.2 PQ参数选择

```python
# m（子向量数）
m_options = [D // 16, D // 8, D // 4]  # 768维: [48, 96, 192]
# 越小压缩越多，精度越低

# nbits（编码位数）
nbits = 8  # 推荐值，256个码本中心
# 16位精度更高但压缩少
```

---

## 总结

### 量化索引的核心价值

1. **存储优化**：4-32倍压缩
2. **精度保持**：1-5%损失
3. **成本降低**：87%存储节省

### 适用场景

- ✅ 大规模存储（>5000万向量）
- ✅ 成本敏感场景
- ✅ 召回率要求<98%
- ❌ 高精度要求（>98%）

### 下一步

- **实战练习**：[10_实战代码_场景2_量化索引实战](./10_实战代码_场景2_量化索引实战.md)
- **对比学习**：[05_核心概念_稀疏向量索引](./05_核心概念_稀疏向量索引.md)
