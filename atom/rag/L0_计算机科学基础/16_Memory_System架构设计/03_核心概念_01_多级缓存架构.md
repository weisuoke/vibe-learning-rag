# 核心概念：多级缓存架构

> **理解计算机和 AI Agent 中的分层存储设计**

---

## 概念定义

**多级缓存架构（Multi-Level Cache Architecture）= 将数据按访问频率和速度需求分层存储，形成从快到慢、从小到大的存储层级**

### 核心特征

1. **速度递减**：L1 > L2 > L3 > L4
2. **容量递增**：L1 < L2 < L3 < L4
3. **成本递减**：L1 最贵，L4 最便宜
4. **数据流动**：热数据向上提升，冷数据向下降级

---

## 4层架构详解

### L1: Working Memory（工作内存）

**定义**：进程内存中的临时变量和数据结构

**特点**：
- **速度**：< 1ms（纳秒级）
- **容量**：KB-MB 级
- **生命周期**：单次函数调用
- **实现**：Python 变量、字典、列表

**代码示例**：
```python
class WorkingMemory:
    """L1: 工作内存（最快，最小）"""
    def __init__(self):
        self.current_context = {}  # 当前对话上下文
        self.temp_variables = {}   # 临时变量

    def set_context(self, key: str, value: any):
        """设置当前上下文"""
        self.current_context[key] = value

    def get_context(self, key: str) -> any:
        """获取当前上下文（< 1ms）"""
        return self.current_context.get(key)
```

**AI Agent 应用**：
- 当前对话的临时变量
- 函数调用的中间结果
- 正在处理的用户输入

---

### L2: Session Cache（会话缓存）

**定义**：单次会话期间的数据缓存

**特点**：
- **速度**：1-10ms
- **容量**：MB-GB 级
- **生命周期**：单次会话（关闭浏览器/断开连接后清空）
- **实现**：Redis、内存 LRU 缓存

**代码示例**：
```python
from collections import OrderedDict
import redis

class SessionCache:
    """L2: 会话缓存（快，中等容量）"""
    def __init__(self, capacity: int = 1000):
        # 方案1：内存 LRU 缓存
        self.memory_cache = OrderedDict()
        self.capacity = capacity

        # 方案2：Redis 缓存
        self.redis = redis.Redis(host='localhost', port=6379)

    def put_memory(self, key: str, value: any):
        """写入内存缓存"""
        if key in self.memory_cache:
            self.memory_cache.move_to_end(key)
        else:
            if len(self.memory_cache) >= self.capacity:
                self.memory_cache.popitem(last=False)
        self.memory_cache[key] = value

    def get_memory(self, key: str) -> any:
        """从内存缓存读取（1-10ms）"""
        if key in self.memory_cache:
            self.memory_cache.move_to_end(key)
            return self.memory_cache[key]
        return None

    def put_redis(self, session_id: str, key: str, value: str, ttl: int = 3600):
        """写入 Redis（带过期时间）"""
        redis_key = f"session:{session_id}:{key}"
        self.redis.setex(redis_key, ttl, value)

    def get_redis(self, session_id: str, key: str) -> str:
        """从 Redis 读取（1-10ms）"""
        redis_key = f"session:{session_id}:{key}"
        return self.redis.get(redis_key)
```

**AI Agent 应用**：
- 对话历史（最近 N 轮）
- 用户当前会话的偏好
- 临时计算结果

---

### L3: Semantic Cache（语义缓存）

**定义**：基于向量相似度的智能缓存

**特点**：
- **速度**：10-100ms
- **容量**：GB-TB 级
- **生命周期**：跨会话（但可能被淘汰）
- **实现**：ChromaDB、Milvus、Redis + Embedding

**代码示例**：
```python
from openai import OpenAI
import numpy as np
import chromadb

client = OpenAI()

class SemanticCache:
    """L3: 语义缓存（智能匹配）"""
    def __init__(self, threshold: float = 0.95):
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.create_collection("semantic_cache")
        self.threshold = threshold

    def _get_embedding(self, text: str) -> list:
        """获取文本向量"""
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding

    def put(self, question: str, answer: str):
        """缓存问答对"""
        embedding = self._get_embedding(question)
        self.collection.add(
            embeddings=[embedding],
            documents=[answer],
            metadatas=[{"question": question}],
            ids=[str(hash(question))]
        )

    def get(self, question: str) -> str | None:
        """语义检索（10-100ms）"""
        query_embedding = self._get_embedding(question)

        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=1
        )

        if results['distances'][0][0] < (1 - self.threshold):
            return results['documents'][0][0]

        return None
```

**AI Agent 应用**：
- 相似问题的答案缓存
- 避免重复 LLM 调用（节省成本）
- 知识库检索结果缓存

---

### L4: Persistent Storage（持久化存储）

**定义**：永久保存的数据

**特点**：
- **速度**：100ms+
- **容量**：TB+ 级
- **生命周期**：永久（除非用户删除）
- **实现**：PostgreSQL、MongoDB、文件系统

**代码示例**：
```python
import psycopg2
from psycopg2.extras import Json

class PersistentStorage:
    """L4: 持久化存储（永久保存）"""
    def __init__(self, db_config: dict):
        self.conn = psycopg2.connect(**db_config)

    def save_user_preference(self, user_id: str, key: str, value: any):
        """保存用户偏好"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO user_preferences (user_id, key, value)
            VALUES (%s, %s, %s)
            ON CONFLICT (user_id, key)
            DO UPDATE SET value = EXCLUDED.value
        """, (user_id, key, Json(value)))
        self.conn.commit()

    def load_user_preference(self, user_id: str, key: str) -> any:
        """加载用户偏好（100ms+）"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT value FROM user_preferences
            WHERE user_id = %s AND key = %s
        """, (user_id, key))
        result = cursor.fetchone()
        return result[0] if result else None

    def save_conversation(self, user_id: str, messages: list):
        """保存对话历史"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO conversations (user_id, messages, created_at)
            VALUES (%s, %s, NOW())
        """, (user_id, Json(messages)))
        self.conn.commit()
```

**AI Agent 应用**：
- 用户长期偏好
- 完整对话历史
- 知识库文档

---

## 完整的多级缓存系统

### 集成实现

```python
class MultiLevelCacheSystem:
    """完整的4层缓存系统"""
    def __init__(self, db_config: dict):
        self.l1_working = WorkingMemory()
        self.l2_session = SessionCache(capacity=1000)
        self.l3_semantic = SemanticCache(threshold=0.95)
        self.l4_persistent = PersistentStorage(db_config)

    def get(self, user_id: str, key: str) -> any:
        """从缓存获取数据（L1 → L2 → L3 → L4）"""
        # L1: 工作内存
        value = self.l1_working.get_context(key)
        if value is not None:
            print(f"✅ L1 命中: {key}")
            return value

        # L2: 会话缓存
        value = self.l2_session.get_memory(key)
        if value is not None:
            print(f"✅ L2 命中: {key}")
            # 提升到 L1
            self.l1_working.set_context(key, value)
            return value

        # L3: 语义缓存（如果是问题）
        if key.startswith("question:"):
            question = key.replace("question:", "")
            value = self.l3_semantic.get(question)
            if value is not None:
                print(f"✅ L3 命中: {key}")
                # 提升到 L2 和 L1
                self.l2_session.put_memory(key, value)
                self.l1_working.set_context(key, value)
                return value

        # L4: 持久化存储
        value = self.l4_persistent.load_user_preference(user_id, key)
        if value is not None:
            print(f"✅ L4 命中: {key}")
            # 提升到 L3, L2, L1
            self.l2_session.put_memory(key, value)
            self.l1_working.set_context(key, value)
            return value

        print(f"❌ 缓存未命中: {key}")
        return None

    def put(self, user_id: str, key: str, value: any, critical: bool = False):
        """写入数据"""
        # L1: 总是写入工作内存
        self.l1_working.set_context(key, value)

        # L2: 写入会话缓存
        self.l2_session.put_memory(key, value)

        # L4: 关键数据立即持久化
        if critical:
            self.l4_persistent.save_user_preference(user_id, key, value)
```

---

## 性能对比

### 延迟对比

| 层级 | 延迟 | 相对速度 | 适用场景 |
|------|------|----------|----------|
| L1 | < 1ms | 1x | 当前对话上下文 |
| L2 | 1-10ms | 10x | 会话历史 |
| L3 | 10-100ms | 100x | 语义缓存 |
| L4 | 100ms+ | 1000x+ | 长期记忆 |

### 容量对比

| 层级 | 容量 | 成本（每 GB） | 适用数据 |
|------|------|---------------|----------|
| L1 | KB-MB | 无法单独购买 | 临时变量 |
| L2 | MB-GB | $5-10 | 会话数据 |
| L3 | GB-TB | $0.1-0.3 | 缓存结果 |
| L4 | TB+ | $0.02-0.05 | 全部数据 |

---

## 2025-2026 最新架构

### AI Agent 4层记忆架构

```
┌─────────────────────────────────────────────────────────┐
│ L1: Working Memory（工作内存）                           │
│ - 当前对话的临时变量                                     │
│ - 实现：Python 变量                                      │
│ - 案例：LangChain 的 ConversationBufferMemory           │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│ L2: Conversation Memory（对话记忆）                      │
│ - 当前会话的对话历史                                     │
│ - 实现：Redis + LRU                                      │
│ - 案例：LangGraph 的 MemorySaver                         │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│ L3: Artifacts（知识制品）                                │
│ - 语义缓存、检索结果                                     │
│ - 实现：ChromaDB + Embedding                             │
│ - 案例：Redis Semantic Cache                             │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│ L4: Long-term Preferences（长期偏好）                    │
│ - 用户偏好、知识库                                       │
│ - 实现：PostgreSQL + pgvector                            │
│ - 案例：LangGraph PostgresStore                          │
└─────────────────────────────────────────────────────────┘
```

---

## 最佳实践

### 1. 数据分层策略

```python
def classify_data(data_type: str) -> str:
    """根据数据类型选择存储层级"""
    if data_type == "temp_variable":
        return "L1"  # 临时变量 → 工作内存
    elif data_type == "conversation":
        return "L2"  # 对话历史 → 会话缓存
    elif data_type == "llm_response":
        return "L3"  # LLM 响应 → 语义缓存
    elif data_type == "user_preference":
        return "L4"  # 用户偏好 → 持久化存储
```

### 2. 缓存提升策略

```python
def promote_to_upper_level(key: str, value: any, current_level: str):
    """将热数据提升到更快的层级"""
    if current_level == "L4":
        # L4 → L3 → L2 → L1
        l3_semantic.put(key, value)
        l2_session.put_memory(key, value)
        l1_working.set_context(key, value)
    elif current_level == "L3":
        # L3 → L2 → L1
        l2_session.put_memory(key, value)
        l1_working.set_context(key, value)
    elif current_level == "L2":
        # L2 → L1
        l1_working.set_context(key, value)
```

### 3. 缓存降级策略

```python
def demote_to_lower_level(key: str, value: any, current_level: str):
    """将冷数据降级到更慢的层级"""
    if current_level == "L1":
        # L1 → L2
        l2_session.put_memory(key, value)
        del l1_working.current_context[key]
    elif current_level == "L2":
        # L2 → L4（持久化）
        l4_persistent.save_user_preference(user_id, key, value)
        del l2_session.memory_cache[key]
```

---

## 参考资源

### 2025-2026 最新研究
- [AI Agents 2026 Architecture](https://andriifurmanets.com/blogs/ai-agents-2026-practical-architecture-tools-memory-evals-guardrails) - 4层记忆架构设计
- [SIGARCH Multi-Agent Memory](https://www.sigarch.org/multi-agent-memory-from-a-computer-architecture-perspective-visions-and-challenges-ahead) - 计算机架构视角
- [2026 Memory Stack for Enterprise Agents](https://alok-mishra.com/2026/01/07/a-2026-memory-stack-for-enterprise-agents) - 企业级记忆栈

### 实现参考
- [LangGraph Memory Documentation](https://docs.langchain.com/oss/python/langgraph/add-memory) - PostgreSQL + pgvector
- [Redis AI Agent Memory](https://redis.io/blog/build-smarter-ai-agents-manage-short-term-and-long-term-memory-with-redis) - Redis 记忆系统
- [ChromaDB Documentation](https://docs.trychroma.com/) - 向量数据库
