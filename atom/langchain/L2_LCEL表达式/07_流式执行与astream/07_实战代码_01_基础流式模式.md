# 实战代码 01：基础流式模式

完整的基础流式模式代码示例，涵盖三种流式模式的实际应用。

---

## 示例 1：ChatGPT 式对话（messages 模式）

```python
"""
ChatGPT 式流式对话应用
展示 messages 模式的基本用法
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 创建模型和链
model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个友好的助手"),
    ("user", "{input}")
])
output_parser = StrOutputParser()

chain = prompt | model | output_parser

async def chat_stream(user_input: str):
    """流式对话"""
    print(f"用户: {user_input}")
    print("助手: ", end="", flush=True)

    async for chunk in chain.astream({"input": user_input}):
        print(chunk, end="", flush=True)

    print("\n")

# 使用示例
async def main():
    await chat_stream("介绍一下 Python")
    await chat_stream("它有什么优点？")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 2：Agent 进度追踪（updates 模式）

```python
"""
Agent 执行进度追踪
展示 updates 模式的基本用法
"""

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

def get_weather(city: str) -> str:
    """获取城市天气"""
    return f"{city}的天气是晴天"

def get_time(timezone: str) -> str:
    """获取时区时间"""
    return f"{timezone}的时间是 14:30"

# 创建 Agent
model = ChatOpenAI(model="gpt-4o-mini")
agent = create_agent(
    model=model,
    tools=[get_weather, get_time]
)

def track_agent_progress(user_input: str):
    """追踪 Agent 执行进度"""
    print(f"用户输入: {user_input}\n")

    step_count = 0
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": user_input}]},
        stream_mode="updates"
    ):
        step_count += 1
        for node_name, data in chunk.items():
            print(f"步骤 {step_count}: [{node_name}] 执行完成")

            # 显示消息详情
            if "messages" in data and data["messages"]:
                last_msg = data["messages"][-1]
                if hasattr(last_msg, 'content') and last_msg.content:
                    print(f"  内容: {last_msg.content[:100]}")
                if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                    for tc in last_msg.tool_calls:
                        print(f"  工具调用: {tc['name']}({tc['args']})")

    print(f"\n总共执行了 {step_count} 个步骤\n")

# 使用示例
if __name__ == "__main__":
    track_agent_progress("北京的天气和东京的时间")
```

---

## 示例 3：自定义进度更新（custom 模式）

```python
"""
自定义进度更新
展示 custom 模式的基本用法
"""

import time
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langgraph.config import get_stream_writer

def process_files(file_count: int) -> str:
    """处理文件并发送进度"""
    writer = get_stream_writer()

    writer(f"开始处理 {file_count} 个文件")

    for i in range(file_count):
        # 模拟处理
        time.sleep(0.1)

        # 发送进度
        progress = (i + 1) / file_count * 100
        writer({
            "type": "progress",
            "current": i + 1,
            "total": file_count,
            "percentage": progress
        })

    writer("处理完成")
    return f"成功处理 {file_count} 个文件"

# 创建 Agent
model = ChatOpenAI(model="gpt-4o-mini")
agent = create_agent(model=model, tools=[process_files])

def stream_custom_progress(user_input: str):
    """流式接收自定义进度"""
    print(f"用户输入: {user_input}\n")

    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": user_input}]},
        stream_mode="custom"
    ):
        if isinstance(chunk, dict):
            # 结构化数据
            if chunk.get("type") == "progress":
                print(f"进度: {chunk['percentage']:.1f}% ({chunk['current']}/{chunk['total']})")
        else:
            # 字符串消息
            print(chunk)

    print()

# 使用示例
if __name__ == "__main__":
    stream_custom_progress("处理 10 个文件")
```

---

## 示例 4：多模式组合

```python
"""
多模式流式组合
同时使用 updates、messages、custom 三种模式
"""

import asyncio
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langgraph.config import get_stream_writer

def analyze_data(data: str) -> str:
    """分析数据"""
    writer = get_stream_writer()

    writer("步骤 1: 数据验证")
    writer("步骤 2: 数据分析")
    writer("步骤 3: 生成报告")

    return f"分析完成: {data}"

# 创建 Agent
model = ChatOpenAI(model="gpt-4o-mini")
agent = create_agent(model=model, tools=[analyze_data])

async def multi_mode_streaming(user_input: str):
    """多模式流式输出"""
    print(f"用户输入: {user_input}\n")

    async for mode, data in agent.astream(
        {"messages": [{"role": "user", "content": user_input}]},
        stream_mode=["updates", "messages", "custom"]
    ):
        if mode == "updates":
            # Agent 进度
            for node_name in data.keys():
                print(f"[步骤] {node_name} 执行完成")

        elif mode == "messages":
            # LLM tokens
            token, metadata = data
            if hasattr(token, 'content') and token.content:
                print(token.content, end="", flush=True)

        elif mode == "custom":
            # 自定义数据
            print(f"\n[进度] {data}")

    print("\n")

# 使用示例
async def main():
    await multi_mode_streaming("分析用户数据")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 5：完整的对话应用

```python
"""
完整的流式对话应用
包含历史记录管理和错误处理
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.memory import ConversationBufferMemory

class StreamingChatApp:
    def __init__(self):
        self.model = ChatOpenAI(model="gpt-4o-mini")
        self.memory = ConversationBufferMemory(return_messages=True)
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个友好的助手"),
            ("placeholder", "{history}"),
            ("user", "{input}")
        ])
        self.chain = self.prompt | self.model | StrOutputParser()

    async def chat(self, user_input: str):
        """流式对话"""
        # 获取历史记录
        history = self.memory.load_memory_variables({})["history"]

        # 流式执行
        print(f"用户: {user_input}")
        print("助手: ", end="", flush=True)

        full_response = ""
        try:
            async for chunk in self.chain.astream({
                "input": user_input,
                "history": history
            }):
                print(chunk, end="", flush=True)
                full_response += chunk

            print("\n")

            # 保存到记忆
            self.memory.save_context(
                {"input": user_input},
                {"output": full_response}
            )

        except Exception as e:
            print(f"\n错误: {e}")
            # 降级到批量模式
            result = self.chain.invoke({
                "input": user_input,
                "history": history
            })
            print(result)
            self.memory.save_context(
                {"input": user_input},
                {"output": result}
            )

# 使用示例
async def main():
    app = StreamingChatApp()

    await app.chat("你好")
    await app.chat("我叫小明")
    await app.chat("我叫什么名字？")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 运行说明

### 环境配置

```bash
# 安装依赖
uv add langchain langchain-openai langchain-core langgraph

# 配置 API 密钥
export OPENAI_API_KEY="your_key_here"
```

### 运行示例

```bash
# 示例 1: ChatGPT 式对话
python 01_chatgpt_style.py

# 示例 2: Agent 进度追踪
python 02_agent_progress.py

# 示例 3: 自定义进度
python 03_custom_progress.py

# 示例 4: 多模式组合
python 04_multi_mode.py

# 示例 5: 完整对话应用
python 05_complete_chat.py
```

---

## 关键要点

1. **messages 模式**：适用于 ChatGPT 式对话
2. **updates 模式**：适用于 Agent 进度追踪
3. **custom 模式**：适用于自定义进度更新
4. **多模式组合**：可同时使用多种模式
5. **错误处理**：实现降级到批量模式

---

**版本**: LangChain 0.3.x (2025-2026)
**最后更新**: 2026-02-21
