# 实战代码 4：分布式哈希表

## 场景描述

**2026 年的 AI Agent 系统需要在多个节点间协调和发现服务，分布式哈希表（DHT）提供了去中心化的解决方案。**

### 核心需求

1. **Agent 发现**：在分布式系统中快速找到目标 Agent
2. **负载均衡**：均匀分配数据到各个节点
3. **容错性**：节点故障时自动恢复
4. **可扩展性**：支持动态添加和删除节点

---

## Kademlia DHT 实现

### 核心概念

**Kademlia 使用 XOR 距离度量实现高效路由。**

```python
from typing import Dict, List, Optional, Set
from dataclasses import dataclass
import random
import time


@dataclass
class Node:
    """节点信息"""
    node_id: int
    address: str
    port: int
    last_seen: float


class KademliaDHT:
    """
    Kademlia 分布式哈希表
    用于 2026 Internet of Agents 架构
    """

    def __init__(self, node_id: int, k: int = 20):
        self.node_id = node_id
        self.k = k  # 每个桶的大小
        self.id_bits = 160  # 160 位 ID 空间

        # 路由表：桶索引 → 节点列表
        self.routing_table: Dict[int, List[Node]] = {}

        # 数据存储：键 → 值
        self.storage: Dict[int, any] = {}

        self.stats = {
            "lookups": 0,
            "stores": 0,
            "nodes_seen": 0,
        }

    def _xor_distance(self, id1: int, id2: int) -> int:
        """计算 XOR 距离"""
        return id1 ^ id2

    def _bucket_index(self, target_id: int) -> int:
        """
        计算目标 ID 应该在哪个桶
        桶索引 = 距离的最高位位置
        """
        distance = self._xor_distance(self.node_id, target_id)
        if distance == 0:
            return 0

        # 计算最高位的位置
        return distance.bit_length() - 1

    def add_node(self, node: Node):
        """添加节点到路由表"""
        if node.node_id == self.node_id:
            return  # 不添加自己

        bucket_idx = self._bucket_index(node.node_id)

        if bucket_idx not in self.routing_table:
            self.routing_table[bucket_idx] = []

        bucket = self.routing_table[bucket_idx]

        # 检查节点是否已存在
        for i, existing_node in enumerate(bucket):
            if existing_node.node_id == node.node_id:
                # 更新节点信息
                bucket[i] = node
                return

        # 桶未满，直接添加
        if len(bucket) < self.k:
            bucket.append(node)
            self.stats["nodes_seen"] += 1
        else:
            # 桶已满，使用 LRU 策略
            # 移除最旧的节点
            bucket.pop(0)
            bucket.append(node)

    def find_closest_nodes(self, target_id: int, count: int = None) -> List[Node]:
        """
        查找最接近目标 ID 的节点
        用于路由查询
        """
        if count is None:
            count = self.k

        all_nodes = []
        for bucket in self.routing_table.values():
            all_nodes.extend(bucket)

        # 按 XOR 距离排序
        all_nodes.sort(key=lambda n: self._xor_distance(n.node_id, target_id))

        return all_nodes[:count]

    def store(self, key: int, value: any):
        """存储键值对"""
        self.storage[key] = value
        self.stats["stores"] += 1

    def retrieve(self, key: int) -> Optional[any]:
        """检索值"""
        self.stats["lookups"] += 1
        return self.storage.get(key)

    def find_node(self, target_id: int) -> Optional[Node]:
        """
        查找目标节点
        返回最接近的节点
        """
        closest_nodes = self.find_closest_nodes(target_id, count=1)
        return closest_nodes[0] if closest_nodes else None

    def get_routing_table_stats(self) -> Dict:
        """获取路由表统计"""
        total_nodes = sum(len(bucket) for bucket in self.routing_table.values())
        non_empty_buckets = len([b for b in self.routing_table.values() if b])

        return {
            "total_nodes": total_nodes,
            "num_buckets": len(self.routing_table),
            "non_empty_buckets": non_empty_buckets,
            "avg_bucket_size": total_nodes / non_empty_buckets if non_empty_buckets > 0 else 0,
        }


# 使用示例
if __name__ == "__main__":
    # 创建 DHT 节点
    dht = KademliaDHT(node_id=12345, k=20)

    # 添加其他节点
    nodes = [
        Node(node_id=11111, address="192.168.1.1", port=8000, last_seen=time.time()),
        Node(node_id=22222, address="192.168.1.2", port=8000, last_seen=time.time()),
        Node(node_id=33333, address="192.168.1.3", port=8000, last_seen=time.time()),
    ]

    for node in nodes:
        dht.add_node(node)

    # 存储数据
    dht.store(key=99999, value="Agent response data")

    # 查找节点
    target_node = dht.find_node(target_id=22222)
    print(f"找到节点: {target_node}")

    # 检索数据
    value = dht.retrieve(key=99999)
    print(f"检索到值: {value}")

    # 统计信息
    print(f"路由表统计: {dht.get_routing_table_stats()}")
    print(f"操作统计: {dht.stats}")
```

---

## 一致性哈希实现

### 核心概念

**一致性哈希用于负载均衡，节点变化时只影响少量数据。**

```python
import hashlib
from typing import Dict, List, Optional
from bisect import bisect_right


class ConsistentHash:
    """
    一致性哈希
    用于分布式缓存和负载均衡
    """

    def __init__(self, nodes: List[str] = None, virtual_nodes: int = 150):
        self.virtual_nodes = virtual_nodes  # 虚拟节点数量
        self.ring: Dict[int, str] = {}  # 哈希环：哈希值 → 节点名
        self.sorted_keys: List[int] = []  # 排序的哈希值列表

        if nodes:
            for node in nodes:
                self.add_node(node)

    def _hash(self, key: str) -> int:
        """计算哈希值"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def add_node(self, node: str):
        """添加节点"""
        for i in range(self.virtual_nodes):
            # 为每个物理节点创建多个虚拟节点
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)

            self.ring[hash_value] = node
            self.sorted_keys.append(hash_value)

        # 保持排序
        self.sorted_keys.sort()

    def remove_node(self, node: str):
        """删除节点"""
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)

            if hash_value in self.ring:
                del self.ring[hash_value]
                self.sorted_keys.remove(hash_value)

    def get_node(self, key: str) -> Optional[str]:
        """获取键对应的节点"""
        if not self.ring:
            return None

        hash_value = self._hash(key)

        # 在环上顺时针查找第一个节点
        idx = bisect_right(self.sorted_keys, hash_value)

        if idx == len(self.sorted_keys):
            idx = 0  # 环形，回到开头

        return self.ring[self.sorted_keys[idx]]

    def get_nodes(self, key: str, count: int = 3) -> List[str]:
        """获取键对应的多个节点（用于副本）"""
        if not self.ring:
            return []

        hash_value = self._hash(key)
        idx = bisect_right(self.sorted_keys, hash_value)

        nodes = []
        seen = set()

        for _ in range(len(self.sorted_keys)):
            if idx >= len(self.sorted_keys):
                idx = 0

            node = self.ring[self.sorted_keys[idx]]
            if node not in seen:
                nodes.append(node)
                seen.add(node)

                if len(nodes) >= count:
                    break

            idx += 1

        return nodes

    def get_distribution(self, keys: List[str]) -> Dict[str, int]:
        """获取键的分布情况"""
        distribution = {}

        for key in keys:
            node = self.get_node(key)
            distribution[node] = distribution.get(node, 0) + 1

        return distribution


# 使用示例
if __name__ == "__main__":
    # 创建一致性哈希
    ch = ConsistentHash(
        nodes=["agent1", "agent2", "agent3"],
        virtual_nodes=150
    )

    # 分配任务
    tasks = [f"task_{i}" for i in range(100)]

    distribution = ch.get_distribution(tasks)
    print("任务分布:")
    for node, count in distribution.items():
        print(f"  {node}: {count} 个任务")

    # 添加新节点
    print("\n添加新节点 agent4...")
    ch.add_node("agent4")

    new_distribution = ch.get_distribution(tasks)
    print("新的任务分布:")
    for node, count in new_distribution.items():
        print(f"  {node}: {count} 个任务")

    # 计算数据迁移量
    moved = sum(
        abs(new_distribution.get(node, 0) - distribution.get(node, 0))
        for node in set(list(distribution.keys()) + list(new_distribution.keys()))
    ) // 2

    print(f"\n数据迁移量: {moved} / {len(tasks)} ({moved/len(tasks):.1%})")
```

---

## 2026 实际应用

### 应用 1：Internet of Agents 服务发现

```python
class AgentDiscoveryService:
    """
    Agent 发现服务
    基于 Kademlia DHT
    """

    def __init__(self, node_id: int):
        self.dht = KademliaDHT(node_id=node_id, k=20)
        self.local_agents: Dict[str, Dict] = {}

    def register_agent(self, agent_id: str, capabilities: List[str], endpoint: str):
        """注册 Agent"""
        # 计算 Agent ID 的哈希
        agent_hash = hash(agent_id) % (2**160)

        # 存储到 DHT
        agent_info = {
            "agent_id": agent_id,
            "capabilities": capabilities,
            "endpoint": endpoint,
            "registered_at": time.time(),
        }

        self.dht.store(key=agent_hash, value=agent_info)
        self.local_agents[agent_id] = agent_info

        print(f"✓ 注册 Agent: {agent_id}")
        print(f"  能力: {', '.join(capabilities)}")
        print(f"  端点: {endpoint}")

    def discover_agent(self, capability: str) -> Optional[Dict]:
        """发现具有特定能力的 Agent"""
        # 在本地 Agent 中查找
        for agent_id, info in self.local_agents.items():
            if capability in info["capabilities"]:
                return info

        # 在 DHT 中查找（简化版）
        capability_hash = hash(capability) % (2**160)
        return self.dht.retrieve(key=capability_hash)

    def get_stats(self) -> Dict:
        """获取统计信息"""
        return {
            "local_agents": len(self.local_agents),
            "dht_stats": self.dht.stats,
            "routing_table": self.dht.get_routing_table_stats(),
        }


# 使用示例
if __name__ == "__main__":
    # 创建发现服务
    discovery = AgentDiscoveryService(node_id=12345)

    # 注册 Agents
    discovery.register_agent(
        agent_id="search_agent_001",
        capabilities=["search", "web_scraping"],
        endpoint="http://192.168.1.10:8000"
    )

    discovery.register_agent(
        agent_id="summarize_agent_001",
        capabilities=["summarize", "text_analysis"],
        endpoint="http://192.168.1.11:8000"
    )

    # 发现 Agent
    agent = discovery.discover_agent("search")
    if agent:
        print(f"\n✓ 发现 Agent: {agent['agent_id']}")
        print(f"  端点: {agent['endpoint']}")

    # 统计
    print(f"\n统计信息: {discovery.get_stats()}")
```

### 应用 2：分布式缓存系统

```python
class DistributedCache:
    """
    分布式缓存系统
    使用一致性哈希实现负载均衡
    """

    def __init__(self, cache_nodes: List[str]):
        self.consistent_hash = ConsistentHash(
            nodes=cache_nodes,
            virtual_nodes=150
        )
        # 模拟本地缓存
        self.local_cache: Dict[str, any] = {}

    def set(self, key: str, value: any):
        """设置缓存"""
        # 确定目标节点
        target_node = self.consistent_hash.get_node(key)

        print(f"存储 {key} 到节点 {target_node}")

        # 实际应用中应该发送到远程节点
        # 这里简化为本地存储
        cache_key = f"{target_node}:{key}"
        self.local_cache[cache_key] = value

    def get(self, key: str) -> Optional[any]:
        """获取缓存"""
        target_node = self.consistent_hash.get_node(key)
        cache_key = f"{target_node}:{key}"

        return self.local_cache.get(cache_key)

    def set_with_replication(self, key: str, value: any, replicas: int = 3):
        """设置缓存（带副本）"""
        # 获取多个节点
        target_nodes = self.consistent_hash.get_nodes(key, count=replicas)

        print(f"存储 {key} 到节点: {', '.join(target_nodes)}")

        for node in target_nodes:
            cache_key = f"{node}:{key}"
            self.local_cache[cache_key] = value

    def add_node(self, node: str):
        """添加缓存节点"""
        print(f"\n添加节点: {node}")
        self.consistent_hash.add_node(node)

        # 实际应用中需要重新分配数据
        print("数据重新分配中...")

    def remove_node(self, node: str):
        """删除缓存节点"""
        print(f"\n删除节点: {node}")
        self.consistent_hash.remove_node(node)

        # 实际应用中需要迁移数据
        print("数据迁移中...")


# 使用示例
if __name__ == "__main__":
    # 创建分布式缓存
    cache = DistributedCache(
        cache_nodes=["cache1", "cache2", "cache3"]
    )

    # 存储数据
    cache.set("user:1001", {"name": "Alice", "age": 25})
    cache.set("user:1002", {"name": "Bob", "age": 30})
    cache.set("user:1003", {"name": "Charlie", "age": 35})

    # 获取数据
    user = cache.get("user:1001")
    print(f"\n获取用户: {user}")

    # 带副本存储
    cache.set_with_replication("important:data", {"value": 42}, replicas=3)

    # 动态扩容
    cache.add_node("cache4")
```

---

## 性能测试

```python
def benchmark_dht():
    """DHT 性能测试"""
    print("=== DHT 性能测试 ===\n")

    # 创建 DHT
    dht = KademliaDHT(node_id=0, k=20)

    # 添加节点
    num_nodes = 1000
    start = time.time()
    for i in range(1, num_nodes + 1):
        node = Node(
            node_id=i,
            address=f"192.168.1.{i % 255}",
            port=8000,
            last_seen=time.time()
        )
        dht.add_node(node)
    add_time = time.time() - start

    print(f"添加 {num_nodes} 个节点: {add_time:.4f}s")
    print(f"平均每节点: {add_time / num_nodes * 1000:.4f}ms")

    # 查找性能
    start = time.time()
    for _ in range(1000):
        dht.find_node(target_id=random.randint(1, num_nodes))
    lookup_time = time.time() - start

    print(f"\n查找 1000 次: {lookup_time:.4f}s")
    print(f"平均每次查找: {lookup_time / 1000 * 1000:.4f}ms")

    # 路由表统计
    stats = dht.get_routing_table_stats()
    print(f"\n路由表统计:")
    print(f"  总节点数: {stats['total_nodes']}")
    print(f"  桶数量: {stats['num_buckets']}")
    print(f"  非空桶: {stats['non_empty_buckets']}")
    print(f"  平均桶大小: {stats['avg_bucket_size']:.2f}")


def benchmark_consistent_hash():
    """一致性哈希性能测试"""
    print("\n=== 一致性哈希性能测试 ===\n")

    # 创建一致性哈希
    nodes = [f"node{i}" for i in range(10)]
    ch = ConsistentHash(nodes=nodes, virtual_nodes=150)

    # 分配性能
    num_keys = 10000
    keys = [f"key_{i}" for i in range(num_keys)]

    start = time.time()
    for key in keys:
        ch.get_node(key)
    assign_time = time.time() - start

    print(f"分配 {num_keys} 个键: {assign_time:.4f}s")
    print(f"平均每键: {assign_time / num_keys * 1000:.4f}ms")

    # 负载均衡测试
    distribution = ch.get_distribution(keys)
    avg = num_keys / len(nodes)
    max_dev = max(abs(count - avg) for count in distribution.values())

    print(f"\n负载均衡:")
    print(f"  平均每节点: {avg:.0f} 个键")
    print(f"  最大偏差: {max_dev:.0f} ({max_dev / avg:.1%})")

    # 节点变化影响
    ch.add_node("node10")
    new_distribution = ch.get_distribution(keys)

    moved = sum(
        1 for key in keys
        if ch.get_node(key) != distribution.get(ch.get_node(key), 0)
    )

    print(f"\n添加节点后:")
    print(f"  数据迁移: {moved} / {num_keys} ({moved / num_keys:.1%})")


if __name__ == "__main__":
    benchmark_dht()
    benchmark_consistent_hash()
```

---

## 核心要点

### Hash Table 的作用

1. **路由表**：Kademlia 使用哈希表存储节点信息
2. **数据存储**：DHT 本身就是分布式哈希表
3. **一致性哈希环**：哈希值到节点的映射

### 实际应用场景

- **Agent 发现**：Internet of Agents 架构
- **负载均衡**：分布式缓存系统
- **P2P 网络**：去中心化存储
- **微服务协调**：服务注册与发现

### 2026 最佳实践

- Kademlia DHT 用于 Agent 发现（亚秒级）
- 一致性哈希用于负载均衡
- 虚拟节点数量 150-200 最优
- XOR 距离度量比欧氏距离更高效

**记住：分布式哈希表是 2026 年 AI Agent 系统协调的基础设施。**
