# 实战代码

> 从零实现一个最简 RAG 系统

---

## 代码目标

实现一个完整的 RAG 系统，包含：
- 离线索引：加载文档 → 分块 → 向量化 → 存储
- 在线查询：用户提问 → 检索 → 生成答案

---

## 完整代码

```python
"""
RAG 架构全景 - 实战示例
演示：从零构建一个完整的 RAG 系统
"""

import os
from typing import List, Dict

# ===== 依赖安装 =====
# pip install openai chromadb

from openai import OpenAI
import chromadb

# ===== 配置 =====
# 请设置环境变量: export OPENAI_API_KEY="your-api-key"
client = OpenAI()
EMBEDDING_MODEL = "text-embedding-3-small"
LLM_MODEL = "gpt-4o-mini"


# ===== 1. 模拟文档数据 =====
# 实际项目中，这些会从 PDF、Word 等文件加载
DOCUMENTS = [
    {
        "id": "doc1",
        "title": "退款政策",
        "content": """
        退款政策说明：
        1. 客户可在购买后7天内申请全额退款
        2. 7-30天内申请退款，扣除10%手续费
        3. 超过30天不支持退款
        4. 退款将在3-5个工作日内原路返回
        """
    },
    {
        "id": "doc2",
        "title": "配送说明",
        "content": """
        配送服务说明：
        1. 标准配送：3-5个工作日，免费
        2. 加急配送：1-2个工作日，额外收费20元
        3. 偏远地区可能需要额外1-2天
        4. 可在订单页面实时查看物流状态
        """
    },
    {
        "id": "doc3",
        "title": "会员权益",
        "content": """
        会员权益说明：
        1. 普通会员：享受9.5折优惠
        2. 黄金会员：享受9折优惠 + 免费加急配送
        3. 钻石会员：享受8.5折优惠 + 专属客服
        4. 会员积分可兑换优惠券
        """
    }
]


# ===== 2. 文本分块（Chunker）=====
def simple_chunker(text: str, chunk_size: int = 200, overlap: int = 50) -> List[str]:
    """
    简单的文本分块器

    Args:
        text: 原始文本
        chunk_size: 每块最大字符数
        overlap: 块之间的重叠字符数

    Returns:
        文本块列表
    """
    chunks = []
    start = 0
    text = text.strip()

    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk.strip())
        start = end - overlap  # 重叠部分

        if start >= len(text):
            break

    return [c for c in chunks if c]  # 过滤空块


# ===== 3. 向量化（Embedder）=====
def get_embedding(text: str) -> List[float]:
    """
    将文本转换为向量

    Args:
        text: 输入文本

    Returns:
        向量（1536维）
    """
    response = client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=text
    )
    return response.data[0].embedding


# ===== 4. 向量存储（VectorStore）=====
def create_vector_store():
    """创建向量数据库"""
    chroma_client = chromadb.Client()  # 内存模式
    collection = chroma_client.create_collection(
        name="rag_demo",
        metadata={"description": "RAG 演示知识库"}
    )
    return collection


# ===== 5. 离线索引流程 =====
def build_index(collection, documents: List[Dict]):
    """
    离线索引：将文档处理并存入向量库

    流程：文档 → 分块 → 向量化 → 存储
    """
    print("=" * 50)
    print("开始离线索引...")
    print("=" * 50)

    all_chunks = []
    all_embeddings = []
    all_ids = []
    all_metadatas = []

    for doc in documents:
        print(f"\n处理文档: {doc['title']}")

        # 分块
        chunks = simple_chunker(doc['content'])
        print(f"  - 分块数量: {len(chunks)}")

        for i, chunk in enumerate(chunks):
            chunk_id = f"{doc['id']}_chunk_{i}"

            # 向量化
            embedding = get_embedding(chunk)

            all_chunks.append(chunk)
            all_embeddings.append(embedding)
            all_ids.append(chunk_id)
            all_metadatas.append({
                "doc_id": doc['id'],
                "doc_title": doc['title'],
                "chunk_index": i
            })

            print(f"  - 块 {i}: {chunk[:30]}...")

    # 批量存入向量库
    collection.add(
        documents=all_chunks,
        embeddings=all_embeddings,
        ids=all_ids,
        metadatas=all_metadatas
    )

    print(f"\n索引完成！共 {len(all_chunks)} 个文本块")
    return collection


# ===== 6. 检索器（Retriever）=====
def retrieve(collection, query: str, top_k: int = 3) -> List[Dict]:
    """
    检索最相关的文档块

    Args:
        collection: 向量库
        query: 用户问题
        top_k: 返回结果数量

    Returns:
        相关文档块列表
    """
    # 将问题向量化
    query_embedding = get_embedding(query)

    # 向量检索
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    # 整理结果
    retrieved = []
    for i in range(len(results['ids'][0])):
        retrieved.append({
            "id": results['ids'][0][i],
            "content": results['documents'][0][i],
            "metadata": results['metadatas'][0][i],
            "distance": results['distances'][0][i] if results['distances'] else None
        })

    return retrieved


# ===== 7. 生成器（Generator）=====
def generate_answer(query: str, context: List[Dict]) -> str:
    """
    基于检索结果生成答案

    Args:
        query: 用户问题
        context: 检索到的相关内容

    Returns:
        生成的答案
    """
    # 组装上下文
    context_text = "\n\n".join([
        f"【来源: {c['metadata']['doc_title']}】\n{c['content']}"
        for c in context
    ])

    # 构建 Prompt
    prompt = f"""你是一个客服助手。请根据以下参考资料回答用户问题。

要求：
1. 只根据参考资料回答，不要编造信息
2. 如果参考资料中没有相关信息，请说明"根据现有资料无法回答"
3. 回答要简洁明了

参考资料：
{context_text}

用户问题：{query}

请回答："""

    # 调用 LLM
    response = client.chat.completions.create(
        model=LLM_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3  # 降低随机性，更准确
    )

    return response.choices[0].message.content


# ===== 8. 完整 RAG Pipeline =====
def rag_query(collection, query: str) -> Dict:
    """
    完整的 RAG 查询流程

    Args:
        collection: 向量库
        query: 用户问题

    Returns:
        包含答案和来源的字典
    """
    print(f"\n{'=' * 50}")
    print(f"用户问题: {query}")
    print('=' * 50)

    # Step 1: 检索
    print("\n[Step 1] 检索相关内容...")
    retrieved = retrieve(collection, query, top_k=3)

    for i, doc in enumerate(retrieved):
        print(f"  结果 {i+1}: {doc['metadata']['doc_title']}")
        print(f"    内容: {doc['content'][:50]}...")
        print(f"    距离: {doc['distance']:.4f}")

    # Step 2: 生成
    print("\n[Step 2] 生成答案...")
    answer = generate_answer(query, retrieved)

    print(f"\n[答案]\n{answer}")

    # 返回结果
    return {
        "query": query,
        "answer": answer,
        "sources": [
            {
                "title": doc['metadata']['doc_title'],
                "content": doc['content']
            }
            for doc in retrieved
        ]
    }


# ===== 9. 主程序 =====
def main():
    """主程序：演示完整的 RAG 流程"""

    print("\n" + "=" * 60)
    print("RAG 架构全景 - 实战演示")
    print("=" * 60)

    # ===== 离线索引阶段 =====
    print("\n【阶段1: 离线索引】")
    collection = create_vector_store()
    build_index(collection, DOCUMENTS)

    # ===== 在线查询阶段 =====
    print("\n【阶段2: 在线查询】")

    # 测试问题
    test_questions = [
        "如何申请退款？",
        "加急配送要多少钱？",
        "钻石会员有什么权益？"
    ]

    for question in test_questions:
        result = rag_query(collection, question)
        print("\n" + "-" * 50)

    print("\n" + "=" * 60)
    print("演示完成！")
    print("=" * 60)


if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
RAG 架构全景 - 实战演示
============================================================

【阶段1: 离线索引】
==================================================
开始离线索引...
==================================================

处理文档: 退款政策
  - 分块数量: 1
  - 块 0: 退款政策说明：
        1. 客户可在购买后7天内...

处理文档: 配送说明
  - 分块数量: 1
  - 块 0: 配送服务说明：
        1. 标准配送：3-5个工作日...

处理文档: 会员权益
  - 分块数量: 1
  - 块 0: 会员权益说明：
        1. 普通会员：享受9.5折优惠...

索引完成！共 3 个文本块

【阶段2: 在线查询】

==================================================
用户问题: 如何申请退款？
==================================================

[Step 1] 检索相关内容...
  结果 1: 退款政策
    内容: 退款政策说明：
        1. 客户可在购买后7天内申请全额退款...
    距离: 0.3521

[Step 2] 生成答案...

[答案]
根据退款政策，您可以按以下方式申请退款：
1. 购买后7天内：可申请全额退款
2. 7-30天内：可申请退款，但需扣除10%手续费
3. 超过30天：不支持退款

退款将在3-5个工作日内原路返回。

--------------------------------------------------
```

---

## 代码结构说明

```
代码结构对应 RAG 六大组件：

┌─────────────────────────────────────────────────┐
│  DOCUMENTS          → Loader（模拟文档加载）     │
│  simple_chunker()   → Chunker（文本分块）        │
│  get_embedding()    → Embedder（向量化）         │
│  create_vector_store() → VectorStore（向量存储） │
│  retrieve()         → Retriever（检索器）        │
│  generate_answer()  → Generator（生成器）        │
│  rag_query()        → 完整 Pipeline              │
└─────────────────────────────────────────────────┘
```

---

## 扩展练习

1. **添加更多文档**：尝试添加自己的文档到 `DOCUMENTS` 列表
2. **调整分块参数**：修改 `chunk_size` 和 `overlap`，观察效果变化
3. **修改 Top-K**：在 `retrieve()` 中调整 `top_k` 参数
4. **优化 Prompt**：修改 `generate_answer()` 中的 Prompt 模板

---

**下一步：** [08_面试必问](./08_面试必问.md) - 准备 RAG 相关面试
