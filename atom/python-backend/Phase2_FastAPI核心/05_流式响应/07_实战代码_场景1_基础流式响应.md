# 实战代码 - 场景1：基础流式响应

> 完整可运行的基础流式响应示例

---

## 场景描述

实现一个简单的流式响应端点，逐步生成和发送数据，演示流式响应的基本用法。

---

## 完整代码

```python
"""
场景1：基础流式响应
演示：StreamingResponse 的基本用法
"""

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio
from typing import AsyncGenerator

app = FastAPI(title="基础流式响应示例")

# ===== 1. 最简单的流式响应 =====
print("=== 场景1：最简单的流式响应 ===")

async def simple_stream() -> AsyncGenerator[str, None]:
    """最简单的异步生成器"""
    for i in range(10):
        await asyncio.sleep(0.5)  # 模拟耗时操作
        yield f"数据 {i}\n"

@app.get("/simple")
async def simple_endpoint():
    """最简单的流式响应端点"""
    return StreamingResponse(
        simple_stream(),
        media_type="text/plain"
    )

# ===== 2. 带参数的流式响应 =====
print("=== 场景2：带参数的流式响应 ===")

async def parameterized_stream(count: int, delay: float) -> AsyncGenerator[str, None]:
    """带参数的异步生成器"""
    for i in range(count):
        await asyncio.sleep(delay)
        yield f"第 {i + 1}/{count} 条数据\n"

@app.get("/parameterized/{count}")
async def parameterized_endpoint(count: int, delay: float = 0.5):
    """带参数的流式响应端点"""
    return StreamingResponse(
        parameterized_stream(count, delay),
        media_type="text/plain"
    )

# ===== 3. JSON 流式响应 =====
print("=== 场景3：JSON 流式响应 ===")

import json

async def json_stream(count: int) -> AsyncGenerator[str, None]:
    """JSON 格式的流式响应"""
    for i in range(count):
        await asyncio.sleep(0.3)
        data = {
            "id": i,
            "message": f"数据项 {i}",
            "timestamp": asyncio.get_event_loop().time()
        }
        # 每行一个 JSON 对象（NDJSON 格式）
        yield json.dumps(data) + "\n"

@app.get("/json/{count}")
async def json_endpoint(count: int):
    """JSON 流式响应端点"""
    return StreamingResponse(
        json_stream(count),
        media_type="application/x-ndjson"  # Newline Delimited JSON
    )

# ===== 4. 带资源清理的流式响应 =====
print("=== 场景4：带资源清理的流式响应 ===")

async def stream_with_cleanup() -> AsyncGenerator[str, None]:
    """带资源清理的流式响应"""
    # 模拟获取资源
    resource = "数据库连接"
    print(f"获取资源: {resource}")

    try:
        for i in range(5):
            await asyncio.sleep(0.2)
            yield f"使用 {resource} 获取数据 {i}\n"
    finally:
        # 确保资源释放
        print(f"释放资源: {resource}")
        yield f"资源已释放\n"

@app.get("/cleanup")
async def cleanup_endpoint():
    """带资源清理的流式响应端点"""
    return StreamingResponse(
        stream_with_cleanup(),
        media_type="text/plain"
    )

# ===== 5. 处理客户端断开连接 =====
print("=== 场景5：处理客户端断开连接 ===")

async def stream_with_disconnect_handling() -> AsyncGenerator[str, None]:
    """处理客户端断开连接"""
    try:
        for i in range(100):
            await asyncio.sleep(0.1)
            yield f"数据 {i}\n"
    except GeneratorExit:
        # 客户端断开连接时触发
        print("客户端断开连接，停止生成数据")
    finally:
        print("生成器结束，资源已清理")

@app.get("/disconnect")
async def disconnect_endpoint():
    """处理客户端断开连接的端点"""
    return StreamingResponse(
        stream_with_disconnect_handling(),
        media_type="text/plain"
    )

# ===== 6. 同步生成器 vs 异步生成器对比 =====
print("=== 场景6：同步 vs 异步生成器对比 ===")

import time

def sync_generator():
    """同步生成器（不推荐）"""
    for i in range(5):
        time.sleep(0.5)  # 阻塞事件循环
        yield f"同步数据 {i}\n"

async def async_generator():
    """异步生成器（推荐）"""
    for i in range(5):
        await asyncio.sleep(0.5)  # 不阻塞事件循环
        yield f"异步数据 {i}\n"

@app.get("/sync")
def sync_endpoint():
    """同步生成器端点（不推荐）"""
    return StreamingResponse(
        sync_generator(),
        media_type="text/plain"
    )

@app.get("/async")
async def async_endpoint():
    """异步生成器端点（推荐）"""
    return StreamingResponse(
        async_generator(),
        media_type="text/plain"
    )

# ===== 7. 自定义响应头 =====
print("=== 场景7：自定义响应头 ===")

async def stream_with_headers() -> AsyncGenerator[str, None]:
    """带自定义响应头的流式响应"""
    for i in range(5):
        await asyncio.sleep(0.3)
        yield f"数据 {i}\n"

@app.get("/headers")
async def headers_endpoint():
    """带自定义响应头的端点"""
    return StreamingResponse(
        stream_with_headers(),
        media_type="text/plain",
        headers={
            "X-Custom-Header": "CustomValue",
            "Cache-Control": "no-cache",
            "Connection": "keep-alive"
        }
    )

# ===== 运行服务器 =====
if __name__ == "__main__":
    import uvicorn

    print("\n" + "="*50)
    print("启动 FastAPI 服务器")
    print("="*50)
    print("\n可用端点：")
    print("  GET  http://localhost:8000/simple")
    print("  GET  http://localhost:8000/parameterized/10?delay=0.5")
    print("  GET  http://localhost:8000/json/5")
    print("  GET  http://localhost:8000/cleanup")
    print("  GET  http://localhost:8000/disconnect")
    print("  GET  http://localhost:8000/sync")
    print("  GET  http://localhost:8000/async")
    print("  GET  http://localhost:8000/headers")
    print("\n使用 curl 测试：")
    print("  curl http://localhost:8000/simple")
    print("  curl http://localhost:8000/json/5")
    print("\n按 Ctrl+C 停止服务器")
    print("="*50 + "\n")

    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 运行输出示例

### 测试1：简单流式响应

```bash
$ curl http://localhost:8000/simple
数据 0
数据 1
数据 2
数据 3
数据 4
数据 5
数据 6
数据 7
数据 8
数据 9
```

**特点：**
- 每 0.5秒 输出一行
- 总耗时约 5秒
- 用户立即看到第一行（0.5秒后）

### 测试2：JSON 流式响应

```bash
$ curl http://localhost:8000/json/3
{"id": 0, "message": "数据项 0", "timestamp": 1234567890.123}
{"id": 1, "message": "数据项 1", "timestamp": 1234567890.456}
{"id": 2, "message": "数据项 2", "timestamp": 1234567890.789}
```

**特点：**
- NDJSON 格式（每行一个 JSON）
- 前端可以逐行解析
- 适合流式传输结构化数据

### 测试3：资源清理

```bash
$ curl http://localhost:8000/cleanup
使用 数据库连接 获取数据 0
使用 数据库连接 获取数据 1
使用 数据库连接 获取数据 2
使用 数据库连接 获取数据 3
使用 数据库连接 获取数据 4
资源已释放
```

**服务器日志：**
```
获取资源: 数据库连接
释放资源: 数据库连接
```

**特点：**
- `finally` 块确保资源释放
- 无论是否正常结束，都会执行清理

### 测试4：客户端断开连接

```bash
$ curl http://localhost:8000/disconnect
数据 0
数据 1
数据 2
^C  # 用户按 Ctrl+C 断开连接
```

**服务器日志：**
```
客户端断开连接，停止生成数据
生成器结束，资源已清理
```

**特点：**
- 捕获 `GeneratorExit` 异常
- 可以记录日志、清理资源

---

## 前端接收示例

### JavaScript (Fetch API)

```javascript
// 接收流式响应
async function fetchStream() {
    const response = await fetch('http://localhost:8000/simple');
    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const text = decoder.decode(value);
        console.log(text);  // 逐步输出
        document.body.innerText += text;
    }
}

fetchStream();
```

### Python (httpx)

```python
import httpx

# 接收流式响应
async with httpx.AsyncClient() as client:
    async with client.stream('GET', 'http://localhost:8000/simple') as response:
        async for chunk in response.aiter_text():
            print(chunk, end='')  # 逐步输出
```

---

## 关键知识点

### 1. 异步生成器的定义

```python
async def generator() -> AsyncGenerator[str, None]:
    #     ↑                    ↑         ↑
    #  async def          yield 类型   send 类型
    yield "数据"
```

### 2. StreamingResponse 的参数

```python
StreamingResponse(
    content,           # 生成器函数
    media_type,        # MIME 类型
    status_code=200,   # HTTP 状态码
    headers=None       # 自定义响应头
)
```

### 3. 资源清理模式

```python
async def generator():
    resource = acquire_resource()
    try:
        yield data
    finally:
        release_resource(resource)  # 确保释放
```

### 4. 客户端断开处理

```python
async def generator():
    try:
        yield data
    except GeneratorExit:
        cleanup()  # 客户端断开时执行
```

---

## 常见问题

### Q1: 为什么推荐使用异步生成器？

**A:** 异步生成器不阻塞事件循环，支持高并发：
- 同步生成器：10个并发请求需要 50秒（串行）
- 异步生成器：10个并发请求需要 5秒（并行）

### Q2: 如何测试流式响应？

**A:** 使用 `curl` 或 `httpx`：
```bash
# curl 测试
curl http://localhost:8000/simple

# httpx 测试
python -c "import httpx; print(httpx.get('http://localhost:8000/simple').text)"
```

### Q3: 流式响应可以设置 Content-Length 吗？

**A:** 不能！流式响应使用 `Transfer-Encoding: chunked`，不知道总长度。

### Q4: 如何在流式响应中处理错误？

**A:** 在数据流中发送错误信息：
```python
async def generator():
    try:
        yield "数据"
    except Exception as e:
        yield f"错误: {e}"
```

---

## 下一步

完成本场景后，继续学习：
- **场景2**：Server-Sent Events (SSE) 实现
- **场景3**：AI 流式输出集成
- **场景4**：大文件流式传输
- **场景5**：生产级流式响应系统
