# 双重类比

> 用前端开发和日常生活的类比理解相似度度量

---

## 类比1：L2距离 = 地图上的直线距离

### 前端类比：Canvas坐标系中的距离

```javascript
// 前端：计算两个DOM元素的距离
function getElementDistance(elem1, elem2) {
    const rect1 = elem1.getBoundingClientRect();
    const rect2 = elem2.getBoundingClientRect();

    const dx = rect1.x - rect2.x;
    const dy = rect1.y - rect2.y;

    // L2距离 = 勾股定理
    return Math.sqrt(dx * dx + dy * dy);
}

// 两个按钮的位置
const button1 = { x: 100, y: 200 };
const button2 = { x: 400, y: 600 };

// 直线距离
const distance = Math.sqrt(
    (button1.x - button2.x) ** 2 +
    (button1.y - button2.y) ** 2
);
// 500像素
```

**对应关系：**
- DOM元素坐标 ↔ 向量
- 像素距离 ↔ L2距离
- 勾股定理 ↔ 欧氏距离公式

### 日常生活类比：两地之间的直线距离

**场景：** 你在北京，朋友在上海

```
北京坐标：(116.4, 39.9)
上海坐标：(121.5, 31.2)

直线距离 = √[(121.5-116.4)² + (31.2-39.9)²]
         ≈ 9.7 度（地理单位）
```

**特点：**
- ✅ 直观：就是"两点之间直线最短"
- ✅ 绝对：不管方向，只看距离
- ❌ 受幅度影响：北京到上海的距离 ≠ 北京到天津的距离

**Python对应：**
```python
import numpy as np

# 地理坐标
beijing = np.array([116.4, 39.9])
shanghai = np.array([121.5, 31.2])

# L2距离
distance = np.linalg.norm(beijing - shanghai)
print(f"直线距离: {distance:.2f}")  # 9.70
```

---

## 类比2：内积IP = 投影长度

### 前端类比：搜索引擎的相关性评分

```javascript
// 前端：计算搜索词与文档的相关性
function calculateRelevance(query, document) {
    // query: [关键词1权重, 关键词2权重, ...]
    // document: [关键词1出现次数, 关键词2出现次数, ...]

    let relevance = 0;
    for (let i = 0; i < query.length; i++) {
        // 内积 = 权重 × 出现次数
        relevance += query[i] * document[i];
    }
    return relevance;
}

// 查询："机器学习 教程"
const query = [0.8, 0.6];  // [机器学习权重, 教程权重]

// 文档1："机器学习入门教程"
const doc1 = [5, 3];  // [机器学习出现5次, 教程出现3次]

// 文档2："机器学习"
const doc2 = [10, 0];  // [机器学习出现10次, 教程出现0次]

// 相关性评分
const score1 = 0.8*5 + 0.6*3 = 5.8  // 文档1
const score2 = 0.8*10 + 0.6*0 = 8.0  // 文档2（更高）
```

**对应关系：**
- 查询权重 ↔ 查询向量
- 文档特征 ↔ 文档向量
- 相关性评分 ↔ 内积IP
- 评分越高越相关 ↔ IP越大越相似

### 日常生活类比：两个人的兴趣匹配度

**场景：** 约会App的匹配算法

```
你的兴趣强度：[运动:8, 音乐:6, 电影:4, 美食:9]
对方的兴趣强度：[运动:7, 音乐:8, 电影:3, 美食:10]

匹配度 = 8×7 + 6×8 + 4×3 + 9×10
       = 56 + 48 + 12 + 90
       = 206
```

**特点：**
- ✅ 考虑方向：兴趣方向一致
- ✅ 考虑强度：兴趣越强，匹配度越高
- ✅ 适合推荐：热门+匹配 = 高分

**Python对应：**
```python
import numpy as np

# 你的兴趣
you = np.array([8, 6, 4, 9])

# 对方的兴趣
partner = np.array([7, 8, 3, 10])

# 内积IP
match_score = np.dot(you, partner)
print(f"匹配度: {match_score}")  # 206
```

---

## 类比3：余弦相似度 = 方向一致性

### 前端类比：CSS渐变方向的相似度

```javascript
// 前端：比较两个渐变方向是否相似
function compareGradientDirection(angle1, angle2) {
    // 转换为向量
    const vec1 = [Math.cos(angle1), Math.sin(angle1)];
    const vec2 = [Math.cos(angle2), Math.sin(angle2)];

    // 余弦相似度 = 点积（向量已归一化）
    const cosine = vec1[0] * vec2[0] + vec1[1] * vec2[1];
    return cosine;
}

// 渐变1：45度
const gradient1 = 45 * Math.PI / 180;

// 渐变2：50度
const gradient2 = 50 * Math.PI / 180;

// 方向相似度
const similarity = compareGradientDirection(gradient1, gradient2);
// 0.996（非常相似）
```

**对应关系：**
- 渐变角度 ↔ 向量方向
- 方向差异 ↔ 余弦相似度
- 忽略渐变长度 ↔ 忽略向量幅度

### 日常生活类比：两个人的观点一致性

**场景：** 政治立场的相似度

```
你的立场：[经济:左7, 社会:右3]
朋友的立场：[经济:左14, 社会:右6]

注意：朋友的立场是你的2倍（幅度不同）

余弦相似度 = 只看方向，忽略强度
           = 1.0（完全一致）

L2距离 = 考虑幅度差异
       = √[(14-7)² + (6-3)²] = 7.6（有差异）
```

**特点：**
- ✅ 只看方向：观点方向一致就算相似
- ✅ 忽略强度：不管表达强烈程度
- ✅ 适合语义：语义相近 = 方向相近

**Python对应：**
```python
import numpy as np

# 你的立场
you = np.array([7, 3])

# 朋友的立场（2倍）
friend = np.array([14, 6])

# 余弦相似度
cosine = np.dot(you, friend) / (np.linalg.norm(you) * np.linalg.norm(friend))
print(f"观点一致性: {cosine:.4f}")  # 1.0000（完全一致）

# L2距离
l2 = np.linalg.norm(you - friend)
print(f"立场差异: {l2:.4f}")  # 7.6158（有差异）
```

---

## 类比4：归一化 = 标准化比较

### 前端类比：响应式设计的百分比布局

```javascript
// 前端：不同屏幕尺寸的布局比例
function normalizeLayout(width, height) {
    const total = Math.sqrt(width * width + height * height);
    return {
        widthRatio: width / total,
        heightRatio: height / total
    };
}

// 手机屏幕：375 × 667
const mobile = normalizeLayout(375, 667);
// { widthRatio: 0.49, heightRatio: 0.87 }

// 平板屏幕：768 × 1024（比例相同，尺寸不同）
const tablet = normalizeLayout(768, 1024);
// { widthRatio: 0.60, heightRatio: 0.80 }

// 归一化后，可以比较布局比例，忽略绝对尺寸
```

**对应关系：**
- 屏幕尺寸 ↔ 向量幅度
- 布局比例 ↔ 归一化向量
- 响应式设计 ↔ 忽略幅度的比较

### 日常生活类比：考试成绩的标准化

**场景：** 比较不同科目的成绩

```
数学：90分（满分100）
英语：135分（满分150）

直接比较：90 < 135（英语更好？）

标准化后：
数学：90/100 = 0.90
英语：135/150 = 0.90

结论：两科成绩相当（归一化后相同）
```

**特点：**
- ✅ 消除量纲：不同单位可以比较
- ✅ 公平比较：忽略绝对值，只看相对表现
- ✅ 适合语义：语义搜索不关心向量长度

**Python对应：**
```python
import numpy as np

# 原始成绩
math = np.array([90])
english = np.array([135])

# 归一化
math_norm = math / 100
english_norm = english / 150

print(f"数学（归一化）: {math_norm[0]:.2f}")  # 0.90
print(f"英语（归一化）: {english_norm[0]:.2f}")  # 0.90
```

---

## 类比5：度量选择 = 评价标准选择

### 前端类比：代码质量评估

```javascript
// 前端：评估两个组件的相似度

// 组件1
const component1 = {
    lines: 100,        // 代码行数
    complexity: 5,     // 复杂度
    performance: 8     // 性能评分
};

// 组件2
const component2 = {
    lines: 120,
    complexity: 6,
    performance: 9
};

// 评价标准1：L2距离（绝对差异）
const l2 = Math.sqrt(
    (100-120)**2 + (5-6)**2 + (8-9)**2
);
// 关注绝对值差异

// 评价标准2：加权评分（内积）
const weights = [0.3, 0.5, 0.2];  // [行数, 复杂度, 性能]
const score1 = 0.3*100 + 0.5*5 + 0.2*8;
const score2 = 0.3*120 + 0.5*6 + 0.2*9;
// 关注加权总分

// 评价标准3：结构相似度（余弦）
// 只看比例，不看绝对值
```

**对应关系：**
- 评价标准 ↔ 度量方式
- 不同标准得出不同结论 ↔ 不同度量得出不同排序

### 日常生活类比：选择餐厅的标准

**场景：** 找相似的餐厅

```
参考餐厅：[价格:50, 口味:9, 环境:8]

候选1：[价格:55, 口味:9, 环境:8]  # 价格略高
候选2：[价格:100, 口味:9, 环境:8]  # 价格高很多

L2距离：
- 候选1：√[(55-50)² + (9-9)² + (8-8)²] = 5
- 候选2：√[(100-50)² + (9-9)² + (8-8)²] = 50
结论：候选1更相似（价格接近）

余弦相似度：
- 候选1：0.998
- 候选2：0.996
结论：两者都很相似（口味和环境比例一致）

选择度量 = 选择你关注什么：
- 关注绝对价格 → L2
- 只关注口味和环境的比例 → COSINE
```

---

## 类比总结表

| 度量方式 | 前端类比 | 日常生活类比 | 核心特点 |
|---------|---------|-------------|---------|
| **L2距离** | Canvas元素距离 | 地图直线距离 | 绝对差异 |
| **内积IP** | 搜索相关性评分 | 兴趣匹配度 | 方向×强度 |
| **余弦COSINE** | 渐变方向相似度 | 观点一致性 | 纯方向 |
| **归一化** | 响应式布局比例 | 成绩标准化 | 消除量纲 |

---

## 记忆口诀

**L2像地图，测量直线距离**
**IP像评分，方向和强度都重要**
**COSINE像指南针，只看方向不看远近**
**归一化像百分比，消除绝对值差异**

---

## 实践练习

### 练习1：判断场景适合哪种度量

```python
# 场景A：文档语义搜索
# 问：用户搜索"机器学习"，找相似文档
# 答案：COSINE（只关注语义方向）

# 场景B：商品推荐
# 问：根据用户历史推荐商品
# 答案：IP（考虑热度和匹配度）

# 场景C：图像特征匹配
# 问：找相似的图片
# 答案：L2或COSINE（取决于特征提取方式）
```

### 练习2：类比理解

```
问题：为什么归一化向量用IP和COSINE效果一样？

类比：
就像比较两个学生的成绩：
- 学生A：数学90，英语90（总分180）
- 学生B：数学90，英语90（总分180）

归一化后：
- 学生A：数学0.5，英语0.5
- 学生B：数学0.5，英语0.5

内积IP = 0.5×0.5 + 0.5×0.5 = 0.5
余弦COSINE = 0.5（归一化后点积就是余弦）

结论：归一化后，IP = COSINE
```

---

**下一步：** [09_实战代码_场景1_L2距离实战.md](./09_实战代码_场景1_L2距离实战.md) - 动手实践
