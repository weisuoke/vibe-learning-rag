# 核心概念5：监控与告警集成

> Prometheus 指标暴露、日志记录、告警规则、可观测性三支柱

---

## 概述

健康检查不仅要判断服务是否可用，还要将健康状态暴露给监控系统，实现：
- **指标暴露**：Prometheus metrics
- **日志记录**：结构化日志
- **告警规则**：自动告警
- **可观测性**：日志、指标、追踪

---

## 1. Prometheus 指标暴露

### 1.1 为什么需要 Prometheus？

**健康检查 vs 监控系统：**

| 维度 | 健康检查 | Prometheus |
|------|---------|-----------|
| 目的 | 判断服务是否可用 | 监控服务状态趋势 |
| 频率 | 每 5-10 秒 | 每 15-60 秒 |
| 数据保留 | 不保留 | 长期保留 |
| 告警 | 不支持 | 支持复杂告警规则 |
| 可视化 | 不支持 | Grafana 可视化 |

**Prometheus 的优势：**
- 长期保留健康检查历史数据
- 分析健康趋势（成功率、响应时间）
- 设置复杂的告警规则
- 可视化健康状态

### 1.2 基础指标定义

```python
from prometheus_client import Counter, Histogram, Gauge, Info

# 1. Counter：健康检查总次数
health_check_total = Counter(
    'health_check_total',
    'Total number of health check requests',
    ['endpoint', 'status']  # 标签：端点、状态
)

# 2. Histogram：健康检查响应时间
health_check_duration_seconds = Histogram(
    'health_check_duration_seconds',
    'Health check duration in seconds',
    ['endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]  # 响应时间分桶
)

# 3. Gauge：依赖服务健康状态
dependency_health_status = Gauge(
    'dependency_health_status',
    'Dependency health status (1=healthy, 0=unhealthy)',
    ['service']  # 标签：服务名
)

# 4. Info：应用信息
app_info = Info(
    'app',
    'Application information'
)

# 设置应用信息
app_info.info({
    'version': '1.0.0',
    'environment': 'production'
})
```

### 1.3 完整实现

```python
from fastapi import FastAPI, HTTPException
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from starlette.responses import Response
import time

app = FastAPI()

# 定义指标
health_check_total = Counter(
    'health_check_total',
    'Total health check requests',
    ['endpoint', 'status']
)

health_check_duration_seconds = Histogram(
    'health_check_duration_seconds',
    'Health check duration',
    ['endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
)

dependency_health_status = Gauge(
    'dependency_health_status',
    'Dependency health status',
    ['service']
)

@app.get("/health")
async def health():
    """健康检查（带指标）"""
    start_time = time.time()

    try:
        # 执行健康检查
        result = {"status": "healthy"}

        # 记录成功
        health_check_total.labels(endpoint='health', status='success').inc()

        return result

    except Exception as e:
        # 记录失败
        health_check_total.labels(endpoint='health', status='failure').inc()
        raise

    finally:
        # 记录响应时间
        duration = time.time() - start_time
        health_check_duration_seconds.labels(endpoint='health').observe(duration)

@app.get("/ready")
async def ready():
    """就绪检查（带指标）"""
    start_time = time.time()

    try:
        # 检查依赖服务
        checks = {
            "database": await check_database(),
            "redis": await check_redis(),
            "llm_api": await check_llm_api(),
        }

        # 更新依赖状态指标
        for service, status in checks.items():
            dependency_health_status.labels(service=service).set(1 if status else 0)

        # 判断整体状态
        if not all(checks.values()):
            health_check_total.labels(endpoint='ready', status='failure').inc()
            raise HTTPException(503, detail=checks)

        health_check_total.labels(endpoint='ready', status='success').inc()
        return {"status": "ready", "checks": checks}

    finally:
        duration = time.time() - start_time
        health_check_duration_seconds.labels(endpoint='ready').observe(duration)

@app.get("/metrics")
async def metrics():
    """Prometheus 指标端点"""
    return Response(
        content=generate_latest(),
        media_type=CONTENT_TYPE_LATEST
    )
```

### 1.4 指标查询示例

**PromQL 查询：**

```promql
# 1. 健康检查成功率
rate(health_check_total{status="success"}[5m])
/
rate(health_check_total[5m])

# 2. 健康检查响应时间 P95
histogram_quantile(0.95,
  rate(health_check_duration_seconds_bucket[5m])
)

# 3. 依赖服务健康状态
dependency_health_status{service="database"}

# 4. 健康检查失败率
rate(health_check_total{status="failure"}[5m])
```

---

## 2. 日志记录最佳实践

### 2.1 结构化日志

**为什么需要结构化日志？**

```python
# ❌ 错误：非结构化日志
logger.info("Health check failed for database")

# ✅ 正确：结构化日志
logger.info(
    "Health check failed",
    extra={
        "service": "database",
        "endpoint": "/ready",
        "duration_ms": 150,
        "error": "Connection timeout"
    }
)
```

**优点：**
- 易于搜索和过滤
- 易于聚合和分析
- 易于集成到日志系统（ELK、Loki）

### 2.2 完整实现

```python
import structlog
import time

# 配置结构化日志
structlog.configure(
    processors=[
        structlog.stdlib.add_log_level,
        structlog.stdlib.add_logger_name,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()

async def check_database() -> bool:
    """检查数据库（带日志）"""
    start_time = time.time()

    try:
        await db.execute("SELECT 1")

        # 记录成功日志
        logger.info(
            "Database health check succeeded",
            service="database",
            duration_ms=int((time.time() - start_time) * 1000)
        )

        return True

    except Exception as e:
        # 记录失败日志
        logger.error(
            "Database health check failed",
            service="database",
            duration_ms=int((time.time() - start_time) * 1000),
            error=str(e),
            error_type=type(e).__name__
        )

        return False

@app.get("/ready")
async def ready():
    """就绪检查（带日志）"""
    start_time = time.time()

    try:
        checks = {
            "database": await check_database(),
            "redis": await check_redis(),
        }

        # 记录健康检查结果
        logger.info(
            "Health check completed",
            endpoint="/ready",
            duration_ms=int((time.time() - start_time) * 1000),
            checks=checks,
            status="ready" if all(checks.values()) else "not_ready"
        )

        if not all(checks.values()):
            raise HTTPException(503)

        return {"status": "ready", "checks": checks}

    except Exception as e:
        logger.error(
            "Health check failed",
            endpoint="/ready",
            duration_ms=int((time.time() - start_time) * 1000),
            error=str(e)
        )
        raise
```

### 2.3 日志级别

| 级别 | 使用场景 | 示例 |
|------|---------|------|
| DEBUG | 详细的调试信息 | 健康检查的详细步骤 |
| INFO | 正常的操作信息 | 健康检查成功 |
| WARNING | 警告信息 | 健康检查响应慢 |
| ERROR | 错误信息 | 健康检查失败 |
| CRITICAL | 严重错误 | 所有依赖服务都失败 |

---

## 3. 告警规则设计

### 3.1 Prometheus 告警规则

**告警规则文件（alerts.yml）：**

```yaml
groups:
  - name: health_check_alerts
    interval: 30s
    rules:
      # 1. 健康检查成功率低于 95%
      - alert: HealthCheckLowSuccessRate
        expr: |
          (
            rate(health_check_total{status="success"}[5m])
            /
            rate(health_check_total[5m])
          ) < 0.95
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Health check success rate is low"
          description: "Health check success rate is {{ $value | humanizePercentage }} (threshold: 95%)"

      # 2. 健康检查响应时间超过 1 秒
      - alert: HealthCheckSlow
        expr: |
          histogram_quantile(0.95,
            rate(health_check_duration_seconds_bucket[5m])
          ) > 1.0
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Health check is slow"
          description: "Health check P95 latency is {{ $value }}s (threshold: 1s)"

      # 3. 依赖服务不健康
      - alert: DependencyUnhealthy
        expr: dependency_health_status == 0
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Dependency {{ $labels.service }} is unhealthy"
          description: "Dependency {{ $labels.service }} has been unhealthy for 2 minutes"

      # 4. 健康检查完全失败
      - alert: HealthCheckDown
        expr: |
          rate(health_check_total{status="success"}[5m]) == 0
          and
          rate(health_check_total[5m]) > 0
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Health check is completely failing"
          description: "All health checks are failing for 1 minute"

      # 5. 数据库连接池接近容量
      - alert: DatabasePoolNearCapacity
        expr: database_pool_checked_out / database_pool_size > 0.9
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Database connection pool near capacity"
          description: "Database pool usage is {{ $value | humanizePercentage }}"
```

### 3.2 告警级别

| 级别 | 含义 | 响应时间 | 示例 |
|------|------|---------|------|
| critical | 严重故障 | 立即响应 | 所有健康检查失败 |
| warning | 警告 | 工作时间内响应 | 健康检查响应慢 |
| info | 信息 | 记录即可 | 健康检查成功率略低 |

### 3.3 告警通知

**Alertmanager 配置：**

```yaml
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'

  routes:
    # Critical 告警立即通知
    - match:
        severity: critical
      receiver: 'pagerduty'
      continue: true

    # Warning 告警发送到 Slack
    - match:
        severity: warning
      receiver: 'slack'

receivers:
  - name: 'default'
    email_configs:
      - to: 'team@example.com'

  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'your-pagerduty-key'

  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/xxx'
        channel: '#alerts'
        title: 'Health Check Alert'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

---

## 4. 健康趋势分析

### 4.1 Grafana 仪表板

**健康检查仪表板示例：**

```json
{
  "dashboard": {
    "title": "Health Check Dashboard",
    "panels": [
      {
        "title": "Health Check Success Rate",
        "targets": [
          {
            "expr": "rate(health_check_total{status=\"success\"}[5m]) / rate(health_check_total[5m])"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Health Check Latency (P95)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(health_check_duration_seconds_bucket[5m]))"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Dependency Health Status",
        "targets": [
          {
            "expr": "dependency_health_status"
          }
        ],
        "type": "stat"
      }
    ]
  }
}
```

### 4.2 关键指标

**1. 成功率（Success Rate）**

```promql
rate(health_check_total{status="success"}[5m])
/
rate(health_check_total[5m])
```

**目标：** > 99.9%

**2. 响应时间（Latency）**

```promql
# P50
histogram_quantile(0.50, rate(health_check_duration_seconds_bucket[5m]))

# P95
histogram_quantile(0.95, rate(health_check_duration_seconds_bucket[5m]))

# P99
histogram_quantile(0.99, rate(health_check_duration_seconds_bucket[5m]))
```

**目标：**
- P50 < 50ms
- P95 < 100ms
- P99 < 500ms

**3. 依赖服务可用性**

```promql
avg_over_time(dependency_health_status{service="database"}[5m])
```

**目标：** > 99.9%

---

## 5. 可观测性三支柱

### 5.1 日志（Logs）

**用途：** 记录健康检查的详细信息

```python
logger.info(
    "Health check completed",
    endpoint="/ready",
    duration_ms=150,
    checks={
        "database": True,
        "redis": False
    },
    status="degraded"
)
```

**查询示例（Loki）：**

```logql
{app="ai-agent-api"} |= "Health check" | json | status="degraded"
```

### 5.2 指标（Metrics）

**用途：** 监控健康检查的趋势

```python
health_check_total.labels(endpoint='ready', status='success').inc()
health_check_duration_seconds.labels(endpoint='ready').observe(0.15)
dependency_health_status.labels(service='redis').set(0)
```

**查询示例（Prometheus）：**

```promql
rate(health_check_total{status="failure"}[5m])
```

### 5.3 追踪（Traces）

**用途：** 追踪健康检查的执行路径

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

@app.get("/ready")
async def ready():
    with tracer.start_as_current_span("health_check"):
        with tracer.start_as_current_span("check_database"):
            db_status = await check_database()

        with tracer.start_as_current_span("check_redis"):
            redis_status = await check_redis()

        return {"status": "ready"}
```

**查询示例（Jaeger）：**

```
service=ai-agent-api operation=health_check duration>100ms
```

---

## 6. 监控工具集成

### 6.1 Prometheus + Grafana

**架构：**

```
AI Agent API
  ↓ (暴露 /metrics)
Prometheus
  ↓ (抓取指标)
Grafana
  ↓ (可视化)
用户
```

**Prometheus 配置：**

```yaml
scrape_configs:
  - job_name: 'ai-agent-api'
    scrape_interval: 15s
    static_configs:
      - targets: ['api1:8000', 'api2:8000', 'api3:8000']
```

### 6.2 ELK Stack（Elasticsearch + Logstash + Kibana）

**架构：**

```
AI Agent API
  ↓ (输出日志)
Logstash
  ↓ (解析日志)
Elasticsearch
  ↓ (存储日志)
Kibana
  ↓ (可视化)
用户
```

**Logstash 配置：**

```ruby
input {
  file {
    path => "/var/log/ai-agent-api/*.log"
    codec => json
  }
}

filter {
  if [service] == "database" and [error] {
    mutate {
      add_tag => ["database_error"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ai-agent-api-%{+YYYY.MM.dd}"
  }
}
```

### 6.3 Datadog

**集成示例：**

```python
from datadog import initialize, statsd

# 初始化 Datadog
initialize(
    api_key='your-api-key',
    app_key='your-app-key'
)

@app.get("/ready")
async def ready():
    start_time = time.time()

    try:
        checks = await check_all_dependencies()

        # 发送指标到 Datadog
        statsd.increment('health_check.success', tags=['endpoint:ready'])

        for service, status in checks.items():
            statsd.gauge(
                f'dependency.health.{service}',
                1 if status else 0
            )

        return {"status": "ready", "checks": checks}

    finally:
        duration = time.time() - start_time
        statsd.histogram('health_check.duration', duration, tags=['endpoint:ready'])
```

---

## 7. 在 AI Agent 后端中的应用

### 7.1 完整的监控系统

```python
from fastapi import FastAPI, HTTPException
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from starlette.responses import Response
import structlog
import time

app = FastAPI()

# 配置日志
structlog.configure(
    processors=[
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ]
)
logger = structlog.get_logger()

# 定义指标
health_check_total = Counter(
    'health_check_total',
    'Total health check requests',
    ['endpoint', 'status']
)

health_check_duration_seconds = Histogram(
    'health_check_duration_seconds',
    'Health check duration',
    ['endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
)

dependency_health_status = Gauge(
    'dependency_health_status',
    'Dependency health status',
    ['service']
)

# 健康检查缓存
health_cache = {"last_check": 0, "checks": {}}

async def check_database() -> bool:
    """检查数据库"""
    start_time = time.time()

    try:
        await db.execute("SELECT 1")

        logger.info(
            "Database health check succeeded",
            service="database",
            duration_ms=int((time.time() - start_time) * 1000)
        )

        return True

    except Exception as e:
        logger.error(
            "Database health check failed",
            service="database",
            duration_ms=int((time.time() - start_time) * 1000),
            error=str(e)
        )

        return False

@app.get("/health")
async def health():
    """Liveness 检查"""
    start_time = time.time()

    try:
        health_check_total.labels(endpoint='health', status='success').inc()
        return {"status": "healthy"}

    finally:
        duration = time.time() - start_time
        health_check_duration_seconds.labels(endpoint='health').observe(duration)

@app.get("/ready")
async def ready():
    """Readiness 检查（带监控）"""
    start_time = time.time()

    try:
        # 使用缓存
        now = time.time()
        if now - health_cache["last_check"] < 30:
            checks = health_cache["checks"]
        else:
            checks = {
                "database": await check_database(),
                "redis": await check_redis(),
                "llm_api": await check_llm_api(),
            }
            health_cache.update({
                "last_check": now,
                "checks": checks
            })

        # 更新依赖状态指标
        for service, status in checks.items():
            dependency_health_status.labels(service=service).set(1 if status else 0)

        # 判断整体状态
        if not checks["database"]:
            health_check_total.labels(endpoint='ready', status='failure').inc()

            logger.error(
                "Health check failed",
                endpoint="/ready",
                duration_ms=int((time.time() - start_time) * 1000),
                checks=checks
            )

            raise HTTPException(503, "Database unavailable")

        # 可选依赖失败 → 降级
        if not checks["llm_api"]:
            health_check_total.labels(endpoint='ready', status='degraded').inc()

            logger.warning(
                "Health check degraded",
                endpoint="/ready",
                duration_ms=int((time.time() - start_time) * 1000),
                checks=checks
            )

            return {
                "status": "degraded",
                "message": "LLM API unavailable",
                "checks": checks
            }

        health_check_total.labels(endpoint='ready', status='success').inc()

        logger.info(
            "Health check succeeded",
            endpoint="/ready",
            duration_ms=int((time.time() - start_time) * 1000),
            checks=checks
        )

        return {"status": "healthy", "checks": checks}

    finally:
        duration = time.time() - start_time
        health_check_duration_seconds.labels(endpoint='ready').observe(duration)

@app.get("/metrics")
async def metrics():
    """Prometheus 指标端点"""
    return Response(
        content=generate_latest(),
        media_type=CONTENT_TYPE_LATEST
    )
```

### 7.2 告警规则

```yaml
groups:
  - name: ai_agent_health
    rules:
      # LLM API 不健康
      - alert: LLMAPIUnhealthy
        expr: dependency_health_status{service="llm_api"} == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "LLM API is unhealthy"

      # 数据库不健康
      - alert: DatabaseUnhealthy
        expr: dependency_health_status{service="database"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Database is unhealthy"

      # 健康检查响应慢
      - alert: HealthCheckSlow
        expr: |
          histogram_quantile(0.95,
            rate(health_check_duration_seconds_bucket{endpoint="ready"}[5m])
          ) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Health check is slow"
```

---

## 总结

监控与告警集成的关键要点：

1. **Prometheus 指标**：暴露健康检查指标（成功率、响应时间、依赖状态）
2. **结构化日志**：记录健康检查的详细信息
3. **告警规则**：设置合理的告警阈值和级别
4. **健康趋势**：使用 Grafana 可视化健康状态
5. **可观测性**：结合日志、指标、追踪
6. **工具集成**：Prometheus、Grafana、ELK、Datadog
7. **AI Agent 特定**：监控 LLM API、向量数据库、Embedding 模型

在 AI Agent 后端中，完善的监控与告警系统可以：
- 快速发现健康问题
- 分析健康趋势
- 自动告警通知
- 提高系统可靠性
