# 化骨绵掌：10个2分钟速记卡片

## 使用说明

**化骨绵掌 = 快速记忆卡片**

每个卡片2分钟，10个卡片20分钟，快速掌握结构化日志的核心知识。

**适用场景：**
- 面试前快速复习
- 项目开始前快速上手
- 知识点查漏补缺

---

## 卡片1：结构化日志本质（2分钟）

### 一句话

**结构化日志 = 把日志从"文本"变成"数据"**

### 核心对比

```python
# 传统日志（文本）
print("User john logged in")

# 结构化日志（数据）
logger.info("user_login", user="john")
```

### 输出对比

```
# 传统
User john logged in

# 结构化
{"event": "user_login", "user": "john", "timestamp": "2024-01-15T10:30:45Z"}
```

### 核心价值

| 维度 | 传统日志 | 结构化日志 |
|------|---------|-----------|
| 查询 | 正则表达式 | 字段查询 |
| 统计 | 手写脚本 | SQL/聚合 |
| 速度 | 慢 | 快 |

### 记忆点

**传统日志 = Word文档**（人类可读，机器难处理）
**结构化日志 = Excel表格**（机器可处理，人类通过工具查看）

---

## 卡片2：日志级别（2分钟）

### 5个标准级别

| 级别 | 用途 | 生产环境 |
|------|------|----------|
| DEBUG | 详细调试 | ❌ |
| INFO | 关键操作 | ✅ |
| WARNING | 潜在问题 | ✅ |
| ERROR | 可恢复错误 | ✅ |
| CRITICAL | 严重错误 | ✅ |

### 决策树

```
需要记录？
├─ 关键操作（登录、API调用）→ INFO
├─ 调试信息（变量值）→ DEBUG
├─ 潜在问题（重试）→ WARNING
├─ 可恢复错误 → ERROR
└─ 严重错误（系统崩溃）→ CRITICAL
```

### 环境配置

```python
# 开发环境
logger.setLevel("DEBUG")

# 生产环境
logger.setLevel("INFO")
```

### 记忆点

**生产环境用INFO，不用DEBUG**（避免日志爆炸）

---

## 卡片3：请求ID（2分钟）

### 核心概念

**请求ID = 每个HTTP请求的唯一标识符**

### 为什么需要

```
一个请求 → 多条日志
用户请求 → RAG检索 → LLM调用 → 返回结果
   ↓          ↓         ↓         ↓
 日志1      日志2      日志3     日志4
```

**问题：** 如何关联这4条日志？
**解决：** 所有日志都带上同一个请求ID

### 实现方式

```python
import uuid

# 生成请求ID
request_id = str(uuid.uuid4())

# 绑定到日志上下文
structlog.contextvars.bind_contextvars(request_id=request_id)

# 所有日志自动包含
logger.info("event1")  # 自动包含request_id
logger.info("event2")  # 自动包含request_id
```

### 记忆点

**请求ID = 快递单号**（追踪整个流程）

---

## 卡片4：上下文绑定（2分钟）

### 核心概念

**上下文绑定 = 信息绑定一次，后续自动包含**

### 对比

```python
# ❌ 繁琐：每次都传
logger.info("event1", request_id=rid, user_id=uid)
logger.info("event2", request_id=rid, user_id=uid)

# ✅ 简洁：绑定一次
structlog.contextvars.bind_contextvars(
    request_id=rid,
    user_id=uid
)
logger.info("event1")  # 自动包含
logger.info("event2")  # 自动包含
```

### 关键API

```python
# 绑定
structlog.contextvars.bind_contextvars(key=value)

# 清理
structlog.contextvars.clear_contextvars()

# 获取
context = structlog.contextvars.get_contextvars()
```

### 记忆点

**上下文绑定 = 对话上下文**（说一次，后续自动知道）

---

## 卡片5：structlog配置（2分钟）

### 最小配置

```python
import structlog

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,  # 合并上下文
        structlog.processors.add_log_level,        # 添加级别
        structlog.processors.TimeStamper(fmt="iso"),  # 时间戳
        structlog.processors.JSONRenderer()        # JSON输出
    ]
)

logger = structlog.get_logger()
```

### 核心处理器

| 处理器 | 作用 |
|--------|------|
| merge_contextvars | 合并上下文变量 |
| add_log_level | 添加日志级别 |
| TimeStamper | 添加时间戳 |
| JSONRenderer | JSON格式输出 |
| ConsoleRenderer | 人类可读输出（开发环境） |

### 环境切换

```python
import sys

if sys.stdout.isatty():  # 开发环境
    renderer = structlog.dev.ConsoleRenderer()
else:  # 生产环境
    renderer = structlog.processors.JSONRenderer()
```

### 记忆点

**4个核心处理器：上下文、级别、时间、格式**

---

## 卡片6：FastAPI中间件（2分钟）

### 完整实现

```python
import uuid
from fastapi import FastAPI, Request
import structlog

app = FastAPI()
logger = structlog.get_logger()

@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    # 1. 生成请求ID
    request_id = str(uuid.uuid4())

    # 2. 绑定上下文
    structlog.contextvars.bind_contextvars(
        request_id=request_id,
        method=request.method,
        path=request.url.path
    )

    # 3. 记录开始
    logger.info("request_start")

    # 4. 处理请求
    response = await call_next(request)

    # 5. 记录结束
    logger.info("request_end", status=response.status_code)

    # 6. 返回请求ID
    response.headers["X-Request-ID"] = request_id

    # 7. 清理上下文
    structlog.contextvars.clear_contextvars()

    return response
```

### 7个关键步骤

1. 生成请求ID
2. 绑定上下文
3. 记录开始
4. 处理请求
5. 记录结束
6. 返回请求ID
7. 清理上下文

### 记忆点

**中间件 = 请求的拦截器**（在处理前后加日志）

---

## 卡片7：LLM调用日志（2分钟）

### 必记录字段

```python
import time
from openai import OpenAI

client = OpenAI()
logger = structlog.get_logger()

async def call_llm(prompt: str, model: str = "gpt-4"):
    start = time.time()

    logger.info("llm_call_start",
        model=model,
        prompt_length=len(prompt)
    )

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}]
        )

        duration_ms = (time.time() - start) * 1000

        logger.info("llm_call_success",
            model=model,
            tokens=response.usage.total_tokens,  # ← 关键
            duration_ms=duration_ms,              # ← 关键
            response_length=len(response.choices[0].message.content)
        )

        return response.choices[0].message.content

    except Exception as e:
        logger.error("llm_call_failed",
            model=model,
            error=str(e),
            duration_ms=(time.time() - start) * 1000
        )
        raise
```

### 4个关键指标

1. **model**：使用的模型
2. **tokens**：Token消耗
3. **duration_ms**：耗时
4. **status**：成功/失败

### 记忆点

**LLM日志 = 记录成本和性能**

---

## 卡片8：RAG检索日志（2分钟）

### 必记录字段

```python
async def rag_search(query: str, k: int = 5):
    start = time.time()

    logger.info("rag_search_start",
        query=query,
        k=k
    )

    # 向量检索
    results = vector_store.similarity_search(query, k=k)

    duration_ms = (time.time() - start) * 1000

    logger.info("rag_search_success",
        query=query,
        results_count=len(results),        # ← 关键
        top_score=results[0].metadata.get("score", 0),  # ← 关键
        duration_ms=duration_ms             # ← 关键
    )

    return results
```

### 4个关键指标

1. **query**：查询内容
2. **results_count**：结果数量
3. **top_score**：最高相似度
4. **duration_ms**：耗时

### 记忆点

**RAG日志 = 记录检索质量**

---

## 卡片9：敏感信息处理（2分钟）

### 绝对不要记录

```python
# ❌ 错误
logger.info("api_call", api_key=api_key)
logger.info("user_login", password=password)
logger.info("llm_call", prompt=full_prompt)  # 可能包含隐私
```

### 正确做法

```python
# ✅ 正确：脱敏
logger.info("api_call", api_key_prefix=api_key[:8] + "...")
logger.info("user_login", username=username)  # 不记录密码
logger.info("llm_call", prompt_length=len(prompt))  # 只记录长度
```

### 自动脱敏

```python
def mask_sensitive(logger, method, event_dict):
    """自动脱敏处理器"""
    sensitive_keys = ["password", "api_key", "token", "secret"]

    for key in sensitive_keys:
        if key in event_dict:
            event_dict[key] = "***REDACTED***"

    return event_dict

structlog.configure(
    processors=[
        mask_sensitive,  # 添加脱敏处理器
        structlog.processors.JSONRenderer()
    ]
)
```

### 记忆点

**敏感信息 = 绝对不记录**（安全 > 调试）

---

## 卡片10：日志查询（2分钟）

### jq基础查询

```bash
# 查询特定请求
jq 'select(.request_id == "req_abc")' app.log

# 查询特定事件
jq 'select(.event == "llm_call")' app.log

# 查询错误
jq 'select(.level == "error")' app.log

# 查询慢请求
jq 'select(.duration_ms > 1000)' app.log
```

### 统计分析

```bash
# 统计事件数量
jq -s 'group_by(.event) | map({event: .[0].event, count: length})' app.log

# 计算平均耗时
jq -s 'map(select(.event == "llm_call")) | map(.duration_ms) | add / length' app.log

# 统计Token消耗
jq -s 'map(select(.event == "llm_call")) | map(.tokens) | add' app.log
```

### Python查询

```python
import json

# 读取日志
with open("app.log") as f:
    logs = [json.loads(line) for line in f]

# 查询特定请求
request_logs = [log for log in logs if log.get("request_id") == "req_abc"]

# 统计平均耗时
llm_logs = [log for log in logs if log.get("event") == "llm_call"]
avg_duration = sum(log["duration_ms"] for log in llm_logs) / len(llm_logs)
```

### 记忆点

**jq = 日志的SQL**（查询、过滤、聚合）

---

## 快速复习清单

### 核心概念（5个）

- [ ] 结构化日志 = 数据化的日志
- [ ] 日志级别：生产用INFO
- [ ] 请求ID：追踪请求链路
- [ ] 上下文绑定：自动传递信息
- [ ] 敏感信息：绝对不记录

### 核心API（5个）

```python
# 1. 配置
structlog.configure(processors=[...])

# 2. 获取logger
logger = structlog.get_logger()

# 3. 记录日志
logger.info("event", key=value)

# 4. 绑定上下文
structlog.contextvars.bind_contextvars(key=value)

# 5. 清理上下文
structlog.contextvars.clear_contextvars()
```

### 核心模式（3个）

**1. FastAPI中间件**
```python
@app.middleware("http")
async def logging_middleware(request, call_next):
    request_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(request_id=request_id)
    response = await call_next(request)
    structlog.contextvars.clear_contextvars()
    return response
```

**2. LLM调用日志**
```python
logger.info("llm_call", model=model, tokens=tokens, duration_ms=duration)
```

**3. 错误日志**
```python
try:
    # ...
except Exception as e:
    logger.error("operation_failed", error=str(e), stack_trace=traceback.format_exc())
```

---

## 20分钟学习路径

### 前5分钟：理解概念

- 卡片1：结构化日志本质
- 卡片2：日志级别
- 卡片3：请求ID

### 中间10分钟：实战代码

- 卡片5：structlog配置
- 卡片6：FastAPI中间件
- 卡片7：LLM调用日志
- 卡片8：RAG检索日志

### 后5分钟：进阶技巧

- 卡片4：上下文绑定
- 卡片9：敏感信息处理
- 卡片10：日志查询

---

## 面试前5分钟速记

### 必背3句话

1. **结构化日志是将日志以键值对格式记录，便于机器解析和查询**
2. **通过请求ID关联一个请求的所有日志，实现完整链路追踪**
3. **生产环境用INFO级别，避免DEBUG导致的日志爆炸**

### 必会1段代码

```python
import uuid
from fastapi import FastAPI, Request
import structlog

app = FastAPI()
logger = structlog.get_logger()

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.JSONRenderer()
    ]
)

@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    request_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(request_id=request_id)
    logger.info("request_start", path=request.url.path)
    response = await call_next(request)
    logger.info("request_end", status=response.status_code)
    structlog.contextvars.clear_contextvars()
    return response
```

### 必答3个问题

1. **什么是结构化日志？** → 键值对格式的日志，机器可解析
2. **如何实现请求追踪？** → 中间件生成请求ID，contextvars绑定
3. **如何处理敏感信息？** → 绝对不记录，或脱敏处理

---

## 总结

**10个卡片 = 结构化日志的完整知识体系**

**记忆口诀：**
- **数据化**：日志是数据，不是文本
- **有ID**：请求ID是标配
- **绑上下文**：信息自动传递
- **INFO级**：生产环境不用DEBUG
- **记关键**：只记录关键信息
- **不记密**：敏感信息绝对不记录
- **用jq查**：jq是日志的SQL

**下一步：**
- 实际项目中应用
- 查看【实战代码】获取完整示例
- 查看【面试必问】准备面试

**记住：** 这10个卡片是结构化日志的核心知识，掌握它们就能在实际项目中使用。
