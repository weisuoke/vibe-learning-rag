# 核心概念 03：认证与模型命令

> 深入理解 Pi 的认证机制和模型切换系统

---

## 概念定义

**Pi 支持两种认证方式（OAuth 订阅登录 + API 密钥）和动态模型切换（15+ Provider），通过统一的 pi-ai 抽象层实现无缝切换。**

---

## 认证系统

### 认证方式 1：OAuth 订阅登录

**原理：** 通过浏览器 OAuth 流程登录 Anthropic/OpenAI 账号，使用订阅额度。

```typescript
// OAuth 认证流程
class OAuthAuthenticator {
  async login(provider: 'anthropic' | 'openai'): Promise<void> {
    // 1. 生成认证 URL
    const authUrl = this.generateAuthUrl(provider);
    // https://auth.anthropic.com/oauth/authorize?client_id=...

    // 2. 打开浏览器
    await open(authUrl);

    // 3. 启动本地服务器接收回调
    const server = http.createServer(async (req, res) => {
      const url = new URL(req.url!, `http://localhost:${port}`);

      if (url.pathname === '/callback') {
        // 4. 提取授权码
        const code = url.searchParams.get('code');

        // 5. 交换访问令牌
        const tokens = await this.exchangeToken(code);

        // 6. 保存令牌
        await this.saveTokens(tokens);

        res.end('Authentication successful! You can close this window.');
        server.close();
      }
    });

    server.listen(port);
  }

  private async exchangeToken(code: string): Promise<Tokens> {
    const response = await fetch('https://auth.anthropic.com/oauth/token', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        grant_type: 'authorization_code',
        code: code,
        client_id: this.clientId,
        client_secret: this.clientSecret,
        redirect_uri: this.redirectUri
      })
    });

    return response.json();
  }

  private async saveTokens(tokens: Tokens): Promise<void> {
    // 保存到 ~/.pi/auth.json
    const authFile = path.join(os.homedir(), '.pi', 'auth.json');
    await fs.writeFile(authFile, JSON.stringify(tokens, null, 2));
  }
}
```

**使用流程：**
```bash
# 1. 启动 pi
$ pi

# 2. 执行登录命令
> /login

# 3. 浏览器自动打开认证页面
Opening browser for authentication...

# 4. 在浏览器中登录并授权
[浏览器] Anthropic Login
Email: your@email.com
Password: ********
[Authorize] [Cancel]

# 5. 认证成功
Authentication successful!
Logged in as: your@email.com
```

**令牌管理：**
```typescript
// 令牌存储结构
interface Tokens {
  access_token: string;
  refresh_token: string;
  expires_at: number;  // Unix timestamp
  provider: string;
}

// 令牌刷新
class TokenManager {
  async getValidToken(): Promise<string> {
    const tokens = await this.loadTokens();

    // 检查是否过期
    if (Date.now() >= tokens.expires_at) {
      // 刷新令牌
      const newTokens = await this.refreshToken(tokens.refresh_token);
      await this.saveTokens(newTokens);
      return newTokens.access_token;
    }

    return tokens.access_token;
  }

  private async refreshToken(refreshToken: string): Promise<Tokens> {
    const response = await fetch('https://auth.anthropic.com/oauth/token', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        grant_type: 'refresh_token',
        refresh_token: refreshToken,
        client_id: this.clientId,
        client_secret: this.clientSecret
      })
    });

    return response.json();
  }
}
```

---

### 认证方式 2：API 密钥

**原理：** 使用环境变量或配置文件提供 API 密钥。

```typescript
// API 密钥认证
class APIKeyAuthenticator {
  getAPIKey(provider: string): string | undefined {
    // 1. 从环境变量读取
    const envKey = this.getEnvKey(provider);
    if (envKey) {
      return envKey;
    }

    // 2. 从配置文件读取
    const configKey = this.getConfigKey(provider);
    if (configKey) {
      return configKey;
    }

    return undefined;
  }

  private getEnvKey(provider: string): string | undefined {
    const envVarMap: Record<string, string> = {
      anthropic: 'ANTHROPIC_API_KEY',
      openai: 'OPENAI_API_KEY',
      google: 'GOOGLE_API_KEY',
      github: 'GITHUB_TOKEN',
      deepseek: 'DEEPSEEK_API_KEY',
    };

    const envVar = envVarMap[provider];
    return process.env[envVar];
  }

  private getConfigKey(provider: string): string | undefined {
    // 从 ~/.pi/config.json 读取
    const configFile = path.join(os.homedir(), '.pi', 'config.json');
    if (!fs.existsSync(configFile)) {
      return undefined;
    }

    const config = JSON.parse(fs.readFileSync(configFile, 'utf-8'));
    return config.apiKeys?.[provider];
  }
}
```

**配置方式：**

```bash
# 方式 1：环境变量
export ANTHROPIC_API_KEY=sk-ant-...
export OPENAI_API_KEY=sk-...

# 方式 2：配置文件
cat > ~/.pi/config.json << 'EOF'
{
  "apiKeys": {
    "anthropic": "sk-ant-...",
    "openai": "sk-...",
    "google": "..."
  }
}
EOF

# 方式 3：项目配置
cat > .pi/settings.json << 'EOF'
{
  "provider": "anthropic",
  "apiKey": "${ANTHROPIC_API_KEY}"
}
EOF
```

---

### 认证优先级

```typescript
// 认证优先级
class AuthenticationManager {
  async authenticate(provider: string): Promise<string> {
    // 1. OAuth 令牌（最高优先级）
    const oauthToken = await this.getOAuthToken(provider);
    if (oauthToken) {
      return oauthToken;
    }

    // 2. 项目配置文件
    const projectKey = this.getProjectAPIKey(provider);
    if (projectKey) {
      return projectKey;
    }

    // 3. 全局配置文件
    const globalKey = this.getGlobalAPIKey(provider);
    if (globalKey) {
      return globalKey;
    }

    // 4. 环境变量
    const envKey = this.getEnvAPIKey(provider);
    if (envKey) {
      return envKey;
    }

    throw new Error(`No authentication found for provider: ${provider}`);
  }
}
```

---

## 模型切换系统

### 命令 1：/model - 切换模型

**语法：**
```bash
# 打开模型选择器
/model

# 直接切换到指定模型
/model claude-opus-4
/model gpt-4o
/model gemini-pro
```

**实现原理：**
```typescript
// 模型切换
class ModelSwitcher {
  private currentModel: string = 'claude-opus-4';
  private availableModels: Model[] = [];

  async switchModel(modelId?: string): Promise<void> {
    if (!modelId) {
      // 打开交互式选择器
      modelId = await this.showModelSelector();
    }

    // 验证模型是否可用
    const model = this.availableModels.find(m => m.id === modelId);
    if (!model) {
      throw new Error(`Model not found: ${modelId}`);
    }

    // 切换模型
    this.currentModel = modelId;

    // 更新 LLM 客户端
    await this.updateLLMClient(model);

    console.log(`Switched to ${model.name}`);
  }

  private async showModelSelector(): Promise<string> {
    // 显示交互式选择器
    const choices = this.availableModels.map(m => ({
      name: `${m.name} (${m.provider})`,
      value: m.id,
      description: `Context: ${m.contextWindow}K | Cost: $${m.costPer1M}/1M tokens`
    }));

    const answer = await inquirer.prompt([{
      type: 'list',
      name: 'model',
      message: 'Select a model:',
      choices: choices
    }]);

    return answer.model;
  }

  private async updateLLMClient(model: Model): Promise<void> {
    // 获取 Provider 适配器
    const adapter = this.getProviderAdapter(model.provider);

    // 创建新的 LLM 客户端
    this.llmClient = adapter.createClient({
      model: model.id,
      apiKey: await this.getAPIKey(model.provider)
    });
  }
}
```

---

### 命令 2：/scoped-models - 配置快速切换模型

**语法：**
```bash
# 配置 Scoped models
/scoped-models claude-opus-4 claude-sonnet-4 claude-haiku-4

# 使用快捷键循环切换
Ctrl+P  # 向前循环
Shift+Ctrl+P  # 向后循环
```

**实现原理：**
```typescript
// Scoped models 管理
class ScopedModelsManager {
  private scopedModels: string[] = [];
  private currentIndex: number = 0;

  setScopedModels(models: string[]): void {
    // 验证所有模型都可用
    for (const modelId of models) {
      const model = this.findModel(modelId);
      if (!model) {
        throw new Error(`Model not found: ${modelId}`);
      }
    }

    this.scopedModels = models;
    this.currentIndex = 0;

    // 保存到配置
    this.saveToConfig();
  }

  cycleForward(): string {
    if (this.scopedModels.length === 0) {
      throw new Error('No scoped models configured');
    }

    this.currentIndex = (this.currentIndex + 1) % this.scopedModels.length;
    return this.scopedModels[this.currentIndex];
  }

  cycleBackward(): string {
    if (this.scopedModels.length === 0) {
      throw new Error('No scoped models configured');
    }

    this.currentIndex = (this.currentIndex - 1 + this.scopedModels.length) % this.scopedModels.length;
    return this.scopedModels[this.currentIndex];
  }

  private saveToConfig(): void {
    const config = {
      scopedModels: this.scopedModels
    };

    fs.writeFileSync(
      path.join(os.homedir(), '.pi', 'scoped-models.json'),
      JSON.stringify(config, null, 2)
    );
  }
}
```

**使用场景：**
```typescript
// 场景 1：成本优化
const costOptimized = [
  'claude-haiku-4',    // 快速、便宜
  'claude-sonnet-4',   // 平衡
  'claude-opus-4'      // 强大、昂贵
];

// 场景 2：多 Provider 对比
const multiProvider = [
  'claude-opus-4',     // Anthropic
  'gpt-4o',            // OpenAI
  'gemini-pro'         // Google
];

// 场景 3：任务特定
const taskSpecific = [
  'claude-opus-4',     // 复杂推理
  'claude-haiku-4',    // 简单任务
  'gpt-4o'             // 代码生成
];
```

---

## 支持的 Provider 和模型

### Provider 列表（15+）

```typescript
// 支持的 Provider
const SUPPORTED_PROVIDERS = {
  // 主流 Provider
  anthropic: {
    name: 'Anthropic',
    models: ['claude-opus-4', 'claude-sonnet-4', 'claude-haiku-4'],
    auth: ['oauth', 'api_key']
  },

  openai: {
    name: 'OpenAI',
    models: ['gpt-4o', 'gpt-4', 'gpt-3.5-turbo'],
    auth: ['oauth', 'api_key']
  },

  google: {
    name: 'Google',
    models: ['gemini-pro', 'gemini-flash'],
    auth: ['api_key']
  },

  github: {
    name: 'GitHub Copilot',
    models: ['copilot-gpt-4', 'copilot-gpt-3.5'],
    auth: ['oauth']
  },

  // 开源 Provider
  deepseek: {
    name: 'DeepSeek',
    models: ['deepseek-chat', 'deepseek-coder'],
    auth: ['api_key']
  },

  qwen: {
    name: 'Qwen',
    models: ['qwen-turbo', 'qwen-plus'],
    auth: ['api_key']
  },

  mistral: {
    name: 'Mistral',
    models: ['mistral-large', 'mistral-medium'],
    auth: ['api_key']
  },

  // 本地 Provider
  ollama: {
    name: 'Ollama',
    models: ['llama2', 'codellama', 'mistral'],
    auth: []
  },

  // 自定义 Provider
  custom: {
    name: 'Custom',
    models: [],  // 通过 models.json 配置
    auth: ['api_key']
  }
};
```

---

### 模型信息

```typescript
// 模型详细信息
interface ModelInfo {
  id: string;
  name: string;
  provider: string;
  contextWindow: number;      // 上下文窗口（tokens）
  maxOutputTokens: number;    // 最大输出（tokens）
  costPer1M: {
    input: number;            // 输入成本（$/1M tokens）
    output: number;           // 输出成本（$/1M tokens）
  };
  capabilities: string[];     // 能力列表
}

// 示例：Claude Opus 4
const claudeOpus4: ModelInfo = {
  id: 'claude-opus-4',
  name: 'Claude Opus 4',
  provider: 'anthropic',
  contextWindow: 200000,
  maxOutputTokens: 4096,
  costPer1M: {
    input: 15,
    output: 75
  },
  capabilities: [
    'text',
    'vision',
    'tool_use',
    'thinking'
  ]
};

// 示例：GPT-4o
const gpt4o: ModelInfo = {
  id: 'gpt-4o',
  name: 'GPT-4o',
  provider: 'openai',
  contextWindow: 128000,
  maxOutputTokens: 4096,
  costPer1M: {
    input: 5,
    output: 15
  },
  capabilities: [
    'text',
    'vision',
    'tool_use'
  ]
};
```

---

## 自定义 Provider 配置

### 配置文件：models.json

```typescript
// ~/.pi/models.json
{
  "providers": {
    "my-custom-llm": {
      "name": "My Custom LLM",
      "baseURL": "https://my-llm-api.com/v1",
      "apiKey": "${MY_LLM_API_KEY}",
      "models": {
        "my-model-1": {
          "id": "my-model-1",
          "name": "My Model 1",
          "contextWindow": 128000,
          "maxOutputTokens": 4096,
          "costPer1M": {
            "input": 1,
            "output": 3
          }
        },
        "my-model-2": {
          "id": "my-model-2",
          "name": "My Model 2",
          "contextWindow": 200000,
          "maxOutputTokens": 8192,
          "costPer1M": {
            "input": 2,
            "output": 6
          }
        }
      }
    }
  }
}
```

---

### 加载自定义 Provider

```typescript
// 自定义 Provider 加载器
class CustomProviderLoader {
  async loadCustomProviders(): Promise<Provider[]> {
    const modelsFile = path.join(os.homedir(), '.pi', 'models.json');

    if (!fs.existsSync(modelsFile)) {
      return [];
    }

    const config = JSON.parse(fs.readFileSync(modelsFile, 'utf-8'));
    const providers: Provider[] = [];

    for (const [providerId, providerConfig] of Object.entries(config.providers)) {
      const provider = this.createProvider(providerId, providerConfig);
      providers.push(provider);
    }

    return providers;
  }

  private createProvider(id: string, config: any): Provider {
    return {
      id: id,
      name: config.name,
      baseURL: config.baseURL,
      apiKey: this.resolveAPIKey(config.apiKey),
      models: Object.values(config.models),
      adapter: new OpenAICompatibleAdapter(config.baseURL)
    };
  }

  private resolveAPIKey(apiKey: string): string {
    // 支持环境变量引用
    if (apiKey.startsWith('${') && apiKey.endsWith('}')) {
      const envVar = apiKey.slice(2, -1);
      return process.env[envVar] || '';
    }

    return apiKey;
  }
}
```

---

## 实际应用场景

### 场景 1：成本优化

```typescript
// 根据任务复杂度选择模型
async function selectModelByComplexity(task: string): Promise<string> {
  const complexity = analyzeComplexity(task);

  if (complexity === 'simple') {
    // 简单任务：使用 Haiku（快速、便宜）
    return 'claude-haiku-4';
  } else if (complexity === 'medium') {
    // 中等任务：使用 Sonnet（平衡）
    return 'claude-sonnet-4';
  } else {
    // 复杂任务：使用 Opus（强大）
    return 'claude-opus-4';
  }
}

// 示例
const tasks = [
  { task: '写一个计算两数之和的函数', model: 'claude-haiku-4' },
  { task: '审查这个文件的代码质量', model: 'claude-sonnet-4' },
  { task: '设计一个分布式系统架构', model: 'claude-opus-4' }
];
```

---

### 场景 2：多模型对比

```bash
# 配置多个模型
/scoped-models claude-opus-4 gpt-4o gemini-pro

# 对同一个问题使用不同模型
请设计一个用户认证系统

# 切换到 GPT-4o
Ctrl+P
请设计一个用户认证系统

# 切换到 Gemini Pro
Ctrl+P
请设计一个用户认证系统

# 比较三个模型的回答
```

---

### 场景 3：本地开发

```bash
# 使用 Ollama 本地模型
/model llama2

# 无需 API 密钥，完全本地运行
请帮我写一个 Python 函数
```

---

## 快速参考

```typescript
// 认证与模型命令
interface AuthAndModelCommands {
  // 认证命令
  auth: {
    login: '/login',           // OAuth 登录
    logout: '/logout',         // 登出
  };

  // 模型命令
  model: {
    switch: '/model [model-id]',  // 切换模型
    scoped: '/scoped-models model1 model2 ...',  // 配置快速切换
    cycleForward: 'Ctrl+P',    // 向前循环
    cycleBackward: 'Shift+Ctrl+P',  // 向后循环
    selector: 'Ctrl+L',        // 打开模型选择器
  };

  // 认证方式
  authMethods: {
    oauth: 'OAuth 订阅登录',
    apiKey: 'API 密钥（环境变量或配置文件）',
  };

  // 支持的 Provider
  providers: [
    'anthropic', 'openai', 'google', 'github',
    'deepseek', 'qwen', 'mistral', 'ollama', 'custom'
  ];
}
```

---

**来源：**
- [Pi Coding Agent README](https://github.com/badlogic/pi-mono/blob/main/packages/coding-agent/README.md) - 2026-02
- [Providers 文档](https://github.com/badlogic/pi-mono/blob/main/packages/coding-agent/docs/providers.md) - 2026-02
- [Models 配置](https://github.com/badlogic/pi-mono/blob/main/packages/coding-agent/docs/models.md) - 2026-02
