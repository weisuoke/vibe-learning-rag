# GraphRAG知识图谱检索 - 核心概念5: 混合检索策略

> Vector RAG + Graph RAG协同,生产级检索系统的最优方案

---

## 概念定义

**混合检索策略**是将Vector RAG和GraphRAG结合使用的架构模式,通过查询路由器智能选择或融合两种检索方式,实现成本、性能和准确率的最优平衡。

**一句话**: 简单查询用Vector(快速便宜),复杂查询用Graph(准确强大),智能路由选择最优策略。

---

## 为什么需要混合检索?

### 单一方案的局限

```python
# 只用Vector RAG
query1 = "什么是RAG?"  # ✅ 适合
query2 = "Alice和Charlie通过哪些人有联系?"  # ❌ 无法多跳推理

# 只用GraphRAG  
query1 = "什么是RAG?"  # ❌ 成本高,过度设计
query2 = "Alice和Charlie通过哪些人有联系?"  # ✅ 适合
```

**混合策略的优势**:
```python
# 智能路由
if is_simple_semantic_query(query):
    use_vector_rag()  # 快速、便宜
elif is_complex_relation_query(query):
    use_graph_rag()  # 准确、强大
else:
    use_hybrid()  # 融合两者
```

---

## 核心架构

### 1. 查询路由器

```python
from openai import OpenAI
import os
import json

class QueryRouter:
    """查询路由器: 智能选择检索策略"""
    
    def __init__(self, client: OpenAI):
        self.client = client
    
    def classify_query(self, query: str) -> dict:
        """分类查询类型"""
        prompt = f"""
分析以下查询并分类:

查询: {query}

分类标准:
1. "vector": 简单语义查询,如"什么是X?","X的定义"
2. "graph": 复杂关系查询,如"A和B的关系?","通过哪些中间人?"
3. "hybrid": 需要同时使用语义和关系,如"X在Y中的作用?"

返回JSON格式:
{{
  "type": "vector|graph|hybrid",
  "confidence": 0.0-1.0,
  "reason": "分类原因"
}}

只返回JSON。
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return json.loads(response.choices[0].message.content)

# 使用示例
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
router = QueryRouter(client)

queries = [
    "什么是GraphRAG?",
    "Alice和Charlie是什么关系?",
    "Alice在公司中的影响力如何?"
]

for query in queries:
    result = router.classify_query(query)
    print(f"\n查询: {query}")
    print(f"类型: {result['type']} (置信度: {result['confidence']})")
    print(f"原因: {result['reason']}")
```

---

### 2. 混合检索系统

```python
from typing import Dict, List
import networkx as nx
from chromadb import Client as ChromaClient

class HybridRAG:
    """混合RAG系统"""
    
    def __init__(
        self,
        graph: nx.Graph,
        vector_db: ChromaClient,
        llm_client: OpenAI
    ):
        self.graph = graph
        self.vector_db = vector_db
        self.client = llm_client
        self.router = QueryRouter(llm_client)
        
        # 初始化检索器
        self.vector_search = VectorSearch(vector_db, llm_client)
        self.graph_search = GraphSearch(graph, llm_client)
    
    def search(self, query: str) -> Dict:
        """混合检索主流程"""
        # 1. 路由查询
        route_result = self.router.classify_query(query)
        query_type = route_result["type"]
        
        # 2. 根据类型选择策略
        if query_type == "vector":
            answer = self.vector_search.search(query)
            method = "Vector RAG"
        elif query_type == "graph":
            answer = self.graph_search.search(query)
            method = "Graph RAG"
        else:  # hybrid
            answer = self._hybrid_search(query)
            method = "Hybrid (Vector + Graph)"
        
        return {
            "query": query,
            "answer": answer,
            "method": method,
            "route_info": route_result
        }
    
    def _hybrid_search(self, query: str) -> str:
        """混合检索: 同时使用Vector和Graph"""
        # 并行检索
        vector_result = self.vector_search.search(query)
        graph_result = self.graph_search.search(query)
        
        # 融合结果
        prompt = f"""
融合以下两个检索结果:

Vector RAG结果(语义相似):
{vector_result}

Graph RAG结果(关系推理):
{graph_result}

问题: {query}

请生成一个融合了语义和关系信息的完整回答。
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return response.choices[0].message.content

class VectorSearch:
    """Vector RAG检索器"""
    
    def __init__(self, vector_db: ChromaClient, client: OpenAI):
        self.vector_db = vector_db
        self.client = client
        self.collection = vector_db.get_or_create_collection("documents")
    
    def search(self, query: str, top_k: int = 3) -> str:
        """向量检索"""
        # 检索相似文档
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )
        
        # 构建上下文
        context = "\n\n".join(results["documents"][0])
        
        # 生成答案
        prompt = f"""
基于以下上下文回答问题:

上下文:
{context}

问题: {query}

请提供详细的回答。
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return response.choices[0].message.content

class GraphSearch:
    """Graph RAG检索器"""
    
    def __init__(self, graph: nx.Graph, client: OpenAI):
        self.graph = graph
        self.client = client
    
    def search(self, query: str) -> str:
        """图检索"""
        # 提取查询中的实体
        entities = self._extract_entities(query)
        
        if not entities:
            return "未找到相关实体"
        
        # 构建实体上下文
        context = self._build_context(entities)
        
        # 生成答案
        prompt = f"""
基于以下图上下文回答问题:

{context}

问题: {query}

请提供详细的回答。
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return response.choices[0].message.content
    
    def _extract_entities(self, query: str) -> List[str]:
        """提取实体"""
        # 简化版: 实际应使用LLM
        entities = []
        for node in self.graph.nodes():
            if node.lower() in query.lower():
                entities.append(node)
        return entities
    
    def _build_context(self, entities: List[str]) -> str:
        """构建实体上下文"""
        context_parts = []
        for entity in entities:
            if entity in self.graph:
                neighbors = list(self.graph.neighbors(entity))
                context_parts.append(f"{entity}的关系: {', '.join(neighbors)}")
        return "\n".join(context_parts)
```

---

## 成本优化策略

### 1. 查询缓存

```python
import hashlib
from typing import Optional

class CachedHybridRAG(HybridRAG):
    """带缓存的混合RAG"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cache = {}
    
    def search(self, query: str) -> Dict:
        """带缓存的检索"""
        # 计算查询哈希
        query_hash = hashlib.md5(query.encode()).hexdigest()
        
        # 检查缓存
        if query_hash in self.cache:
            result = self.cache[query_hash]
            result["from_cache"] = True
            return result
        
        # 执行检索
        result = super().search(query)
        
        # 缓存结果
        self.cache[query_hash] = result
        result["from_cache"] = False
        
        return result
```

### 2. 成本监控

```python
class CostMonitor:
    """成本监控器"""
    
    def __init__(self):
        self.costs = {
            "vector": 0.0,
            "graph": 0.0,
            "hybrid": 0.0
        }
        self.counts = {
            "vector": 0,
            "graph": 0,
            "hybrid": 0
        }
    
    def record(self, method: str, cost: float):
        """记录成本"""
        method_type = method.lower().split()[0]
        if method_type in self.costs:
            self.costs[method_type] += cost
            self.counts[method_type] += 1
    
    def report(self) -> Dict:
        """生成成本报告"""
        total_cost = sum(self.costs.values())
        total_count = sum(self.counts.values())
        
        return {
            "total_cost": total_cost,
            "total_queries": total_count,
            "avg_cost_per_query": total_cost / total_count if total_count > 0 else 0,
            "breakdown": {
                method: {
                    "cost": cost,
                    "count": self.counts[method],
                    "avg_cost": cost / self.counts[method] if self.counts[method] > 0 else 0,
                    "percentage": (cost / total_cost * 100) if total_cost > 0 else 0
                }
                for method, cost in self.costs.items()
            }
        }

# 使用示例
monitor = CostMonitor()

# 模拟查询
monitor.record("Vector RAG", 0.001)
monitor.record("Graph RAG", 0.01)
monitor.record("Hybrid", 0.015)

report = monitor.report()
print("\n成本报告:")
print(f"总成本: ${report['total_cost']:.4f}")
print(f"总查询数: {report['total_queries']}")
print(f"平均成本: ${report['avg_cost_per_query']:.4f}")
print("\n分类统计:")
for method, stats in report['breakdown'].items():
    print(f"  {method}:")
    print(f"    成本: ${stats['cost']:.4f} ({stats['percentage']:.1f}%)")
    print(f"    查询数: {stats['count']}")
    print(f"    平均: ${stats['avg_cost']:.4f}")
```

---

## 性能优化

### 1. 并行检索

```python
from concurrent.futures import ThreadPoolExecutor

class ParallelHybridRAG(HybridRAG):
    """并行混合RAG"""
    
    def _hybrid_search(self, query: str) -> str:
        """并行混合检索"""
        with ThreadPoolExecutor(max_workers=2) as executor:
            # 并行执行Vector和Graph检索
            vector_future = executor.submit(self.vector_search.search, query)
            graph_future = executor.submit(self.graph_search.search, query)
            
            # 等待结果
            vector_result = vector_future.result()
            graph_result = graph_future.result()
        
        # 融合结果
        return self._merge_results(query, vector_result, graph_result)
```

### 2. 索引优化

```python
class OptimizedHybridRAG(HybridRAG):
    """优化的混合RAG"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._build_indexes()
    
    def _build_indexes(self):
        """构建索引"""
        # Vector索引
        self.vector_index = self._build_vector_index()
        
        # Graph索引
        self.graph_index = self._build_graph_index()
    
    def _build_vector_index(self):
        """构建向量索引"""
        # 使用FAISS或类似库加速
        pass
    
    def _build_graph_index(self):
        """构建图索引"""
        # 预计算常用路径
        pass
```

---

## 在RAG开发中的应用

### 应用场景1: 企业知识库

```python
# 场景: 企业文档问答系统
hybrid_rag = HybridRAG(graph, vector_db, client)

queries = [
    "公司的使命是什么?",  # Vector
    "张三和李四的汇报关系?",  # Graph
    "技术部门的核心职责是什么?"  # Hybrid
]

for query in queries:
    result = hybrid_rag.search(query)
    print(f"\n查询: {result['query']}")
    print(f"方法: {result['method']}")
    print(f"回答: {result['answer']}")
```

### 应用场景2: 学术文献分析

```python
# 场景: 论文检索系统
# Vector: "什么是Transformer?"
# Graph: "这篇论文引用了哪些相关工作?"
# Hybrid: "Transformer在NLP领域的影响力如何?"
```

---

## 最佳实践

### 1. 路由策略选择

```python
# 规则1: 简单语义查询 → Vector
if contains_keywords(query, ["什么是", "定义", "解释"]):
    use_vector()

# 规则2: 关系查询 → Graph
if contains_keywords(query, ["关系", "联系", "通过"]):
    use_graph()

# 规则3: 复杂查询 → Hybrid
if is_complex(query):
    use_hybrid()
```

### 2. 成本控制

```python
# 策略1: 优先使用Vector
if confidence < 0.8:
    use_vector()  # 不确定时用便宜的

# 策略2: 设置预算
if daily_cost > budget:
    use_vector_only()

# 策略3: 缓存热门查询
if query in hot_queries:
    return cached_result
```

---

## 检查清单

掌握混合检索策略后,你应该能够:

- [ ] 理解混合检索的必要性
- [ ] 实现查询路由器
- [ ] 构建混合RAG系统
- [ ] 优化成本和性能
- [ ] 监控系统运行状态
- [ ] 根据场景选择策略

---

**版本**: v1.0 (基于2025-2026生产级实践)
**最后更新**: 2026-02-17
**维护者**: Claude Code
