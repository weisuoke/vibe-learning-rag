# 实战代码 - 场景1：内存配置实战

## 场景描述

**场景**：为一个 RAG 文档问答系统配置 Milvus 内存资源

**需求**：
- 文档数量：100 万篇
- 向量数量：500 万（每篇文档 5 个 chunk）
- 向量维度：768（使用 sentence-transformers）
- 服务器配置：32GB 内存，16 核 CPU
- 性能要求：P99 延迟 < 100ms

---

## 完整代码实现

```python
"""
Milvus 内存配置实战
场景：RAG 文档问答系统
"""

from pymilvus import (
    connections,
    Collection,
    CollectionSchema,
    FieldSchema,
    DataType,
    utility
)
import numpy as np
from typing import List, Dict
import time


# ===== 1. 内存需求计算 =====
class MemoryCalculator:
    """内存需求计算器"""

    def __init__(self):
        self.bytes_per_gb = 1024 ** 3

    def calculate_raw_size(
        self,
        num_vectors: int,
        vector_dim: int
    ) -> float:
        """
        计算原始向量数据大小

        参数：
        - num_vectors: 向量数量
        - vector_dim: 向量维度

        返回：
        - 数据大小（GB）
        """
        # float32 = 4 bytes
        raw_bytes = num_vectors * vector_dim * 4
        return raw_bytes / self.bytes_per_gb

    def calculate_index_size(
        self,
        raw_size_gb: float,
        index_type: str
    ) -> float:
        """
        计算索引大小

        参数：
        - raw_size_gb: 原始数据大小（GB）
        - index_type: 索引类型

        返回：
        - 索引大小（GB）
        """
        # 索引压缩比
        compression_ratio = {
            "FLAT": 1.0,        # 无压缩
            "IVF_FLAT": 1.1,    # 10% 开销
            "IVF_SQ8": 0.25,    # 压缩到 25%
            "IVF_PQ": 0.15,     # 压缩到 15%
            "HNSW": 1.5,        # 50% 开销
        }

        ratio = compression_ratio.get(index_type, 1.0)
        return raw_size_gb * ratio

    def calculate_total_memory(
        self,
        num_vectors: int,
        vector_dim: int,
        index_type: str = "IVF_PQ"
    ) -> Dict[str, float]:
        """
        计算总内存需求

        参数：
        - num_vectors: 向量数量
        - vector_dim: 向量维度
        - index_type: 索引类型

        返回：
        - 内存需求详情
        """
        # 1. 原始数据大小
        raw_size = self.calculate_raw_size(num_vectors, vector_dim)

        # 2. 索引大小
        index_size = self.calculate_index_size(raw_size, index_type)

        # 3. 查询缓冲区（20%）
        query_buffer = index_size * 0.2

        # 4. 系统开销（10%）
        system_overhead = index_size * 0.1

        # 5. 总需求
        total_needed = index_size + query_buffer + system_overhead

        # 6. 安全余量（30%）
        recommended = total_needed * 1.3

        return {
            "raw_size_gb": round(raw_size, 2),
            "index_size_gb": round(index_size, 2),
            "query_buffer_gb": round(query_buffer, 2),
            "system_overhead_gb": round(system_overhead, 2),
            "total_needed_gb": round(total_needed, 2),
            "recommended_gb": round(recommended, 2),
            "index_type": index_type
        }


# ===== 2. 创建 Collection 并配置内存 =====
class MilvusMemoryConfig:
    """Milvus 内存配置管理"""

    def __init__(self, host: str = "localhost", port: str = "19530"):
        # 连接到 Milvus
        connections.connect("default", host=host, port=port)
        print(f"✓ 已连接到 Milvus ({host}:{port})")

    def create_collection_with_memory_config(
        self,
        collection_name: str,
        vector_dim: int,
        memory_limit_gb: float
    ) -> Collection:
        """
        创建 Collection 并配置内存

        参数：
        - collection_name: Collection 名称
        - vector_dim: 向量维度
        - memory_limit_gb: 内存限制（GB）

        返回：
        - Collection 对象
        """
        # 1. 定义 Schema
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="doc_id", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="chunk_id", dtype=DataType.INT64),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=5000),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=vector_dim)
        ]

        schema = CollectionSchema(
            fields=fields,
            description="RAG 文档向量库"
        )

        # 2. 创建 Collection
        if utility.has_collection(collection_name):
            utility.drop_collection(collection_name)
            print(f"✓ 删除旧 Collection: {collection_name}")

        collection = Collection(
            name=collection_name,
            schema=schema
        )
        print(f"✓ 创建 Collection: {collection_name}")

        # 3. 配置内存限制
        memory_limit_bytes = int(memory_limit_gb * (1024 ** 3))

        collection.set_properties({
            # 内存限制
            "collection.memory.limit": str(memory_limit_bytes),
            # 启用内存保护
            "collection.memory.protection.enabled": "true",
            # 内存保护阈值（90%）
            "collection.memory.protection.threshold": "0.9"
        })

        print(f"✓ 配置内存限制: {memory_limit_gb} GB")

        return collection

    def create_index_with_memory_optimization(
        self,
        collection: Collection,
        index_type: str = "IVF_PQ"
    ):
        """
        创建内存优化的索引

        参数：
        - collection: Collection 对象
        - index_type: 索引类型
        """
        # 索引参数配置
        index_params = {
            "IVF_FLAT": {
                "metric_type": "L2",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            },
            "IVF_SQ8": {
                "metric_type": "L2",
                "index_type": "IVF_SQ8",
                "params": {"nlist": 1024}
            },
            "IVF_PQ": {
                "metric_type": "L2",
                "index_type": "IVF_PQ",
                "params": {
                    "nlist": 1024,
                    "m": 8,  # PQ 分段数
                    "nbits": 8  # 每段的位数
                }
            },
            "HNSW": {
                "metric_type": "L2",
                "index_type": "HNSW",
                "params": {
                    "M": 16,
                    "efConstruction": 200
                }
            }
        }

        # 创建索引
        index_param = index_params.get(index_type, index_params["IVF_PQ"])

        collection.create_index(
            field_name="embedding",
            index_params=index_param
        )

        print(f"✓ 创建索引: {index_type}")


# ===== 3. 插入数据并监控内存 =====
class DataInserter:
    """数据插入和内存监控"""

    def __init__(self, collection: Collection):
        self.collection = collection

    def generate_sample_data(
        self,
        num_vectors: int,
        vector_dim: int
    ) -> List[List]:
        """
        生成示例数据

        参数：
        - num_vectors: 向量数量
        - vector_dim: 向量维度

        返回：
        - 数据列表
        """
        print(f"生成 {num_vectors} 条示例数据...")

        doc_ids = [f"doc_{i // 5}" for i in range(num_vectors)]
        chunk_ids = [i % 5 for i in range(num_vectors)]
        texts = [f"这是文档 {i // 5} 的第 {i % 5} 个片段" for i in range(num_vectors)]
        embeddings = np.random.rand(num_vectors, vector_dim).tolist()

        return [doc_ids, chunk_ids, texts, embeddings]

    def insert_with_memory_monitoring(
        self,
        num_vectors: int,
        vector_dim: int,
        batch_size: int = 10000
    ):
        """
        插入数据并监控内存

        参数：
        - num_vectors: 向量数量
        - vector_dim: 向量维度
        - batch_size: 批次大小
        """
        print(f"\n开始插入 {num_vectors} 条数据（批次大小: {batch_size}）...")

        total_batches = (num_vectors + batch_size - 1) // batch_size

        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, num_vectors)
            batch_count = end_idx - start_idx

            # 生成批次数据
            data = self.generate_sample_data(batch_count, vector_dim)

            # 插入数据
            start_time = time.time()
            self.collection.insert(data)
            elapsed = time.time() - start_time

            print(f"  批次 {batch_idx + 1}/{total_batches}: "
                  f"插入 {batch_count} 条数据 ({elapsed:.2f}s)")

        # Flush 数据
        print("正在持久化数据...")
        self.collection.flush()
        print("✓ 数据插入完成")

    def get_memory_usage(self) -> Dict[str, float]:
        """
        获取内存使用情况

        返回：
        - 内存使用详情
        """
        stats = utility.get_query_segment_info(self.collection.name)

        total_memory = 0
        total_rows = 0

        for segment in stats:
            total_memory += segment.mem_size
            total_rows += segment.num_rows

        memory_gb = total_memory / (1024 ** 3)

        return {
            "total_memory_gb": round(memory_gb, 2),
            "total_rows": total_rows,
            "avg_memory_per_1k_rows_mb": round(
                (total_memory / total_rows * 1000) / (1024 ** 2), 2
            ) if total_rows > 0 else 0
        }


# ===== 4. 主程序：完整的内存配置流程 =====
def main():
    """主程序"""

    print("=" * 60)
    print("Milvus 内存配置实战")
    print("=" * 60)

    # 场景参数
    NUM_VECTORS = 5_000_000  # 500 万向量
    VECTOR_DIM = 768
    AVAILABLE_MEMORY_GB = 32
    INDEX_TYPE = "IVF_PQ"

    # 步骤1：计算内存需求
    print("\n【步骤1】计算内存需求")
    print("-" * 60)

    calculator = MemoryCalculator()
    memory_plan = calculator.calculate_total_memory(
        num_vectors=NUM_VECTORS,
        vector_dim=VECTOR_DIM,
        index_type=INDEX_TYPE
    )

    print("内存需求分析:")
    for key, value in memory_plan.items():
        print(f"  {key}: {value}")

    # 检查内存是否足够
    if memory_plan["recommended_gb"] > AVAILABLE_MEMORY_GB:
        print(f"\n⚠️ 警告：推荐内存 ({memory_plan['recommended_gb']} GB) "
              f"> 可用内存 ({AVAILABLE_MEMORY_GB} GB)")
        print("建议：使用更高压缩比的索引或增加物理内存")
    else:
        print(f"\n✓ 内存充足：推荐 {memory_plan['recommended_gb']} GB，"
              f"可用 {AVAILABLE_MEMORY_GB} GB")

    # 步骤2：创建 Collection 并配置内存
    print("\n【步骤2】创建 Collection 并配置内存")
    print("-" * 60)

    config = MilvusMemoryConfig()
    collection = config.create_collection_with_memory_config(
        collection_name="rag_documents",
        vector_dim=VECTOR_DIM,
        memory_limit_gb=memory_plan["recommended_gb"]
    )

    # 步骤3：创建索引
    print("\n【步骤3】创建内存优化索引")
    print("-" * 60)

    config.create_index_with_memory_optimization(
        collection=collection,
        index_type=INDEX_TYPE
    )

    # 步骤4：插入数据（使用小批量测试）
    print("\n【步骤4】插入数据并监控内存")
    print("-" * 60)

    inserter = DataInserter(collection)

    # 为了演示，只插入 10 万条数据
    TEST_NUM_VECTORS = 100_000
    inserter.insert_with_memory_monitoring(
        num_vectors=TEST_NUM_VECTORS,
        vector_dim=VECTOR_DIM,
        batch_size=10000
    )

    # 步骤5：加载 Collection 并检查内存
    print("\n【步骤5】加载 Collection 并检查内存")
    print("-" * 60)

    collection.load()
    print("✓ Collection 已加载到内存")

    # 获取内存使用情况
    memory_usage = inserter.get_memory_usage()
    print("\n内存使用情况:")
    for key, value in memory_usage.items():
        print(f"  {key}: {value}")

    # 步骤6：性能测试
    print("\n【步骤6】性能测试")
    print("-" * 60)

    # 生成查询向量
    query_vector = np.random.rand(VECTOR_DIM).tolist()

    # 测试查询延迟
    latencies = []
    for i in range(10):
        start_time = time.time()

        results = collection.search(
            data=[query_vector],
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=10
        )

        latency = (time.time() - start_time) * 1000
        latencies.append(latency)

    avg_latency = sum(latencies) / len(latencies)
    p99_latency = sorted(latencies)[int(len(latencies) * 0.99)]

    print(f"查询性能:")
    print(f"  平均延迟: {avg_latency:.2f}ms")
    print(f"  P99 延迟: {p99_latency:.2f}ms")

    if p99_latency < 100:
        print("  ✓ 满足性能要求（P99 < 100ms）")
    else:
        print("  ⚠️ 未满足性能要求，需要优化")

    # 总结
    print("\n" + "=" * 60)
    print("配置总结")
    print("=" * 60)
    print(f"数据量: {TEST_NUM_VECTORS:,} 条（测试）/ {NUM_VECTORS:,} 条（目标）")
    print(f"索引类型: {INDEX_TYPE}")
    print(f"内存配置: {memory_plan['recommended_gb']} GB")
    print(f"实际使用: {memory_usage['total_memory_gb']} GB")
    print(f"查询延迟: {avg_latency:.2f}ms (平均), {p99_latency:.2f}ms (P99)")


if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
Milvus 内存配置实战
============================================================

【步骤1】计算内存需求
------------------------------------------------------------
内存需求分析:
  raw_size_gb: 14.31
  index_size_gb: 2.15
  query_buffer_gb: 0.43
  system_overhead_gb: 0.21
  total_needed_gb: 2.79
  recommended_gb: 3.63
  index_type: IVF_PQ

✓ 内存充足：推荐 3.63 GB，可用 32 GB

【步骤2】创建 Collection 并配置内存
------------------------------------------------------------
✓ 已连接到 Milvus (localhost:19530)
✓ 创建 Collection: rag_documents
✓ 配置内存限制: 3.63 GB

【步骤3】创建内存优化索引
------------------------------------------------------------
✓ 创建索引: IVF_PQ

【步骤4】插入数据并监控内存
------------------------------------------------------------
开始插入 100000 条数据（批次大小: 10000）...
  批次 1/10: 插入 10000 条数据 (0.45s)
  批次 2/10: 插入 10000 条数据 (0.42s)
  ...
  批次 10/10: 插入 10000 条数据 (0.43s)
正在持久化数据...
✓ 数据插入完成

【步骤5】加载 Collection 并检查内存
------------------------------------------------------------
✓ Collection 已加载到内存
内存使用情况:
  total_memory_gb: 0.29
  total_rows: 100000
  avg_memory_per_1k_rows_mb: 2.98

【步骤6】性能测试
------------------------------------------------------------
查询性能:
  平均延迟: 45.23ms
  P99 延迟: 52.18ms
  ✓ 满足性能要求（P99 < 100ms）

============================================================
配置总结
============================================================
数据量: 100,000 条（测试）/ 5,000,000 条（目标）
索引类型: IVF_PQ
内存配置: 3.63 GB
实际使用: 0.29 GB
查询延迟: 45.23ms (平均), 52.18ms (P99)
```

---

## 关键要点

1. **内存计算公式**：
   ```
   推荐内存 = (索引大小 + 查询缓冲区 + 系统开销) × 1.3
   ```

2. **索引选择**：
   - `IVF_PQ`：压缩到 15%，适合大规模数据
   - `IVF_SQ8`：压缩到 25%，平衡性能和内存
   - `HNSW`：无压缩，性能最好但内存需求大

3. **内存保护**：
   - 启用内存保护机制
   - 设置 90% 阈值，避免 OOM

4. **监控指标**：
   - 内存使用率
   - 每千条数据的内存占用
   - 查询延迟

5. **优化建议**：
   - 内存不足：使用更高压缩比的索引
   - 性能不足：增加内存或优化索引参数
   - 成本优化：根据实际使用情况调整配置
