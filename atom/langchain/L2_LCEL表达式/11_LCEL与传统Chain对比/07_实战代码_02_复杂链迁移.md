# 实战代码 02：复杂链迁移

> RouterChain、Memory、自定义 Chain 的完整迁移示例

---

## 概述

本文提供复杂场景的完整迁移代码示例，包括 RouterChain、Memory、自定义 Chain 等高级用法。

---

## 模式 1：RouterChain 迁移

### 1.1 传统 RouterChain

```python
"""
传统 RouterChain 示例
"""
from langchain.chains.router import MultiPromptChain
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 定义不同的 prompt
physics_template = "你是物理专家。回答：{input}"
math_template = "你是数学专家。回答：{input}"
history_template = "你是历史专家。回答：{input}"

prompt_infos = [
    {"name": "physics", "description": "适合物理问题", "prompt_template": physics_template},
    {"name": "math", "description": "适合数学问题", "prompt_template": math_template},
    {"name": "history", "description": "适合历史问题", "prompt_template": history_template}
]

# 创建 RouterChain
destination_chains = {}
for p_info in prompt_infos:
    name = p_info["name"]
    prompt = ChatPromptTemplate.from_template(p_info["prompt_template"])
    chain = LLMChain(llm=llm, prompt=prompt)
    destination_chains[name] = chain

router_chain = MultiPromptChain.from_prompts(
    llm=llm,
    destination_chains=destination_chains,
    default_chain=destination_chains["physics"]
)

# 使用
result = router_chain.run("什么是牛顿第一定律？")
print(f"结果: {result}")
```

### 1.2 LCEL 版本

```python
"""
LCEL 版本：使用 RunnableBranch
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableBranch
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 定义不同的链
physics_prompt = ChatPromptTemplate.from_template("你是物理专家。回答：{input}")
physics_chain = physics_prompt | llm | StrOutputParser()

math_prompt = ChatPromptTemplate.from_template("你是数学专家。回答：{input}")
math_chain = math_prompt | llm | StrOutputParser()

history_prompt = ChatPromptTemplate.from_template("你是历史专家。回答：{input}")
history_chain = history_prompt | llm | StrOutputParser()

# 定义路由逻辑
def is_physics(input_dict):
    text = input_dict["input"].lower()
    return any(word in text for word in ["物理", "牛顿", "力", "运动"])

def is_math(input_dict):
    text = input_dict["input"].lower()
    return any(word in text for word in ["数学", "计算", "方程", "函数"])

# 创建 RunnableBranch
router_chain = RunnableBranch(
    (is_physics, physics_chain),
    (is_math, math_chain),
    history_chain  # default
)

# 使用
result = router_chain.invoke({"input": "什么是牛顿第一定律？"})
print(f"结果: {result}")
```

---

## 模式 2：Memory 迁移

### 2.1 传统 ConversationChain

```python
"""
传统 ConversationChain with Memory
"""
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
memory = ConversationBufferMemory()

conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# 对话
print(conversation.predict(input="我叫张三"))
print(conversation.predict(input="我的名字是什么？"))
```

### 2.2 LCEL 版本

```python
"""
LCEL 版本：使用 RunnableWithMessageHistory
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 定义 prompt（包含历史消息）
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个友好的助手。"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

# 创建基础链
base_chain = prompt | llm | StrOutputParser()

# 存储会话历史
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 创建带历史的链
conversation = RunnableWithMessageHistory(
    base_chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

# 对话
config = {"configurable": {"session_id": "user123"}}
print(conversation.invoke({"input": "我叫张三"}, config=config))
print(conversation.invoke({"input": "我的名字是什么？"}, config=config))
```

---

## 模式 3：自定义 Chain 迁移

### 3.1 传统自定义 Chain

```python
"""
传统自定义 Chain
"""
from langchain.chains.base import Chain
from langchain_openai import ChatOpenAI
from typing import Dict, Any, List
from dotenv import load_dotenv

load_dotenv()

class CustomAnalysisChain(Chain):
    """自定义分析链"""
    llm: ChatOpenAI

    @property
    def input_keys(self) -> List[str]:
        return ["text"]

    @property
    def output_keys(self) -> List[str]:
        return ["sentiment", "summary", "keywords"]

    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        text = inputs["text"]

        # 步骤1：情感分析
        sentiment_prompt = f"分析情感（正面/负面/中性）：{text}"
        sentiment = self.llm.predict(sentiment_prompt)

        # 步骤2：总结
        summary_prompt = f"总结：{text}"
        summary = self.llm.predict(summary_prompt)

        # 步骤3：提取关键词
        keywords_prompt = f"提取3个关键词：{text}"
        keywords = self.llm.predict(keywords_prompt)

        return {
            "sentiment": sentiment,
            "summary": summary,
            "keywords": keywords
        }

# 使用
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = CustomAnalysisChain(llm=llm)
result = chain({"text": "今天天气很好，我很开心。"})
print(result)
```

### 3.2 LCEL 版本

```python
"""
LCEL 版本：使用 RunnableParallel
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 定义三个并行任务
sentiment_prompt = ChatPromptTemplate.from_template("分析情感（正面/负面/中性）：{text}")
sentiment_chain = sentiment_prompt | llm | StrOutputParser()

summary_prompt = ChatPromptTemplate.from_template("总结：{text}")
summary_chain = summary_prompt | llm | StrOutputParser()

keywords_prompt = ChatPromptTemplate.from_template("提取3个关键词：{text}")
keywords_chain = keywords_prompt | llm | StrOutputParser()

# 并行执行
analysis_chain = RunnableParallel(
    sentiment=sentiment_chain,
    summary=summary_chain,
    keywords=keywords_chain
)

# 使用
result = analysis_chain.invoke({"text": "今天天气很好，我很开心。"})
print(result)
# 输出: {'sentiment': '正面', 'summary': '...',  'keywords': '...'}
```

---

## 模式 4：多步 RAG 迁移

### 4.1 传统多步 RAG

```python
"""
传统多步 RAG：检索 → ReRank → 生成
"""
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv

load_dotenv()

# 初始化
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(embedding_function=embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 创建 QA Chain（无法自定义 ReRank）
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever
)

result = qa_chain({"query": "什么是 LCEL？"})
print(result["result"])
```

### 4.2 LCEL 版本（带 ReRank）

```python
"""
LCEL 版本：检索 → ReRank → 生成
"""
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from dotenv import load_dotenv

load_dotenv()

# 初始化
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(embedding_function=embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ReRank 函数
def rerank_docs(docs_and_query):
    """简单的 ReRank：基于相关性分数"""
    docs = docs_and_query["docs"]
    query = docs_and_query["query"]

    # 这里可以使用更复杂的 ReRank 模型
    # 简化示例：只返回前3个
    return docs[:3]

# 格式化文档
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# 创建 LCEL 链
prompt = ChatPromptTemplate.from_template("""基于以下上下文回答问题：

上下文：
{context}

问题：{question}

答案：""")

chain = (
    {
        "docs": retriever,
        "query": RunnablePassthrough()
    }
    | RunnablePassthrough.assign(docs=RunnableLambda(rerank_docs))
    | {
        "context": lambda x: format_docs(x["docs"]),
        "question": lambda x: x["query"]
    }
    | prompt
    | llm
    | StrOutputParser()
)

# 使用
result = chain.invoke("什么是 LCEL？")
print(result)
```

---

## 完整测试脚本

```python
"""
复杂链迁移测试脚本
"""
from dotenv import load_dotenv

load_dotenv()

def test_all_complex_migrations():
    """测试所有复杂迁移模式"""

    print("=" * 60)
    print("复杂链迁移测试")
    print("=" * 60)

    # 测试 1：RouterChain
    print("\n1. RouterChain 迁移测试")
    print("-" * 60)
    test_router_chain()

    # 测试 2：Memory
    print("\n2. Memory 迁移测试")
    print("-" * 60)
    test_memory()

    # 测试 3：自定义 Chain
    print("\n3. 自定义 Chain 迁移测试")
    print("-" * 60)
    test_custom_chain()

    print("\n" + "=" * 60)
    print("所有测试完成！")
    print("=" * 60)

def test_router_chain():
    """测试 RouterChain 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnableBranch

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    physics_prompt = ChatPromptTemplate.from_template("物理专家：{input}")
    physics_chain = physics_prompt | llm | StrOutputParser()

    math_prompt = ChatPromptTemplate.from_template("数学专家：{input}")
    math_chain = math_prompt | llm | StrOutputParser()

    def is_physics(x):
        return "物理" in x["input"] or "牛顿" in x["input"]

    router = RunnableBranch(
        (is_physics, physics_chain),
        math_chain
    )

    result = router.invoke({"input": "什么是牛顿第一定律？"})
    print(f"✓ 路由到物理专家: {result[:50]}...")

def test_memory():
    """测试 Memory 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnableWithMessageHistory
    from langchain_community.chat_message_histories import ChatMessageHistory

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = ChatPromptTemplate.from_messages([
        ("system", "你是助手。"),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])

    base_chain = prompt | llm | StrOutputParser()

    store = {}
    def get_history(session_id):
        if session_id not in store:
            store[session_id] = ChatMessageHistory()
        return store[session_id]

    conversation = RunnableWithMessageHistory(
        base_chain,
        get_history,
        input_messages_key="input",
        history_messages_key="history"
    )

    config = {"configurable": {"session_id": "test"}}
    conversation.invoke({"input": "我叫张三"}, config=config)
    result = conversation.invoke({"input": "我叫什么？"}, config=config)
    print(f"✓ 记住了名字: {result}")

def test_custom_chain():
    """测试自定义 Chain 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnableParallel

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    sentiment_prompt = ChatPromptTemplate.from_template("情感：{text}")
    sentiment_chain = sentiment_prompt | llm | StrOutputParser()

    summary_prompt = ChatPromptTemplate.from_template("总结：{text}")
    summary_chain = summary_prompt | llm | StrOutputParser()

    analysis = RunnableParallel(
        sentiment=sentiment_chain,
        summary=summary_chain
    )

    result = analysis.invoke({"text": "今天很开心"})
    print(f"✓ 并行分析完成: sentiment={result['sentiment'][:20]}...")

if __name__ == "__main__":
    test_all_complex_migrations()
```

---

## 总结

### 复杂迁移模式总结

| 传统 Chain | LCEL 模式 | 关键技术 |
|-----------|----------|----------|
| RouterChain | RunnableBranch | 条件路由 |
| ConversationChain | RunnableWithMessageHistory | 消息历史 |
| 自定义 Chain | RunnableParallel | 并行执行 |
| 多步 RAG | 组合 Runnable | 灵活组合 |

### 关键要点

1. **条件路由**：使用 RunnableBranch
2. **状态管理**：使用 RunnableWithMessageHistory
3. **并行执行**：使用 RunnableParallel
4. **灵活组合**：任意组合 Runnable

---

**下一步**：阅读 `07_实战代码_03_性能基准测试.md` 学习性能测试
