# å®æˆ˜ä»£ç 7ï¼šé”™è¯¯å¤„ç†å®¹é”™

> å¥å£®çš„é”™è¯¯å¤„ç†å’Œå®¹é”™æœºåˆ¶å®Œæ•´ç¤ºä¾‹

---

## åœºæ™¯æè¿°

æ¼”ç¤ºå¦‚ä½•æ„å»ºå¥å£®çš„æ–‡æ¡£åŠ è½½ç³»ç»Ÿï¼ŒåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶ã€é™çº§ç­–ç•¥å’Œç›‘æ§å‘Šè­¦ã€‚

**é€‚ç”¨åœºæ™¯ï¼š**
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- æ‰¹é‡æ–‡æ¡£å¤„ç†
- é«˜å¯ç”¨ç³»ç»Ÿ

---

## ä¾èµ–åº“

```bash
# å®‰è£…ä¾èµ–
uv add pypdf python-docx langchain langchain-openai chromadb python-dotenv chardet tenacity
```

---

## å®Œæ•´ä»£ç 

```python
"""
é”™è¯¯å¤„ç†å®¹é”™ç¤ºä¾‹
æ¼”ç¤ºï¼šå¥å£®çš„æ–‡æ¡£åŠ è½½ç³»ç»Ÿï¼ŒåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œå®¹é”™æœºåˆ¶

ä¾èµ–åº“ï¼š
- pypdf, python-docx: æ–‡æ¡£è§£æ
- chardet: ç¼–ç æ£€æµ‹
- tenacity: é‡è¯•æœºåˆ¶
- langchain: æ–‡æ¡£å¤„ç†æ¡†æ¶

å‚è€ƒæ¥æºï¼š
- Python Error Handling Best Practices (2025): https://realpython.com/python-exceptions/
- Tenacity Documentation (2025): https://tenacity.readthedocs.io/
- Circuit Breaker Pattern (2025): https://martinfowler.com/bliki/CircuitBreaker.html
"""

import os
import time
import logging
from typing import List, Dict, Optional, Callable
from datetime import datetime
from enum import Enum
from dotenv import load_dotenv
from langchain.schema import Document
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ===== 1. é”™è¯¯åˆ†ç±» =====
print("=== 1. é”™è¯¯åˆ†ç±» ===")

class ErrorType(Enum):
    """é”™è¯¯ç±»å‹æšä¸¾"""
    FILE_NOT_FOUND = "æ–‡ä»¶ä¸å­˜åœ¨"
    PERMISSION_DENIED = "æƒé™ä¸è¶³"
    ENCODING_ERROR = "ç¼–ç é”™è¯¯"
    FORMAT_ERROR = "æ ¼å¼é”™è¯¯"
    CORRUPTED_FILE = "æ–‡ä»¶æŸå"
    TIMEOUT = "è¶…æ—¶"
    NETWORK_ERROR = "ç½‘ç»œé”™è¯¯"
    MEMORY_ERROR = "å†…å­˜ä¸è¶³"
    UNKNOWN = "æœªçŸ¥é”™è¯¯"

class DocumentLoadError(Exception):
    """æ–‡æ¡£åŠ è½½é”™è¯¯åŸºç±»"""

    def __init__(self, error_type: ErrorType, message: str, file_path: str = None, original_error: Exception = None):
        self.error_type = error_type
        self.message = message
        self.file_path = file_path
        self.original_error = original_error
        self.timestamp = datetime.now()

        super().__init__(f"{error_type.value}: {message}")

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "error_type": self.error_type.value,
            "message": self.message,
            "file_path": self.file_path,
            "timestamp": self.timestamp.isoformat(),
            "original_error": str(self.original_error) if self.original_error else None
        }

# ===== 2. ç¼–ç æ£€æµ‹ä¸å¤„ç† =====
print("\n=== 2. ç¼–ç æ£€æµ‹ä¸å¤„ç† ===")

import chardet

class EncodingHandler:
    """ç¼–ç å¤„ç†å™¨"""

    def __init__(self, confidence_threshold: float = 0.7):
        self.confidence_threshold = confidence_threshold
        self.fallback_encodings = ['utf-8', 'gbk', 'gb2312', 'iso-8859-1', 'ascii']

    def read_file(self, file_path: str) -> tuple[str, str]:
        """
        æ™ºèƒ½è¯»å–æ–‡ä»¶
        è¿”å›: (content, encoding)
        """
        # 1. æ£€æµ‹ç¼–ç 
        detected = self._detect_encoding(file_path)

        # 2. å¦‚æœç½®ä¿¡åº¦é«˜ï¼Œä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç 
        if detected['confidence'] >= self.confidence_threshold:
            try:
                content = self._read_with_encoding(file_path, detected['encoding'])
                logger.info(f"ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç : {detected['encoding']} (ç½®ä¿¡åº¦: {detected['confidence']:.2%})")
                return content, detected['encoding']
            except Exception as e:
                logger.warning(f"æ£€æµ‹åˆ°çš„ç¼–ç å¤±è´¥: {e}")

        # 3. ä½¿ç”¨å›é€€ç­–ç•¥
        logger.info("ä½¿ç”¨å›é€€ç­–ç•¥")
        return self._read_with_fallback(file_path)

    def _detect_encoding(self, file_path: str) -> Dict:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        with open(file_path, 'rb') as f:
            raw_data = f.read()
        result = chardet.detect(raw_data)
        return {
            "encoding": result['encoding'],
            "confidence": result['confidence']
        }

    def _read_with_encoding(self, file_path: str, encoding: str) -> str:
        """ä½¿ç”¨æŒ‡å®šç¼–ç è¯»å–"""
        with open(file_path, 'r', encoding=encoding) as f:
            return f.read()

    def _read_with_fallback(self, file_path: str) -> tuple[str, str]:
        """å›é€€ç­–ç•¥è¯»å–"""
        for encoding in self.fallback_encodings:
            try:
                content = self._read_with_encoding(file_path, encoding)
                logger.info(f"å›é€€æˆåŠŸ: {encoding}")
                return content, encoding
            except:
                continue

        # æœ€åçš„æ‰‹æ®µï¼šå¿½ç•¥é”™è¯¯
        logger.warning("ä½¿ç”¨UTF-8å¹¶å¿½ç•¥é”™è¯¯")
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read(), 'utf-8 (errors ignored)'

# ===== 3. é‡è¯•æœºåˆ¶ =====
print("\n=== 3. é‡è¯•æœºåˆ¶ ===")

class RetryableLoader:
    """æ”¯æŒé‡è¯•çš„æ–‡æ¡£åŠ è½½å™¨"""

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((IOError, TimeoutError)),
        reraise=True
    )
    def load_with_retry(self, file_path: str) -> Document:
        """å¸¦é‡è¯•çš„æ–‡æ¡£åŠ è½½"""
        logger.info(f"å°è¯•åŠ è½½: {file_path}")

        # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ
        if not os.path.exists(file_path):
            raise DocumentLoadError(
                ErrorType.FILE_NOT_FOUND,
                f"æ–‡ä»¶ä¸å­˜åœ¨",
                file_path
            )

        # å®é™…åŠ è½½é€»è¾‘
        encoding_handler = EncodingHandler()
        content, encoding = encoding_handler.read_file(file_path)

        return Document(
            page_content=content,
            metadata={
                "source": file_path,
                "encoding": encoding,
                "loaded_at": datetime.now().isoformat()
            }
        )

# ===== 4. é™çº§ç­–ç•¥ =====
print("\n=== 4. é™çº§ç­–ç•¥ ===")

class FallbackLoader:
    """æ”¯æŒé™çº§çš„æ–‡æ¡£åŠ è½½å™¨"""

    def __init__(self):
        self.parsers = [
            ("é«˜çº§è§£æå™¨", self._advanced_parser),
            ("æ ‡å‡†è§£æå™¨", self._standard_parser),
            ("ç®€å•è§£æå™¨", self._simple_parser),
            ("æœ€åæ‰‹æ®µ", self._last_resort_parser)
        ]

    def load(self, file_path: str) -> Document:
        """ä½¿ç”¨é™çº§ç­–ç•¥åŠ è½½æ–‡æ¡£"""
        last_error = None

        for parser_name, parser_func in self.parsers:
            try:
                logger.info(f"å°è¯• {parser_name}...")
                doc = parser_func(file_path)
                logger.info(f"âœ… {parser_name} æˆåŠŸ")
                return doc
            except Exception as e:
                logger.warning(f"âŒ {parser_name} å¤±è´¥: {e}")
                last_error = e
                continue

        # æ‰€æœ‰è§£æå™¨éƒ½å¤±è´¥
        raise DocumentLoadError(
            ErrorType.FORMAT_ERROR,
            f"æ‰€æœ‰è§£æå™¨éƒ½å¤±è´¥",
            file_path,
            last_error
        )

    def _advanced_parser(self, file_path: str) -> Document:
        """é«˜çº§è§£æå™¨"""
        encoding_handler = EncodingHandler(confidence_threshold=0.9)
        content, encoding = encoding_handler.read_file(file_path)

        # é«˜çº§å¤„ç†
        content = self._advanced_processing(content)

        return Document(
            page_content=content,
            metadata={"source": file_path, "parser": "advanced", "encoding": encoding}
        )

    def _standard_parser(self, file_path: str) -> Document:
        """æ ‡å‡†è§£æå™¨"""
        encoding_handler = EncodingHandler(confidence_threshold=0.7)
        content, encoding = encoding_handler.read_file(file_path)

        return Document(
            page_content=content,
            metadata={"source": file_path, "parser": "standard", "encoding": encoding}
        )

    def _simple_parser(self, file_path: str) -> Document:
        """ç®€å•è§£æå™¨"""
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        return Document(
            page_content=content,
            metadata={"source": file_path, "parser": "simple", "encoding": "utf-8"}
        )

    def _last_resort_parser(self, file_path: str) -> Document:
        """æœ€åæ‰‹æ®µè§£æå™¨"""
        with open(file_path, 'rb') as f:
            raw_data = f.read()

        # å°è¯•å¤šç§è§£ç 
        for encoding in ['utf-8', 'gbk', 'iso-8859-1']:
            try:
                content = raw_data.decode(encoding, errors='ignore')
                if len(content.strip()) > 0:
                    return Document(
                        page_content=content,
                        metadata={"source": file_path, "parser": "last_resort", "encoding": encoding}
                    )
            except:
                continue

        raise Exception("æ— æ³•è§£ç æ–‡ä»¶")

    def _advanced_processing(self, content: str) -> str:
        """é«˜çº§å†…å®¹å¤„ç†"""
        import re
        content = re.sub(r'\n{3,}', '\n\n', content)
        content = re.sub(r' {2,}', ' ', content)
        return content.strip()

# ===== 5. å¥å£®çš„æ‰¹é‡åŠ è½½å™¨ =====
print("\n=== 5. å¥å£®çš„æ‰¹é‡åŠ è½½å™¨ ===")

class RobustBatchLoader:
    """å¥å£®çš„æ‰¹é‡æ–‡æ¡£åŠ è½½å™¨"""

    def __init__(self, max_retries: int = 3, timeout: int = 30):
        self.max_retries = max_retries
        self.timeout = timeout
        self.failed_files = []
        self.stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "by_error_type": {}
        }

    def load_batch(self, file_paths: List[str]) -> tuple[List[Document], Dict]:
        """
        æ‰¹é‡åŠ è½½æ–‡æ¡£
        è¿”å›: (æˆåŠŸçš„æ–‡æ¡£, ç»Ÿè®¡ä¿¡æ¯)
        """
        successful_docs = []

        logger.info(f"å¼€å§‹æ‰¹é‡åŠ è½½ {len(file_paths)} ä¸ªæ–‡ä»¶")

        for file_path in file_paths:
            self.stats["total"] += 1

            try:
                doc = self._load_single_file(file_path)
                if doc:
                    successful_docs.append(doc)
                    self.stats["success"] += 1
                    logger.info(f"âœ… æˆåŠŸ: {file_path}")
            except DocumentLoadError as e:
                self._handle_error(e)
            except Exception as e:
                self._handle_error(DocumentLoadError(
                    ErrorType.UNKNOWN,
                    str(e),
                    file_path,
                    e
                ))

        logger.info(f"æ‰¹é‡åŠ è½½å®Œæˆ: æˆåŠŸ {self.stats['success']}/{self.stats['total']}")

        return successful_docs, self.stats

    def _load_single_file(self, file_path: str) -> Optional[Document]:
        """åŠ è½½å•ä¸ªæ–‡ä»¶ï¼ˆå¸¦é‡è¯•ï¼‰"""
        fallback_loader = FallbackLoader()

        for attempt in range(self.max_retries):
            try:
                return fallback_loader.load(file_path)
            except Exception as e:
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.warning(f"å°è¯• {attempt + 1}/{self.max_retries} å¤±è´¥ï¼Œç­‰å¾… {wait_time}ç§’åé‡è¯•")
                    time.sleep(wait_time)
                    continue
                else:
                    raise

    def _handle_error(self, error: DocumentLoadError):
        """å¤„ç†é”™è¯¯"""
        self.stats["failed"] += 1

        # æŒ‰é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_type = error.error_type.value
        self.stats["by_error_type"][error_type] = self.stats["by_error_type"].get(error_type, 0) + 1

        # è®°å½•å¤±è´¥æ–‡ä»¶
        self.failed_files.append(error.to_dict())

        logger.error(f"âŒ å¤±è´¥: {error.file_path} - {error.message}")

    def get_failure_report(self) -> str:
        """ç”Ÿæˆå¤±è´¥æŠ¥å‘Š"""
        if not self.failed_files:
            return "æ‰€æœ‰æ–‡ä»¶åŠ è½½æˆåŠŸ"

        report = f"=== å¤±è´¥æŠ¥å‘Š ===\n"
        report += f"å¤±è´¥æ–‡ä»¶æ•°: {self.stats['failed']}/{self.stats['total']}\n\n"

        report += "æŒ‰é”™è¯¯ç±»å‹åˆ†å¸ƒ:\n"
        for error_type, count in self.stats["by_error_type"].items():
            report += f"  {error_type}: {count}\n"

        report += "\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:\n"
        for failure in self.failed_files:
            report += f"- {failure['file_path']}\n"
            report += f"  é”™è¯¯ç±»å‹: {failure['error_type']}\n"
            report += f"  é”™è¯¯ä¿¡æ¯: {failure['message']}\n"
            report += f"  æ—¶é—´: {failure['timestamp']}\n\n"

        return report

# ===== 6. ç›‘æ§å’Œå‘Šè­¦ =====
print("\n=== 6. ç›‘æ§å’Œå‘Šè­¦ ===")

class LoadingMonitor:
    """åŠ è½½ç›‘æ§å™¨"""

    def __init__(self, failure_threshold: float = 0.2, alert_callback: Callable = None):
        self.failure_threshold = failure_threshold
        self.alert_callback = alert_callback
        self.stats = {
            "total": 0,
            "success": 0,
            "failure": 0,
            "by_error_type": {}
        }

    def record_success(self, file_path: str):
        """è®°å½•æˆåŠŸ"""
        self.stats["total"] += 1
        self.stats["success"] += 1
        logger.debug(f"è®°å½•æˆåŠŸ: {file_path}")

    def record_failure(self, error: DocumentLoadError):
        """è®°å½•å¤±è´¥"""
        self.stats["total"] += 1
        self.stats["failure"] += 1

        error_type = error.error_type.value
        self.stats["by_error_type"][error_type] = self.stats["by_error_type"].get(error_type, 0) + 1

        logger.warning(f"è®°å½•å¤±è´¥: {error.file_path} - {error.error_type.value}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
        if self.should_alert():
            self._trigger_alert()

    def get_failure_rate(self) -> float:
        """è·å–å¤±è´¥ç‡"""
        if self.stats["total"] == 0:
            return 0.0
        return self.stats["failure"] / self.stats["total"]

    def should_alert(self) -> bool:
        """æ˜¯å¦åº”è¯¥å‘Šè­¦"""
        return self.get_failure_rate() > self.failure_threshold

    def _trigger_alert(self):
        """è§¦å‘å‘Šè­¦"""
        failure_rate = self.get_failure_rate()
        message = f"ğŸš¨ å‘Šè­¦: å¤±è´¥ç‡ {failure_rate:.1%} è¶…è¿‡é˜ˆå€¼ {self.failure_threshold:.1%}"

        logger.error(message)

        if self.alert_callback:
            self.alert_callback(message, self.stats)

    def get_report(self) -> str:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        failure_rate = self.get_failure_rate()

        report = f"""
=== åŠ è½½ç›‘æ§æŠ¥å‘Š ===
æ€»æ–‡ä»¶æ•°: {self.stats['total']}
æˆåŠŸ: {self.stats['success']} ({self.stats['success']/self.stats['total']*100:.1f}%)
å¤±è´¥: {self.stats['failure']} ({failure_rate*100:.1f}%)

å¤±è´¥ç±»å‹åˆ†å¸ƒ:
"""
        for error_type, count in self.stats["by_error_type"].items():
            report += f"  {error_type}: {count}\n"

        report += f"\nå‘Šè­¦çŠ¶æ€: {'ğŸš¨ éœ€è¦å…³æ³¨' if self.should_alert() else 'âœ… æ­£å¸¸'}"

        return report

# ===== 7. å®Œæ•´çš„ç”Ÿäº§çº§åŠ è½½ç³»ç»Ÿ =====
print("\n=== 7. å®Œæ•´çš„ç”Ÿäº§çº§åŠ è½½ç³»ç»Ÿ ===")

class ProductionDocumentLoader:
    """ç”Ÿäº§çº§æ–‡æ¡£åŠ è½½ç³»ç»Ÿ"""

    def __init__(
        self,
        max_retries: int = 3,
        timeout: int = 30,
        failure_threshold: float = 0.2,
        alert_callback: Callable = None
    ):
        self.batch_loader = RobustBatchLoader(max_retries, timeout)
        self.monitor = LoadingMonitor(failure_threshold, alert_callback)

    def load(self, file_paths: List[str]) -> tuple[List[Document], Dict]:
        """
        åŠ è½½æ–‡æ¡£å¹¶ç›‘æ§
        è¿”å›: (æ–‡æ¡£åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info(f"=== ç”Ÿäº§çº§æ–‡æ¡£åŠ è½½ç³»ç»Ÿ ===")
        logger.info(f"å¾…åŠ è½½æ–‡ä»¶æ•°: {len(file_paths)}")

        # æ‰¹é‡åŠ è½½
        documents, stats = self.batch_loader.load_batch(file_paths)

        # æ›´æ–°ç›‘æ§
        for _ in range(stats["success"]):
            self.monitor.record_success("file")

        for failure in self.batch_loader.failed_files:
            error = DocumentLoadError(
                ErrorType[failure["error_type"].replace(" ", "_").upper()],
                failure["message"],
                failure["file_path"]
            )
            self.monitor.record_failure(error)

        # ç”ŸæˆæŠ¥å‘Š
        logger.info("\n" + self.monitor.get_report())

        if self.batch_loader.failed_files:
            logger.warning("\n" + self.batch_loader.get_failure_report())

        return documents, stats

# ===== 8. ä½¿ç”¨ç¤ºä¾‹ =====
print("\n=== 8. ä½¿ç”¨ç¤ºä¾‹ ===")

def alert_callback(message: str, stats: Dict):
    """å‘Šè­¦å›è°ƒå‡½æ•°"""
    print(f"\nğŸ“§ å‘é€å‘Šè­¦é‚®ä»¶: {message}")
    print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")

def example_usage():
    """å®Œæ•´ä½¿ç”¨ç¤ºä¾‹"""

    # åˆ›å»ºç”Ÿäº§çº§åŠ è½½å™¨
    loader = ProductionDocumentLoader(
        max_retries=3,
        timeout=30,
        failure_threshold=0.2,
        alert_callback=alert_callback
    )

    # å‡†å¤‡æ–‡ä»¶åˆ—è¡¨
    file_paths = [
        "docs/report1.txt",
        "docs/report2.txt",
        "docs/report3.txt",
        "docs/missing.txt",  # ä¸å­˜åœ¨çš„æ–‡ä»¶
        "docs/corrupted.txt"  # æŸåçš„æ–‡ä»¶
    ]

    # åŠ è½½æ–‡æ¡£
    documents, stats = loader.load(file_paths)

    print(f"\n=== åŠ è½½ç»“æœ ===")
    print(f"æˆåŠŸåŠ è½½: {len(documents)} ä¸ªæ–‡æ¡£")
    print(f"å¤±è´¥: {stats['failed']} ä¸ªæ–‡ä»¶")

    # ä½¿ç”¨åŠ è½½çš„æ–‡æ¡£
    if documents:
        print(f"\nç¬¬ä¸€ä¸ªæ–‡æ¡£å†…å®¹é¢„è§ˆ:")
        print(documents[0].page_content[:200])

# è¿è¡Œç¤ºä¾‹
# example_usage()

print("\n=== ç¤ºä¾‹ä»£ç æ‰§è¡Œå®Œæˆ ===")
print("\nä½¿ç”¨è¯´æ˜:")
print("1. å‡†å¤‡è¦åŠ è½½çš„æ–‡æ¡£")
print("2. é…ç½®é‡è¯•æ¬¡æ•°å’Œå¤±è´¥é˜ˆå€¼")
print("3. è®¾ç½®å‘Šè­¦å›è°ƒå‡½æ•°")
print("4. è¿è¡ŒåŠ è½½ç³»ç»Ÿ")
print("\nåŠŸèƒ½:")
print("- æ™ºèƒ½ç¼–ç æ£€æµ‹")
print("- è‡ªåŠ¨é‡è¯•æœºåˆ¶")
print("- é™çº§ç­–ç•¥")
print("- é”™è¯¯åˆ†ç±»å’Œç»Ÿè®¡")
print("- å®æ—¶ç›‘æ§å’Œå‘Šè­¦")
print("- è¯¦ç»†çš„å¤±è´¥æŠ¥å‘Š")
```

---

## è¿è¡Œè¾“å‡ºç¤ºä¾‹

```
=== ç”Ÿäº§çº§æ–‡æ¡£åŠ è½½ç³»ç»Ÿ ===
å¾…åŠ è½½æ–‡ä»¶æ•°: 5

å¼€å§‹æ‰¹é‡åŠ è½½ 5 ä¸ªæ–‡ä»¶
å°è¯• é«˜çº§è§£æå™¨...
âœ… é«˜çº§è§£æå™¨ æˆåŠŸ
âœ… æˆåŠŸ: docs/report1.txt
å°è¯• é«˜çº§è§£æå™¨...
âœ… é«˜çº§è§£æå™¨ æˆåŠŸ
âœ… æˆåŠŸ: docs/report2.txt
å°è¯• é«˜çº§è§£æå™¨...
âŒ é«˜çº§è§£æå™¨ å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨
å°è¯• æ ‡å‡†è§£æå™¨...
âŒ æ ‡å‡†è§£æå™¨ å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨
âŒ å¤±è´¥: docs/missing.txt - æ–‡ä»¶ä¸å­˜åœ¨

=== åŠ è½½ç›‘æ§æŠ¥å‘Š ===
æ€»æ–‡ä»¶æ•°: 5
æˆåŠŸ: 3 (60.0%)
å¤±è´¥: 2 (40.0%)

å¤±è´¥ç±»å‹åˆ†å¸ƒ:
  æ–‡ä»¶ä¸å­˜åœ¨: 1
  æ–‡ä»¶æŸå: 1

å‘Šè­¦çŠ¶æ€: ğŸš¨ éœ€è¦å…³æ³¨

ğŸ“§ å‘é€å‘Šè­¦é‚®ä»¶: ğŸš¨ å‘Šè­¦: å¤±è´¥ç‡ 40.0% è¶…è¿‡é˜ˆå€¼ 20.0%

=== å¤±è´¥æŠ¥å‘Š ===
å¤±è´¥æ–‡ä»¶æ•°: 2/5

æŒ‰é”™è¯¯ç±»å‹åˆ†å¸ƒ:
  æ–‡ä»¶ä¸å­˜åœ¨: 1
  æ–‡ä»¶æŸå: 1

å¤±è´¥æ–‡ä»¶åˆ—è¡¨:
- docs/missing.txt
  é”™è¯¯ç±»å‹: æ–‡ä»¶ä¸å­˜åœ¨
  é”™è¯¯ä¿¡æ¯: æ–‡ä»¶ä¸å­˜åœ¨
  æ—¶é—´: 2026-02-15T12:00:00

- docs/corrupted.txt
  é”™è¯¯ç±»å‹: æ–‡ä»¶æŸå
  é”™è¯¯ä¿¡æ¯: æ— æ³•è§£ææ–‡ä»¶
  æ—¶é—´: 2026-02-15T12:00:01
```

---

## å…³é”®è¦ç‚¹

### 1. é”™è¯¯å¤„ç†å±‚æ¬¡

```python
# ä¸‰å±‚é”™è¯¯å¤„ç†
1. é¢„é˜²æ€§æ£€æŸ¥ï¼ˆæ–‡ä»¶å­˜åœ¨ã€æƒé™ï¼‰
2. é‡è¯•æœºåˆ¶ï¼ˆä¸´æ—¶æ€§é”™è¯¯ï¼‰
3. é™çº§ç­–ç•¥ï¼ˆæ°¸ä¹…æ€§é”™è¯¯ï¼‰
```

### 2. é‡è¯•ç­–ç•¥

```python
# æŒ‡æ•°é€€é¿
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
```

### 3. ç›‘æ§æŒ‡æ ‡

- æˆåŠŸç‡/å¤±è´¥ç‡
- é”™è¯¯ç±»å‹åˆ†å¸ƒ
- å¤„ç†æ—¶é—´
- èµ„æºä½¿ç”¨

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è®¾ç½®åˆé€‚çš„é‡è¯•æ¬¡æ•°ï¼Ÿ

```python
# æ ¹æ®é”™è¯¯ç±»å‹è®¾ç½®
- ç½‘ç»œé”™è¯¯: 3-5æ¬¡
- ç¼–ç é”™è¯¯: 1-2æ¬¡
- æ–‡ä»¶ä¸å­˜åœ¨: 0æ¬¡ï¼ˆä¸é‡è¯•ï¼‰
```

### Q2: å¦‚ä½•é¿å…é‡è¯•é£æš´ï¼Ÿ

```python
# ä½¿ç”¨æŒ‡æ•°é€€é¿
wait_exponential(multiplier=1, min=2, max=10)

# æ·»åŠ éšæœºæŠ–åŠ¨
wait_exponential(multiplier=1, min=2, max=10) + wait_random(0, 2)
```

### Q3: å¦‚ä½•å¤„ç†å†…å­˜ä¸è¶³ï¼Ÿ

```python
# åˆ†æ‰¹å¤„ç†
batch_size = 100
for i in range(0, len(files), batch_size):
    batch = files[i:i+batch_size]
    process_batch(batch)
    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
```

---

## æ‰©å±•é˜…è¯»

- [Python Error Handling](https://realpython.com/python-exceptions/) (2025)
- [Tenacity Documentation](https://tenacity.readthedocs.io/) (2025)
- [Circuit Breaker Pattern](https://martinfowler.com/bliki/CircuitBreaker.html) (2025)

---

**ç‰ˆæœ¬ï¼š** v1.0
**æœ€åæ›´æ–°ï¼š** 2026-02-15
**ä¸‹ä¸€æ­¥ï¼š** é˜…è¯» [09_åŒ–éª¨ç»µæŒ.md](./09_åŒ–éª¨ç»µæŒ.md)
