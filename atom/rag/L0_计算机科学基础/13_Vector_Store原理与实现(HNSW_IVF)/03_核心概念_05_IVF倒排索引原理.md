# 核心概念05：IVF倒排索引原理

> 理解IVF通过聚类分区实现大规模向量检索

---

## 概述

**IVF（Inverted File Index）** 是基于聚类的向量检索算法，适合大规模场景。

**核心特点**：
- 内存效率高（结合PQ压缩64倍）
- 适用规模：>1000万向量
- 时间复杂度：O(√n)

---

## 1. 核心思想

### 1.1 倒排索引类比

**文本检索中的倒排索引**：
```
文档1: "Python 编程"
文档2: "机器 学习"
文档3: "Python 学习"

倒排索引：
Python → [文档1, 文档3]
编程 → [文档1]
机器 → [文档2]
学习 → [文档2, 文档3]
```

**向量检索中的IVF**：
```
聚类中心1 → [向量1, 向量5, 向量9]
聚类中心2 → [向量2, 向量6, 向量10]
聚类中心3 → [向量3, 向量7, 向量11]
...
```

---

### 1.2 三个阶段

**1. 训练阶段**：K-means聚类
```python
from sklearn.cluster import KMeans

# 训练聚类
kmeans = KMeans(n_clusters=100)
kmeans.fit(training_vectors)

# 得到100个聚类中心
cluster_centers = kmeans.cluster_centers_
```

**2. 添加阶段**：分配到聚类
```python
# 预测每个向量属于哪个聚类
labels = kmeans.predict(vectors)

# 构建倒排列表
inverted_lists = {}
for i, label in enumerate(labels):
    if label not in inverted_lists:
        inverted_lists[label] = []
    inverted_lists[label].append(vectors[i])
```

**3. 查询阶段**：只搜索最近的几个聚类
```python
# 找到最近的nprobe个聚类中心
distances = np.linalg.norm(cluster_centers - query, axis=1)
nearest_clusters = np.argsort(distances)[:nprobe]

# 只在这些聚类中搜索
candidates = []
for cluster_id in nearest_clusters:
    candidates.extend(inverted_lists[cluster_id])

# 计算距离并排序
results = sorted(candidates, key=lambda v: np.linalg.norm(v - query))[:k]
```

---

## 2. 完整实现

```python
import numpy as np
from sklearn.cluster import KMeans

class IVF:
    """IVF倒排索引实现"""

    def __init__(self, n_clusters=100):
        self.n_clusters = n_clusters
        self.kmeans = None
        self.inverted_lists = {}
        self.metadata = {}

    def train(self, vectors):
        """训练聚类"""
        print(f"训练{self.n_clusters}个聚类中心...")
        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)
        self.kmeans.fit(vectors)
        print("训练完成")

    def add(self, vectors, doc_ids):
        """添加向量"""
        if self.kmeans is None:
            raise ValueError("请先调用train()训练聚类")

        # 分配到聚类
        labels = self.kmeans.predict(vectors)

        # 构建倒排列表
        for i, label in enumerate(labels):
            if label not in self.inverted_lists:
                self.inverted_lists[label] = []

            self.inverted_lists[label].append({
                'vector': vectors[i],
                'doc_id': doc_ids[i]
            })

        print(f"添加了{len(vectors)}个向量")

    def search(self, query, nprobe=10, k=10):
        """搜索Top-K"""
        if self.kmeans is None:
            raise ValueError("请先调用train()训练聚类")

        # 找到最近的nprobe个聚类中心
        cluster_centers = self.kmeans.cluster_centers_
        distances = np.linalg.norm(cluster_centers - query, axis=1)
        nearest_clusters = np.argsort(distances)[:nprobe]

        print(f"搜索{nprobe}个聚类（共{self.n_clusters}个）")

        # 收集候选向量
        candidates = []
        for cluster_id in nearest_clusters:
            if cluster_id in self.inverted_lists:
                for item in self.inverted_lists[cluster_id]:
                    dist = np.linalg.norm(item['vector'] - query)
                    candidates.append((dist, item['doc_id']))

        # 排序返回Top-K
        candidates.sort()
        return candidates[:k]

# 使用示例
vectors = np.random.randn(10000, 768).astype('float32')
doc_ids = list(range(10000))

ivf = IVF(n_clusters=100)
ivf.train(vectors[:1000])  # 用1000个样本训练
ivf.add(vectors, doc_ids)

query = np.random.randn(768).astype('float32')
results = ivf.search(query, nprobe=10, k=10)

print("\nTop-10结果:")
for dist, doc_id in results:
    print(f"文档{doc_id}: 距离{dist:.3f}")
```

---

## 3. 关键参数

### 3.1 nlist（聚类数量）

**定义**：聚类中心的数量

**选择规则**：
```python
# 经验公式
nlist = int(np.sqrt(n_vectors))

# 示例
n_vectors = 1000000
nlist = int(np.sqrt(1000000))  # 1000
```

**影响**：
- nlist越大：搜索越精确，但训练时间越长
- nlist越小：训练快，但搜索精度下降

**推荐值**：
- 100万向量：nlist=1000
- 1000万向量：nlist=3162
- 1亿向量：nlist=10000

---

### 3.2 nprobe（搜索聚类数）

**定义**：查询时搜索的聚类数量

**影响**：
- nprobe越大：召回率越高，查询延迟越高
- nprobe越小：查询快，但召回率下降

**推荐值**：
```python
# 快速查询
nprobe = 1

# 平衡配置
nprobe = 10

# 高召回率
nprobe = 32
```

**召回率对比**：
```
nprobe=1:  召回率~60%，延迟~5ms
nprobe=10: 召回率~85%，延迟~20ms
nprobe=32: 召回率~92%，延迟~50ms
```

---

## 4. 性能分析

### 4.1 时间复杂度

**训练**：O(n × k × i)
- n：向量数量
- k：聚类数量
- i：迭代次数

**查询**：O(nprobe × n/nlist)
- 近似为O(√n)

---

### 4.2 空间复杂度

**内存占用**：
```
聚类中心：nlist × d × 4字节
向量：n × d × 4字节
倒排列表：n × 4字节（索引）

示例（100万向量，768维，nlist=1000）：
聚类中心：1000 × 768 × 4 = 3MB
向量：100万 × 768 × 4 = 3GB
倒排列表：100万 × 4 = 4MB
总计：~3GB
```

---

## 5. 与HNSW对比

| 维度 | IVF | HNSW |
|------|-----|------|
| **时间复杂度** | O(√n) | O(log n) |
| **召回率** | 85-95% | 95-98% |
| **内存占用** | 低 | 高 |
| **构建时间** | 短 | 长 |
| **适用规模** | >1000万 | <1000万 |
| **GPU加速** | 支持 | 不支持 |

---

## 6. 在RAG系统中的应用

### 6.1 FAISS实现

```python
import faiss

# 创建IVF索引
dim = 768
nlist = 100

quantizer = faiss.IndexFlatL2(dim)
index = faiss.IndexIVFFlat(quantizer, dim, nlist)

# 训练
index.train(training_vectors)

# 添加向量
index.add(vectors)

# 查询
index.nprobe = 10
distances, indices = index.search(query, k=10)
```

---

### 6.2 Milvus实现

```python
from pymilvus import Collection, connections

connections.connect(host="localhost", port="19530")

# 创建IVF索引
index_params = {
    "metric_type": "COSINE",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 1024}
}

collection.create_index(
    field_name="embedding",
    index_params=index_params
)

# 查询
search_params = {
    "metric_type": "COSINE",
    "params": {"nprobe": 10}
}

results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

---

## 7. 优化技巧

### 7.1 冗余分配

**问题**：向量可能在聚类边界，分配到错误的聚类

**解决**：分配到多个聚类
```python
# 分配到最近的3个聚类
distances = np.linalg.norm(cluster_centers - vector, axis=1)
top3_clusters = np.argsort(distances)[:3]

for cluster_id in top3_clusters:
    inverted_lists[cluster_id].append(vector)
```

**效果**：召回率↑10%，内存↑3倍

---

### 7.2 自适应nprobe

```python
def adaptive_nprobe(query_complexity):
    """根据查询复杂度动态调整nprobe"""
    if query_complexity == "simple":
        return 5
    elif query_complexity == "medium":
        return 10
    else:
        return 20
```

---

## 8. 2025-2026最新优化

### 8.1 NVIDIA cuVS（2025）

**来源**：NVIDIA Developer Blog 2025

**GPU加速**：
- IVF-PQ构建加速4.7倍
- 搜索延迟降低8倍
- 支持动态批处理

---

### 8.2 Oracle IVF（2025）

**来源**：Oracle Database 2025

**平面分区索引优化**：
- 数据库原生集成
- SQL查询支持

---

## 总结

### 核心要点

1. **聚类分区**：K-means聚类，构建倒排列表
2. **两个参数**：nlist（聚类数）、nprobe（搜索聚类数）
3. **时间复杂度**：O(√n)
4. **内存效率**：适合大规模
5. **GPU加速**：2025年重大突破

### 参数推荐

| 规模 | nlist | nprobe |
|------|-------|--------|
| 100万 | 1000 | 10 |
| 1000万 | 3162 | 10 |
| 1亿 | 10000 | 32 |

### 下一步

学习 `03_核心概念_06_IVF_2025年优化技术.md`，了解最新优化。
