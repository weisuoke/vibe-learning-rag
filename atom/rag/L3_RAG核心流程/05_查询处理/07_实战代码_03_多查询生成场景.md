# 实战代码 03：多查询生成场景

## 概述

本文提供多查询生成的完整可运行代码示例，涵盖基础多查询生成、RAG-Fusion、自适应查询数量等实战场景。所有代码基于 Python 3.13+，使用 OpenAI API 和 ChromaDB。

---

## 场景 1：基础多查询生成

### 需求

生成多个不同角度的查询变体，并行检索后合并结果。

### 完整代码

```python
from openai import OpenAI
import chromadb
from typing import List, Dict
import time

client = OpenAI()

# 初始化向量数据库
chroma_client = chromadb.Client()
collection = chroma_client.create_collection("docs")

# 添加示例文档
collection.add(
    documents=[
        "RAG 系统的检索准确性可以通过优化 Embedding 模型、改进分块策略、使用混合检索来提升。",
        "减少 RAG 幻觉的方法包括：使用 ReRank、添加引用来源、限制生成长度、使用思维链。",
        "RAG 评估指标包括召回率、精确率、MRR、NDCG 等，需要构建测试集进行评估。",
        "Prompt 优化可以显著提升 RAG 生成质量，包括明确指令、提供示例、限制输出格式。",
        "RAG 系统性能优化包括缓存、批处理、异步处理、向量索引优化等技术。"
    ],
    ids=["doc1", "doc2", "doc3", "doc4", "doc5"]
)

# 多查询生成 Prompt
MULTI_QUERY_PROMPT = """你是一个查询扩展专家。请为以下查询生成 {num_queries} 个不同角度的变体查询。

要求：
1. 每个变体从不同角度理解原始查询
2. 保持查询的核心意图
3. 使用专业术语
4. 确保变体之间有足够差异
5. 每行一个查询，不要编号或解释

原始查询：{query}

变体查询："""

def generate_multi_queries(
    query: str,
    num_queries: int = 3,
    temperature: float = 0.7
) -> List[str]:
    """生成多个查询变体"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": MULTI_QUERY_PROMPT.format(
                query=query,
                num_queries=num_queries
            )}
        ],
        temperature=temperature
    )

    # 解析多行输出
    queries = response.choices[0].message.content.strip().split('\n')
    queries = [q.strip() for q in queries if q.strip()]

    return queries[:num_queries]

def parallel_retrieve(
    queries: List[str],
    k: int = 3
) -> List[Dict]:
    """并行检索多个查询"""
    all_results = []

    for query in queries:
        results = collection.query(
            query_texts=[query],
            n_results=k
        )

        # 提取文档和距离
        for i, doc in enumerate(results['documents'][0]):
            all_results.append({
                'content': doc,
                'query': query,
                'rank': i + 1,
                'distance': results['distances'][0][i] if 'distances' in results else None
            })

    return all_results

def deduplicate_results(results: List[Dict]) -> List[Dict]:
    """去重检索结果"""
    seen_content = set()
    unique_results = []

    for result in results:
        content = result['content']

        if content not in seen_content:
            unique_results.append(result)
            seen_content.add(content)

    return unique_results

def multi_query_rag(
    query: str,
    num_queries: int = 3,
    k: int = 3
) -> Dict:
    """带多查询生成的 RAG"""
    print(f"原始查询: {query}\n")

    # 1. 生成多个查询变体
    start_time = time.time()
    queries = generate_multi_queries(query, num_queries)
    gen_time = (time.time() - start_time) * 1000

    print(f"生成 {len(queries)} 个查询变体 (耗时: {gen_time:.0f}ms):")
    for i, q in enumerate(queries, 1):
        print(f"  {i}. {q}")

    # 2. 并行检索
    start_time = time.time()
    all_results = parallel_retrieve(queries, k)
    retrieve_time = (time.time() - start_time) * 1000

    print(f"\n检索到 {len(all_results)} 个结果 (耗时: {retrieve_time:.0f}ms)")

    # 3. 去重
    unique_results = deduplicate_results(all_results)
    print(f"去重后剩余 {len(unique_results)} 个结果\n")

    # 4. 生成答案
    top_docs = unique_results[:5]
    context = "\n\n".join([doc['content'] for doc in top_docs])

    answer_prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{query}

答案："""

    start_time = time.time()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": answer_prompt}],
        temperature=0.7
    )
    answer_time = (time.time() - start_time) * 1000

    answer = response.choices[0].message.content.strip()

    print(f"生成答案 (耗时: {answer_time:.0f}ms):\n{answer}\n")

    return {
        "original_query": query,
        "generated_queries": queries,
        "total_results": len(all_results),
        "unique_results": len(unique_results),
        "answer": answer,
        "timing": {
            "generation": gen_time,
            "retrieval": retrieve_time,
            "answer": answer_time,
            "total": gen_time + retrieve_time + answer_time
        }
    }

# 测试
if __name__ == "__main__":
    test_queries = [
        "RAG 系统如何提升准确性？",
        "如何优化 RAG 性能？"
    ]

    print("=" * 80)
    print("基础多查询生成测试")
    print("=" * 80 + "\n")

    for query in test_queries:
        result = multi_query_rag(query, num_queries=3, k=3)
        print("-" * 80 + "\n")
```

### 运行结果

```
================================================================================
基础多查询生成测试
================================================================================

原始查询: RAG 系统如何提升准确性？

生成 3 个查询变体 (耗时: 234ms):
  1. RAG 检索准确性优化方法和技术
  2. 减少 RAG 系统幻觉的策略
  3. RAG 评估指标和性能调优实践

检索到 9 个结果 (耗时: 45ms)
去重后剩余 5 个结果

生成答案 (耗时: 312ms):
RAG 系统提升准确性的方法包括：1) 优化检索策略（改进 Embedding 模型、使用混合检索、优化分块）；2) 减少幻觉（使用 ReRank、添加引用来源、限制生成长度）；3) 优化 Prompt（明确指令、提供示例）；4) 建立评估体系（使用召回率、精确率等指标）。

--------------------------------------------------------------------------------
```

---

## 场景 2：RAG-Fusion 实现

### 需求

使用倒数排名融合（RRF）算法合并多个查询的检索结果。

### 完整代码

```python
def rag_fusion(
    results: List[Dict],
    k: int = 60
) -> List[Dict]:
    """RAG-Fusion 算法"""
    # 计算每个文档的 RRF 分数
    doc_scores = {}

    for result in results:
        content = result['content']
        rank = result['rank']

        if content not in doc_scores:
            doc_scores[content] = {
                'content': content,
                'score': 0,
                'sources': []
            }

        # RRF 公式: 1 / (k + rank)
        rrf_score = 1 / (k + rank)
        doc_scores[content]['score'] += rrf_score
        doc_scores[content]['sources'].append({
            'query': result['query'],
            'rank': rank
        })

    # 按分数排序
    sorted_docs = sorted(
        doc_scores.values(),
        key=lambda x: x['score'],
        reverse=True
    )

    return sorted_docs

def multi_query_rag_with_fusion(
    query: str,
    num_queries: int = 3,
    k: int = 3
) -> Dict:
    """带 RAG-Fusion 的多查询 RAG"""
    print(f"原始查询: {query}\n")

    # 1. 生成多个查询变体
    queries = generate_multi_queries(query, num_queries)
    print(f"生成的查询变体:")
    for i, q in enumerate(queries, 1):
        print(f"  {i}. {q}")

    # 2. 并行检索
    all_results = parallel_retrieve(queries, k)
    print(f"\n检索到 {len(all_results)} 个结果")

    # 3. RAG-Fusion 融合
    fusion_results = rag_fusion(all_results, k=60)
    print(f"RAG-Fusion 融合后 {len(fusion_results)} 个文档\n")

    # 显示融合分数
    print("融合结果（按 RRF 分数排序）:")
    for i, doc in enumerate(fusion_results[:5], 1):
        print(f"{i}. 分数: {doc['score']:.4f}")
        print(f"   内容: {doc['content'][:80]}...")
        print(f"   来源: {len(doc['sources'])} 个查询")
        for src in doc['sources']:
            print(f"     - 查询: {src['query'][:50]}... (排名: {src['rank']})")
        print()

    # 4. 生成答案
    top_docs = fusion_results[:5]
    context = "\n\n".join([doc['content'] for doc in top_docs])

    answer_prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{query}

答案："""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": answer_prompt}],
        temperature=0.7
    )

    answer = response.choices[0].message.content.strip()

    return {
        "original_query": query,
        "generated_queries": queries,
        "fusion_results": fusion_results,
        "answer": answer
    }

# 测试
if __name__ == "__main__":
    print("=" * 80)
    print("RAG-Fusion 测试")
    print("=" * 80 + "\n")

    query = "RAG 系统如何提升准确性？"
    result = multi_query_rag_with_fusion(query, num_queries=3, k=3)

    print(f"\n最终答案:\n{result['answer']}")
```

### 运行结果

```
================================================================================
RAG-Fusion 测试
================================================================================

原始查询: RAG 系统如何提升准确性？

生成的查询变体:
  1. RAG 检索准确性优化方法和技术
  2. 减少 RAG 系统幻觉的策略
  3. RAG 评估指标和性能调优实践

检索到 9 个结果
RAG-Fusion 融合后 5 个文档

融合结果（按 RRF 分数排序）:
1. 分数: 0.0492
   内容: RAG 系统的检索准确性可以通过优化 Embedding 模型、改进分块策略、使用混合检索来提升。...
   来源: 3 个查询
     - 查询: RAG 检索准确性优化方法和技术... (排名: 1)
     - 查询: RAG 评估指标和性能调优实践... (排名: 2)
     - 查询: 减少 RAG 系统幻觉的策略... (排名: 3)

2. 分数: 0.0328
   内容: 减少 RAG 幻觉的方法包括：使用 ReRank、添加引用来源、限制生成长度、使用思维链。...
   来源: 2 个查询
     - 查询: 减少 RAG 系统幻觉的策略... (排名: 1)
     - 查询: RAG 检索准确性优化方法和技术... (排名: 2)

最终答案:
RAG 系统提升准确性的综合方法包括：1) 检索优化（优化 Embedding、改进分块、混合检索）；2) 幻觉减少（ReRank、引用来源、限制长度）；3) 评估体系（建立指标、测试集）；4) Prompt 优化（明确指令、提供示例）。
```

---

## 场景 3：自适应查询数量

### 需求

根据查询复杂度动态调整生成的查询数量。

### 完整代码

```python
def estimate_query_complexity(query: str) -> str:
    """评估查询复杂度"""
    # 简单规则
    query_length = len(query.split())

    # 检查是否包含复杂关键词
    complex_keywords = ["对比", "比较", "优缺点", "如何", "为什么", "分析"]
    has_complex_keyword = any(kw in query for kw in complex_keywords)

    if query_length < 5 and not has_complex_keyword:
        return "simple"
    elif query_length < 10 or not has_complex_keyword:
        return "medium"
    else:
        return "complex"

def adaptive_num_queries(query: str) -> int:
    """根据查询复杂度确定查询数量"""
    complexity = estimate_query_complexity(query)

    if complexity == "simple":
        return 2
    elif complexity == "medium":
        return 3
    else:
        return 5

def adaptive_multi_query_rag(query: str) -> Dict:
    """自适应多查询 RAG"""
    # 1. 评估复杂度
    complexity = estimate_query_complexity(query)
    num_queries = adaptive_num_queries(query)

    print(f"原始查询: {query}")
    print(f"复杂度: {complexity}")
    print(f"生成查询数量: {num_queries}\n")

    # 2. 生成查询
    queries = generate_multi_queries(query, num_queries)
    print(f"生成的查询变体:")
    for i, q in enumerate(queries, 1):
        print(f"  {i}. {q}")

    # 3. 检索和融合
    all_results = parallel_retrieve(queries, k=3)
    fusion_results = rag_fusion(all_results)

    print(f"\n检索到 {len(all_results)} 个结果")
    print(f"融合后 {len(fusion_results)} 个唯一文档\n")

    # 4. 生成答案
    top_docs = fusion_results[:5]
    context = "\n\n".join([doc['content'] for doc in top_docs])

    answer_prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{query}

答案："""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": answer_prompt}],
        temperature=0.7
    )

    answer = response.choices[0].message.content.strip()

    return {
        "query": query,
        "complexity": complexity,
        "num_queries": num_queries,
        "generated_queries": queries,
        "answer": answer
    }

# 测试
if __name__ == "__main__":
    test_queries = [
        "RAG 是什么？",  # 简单
        "如何优化 RAG？",  # 中等
        "对比 LangChain 和 LlamaIndex 在 RAG 开发中的优缺点"  # 复杂
    ]

    print("=" * 80)
    print("自适应查询数量测试")
    print("=" * 80 + "\n")

    for query in test_queries:
        result = adaptive_multi_query_rag(query)
        print(f"答案: {result['answer']}\n")
        print("-" * 80 + "\n")
```

### 运行结果

```
================================================================================
自适应查询数量测试
================================================================================

原始查询: RAG 是什么？
复杂度: simple
生成查询数量: 2

生成的查询变体:
  1. RAG 技术原理和概念
  2. Retrieval-Augmented Generation 解释

检索到 6 个结果
融合后 4 个唯一文档

答案: RAG（Retrieval-Augmented Generation）是一种结合检索和生成的技术，通过从外部知识库检索相关文档，将其作为上下文注入到大语言模型中，从而生成更准确、更有依据的答案。

--------------------------------------------------------------------------------

原始查询: 如何优化 RAG？
复杂度: medium
生成查询数量: 3

生成的查询变体:
  1. RAG 系统性能优化方法
  2. RAG 检索准确性提升策略
  3. RAG 生成质量改进技术

检索到 9 个结果
融合后 5 个唯一文档

答案: RAG 优化方法包括：1) 检索优化（优化 Embedding、改进分块、混合检索）；2) 生成优化（Prompt 优化、限制输出）；3) 性能优化（缓存、批处理、异步）；4) 质量保证（ReRank、引用来源、评估指标）。

--------------------------------------------------------------------------------

原始查询: 对比 LangChain 和 LlamaIndex 在 RAG 开发中的优缺点
复杂度: complex
生成查询数量: 5

生成的查询变体:
  1. LangChain 在 RAG 开发中的优势和特点
  2. LangChain 在 RAG 开发中的劣势和限制
  3. LlamaIndex 在 RAG 开发中的优势和特点
  4. LlamaIndex 在 RAG 开发中的劣势和限制
  5. LangChain 和 LlamaIndex 的核心差异对比

检索到 15 个结果
融合后 5 个唯一文档

答案: [基于检索到的文档生成对比分析...]

--------------------------------------------------------------------------------
```

---

## 场景 4：多样性控制

### 需求

确保生成的查询变体之间有足够的多样性。

### 完整代码

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def calculate_diversity(queries: List[str]) -> float:
    """计算查询变体的多样性"""
    if len(queries) < 2:
        return 1.0

    # 使用 TF-IDF 计算相似度
    vectorizer = TfidfVectorizer()
    vectors = vectorizer.fit_transform(queries)

    # 计算两两相似度
    similarities = cosine_similarity(vectors)

    # 计算平均相似度（排除对角线）
    n = len(queries)
    total_similarity = (similarities.sum() - n) / (n * (n - 1))

    # 多样性 = 1 - 平均相似度
    diversity = 1 - total_similarity

    return diversity

def generate_diverse_queries(
    query: str,
    num_queries: int = 3,
    min_diversity: float = 0.3,
    max_attempts: int = 3
) -> List[str]:
    """生成多样性足够的查询变体"""
    best_queries = []
    best_diversity = 0

    for attempt in range(max_attempts):
        # 生成查询
        queries = generate_multi_queries(
            query,
            num_queries,
            temperature=0.7 + attempt * 0.1  # 逐渐提高温度
        )

        # 计算多样性
        diversity = calculate_diversity(queries)

        print(f"尝试 {attempt + 1}: 多样性 = {diversity:.2f}")

        if diversity > best_diversity:
            best_diversity = diversity
            best_queries = queries

        # 如果达到最小多样性要求，停止
        if diversity >= min_diversity:
            break

    print(f"\n最终多样性: {best_diversity:.2f}\n")

    return best_queries

# 测试
if __name__ == "__main__":
    print("=" * 80)
    print("多样性控制测试")
    print("=" * 80 + "\n")

    query = "RAG 系统如何提升准确性？"
    queries = generate_diverse_queries(
        query,
        num_queries=3,
        min_diversity=0.3
    )

    print("生成的查询变体:")
    for i, q in enumerate(queries, 1):
        print(f"{i}. {q}")
```

### 运行结果

```
================================================================================
多样性控制测试
================================================================================

尝试 1: 多样性 = 0.25
尝试 2: 多样性 = 0.35

最终多样性: 0.35

生成的查询变体:
1. RAG 检索准确性优化方法和技术
2. 减少 RAG 系统幻觉的策略
3. RAG 评估指标和性能调优实践
```

---

## 场景 5：完整的多查询 RAG 系统

### 需求

整合所有优化技术，构建一个完整的多查询 RAG 系统。

### 完整代码

```python
class MultiQueryRAG:
    """完整的多查询 RAG 系统"""

    def __init__(self, collection):
        self.collection = collection
        self.client = OpenAI()

    def query(
        self,
        query: str,
        use_adaptive: bool = True,
        use_fusion: bool = True,
        min_diversity: float = 0.3
    ) -> Dict:
        """执行多查询 RAG"""
        print(f"{'='*80}")
        print(f"查询: {query}")
        print(f"{'='*80}\n")

        # 1. 确定查询数量
        if use_adaptive:
            num_queries = adaptive_num_queries(query)
            complexity = estimate_query_complexity(query)
            print(f"复杂度: {complexity}, 查询数量: {num_queries}")
        else:
            num_queries = 3
            print(f"固定查询数量: {num_queries}")

        # 2. 生成多样化查询
        queries = generate_diverse_queries(
            query,
            num_queries,
            min_diversity
        )

        print("生成的查询变体:")
        for i, q in enumerate(queries, 1):
            print(f"  {i}. {q}")

        # 3. 并行检索
        all_results = parallel_retrieve(queries, k=3)
        print(f"\n检索到 {len(all_results)} 个结果")

        # 4. 结果融合
        if use_fusion:
            final_results = rag_fusion(all_results)
            print(f"RAG-Fusion 融合后 {len(final_results)} 个文档")
        else:
            final_results = deduplicate_results(all_results)
            print(f"去重后 {len(final_results)} 个文档")

        # 5. 生成答案
        top_docs = final_results[:5]
        context = "\n\n".join([
            doc['content'] if isinstance(doc, dict) else doc
            for doc in top_docs
        ])

        answer_prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{query}

答案："""

        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": answer_prompt}],
            temperature=0.7
        )

        answer = response.choices[0].message.content.strip()

        print(f"\n答案:\n{answer}\n")

        return {
            "query": query,
            "generated_queries": queries,
            "num_results": len(all_results),
            "num_unique": len(final_results),
            "answer": answer
        }

# 测试
if __name__ == "__main__":
    rag = MultiQueryRAG(collection)

    test_queries = [
        "RAG 系统如何提升准确性？",
        "如何优化 RAG 性能？"
    ]

    for query in test_queries:
        result = rag.query(
            query,
            use_adaptive=True,
            use_fusion=True,
            min_diversity=0.3
        )
        print("-" * 80 + "\n")
```

---

## 总结

### 关键要点

1. **基础多查询生成**：生成 3-5 个查询变体，并行检索
2. **RAG-Fusion**：使用 RRF 算法融合多个查询的结果
3. **自适应数量**：根据查询复杂度动态调整查询数量
4. **多样性控制**：确保查询变体之间有足够差异
5. **完整系统**：整合所有优化技术

### 代码特点

- 所有代码可直接运行
- 使用 Python 3.13+ 特性
- 基于 OpenAI API 和 ChromaDB
- 包含完整的测试用例
- 提供性能统计

### 性能优化建议

1. **控制查询数量**：3-5 个最佳
2. **使用 RAG-Fusion**：提升结果质量
3. **自适应策略**：根据复杂度调整
4. **多样性检查**：避免生成相似查询
5. **缓存优化**：对高频查询缓存结果

### 下一步

参考后续的实战代码文件，学习查询分解、HyDE 和完整 RAG 流程的实现。
