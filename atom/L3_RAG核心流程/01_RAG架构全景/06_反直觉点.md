# 反直觉点

> RAG 最容易踩的 3 个坑

---

## 误区1：RAG 就是简单的"搜索 + GPT" ❌

### 错误观点

> "RAG 很简单，就是先搜索一下，然后把结果丢给 GPT 就行了。"

### 为什么错？

RAG 的核心挑战不在于"搜索"和"生成"，而在于**检索质量**。

```
简单理解（错误）:
搜索 → GPT → 答案 ✓

实际情况（复杂）:
文档解析（可能乱码）
    ↓
分块策略（块大小？重叠？）
    ↓
Embedding 选择（哪个模型？）
    ↓
向量索引（HNSW？IVF？）
    ↓
检索策略（Top-K？阈值？）
    ↓
重排序（需要 ReRank 吗？）
    ↓
Prompt 设计（怎么组织上下文？）
    ↓
生成答案
```

**每个环节都可能出问题，而且问题会层层传递。**

### 为什么人们容易这样错？

- RAG 的概念确实简单（检索 + 生成）
- Demo 跑起来很容易（几十行代码）
- 但从 Demo 到生产级系统，差距巨大

### 正确理解

```python
# 看起来简单
answer = rag_pipeline(question)

# 实际上每个环节都需要精心设计
def rag_pipeline(question):
    # 1. 问题理解（可能需要改写）
    processed_question = query_rewriter(question)

    # 2. 检索（可能需要多路召回）
    results_semantic = semantic_search(processed_question)
    results_keyword = keyword_search(processed_question)
    results = merge_results(results_semantic, results_keyword)

    # 3. 重排序（提升精度）
    reranked = reranker(question, results)

    # 4. 过滤（去掉不相关的）
    filtered = filter_by_threshold(reranked, threshold=0.7)

    # 5. 生成（精心设计的 Prompt）
    answer = generate_with_citation(question, filtered)

    return answer
```

**记住：Garbage In, Garbage Out。检索质量决定生成质量。**

---

## 误区2：RAG 能解决所有 LLM 问题 ❌

### 错误观点

> "有了 RAG，LLM 就无所不能了，什么问题都能解决。"

### 为什么错？

RAG 只解决**知识获取**问题，不能解决：

| 问题类型 | RAG 能解决吗 | 原因 |
|---------|-------------|------|
| 知识过时 | ✅ 能 | 可以检索最新文档 |
| 私有知识 | ✅ 能 | 可以检索企业文档 |
| 推理能力不足 | ❌ 不能 | RAG 不提升推理能力 |
| 格式/风格问题 | ❌ 不能 | 需要 Fine-tuning |
| 复杂计算 | ❌ 不能 | 需要工具调用 |

### 一个直观的例子

```
问题: "计算 2024 年 Q1 到 Q4 的销售额增长率"

RAG 能做的:
- 检索到 Q1 销售额: 100万
- 检索到 Q4 销售额: 150万

RAG 不能保证的:
- LLM 能正确计算 (150-100)/100 = 50%
- 如果 LLM 推理能力弱，可能算错
```

### 为什么人们容易这样错？

- RAG 确实很强大，解决了很多问题
- 容易把"知识问题"和"能力问题"混淆
- 看到 RAG 的成功案例，就以为它万能

### 正确理解

```
RAG 适合的场景:
✅ 知识密集型问答（FAQ、文档查询）
✅ 需要引用来源的场景
✅ 知识频繁更新的场景

RAG 不适合的场景:
❌ 复杂推理任务（用 Chain-of-Thought）
❌ 风格/格式调整（用 Fine-tuning）
❌ 精确计算（用工具调用）
❌ 实时数据（用 API 集成）
```

**RAG 是工具箱里的一把锤子，不是万能钥匙。**

---

## 误区3：检索到的内容越多越好 ❌

### 错误观点

> "多检索一些内容总没错，宁可多不可少。"

### 为什么错？

检索内容过多会导致三个问题：

```
问题1: Context Window 限制
┌─────────────────────────────────────┐
│ System Prompt: 500 tokens           │
│ 检索内容: 10000 tokens  ← 太多了！   │
│ 用户问题: 100 tokens                │
│ 预留生成: 2000 tokens               │
└─────────────────────────────────────┘
总计: 12600 tokens，可能超出限制

问题2: "Lost in the Middle" 效应
研究发现，LLM 对中间位置的信息关注度低
┌─────────────────────────────────────┐
│ 开头内容 → 关注度高 ✓               │
│ 中间内容 → 关注度低 ✗ ← 可能被忽略   │
│ 结尾内容 → 关注度高 ✓               │
└─────────────────────────────────────┘

问题3: 无关内容干扰生成
检索结果: [相关1, 相关2, 不相关3, 不相关4, 不相关5]
LLM 可能被不相关内容误导，生成错误答案
```

### 为什么人们容易这样错？

- 直觉上"信息越多越好"
- 担心漏掉重要信息
- 没有意识到 LLM 的注意力是有限的

### 正确理解

```python
# 错误做法：检索太多
results = retriever.search(question, top_k=20)  # 20个太多了

# 正确做法：精准检索 + 过滤
results = retriever.search(question, top_k=5)   # 先检索少量
results = reranker.rerank(question, results)    # 重排序
results = filter(results, threshold=0.8)        # 过滤低分结果
# 最终可能只有 2-3 个高质量结果
```

**质量 > 数量。3 个高度相关的结果，胜过 10 个一般相关的结果。**

---

## 误区对照表

| 误区 | 错误想法 | 正确理解 |
|-----|---------|---------|
| RAG 很简单 | 搜索 + GPT 就行 | 每个环节都需要精心设计 |
| RAG 万能 | 能解决所有问题 | 只解决知识获取问题 |
| 越多越好 | 多检索总没错 | 质量 > 数量 |

---

## 检查清单

学完本节，你应该能：

- [ ] 解释为什么 RAG 不是"简单的搜索 + GPT"
- [ ] 说出 RAG 不能解决的问题类型
- [ ] 理解为什么检索结果不是越多越好
- [ ] 知道 "Lost in the Middle" 效应是什么

---

**下一步：** [07_实战代码](./07_实战代码.md) - 动手实现一个最简 RAG
