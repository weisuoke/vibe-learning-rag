# 实战代码4：MMR多样性

> MMR算法完整实现，平衡相关性和多样性，避免重复结果

---

## 代码概述

本示例展示如何实现MMR (Maximal Marginal Relevance) 算法，包括：
1. MMR算法原理和实现
2. Lambda参数调优
3. 与Top-K对比
4. LangChain集成
5. 实际应用场景

---

## 完整代码

```python
"""
MMR多样性算法完整实现
演示：平衡相关性和多样性的检索策略
"""

import os
from typing import List, Dict, Tuple, Optional
from dotenv import load_dotenv
from openai import OpenAI
import numpy as np
import time

# 加载环境变量
load_dotenv()

# ===== 1. MMR算法实现 =====
class MMRSelector:
    """MMR (Maximal Marginal Relevance) 选择器"""

    def __init__(self, lambda_param: float = 0.7):
        """
        初始化MMR选择器

        Args:
            lambda_param: 平衡参数（0-1）
                         1.0 = 只考虑相关性
                         0.0 = 只考虑多样性
                         0.7 = 推荐值（70%相关性 + 30%多样性）
        """
        self.lambda_param = lambda_param

    def select(
        self,
        query_embedding: np.ndarray,
        doc_embeddings: np.ndarray,
        k: int = 5,
        fetch_k: int = 20
    ) -> List[int]:
        """
        使用MMR选择文档

        Args:
            query_embedding: 查询向量
            doc_embeddings: 文档向量列表
            k: 最终返回数量
            fetch_k: 候选文档数量

        Returns:
            选中的文档索引列表
        """
        # 1. 计算查询-文档相似度
        query_doc_sim = self._cosine_similarity_batch(
            query_embedding,
            doc_embeddings
        )

        # 2. 选择Top-fetch_k作为候选
        candidate_indices = query_doc_sim.argsort()[-fetch_k:][::-1].tolist()

        # 3. 初始化
        selected = []
        selected_embeddings = []

        # 4. 迭代选择
        while len(selected) < k and candidate_indices:
            # 计算每个候选的MMR得分
            mmr_scores = []

            for idx in candidate_indices:
                # 相关性得分
                relevance = query_doc_sim[idx]

                # 多样性得分（与已选文档的最大相似度）
                if selected_embeddings:
                    doc_doc_sim = self._cosine_similarity_batch(
                        doc_embeddings[idx],
                        np.array(selected_embeddings)
                    )
                    diversity = -np.max(doc_doc_sim)  # 负号：越不相似越好
                else:
                    diversity = 0

                # MMR得分
                mmr_score = (
                    self.lambda_param * relevance +
                    (1 - self.lambda_param) * diversity
                )

                mmr_scores.append((idx, mmr_score))

            # 选择MMR得分最高的
            best_idx, best_score = max(mmr_scores, key=lambda x: x[1])

            selected.append(best_idx)
            selected_embeddings.append(doc_embeddings[best_idx])

            # 从候选中移除
            candidate_indices.remove(best_idx)

        return selected

    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        """计算余弦相似度"""
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    def _cosine_similarity_batch(
        self,
        query: np.ndarray,
        docs: np.ndarray
    ) -> np.ndarray:
        """批量计算余弦相似度"""
        # 归一化
        query_norm = query / np.linalg.norm(query)
        docs_norm = docs / np.linalg.norm(docs, axis=1, keepdims=True)

        # 计算相似度
        similarities = np.dot(docs_norm, query_norm)

        return similarities


# ===== 2. MMR检索器 =====
class MMRRetriever:
    """带MMR的检索器"""

    def __init__(
        self,
        embedding_model: str = "text-embedding-3-small",
        lambda_param: float = 0.7
    ):
        """
        初始化MMR检索器

        Args:
            embedding_model: Embedding模型
            lambda_param: MMR平衡参数
        """
        self.client = OpenAI()
        self.embedding_model = embedding_model
        self.mmr_selector = MMRSelector(lambda_param=lambda_param)

        self.documents = []
        self.doc_embeddings = None

    def index_documents(self, documents: List[str]):
        """
        索引文档

        Args:
            documents: 文档列表
        """
        print(f"\n=== 索引{len(documents)}个文档 ===")

        self.documents = documents

        # 生成embeddings
        start = time.time()
        embeddings = self._generate_embeddings_batch(documents)
        self.doc_embeddings = np.array(embeddings)
        embedding_time = time.time() - start

        print(f"✓ Embedding生成耗时: {embedding_time:.2f}s")

    def search_mmr(
        self,
        query: str,
        k: int = 5,
        fetch_k: int = 20
    ) -> List[Dict]:
        """
        使用MMR检索

        Args:
            query: 查询文本
            k: 返回结果数量
            fetch_k: 候选数量

        Returns:
            检索结果列表
        """
        print(f"\n=== MMR检索: {query} ===")
        print(f"✓ 参数: k={k}, fetch_k={fetch_k}, lambda={self.mmr_selector.lambda_param}")

        # 生成查询embedding
        start = time.time()
        query_embedding = self._generate_embedding(query)
        embedding_time = time.time() - start

        # MMR选择
        start = time.time()
        selected_indices = self.mmr_selector.select(
            query_embedding=query_embedding,
            doc_embeddings=self.doc_embeddings,
            k=k,
            fetch_k=fetch_k
        )
        mmr_time = time.time() - start

        print(f"✓ 查询embedding耗时: {embedding_time:.3f}s")
        print(f"✓ MMR选择耗时: {mmr_time:.3f}s")

        # 格式化结果
        results = []
        for rank, idx in enumerate(selected_indices, 1):
            # 计算相似度
            similarity = np.dot(query_embedding, self.doc_embeddings[idx])

            results.append({
                "rank": rank,
                "document": self.documents[idx],
                "similarity": similarity,
                "index": idx
            })

        return results

    def search_top_k(self, query: str, k: int = 5) -> List[Dict]:
        """
        使用Top-K检索（对比用）

        Args:
            query: 查询文本
            k: 返回结果数量

        Returns:
            检索结果列表
        """
        print(f"\n=== Top-K检索: {query} ===")

        # 生成查询embedding
        query_embedding = self._generate_embedding(query)

        # 计算相似度
        similarities = np.dot(self.doc_embeddings, query_embedding)

        # 排序并返回Top-K
        top_k_indices = similarities.argsort()[-k:][::-1]

        results = []
        for rank, idx in enumerate(top_k_indices, 1):
            results.append({
                "rank": rank,
                "document": self.documents[idx],
                "similarity": similarities[idx],
                "index": idx
            })

        return results

    def _generate_embedding(self, text: str) -> np.ndarray:
        """生成单个embedding"""
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=text
        )
        return np.array(response.data[0].embedding)

    def _generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """批量生成embeddings"""
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=texts
        )
        return [item.embedding for item in response.data]


# ===== 3. Lambda参数调优 =====
class LambdaTuner:
    """Lambda参数调优器"""

    def __init__(self, retriever: MMRRetriever):
        self.retriever = retriever

    def tune(
        self,
        query: str,
        lambda_values: List[float] = [0.3, 0.5, 0.7, 0.9, 1.0]
    ):
        """
        调优lambda参数

        Args:
            query: 测试查询
            lambda_values: lambda候选值列表
        """
        print(f"\n=== Lambda参数调优 ===")
        print(f"查询: {query}\n")

        for lambda_val in lambda_values:
            # 设置lambda
            self.retriever.mmr_selector.lambda_param = lambda_val

            # 检索
            results = self.retriever.search_mmr(query, k=5, fetch_k=20)

            print(f"\n--- Lambda = {lambda_val} ---")
            for result in results[:3]:
                print(f"{result['rank']}. {result['document'][:60]}...")

            # 计算多样性
            diversity = self._calculate_diversity(results)
            print(f"多样性得分: {diversity:.3f}")

    def _calculate_diversity(self, results: List[Dict]) -> float:
        """
        计算结果多样性

        Args:
            results: 检索结果

        Returns:
            多样性得分（0-1，越高越多样）
        """
        if len(results) < 2:
            return 1.0

        # 计算结果之间的平均相似度
        indices = [r['index'] for r in results]
        embeddings = self.retriever.doc_embeddings[indices]

        similarities = []
        for i in range(len(embeddings)):
            for j in range(i+1, len(embeddings)):
                sim = np.dot(embeddings[i], embeddings[j])
                similarities.append(sim)

        avg_similarity = np.mean(similarities)

        # 多样性 = 1 - 平均相似度
        diversity = 1 - avg_similarity

        return diversity


# ===== 4. LangChain集成 =====
def langchain_mmr_example():
    """LangChain MMR示例"""
    from langchain_community.vectorstores import Chroma
    from langchain_openai import OpenAIEmbeddings

    print("\n" + "="*50)
    print("LangChain MMR示例")
    print("="*50)

    # 准备文档
    documents = [
        "Python是一种高级编程语言",
        "Python是一门编程语言",  # 与第1个高度相似
        "JavaScript用于Web开发",
        "JS是Web开发语言",       # 与第3个高度相似
        "机器学习是AI的核心",
        "深度学习使用神经网络",
        "RAG系统结合检索和生成"
    ]

    # 创建向量存储
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_texts(documents, embeddings)

    # 查询
    query = "编程语言"

    # 1. Top-K检索
    print(f"\n查询: {query}")
    print("\n=== Top-K结果（可能重复）===")
    top_k_results = vectorstore.similarity_search(query, k=5)
    for i, doc in enumerate(top_k_results, 1):
        print(f"{i}. {doc.page_content}")

    # 2. MMR检索
    print("\n=== MMR结果（多样性）===")
    mmr_results = vectorstore.max_marginal_relevance_search(
        query=query,
        k=5,
        fetch_k=7,
        lambda_mult=0.7
    )
    for i, doc in enumerate(mmr_results, 1):
        print(f"{i}. {doc.page_content}")


# ===== 5. 使用示例 =====
def main():
    """主函数"""

    # 准备文档（包含重复和相似内容）
    documents = [
        "Python是一种高级编程语言，由Guido van Rossum创建。",
        "Python是一门高级编程语言，Guido van Rossum是其创始人。",  # 与第1个高度相似
        "Python编程语言具有简洁的语法和强大的功能。",              # 与第1个相似
        "JavaScript是一种用于Web开发的编程语言。",
        "JavaScript主要用于前端Web开发。",                        # 与第4个相似
        "机器学习是人工智能的一个子领域。",
        "深度学习使用神经网络进行特征学习。",
        "RAG系统结合检索和生成技术。",
        "FastAPI是一个现代的Python Web框架。",
        "Docker是一个容器化平台。"
    ]

    # 创建检索器
    retriever = MMRRetriever(lambda_param=0.7)
    retriever.index_documents(documents)

    # 测试查询
    query = "Python编程"

    # 1. Top-K检索（可能重复）
    print("\n" + "="*50)
    print("对比：Top-K vs MMR")
    print("="*50)

    top_k_results = retriever.search_top_k(query, k=5)

    print("\n=== Top-K结果（可能重复）===")
    for result in top_k_results:
        print(f"\n{result['rank']}. [相似度: {result['similarity']:.3f}]")
        print(f"   {result['document']}")

    # 2. MMR检索（多样性）
    mmr_results = retriever.search_mmr(query, k=5, fetch_k=10)

    print("\n=== MMR结果（多样性）===")
    for result in mmr_results:
        print(f"\n{result['rank']}. [相似度: {result['similarity']:.3f}]")
        print(f"   {result['document']}")

    # 3. Lambda参数调优
    print("\n" + "="*50)
    print("Lambda参数调优")
    print("="*50)

    tuner = LambdaTuner(retriever)
    tuner.tune(query, lambda_values=[0.3, 0.5, 0.7, 0.9, 1.0])


# ===== 6. 多样性评估 =====
def diversity_evaluation():
    """多样性评估实验"""

    print("\n" + "="*50)
    print("多样性评估实验")
    print("="*50)

    # 准备文档
    documents = [
        "Python入门教程第一章",
        "Python入门教程第二章",
        "Python入门教程第三章",
        "Python进阶技巧",
        "Python实战项目",
        "Python性能优化",
        "Python最佳实践",
        "JavaScript基础教程",
        "机器学习入门",
        "深度学习实战"
    ]

    # 创建检索器
    retriever = MMRRetriever()
    retriever.index_documents(documents)

    query = "Python教程"

    # 测试不同lambda值
    lambda_values = [1.0, 0.7, 0.5, 0.3]

    for lambda_val in lambda_values:
        retriever.mmr_selector.lambda_param = lambda_val

        results = retriever.search_mmr(query, k=5, fetch_k=10)

        print(f"\n=== Lambda = {lambda_val} ===")
        for result in results:
            print(f"{result['rank']}. {result['document']}")

        # 计算多样性
        tuner = LambdaTuner(retriever)
        diversity = tuner._calculate_diversity(results)
        print(f"多样性得分: {diversity:.3f}")


# ===== 7. 性能测试 =====
def benchmark():
    """性能基准测试"""

    print("\n" + "="*50)
    print("性能基准测试")
    print("="*50)

    # 生成测试文档
    n_docs = 1000
    documents = [f"这是第{i}个测试文档，内容关于主题{i%10}" for i in range(n_docs)]

    # 创建检索器
    retriever = MMRRetriever()

    # 测试索引性能
    print(f"\n测试索引{n_docs}个文档...")
    start = time.time()
    retriever.index_documents(documents)
    index_time = time.time() - start

    print(f"\n索引性能:")
    print(f"  总耗时: {index_time:.2f}s")
    print(f"  平均每文档: {index_time/n_docs*1000:.2f}ms")

    # 测试检索性能
    print(f"\n测试检索性能...")
    query = "测试查询"
    n_queries = 100

    # Top-K性能
    start = time.time()
    for _ in range(n_queries):
        retriever.search_top_k(query, k=5)
    top_k_time = time.time() - start

    # MMR性能
    start = time.time()
    for _ in range(n_queries):
        retriever.search_mmr(query, k=5, fetch_k=20)
    mmr_time = time.time() - start

    print(f"\n检索性能:")
    print(f"  Top-K: {top_k_time:.2f}s ({n_queries/top_k_time:.1f} QPS)")
    print(f"  MMR: {mmr_time:.2f}s ({n_queries/mmr_time:.1f} QPS)")
    print(f"  MMR开销: +{(mmr_time-top_k_time)/top_k_time*100:.1f}%")


if __name__ == "__main__":
    # 运行主示例
    main()

    # 运行多样性评估（可选）
    # diversity_evaluation()

    # 运行LangChain示例（可选）
    # langchain_mmr_example()

    # 运行性能测试（可选）
    # benchmark()
```

---

## 运行输出示例

```
=== 索引10个文档 ===
✓ Embedding生成耗时: 0.52s

=== 对比：Top-K vs MMR ===

=== Top-K检索: Python编程 ===

=== Top-K结果（可能重复）===

1. [相似度: 0.892]
   Python是一种高级编程语言，由Guido van Rossum创建。

2. [相似度: 0.885]
   Python是一门高级编程语言，Guido van Rossum是其创始人。

3. [相似度: 0.876]
   Python编程语言具有简洁的语法和强大的功能。

4. [相似度: 0.654]
   FastAPI是一个现代的Python Web框架。

5. [相似度: 0.432]
   JavaScript是一种用于Web开发的编程语言。

=== MMR检索: Python编程 ===
✓ 参数: k=5, fetch_k=10, lambda=0.7
✓ 查询embedding耗时: 0.123s
✓ MMR选择耗时: 0.002s

=== MMR结果（多样性）===

1. [相似度: 0.892]
   Python是一种高级编程语言，由Guido van Rossum创建。

2. [相似度: 0.654]
   FastAPI是一个现代的Python Web框架。

3. [相似度: 0.432]
   JavaScript是一种用于Web开发的编程语言。

4. [相似度: 0.387]
   机器学习是人工智能的一个子领域。

5. [相似度: 0.298]
   Docker是一个容器化平台。
```

---

## 代码说明

### 1. MMRSelector类

**功能**：
- 实现MMR算法核心逻辑
- 平衡相关性和多样性
- 支持lambda参数调整

**MMR公式**：
```
MMR_score = λ × relevance + (1-λ) × diversity

其中：
- relevance = similarity(query, doc)
- diversity = -max(similarity(doc, selected_docs))
```

### 2. MMRRetriever类

**功能**：
- 整合Embedding生成和MMR选择
- 提供Top-K和MMR两种检索方式
- 性能监控

**关键方法**：
- `search_mmr()`: MMR检索
- `search_top_k()`: Top-K检索（对比用）

### 3. LambdaTuner类

**功能**：
- Lambda参数调优
- 多样性评估
- 可视化对比

---

## 优化要点

### 1. Lambda参数选择

```python
# 不同场景的lambda推荐值
lambda_configs = {
    "精准问答": 0.9,      # 强调相关性
    "通用检索": 0.7,      # 平衡（推荐）
    "探索性搜索": 0.5,    # 强调多样性
    "发现新内容": 0.3     # 极致多样性
}
```

### 2. fetch_k优化

```python
# fetch_k应该是k的2-5倍
def optimal_fetch_k(k: int) -> int:
    """计算最优fetch_k"""
    if k <= 5:
        return k * 4
    elif k <= 10:
        return k * 3
    else:
        return k * 2
```

### 3. 性能优化

```python
# 使用向量化计算加速
def fast_mmr_select(query_emb, doc_embs, k, fetch_k, lambda_param):
    """优化的MMR实现"""
    # 预计算所有相似度
    query_doc_sim = np.dot(doc_embs, query_emb)

    # 向量化计算多样性
    selected = []
    for _ in range(k):
        if not selected:
            # 第一个选择最相关的
            idx = query_doc_sim.argmax()
        else:
            # 向量化计算MMR得分
            selected_embs = doc_embs[selected]
            doc_doc_sim = np.dot(doc_embs, selected_embs.T)
            diversity = -doc_doc_sim.max(axis=1)

            mmr_scores = lambda_param * query_doc_sim + (1-lambda_param) * diversity
            idx = mmr_scores.argmax()

        selected.append(idx)
        query_doc_sim[idx] = -np.inf  # 标记已选

    return selected
```

---

## 扩展功能

### 1. 动态Lambda

```python
def dynamic_lambda(query: str, results: List[Dict]) -> float:
    """根据查询和结果动态调整lambda"""
    # 如果查询很具体，提高相关性权重
    if any(word in query for word in ['什么是', '定义', '解释']):
        return 0.9

    # 如果结果高度相似，提高多样性权重
    avg_similarity = calculate_avg_similarity(results)
    if avg_similarity > 0.8:
        return 0.5

    return 0.7  # 默认
```

### 2. 分组MMR

```python
def grouped_mmr(query_emb, doc_embs, groups, k_per_group):
    """每个组内使用MMR选择"""
    selected = []

    for group_indices in groups:
        group_embs = doc_embs[group_indices]

        # 组内MMR
        group_selected = mmr_select(
            query_emb,
            group_embs,
            k=k_per_group
        )

        selected.extend([group_indices[i] for i in group_selected])

    return selected
```

### 3. 时间衰减MMR

```python
def time_decay_mmr(query_emb, doc_embs, timestamps, k, decay_rate=0.1):
    """考虑时间因素的MMR"""
    # 计算时间衰减因子
    current_time = time.time()
    time_factors = np.exp(-decay_rate * (current_time - timestamps))

    # 调整相关性得分
    query_doc_sim = np.dot(doc_embs, query_emb)
    adjusted_sim = query_doc_sim * time_factors

    # 使用调整后的相似度进行MMR
    return mmr_select(query_emb, doc_embs, k, relevance_scores=adjusted_sim)
```

---

## 常见问题

### Q1: MMR会降低相关性吗？

**A**:
- 会略微降低（5-10%），但提升用户体验
- lambda=0.7时，相关性降低<10%，多样性显著提升
- 实际应用中，用户更喜欢多样化的结果

### Q2: fetch_k如何选择？

**A**:
- fetch_k应该是k的2-5倍
- k=5 → fetch_k=10-25
- fetch_k越大，多样性选择空间越大，但计算成本越高

### Q3: MMR计算成本高吗？

**A**:
- 相比Top-K，增加约20-30%计算时间
- 主要开销在文档-文档相似度计算
- 可以通过向量化和缓存优化

### Q4: 什么时候用MMR？

**A**:
- 通用检索：默认使用MMR
- 精准问答：可以只用Top-K
- 探索性搜索：必须用MMR

---

## 总结

本示例展示了完整的MMR实现，包括：
- ✅ MMR算法核心逻辑
- ✅ Lambda参数调优
- ✅ Top-K vs MMR对比
- ✅ 多样性评估
- ✅ LangChain集成
- ✅ 性能优化

**下一步**：学习【实战代码5：HNSW调优】，实现向量索引参数调优实验。
