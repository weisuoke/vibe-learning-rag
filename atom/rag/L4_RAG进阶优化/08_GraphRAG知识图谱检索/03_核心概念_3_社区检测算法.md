# GraphRAG知识图谱检索 - 核心概念3: 社区检测算法

> Leiden算法分层聚类,GraphRAG全局理解的核心

---

## 概念定义

**社区检测(Community Detection)**是在知识图谱中识别关系密集的实体群组的算法,GraphRAG使用Leiden算法进行分层聚类,为Global Search提供全局摘要。

**一句话**: 把知识图谱中关系密切的实体聚成"社区",就像把朋友圈分组。

---

## 为什么需要社区检测?

### 问题场景

```python
# 大型知识图谱
graph = {
    # 技术团队
    "Alice": [("manages", "Bob"), ("manages", "Charlie")],
    "Bob": [("works_with", "Charlie")],
    
    # 市场团队  
    "David": [("manages", "Eve"), ("manages", "Frank")],
    "Eve": [("works_with", "Frank")],
    
    # 高层
    "CEO": [("oversees", "Alice"), ("oversees", "David")]
}

# 用户查询: "公司的组织结构是什么?"
# 问题: 如何从图中提取整体结构?
```

**没有社区检测的问题**:
```python
# ❌ 只能遍历所有节点,无法理解整体结构
# ❌ 无法回答"有哪些团队?"这样的全局问题
# ❌ 无法生成高层次摘要
```

**有社区检测的优势**:
```python
# ✅ 自动发现3个社区:
# Community 1: [Alice, Bob, Charlie] - 技术团队
# Community 2: [David, Eve, Frank] - 市场团队  
# Community 3: [CEO] - 高层

# ✅ 可以回答全局问题
# ✅ 可以生成分层摘要
```

---

## Leiden算法原理

### 1. 什么是Leiden算法?

**Leiden算法**是一种基于模块度优化的社区检测算法,改进自Louvain算法,2019年发表。

**核心思想**:
```
1. 模块度(Modularity): 衡量社区划分质量的指标
   - 社区内部连接多 → 模块度高
   - 社区之间连接少 → 模块度高

2. 优化过程:
   - 局部移动: 将节点移动到邻居社区
   - 精炼: 拆分不连通的社区
   - 聚合: 将社区作为超节点
   - 重复: 直到模块度不再提升
```

### 2. Leiden vs Louvain

| 维度 | Louvain | Leiden |
|------|---------|--------|
| **质量** | 可能产生不连通社区 | 保证社区连通性 |
| **速度** | 快 | 稍慢但更准确 |
| **分辨率** | 固定 | 可调节 |
| **GraphRAG使用** | ❌ | ✅ |

---

## 核心技术详解

### 1. 使用python-louvain实现

```python
import networkx as nx
import community as community_louvain
from typing import Dict, List

def detect_communities_louvain(G: nx.Graph) -> Dict[int, List[str]]:
    """
    使用Louvain算法检测社区
    """
    # 计算最佳分区
    partition = community_louvain.best_partition(G)
    
    # 转换为社区字典
    communities = {}
    for node, comm_id in partition.items():
        if comm_id not in communities:
            communities[comm_id] = []
        communities[comm_id].append(node)
    
    return communities

# 示例
G = nx.Graph()
edges = [
    ("Alice", "Bob"), ("Alice", "Charlie"), ("Bob", "Charlie"),  # 社区1
    ("David", "Eve"), ("David", "Frank"), ("Eve", "Frank"),      # 社区2
    ("CEO", "Alice"), ("CEO", "David")                           # 连接
]
G.add_edges_from(edges)

communities = detect_communities_louvain(G)
print("检测到的社区:")
for comm_id, members in communities.items():
    print(f"  社区{comm_id}: {members}")
```

**输出**:
```
检测到的社区:
  社区0: ['Alice', 'Bob', 'Charlie']
  社区1: ['David', 'Eve', 'Frank']
  社区2: ['CEO']
```

### 2. 使用NetworkX内置算法

```python
import networkx as nx
from networkx.algorithms import community

def detect_communities_greedy(G: nx.Graph) -> List[set]:
    """
    使用贪心模块度优化
    """
    communities = community.greedy_modularity_communities(G)
    return list(communities)

# 示例
communities = detect_communities_greedy(G)
print("\n贪心算法检测的社区:")
for i, comm in enumerate(communities):
    print(f"  社区{i}: {list(comm)}")
```

### 3. 计算模块度

```python
def calculate_modularity(G: nx.Graph, communities: List[set]) -> float:
    """
    计算社区划分的模块度
    """
    return community.modularity(G, communities)

# 示例
modularity = calculate_modularity(G, communities)
print(f"\n模块度: {modularity:.4f}")
# 模块度范围: [-0.5, 1.0]
# 越接近1.0,社区划分越好
```

---

## 分层社区检测

### 1. 多层次社区结构

```python
def hierarchical_communities(G: nx.Graph, max_level: int = 3) -> Dict:
    """
    分层社区检测
    """
    hierarchy = {}
    current_G = G.copy()
    
    for level in range(max_level):
        # 检测当前层的社区
        partition = community_louvain.best_partition(current_G)
        
        # 存储当前层
        communities = {}
        for node, comm_id in partition.items():
            if comm_id not in communities:
                communities[comm_id] = []
            communities[comm_id].append(node)
        
        hierarchy[f"level_{level}"] = communities
        
        # 如果只有一个社区,停止
        if len(communities) == 1:
            break
        
        # 构建下一层的图(社区作为节点)
        next_G = nx.Graph()
        for comm_id, members in communities.items():
            # 添加社区间的边
            for other_comm_id in communities:
                if comm_id != other_comm_id:
                    # 检查是否有跨社区的边
                    for node1 in members:
                        for node2 in communities[other_comm_id]:
                            if current_G.has_edge(node1, node2):
                                next_G.add_edge(comm_id, other_comm_id)
                                break
        
        current_G = next_G
    
    return hierarchy

# 示例
hierarchy = hierarchical_communities(G)
print("\n分层社区结构:")
for level, communities in hierarchy.items():
    print(f"\n{level}:")
    for comm_id, members in communities.items():
        print(f"  社区{comm_id}: {members}")
```

---

## 社区摘要生成

### 1. 为每个社区生成摘要

```python
from openai import OpenAI
import os
import json

def generate_community_summary(
    community_members: List[str],
    G: nx.Graph,
    client: OpenAI
) -> str:
    """
    使用LLM为社区生成摘要
    """
    # 提取社区内的关系
    relations = []
    for node1 in community_members:
        for node2 in community_members:
            if G.has_edge(node1, node2):
                edge_data = G.get_edge_data(node1, node2)
                relation = edge_data.get('relation', 'connected_to')
                relations.append(f"{node1} --[{relation}]--> {node2}")
    
    # 构建prompt
    prompt = f"""
分析以下社区的结构并生成摘要:

成员: {', '.join(community_members)}

关系:
{chr(10).join(relations)}

请生成一个简洁的摘要(2-3句话),描述:
1. 这个社区的主要特征
2. 成员之间的关系模式
3. 这个社区在整体中的作用

只返回摘要文本。
"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    
    return response.choices[0].message.content

# 示例
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

for comm_id, members in communities.items():
    summary = generate_community_summary(members, G, client)
    print(f"\n社区{comm_id}摘要:")
    print(f"  {summary}")
```

### 2. 生成全局摘要

```python
def generate_global_summary(
    communities: Dict[int, List[str]],
    community_summaries: Dict[int, str],
    client: OpenAI
) -> str:
    """
    基于社区摘要生成全局摘要
    """
    prompt = f"""
基于以下社区摘要,生成整体的全局摘要:

{chr(10).join([f"社区{i}: {summary}" for i, summary in community_summaries.items()])}

请生成一个全局摘要(3-5句话),描述:
1. 整体结构的特征
2. 不同社区之间的关系
3. 整体的组织模式

只返回摘要文本。
"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    
    return response.choices[0].message.content
```

---

## 在GraphRAG中的应用

### 1. Global Search流程

```python
class GlobalSearch:
    """
    基于社区检测的全局搜索
    """
    
    def __init__(self, G: nx.Graph, client: OpenAI):
        self.G = G
        self.client = client
        self.communities = None
        self.community_summaries = {}
        self.global_summary = None
    
    def build_index(self):
        """构建社区索引"""
        # 1. 检测社区
        self.communities = detect_communities_louvain(self.G)
        
        # 2. 生成社区摘要
        for comm_id, members in self.communities.items():
            summary = generate_community_summary(
                members, self.G, self.client
            )
            self.community_summaries[comm_id] = summary
        
        # 3. 生成全局摘要
        self.global_summary = generate_global_summary(
            self.communities,
            self.community_summaries,
            self.client
        )
    
    def search(self, query: str) -> str:
        """全局搜索"""
        # 使用全局摘要和社区摘要回答查询
        context = f"""
全局摘要:
{self.global_summary}

社区详情:
{chr(10).join([f"社区{i}: {s}" for i, s in self.community_summaries.items()])}
"""
        
        prompt = f"""
基于以下知识图谱的全局信息回答问题:

{context}

问题: {query}

请提供详细的回答。
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return response.choices[0].message.content

# 使用示例
global_search = GlobalSearch(G, client)
global_search.build_index()

query = "公司的组织结构是什么?"
answer = global_search.search(query)
print(f"\n问题: {query}")
print(f"回答: {answer}")
```

---

## 性能优化

### 1. 增量社区检测

```python
class IncrementalCommunityDetector:
    """增量社区检测"""
    
    def __init__(self):
        self.G = nx.Graph()
        self.communities = {}
        self.node_to_community = {}
    
    def add_edge(self, node1: str, node2: str):
        """添加边并更新社区"""
        self.G.add_edge(node1, node2)
        
        # 检查是否需要重新计算
        if node1 in self.node_to_community and node2 in self.node_to_community:
            comm1 = self.node_to_community[node1]
            comm2 = self.node_to_community[node2]
            
            if comm1 != comm2:
                # 可能需要合并社区
                self._recompute_local(node1, node2)
        else:
            # 新节点,重新计算
            self._recompute_all()
    
    def _recompute_all(self):
        """完全重新计算"""
        partition = community_louvain.best_partition(self.G)
        self.communities = {}
        self.node_to_community = {}
        
        for node, comm_id in partition.items():
            if comm_id not in self.communities:
                self.communities[comm_id] = []
            self.communities[comm_id].append(node)
            self.node_to_community[node] = comm_id
    
    def _recompute_local(self, node1: str, node2: str):
        """局部重新计算"""
        # 简化版:完全重新计算
        # 生产环境可以优化为只重新计算受影响的社区
        self._recompute_all()
```

### 2. 缓存社区摘要

```python
import hashlib

class CachedCommunityDetector:
    """带缓存的社区检测"""
    
    def __init__(self, cache_file: str = "community_cache.json"):
        self.cache_file = cache_file
        self.cache = self._load_cache()
    
    def _load_cache(self) -> dict:
        try:
            with open(self.cache_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def _save_cache(self):
        with open(self.cache_file, 'w') as f:
            json.dump(self.cache, f)
    
    def _graph_hash(self, G: nx.Graph) -> str:
        """计算图的哈希"""
        edges = sorted(G.edges())
        return hashlib.md5(str(edges).encode()).hexdigest()
    
    def detect_with_cache(self, G: nx.Graph) -> Dict:
        """带缓存的社区检测"""
        graph_hash = self._graph_hash(G)
        
        if graph_hash in self.cache:
            return self.cache[graph_hash]
        
        # 计算社区
        communities = detect_communities_louvain(G)
        
        # 缓存结果
        self.cache[graph_hash] = communities
        self._save_cache()
        
        return communities
```

---

## 常见问题与解决方案

### 问题1: 社区数量过多

**解决方案**:
```python
def merge_small_communities(
    communities: Dict[int, List[str]],
    min_size: int = 3
) -> Dict[int, List[str]]:
    """合并小社区"""
    large_communities = {}
    small_members = []
    
    for comm_id, members in communities.items():
        if len(members) >= min_size:
            large_communities[comm_id] = members
        else:
            small_members.extend(members)
    
    if small_members:
        # 将小社区成员合并到一个"其他"社区
        large_communities[-1] = small_members
    
    return large_communities
```

### 问题2: 社区摘要成本高

**解决方案**:
1. 只为大社区生成摘要
2. 使用更便宜的模型(gpt-4o-mini)
3. 批量生成摘要

---

## 检查清单

掌握社区检测算法后,你应该能够:

- [ ] 理解社区检测的作用
- [ ] 使用Leiden/Louvain算法
- [ ] 计算模块度评估质量
- [ ] 实现分层社区检测
- [ ] 为社区生成摘要
- [ ] 实现Global Search
- [ ] 优化社区检测性能

---

**版本**: v1.0 (基于2025-2026生产级实践)
**最后更新**: 2026-02-17
**维护者**: Claude Code
