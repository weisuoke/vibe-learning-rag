# 核心概念 09：知识图谱RAG

## 什么是GraphRAG？

**GraphRAG**是结合知识图谱和检索增强生成的架构，通过图结构增强RAG系统的检索和推理能力。

**核心特点**：
- 结构化知识：显式的实体和关系
- 多跳推理：支持复杂查询
- 可解释性：提供推理路径
- 混合检索：向量+图+关键词

**与传统RAG的区别**：

| 特性 | 传统RAG | GraphRAG |
|------|---------|----------|
| 知识表示 | 文档块 | 实体+关系 |
| 检索方式 | 向量相似度 | 图遍历+向量 |
| 推理能力 | 弱 | 强（多跳） |
| 可解释性 | 低 | 高（路径） |

---

## GraphRAG架构

### 完整流程

```
文档输入
  ↓
┌─────────────────────────────────┐
│  文档处理                        │
│  - 分块                          │
│  - 实体提取                      │
│  - 关系抽取                      │
└─────────────────────────────────┘
  ↓
┌─────────────────────────────────┐
│  知识图谱构建                    │
│  - 实体标准化                    │
│  - 关系标准化                    │
│  - 图存储（Neo4j）               │
│  - 向量索引                      │
└─────────────────────────────────┘
  ↓
┌─────────────────────────────────┐
│  查询处理                        │
│  - 实体识别                      │
│  - 查询改写                      │
└─────────────────────────────────┘
  ↓
┌─────────────────────────────────┐
│  混合检索                        │
│  - 向量检索（语义）              │
│  - 图检索（关系）                │
│  - 结果融合                      │
└─────────────────────────────────┘
  ↓
┌─────────────────────────────────┐
│  答案生成                        │
│  - 上下文构建                    │
│  - LLM生成                       │
│  - 幻觉检测                      │
└─────────────────────────────────┘
  ↓
最终答案 + 推理路径
```

---

## 实现GraphRAG

### 1. 文档处理

```python
from typing import List, Dict
from openai import OpenAI

client = OpenAI()

class DocumentProcessor:
    """文档处理器"""

    def process(self, document: str) -> Dict:
        """处理文档"""
        # 1. 分块
        chunks = self._chunk_document(document)

        # 2. 提取实体和关系
        triples = []
        for chunk in chunks:
            chunk_triples = self._extract_triples(chunk)
            triples.extend(chunk_triples)

        # 3. 去重和标准化
        triples = self._deduplicate(triples)

        return {
            "chunks": chunks,
            "triples": triples
        }

    def _chunk_document(self, document: str, chunk_size: int = 500) -> List[str]:
        """文档分块"""
        # 简单按句子分块
        sentences = document.split("。")
        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk) + len(sentence) < chunk_size:
                current_chunk += sentence + "。"
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence + "。"

        if current_chunk:
            chunks.append(current_chunk)

        return chunks

    def _extract_triples(self, text: str) -> List[Dict]:
        """提取三元组"""
        prompt = f"""
从以下文本中提取实体和关系。

文本：{text}

返回JSON格式：
{{
    "triples": [
        {{
            "subject": {{"name": "实体名", "type": "类型"}},
            "predicate": "关系",
            "object": {{"name": "实体名", "type": "类型"}}
        }}
    ]
}}
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        import json
        result = json.loads(response.choices[0].message.content)
        return result["triples"]

    def _deduplicate(self, triples: List[Dict]) -> List[Dict]:
        """去重"""
        seen = set()
        unique = []

        for triple in triples:
            key = (
                triple["subject"]["name"],
                triple["predicate"],
                triple["object"]["name"]
            )
            if key not in seen:
                seen.add(key)
                unique.append(triple)

        return unique
```

### 2. 知识图谱构建

```python
from neo4j import GraphDatabase

class KnowledgeGraphBuilder:
    """知识图谱构建器"""

    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str):
        self.driver = GraphDatabase.driver(
            neo4j_uri,
            auth=(neo4j_user, neo4j_password)
        )

    def build(self, triples: List[Dict], chunks: List[str]):
        """构建知识图谱"""
        # 1. 创建实体节点
        self._create_entities(triples)

        # 2. 创建关系
        self._create_relations(triples)

        # 3. 添加向量索引
        self._add_embeddings(chunks)

    def _create_entities(self, triples: List[Dict]):
        """创建实体节点"""
        with self.driver.session() as session:
            for triple in triples:
                # 创建主语实体
                session.run("""
                    MERGE (e:Entity {name: $name})
                    SET e.type = $type
                """,
                    name=triple["subject"]["name"],
                    type=triple["subject"]["type"]
                )

                # 创建宾语实体
                session.run("""
                    MERGE (e:Entity {name: $name})
                    SET e.type = $type
                """,
                    name=triple["object"]["name"],
                    type=triple["object"]["type"]
                )

    def _create_relations(self, triples: List[Dict]):
        """创建关系"""
        with self.driver.session() as session:
            for triple in triples:
                session.run("""
                    MATCH (s:Entity {name: $subject})
                    MATCH (o:Entity {name: $object})
                    MERGE (s)-[r:RELATION {type: $predicate}]->(o)
                """,
                    subject=triple["subject"]["name"],
                    predicate=triple["predicate"],
                    object=triple["object"]["name"]
                )

    def _add_embeddings(self, chunks: List[str]):
        """添加向量索引"""
        for chunk in chunks:
            # 生成向量
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=chunk
            )
            embedding = response.data[0].embedding

            # 存储到Neo4j
            with self.driver.session() as session:
                session.run("""
                    CREATE (c:Chunk {content: $content, embedding: $embedding})
                """, content=chunk, embedding=embedding)
```

### 3. 查询处理

```python
class QueryProcessor:
    """查询处理器"""

    def process(self, query: str) -> Dict:
        """处理查询"""
        # 1. 实体识别
        entities = self._extract_entities(query)

        # 2. 查询改写
        rewritten_queries = self._rewrite_query(query)

        return {
            "original_query": query,
            "entities": entities,
            "rewritten_queries": rewritten_queries
        }

    def _extract_entities(self, query: str) -> List[str]:
        """提取查询中的实体"""
        prompt = f"""
从以下查询中提取实体名称。

查询：{query}

只返回实体名称列表，JSON格式：{{"entities": ["实体1", "实体2"]}}
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        import json
        result = json.loads(response.choices[0].message.content)
        return result["entities"]

    def _rewrite_query(self, query: str) -> List[str]:
        """查询改写"""
        prompt = f"""
将以下查询改写成3个不同的表述，保持语义不变。

原查询：{query}

返回JSON格式：{{"queries": ["改写1", "改写2", "改写3"]}}
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        import json
        result = json.loads(response.choices[0].message.content)
        return result["queries"]
```

### 4. 混合检索

```python
class GraphRAGRetriever:
    """GraphRAG检索器"""

    def __init__(self, neo4j_driver):
        self.driver = neo4j_driver

    def retrieve(self, query_info: Dict, top_k: int = 10) -> Dict:
        """混合检索"""
        # 1. 向量检索
        vector_results = self._vector_search(
            query_info["original_query"],
            top_k
        )

        # 2. 图检索
        graph_results = self._graph_search(
            query_info["entities"],
            top_k
        )

        # 3. 结果融合
        merged_results = self._merge_results(
            vector_results,
            graph_results,
            top_k
        )

        return {
            "vector_results": vector_results,
            "graph_results": graph_results,
            "merged_results": merged_results
        }

    def _vector_search(self, query: str, top_k: int) -> List[Dict]:
        """向量检索"""
        # 生成查询向量
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=query
        )
        query_embedding = response.data[0].embedding

        # 向量检索
        with self.driver.session() as session:
            result = session.run("""
                MATCH (c:Chunk)
                WHERE c.embedding IS NOT NULL
                WITH c, vector.similarity.cosine(c.embedding, $query_embedding) AS score
                WHERE score > 0.7
                RETURN c.content AS content, score
                ORDER BY score DESC
                LIMIT $top_k
            """, query_embedding=query_embedding, top_k=top_k)

            return [
                {"content": record["content"], "score": record["score"]}
                for record in result
            ]

    def _graph_search(self, entities: List[str], top_k: int) -> List[Dict]:
        """图检索"""
        results = []

        with self.driver.session() as session:
            for entity in entities:
                result = session.run("""
                    MATCH path = (e:Entity {name: $entity})-[*1..2]-(related)
                    RETURN path
                    LIMIT $top_k
                """, entity=entity, top_k=top_k)

                for record in result:
                    path = record["path"]
                    results.append({
                        "content": self._format_path(path),
                        "score": 1.0,
                        "path": path
                    })

        return results

    def _format_path(self, path) -> str:
        """格式化路径"""
        nodes = [dict(node) for node in path.nodes]
        rels = [rel.type for rel in path.relationships]

        parts = []
        for i, node in enumerate(nodes):
            parts.append(node.get("name", str(node)))
            if i < len(rels):
                parts.append(f"--[{rels[i]}]-->")

        return " ".join(parts)

    def _merge_results(
        self,
        vector_results: List[Dict],
        graph_results: List[Dict],
        top_k: int
    ) -> List[Dict]:
        """结果融合（RRF）"""
        k = 60
        rrf_scores = {}

        for rank, result in enumerate(vector_results, 1):
            key = result["content"]
            rrf_scores[key] = rrf_scores.get(key, 0) + 1 / (k + rank)

        for rank, result in enumerate(graph_results, 1):
            key = result["content"]
            rrf_scores[key] = rrf_scores.get(key, 0) + 1 / (k + rank)

        sorted_results = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return [
            {"content": content, "score": score}
            for content, score in sorted_results[:top_k]
        ]
```

### 5. 答案生成

```python
class AnswerGenerator:
    """答案生成器"""

    def generate(self, query: str, retrieval_results: Dict) -> Dict:
        """生成答案"""
        # 1. 构建上下文
        context = self._build_context(retrieval_results)

        # 2. 生成答案
        answer = self._generate_answer(query, context)

        # 3. 提取推理路径
        reasoning_path = self._extract_reasoning_path(
            retrieval_results["graph_results"]
        )

        return {
            "answer": answer,
            "context": context,
            "reasoning_path": reasoning_path,
            "sources": retrieval_results["merged_results"]
        }

    def _build_context(self, retrieval_results: Dict) -> str:
        """构建上下文"""
        context_parts = []

        # 添加向量检索结果
        context_parts.append("## 相关文档：")
        for i, result in enumerate(retrieval_results["vector_results"][:3], 1):
            context_parts.append(f"{i}. {result['content']}")

        # 添加图检索结果
        context_parts.append("\n## 相关关系：")
        for i, result in enumerate(retrieval_results["graph_results"][:3], 1):
            context_parts.append(f"{i}. {result['content']}")

        return "\n".join(context_parts)

    def _generate_answer(self, query: str, context: str) -> str:
        """生成答案"""
        prompt = f"""
基于以下上下文回答问题。

上下文：
{context}

问题：{query}

要求：
1. 基于上下文回答
2. 如果上下文不足，说明"信息不足"
3. 提供推理过程

答案：
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return response.choices[0].message.content

    def _extract_reasoning_path(self, graph_results: List[Dict]) -> List[str]:
        """提取推理路径"""
        paths = []
        for result in graph_results:
            if "path" in result:
                paths.append(result["content"])
        return paths
```

---

## 完整的GraphRAG系统

```python
class GraphRAGSystem:
    """完整的GraphRAG系统"""

    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str):
        self.processor = DocumentProcessor()
        self.builder = KnowledgeGraphBuilder(neo4j_uri, neo4j_user, neo4j_password)
        self.query_processor = QueryProcessor()
        self.retriever = GraphRAGRetriever(self.builder.driver)
        self.generator = AnswerGenerator()

    def index_document(self, document: str):
        """索引文档"""
        # 1. 处理文档
        processed = self.processor.process(document)

        # 2. 构建知识图谱
        self.builder.build(
            processed["triples"],
            processed["chunks"]
        )

        print(f"索引完成：{len(processed['triples'])}个三元组，{len(processed['chunks'])}个文档块")

    def query(self, question: str) -> Dict:
        """查询"""
        # 1. 处理查询
        query_info = self.query_processor.process(question)

        # 2. 混合检索
        retrieval_results = self.retriever.retrieve(query_info)

        # 3. 生成答案
        result = self.generator.generate(question, retrieval_results)

        return result

# 使用示例
system = GraphRAGSystem(
    neo4j_uri="bolt://localhost:7687",
    neo4j_user="neo4j",
    neo4j_password="password"
)

# 索引文档
documents = [
    "张三在阿里巴巴工作，担任高级工程师。",
    "阿里巴巴总部位于杭州西湖区。",
    "李四也在阿里巴巴工作，是张三的同事。"
]

for doc in documents:
    system.index_document(doc)

# 查询
result = system.query("张三在哪个城市工作？")
print(f"答案：{result['answer']}")
print(f"\n推理路径：")
for path in result['reasoning_path']:
    print(f"  - {path}")
```

---

## 使用Neo4j GraphRAG包

### 2025-2026官方方案

```python
from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline
from neo4j_graphrag.llm import OpenAILLM
from neo4j_graphrag.retrievers import VectorRetriever, VectorCypherRetriever
from neo4j import GraphDatabase

# 初始化
llm = OpenAILLM(model_name="gpt-4", api_key="your-api-key")
driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))

# 1. 构建知识图谱
kg_pipeline = SimpleKGPipeline(
    llm=llm,
    driver=driver,
    entities=["Person", "Company", "Location"],
    relations=["WORKS_AT", "LOCATED_IN", "KNOWS"],
    from_pdf=False
)

# 索引文档
text = "张三在阿里巴巴工作，阿里巴巴位于杭州。"
kg_pipeline.run(text=text)

# 2. 混合检索
retriever = VectorCypherRetriever(
    driver=driver,
    index_name="entity_embedding",
    retrieval_query="""
    MATCH (node)-[r]->(related)
    RETURN node.name + ' ' + type(r) + ' ' + related.name AS text,
           score,
           {entity: node.name, relation: type(r), related: related.name} AS metadata
    """
)

# 查询
results = retriever.search(query_text="张三在哪工作？", top_k=5)
for result in results:
    print(f"内容：{result.content}")
    print(f"分数：{result.score}")
    print(f"元数据：{result.metadata}")
```

---

## 评估GraphRAG

### 评估指标

```python
def evaluate_graphrag(
    test_queries: List[Dict],  # {"query": "...", "ground_truth": "..."}
    system: GraphRAGSystem
):
    """评估GraphRAG系统"""
    metrics = {
        "accuracy": [],
        "retrieval_precision": [],
        "reasoning_quality": []
    }

    for test in test_queries:
        query = test["query"]
        ground_truth = test["ground_truth"]

        # 执行查询
        result = system.query(query)

        # 1. 答案准确性
        accuracy = evaluate_answer_accuracy(
            result["answer"],
            ground_truth
        )
        metrics["accuracy"].append(accuracy)

        # 2. 检索精确度
        precision = evaluate_retrieval_precision(
            result["sources"],
            test.get("relevant_docs", [])
        )
        metrics["retrieval_precision"].append(precision)

        # 3. 推理质量
        reasoning_quality = evaluate_reasoning_quality(
            result["reasoning_path"]
        )
        metrics["reasoning_quality"].append(reasoning_quality)

    # 计算平均值
    return {
        metric: sum(values) / len(values)
        for metric, values in metrics.items()
    }

def evaluate_answer_accuracy(answer: str, ground_truth: str) -> float:
    """评估答案准确性（使用LLM）"""
    prompt = f"""
评估答案的准确性。

标准答案：{ground_truth}
生成答案：{answer}

返回0-1之间的分数，1表示完全正确。
只返回数字。
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return float(response.choices[0].message.content.strip())
```

---

## 生产案例

### 企业知识库问答

```python
# 场景：企业内部知识库
documents = [
    "公司政策：员工每年有15天年假。",
    "张三是技术部门的负责人。",
    "技术部门位于3楼。",
    "李四向张三汇报工作。"
]

# 索引
for doc in documents:
    system.index_document(doc)

# 查询
queries = [
    "张三的办公室在哪？",  # 需要推理：张三 -> 技术部门 -> 3楼
    "李四的上级在哪个楼层？",  # 需要多跳：李四 -> 张三 -> 技术部门 -> 3楼
    "员工有多少天年假？"  # 直接检索
]

for query in queries:
    result = system.query(query)
    print(f"\n问题：{query}")
    print(f"答案：{result['answer']}")
    print(f"推理路径：{result['reasoning_path']}")
```

---

## 总结

### GraphRAG的核心价值

1. **结构化知识**：显式的实体和关系
2. **多跳推理**：支持复杂查询
3. **可解释性**：提供推理路径
4. **混合检索**：向量+图的优势结合

### 适用场景

**适合GraphRAG如果**：
- 需要复杂推理
- 需要可解释性
- 有结构化知识
- 企业知识库

**不适合GraphRAG如果**：
- 简单问答
- 无关系数据
- 实时性要求极高

### 最佳实践

1. **实体标准化**：统一实体表示
2. **关系标准化**：统一关系类型
3. **混合检索**：结合向量和图
4. **质量评估**：持续监控和优化

---

**引用来源**：
- [Neo4j GraphRAG](https://neo4j.com/docs/neo4j-graphrag-python)
- [Microsoft GraphRAG](https://microsoft.github.io/graphrag/)
- [GraphRAG论文](https://arxiv.org/abs/2404.16130)
- [Neo4j GraphRAG教程](https://neo4j.com/developer/graph-data-science/graphrag/)

---

**版本**：v1.0
**最后更新**：2026-02-14
**维护者**：Claude Code
