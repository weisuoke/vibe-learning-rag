# 实战代码 场景4：混合检索RAG系统

## 场景描述

构建完整的混合检索RAG系统，结合向量检索和图检索的优势。

**目标**：
- 向量检索实现
- 图检索实现
- 结果融合（RRF）
- LLM生成答案
- 完整的RAG流程

**技术栈**：
- Python 3.13+
- ChromaDB（向量存储）
- Neo4j（图存储）
- OpenAI API

---

## 完整代码

```python
"""
混合检索RAG系统

功能：
1. 向量检索
2. 图检索
3. 结果融合（RRF）
4. LLM生成答案
5. 可解释性
"""

from typing import List, Dict, Optional
from dataclasses import dataclass
from openai import OpenAI
import chromadb
from neo4j import GraphDatabase

client = OpenAI()


@dataclass
class SearchResult:
    """检索结果"""
    content: str
    score: float
    source: str  # "vector", "graph", "hybrid"
    metadata: Optional[Dict] = None


class VectorRetriever:
    """向量检索器"""

    def __init__(self, collection_name: str = "documents"):
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.get_or_create_collection(
            name=collection_name
        )

    def add_documents(self, documents: List[str]):
        """添加文档"""
        # 生成向量
        embeddings = []
        for doc in documents:
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=doc
            )
            embeddings.append(response.data[0].embedding)

        # 存储
        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            ids=[f"doc_{i}" for i in range(len(documents))]
        )

        print(f"✓ 添加了 {len(documents)} 个文档到向量库")

    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """向量检索"""
        # 生成查询向量
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=query
        )
        query_embedding = response.data[0].embedding

        # 检索
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        return [
            SearchResult(
                content=doc,
                score=1 - distance,  # 转换为相似度
                source="vector"
            )
            for doc, distance in zip(
                results["documents"][0],
                results["distances"][0]
            )
        ]


class GraphRetriever:
    """图检索器"""

    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str):
        self.driver = GraphDatabase.driver(
            neo4j_uri,
            auth=(neo4j_user, neo4j_password)
        )

    def search(self, entities: List[str], max_hops: int = 2) -> List[SearchResult]:
        """图检索"""
        results = []

        with self.driver.session() as session:
            for entity in entities:
                result = session.run("""
                    MATCH path = (e:Entity {name: $entity})-[*1..$max_hops]-(related)
                    RETURN path
                    LIMIT 10
                """, entity=entity, max_hops=max_hops)

                for record in result:
                    path = record["path"]
                    content = self._format_path(path)
                    results.append(SearchResult(
                        content=content,
                        score=1.0,
                        source="graph",
                        metadata={"entity": entity, "path": path}
                    ))

        return results

    def _format_path(self, path) -> str:
        """格式化路径"""
        nodes = [dict(node) for node in path.nodes]
        rels = [rel.type for rel in path.relationships]

        parts = []
        for i, node in enumerate(nodes):
            parts.append(node.get("name", str(node)))
            if i < len(rels):
                parts.append(f"--[{rels[i]}]-->")

        return " ".join(parts)


class HybridRetriever:
    """混合检索器"""

    def __init__(
        self,
        vector_retriever: VectorRetriever,
        graph_retriever: GraphRetriever
    ):
        self.vector_retriever = vector_retriever
        self.graph_retriever = graph_retriever

    def search(
        self,
        query: str,
        entities: List[str],
        top_k: int = 10
    ) -> List[SearchResult]:
        """混合检索"""
        # 1. 向量检索
        vector_results = self.vector_retriever.search(query, top_k)

        # 2. 图检索
        graph_results = self.graph_retriever.search(entities, max_hops=2)

        # 3. 结果融合（RRF）
        merged_results = self._rrf_fusion(
            vector_results,
            graph_results,
            top_k
        )

        return merged_results

    def _rrf_fusion(
        self,
        vector_results: List[SearchResult],
        graph_results: List[SearchResult],
        top_k: int,
        k: int = 60
    ) -> List[SearchResult]:
        """Reciprocal Rank Fusion"""
        rrf_scores = {}

        # 向量检索结果
        for rank, result in enumerate(vector_results, 1):
            key = result.content
            rrf_scores[key] = rrf_scores.get(key, 0) + 1 / (k + rank)

        # 图检索结果
        for rank, result in enumerate(graph_results, 1):
            key = result.content
            rrf_scores[key] = rrf_scores.get(key, 0) + 1 / (k + rank)

        # 排序
        sorted_results = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return [
            SearchResult(content=content, score=score, source="hybrid")
            for content, score in sorted_results[:top_k]
        ]


class RAGSystem:
    """完整的RAG系统"""

    def __init__(
        self,
        vector_retriever: VectorRetriever,
        graph_retriever: GraphRetriever
    ):
        self.hybrid_retriever = HybridRetriever(
            vector_retriever,
            graph_retriever
        )

    def query(self, question: str) -> Dict:
        """查询"""
        # 1. 提取实体
        entities = self._extract_entities(question)

        # 2. 混合检索
        results = self.hybrid_retriever.search(
            query=question,
            entities=entities,
            top_k=5
        )

        # 3. 构建上下文
        context = self._build_context(results)

        # 4. 生成答案
        answer = self._generate_answer(question, context)

        # 5. 提取推理路径
        reasoning_paths = self._extract_reasoning_paths(results)

        return {
            "answer": answer,
            "context": context,
            "sources": results,
            "reasoning_paths": reasoning_paths,
            "entities": entities
        }

    def _extract_entities(self, query: str) -> List[str]:
        """提取实体"""
        prompt = f"""
从以下查询中提取实体名称。

查询：{query}

只返回实体名称列表，JSON格式：{{"entities": ["实体1", "实体2"]}}
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        import json
        result = json.loads(response.choices[0].message.content)
        return result.get("entities", [])

    def _build_context(self, results: List[SearchResult]) -> str:
        """构建上下文"""
        context_parts = []

        for i, result in enumerate(results, 1):
            context_parts.append(f"[{i}] {result.content}")

            # 如果是图检索结果，添加来源标记
            if result.source == "graph":
                context_parts.append(f"    (来源: 知识图谱)")

        return "\n\n".join(context_parts)

    def _generate_answer(self, question: str, context: str) -> str:
        """生成答案"""
        prompt = f"""
基于以下上下文回答问题。

上下文：
{context}

问题：{question}

要求：
1. 基于上下文回答
2. 如果上下文不足，说明"信息不足"
3. 提供推理过程

答案：
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return response.choices[0].message.content

    def _extract_reasoning_paths(
        self,
        results: List[SearchResult]
    ) -> List[str]:
        """提取推理路径"""
        paths = []
        for result in results:
            if result.source == "graph" and result.metadata:
                paths.append(result.content)
        return paths


def main():
    """主函数"""
    print("=== 混合检索RAG系统 ===\n")

    # 1. 初始化向量检索器
    print("1. 初始化向量检索器")
    print("-" * 50)
    vector_retriever = VectorRetriever()

    # 添加文档
    documents = [
        "张三在阿里巴巴工作，担任高级工程师。",
        "张三使用Python和机器学习技术开发推荐系统。",
        "阿里巴巴总部位于杭州西湖区。",
        "阿里巴巴是中国最大的电商公司之一。",
        "李四也在阿里巴巴工作，是张三的同事。",
        "李四负责数据分析工作。",
        "杭州是浙江省的省会城市。",
        "浙江省位于中国东南沿海。"
    ]
    vector_retriever.add_documents(documents)

    # 2. 初始化图检索器
    print("\n2. 初始化图检索器")
    print("-" * 50)
    graph_retriever = GraphRetriever(
        neo4j_uri="bolt://localhost:7687",
        neo4j_user="neo4j",
        neo4j_password="password"
    )
    print("✓ 图检索器初始化成功")

    # 3. 创建RAG系统
    print("\n3. 创建RAG系统")
    print("-" * 50)
    rag = RAGSystem(vector_retriever, graph_retriever)
    print("✓ RAG系统创建成功")

    # 4. 测试查询
    print("\n4. 测试查询")
    print("-" * 50)

    queries = [
        "张三在哪个城市工作？",
        "张三使用什么技术？",
        "李四的工作内容是什么？"
    ]

    for query in queries:
        print(f"\n问题：{query}")
        print("-" * 30)

        result = rag.query(query)

        print(f"\n答案：{result['answer']}")

        print(f"\n提取的实体：{', '.join(result['entities'])}")

        print(f"\n检索到的来源 ({len(result['sources'])}个):")
        for i, source in enumerate(result['sources'][:3], 1):
            print(f"  {i}. [{source.source}] {source.content[:50]}...")

        if result['reasoning_paths']:
            print(f"\n推理路径 ({len(result['reasoning_paths'])}条):")
            for i, path in enumerate(result['reasoning_paths'][:2], 1):
                print(f"  {i}. {path}")

    # 5. 性能对比
    print("\n\n5. 性能对比")
    print("-" * 50)

    query = "张三在哪个城市工作？"

    # 只用向量检索
    vector_results = vector_retriever.search(query, top_k=5)
    print(f"\n向量检索结果 ({len(vector_results)}个):")
    for i, result in enumerate(vector_results[:3], 1):
        print(f"  {i}. {result.content[:50]}... (分数: {result.score:.2f})")

    # 只用图检索
    entities = ["张三"]
    graph_results = graph_retriever.search(entities, max_hops=2)
    print(f"\n图检索结果 ({len(graph_results)}个):")
    for i, result in enumerate(graph_results[:3], 1):
        print(f"  {i}. {result.content[:50]}...")

    # 混合检索
    hybrid_results = rag.hybrid_retriever.search(query, entities, top_k=5)
    print(f"\n混合检索结果 ({len(hybrid_results)}个):")
    for i, result in enumerate(hybrid_results[:3], 1):
        print(f"  {i}. {result.content[:50]}... (分数: {result.score:.2f})")

    print("\n✓ 完成")


if __name__ == "__main__":
    main()
```

---

## 运行示例

```bash
# 1. 启动Neo4j
docker run -d \
  --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/password \
  neo4j:latest

# 2. 确保已构建知识图谱（运行场景2）
python examples/kg/02_neo4j_builder.py

# 3. 设置环境变量
export OPENAI_API_KEY="your-api-key"

# 4. 运行
python examples/kg/04_hybrid_rag.py
```

**预期输出**：
```
=== 混合检索RAG系统 ===

1. 初始化向量检索器
--------------------------------------------------
✓ 添加了 8 个文档到向量库

2. 初始化图检索器
--------------------------------------------------
✓ 图检索器初始化成功

3. 创建RAG系统
--------------------------------------------------
✓ RAG系统创建成功

4. 测试查询
--------------------------------------------------

问题：张三在哪个城市工作？
------------------------------

答案：根据上下文信息，张三在阿里巴巴工作，而阿里巴巴总部位于杭州西湖区。因此，张三在杭州工作。

推理过程：
1. 张三在阿里巴巴工作
2. 阿里巴巴位于杭州
3. 所以张三在杭州工作

提取的实体：张三

检索到的来源 (5个):
  1. [hybrid] 张三在阿里巴巴工作，担任高级工程师。...
  2. [hybrid] 阿里巴巴总部位于杭州西湖区。...
  3. [hybrid] 张三 --[WORKS_AT]--> 阿里巴巴 --[LOCATED_IN]--> 杭州...

推理路径 (1条):
  1. 张三 --[WORKS_AT]--> 阿里巴巴 --[LOCATED_IN]--> 杭州

...

5. 性能对比
--------------------------------------------------

向量检索结果 (5个):
  1. 张三在阿里巴巴工作，担任高级工程师。 (分数: 0.89)
  2. 张三使用Python和机器学习技术开发推荐系统。 (分数: 0.76)
  3. 李四也在阿里巴巴工作，是张三的同事。 (分数: 0.72)

图检索结果 (3个):
  1. 张三 --[WORKS_AT]--> 阿里巴巴
  2. 张三 --[USES]--> Python
  3. 张三 --[COLLEAGUE]--> 李四

混合检索结果 (5个):
  1. 张三在阿里巴巴工作，担任高级工程师。 (分数: 0.92)
  2. 张三 --[WORKS_AT]--> 阿里巴巴 --[LOCATED_IN]--> 杭州 (分数: 0.88)
  3. 阿里巴巴总部位于杭州西湖区。 (分数: 0.85)

✓ 完成
```

---

## 扩展功能

### 1. ReRank重排序

```python
def rerank_results(
    query: str,
    results: List[SearchResult],
    top_k: int = 5
) -> List[SearchResult]:
    """使用LLM重排序"""
    documents_text = "\n\n".join([
        f"[{i}] {r.content}"
        for i, r in enumerate(results)
    ])

    prompt = f"""
给定查询和文档列表，按相关性从高到低排序文档。

查询：{query}

文档：
{documents_text}

返回文档编号列表（JSON格式）：{{"indices": ["0", "2", "1", ...]}}
只返回最相关的{top_k}个文档编号。
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    import json
    ranked_indices = json.loads(response.choices[0].message.content)["indices"]

    return [results[int(idx)] for idx in ranked_indices[:top_k]]
```

### 2. 查询改写

```python
def rewrite_query(query: str) -> List[str]:
    """查询改写"""
    prompt = f"""
将以下查询改写成3个不同的表述，保持语义不变。

原查询：{query}

返回JSON格式：{{"queries": ["改写1", "改写2", "改写3"]}}
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    import json
    result = json.loads(response.choices[0].message.content)
    return result["queries"]
```

### 3. 幻觉检测

```python
def detect_hallucination(answer: str, context: str) -> bool:
    """检测幻觉"""
    prompt = f"""
判断答案是否基于上下文，还是包含幻觉内容。

上下文：
{context}

答案：
{answer}

返回JSON格式：{{"has_hallucination": true/false, "reason": "原因"}}
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    import json
    result = json.loads(response.choices[0].message.content)
    return result["has_hallucination"]
```

---

## 总结

本示例实现了完整的混合检索RAG系统，包括：
- 向量检索（语义相似度）
- 图检索（关系遍历）
- RRF结果融合
- LLM答案生成
- 推理路径提取

**核心优势**：
- 结合向量和图的优势
- 提供可解释的推理路径
- 支持复杂查询
- 提高检索准确率

**适用场景**：
- 企业知识库问答
- 文档智能检索
- 复杂问题推理

**下一步**：
- 添加ReRank重排序
- 实现查询改写
- 添加幻觉检测
- 集成LangGraph

---

**版本**：v1.0
**最后更新**：2026-02-14
**维护者**：Claude Code
