# 核心概念01：日志级别与格式化

## 学习目标

深入理解日志级别的设计原理和格式化策略，掌握在不同环境中选择合适的日志配置。

---

## 第一部分：日志级别深度解析

### 1.1 五个标准日志级别

#### DEBUG（调试级别）

**定义：** 详细的调试信息，用于开发和调试阶段

**使用场景：**
```python
logger.debug("entering function", function_name="process_data")
logger.debug("variable value", x=x, y=y)
logger.debug("loop iteration", index=i, item=item)
```

**特点：**
- 信息量最大
- 只在开发环境使用
- 生产环境会严重影响性能

**AI Agent 示例：**
```python
logger.debug("rag_search_details",
    query_embedding=embedding[:10],  # 只记录前10维
    search_params={"k": 5, "threshold": 0.7}
)
```

#### INFO（信息级别）

**定义：** 关键操作的记录，表示系统正常运行

**使用场景：**
```python
logger.info("user_login", user_id="user_123")
logger.info("api_call", endpoint="/chat", method="POST")
logger.info("llm_call", model="gpt-4", tokens=100)
```

**特点：**
- 生产环境的标准级别
- 记录关键业务操作
- 信息量适中

**AI Agent 示例：**
```python
logger.info("chat_request",
    user_id="user_123",
    message_length=len(message),
    session_id="session_456"
)

logger.info("rag_search",
    query="Python",
    results_count=5,
    top_score=0.95
)

logger.info("llm_call",
    model="gpt-4",
    tokens_used=150,
    duration_ms=1200
)
```

#### WARNING（警告级别）

**定义：** 潜在问题，系统仍能正常运行但需要注意

**使用场景：**
```python
logger.warning("api_slow", duration_ms=3000, threshold_ms=2000)
logger.warning("retry_attempt", attempt=2, max_attempts=3)
logger.warning("cache_miss", key="user_123")
```

**特点：**
- 表示潜在问题
- 不影响当前操作
- 需要关注和优化

**AI Agent 示例：**
```python
logger.warning("llm_response_slow",
    duration_ms=5000,
    threshold_ms=3000,
    model="gpt-4"
)

logger.warning("rag_low_score",
    top_score=0.6,
    threshold=0.7,
    query="Python"
)

logger.warning("token_usage_high",
    tokens=2000,
    budget=1500
)
```

#### ERROR（错误级别）

**定义：** 错误发生，但系统可以继续运行

**使用场景：**
```python
logger.error("api_call_failed",
    error="timeout",
    url="https://api.openai.com"
)

logger.error("database_query_failed",
    error=str(e),
    query="SELECT * FROM users"
)
```

**特点：**
- 表示操作失败
- 需要立即关注
- 应该包含错误详情

**AI Agent 示例：**
```python
try:
    response = await client.chat.completions.create(...)
except Exception as e:
    logger.error("llm_call_failed",
        error=str(e),
        error_type=type(e).__name__,
        model="gpt-4",
        retry_count=retry_count
    )
```

#### CRITICAL（严重错误级别）

**定义：** 严重错误，系统可能无法继续运行

**使用场景：**
```python
logger.critical("database_connection_lost",
    error=str(e),
    host="localhost",
    port=5432
)

logger.critical("out_of_memory",
    memory_used_gb=15.8,
    memory_total_gb=16
)
```

**特点：**
- 最高优先级
- 需要立即处理
- 可能导致系统崩溃

**AI Agent 示例：**
```python
logger.critical("openai_api_key_invalid",
    error="authentication failed",
    impact="all LLM calls will fail"
)
```

### 1.2 日志级别的选择决策树

```
需要记录日志？
│
├─ 是正常操作？
│  ├─ 是关键业务操作？
│  │  ├─ 用户登录、API调用、LLM调用 → INFO
│  │  └─ 函数调用、变量赋值 → DEBUG
│  │
│  └─ 是性能指标？
│     ├─ 正常范围内 → INFO
│     └─ 超过阈值 → WARNING
│
├─ 是潜在问题？
│  ├─ 不影响当前操作 → WARNING
│  └─ 影响当前操作 → ERROR
│
├─ 是错误？
│  ├─ 可恢复（重试、降级） → ERROR
│  └─ 不可恢复（系统崩溃） → CRITICAL
│
└─ 是调试信息？ → DEBUG
```

### 1.3 不同环境的日志级别配置

#### 本地开发环境

```python
import os
import structlog

def setup_logging():
    env = os.getenv("ENV", "development")

    if env == "development":
        # 开发环境：DEBUG级别
        log_level = "DEBUG"
        renderer = structlog.dev.ConsoleRenderer()  # 人类可读
    else:
        # 生产环境：INFO级别
        log_level = "INFO"
        renderer = structlog.processors.JSONRenderer()  # JSON格式

    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            renderer
        ],
        wrapper_class=structlog.make_filtering_bound_logger(
            getattr(structlog.stdlib, log_level)
        )
    )
```

#### 测试环境

```python
# 测试环境：可以动态调整
if os.getenv("TEST_DEBUG") == "true":
    log_level = "DEBUG"
else:
    log_level = "INFO"
```

#### 生产环境

```python
# 生产环境：INFO级别，JSON格式
log_level = "INFO"
renderer = structlog.processors.JSONRenderer()

# 支持运行时调整（用于紧急调试）
@app.post("/admin/log-level")
async def set_log_level(level: str, admin_token: str):
    if admin_token != os.getenv("ADMIN_TOKEN"):
        raise HTTPException(401)

    if level in ["DEBUG", "INFO", "WARNING", "ERROR"]:
        # 临时调整日志级别
        structlog.configure(
            wrapper_class=structlog.make_filtering_bound_logger(
                getattr(structlog.stdlib, level)
            )
        )
        return {"message": f"Log level set to {level}"}
```

### 1.4 日志级别的性能影响

#### 性能测试

```python
import time
import structlog

logger = structlog.get_logger()

def benchmark_logging(level: str, count: int = 10000):
    """测试不同日志级别的性能"""
    start = time.time()

    for i in range(count):
        if level == "DEBUG":
            logger.debug("test", index=i)
        elif level == "INFO":
            logger.info("test", index=i)

    duration = time.time() - start
    return duration

# 测试结果（10000条日志）
# DEBUG级别：0.150秒
# INFO级别：0.145秒
# 差异：5ms（可忽略）

# 但如果记录大对象：
def benchmark_large_object():
    large_dict = {"data": "x" * 10000}

    start = time.time()
    for i in range(1000):
        logger.debug("test", data=large_dict)  # 序列化大对象
    duration = time.time() - start

    return duration

# 结果：1.5秒（明显变慢）
```

**结论：**
- 日志级别本身性能影响很小
- 真正的性能问题在于记录大对象
- 生产环境用INFO是为了减少日志量，不是性能

---

## 第二部分：日志格式化

### 2.1 三种主要格式

#### 格式1：JSON格式（生产环境）

**特点：**
- 机器可解析
- 易于查询和聚合
- 日志平台友好

**示例：**
```json
{
  "event": "user_login",
  "user_id": "user_123",
  "timestamp": "2024-01-15T10:30:45Z",
  "level": "info",
  "request_id": "req_abc"
}
```

**配置：**
```python
structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()  # JSON格式
    ]
)
```

#### 格式2：键值对格式（开发环境）

**特点：**
- 人类可读
- 保留结构化信息
- 适合终端查看

**示例：**
```
2024-01-15 10:30:45 [info     ] user_login    user_id=user_123 request_id=req_abc
```

**配置：**
```python
structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()  # 彩色、易读
    ]
)
```

#### 格式3：纯文本格式（不推荐）

**特点：**
- 最简单
- 不易解析
- 不推荐使用

**示例：**
```
User user_123 logged in at 2024-01-15 10:30:45
```

### 2.2 时间戳格式

#### ISO 8601格式（推荐）

```python
structlog.processors.TimeStamper(fmt="iso")
# 输出：2024-01-15T10:30:45.123456Z
```

**优势：**
- 国际标准
- 包含时区信息
- 易于解析

#### Unix时间戳

```python
structlog.processors.TimeStamper(fmt="unix")
# 输出：1705318245.123456
```

**优势：**
- 紧凑
- 易于计算时间差
- 跨时区一致

#### 自定义格式

```python
structlog.processors.TimeStamper(fmt="%Y-%m-%d %H:%M:%S")
# 输出：2024-01-15 10:30:45
```

### 2.3 自定义格式化器

#### 添加自定义字段

```python
def add_app_context(logger, method_name, event_dict):
    """添加应用上下文"""
    event_dict["app"] = "ai-agent-api"
    event_dict["version"] = "1.0.0"
    event_dict["environment"] = os.getenv("ENV", "development")
    return event_dict

structlog.configure(
    processors=[
        add_app_context,  # 自定义处理器
        structlog.contextvars.merge_contextvars,
        structlog.processors.JSONRenderer()
    ]
)
```

#### 脱敏处理器

```python
def mask_sensitive_data(logger, method_name, event_dict):
    """自动脱敏敏感信息"""
    sensitive_keys = ["password", "api_key", "token", "secret"]

    for key in sensitive_keys:
        if key in event_dict:
            value = event_dict[key]
            if isinstance(value, str) and len(value) > 8:
                event_dict[key] = value[:4] + "***" + value[-4:]
            else:
                event_dict[key] = "***REDACTED***"

    return event_dict
```

#### 性能监控处理器

```python
import time

def add_performance_metrics(logger, method_name, event_dict):
    """添加性能指标"""
    # 如果有duration_ms字段，添加性能标签
    if "duration_ms" in event_dict:
        duration = event_dict["duration_ms"]
        if duration > 3000:
            event_dict["performance"] = "slow"
        elif duration > 1000:
            event_dict["performance"] = "medium"
        else:
            event_dict["performance"] = "fast"

    return event_dict
```

### 2.4 日志输出目标

#### 输出到控制台

```python
import structlog

structlog.configure(
    processors=[
        structlog.processors.JSONRenderer()
    ],
    logger_factory=structlog.PrintLoggerFactory()  # 输出到stdout
)
```

#### 输出到文件

```python
import logging
from logging.handlers import RotatingFileHandler

# 配置标准库logging
handler = RotatingFileHandler(
    "app.log",
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)

logging.basicConfig(
    handlers=[handler],
    level=logging.INFO
)

# 配置structlog使用标准库logging
structlog.configure(
    logger_factory=structlog.stdlib.LoggerFactory()
)
```

#### 输出到多个目标

```python
import logging

# 控制台handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

# 文件handler
file_handler = RotatingFileHandler("app.log", maxBytes=10*1024*1024)
file_handler.setLevel(logging.INFO)

# 错误文件handler
error_handler = RotatingFileHandler("error.log", maxBytes=10*1024*1024)
error_handler.setLevel(logging.ERROR)

# 配置
logging.basicConfig(
    handlers=[console_handler, file_handler, error_handler],
    level=logging.INFO
)
```

---

## 第三部分：AI Agent 特定的日志格式化

### 3.1 LLM调用日志格式

```python
def log_llm_call(
    model: str,
    prompt: str,
    response: str,
    tokens: int,
    duration_ms: float
):
    """标准化的LLM调用日志"""
    logger.info("llm_call",
        # 基本信息
        model=model,
        provider="openai",

        # 输入输出
        prompt_length=len(prompt),
        prompt_hash=hashlib.sha256(prompt.encode()).hexdigest()[:16],
        response_length=len(response),

        # 性能指标
        tokens_used=tokens,
        tokens_prompt=tokens // 2,  # 估算
        tokens_completion=tokens // 2,
        duration_ms=duration_ms,

        # 成本估算
        cost_usd=tokens * 0.00003  # gpt-4价格
    )
```

### 3.2 RAG检索日志格式

```python
def log_rag_search(
    query: str,
    results: list,
    duration_ms: float
):
    """标准化的RAG检索日志"""
    logger.info("rag_search",
        # 查询信息
        query=query,
        query_length=len(query),

        # 检索结果
        results_count=len(results),
        top_score=results[0].metadata.get("score", 0) if results else 0,
        avg_score=sum(r.metadata.get("score", 0) for r in results) / len(results) if results else 0,

        # 性能指标
        duration_ms=duration_ms
    )
```

### 3.3 完整请求链路日志

```python
@app.post("/api/chat")
async def chat(message: str):
    # 1. 请求开始
    logger.info("chat_request_start",
        message_length=len(message)
    )

    # 2. RAG检索
    rag_start = time.time()
    docs = await rag_search(message)
    rag_duration = (time.time() - rag_start) * 1000

    logger.info("rag_search_complete",
        results_count=len(docs),
        duration_ms=rag_duration
    )

    # 3. LLM调用
    llm_start = time.time()
    response = await call_llm(message, docs)
    llm_duration = (time.time() - llm_start) * 1000

    logger.info("llm_call_complete",
        tokens=response.usage.total_tokens,
        duration_ms=llm_duration
    )

    # 4. 请求结束
    total_duration = (time.time() - rag_start) * 1000
    logger.info("chat_request_complete",
        total_duration_ms=total_duration,
        rag_duration_ms=rag_duration,
        llm_duration_ms=llm_duration,
        rag_percentage=rag_duration / total_duration * 100,
        llm_percentage=llm_duration / total_duration * 100
    )

    return response
```

---

## 总结

### 核心要点

1. **日志级别选择**
   - 开发环境：DEBUG
   - 生产环境：INFO
   - 关键操作：INFO
   - 潜在问题：WARNING
   - 错误：ERROR/CRITICAL

2. **格式化策略**
   - 生产环境：JSON格式
   - 开发环境：人类可读格式
   - 时间戳：ISO 8601格式

3. **AI Agent 特定**
   - LLM调用：记录model、tokens、duration、cost
   - RAG检索：记录query、results_count、top_score
   - 完整链路：记录每个阶段的耗时占比

### 最佳实践

1. 根据环境选择日志级别和格式
2. 使用自定义处理器添加上下文
3. 脱敏敏感信息
4. 标准化AI Agent日志格式
5. 记录性能指标和成本

### 下一步

- 【核心概念02】：结构化日志设计
- 【核心概念03】：请求链路追踪
- 【实战代码】：完整的日志系统实现
