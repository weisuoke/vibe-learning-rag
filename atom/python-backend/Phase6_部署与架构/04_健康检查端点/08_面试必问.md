# 面试必问

> 健康检查端点的高频面试问题和出彩回答

---

## 问题1："请解释 Kubernetes 中 Liveness Probe 和 Readiness Probe 的区别"

### 普通回答（❌ 不出彩）

"Liveness Probe 是检查容器是否存活，Readiness Probe 是检查容器是否准备好。"

**问题：** 太简单，没有展示深度理解

---

### 出彩回答（✅ 推荐）

> **Liveness Probe 和 Readiness Probe 有三层区别：**
>
> **1. 检查目的不同：**
> - **Liveness Probe** 检查进程是否存活（是否死锁、内存泄漏导致无响应）
> - **Readiness Probe** 检查服务是否准备好接收流量（依赖服务是否可用）
>
> **2. 失败处理不同：**
> - **Liveness 失败** → Kubernetes 重启 Pod（破坏性操作）
> - **Readiness 失败** → 从 Service 的 Endpoints 中移除，停止发流量（非破坏性）
>
> **3. 检查内容不同：**
> - **Liveness** 应该简单快速（只检查进程是否响应）
> - **Readiness** 可以检查依赖服务（数据库、Redis、外部 API）
>
> **实际场景举例：**
>
> 在我们的 AI Agent API 中：
> - `/health` 端点用于 Liveness，只要进程运行就返回 200
> - `/ready` 端点用于 Readiness，检查数据库、Redis、LLM API 是否可用
>
> 如果数据库连接断了：
> - Liveness 仍然通过（进程还活着）
> - Readiness 失败（服务不可用）
> - 结果：Pod 不重启，但停止接收新流量，等待数据库恢复
>
> **还有第三种探测：Startup Probe**
> - 用于慢启动的应用（如加载大型 ML 模型）
> - 在 Startup Probe 成功前，Liveness 和 Readiness 不会执行
> - 避免应用启动过程中被误判为不健康而重启

---

### 为什么这个回答出彩？

1. ✅ **多层次解释**：从目的、处理、内容三个维度对比
2. ✅ **实际场景**：结合 AI Agent API 的具体例子
3. ✅ **深度理解**：提到 Startup Probe，展示全面了解
4. ✅ **实践经验**：说明在实际项目中如何使用

---

## 问题2："健康检查端点应该检查哪些内容？如何避免影响性能？"

### 普通回答（❌ 不出彩）

"健康检查应该检查数据库、Redis 等依赖服务，使用缓存可以避免影响性能。"

**问题：** 没有说明为什么，没有展示权衡思考

---

### 出彩回答（✅ 推荐）

> **健康检查的内容设计需要权衡三个因素：准确性、性能、稳定性**
>
> **1. 分层检查策略：**
>
> **层次1：Liveness（最简单）**
> ```python
> @app.get("/health")
> async def health():
>     # 只检查进程是否响应，不检查依赖
>     return {"status": "healthy"}
> ```
> - 响应时间：< 10ms
> - 检查频率：每 10 秒
> - 失败处理：重启 Pod
>
> **层次2：Readiness（检查关键依赖）**
> ```python
> @app.get("/ready")
> async def ready():
>     # 检查关键依赖，使用缓存
>     checks = await get_cached_health_status()  # 缓存 30 秒
>     if not all(checks.values()):
>         raise HTTPException(503)
>     return {"status": "ready", "checks": checks}
> ```
> - 响应时间：< 100ms
> - 检查频率：每 5 秒
> - 失败处理：停止流量
>
> **层次3：Deep Health（详细检查，手动触发）**
> ```python
> @app.get("/health/deep")
> async def deep_health():
>     # 端到端测试，不缓存
>     return await run_comprehensive_checks()
> ```
> - 响应时间：几秒
> - 检查频率：手动触发或定时任务
> - 失败处理：告警通知
>
> **2. 性能优化策略：**
>
> **策略1：缓存健康检查结果**
> ```python
> health_cache = {"last_check": 0, "checks": {}}
> CACHE_TTL = 30  # 缓存 30 秒
>
> async def get_cached_health_status():
>     if time.time() - health_cache["last_check"] < CACHE_TTL:
>         return health_cache["checks"]
>     # 执行实际检查
>     checks = await check_all_dependencies()
>     health_cache.update({"last_check": time.time(), "checks": checks})
>     return checks
> ```
>
> **策略2：区分核心依赖和可选依赖**
> - **核心依赖**（数据库）：失败 → 返回 503
> - **可选依赖**（Redis）：失败 → 返回 200 但标记为 degraded
>
> **策略3：设置合理的超时时间**
> ```python
> async def check_database():
>     try:
>         # 超时 3 秒
>         await asyncio.wait_for(db.execute("SELECT 1"), timeout=3.0)
>         return True
>     except asyncio.TimeoutError:
>         return False
> ```
>
> **3. 在 AI Agent API 中的实践：**
>
> 我们的健康检查策略：
> - **Liveness**：只检查进程响应（< 10ms）
> - **Readiness**：检查数据库、Redis、LLM API（< 100ms，缓存 30 秒）
> - **不检查**：向量数据库的详细查询（太慢，交给监控系统）
>
> **关键权衡：**
> - 健康检查被调用频率很高（每 5-10 秒）
> - 过于详细的检查会影响性能（每次都查询数据库）
> - 缓存可以平滑短暂抖动，提高稳定性
> - 详细的检查应该由监控系统（Prometheus）负责

---

### 为什么这个回答出彩？

1. ✅ **系统化思考**：分层检查策略，展示架构能力
2. ✅ **权衡分析**：说明准确性、性能、稳定性的权衡
3. ✅ **具体实现**：提供完整的代码示例
4. ✅ **实践经验**：结合 AI Agent API 的实际场景
5. ✅ **深度理解**：说明为什么需要缓存，为什么要区分核心和可选依赖

---

## 问题3："如果健康检查端点本身变慢了，应该如何排查和优化？"

### 普通回答（❌ 不出彩）

"可以检查数据库查询是否慢，优化查询语句。"

**问题：** 没有系统化的排查思路，没有展示问题分析能力

---

### 出彩回答（✅ 推荐）

> **健康检查变慢的排查和优化需要系统化的方法：**
>
> **1. 监控健康检查本身：**
>
> 首先，健康检查本身也需要监控：
>
> ```python
> from prometheus_client import Histogram
>
> health_check_duration = Histogram(
>     'health_check_duration_seconds',
>     'Health check duration',
>     ['endpoint'],
>     buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
> )
>
> @app.get("/ready")
> async def ready():
>     start_time = time.time()
>     try:
>         checks = await check_all_dependencies()
>         return {"status": "ready", "checks": checks}
>     finally:
>         duration = time.time() - start_time
>         health_check_duration.labels(endpoint='ready').observe(duration)
> ```
>
> **2. 排查步骤：**
>
> **步骤1：确定慢在哪里**
>
> 为每个依赖检查添加计时：
>
> ```python
> async def check_all_dependencies():
>     results = {}
>     timings = {}
>
>     # 检查数据库
>     start = time.time()
>     results["database"] = await check_database()
>     timings["database"] = time.time() - start
>
>     # 检查 Redis
>     start = time.time()
>     results["redis"] = await check_redis()
>     timings["redis"] = time.time() - start
>
>     # 检查 LLM API
>     start = time.time()
>     results["llm_api"] = await check_llm_api()
>     timings["llm_api"] = time.time() - start
>
>     # 记录慢的检查
>     for service, duration in timings.items():
>         if duration > 0.1:  # 超过 100ms
>             logger.warning(f"Slow health check: {service} took {duration:.3f}s")
>
>     return results
> ```
>
> **步骤2：分析原因**
>
> 常见原因：
> - **数据库连接池耗尽**：所有连接都在使用，健康检查等待连接
> - **依赖服务响应慢**：外部 API 或 Redis 响应变慢
> - **网络延迟**：依赖服务在远程，网络延迟高
> - **没有使用缓存**：每次都实时检查
> - **检查内容太复杂**：执行了复杂的查询或计算
>
> **步骤3：优化策略**
>
> **优化1：使用缓存**
> ```python
> # 缓存健康检查结果 30 秒
> health_cache = {"last_check": 0, "checks": {}}
> CACHE_TTL = 30
>
> async def get_cached_health_status():
>     if time.time() - health_cache["last_check"] < CACHE_TTL:
>         return health_cache["checks"]
>     checks = await check_all_dependencies()
>     health_cache.update({"last_check": time.time(), "checks": checks})
>     return checks
> ```
>
> **优化2：并发检查**
> ```python
> async def check_all_dependencies():
>     # 并发检查所有依赖，而不是串行
>     results = await asyncio.gather(
>         check_database(),
>         check_redis(),
>         check_llm_api(),
>         return_exceptions=True
>     )
>     return {
>         "database": results[0] if not isinstance(results[0], Exception) else False,
>         "redis": results[1] if not isinstance(results[1], Exception) else False,
>         "llm_api": results[2] if not isinstance(results[2], Exception) else False,
>     }
> ```
>
> **优化3：设置超时**
> ```python
> async def check_database():
>     try:
>         # 超时 3 秒，避免长时间等待
>         await asyncio.wait_for(
>             db.execute("SELECT 1"),
>             timeout=3.0
>         )
>         return True
>     except asyncio.TimeoutError:
>         logger.warning("Database health check timeout")
>         return False
> ```
>
> **优化4：简化检查内容**
> ```python
> # ❌ 错误：检查太复杂
> async def check_database():
>     await db.execute("SELECT COUNT(*) FROM users")  # 慢
>     await db.execute("SELECT COUNT(*) FROM conversations")  # 慢
>
> # ✅ 正确：简单快速
> async def check_database():
>     await db.execute("SELECT 1")  # 快
> ```
>
> **3. 在 AI Agent API 中的实践：**
>
> 我们遇到过健康检查变慢的问题：
> - **原因**：LLM API 健康检查每次都发送真实请求，响应慢
> - **优化**：改为只检查 API 连接性（HTTP HEAD 请求），不发送真实请求
> - **结果**：健康检查从 2 秒降到 50ms
>
> **监控告警：**
> ```yaml
> # Prometheus 告警规则
> - alert: HealthCheckSlow
>   expr: |
>     histogram_quantile(0.95,
>       rate(health_check_duration_seconds_bucket[5m])
>     ) > 1.0
>   for: 5m
>   annotations:
>     summary: "Health check is slow (p95 > 1s)"
> ```

---

### 为什么这个回答出彩？

1. ✅ **系统化排查**：监控 → 定位 → 分析 → 优化
2. ✅ **具体方法**：提供完整的代码示例
3. ✅ **多种优化策略**：缓存、并发、超时、简化
4. ✅ **实践经验**：分享实际遇到的问题和解决方案
5. ✅ **监控集成**：说明如何通过监控发现问题

---

## 问题4："在微服务架构中，如何设计健康检查来避免级联故障？"

### 普通回答（❌ 不出彩）

"可以设置超时时间，避免一个服务故障影响其他服务。"

**问题：** 太简单，没有展示对分布式系统的理解

---

### 出彩回答（✅ 推荐）

> **避免级联故障需要多层防护：**
>
> **1. 问题场景：**
>
> 假设有这样的服务依赖链：
> ```
> 用户 → API Gateway → AI Agent API → [数据库, Redis, LLM API]
> ```
>
> **级联故障场景：**
> - LLM API 响应慢（10 秒）
> - AI Agent API 的健康检查调用 LLM API，也变慢（10 秒）
> - API Gateway 检查 AI Agent API 健康，超时
> - API Gateway 认为 AI Agent API 不健康，停止发流量
> - 实际上 AI Agent API 本身是健康的，只是 LLM API 慢
>
> **2. 防护策略：**
>
> **策略1：区分核心依赖和可选依赖**
>
> ```python
> @app.get("/ready")
> async def ready():
>     checks = {
>         "database": await check_database(),      # 核心依赖
>         "redis": await check_redis(),            # 可选依赖
>         "llm_api": await check_llm_api(),        # 可选依赖
>     }
>
>     # 只有核心依赖失败才返回不健康
>     if not checks["database"]:
>         raise HTTPException(503, "Database unavailable")
>
>     # 可选依赖失败，返回降级状态
>     if not checks["llm_api"]:
>         return {
>             "status": "degraded",
>             "message": "LLM API unavailable, using fallback",
>             "checks": checks
>         }
>
>     return {"status": "healthy", "checks": checks}
> ```
>
> **策略2：设置合理的超时时间**
>
> ```python
> async def check_llm_api():
>     try:
>         # 超时 3 秒，避免长时间等待
>         await asyncio.wait_for(
>             llm_client.check_health(),
>             timeout=3.0
>         )
>         return True
>     except asyncio.TimeoutError:
>         # 超时视为不健康，但不阻塞整个健康检查
>         return False
> ```
>
> **策略3：使用熔断器模式**
>
> ```python
> class CircuitBreaker:
>     def __init__(self, failure_threshold=5, timeout=60):
>         self.failure_count = 0
>         self.failure_threshold = failure_threshold
>         self.timeout = timeout
>         self.last_failure_time = None
>         self.state = "closed"  # closed, open, half_open
>
>     async def call(self, func):
>         # 如果熔断器打开，直接返回失败
>         if self.state == "open":
>             if time.time() - self.last_failure_time > self.timeout:
>                 self.state = "half_open"  # 尝试恢复
>             else:
>                 return False  # 快速失败，不调用依赖服务
>
>         try:
>             result = await func()
>             if self.state == "half_open":
>                 self.state = "closed"  # 恢复正常
>                 self.failure_count = 0
>             return result
>         except Exception:
>             self.failure_count += 1
>             if self.failure_count >= self.failure_threshold:
>                 self.state = "open"  # 打开熔断器
>                 self.last_failure_time = time.time()
>             return False
>
> # 使用熔断器
> llm_api_breaker = CircuitBreaker(failure_threshold=5, timeout=60)
>
> async def check_llm_api():
>     return await llm_api_breaker.call(
>         lambda: llm_client.check_health()
>     )
> ```
>
> **策略4：健康检查不应该依赖下游服务的健康检查**
>
> ```python
> # ❌ 错误：递归检查下游服务
> async def check_llm_api():
>     # 调用 LLM API 的健康检查端点
>     response = await http_client.get("https://api.openai.com/health")
>     # 如果 OpenAI 的健康检查也检查它的依赖，会导致级联
>     return response.status_code == 200
>
> # ✅ 正确：只检查连接性
> async def check_llm_api():
>     try:
>         # 只检查能否连接，不调用健康检查端点
>         await asyncio.wait_for(
>             http_client.head("https://api.openai.com"),
>             timeout=3.0
>         )
>         return True
>     except Exception:
>         return False
> ```
>
> **策略5：使用缓存 + 异步更新**
>
> ```python
> class AsyncHealthChecker:
>     def __init__(self):
>         self.cache = {"status": "unknown", "last_check": 0}
>         self.checking = False
>
>     async def get_status(self):
>         # 返回缓存状态
>         if time.time() - self.cache["last_check"] < 30:
>             return self.cache["status"]
>
>         # 如果没有正在检查，启动异步检查
>         if not self.checking:
>             asyncio.create_task(self._update_status())
>
>         # 返回旧的缓存状态，不阻塞
>         return self.cache["status"]
>
>     async def _update_status(self):
>         self.checking = True
>         try:
>             status = await check_all_dependencies()
>             self.cache = {"status": status, "last_check": time.time()}
>         finally:
>             self.checking = False
> ```
>
> **3. 在 AI Agent API 中的实践：**
>
> 我们的防护策略：
> - **核心依赖**（数据库）：失败 → 返回 503
> - **可选依赖**（LLM API）：失败 → 返回 degraded，使用缓存响应
> - **超时设置**：所有依赖检查超时 3 秒
> - **熔断器**：LLM API 连续失败 5 次，打开熔断器 60 秒
> - **缓存**：健康检查结果缓存 30 秒
>
> **结果：**
> - LLM API 故障时，AI Agent API 仍然可用（降级模式）
> - 避免了级联故障
> - 用户体验：部分功能不可用，但核心功能正常

---

### 为什么这个回答出彩？

1. ✅ **问题分析**：清晰说明级联故障的场景
2. ✅ **多层防护**：5 种防护策略，展示全面思考
3. ✅ **具体实现**：提供完整的代码示例（熔断器、异步更新）
4. ✅ **实践经验**：分享实际的防护策略和效果
5. ✅ **系统化思维**：展示对分布式系统的深刻理解

---

## 总结

面试中回答健康检查问题的关键：

1. **多层次解释**：从原理、实现、应用多个维度说明
2. **对比分析**：说明不同方案的优缺点和适用场景
3. **具体实现**：提供完整的代码示例
4. **实践经验**：结合实际项目的场景和问题
5. **系统化思维**：展示对分布式系统的理解

在 AI Agent 后端开发中，健康检查不仅是技术问题，更是架构设计和可靠性工程的体现。
