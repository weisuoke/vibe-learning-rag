# 实战代码1：固定大小分块实现

完整可运行的固定大小分块代码示例（2025-2026 NVIDIA 推荐配置）。

---

## 基础实现

```python
"""
固定大小分块实现
NVIDIA 2025 推荐配置：chunk_size=512, overlap=77 (15%)
"""

def fixed_size_chunk(
    text: str,
    chunk_size: int = 512,
    chunk_overlap: int = 77
) -> list[str]:
    """
    固定大小分块（NVIDIA 2025 推荐）
    
    Args:
        text: 原始文本
        chunk_size: 块大小（默认 512，适合事实查询）
        chunk_overlap: 重叠大小（默认 77，15% overlap）
    
    Returns:
        分块后的文本列表
    """
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - chunk_overlap
    
    return chunks

# 测试
text = "Python是一种编程语言。" * 100
chunks = fixed_size_chunk(text)

print(f"原文长度: {len(text)}")
print(f"分块数: {len(chunks)}")
print(f"第一块: {chunks[0][:50]}...")
```

---

## 查询类型自适应（NVIDIA 2025）

```python
"""
根据查询类型自适应调整块大小
研究来源: NVIDIA 2025 Chunking Benchmark
"""

from typing import Literal

QueryType = Literal["factual", "analytical", "mixed"]

def adaptive_fixed_chunk(
    text: str,
    query_type: QueryType = "factual"
) -> list[str]:
    """
    查询类型自适应分块（NVIDIA 2025）
    
    Args:
        text: 原始文本
        query_type: 查询类型
            - factual: 事实查询（256-512 tokens）
            - analytical: 分析查询（1024+ tokens）
            - mixed: 混合查询（512-768 tokens）
    
    Returns:
        分块后的文本列表
    """
    # NVIDIA 2025 推荐配置
    config = {
        "factual": {"chunk_size": 512, "overlap_ratio": 0.15},
        "analytical": {"chunk_size": 1024, "overlap_ratio": 0.15},
        "mixed": {"chunk_size": 768, "overlap_ratio": 0.15}
    }
    
    cfg = config[query_type]
    chunk_size = cfg["chunk_size"]
    chunk_overlap = int(chunk_size * cfg["overlap_ratio"])
    
    return fixed_size_chunk(text, chunk_size, chunk_overlap)

# 测试不同查询类型
text = "Python编程语言..." * 200

factual_chunks = adaptive_fixed_chunk(text, "factual")
analytical_chunks = adaptive_fixed_chunk(text, "analytical")

print(f"事实查询分块数: {len(factual_chunks)}")
print(f"分析查询分块数: {len(analytical_chunks)}")
```

---

## 优化实现：避免切断单词

```python
"""
优化的固定大小分块：在单词边界切分
"""

def fixed_chunk_preserve_words(
    text: str,
    chunk_size: int = 512,
    chunk_overlap: int = 77
) -> list[str]:
    """
    固定大小分块（避免切断单词）
    
    在接近 chunk_size 时，向后查找最近的空格或标点
    """
    chunks = []
    start = 0
    
    while start < len(text):
        end = min(start + chunk_size, len(text))
        
        # 如果不是文本末尾，尝试在单词边界切分
        if end < len(text):
            # 向后查找最近的空格或标点（最多回退50个字符）
            for i in range(end, max(start, end - 50), -1):
                if text[i] in ' \n。！？.!?':
                    end = i + 1
                    break
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        start = end - chunk_overlap
    
    return chunks

# 测试
text = """
Python是一种广泛使用的编程语言。它以简洁的语法和强大的功能而闻名。
Python支持多种编程范式，包括面向对象、命令式、函数式和过程式编程。
""" * 10

chunks = fixed_chunk_preserve_words(text, chunk_size=100, chunk_overlap=15)

for i, chunk in enumerate(chunks[:3]):
    print(f"\nChunk {i+1}:")
    print(chunk)
```

---

## 完整生产级实现

```python
"""
生产级固定大小分块实现
包含：验证、统计、元数据
"""

from typing import List, Dict
from dataclasses import dataclass

@dataclass
class ChunkMetadata:
    """Chunk 元数据"""
    index: int
    start: int
    end: int
    size: int
    overlap_with_prev: int

class FixedSizeChunker:
    """固定大小分块器（生产级）"""
    
    def __init__(
        self,
        chunk_size: int = 512,
        overlap_ratio: float = 0.15,
        preserve_words: bool = True
    ):
        """
        初始化分块器
        
        Args:
            chunk_size: 块大小（NVIDIA 2025: 512 for factual）
            overlap_ratio: 重叠比例（NVIDIA 2025: 0.15 最优）
            preserve_words: 是否避免切断单词
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = int(chunk_size * overlap_ratio)
        self.preserve_words = preserve_words
    
    def chunk(self, text: str) -> List[Dict]:
        """
        执行分块
        
        Returns:
            包含 chunk 和 metadata 的字典列表
        """
        chunks = []
        start = 0
        index = 0
        
        while start < len(text):
            end = min(start + self.chunk_size, len(text))
            
            # 避免切断单词
            if self.preserve_words and end < len(text):
                for i in range(end, max(start, end - 50), -1):
                    if text[i] in ' \n。！？.!?':
                        end = i + 1
                        break
            
            chunk = text[start:end].strip()
            
            if chunk:
                # 计算与前一个块的重叠
                overlap_with_prev = 0
                if index > 0:
                    prev_chunk = chunks[-1]["chunk"]
                    # 简单估算重叠
                    overlap_with_prev = self.chunk_overlap
                
                chunks.append({
                    "chunk": chunk,
                    "metadata": ChunkMetadata(
                        index=index,
                        start=start,
                        end=end,
                        size=len(chunk),
                        overlap_with_prev=overlap_with_prev
                    )
                })
                index += 1
            
            start = end - self.chunk_overlap
        
        return chunks
    
    def get_statistics(self, chunks: List[Dict]) -> Dict:
        """获取分块统计信息"""
        sizes = [c["metadata"].size for c in chunks]
        
        return {
            "total_chunks": len(chunks),
            "min_size": min(sizes) if sizes else 0,
            "max_size": max(sizes) if sizes else 0,
            "avg_size": sum(sizes) // len(sizes) if sizes else 0,
            "target_size": self.chunk_size,
            "overlap": self.chunk_overlap,
            "overlap_ratio": f"{(self.chunk_overlap / self.chunk_size * 100):.1f}%"
        }

# 使用示例
chunker = FixedSizeChunker(
    chunk_size=512,
    overlap_ratio=0.15,  # NVIDIA 2025 最优
    preserve_words=True
)

text = "你的长文本..." * 100
chunks = chunker.chunk(text)
stats = chunker.get_statistics(chunks)

print("分块统计:")
for key, value in stats.items():
    print(f"  {key}: {value}")

print(f"\n前3个块:")
for chunk_data in chunks[:3]:
    print(f"\nChunk {chunk_data['metadata'].index}:")
    print(f"  大小: {chunk_data['metadata'].size}")
    print(f"  内容: {chunk_data['chunk'][:100]}...")
```

---

## 性能对比测试

```python
"""
对比不同配置的性能
"""

import time

def benchmark_chunking(text: str, configs: List[Dict]):
    """对比不同配置的分块性能"""
    results = []
    
    for config in configs:
        chunker = FixedSizeChunker(**config)
        
        start_time = time.time()
        chunks = chunker.chunk(text)
        elapsed = time.time() - start_time
        
        stats = chunker.get_statistics(chunks)
        stats["elapsed_ms"] = f"{elapsed * 1000:.2f}"
        stats["config"] = config
        
        results.append(stats)
    
    return results

# 测试数据
text = "Python编程语言..." * 1000  # 约10万字符

# 不同配置
configs = [
    {"chunk_size": 256, "overlap_ratio": 0.15},  # 小块
    {"chunk_size": 512, "overlap_ratio": 0.15},  # NVIDIA 推荐
    {"chunk_size": 1024, "overlap_ratio": 0.15}, # 大块
]

results = benchmark_chunking(text, configs)

print("性能对比:")
for result in results:
    print(f"\nchunk_size={result['config']['chunk_size']}:")
    print(f"  分块数: {result['total_chunks']}")
    print(f"  平均大小: {result['avg_size']}")
    print(f"  耗时: {result['elapsed_ms']} ms")
```

---

## 核心研究来源

**NVIDIA 2025**: [Finding the Best Chunking Strategy](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses)
- 推荐 chunk_size=512（事实查询）
- 推荐 15% 重叠率
- 查询类型决定块大小

---

**下一步：** [07_实战代码_02_递归分块实现](./07_实战代码_02_递归分块实现.md)
