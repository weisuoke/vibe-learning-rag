# 实战代码 - 场景1：负载均衡配置与监控

## 场景描述

本示例演示如何配置 Milvus 分布式集群的负载均衡，并监控负载分布情况。

**目标**：
- 配置负载均衡策略
- 监控各节点的负载情况
- 识别并处理热点数据
- 验证负载均衡效果

---

## 完整代码

```python
"""
Milvus 分布式优化 - 负载均衡配置与监控
演示：如何配置和监控 Milvus 集群的负载均衡
"""

import time
import requests
from typing import Dict, List
from pymilvus import (
    connections,
    Collection,
    FieldSchema,
    CollectionSchema,
    DataType,
    utility
)
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed


# ===== 1. 连接配置 =====
def connect_to_milvus():
    """连接到 Milvus 集群"""
    print("=== 连接到 Milvus 集群 ===")
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )
    print(f"✓ 已连接到 Milvus")
    print(f"  版本: {utility.get_server_version()}")


# ===== 2. 创建测试 Collection =====
def create_test_collection(collection_name: str, dim: int = 128):
    """创建测试用的 Collection"""
    print(f"\n=== 创建 Collection: {collection_name} ===")

    # 检查是否已存在
    if utility.has_collection(collection_name):
        print(f"✓ Collection 已存在，删除旧的")
        utility.drop_collection(collection_name)

    # 定义 Schema
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim),
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100)
    ]
    schema = CollectionSchema(fields=fields, description="负载均衡测试")

    # 创建 Collection
    collection = Collection(name=collection_name, schema=schema)
    print(f"✓ Collection 创建成功")

    return collection


# ===== 3. 插入测试数据 =====
def insert_test_data(collection: Collection, num_vectors: int = 100000):
    """插入测试数据"""
    print(f"\n=== 插入 {num_vectors} 条测试数据 ===")

    batch_size = 10000
    categories = ["electronics", "books", "clothing", "food", "toys"]

    for i in range(0, num_vectors, batch_size):
        # 生成随机向量
        vectors = np.random.rand(batch_size, 128).tolist()

        # 生成类别
        cats = [categories[j % len(categories)] for j in range(i, i + batch_size)]

        # 插入数据
        data = [vectors, cats]
        collection.insert(data)

        if (i + batch_size) % 50000 == 0:
            print(f"  已插入 {i + batch_size} 条数据")

    # 刷盘
    collection.flush()
    print(f"✓ 数据插入完成")


# ===== 4. 创建索引 =====
def create_index(collection: Collection):
    """创建向量索引"""
    print(f"\n=== 创建索引 ===")

    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "L2",
        "params": {"nlist": 128}
    }

    collection.create_index(
        field_name="embedding",
        index_params=index_params
    )
    print(f"✓ 索引创建成功")


# ===== 5. 加载 Collection（配置副本数）=====
def load_collection_with_replicas(collection: Collection, replica_number: int = 2):
    """加载 Collection 并配置副本数"""
    print(f"\n=== 加载 Collection（副本数: {replica_number}）===")

    collection.load(replica_number=replica_number)
    print(f"✓ Collection 已加载")

    # 等待加载完成
    time.sleep(5)


# ===== 6. 监控节点负载 =====
def monitor_node_load() -> Dict:
    """监控各个 QueryNode 的负载情况"""
    print(f"\n=== 监控节点负载 ===")

    try:
        # 从 Prometheus metrics 获取负载信息
        metrics_url = "http://localhost:9091/metrics"
        response = requests.get(metrics_url, timeout=5)

        if response.status_code != 200:
            print(f"⚠ 无法获取 metrics（状态码: {response.status_code}）")
            return {}

        metrics_text = response.text
        node_metrics = {}

        # 解析 QueryNode 的内存使用率
        for line in metrics_text.split('\n'):
            if 'milvus_querynode_memory_usage_bytes' in line and not line.startswith('#'):
                parts = line.split()
                if len(parts) >= 2:
                    # 提取 node_id
                    if 'node_id=' in line:
                        node_id = line.split('node_id="')[1].split('"')[0]
                        memory_bytes = float(parts[-1])
                        memory_mb = memory_bytes / 1024 / 1024

                        if node_id not in node_metrics:
                            node_metrics[node_id] = {}
                        node_metrics[node_id]['memory_mb'] = memory_mb

            # 解析 Segment 数量
            if 'milvus_querynode_segment_num' in line and not line.startswith('#'):
                parts = line.split()
                if len(parts) >= 2:
                    if 'node_id=' in line:
                        node_id = line.split('node_id="')[1].split('"')[0]
                        segment_count = int(float(parts[-1]))

                        if node_id not in node_metrics:
                            node_metrics[node_id] = {}
                        node_metrics[node_id]['segment_count'] = segment_count

        # 打印负载信息
        if node_metrics:
            print(f"\n节点负载分布：")
            for node_id, metrics in node_metrics.items():
                memory = metrics.get('memory_mb', 0)
                segments = metrics.get('segment_count', 0)
                print(f"  Node {node_id}:")
                print(f"    内存使用: {memory:.1f} MB")
                print(f"    Segment 数: {segments}")
        else:
            print(f"⚠ 未找到节点负载信息（可能是单节点部署）")

        return node_metrics

    except Exception as e:
        print(f"⚠ 监控失败: {e}")
        return {}


# ===== 7. 并发查询测试 =====
def concurrent_query_test(collection: Collection, num_queries: int = 100, concurrency: int = 10):
    """并发查询测试，验证负载均衡效果"""
    print(f"\n=== 并发查询测试（{num_queries} 个查询，并发度 {concurrency}）===")

    def single_query(query_id: int):
        """单个查询任务"""
        start_time = time.time()

        # 生成随机查询向量
        query_vector = np.random.rand(1, 128).tolist()

        # 执行查询
        results = collection.search(
            data=query_vector,
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=10
        )

        elapsed = time.time() - start_time
        return query_id, elapsed

    # 并发执行查询
    latencies = []
    start_time = time.time()

    with ThreadPoolExecutor(max_workers=concurrency) as executor:
        futures = [executor.submit(single_query, i) for i in range(num_queries)]

        for future in as_completed(futures):
            query_id, latency = future.result()
            latencies.append(latency)

            if (query_id + 1) % 20 == 0:
                print(f"  已完成 {query_id + 1} 个查询")

    total_time = time.time() - start_time

    # 统计结果
    latencies.sort()
    avg_latency = sum(latencies) / len(latencies)
    p50_latency = latencies[len(latencies) // 2]
    p95_latency = latencies[int(len(latencies) * 0.95)]
    p99_latency = latencies[int(len(latencies) * 0.99)]
    qps = num_queries / total_time

    print(f"\n查询性能统计：")
    print(f"  总耗时: {total_time:.2f}秒")
    print(f"  吞吐量: {qps:.1f} QPS")
    print(f"  平均延迟: {avg_latency*1000:.1f}ms")
    print(f"  P50 延迟: {p50_latency*1000:.1f}ms")
    print(f"  P95 延迟: {p95_latency*1000:.1f}ms")
    print(f"  P99 延迟: {p99_latency*1000:.1f}ms")

    return {
        'qps': qps,
        'avg_latency': avg_latency,
        'p50': p50_latency,
        'p95': p95_latency,
        'p99': p99_latency
    }


# ===== 8. 热点数据模拟 =====
def simulate_hot_data_queries(collection: Collection, num_queries: int = 200):
    """模拟热点数据查询（重复查询相同的向量）"""
    print(f"\n=== 模拟热点数据查询 ===")

    # 生成 5 个热点查询向量
    hot_vectors = [np.random.rand(1, 128).tolist() for _ in range(5)]

    latencies = []
    start_time = time.time()

    for i in range(num_queries):
        # 80% 的查询访问热点数据
        if i % 5 < 4:
            query_vector = hot_vectors[i % len(hot_vectors)]
        else:
            query_vector = np.random.rand(1, 128).tolist()

        query_start = time.time()
        results = collection.search(
            data=query_vector,
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=10
        )
        latency = time.time() - query_start
        latencies.append(latency)

        if (i + 1) % 50 == 0:
            print(f"  已完成 {i + 1} 个查询")

    total_time = time.time() - start_time
    avg_latency = sum(latencies) / len(latencies)
    qps = num_queries / total_time

    print(f"\n热点查询性能：")
    print(f"  吞吐量: {qps:.1f} QPS")
    print(f"  平均延迟: {avg_latency*1000:.1f}ms")

    # 如果负载均衡和缓存生效，热点查询的延迟应该更低
    return {'qps': qps, 'avg_latency': avg_latency}


# ===== 9. 对比不同副本数的性能 =====
def compare_replica_performance(collection: Collection):
    """对比不同副本数的查询性能"""
    print(f"\n=== 对比不同副本数的性能 ===")

    results = {}

    for replica_num in [1, 2, 3]:
        print(f"\n--- 测试副本数: {replica_num} ---")

        # 释放之前的加载
        collection.release()
        time.sleep(2)

        # 加载指定副本数
        collection.load(replica_number=replica_num)
        time.sleep(5)

        # 并发查询测试
        perf = concurrent_query_test(collection, num_queries=100, concurrency=20)
        results[replica_num] = perf

    # 打印对比结果
    print(f"\n=== 副本数性能对比 ===")
    print(f"{'副本数':<10} {'QPS':<15} {'平均延迟':<15} {'P99延迟':<15}")
    print("-" * 55)
    for replica_num, perf in results.items():
        print(f"{replica_num:<10} {perf['qps']:<15.1f} {perf['avg_latency']*1000:<15.1f} {perf['p99']*1000:<15.1f}")

    return results


# ===== 10. 主函数 =====
def main():
    """主函数"""
    print("=" * 60)
    print("Milvus 分布式优化 - 负载均衡配置与监控")
    print("=" * 60)

    # 1. 连接到 Milvus
    connect_to_milvus()

    # 2. 创建测试 Collection
    collection_name = "load_balance_demo"
    collection = create_test_collection(collection_name)

    # 3. 插入测试数据
    insert_test_data(collection, num_vectors=100000)

    # 4. 创建索引
    create_index(collection)

    # 5. 加载 Collection（2个副本）
    load_collection_with_replicas(collection, replica_number=2)

    # 6. 监控节点负载（初始状态）
    print("\n【初始负载状态】")
    monitor_node_load()

    # 7. 并发查询测试
    concurrent_query_test(collection, num_queries=100, concurrency=10)

    # 8. 监控节点负载（查询后）
    print("\n【查询后负载状态】")
    monitor_node_load()

    # 9. 热点数据查询测试
    simulate_hot_data_queries(collection, num_queries=200)

    # 10. 监控节点负载（热点查询后）
    print("\n【热点查询后负载状态】")
    monitor_node_load()

    # 11. 对比不同副本数的性能
    compare_replica_performance(collection)

    # 12. 清理
    print(f"\n=== 清理资源 ===")
    collection.release()
    utility.drop_collection(collection_name)
    print(f"✓ 资源清理完成")

    print("\n" + "=" * 60)
    print("测试完成！")
    print("=" * 60)


if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
Milvus 分布式优化 - 负载均衡配置与监控
============================================================
=== 连接到 Milvus 集群 ===
✓ 已连接到 Milvus
  版本: v2.4.0

=== 创建 Collection: load_balance_demo ===
✓ Collection 创建成功

=== 插入 100000 条测试数据 ===
  已插入 50000 条数据
  已插入 100000 条数据
✓ 数据插入完成

=== 创建索引 ===
✓ 索引创建成功

=== 加载 Collection（副本数: 2）===
✓ Collection 已加载

【初始负载状态】
=== 监控节点负载 ===

节点负载分布：
  Node 1:
    内存使用: 1250.5 MB
    Segment 数: 75
  Node 2:
    内存使用: 1180.2 MB
    Segment 数: 73

=== 并发查询测试（100 个查询，并发度 10）===
  已完成 20 个查询
  已完成 40 个查询
  已完成 60 个查询
  已完成 80 个查询
  已完成 100 个查询

查询性能统计：
  总耗时: 2.35秒
  吞吐量: 42.6 QPS
  平均延迟: 23.5ms
  P50 延迟: 22.1ms
  P95 延迟: 28.5ms
  P99 延迟: 32.8ms

【查询后负载状态】
=== 监控节点负载 ===

节点负载分布：
  Node 1:
    内存使用: 1320.8 MB
    Segment 数: 75
  Node 2:
    内存使用: 1245.3 MB
    Segment 数: 73

=== 模拟热点数据查询 ===
  已完成 50 个查询
  已完成 100 个查询
  已完成 150 个查询
  已完成 200 个查询

热点查询性能：
  吞吐量: 95.2 QPS
  平均延迟: 10.5ms

【热点查询后负载状态】
=== 监控节点负载 ===

节点负载分布：
  Node 1:
    内存使用: 1380.5 MB
    Segment 数: 75
  Node 2:
    内存使用: 1295.7 MB
    Segment 数: 73

=== 对比不同副本数的性能 ===

--- 测试副本数: 1 ---
=== 并发查询测试（100 个查询，并发度 20）===
  已完成 20 个查询
  已完成 40 个查询
  已完成 60 个查询
  已完成 80 个查询
  已完成 100 个查询

查询性能统计：
  总耗时: 3.85秒
  吞吐量: 26.0 QPS
  平均延迟: 38.5ms
  P50 延迟: 35.2ms
  P95 延迟: 52.8ms
  P99 延迟: 68.5ms

--- 测试副本数: 2 ---
=== 并发查询测试（100 个查询，并发度 20）===
查询性能统计：
  总耗时: 2.15秒
  吞吐量: 46.5 QPS
  平均延迟: 21.5ms
  P50 延迟: 19.8ms
  P95 延迟: 28.2ms
  P99 延迟: 35.5ms

--- 测试副本数: 3 ---
=== 并发查询测试（100 个查询，并发度 20）===
查询性能统计：
  总耗时: 1.65秒
  吞吐量: 60.6 QPS
  平均延迟: 16.5ms
  P50 延迟: 15.2ms
  P95 延迟: 22.8ms
  P99 延迟: 28.5ms

=== 副本数性能对比 ===
副本数      QPS            平均延迟         P99延迟
-------------------------------------------------------
1          26.0           38.5           68.5
2          46.5           21.5           35.5
3          60.6           16.5           28.5

=== 清理资源 ===
✓ 资源清理完成

============================================================
测试完成！
============================================================
```

---

## 关键观察点

### 1. 负载均衡效果

从监控数据可以看到：
- 两个 QueryNode 的内存使用和 Segment 数量相近
- 说明负载均衡策略生效

### 2. 副本数对性能的影响

| 副本数 | QPS | 平均延迟 | P99延迟 | 性能提升 |
|--------|-----|----------|---------|----------|
| 1 | 26.0 | 38.5ms | 68.5ms | 基准 |
| 2 | 46.5 | 21.5ms | 35.5ms | 1.8x |
| 3 | 60.6 | 16.5ms | 28.5ms | 2.3x |

**结论**：
- 副本数从 1 增加到 2，性能提升明显（1.8x）
- 副本数从 2 增加到 3，性能提升递减（1.3x）
- 推荐使用 2 个副本（平衡性能和成本）

### 3. 热点数据处理

热点查询的平均延迟（10.5ms）明显低于普通查询（23.5ms），说明：
- 缓存生效
- 负载均衡将热点查询分散到多个副本

---

## 优化建议

### 1. 根据实际负载调整副本数

```python
# 低并发场景（< 100 QPS）
collection.load(replica_number=1)

# 中等并发场景（100-1000 QPS）
collection.load(replica_number=2)  # 推荐

# 高并发场景（> 1000 QPS）
collection.load(replica_number=3)
```

### 2. 监控负载均衡指标

定期检查：
- 各节点的内存使用率（目标：< 80%）
- 各节点的 Segment 数量（目标：均衡分布）
- 查询延迟分布（目标：P99 < 100ms）

### 3. 处理热点数据

如果发现某些数据被频繁查询：
- 增加副本数
- 使用分区隔离热点数据
- 启用查询结果缓存
