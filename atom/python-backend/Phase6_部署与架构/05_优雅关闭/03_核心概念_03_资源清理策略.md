# 核心概念：资源清理策略

> 深入理解如何正确清理数据库连接、Redis 连接、文件句柄等资源

---

## 什么是资源清理？

**资源清理（Resource Cleanup）** 是优雅关闭的关键步骤，指在进程退出前，正确释放所有占用的系统资源。

**核心资源类型：**
1. **网络连接**：数据库、Redis、HTTP 客户端、向量数据库
2. **文件句柄**：打开的文件、日志文件、临时文件
3. **内存资源**：缓存、模型、大对象
4. **系统资源**：线程、进程、信号量

**类比：**
- **前端视角**：类似于 React 的 `useEffect` cleanup 函数，组件卸载时清理副作用
- **日常视角**：类似于图书馆闭馆，归还所有借出的书籍、关闭电脑、关灯、锁门

---

## 为什么需要资源清理？

### 问题场景：没有资源清理

```python
# 没有资源清理的"伪优雅关闭"
def signal_handler(signum, frame):
    print("收到信号，立即退出")
    sys.exit(0)  # 立即退出，不清理资源

# 问题：
# 1. 数据库连接未关闭 → 连接泄漏
# 2. Redis 连接未关闭 → 连接泄漏
# 3. 文件句柄未关闭 → 文件描述符泄漏
# 4. 临时文件未删除 → 磁盘空间浪费
# 5. 模型未卸载 → 内存泄漏
```

**实际后果：**
```
数据库端：
- 显示大量 "idle in transaction" 连接
- 连接池耗尽，新连接无法建立
- 需要手动清理或等待超时

系统端：
- 文件描述符泄漏，达到系统限制
- 内存泄漏，可用内存减少
- 临时文件堆积，磁盘空间不足

应用端：
- 重启后无法连接数据库（连接池满）
- 性能下降（资源不足）
- 需要重启数据库或系统
```

---

## 核心资源清理策略

### 1. 数据库连接池清理

**SQLAlchemy 连接池：**

```python
from sqlalchemy.ext.asyncio import create_async_engine

# 创建引擎
engine = create_async_engine(
    "postgresql+asyncpg://user:pass@localhost/db",
    pool_size=10,
    max_overflow=20,
)

async def cleanup_database():
    """清理数据库连接池"""
    print("关闭数据库连接池...")

    # 1. 等待所有活跃连接完成
    # dispose() 会等待所有连接返回连接池
    await engine.dispose()

    print("数据库连接池已关闭")
```

**详细流程：**
```python
async def cleanup_database_detailed():
    """详细的数据库清理流程"""
    print("开始清理数据库连接...")

    # 1. 获取连接池状态
    pool = engine.pool
    print(f"连接池大小: {pool.size()}")
    print(f"已签出连接: {pool.checkedout()}")
    print(f"溢出连接: {pool.overflow()}")

    # 2. 关闭连接池
    # dispose() 会：
    # - 关闭所有空闲连接
    # - 等待所有活跃连接返回
    # - 标记连接池为已关闭
    await engine.dispose()

    print("数据库连接池已关闭")
```

**注意事项：**
- `dispose()` 会等待所有活跃连接完成
- 不会强制中断正在执行的查询
- 关闭后无法再使用该引擎

---

### 2. Redis 连接清理

**Redis 客户端：**

```python
from redis.asyncio import Redis

# 创建 Redis 客户端
redis_client = Redis.from_url(
    "redis://localhost:6379/0",
    encoding="utf-8",
    decode_responses=True,
)

async def cleanup_redis():
    """清理 Redis 连接"""
    print("关闭 Redis 连接...")

    # 1. 等待所有命令完成
    # close() 会等待所有待处理的命令完成
    await redis_client.close()

    # 2. 等待连接关闭
    await redis_client.connection_pool.disconnect()

    print("Redis 连接已关闭")
```

**详细流程：**
```python
async def cleanup_redis_detailed():
    """详细的 Redis 清理流程"""
    print("开始清理 Redis 连接...")

    # 1. 检查连接状态
    try:
        await redis_client.ping()
        print("Redis 连接正常")
    except Exception as e:
        print(f"Redis 连接异常: {e}")

    # 2. 关闭客户端
    await redis_client.close()

    # 3. 断开连接池
    await redis_client.connection_pool.disconnect()

    print("Redis 连接已关闭")
```

---

### 3. 向量数据库连接清理

**Milvus 连接：**

```python
from pymilvus import connections, Collection

# 连接 Milvus
connections.connect(
    alias="default",
    host="localhost",
    port="19530"
)

async def cleanup_vector_db():
    """清理向量数据库连接"""
    print("关闭向量数据库连接...")

    # 1. 等待所有查询完成
    # （Milvus 客户端会自动等待）

    # 2. 断开连接
    connections.disconnect("default")

    print("向量数据库连接已关闭")
```

---

### 4. HTTP 客户端清理

**httpx 客户端：**

```python
import httpx

# 创建 HTTP 客户端
http_client = httpx.AsyncClient(
    timeout=30.0,
    limits=httpx.Limits(max_connections=100)
)

async def cleanup_http_client():
    """清理 HTTP 客户端"""
    print("关闭 HTTP 客户端...")

    # 1. 等待所有请求完成
    # aclose() 会等待所有活跃请求完成
    await http_client.aclose()

    print("HTTP 客户端已关闭")
```

---

### 5. 文件句柄清理

**文件管理：**

```python
from typing import List
import os

# 全局文件句柄列表
open_files: List[IO] = []

def cleanup_files():
    """清理文件句柄"""
    print(f"关闭 {len(open_files)} 个文件句柄...")

    for file_handle in open_files:
        try:
            if not file_handle.closed:
                file_handle.flush()  # 刷新缓冲区
                file_handle.close()  # 关闭文件
        except Exception as e:
            print(f"关闭文件失败: {e}")

    open_files.clear()
    print("文件句柄已关闭")
```

**临时文件清理：**

```python
import tempfile
import shutil

# 临时目录列表
temp_dirs: List[str] = []

def cleanup_temp_files():
    """清理临时文件"""
    print(f"清理 {len(temp_dirs)} 个临时目录...")

    for temp_dir in temp_dirs:
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
        except Exception as e:
            print(f"清理临时目录失败: {e}")

    temp_dirs.clear()
    print("临时文件已清理")
```

---

### 6. Embedding 模型卸载

**SentenceTransformer 模型：**

```python
from sentence_transformers import SentenceTransformer
import torch

# 加载模型
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

def cleanup_embedding_model():
    """卸载 Embedding 模型"""
    print("卸载 Embedding 模型...")

    # 1. 删除模型对象
    global embedding_model
    del embedding_model

    # 2. 释放 GPU 内存（如果使用 GPU）
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    print("Embedding 模型已卸载")
```

---

## 资源清理的顺序

**推荐顺序：**

```python
async def cleanup_all_resources():
    """按顺序清理所有资源"""

    # 1. 停止接收新请求（已在请求排空阶段完成）

    # 2. 等待现有请求完成（已在请求排空阶段完成）

    # 3. 取消后台任务
    print("取消后台任务...")
    for task in background_tasks:
        if not task.done():
            task.cancel()
    await asyncio.gather(*background_tasks, return_exceptions=True)

    # 4. 关闭 HTTP 客户端（避免新的外部请求）
    print("关闭 HTTP 客户端...")
    if http_client:
        await http_client.aclose()

    # 5. 关闭 Redis 连接（缓存层）
    print("关闭 Redis 连接...")
    if redis_client:
        await redis_client.close()
        await redis_client.connection_pool.disconnect()

    # 6. 关闭向量数据库连接
    print("关闭向量数据库连接...")
    if vector_db:
        connections.disconnect("default")

    # 7. 关闭数据库连接池（最后关闭，因为其他操作可能需要数据库）
    print("关闭数据库连接池...")
    if db_engine:
        await db_engine.dispose()

    # 8. 卸载模型（释放内存）
    print("卸载 Embedding 模型...")
    if embedding_model:
        cleanup_embedding_model()

    # 9. 关闭文件句柄
    print("关闭文件句柄...")
    cleanup_files()

    # 10. 清理临时文件
    print("清理临时文件...")
    cleanup_temp_files()

    print("所有资源已清理")
```

**为什么是这个顺序？**
1. **后台任务**：先取消，避免新的资源请求
2. **HTTP 客户端**：避免新的外部请求
3. **Redis**：缓存层，不影响核心功能
4. **向量数据库**：可选功能
5. **数据库**：最后关闭，因为其他操作可能需要
6. **模型**：释放内存
7. **文件**：最后清理

---

## 资源清理的超时控制

```python
async def cleanup_with_timeout():
    """带超时控制的资源清理"""

    # 为每个清理步骤设置超时
    cleanup_steps = [
        ("后台任务", cleanup_background_tasks, 10),
        ("HTTP 客户端", cleanup_http_client, 5),
        ("Redis 连接", cleanup_redis, 5),
        ("向量数据库", cleanup_vector_db, 5),
        ("数据库连接池", cleanup_database, 10),
        ("Embedding 模型", cleanup_embedding_model_async, 5),
        ("文件句柄", cleanup_files_async, 5),
    ]

    for name, cleanup_func, timeout in cleanup_steps:
        print(f"清理 {name}（超时 {timeout}秒）...")
        try:
            await asyncio.wait_for(
                cleanup_func(),
                timeout=timeout
            )
            print(f"✓ {name} 清理完成")
        except asyncio.TimeoutError:
            print(f"✗ {name} 清理超时")
        except Exception as e:
            print(f"✗ {name} 清理失败: {e}")
```

---

## AI Agent 后端特定资源清理

### 1. LLM 客户端清理

```python
from openai import AsyncOpenAI

# OpenAI 客户端
openai_client = AsyncOpenAI()

async def cleanup_llm_client():
    """清理 LLM 客户端"""
    print("关闭 LLM 客户端...")

    # OpenAI 客户端基于 httpx，需要关闭底层 HTTP 客户端
    await openai_client.close()

    print("LLM 客户端已关闭")
```

### 2. LangChain 资源清理

```python
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma

# LangChain 组件
qa_chain = None
vectorstore = None

async def cleanup_langchain():
    """清理 LangChain 资源"""
    print("清理 LangChain 资源...")

    # 1. 清理向量存储
    if vectorstore:
        # Chroma 会自动清理
        pass

    # 2. 清理 Chain
    if qa_chain:
        # Chain 没有显式清理方法，依赖 GC
        pass

    print("LangChain 资源已清理")
```

### 3. Agent 任务队列清理

```python
from typing import Set
import asyncio

# Agent 任务队列
agent_tasks: Set[asyncio.Task] = set()

async def cleanup_agent_tasks():
    """清理 Agent 任务队列"""
    print(f"清理 {len(agent_tasks)} 个 Agent 任务...")

    # 1. 取消所有任务
    for task in agent_tasks:
        if not task.done():
            task.cancel()

    # 2. 等待所有任务完成
    await asyncio.gather(*agent_tasks, return_exceptions=True)

    # 3. 清空任务集合
    agent_tasks.clear()

    print("Agent 任务已清理")
```

---

## 完整示例：生产级资源清理

```python
"""
生产级资源清理实现
演示：完整的资源清理流程
"""

import asyncio
from typing import List, Set, Optional
from sqlalchemy.ext.asyncio import create_async_engine
from redis.asyncio import Redis
import httpx

# ===== 1. 资源管理器 =====
class ResourceManager:
    """资源管理器"""

    def __init__(self):
        # 数据库
        self.db_engine: Optional[AsyncEngine] = None

        # Redis
        self.redis_client: Optional[Redis] = None

        # HTTP 客户端
        self.http_client: Optional[httpx.AsyncClient] = None

        # 后台任务
        self.background_tasks: Set[asyncio.Task] = set()

        # 文件句柄
        self.open_files: List[IO] = []

        # 临时目录
        self.temp_dirs: List[str] = []

    async def initialize(self):
        """初始化资源"""
        # 创建数据库引擎
        self.db_engine = create_async_engine(
            "postgresql+asyncpg://user:pass@localhost/db"
        )

        # 创建 Redis 客户端
        self.redis_client = Redis.from_url("redis://localhost:6379/0")

        # 创建 HTTP 客户端
        self.http_client = httpx.AsyncClient()

    async def cleanup(self, timeout: int = 30):
        """清理所有资源"""
        print("\n========== 开始资源清理 ==========")

        cleanup_steps = [
            ("后台任务", self._cleanup_background_tasks, 10),
            ("HTTP 客户端", self._cleanup_http_client, 5),
            ("Redis 连接", self._cleanup_redis, 5),
            ("数据库连接池", self._cleanup_database, 10),
            ("文件句柄", self._cleanup_files, 5),
            ("临时文件", self._cleanup_temp_files, 5),
        ]

        for name, cleanup_func, step_timeout in cleanup_steps:
            print(f"\n清理 {name}（超时 {step_timeout}秒）...")
            try:
                await asyncio.wait_for(
                    cleanup_func(),
                    timeout=step_timeout
                )
                print(f"✓ {name} 清理完成")
            except asyncio.TimeoutError:
                print(f"✗ {name} 清理超时")
            except Exception as e:
                print(f"✗ {name} 清理失败: {e}")

        print("\n========== 资源清理完成 ==========\n")

    async def _cleanup_background_tasks(self):
        """清理后台任务"""
        if not self.background_tasks:
            return

        print(f"取消 {len(self.background_tasks)} 个后台任务...")

        for task in self.background_tasks:
            if not task.done():
                task.cancel()

        await asyncio.gather(*self.background_tasks, return_exceptions=True)
        self.background_tasks.clear()

    async def _cleanup_http_client(self):
        """清理 HTTP 客户端"""
        if self.http_client:
            await self.http_client.aclose()
            self.http_client = None

    async def _cleanup_redis(self):
        """清理 Redis 连接"""
        if self.redis_client:
            await self.redis_client.close()
            await self.redis_client.connection_pool.disconnect()
            self.redis_client = None

    async def _cleanup_database(self):
        """清理数据库连接池"""
        if self.db_engine:
            await self.db_engine.dispose()
            self.db_engine = None

    async def _cleanup_files(self):
        """清理文件句柄"""
        for file_handle in self.open_files:
            try:
                if not file_handle.closed:
                    file_handle.flush()
                    file_handle.close()
            except Exception as e:
                print(f"关闭文件失败: {e}")

        self.open_files.clear()

    async def _cleanup_temp_files(self):
        """清理临时文件"""
        import shutil
        import os

        for temp_dir in self.temp_dirs:
            try:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
            except Exception as e:
                print(f"清理临时目录失败: {e}")

        self.temp_dirs.clear()

# ===== 2. 使用示例 =====
resource_manager = ResourceManager()

async def startup():
    """应用启动"""
    await resource_manager.initialize()

async def shutdown():
    """应用关闭"""
    await resource_manager.cleanup()
```

---

## 资源泄漏检测

### 1. 连接池监控

```python
async def monitor_connection_pool():
    """监控数据库连接池"""
    pool = engine.pool

    print("连接池状态:")
    print(f"  连接池大小: {pool.size()}")
    print(f"  已签出连接: {pool.checkedout()}")
    print(f"  溢出连接: {pool.overflow()}")
    print(f"  空闲连接: {pool.size() - pool.checkedout()}")

    # 检查是否有连接泄漏
    if pool.checkedout() > 0:
        print("⚠️  警告：有连接未归还")
```

### 2. 文件描述符监控

```python
import psutil
import os

def monitor_file_descriptors():
    """监控文件描述符"""
    process = psutil.Process(os.getpid())

    # 获取打开的文件数
    open_files = process.open_files()
    print(f"打开的文件数: {len(open_files)}")

    # 显示打开的文件
    for f in open_files[:10]:  # 只显示前10个
        print(f"  {f.path}")

    # 检查是否有泄漏
    if len(open_files) > 100:
        print("⚠️  警告：打开的文件过多，可能有泄漏")
```

---

## 总结

### 核心要点

1. **资源清理顺序**：
   - 后台任务 → HTTP 客户端 → Redis → 向量数据库 → 数据库 → 模型 → 文件

2. **超时控制**：
   - 为每个清理步骤设置超时
   - 超时后继续下一步，不阻塞整个流程

3. **错误处理**：
   - 捕获每个清理步骤的异常
   - 记录错误但继续执行

4. **资源监控**：
   - 监控连接池状态
   - 监控文件描述符
   - 检测资源泄漏

### 检查清单

- [ ] 关闭数据库连接池
- [ ] 关闭 Redis 连接
- [ ] 关闭向量数据库连接
- [ ] 关闭 HTTP 客户端
- [ ] 取消后台任务
- [ ] 卸载 Embedding 模型
- [ ] 关闭文件句柄
- [ ] 清理临时文件
- [ ] 设置超时控制
- [ ] 监控资源泄漏

---

**下一步**：学习 **03_核心概念_04_FastAPI生命周期管理.md**，了解如何使用 FastAPI 的 startup/shutdown 事件。
