# 化骨绵掌：10个2分钟知识卡片

> 碎片化学习，每天10分钟掌握健康检查端点

---

## 卡片1：健康检查的本质

**一句话：** 健康检查端点是服务向外界暴露自身状态的标准化接口

**举例：**

```python
@app.get("/health")
async def health():
    return {"status": "healthy"}
```

就像餐厅门口的"营业中"标志，告诉顾客是否可以进来。

**应用：** 在 AI Agent 后端中，健康检查用于：
- Kubernetes 自动重启失败的 Pod
- 负载均衡器决定是否发送流量
- 监控系统判断服务是否可用

---

## 卡片2：Liveness vs Readiness

**一句话：** Liveness 检查进程是否存活，Readiness 检查是否准备好接收流量

**对比：**

| 维度 | Liveness | Readiness |
|------|----------|-----------|
| 检查内容 | 进程是否响应 | 依赖服务是否可用 |
| 失败处理 | 重启 Pod | 停止流量 |
| 检查速度 | 极快（< 10ms） | 快速（< 100ms） |

**类比：**
- **Liveness** = 医生检查心跳（人还活着吗？）
- **Readiness** = 餐厅检查厨房（可以接待客人吗？）

**应用：** 数据库断了 → Liveness 通过，Readiness 失败 → Pod 不重启，但停止流量

---

## 卡片3：健康检查缓存

**一句话：** 健康检查会被频繁调用（每5-10秒），需要缓存结果避免影响性能

**代码：**

```python
health_cache = {"last_check": 0, "checks": {}}
CACHE_TTL = 30  # 缓存 30 秒

async def get_health_status():
    now = time.time()

    # 如果缓存未过期，直接返回
    if now - health_cache["last_check"] < CACHE_TTL:
        return health_cache

    # 执行实际检查
    checks = await check_all_dependencies()
    health_cache.update({"last_check": now, "checks": checks})

    return health_cache
```

**应用：** 避免每次健康检查都查询数据库，减少对依赖服务的压力

---

## 卡片4：三态健康模型

**一句话：** 服务有三种状态：健康、降级、不健康

**状态定义：**

```python
class HealthStatus(str, Enum):
    HEALTHY = "healthy"      # 所有依赖正常
    DEGRADED = "degraded"    # 部分依赖失败，但核心功能可用
    UNHEALTHY = "unhealthy"  # 核心依赖失败，不可用
```

**判断逻辑：**
- 数据库正常 + Redis 正常 → HEALTHY
- 数据库正常 + Redis 失败 → DEGRADED（可以不用缓存）
- 数据库失败 → UNHEALTHY（服务不可用）

**应用：** Redis 失败时，AI Agent 可以降级运行（不使用缓存），而不是完全不可用

---

## 卡片5：Kubernetes 探测配置

**一句话：** Kubernetes 通过配置探测参数来自动管理 Pod 生命周期

**关键参数：**

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 30  # 启动后 30 秒开始检查
  periodSeconds: 10         # 每 10 秒检查一次
  timeoutSeconds: 5         # 超时时间 5 秒
  failureThreshold: 3       # 连续失败 3 次才重启
```

**计算重启时间：**
```
重启时间 = failureThreshold × periodSeconds
         = 3 × 10s = 30秒
```

**应用：** 避免短暂抖动导致 Pod 频繁重启

---

## 卡片6：依赖服务检查策略

**一句话：** 区分核心依赖和可选依赖，核心依赖失败导致服务不可用，可选依赖失败导致服务降级

**依赖分类：**

| 依赖 | 类型 | 失败处理 |
|------|------|---------|
| 数据库 | 核心 | 返回 503，服务不可用 |
| Redis | 可选 | 返回 200，服务降级 |
| LLM API | 可选 | 返回 200，使用缓存响应 |

**代码：**

```python
if not checks["database"]:
    raise HTTPException(503, "Database unavailable")

if not checks["llm_api"]:
    return {
        "status": "degraded",
        "message": "LLM API unavailable, using cached responses"
    }
```

**应用：** LLM API 故障时，AI Agent 仍可使用缓存响应提供服务

---

## 卡片7：熔断器模式

**一句话：** 当连续失败次数超过阈值时，打开熔断器，快速失败，避免雪崩

**状态转换：**

```
CLOSED (关闭) → OPEN (打开) → HALF_OPEN (半开) → CLOSED
     ↑                                              ↓
     └──────────────────────────────────────────────┘
```

**关键参数：**
- `failure_threshold`：连续失败 5 次打开熔断器
- `timeout`：熔断器打开 60 秒后进入半开状态
- `success_threshold`：半开状态连续成功 2 次关闭熔断器

**应用：** LLM API 连续失败时，快速失败并返回缓存响应，避免长时间等待

---

## 卡片8：负载均衡器集成

**一句话：** 负载均衡器通过健康检查决定是否将流量发送到后端服务

**工作原理：**

```
用户请求
  ↓
负载均衡器
  ↓ (定期健康检查)
  ├─→ 服务A (/ready → 200) ✅ 发送流量
  ├─→ 服务B (/ready → 503) ❌ 停止流量
  └─→ 服务C (/ready → 超时) ❌ 停止流量
```

**HAProxy 配置：**

```haproxy
backend ai_agent_api
    option httpchk GET /ready
    http-check expect status 200

    server api1 10.0.1.10:8000 check inter 5s rise 2 fall 3
    server api2 10.0.1.11:8000 check inter 5s rise 2 fall 3
```

**应用：** 服务故障时，负载均衡器自动停止发送流量，等待恢复后自动恢复流量

---

## 卡片9：Prometheus 监控集成

**一句话：** 将健康检查指标暴露给 Prometheus，实现长期监控和告警

**关键指标：**

```python
from prometheus_client import Counter, Histogram, Gauge

# 健康检查总次数
health_check_total = Counter(
    'health_check_total',
    'Total health check requests',
    ['endpoint', 'status']
)

# 健康检查响应时间
health_check_duration_seconds = Histogram(
    'health_check_duration_seconds',
    'Health check duration',
    ['endpoint']
)

# 依赖服务健康状态
dependency_health_status = Gauge(
    'dependency_health_status',
    'Dependency health status',
    ['service']
)
```

**告警规则：**

```yaml
- alert: HealthCheckLowSuccessRate
  expr: |
    rate(health_check_total{status="success"}[5m])
    /
    rate(health_check_total[5m])
    < 0.95
  for: 5m
```

**应用：** 健康检查成功率低于 95% 时自动告警

---

## 卡片10：生产级健康检查系统

**一句话：** 完整的健康检查系统包括：依赖注册、缓存管理、三态模型、熔断器、监控集成

**架构设计：**

```python
# 1. 定义依赖检查器
class DatabaseChecker(DependencyChecker):
    async def check(self) -> DependencyHealth:
        # 检查数据库连接
        pass

# 2. 注册依赖
health_manager = HealthCheckManager()
health_manager.register(DatabaseChecker(engine))
health_manager.register(RedisChecker(redis_client))
health_manager.register(LLMAPIChecker(openai_client))

# 3. 执行健康检查
@app.get("/ready")
async def ready():
    result = await health_manager.check_all()

    if result.status == HealthStatus.UNHEALTHY:
        raise HTTPException(503)

    return result
```

**关键特性：**
- ✅ 统一的依赖检查器接口
- ✅ 自动缓存管理
- ✅ 三态模型（健康/降级/不健康）
- ✅ 并发检查所有依赖
- ✅ Prometheus 指标集成

**应用：** 在 AI Agent 后端中，生产级健康检查系统可以实现自动化的故障检测、降级运行和监控告警

---

## 学习路径建议

### 第1天：基础概念
- 卡片1：健康检查的本质
- 卡片2：Liveness vs Readiness
- 卡片3：健康检查缓存

### 第2天：高级特性
- 卡片4：三态健康模型
- 卡片5：Kubernetes 探测配置
- 卡片6：依赖服务检查策略

### 第3天：生产实践
- 卡片7：熔断器模式
- 卡片8：负载均衡器集成

### 第4天：监控与系统设计
- 卡片9：Prometheus 监控集成
- 卡片10：生产级健康检查系统

---

## 快速参考

### 常用命令

```bash
# 测试健康检查
curl http://localhost:8000/health
curl http://localhost:8000/ready

# 查看 Kubernetes Pod 状态
kubectl get pods
kubectl describe pod <pod-name>

# 查看 Prometheus 指标
curl http://localhost:8000/metrics
```

### 常用配置

```python
# 基础健康检查
@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.get("/ready")
async def ready():
    checks = await check_all_dependencies()
    if not all(checks.values()):
        raise HTTPException(503)
    return {"status": "ready", "checks": checks}
```

```yaml
# Kubernetes 探测配置
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8000
  initialDelaySeconds: 5
  periodSeconds: 5
  failureThreshold: 2
```

---

## 关键洞察

### 洞察1：健康检查不是越详细越好

**误区：** 健康检查应该检查所有可能的问题

**真相：** 健康检查应该快速返回，只检查关键依赖

**原因：** 健康检查会被频繁调用（每 5-10 秒），过于详细的检查会影响性能

### 洞察2：健康检查应该有缓存

**误区：** 每次健康检查都实时检查依赖服务

**真相：** 应该缓存健康检查结果，定期更新

**原因：** 避免频繁检查影响依赖服务性能，避免短暂抖动导致误报

### 洞察3：健康检查应该区分 Liveness 和 Readiness

**误区：** 一个 /health 端点就够了

**真相：** 应该有 /health（存活）和 /ready（就绪）两个端点

**原因：** Liveness 失败 → 重启容器，Readiness 失败 → 停止流量，两者的处理策略完全不同

### 洞察4：依赖服务应该区分核心和可选

**误区：** 所有依赖服务失败都应该导致服务不可用

**真相：** 核心依赖失败 → 不可用，可选依赖失败 → 降级

**原因：** 可以在部分依赖失败时提供降级服务，提高系统可用性

### 洞察5：熔断器可以防止雪崩

**误区：** 依赖服务失败时应该一直重试

**真相：** 连续失败时应该快速失败，避免雪崩

**原因：** 熔断器可以防止故障扩散，保护系统稳定性

---

## 总结

健康检查端点的10个核心知识点：

1. **本质**：服务向外界暴露自身状态的标准化接口
2. **Liveness vs Readiness**：存活检查 vs 就绪检查
3. **缓存**：避免频繁检查影响性能
4. **三态模型**：健康、降级、不健康
5. **Kubernetes**：自动管理 Pod 生命周期
6. **依赖检查**：区分核心和可选依赖
7. **熔断器**：防止雪崩
8. **负载均衡**：自动流量切换
9. **监控**：Prometheus 指标和告警
10. **生产系统**：完整的健康检查框架

在 AI Agent 后端中，健康检查是监控和高可用性的基础，合理的健康检查设计可以实现自动化的故障检测、降级运行和监控告警，提高系统的可用性和可靠性。

---

**版本：** v1.0
**最后更新：** 2026-02-13
**学习时间：** 每天10分钟，4天掌握
