# 反直觉点

> 避开3个最常见的误区，正确理解标量过滤

---

## 误区1：标量过滤不影响性能 ❌

### 为什么错？

**标量过滤会显著影响查询性能，尤其是在没有标量索引的情况下。**

```python
# 场景：100万条文档，查询 year == 2024 的文档

# 没有标量索引：
# 1. 先执行向量检索（计算100万次向量距离）
# 2. 再对结果进行标量过滤
# 时间：~5秒

# 有标量索引：
# 1. 先通过索引快速定位 year == 2024 的文档（假设10万条）
# 2. 只对这10万条执行向量检索
# 时间：~0.5秒（性能提升10倍）
```

**关键区别**：
- **无索引**：全表扫描，O(n) 复杂度
- **有索引**：索引查找，O(log n) 或 O(1) 复杂度

### 为什么人们容易这样错？

**心理原因**：在小数据集上测试时，性能差异不明显。

```python
# 1000条数据：
# 无索引：0.05秒
# 有索引：0.04秒
# 差异：0.01秒（感觉不到）

# 100万条数据：
# 无索引：5秒
# 有索引：0.5秒
# 差异：4.5秒（明显卡顿）
```

**认知陷阱**：开发环境数据少，生产环境数据多，导致性能问题在生产环境才暴露。

### 正确理解

**标量过滤的性能取决于：**
1. **数据量**：数据越多，索引的价值越大
2. **过滤选择性**：过滤后剩余数据越少，性能提升越明显
3. **是否有索引**：标量索引是性能优化的关键

```python
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 创建 Collection 时定义标量索引
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
    FieldSchema(name="year", dtype=DataType.INT64),  # 标量字段
    FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100)
]
schema = CollectionSchema(fields=fields)
collection = Collection(name="documents", schema=schema)

# 为标量字段创建索引（重要！）
collection.create_index(
    field_name="year",
    index_name="year_index"
)
collection.create_index(
    field_name="category",
    index_name="category_index"
)

# 现在标量过滤会很快
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    limit=10,
    expr="year == 2024 and category == 'tech'"  # 使用索引加速
)
```

**记住**：标量过滤不是"免费"的，需要合理使用索引优化性能。

---

## 误区2：标量过滤在向量检索之后执行 ❌

### 为什么错？

**Milvus 的标量过滤是在向量检索之前或同时执行的，而非之后。**

```python
# 错误理解：
# 1. 先执行向量检索，找到Top 1000相似的文档
# 2. 再对这1000条应用标量过滤
# 3. 返回符合条件的结果

# 正确理解：
# 1. 先应用标量过滤，找到符合条件的文档集合
# 2. 只在这个子集上执行向量检索
# 3. 返回Top N结果
```

**实际执行流程**：

```python
# 场景：100万条文档，其中10万条 year == 2024
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    limit=10,
    expr="year == 2024"
)

# 执行顺序：
# Step 1: 标量过滤 year == 2024 → 得到10万条候选文档
# Step 2: 在这10万条上执行向量检索 → 计算10万次向量距离
# Step 3: 返回Top 10结果

# 而不是：
# Step 1: 向量检索 → 计算100万次向量距离，得到Top 1000
# Step 2: 标量过滤 → 从1000条中筛选 year == 2024
```

### 为什么人们容易这样错？

**心理原因**：类比传统数据库的"先查询后过滤"模式。

```sql
-- SQL 中常见的模式：
SELECT * FROM (
    SELECT * FROM documents ORDER BY score DESC LIMIT 1000
) WHERE year = 2024;
-- 先取Top 1000，再过滤
```

**认知陷阱**：将向量检索类比为 SQL 的 ORDER BY，但实际上向量检索是昂贵的计算操作，应该尽量减少计算量。

### 正确理解

**Milvus 的优化策略：先过滤后检索**

```python
# 示例：理解执行顺序的影响
import time

# 场景1：先过滤后检索（Milvus 的做法）
start = time.time()
# 1. 过滤：100万 → 10万（快速）
# 2. 向量检索：计算10万次距离（较慢）
print(f"先过滤后检索: {time.time() - start:.2f}秒")  # ~0.5秒

# 场景2：先检索后过滤（错误理解）
start = time.time()
# 1. 向量检索：计算100万次距离（非常慢）
# 2. 过滤：从结果中筛选（快速）
print(f"先检索后过滤: {time.time() - start:.2f}秒")  # ~5秒
```

**性能对比**：

| 执行顺序 | 向量计算次数 | 性能 |
|---------|-------------|------|
| 先过滤后检索 | 10万次 | 快 ✅ |
| 先检索后过滤 | 100万次 | 慢 ❌ |

**记住**：标量过滤是"预筛选"，不是"后过滤"。

---

## 误区3：可以在过滤表达式中使用向量字段 ❌

### 为什么错？

**过滤表达式只能用于标量字段，不能用于向量字段。**

```python
# ❌ 错误：尝试在表达式中使用向量字段
expr = "embedding == [0.1, 0.2, 0.3, ...]"  # 不支持！

# ❌ 错误：尝试比较向量
expr = "embedding > some_vector"  # 不支持！

# ✅ 正确：只在标量字段上过滤
expr = "year == 2024 and category == 'tech'"
```

**原因**：
1. 向量比较需要距离度量（L2、IP、COSINE），不是简单的 `==` 或 `>`
2. 向量检索通过 `search()` 的 `data` 参数指定，不是通过 `expr`
3. 标量过滤和向量检索是两个独立的维度

### 为什么人们容易这样错？

**心理原因**：希望在一个表达式中同时表达向量相似度和标量条件。

```python
# 错误的期望：
expr = "embedding similar_to query_vector and year == 2024"  # 不存在这种语法

# 正确的做法：分开指定
results = collection.search(
    data=[query_vector],        # 向量相似度（这里指定）
    anns_field="embedding",
    limit=10,
    expr="year == 2024"         # 标量条件（这里指定）
)
```

**认知陷阱**：混淆了"向量检索"和"标量过滤"的职责边界。

### 正确理解

**向量检索和标量过滤的职责分工：**

```python
from pymilvus import Collection
import numpy as np

collection = Collection("documents")

# 向量检索：通过 data 参数指定
query_vector = np.random.rand(768).tolist()

# 标量过滤：通过 expr 参数指定
scalar_filter = "year == 2024 and category == 'tech'"

# 混合检索：两者结合
results = collection.search(
    data=[query_vector],           # 向量维度：语义相似度
    anns_field="embedding",
    param={"metric_type": "L2"},   # 向量距离度量
    limit=10,
    expr=scalar_filter,            # 标量维度：业务条件
    output_fields=["title", "year", "category"]
)

# 结果：同时满足语义相似和业务条件的文档
```

**职责对照表**：

| 维度 | 指定方式 | 作用 | 示例 |
|------|---------|------|------|
| 向量检索 | `data` 参数 | 语义相似度 | `data=[query_vector]` |
| 距离度量 | `metric_type` | 如何计算相似度 | `"L2"`, `"IP"`, `"COSINE"` |
| 标量过滤 | `expr` 参数 | 业务条件 | `"year == 2024"` |

**记住**：向量字段用于 `search()`，标量字段用于 `expr`，两者不能混用。

---

## 额外误区：字符串比较区分大小写

### 常见错误

```python
# 数据库中存储的是 "Tech"（首字母大写）
# 查询时使用小写
expr = "category == 'tech'"  # ❌ 匹配不到！

# 正确：大小写必须完全一致
expr = "category == 'Tech'"  # ✅ 匹配成功
```

### 解决方案

**方案1：统一大小写（推荐）**

```python
# 插入数据时统一转为小写
data = [
    {"id": 1, "embedding": [...], "category": "tech".lower()},
    {"id": 2, "embedding": [...], "category": "AI".lower()}
]
collection.insert(data)

# 查询时也使用小写
expr = "category == 'tech'"  # ✅ 匹配成功
```

**方案2：使用 LIKE（不区分大小写的替代方案）**

```python
# 注意：LIKE 仍然区分大小写，但可以用通配符
expr = "category like 'tech'"  # 精确匹配，仍区分大小写

# 如果需要不区分大小写，需要在应用层处理
# Milvus 目前不支持 ILIKE 或 LOWER() 函数
```

---

## 核心洞察

通过理解这些反直觉点，我们认识到：

1. **性能不是免费的**：标量过滤需要索引优化，尤其是大数据集
2. **执行顺序很重要**：先过滤后检索，而非先检索后过滤
3. **职责要分清**：向量字段用于检索，标量字段用于过滤
4. **细节要注意**：字符串比较区分大小写，需要统一处理

**记住**：理解这些反直觉点，能帮你避开90%的性能问题和查询错误。
