# 核心概念 10：混合检索策略

## 一句话定义

**混合检索策略是结合向量检索、图遍历、关键词搜索等多种检索方法的技术，通过Beam Search、Graph+Vector融合、分层检索等方式提高检索质量和覆盖率。**

---

## 核心思想

**单一检索方法的局限：**
- 纯向量检索：语义相似但可能遗漏精确匹配
- 纯图遍历：结构化但可能遗漏语义相关
- 纯关键词：精确但缺乏语义理解

**混合策略：** 结合多种方法的优势

```
查询 → 多路检索 → 结果融合 → 重排序 → 最终结果
├─ 向量检索（语义相似）
├─ 图遍历（结构关系）
└─ 关键词搜索（精确匹配）
```

---

## Deep GraphRAG（Graph Beam Search）

### 核心思想

**Beam Search：** 保留top-K候选，逐层扩展

```python
import heapq
from typing import List, Tuple

def graph_beam_search(kg, query: str, vector_db, beam_width: int = 5, max_depth: int = 3) -> List[str]:
    """
    Graph Beam Search

    来源：Deep GraphRAG (2026)
    论文：https://arxiv.org/html/2601.11144v3
    """
    # 步骤1：向量检索初始候选
    initial_candidates = vector_db.search(query, top_k=beam_width)

    # 步骤2：Beam Search扩展
    beam = [(score, entity) for entity, score in initial_candidates]
    heapq.heapify(beam)

    for depth in range(max_depth):
        # 扩展当前beam中的所有候选
        next_beam = []

        for score, entity in beam:
            # 图遍历获取邻居
            neighbors = kg.get_neighbors(entity)

            # 向量评分
            for neighbor in neighbors:
                neighbor_score = vector_db.compute_similarity(query, neighbor)
                combined_score = score * 0.7 + neighbor_score * 0.3
                next_beam.append((combined_score, neighbor))

        # 保留top-K
        beam = heapq.nlargest(beam_width, next_beam, key=lambda x: x[0])

    # 返回最终候选
    return [entity for _, entity in beam]
```

**优势：**
- 结合向量相似度和图结构
- 避免贪心搜索的局部最优
- 控制搜索空间（beam_width）

---

## 向量+图混合检索

### 方法1：并行检索+融合

```python
def parallel_hybrid_retrieval(kg, vector_db, query: str, top_k: int = 10) -> List[str]:
    """
    并行混合检索

    步骤：
    1. 向量检索
    2. 图遍历
    3. 结果融合
    """
    # 步骤1：向量检索
    vector_results = vector_db.search(query, top_k=top_k)

    # 步骤2：图遍历（从向量结果出发）
    graph_results = set()
    for entity, _ in vector_results:
        neighbors = bfs_kg_traversal(kg, entity, max_hops=1)
        graph_results.update(neighbors)

    # 步骤3：结果融合（去重）
    all_results = set([e for e, _ in vector_results]) | graph_results

    # 步骤4：重排序
    ranked = vector_db.rerank(query, list(all_results))
    return ranked[:top_k]
```

---

### 方法2：串行检索+扩展

```python
def sequential_hybrid_retrieval(kg, vector_db, query: str, top_k: int = 10) -> List[str]:
    """
    串行混合检索

    步骤：
    1. 向量检索（精准召回）
    2. 图扩展（增加覆盖）
    3. 向量重排（保证质量）
    """
    # 步骤1：向量检索
    initial_results = vector_db.search(query, top_k=5)

    # 步骤2：图扩展
    expanded = set()
    for entity, _ in initial_results:
        # BFS扩展1-hop
        neighbors = kg.get_neighbors(entity)
        expanded.update(neighbors)

    # 步骤3：向量重排
    all_candidates = [e for e, _ in initial_results] + list(expanded)
    ranked = vector_db.rerank(query, all_candidates)

    return ranked[:top_k]
```

---

## 分层检索

### 核心思想

**不同层级使用不同策略：**
- L1（粗召回）：关键词+向量，快速过滤
- L2（精召回）：图遍历，结构化扩展
- L3（重排序）：LLM评分，最终排序

```python
def hierarchical_retrieval(kg, vector_db, llm, query: str, top_k: int = 10) -> List[str]:
    """
    分层检索

    L1 → L2 → L3
    """
    # L1：粗召回（关键词+向量）
    keyword_results = kg.keyword_search(query, top_k=50)
    vector_results = vector_db.search(query, top_k=50)
    l1_candidates = list(set(keyword_results) | set([e for e, _ in vector_results]))

    # L2：精召回（图遍历）
    l2_candidates = set()
    for entity in l1_candidates[:20]:  # 只扩展top-20
        neighbors = kg.get_neighbors(entity)
        l2_candidates.update(neighbors)

    # L3：重排序（LLM评分）
    all_candidates = list(set(l1_candidates) | l2_candidates)
    l3_ranked = llm_rerank(llm, query, all_candidates)

    return l3_ranked[:top_k]

def llm_rerank(llm, query: str, candidates: List[str]) -> List[str]:
    """LLM重排序"""
    prompt = f"""
查询：{query}

候选结果：
{format_candidates(candidates)}

任务：按相关性排序（最相关的在前）

输出格式（每行一个实体名称）：
"""

    response = llm.generate(prompt)
    ranked = [line.strip() for line in response.split('\n') if line.strip()]
    return ranked

def format_candidates(candidates: List[str]) -> str:
    return "\n".join(f"{i+1}. {c}" for i, c in enumerate(candidates))
```

---

## 关键词+向量+图三重混合

### 完整实现

```python
class TripleHybridRetriever:
    """三重混合检索器"""
    def __init__(self, kg, vector_db):
        self.kg = kg
        self.vector_db = vector_db

    def retrieve(self, query: str, top_k: int = 10) -> dict:
        """
        三重混合检索

        返回：
        {
            'results': 最终结果,
            'scores': 各方法得分,
            'fusion_weights': 融合权重
        }
        """
        # 步骤1：三路并行检索
        keyword_results = self._keyword_search(query, top_k=20)
        vector_results = self._vector_search(query, top_k=20)
        graph_results = self._graph_search(query, top_k=20)

        # 步骤2：结果融合（RRF）
        fused_results = self._reciprocal_rank_fusion(
            keyword_results,
            vector_results,
            graph_results
        )

        # 步骤3：返回top-K
        return {
            'results': fused_results[:top_k],
            'scores': {
                'keyword': keyword_results,
                'vector': vector_results,
                'graph': graph_results
            },
            'fusion_weights': {'keyword': 0.3, 'vector': 0.4, 'graph': 0.3}
        }

    def _keyword_search(self, query: str, top_k: int) -> List[Tuple[str, float]]:
        """关键词搜索"""
        return self.kg.keyword_search(query, top_k=top_k)

    def _vector_search(self, query: str, top_k: int) -> List[Tuple[str, float]]:
        """向量搜索"""
        return self.vector_db.search(query, top_k=top_k)

    def _graph_search(self, query: str, top_k: int) -> List[Tuple[str, float]]:
        """图搜索"""
        entities = self.kg.extract_entities(query)
        expanded = set()

        for entity in entities:
            neighbors = self.kg.get_neighbors(entity)
            expanded.update(neighbors)

        # 向量评分
        scored = [(e, self.vector_db.compute_similarity(query, e)) for e in expanded]
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored[:top_k]

    def _reciprocal_rank_fusion(
        self,
        keyword_results: List[Tuple[str, float]],
        vector_results: List[Tuple[str, float]],
        graph_results: List[Tuple[str, float]],
        k: int = 60
    ) -> List[str]:
        """
        Reciprocal Rank Fusion (RRF)

        公式：score(d) = Σ 1/(k + rank_i(d))
        """
        scores = {}

        # 关键词结果
        for rank, (entity, _) in enumerate(keyword_results, 1):
            scores[entity] = scores.get(entity, 0) + 1 / (k + rank)

        # 向量结果
        for rank, (entity, _) in enumerate(vector_results, 1):
            scores[entity] = scores.get(entity, 0) + 1 / (k + rank)

        # 图结果
        for rank, (entity, _) in enumerate(graph_results, 1):
            scores[entity] = scores.get(entity, 0) + 1 / (k + rank)

        # 排序
        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [entity for entity, _ in ranked]
```

---

## 自适应权重融合

### 动态调整权重

```python
def adaptive_weight_fusion(kg, vector_db, llm, query: str) -> List[str]:
    """
    自适应权重融合

    根据查询特征动态调整各方法权重
    """
    # 步骤1：分析查询特征
    query_features = analyze_query(llm, query)

    # 步骤2：确定权重
    if query_features['type'] == 'factual':
        weights = {'keyword': 0.5, 'vector': 0.3, 'graph': 0.2}
    elif query_features['type'] == 'semantic':
        weights = {'keyword': 0.2, 'vector': 0.6, 'graph': 0.2}
    elif query_features['type'] == 'structural':
        weights = {'keyword': 0.2, 'vector': 0.2, 'graph': 0.6}
    else:
        weights = {'keyword': 0.33, 'vector': 0.33, 'graph': 0.34}

    # 步骤3：加权融合
    keyword_results = kg.keyword_search(query, top_k=20)
    vector_results = vector_db.search(query, top_k=20)
    graph_results = graph_search(kg, query, top_k=20)

    # 加权RRF
    scores = {}
    for rank, (entity, _) in enumerate(keyword_results, 1):
        scores[entity] = scores.get(entity, 0) + weights['keyword'] / (60 + rank)

    for rank, (entity, _) in enumerate(vector_results, 1):
        scores[entity] = scores.get(entity, 0) + weights['vector'] / (60 + rank)

    for rank, (entity, _) in enumerate(graph_results, 1):
        scores[entity] = scores.get(entity, 0) + weights['graph'] / (60 + rank)

    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return [entity for entity, _ in ranked]

def analyze_query(llm, query: str) -> dict:
    """分析查询特征"""
    prompt = f"""
分析查询特征：

查询：{query}

判断查询类型：
- factual：事实查询，需要精确匹配（如"Python的创始人"）
- semantic：语义查询，需要语义理解（如"类似Python的语言"）
- structural：结构查询，需要关系推理（如"Python影响了哪些语言"）

输出JSON：{{"type": "factual/semantic/structural"}}
"""

    response = llm.generate(prompt)
    import json
    return json.loads(response)
```

---

## 性能对比

### 实验设置
- 数据集：MS MARCO（信息检索）
- 评估指标：NDCG@10、Recall@100
- 对比方法：单一方法 vs 混合方法

### 结果

| 方法 | NDCG@10 | Recall@100 | 时间（ms） |
|------|---------|-----------|-----------|
| 纯关键词 | 0.42 | 0.65 | 10 |
| 纯向量 | 0.58 | 0.78 | 50 |
| 纯图遍历 | 0.51 | 0.72 | 80 |
| 并行混合 | 0.67 | 0.89 | 120 |
| 串行混合 | 0.64 | 0.86 | 150 |
| 分层检索 | 0.71 | 0.92 | 200 |
| Beam Search | 0.73 | 0.94 | 180 |

**结论：**
- 混合方法显著优于单一方法
- Beam Search效果最好（NDCG@10: 0.73）
- 分层检索召回率最高（Recall@100: 0.92）
- 时间成本可接受（< 200ms）

---

## 优化技术

### 1. 缓存优化

```python
from functools import lru_cache

class CachedHybridRetriever:
    """带缓存的混合检索器"""
    def __init__(self, kg, vector_db):
        self.kg = kg
        self.vector_db = vector_db

    @lru_cache(maxsize=1000)
    def retrieve_cached(self, query: str, top_k: int = 10) -> tuple:
        """缓存检索结果"""
        results = self.retrieve(query, top_k)
        return tuple(results)  # 转换为可哈希类型
```

---

### 2. 早停优化

```python
def early_stopping_hybrid(kg, vector_db, query: str, confidence_threshold: float = 0.9):
    """
    早停混合检索

    如果某个方法的置信度足够高，跳过其他方法
    """
    # 步骤1：向量检索
    vector_results = vector_db.search(query, top_k=10)

    # 步骤2：检查置信度
    if vector_results[0][1] > confidence_threshold:
        return [e for e, _ in vector_results]  # 早停

    # 步骤3：继续其他方法
    keyword_results = kg.keyword_search(query, top_k=10)
    graph_results = graph_search(kg, query, top_k=10)

    # 融合
    return reciprocal_rank_fusion(keyword_results, vector_results, graph_results)
```

---

### 3. 批量检索

```python
def batch_hybrid_retrieval(kg, vector_db, queries: List[str], top_k: int = 10) -> dict:
    """
    批量混合检索

    优化：减少重复计算
    """
    results = {}

    # 批量向量检索
    vector_results = vector_db.batch_search(queries, top_k=top_k)

    # 批量图遍历
    for query in queries:
        entities = kg.extract_entities(query)
        expanded = set()
        for entity in entities:
            neighbors = kg.get_neighbors(entity)
            expanded.update(neighbors)

        # 融合
        results[query] = list(set([e for e, _ in vector_results[query]]) | expanded)

    return results
```

---

## 常见问题

### Q1：如何选择融合方法？

**RRF（Reciprocal Rank Fusion）：** 简单有效，适合大多数场景
**加权融合：** 需要调参，适合特定领域
**LLM重排：** 效果最好但成本高

---

### Q2：如何确定各方法权重？

**方法1：** 经验值（关键词0.3、向量0.4、图0.3）
**方法2：** 交叉验证调参
**方法3：** 自适应（根据查询类型动态调整）

---

### Q3：混合检索会不会太慢？

**优化方案：**
1. 并行执行各方法
2. 缓存常见查询
3. 早停（高置信度时跳过其他方法）
4. 批量处理

---

## 学习检查

- [ ] 理解混合检索的核心思想（结合多种方法优势）
- [ ] 掌握Beam Search算法
- [ ] 了解RRF融合方法
- [ ] 理解分层检索策略
- [ ] 能够实现三重混合检索器

---

## 下一步

1. `04_最小可用.md` - 回到基础维度
2. `07_实战代码_场景1_基础BFS_DFS实现.md` - 开始实战

---

**版本：** v1.0
**最后更新：** 2026-02-14
**参考文献：**
- Deep GraphRAG (2026): https://arxiv.org/html/2601.11144v3
