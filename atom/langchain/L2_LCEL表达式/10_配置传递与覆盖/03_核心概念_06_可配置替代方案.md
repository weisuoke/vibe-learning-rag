# 核心概念06：可配置替代方案

> **本节目标**: 掌握configurable_alternatives()方法，实现动态组件切换

---

## 一、可配置替代方案概述

### 1.1 什么是可配置替代方案？

可配置替代方案允许在运行时动态切换整个Runnable组件，而不仅仅是修改参数。

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import ConfigurableField

# 定义可配置替代方案
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model_choice"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo"),
    claude=ChatAnthropic(model="claude-3-opus")
)

# 运行时切换模型
result_gpt4 = llm.invoke("Hello")  # 使用gpt-4
result_gpt35 = llm.invoke("Hello", config={"configurable": {"model_choice": "gpt35"}})
result_claude = llm.invoke("Hello", config={"configurable": {"model_choice": "claude"}})
```

### 1.2 vs configurable_fields

**configurable_fields**: 修改参数
```python
llm = ChatOpenAI().configurable_fields(
    temperature=ConfigurableField(id="temp")
)
# 运行时修改temperature参数
```

**configurable_alternatives**: 切换组件
```python
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo")
)
# 运行时切换整个LLM实例
```

---

## 二、configurable_alternatives()方法

### 2.1 方法签名

```python
def configurable_alternatives(
    self,
    config_field: ConfigurableField,
    *,
    default_key: str = "default",
    **alternatives: Runnable
) -> RunnableConfigurableAlternatives:
    """
    定义可配置的替代方案

    参数:
        config_field: 配置字段定义
        default_key: 默认选项的键
        **alternatives: 替代方案映射

    返回:
        RunnableConfigurableAlternatives实例
    """
```

### 2.2 基本用法

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import ConfigurableField

# 定义替代方案
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(
        id="model_choice",
        name="Model Choice",
        description="Choose which model to use"
    ),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo"),
    gpt4_turbo=ChatOpenAI(model="gpt-4-turbo")
)

# 使用默认（gpt-4）
result = llm.invoke("Hello")

# 切换到gpt-3.5-turbo
result = llm.invoke("Hello", config={"configurable": {"model_choice": "gpt35"}})

# 切换到gpt-4-turbo
result = llm.invoke("Hello", config={"configurable": {"model_choice": "gpt4_turbo"}})
```

---

## 三、多模型切换

### 3.1 OpenAI模型切换

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import ConfigurableField

# 定义多个OpenAI模型
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo"),
    gpt4_turbo=ChatOpenAI(model="gpt-4-turbo"),
    gpt4_32k=ChatOpenAI(model="gpt-4-32k")
)

# 根据任务复杂度选择模型
def get_model_config(complexity: str):
    if complexity == "high":
        return {"configurable": {"model": "gpt4_32k"}}
    elif complexity == "medium":
        return {"configurable": {"model": "gpt4"}}
    else:
        return {"configurable": {"model": "gpt35"}}

result = llm.invoke(input, config=get_model_config("high"))
```

### 3.2 跨提供商模型切换

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# 定义多个提供商的模型
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="provider"),
    default_key="openai",
    anthropic=ChatAnthropic(model="claude-3-opus"),
    google=ChatGoogleGenerativeAI(model="gemini-pro")
)

# 切换提供商
result_openai = llm.invoke("Hello")
result_anthropic = llm.invoke("Hello", config={"configurable": {"provider": "anthropic"}})
result_google = llm.invoke("Hello", config={"configurable": {"provider": "google"}})
```

### 3.3 成本优化策略

```python
# 根据成本选择模型
def get_cost_optimized_config(budget: str):
    """根据预算选择模型"""
    if budget == "high":
        return {"configurable": {"model": "gpt4"}}
    elif budget == "medium":
        return {"configurable": {"model": "gpt35"}}
    else:
        return {"configurable": {"model": "gpt35"}}  # 最便宜

# 使用
result = llm.invoke(input, config=get_cost_optimized_config("low"))
```

---

## 四、Retriever替代方案

### 4.1 多个Retriever切换

```python
from langchain_community.vectorstores import Chroma, FAISS
from langchain_core.runnables import ConfigurableField

# 创建多个retriever
chroma_retriever = Chroma(...).as_retriever()
faiss_retriever = FAISS(...).as_retriever()

# 定义可配置替代方案
retriever = chroma_retriever.configurable_alternatives(
    ConfigurableField(id="retriever_type"),
    default_key="chroma",
    faiss=faiss_retriever
)

# 运行时切换
docs_chroma = retriever.invoke("query")
docs_faiss = retriever.invoke("query", config={"configurable": {"retriever_type": "faiss"}})
```

### 4.2 RAG应用中的使用

```python
# RAG链
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | parser
)

# 运行时切换retriever和llm
result = rag_chain.invoke(
    "What is AI?",
    config={
        "configurable": {
            "retriever_type": "faiss",
            "model": "gpt4"
        }
    }
)
```

---

## 五、默认替代方案

### 5.1 default_key参数

```python
# 指定默认选项
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",  # 默认使用gpt-4
    gpt35=ChatOpenAI(model="gpt-3.5-turbo")
)

# 不提供config时使用默认
result = llm.invoke("Hello")  # 使用gpt-4
```

### 5.2 默认选项的选择

```python
# 根据环境选择默认
import os

env = os.getenv("ENV", "development")

if env == "production":
    default_model = "gpt4"
else:
    default_model = "gpt35"

llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key=default_model,
    gpt4=ChatOpenAI(model="gpt-4"),
    gpt35=ChatOpenAI(model="gpt-3.5-turbo")
)
```

---

## 六、实际应用场景

### 6.1 环境特定模型

```python
def create_env_specific_llm(env: str):
    """根据环境创建LLM"""
    if env == "production":
        base_llm = ChatOpenAI(model="gpt-4")
        default = "gpt4"
    else:
        base_llm = ChatOpenAI(model="gpt-3.5-turbo")
        default = "gpt35"

    return base_llm.configurable_alternatives(
        ConfigurableField(id="model"),
        default_key=default,
        gpt4=ChatOpenAI(model="gpt-4"),
        gpt35=ChatOpenAI(model="gpt-3.5-turbo")
    )

# 使用
prod_llm = create_env_specific_llm("production")
dev_llm = create_env_specific_llm("development")
```

### 6.2 用户等级模型

```python
def create_user_tier_llm(tier: str):
    """根据用户等级创建LLM"""
    llm_map = {
        "premium": ChatOpenAI(model="gpt-4"),
        "standard": ChatOpenAI(model="gpt-3.5-turbo"),
        "free": ChatOpenAI(model="gpt-3.5-turbo", max_tokens=100)
    }

    base_llm = llm_map[tier]

    return base_llm.configurable_alternatives(
        ConfigurableField(id="model"),
        default_key=tier,
        **llm_map
    )

# 使用
premium_llm = create_user_tier_llm("premium")
free_llm = create_user_tier_llm("free")
```

### 6.3 A/B测试

```python
# A/B测试不同模型
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="ab_test"),
    default_key="variant_a",
    variant_a=ChatOpenAI(model="gpt-4", temperature=0.3),
    variant_b=ChatOpenAI(model="gpt-4", temperature=0.9)
)

# 随机分配用户到不同变体
import random

def get_ab_config(user_id: str):
    variant = "variant_a" if hash(user_id) % 2 == 0 else "variant_b"
    return {"configurable": {"ab_test": variant}}

result = llm.invoke(input, config=get_ab_config("user-123"))
```

---

## 七、组合使用

### 7.1 同时使用fields和alternatives

```python
# 同时配置字段和替代方案
llm = ChatOpenAI(model="gpt-4", temperature=0.5).configurable_fields(
    temperature=ConfigurableField(id="temp")
).configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5).configurable_fields(
        temperature=ConfigurableField(id="temp")
    )
)

# 同时配置模型和温度
result = llm.invoke(
    "Hello",
    config={
        "configurable": {
            "model": "gpt35",
            "temp": 0.9
        }
    }
)
```

### 7.2 嵌套替代方案

```python
# 嵌套的替代方案
fast_llm = ChatOpenAI(model="gpt-3.5-turbo")
slow_llm = ChatOpenAI(model="gpt-4")

llm = fast_llm.configurable_alternatives(
    ConfigurableField(id="speed"),
    default_key="fast",
    slow=slow_llm
).configurable_alternatives(
    ConfigurableField(id="provider"),
    default_key="openai",
    anthropic=ChatAnthropic(model="claude-3-opus")
)

# 多层配置
result = llm.invoke(
    "Hello",
    config={
        "configurable": {
            "speed": "slow",
            "provider": "anthropic"
        }
    }
)
```

---

## 八、性能考虑

### 8.1 延迟初始化

```python
# 替代方案在使用时才初始化
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo")  # 只在选择时初始化
)
```

### 8.2 缓存替代方案

```python
from functools import lru_cache

@lru_cache(maxsize=10)
def get_llm_alternative(model: str):
    """缓存LLM实例"""
    if model == "gpt4":
        return ChatOpenAI(model="gpt-4")
    elif model == "gpt35":
        return ChatOpenAI(model="gpt-3.5-turbo")
    else:
        return ChatOpenAI(model="gpt-3.5-turbo")

# 使用缓存的实例
llm = get_llm_alternative("gpt4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=get_llm_alternative("gpt35")
)
```

---

## 九、常见陷阱

### 9.1 忘记提供所有替代方案

```python
# ❌ 错误：只定义了default，没有替代方案
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4"
    # 缺少替代方案
)

# ✓ 正确：提供至少一个替代方案
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo")
)
```

### 9.2 键名不匹配

```python
# ❌ 错误：config中的键与定义的键不匹配
llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    gpt35=ChatOpenAI(model="gpt-3.5-turbo")
)

result = llm.invoke("Hello", config={"configurable": {"model": "gpt3.5"}})
# 错误：应该是"gpt35"，不是"gpt3.5"
```

### 9.3 类型不兼容

```python
# ❌ 错误：替代方案类型不兼容
from langchain_core.runnables import RunnableLambda

llm = ChatOpenAI(model="gpt-4").configurable_alternatives(
    ConfigurableField(id="model"),
    default_key="gpt4",
    lambda_func=RunnableLambda(lambda x: x)  # 类型不兼容
)
```

---

## 十、最佳实践

### 10.1 使用工厂模式

```python
def create_configurable_llm():
    """创建可配置LLM的工厂函数"""
    return ChatOpenAI(model="gpt-4").configurable_alternatives(
        ConfigurableField(
            id="model_choice",
            name="Model Choice",
            description="Choose which model to use"
        ),
        default_key="gpt4",
        gpt35=ChatOpenAI(model="gpt-3.5-turbo"),
        gpt4_turbo=ChatOpenAI(model="gpt-4-turbo")
    )

# 使用
llm = create_configurable_llm()
```

### 10.2 配置验证

```python
def validate_model_config(config: dict):
    """验证模型配置"""
    valid_models = ["gpt4", "gpt35", "gpt4_turbo"]
    model = config.get("configurable", {}).get("model_choice")

    if model and model not in valid_models:
        raise ValueError(f"Invalid model: {model}. Must be one of {valid_models}")

    return config

# 使用
config = {"configurable": {"model_choice": "gpt35"}}
validated_config = validate_model_config(config)
result = llm.invoke(input, config=validated_config)
```

### 10.3 文档化

```python
def create_multi_model_chain():
    """
    创建多模型链

    可配置替代方案:
        - model_choice: 选择模型
          - gpt4 (默认): GPT-4
          - gpt35: GPT-3.5 Turbo
          - gpt4_turbo: GPT-4 Turbo

    示例:
        config = {"configurable": {"model_choice": "gpt35"}}
        result = chain.invoke(input, config=config)
    """
    # 实现...
```

---

## 十一、下一步

- Callbacks配置: [核心概念07 - Callbacks配置与传递](./03_核心概念_07_Callbacks配置与传递.md)
- 并发控制: [核心概念08 - 并发与递归控制](./03_核心概念_08_并发与递归控制.md)
- 实战练习: [实战代码04 - 多模型切换](./07_实战代码_04_多模型切换.md)
