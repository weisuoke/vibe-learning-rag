# 实战代码 - 场景2：RAG元数据扩展

> RAG系统中使用动态Schema实现文档元数据的灵活扩展

---

## 场景描述

在RAG系统中，文档的元数据需求会随着业务发展不断变化：
- 初期：只有基本的文本和向量
- 中期：添加作者、分类、标签等元数据
- 后期：添加评分、浏览量、更新时间等扩展信息

使用动态Schema可以实现无需重建Collection的元数据扩展。

---

## 完整代码

```python
from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility
from sentence_transformers import SentenceTransformer
import numpy as np
from datetime import datetime

class RAGDynamicMetadataSystem:
    """RAG系统动态元数据管理"""

    def __init__(self, collection_name="rag_dynamic_metadata"):
        self.collection_name = collection_name
        self.collection = None
        self.model = None

    def setup(self):
        """初始化系统"""
        print("=" * 60)
        print("RAG动态元数据系统 - 初始化")
        print("=" * 60)

        # 连接Milvus
        connections.connect(host="localhost", port="19530")
        print("✅ 已连接到Milvus")

        # 删除旧Collection
        if utility.has_collection(self.collection_name):
            utility.drop_collection(self.collection_name)

        # 创建Collection（最小固定字段 + 动态字段）
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2000)
        ]

        schema = CollectionSchema(
            fields=fields,
            description="RAG system with dynamic metadata",
            enable_dynamic_field=True  # 启用动态元数据
        )

        self.collection = Collection(name=self.collection_name, schema=schema)
        print(f"✅ 已创建Collection: {self.collection_name}")
        print("   - 固定字段: id, embedding, text")
        print("   - 动态元数据: 已启用")

        # 加载Embedding模型
        print("\n加载Embedding模型...")
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        print("✅ 模型加载完成")

    def phase1_basic_documents(self):
        """阶段1：插入基础文档（只有文本和向量）"""
        print("\n" + "=" * 60)
        print("阶段1：插入基础文档")
        print("=" * 60)

        documents = [
            "Milvus is a vector database for AI applications",
            "RAG combines retrieval and generation for better AI responses",
            "Vector embeddings represent text as numerical vectors"
        ]

        data = []
        for doc in documents:
            embedding = self.model.encode(doc).tolist()
            data.append({
                "text": doc,
                "embedding": embedding
            })

        result = self.collection.insert(data)
        self.collection.flush()

        print(f"✅ 插入 {len(data)} 条基础文档")
        print("   - 字段: text, embedding")
        return result.primary_keys

    def phase2_add_basic_metadata(self):
        """阶段2：添加基础元数据（作者、分类）"""
        print("\n" + "=" * 60)
        print("阶段2：添加基础元数据")
        print("=" * 60)

        documents = [
            {
                "text": "Introduction to vector databases and their applications",
                "author": "Alice",
                "category": "database"
            },
            {
                "text": "How to build a RAG system with Milvus",
                "author": "Bob",
                "category": "tutorial"
            }
        ]

        data = []
        for doc in documents:
            embedding = self.model.encode(doc["text"]).tolist()
            data.append({
                "text": doc["text"],
                "embedding": embedding,
                # 动态元数据
                "author": doc["author"],
                "category": doc["category"]
            })

        result = self.collection.insert(data)
        self.collection.flush()

        print(f"✅ 插入 {len(data)} 条文档（含基础元数据）")
        print("   - 新增动态字段: author, category")
        return result.primary_keys

    def phase3_add_extended_metadata(self):
        """阶段3：添加扩展元数据（标签、评分、时间）"""
        print("\n" + "=" * 60)
        print("阶段3：添加扩展元数据")
        print("=" * 60)

        documents = [
            {
                "text": "Advanced RAG techniques for production systems",
                "author": "Carol",
                "category": "advanced",
                "tags": ["RAG", "production", "optimization"],
                "rating": 4.8,
                "created_at": datetime.now().isoformat(),
                "views": 1500
            },
            {
                "text": "Milvus performance tuning guide",
                "author": "David",
                "category": "tutorial",
                "tags": ["Milvus", "performance", "tuning"],
                "rating": 4.5,
                "created_at": datetime.now().isoformat(),
                "views": 800,
                "difficulty": "intermediate"
            }
        ]

        data = []
        for doc in documents:
            embedding = self.model.encode(doc["text"]).tolist()
            item = {
                "text": doc["text"],
                "embedding": embedding
            }
            # 添加所有动态元数据
            for key, value in doc.items():
                if key != "text":
                    item[key] = value

            data.append(item)

        result = self.collection.insert(data)
        self.collection.flush()

        print(f"✅ 插入 {len(data)} 条文档（含扩展元数据）")
        print("   - 新增动态字段: tags, rating, created_at, views, difficulty")
        return result.primary_keys

    def create_index_and_load(self):
        """创建索引并加载"""
        print("\n" + "=" * 60)
        print("创建索引并加载Collection")
        print("=" * 60)

        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 128}
        }

        self.collection.create_index(field_name="embedding", index_params=index_params)
        self.collection.load()
        print("✅ 索引创建完成，Collection已加载")

    def query_all_documents(self):
        """查询所有文档，展示元数据演化"""
        print("\n" + "=" * 60)
        print("查询所有文档（展示元数据演化）")
        print("=" * 60)

        results = self.collection.query(
            expr="id > 0",
            output_fields=["*"],
            limit=100
        )

        print(f"✅ 共 {len(results)} 条文档\n")

        for i, result in enumerate(results, 1):
            print(f"文档 {i}:")
            print(f"  ID: {result['id']}")
            print(f"  Text: {result['text'][:60]}...")

            # 显示动态元数据
            dynamic_fields = {k: v for k, v in result.items()
                            if k not in ["id", "text", "embedding"]}

            if dynamic_fields:
                print("  元数据:")
                for field_name, field_value in dynamic_fields.items():
                    if isinstance(field_value, list):
                        print(f"    {field_name}: {', '.join(map(str, field_value))}")
                    else:
                        print(f"    {field_name}: {field_value}")
            else:
                print("  元数据: 无")
            print()

    def rag_search_with_metadata_filter(self, query, filter_expr=None):
        """RAG检索（支持元数据过滤）"""
        print("\n" + "=" * 60)
        print(f"RAG检索: {query}")
        if filter_expr:
            print(f"过滤条件: {filter_expr}")
        print("=" * 60)

        # 生成查询向量
        query_embedding = self.model.encode(query).tolist()

        # 向量检索 + 元数据过滤
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

        results = self.collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param=search_params,
            limit=5,
            expr=filter_expr,
            output_fields=["*"]
        )

        print(f"✅ 找到 {len(results[0])} 条相关文档\n")

        for i, hit in enumerate(results[0], 1):
            print(f"结果 {i}:")
            print(f"  相似度: {1 / (1 + hit.distance):.4f}")
            print(f"  文本: {hit.entity.get('text')[:60]}...")

            # 显示元数据
            dynamic_fields = {k: v for k, v in hit.entity.items()
                            if k not in ["id", "text", "embedding"]}

            if dynamic_fields:
                print("  元数据:")
                for field_name, field_value in dynamic_fields.items():
                    if isinstance(field_value, list):
                        print(f"    {field_name}: {', '.join(map(str, field_value))}")
                    else:
                        print(f"    {field_name}: {field_value}")
            print()

        return results[0]

    def update_document_metadata(self, doc_id, metadata_updates):
        """更新文档元数据"""
        print("\n" + "=" * 60)
        print(f"更新文档元数据 (ID: {doc_id})")
        print("=" * 60)

        # 查询原始数据
        results = self.collection.query(
            expr=f"id == {doc_id}",
            output_fields=["*"]
        )

        if not results:
            print(f"❌ 未找到ID为{doc_id}的文档")
            return False

        # 合并更新
        original = results[0]
        updated = {**original, **metadata_updates}

        # 删除并重新插入
        self.collection.delete(expr=f"id == {doc_id}")
        self.collection.insert([updated])
        self.collection.flush()

        print(f"✅ 元数据更新成功")
        print(f"   更新字段: {list(metadata_updates.keys())}")
        return True

    def get_metadata_statistics(self):
        """获取元数据统计信息"""
        print("\n" + "=" * 60)
        print("元数据统计信息")
        print("=" * 60)

        results = self.collection.query(
            expr="id > 0",
            output_fields=["*"],
            limit=1000
        )

        # 统计动态字段
        field_counts = {}
        for result in results:
            for field_name in result.keys():
                if field_name not in ["id", "text", "embedding"]:
                    field_counts[field_name] = field_counts.get(field_name, 0) + 1

        print(f"✅ 共 {len(results)} 条文档")
        print(f"\n动态字段统计:")
        for field_name, count in sorted(field_counts.items(), key=lambda x: x[1], reverse=True):
            coverage = count / len(results) * 100
            print(f"  {field_name}: {count} 条 ({coverage:.1f}%)")

    def cleanup(self):
        """清理资源"""
        print("\n" + "=" * 60)
        print("清理资源")
        print("=" * 60)

        self.collection.release()
        connections.disconnect("default")
        print("✅ 资源清理完成")

    def run(self):
        """运行完整演示"""
        try:
            # 1. 初始化
            self.setup()

            # 2. 阶段1：基础文档
            self.phase1_basic_documents()

            # 3. 阶段2：添加基础元数据
            self.phase2_add_basic_metadata()

            # 4. 阶段3：添加扩展元数据
            ids = self.phase3_add_extended_metadata()

            # 5. 创建索引并加载
            self.create_index_and_load()

            # 6. 查询所有文档
            self.query_all_documents()

            # 7. RAG检索（无过滤）
            self.rag_search_with_metadata_filter("vector database")

            # 8. RAG检索（按作者过滤）
            self.rag_search_with_metadata_filter(
                "RAG system",
                filter_expr='author == "Bob"'
            )

            # 9. RAG检索（按评分过滤）
            self.rag_search_with_metadata_filter(
                "performance optimization",
                filter_expr='rating > 4.5'
            )

            # 10. 更新元数据
            if ids:
                self.update_document_metadata(
                    ids[0],
                    {
                        "views": 2000,
                        "last_updated": datetime.now().isoformat(),
                        "featured": True
                    }
                )

            # 11. 元数据统计
            self.get_metadata_statistics()

            # 12. 清理
            self.cleanup()

            print("\n" + "=" * 60)
            print("✅ RAG动态元数据系统演示完成！")
            print("=" * 60)

        except Exception as e:
            print(f"\n❌ 发生错误: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    system = RAGDynamicMetadataSystem()
    system.run()
```

---

## 核心优势

### 1. 无需重建Collection

```python
# 传统方式：添加新字段需要重建
# 1. 创建新Collection
# 2. 迁移所有数据
# 3. 重建索引
# 4. 切换应用

# 动态Schema：直接添加新字段
data = {
    "text": "New document",
    "embedding": [...],
    "new_field": "new_value"  # 直接添加
}
collection.insert([data])
```

### 2. 支持渐进式元数据扩展

```python
# 阶段1：基础文档
{"text": "...", "embedding": [...]}

# 阶段2：添加基础元数据
{"text": "...", "embedding": [...], "author": "...", "category": "..."}

# 阶段3：添加扩展元数据
{"text": "...", "embedding": [...], "author": "...", "tags": [...], "rating": 4.5}
```

### 3. 灵活的元数据查询

```python
# 按作者查询
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    expr='author == "Alice"',
    output_fields=["*"]
)

# 按评分查询
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    expr='rating > 4.5',
    output_fields=["*"]
)
```

---

## 实际应用场景

### 场景1：文档管理系统

```python
# 初期：只有文档内容
doc_v1 = {
    "text": "Document content",
    "embedding": [...]
}

# 中期：添加管理信息
doc_v2 = {
    "text": "Document content",
    "embedding": [...],
    "author": "Alice",
    "department": "Engineering",
    "created_at": "2024-01-01"
}

# 后期：添加协作信息
doc_v3 = {
    "text": "Document content",
    "embedding": [...],
    "author": "Alice",
    "department": "Engineering",
    "created_at": "2024-01-01",
    "collaborators": ["Bob", "Carol"],
    "last_edited_by": "Bob",
    "version": 3
}
```

### 场景2：知识库系统

```python
# 初期：基础知识
knowledge_v1 = {
    "text": "Knowledge content",
    "embedding": [...]
}

# 中期：添加分类和标签
knowledge_v2 = {
    "text": "Knowledge content",
    "embedding": [...],
    "category": "技术",
    "tags": ["Python", "AI"],
    "difficulty": "中级"
}

# 后期：添加用户反馈
knowledge_v3 = {
    "text": "Knowledge content",
    "embedding": [...],
    "category": "技术",
    "tags": ["Python", "AI"],
    "difficulty": "中级",
    "helpful_count": 150,
    "view_count": 5000,
    "last_updated": "2024-01-01"
}
```

---

## 性能优化建议

### 1. 高频查询字段迁移到固定Schema

```python
# 如果发现某些元数据查询频繁，迁移到固定字段
# 监控查询频率
query_stats = {
    "author": 1000,    # 高频 → 迁移
    "category": 500,   # 中频 → 考虑迁移
    "tags": 10         # 低频 → 保持动态
}

# 创建新Schema
new_schema = CollectionSchema(
    fields=[
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2000),
        FieldSchema(name="author", dtype=DataType.VARCHAR, max_length=100),  # 迁移
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50)  # 迁移
    ],
    enable_dynamic_field=True
)
```

### 2. 分层查询策略

```python
# 先用固定字段过滤，再用动态字段过滤
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    expr='category == "tutorial"',  # 固定字段（快）
    limit=100,
    output_fields=["*"]
)

# 应用层过滤动态字段
filtered = [r for r in results[0] if r.entity.get("rating", 0) > 4.5]
```

---

## 总结

**核心价值**：
1. 无需重建Collection即可扩展元数据
2. 支持渐进式元数据演化
3. 灵活的元数据查询和过滤
4. 适应业务快速变化

**最佳实践**：
1. 初期使用动态Schema快速迭代
2. 监控查询频率，识别高频字段
3. 将高频字段迁移到固定Schema
4. 使用分层查询优化性能

**记住**：动态Schema是RAG系统元数据管理的利器，但要注意性能优化。
