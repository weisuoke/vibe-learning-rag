# 核心概念3：灾难恢复（Disaster Recovery）

**灾难恢复是在发生数据中心级别的灾难（地震、火灾、断电）时，能够快速恢复服务和数据的能力。**

---

## 什么是灾难恢复？

灾难恢复（Disaster Recovery, DR）是指在发生重大灾难事件时，能够将服务和数据恢复到可用状态的一系列策略和流程。与高可用（HA）不同，灾难恢复关注的是极端情况下的数据保护和服务恢复。

```
高可用 vs 灾难恢复：
┌─────────────────────────────────────────┐
│  高可用（HA）                            │
│  - 防护对象：单个节点故障                │
│  - RTO: 5-15 秒                          │
│  - RPO: 0（无数据丢失）                  │
│  - 适用场景：硬件故障、进程崩溃          │
├─────────────────────────────────────────┤
│  灾难恢复（DR）                          │
│  - 防护对象：数据中心级别灾难            │
│  - RTO: 1-4 小时                         │
│  - RPO: 1-24 小时                        │
│  - 适用场景：地震、火灾、断电、洪水      │
└─────────────────────────────────────────┘
```

---

## 灾难恢复的两个关键指标

### 1. RTO（Recovery Time Objective）- 恢复时间目标

**定义：** 从灾难发生到服务恢复的最大可接受时间

```
RTO 示例：
灾难发生 → 检测灾难 → 启动恢复流程 → 恢复数据 → 验证服务 → 服务可用
    0s        5min         10min         30min       10min       55min
                                                                  ↑
                                                              RTO = 55 分钟
```

**不同业务的 RTO 要求：**

| 业务类型 | RTO 要求 | 示例 |
|---------|---------|------|
| 关键业务 | < 1 小时 | 金融交易、医疗系统 |
| 重要业务 | 1-4 小时 | 电商平台、企业 ERP |
| 一般业务 | 4-24 小时 | 内部工具、报表系统 |
| 非关键业务 | > 24 小时 | 历史数据归档 |

---

### 2. RPO（Recovery Point Objective）- 恢复点目标

**定义：** 从灾难发生到最近一次备份的最大可接受数据丢失时间

```
RPO 示例：
上次备份 → 灾难发生 → 从备份恢复
  昨天凌晨2点   今天下午3点   今天下午4点
       ↓            ↓
    备份时间      灾难时间
       └────────────┘
         RPO = 37 小时（丢失 37 小时的数据）
```

**不同业务的 RPO 要求：**

| 业务类型 | RPO 要求 | 备份频率 | 示例 |
|---------|---------|---------|------|
| 零容忍 | 0（无数据丢失） | 实时同步 | 金融交易 |
| 极低容忍 | < 1 小时 | 每小时备份 | 订单系统 |
| 低容忍 | 1-24 小时 | 每天备份 | 用户数据 |
| 可容忍 | > 24 小时 | 每周备份 | 日志数据 |

---

## Milvus 的灾难恢复策略

### 策略1：定期备份（Backup）

**原理：** 定期将数据备份到外部存储，灾难发生时从备份恢复

```
备份流程：
┌─────────────────────────────────────────┐
│  Milvus 集群（主数据中心）               │
│  ├─ Collection 数据                      │
│  ├─ 索引数据                             │
│  └─ 元数据                               │
└─────────────┬───────────────────────────┘
              ↓ 每天凌晨 2 点备份
┌─────────────────────────────────────────┐
│  对象存储（S3/MinIO）                    │
│  ├─ backup-2024-01-01/                  │
│  ├─ backup-2024-01-02/                  │
│  └─ backup-2024-01-03/                  │
└─────────────────────────────────────────┘
```

**使用 Milvus Backup 工具：**

```python
"""
使用 Milvus Backup 工具进行备份
"""
import subprocess
import datetime

def backup_milvus_collection(collection_name, backup_path):
    """备份 Milvus Collection"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"{collection_name}_{timestamp}"

    # 使用 Milvus Backup CLI
    cmd = [
        "milvus-backup",
        "create",
        "-n", backup_name,
        "-c", collection_name,
        "-p", backup_path
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode == 0:
        print(f"✅ 备份成功: {backup_name}")
        print(f"   备份路径: {backup_path}/{backup_name}")
        return backup_name
    else:
        print(f"❌ 备份失败: {result.stderr}")
        return None

# 备份示例
backup_name = backup_milvus_collection(
    collection_name="documents",
    backup_path="s3://milvus-backup-bucket/backups"
)
```

**自动化备份脚本：**

```python
"""
自动化备份脚本（每天凌晨 2 点执行）
"""
from pymilvus import connections, utility
import subprocess
import datetime
import os

def automated_backup():
    """自动化备份所有 Collection"""
    # 连接到 Milvus
    connections.connect(
        alias="default",
        host=os.getenv("MILVUS_HOST", "localhost"),
        port=os.getenv("MILVUS_PORT", "19530")
    )

    # 获取所有 Collection
    collections = utility.list_collections()
    print(f"发现 {len(collections)} 个 Collection")

    # 备份路径
    timestamp = datetime.datetime.now().strftime("%Y%m%d")
    backup_base_path = f"s3://milvus-backup-bucket/daily/{timestamp}"

    # 逐个备份
    success_count = 0
    for collection_name in collections:
        print(f"\n正在备份: {collection_name}")
        backup_name = backup_milvus_collection(
            collection_name=collection_name,
            backup_path=backup_base_path
        )
        if backup_name:
            success_count += 1

    print(f"\n=== 备份完成 ===")
    print(f"成功: {success_count}/{len(collections)}")
    print(f"备份路径: {backup_base_path}")

    # 清理旧备份（保留最近 30 天）
    cleanup_old_backups(days=30)

def cleanup_old_backups(days=30):
    """清理旧备份"""
    cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)
    print(f"\n清理 {cutoff_date.strftime('%Y-%m-%d')} 之前的备份...")

    # 使用 AWS CLI 删除旧备份
    cmd = [
        "aws", "s3", "rm",
        "s3://milvus-backup-bucket/daily/",
        "--recursive",
        "--exclude", "*",
        "--include", f"*{cutoff_date.strftime('%Y%m')}*"
    ]

    subprocess.run(cmd)

if __name__ == "__main__":
    automated_backup()
```

**Cron 定时任务配置：**

```bash
# 每天凌晨 2 点执行备份
0 2 * * * /usr/bin/python3 /opt/milvus-backup/automated_backup.py >> /var/log/milvus-backup.log 2>&1
```

---

### 策略2：跨数据中心复制（Cross-Region Replication）

**原理：** 在不同地理位置部署多个 Milvus 集群，实时或定期同步数据

```
跨数据中心架构：
┌─────────────────────────────────────────┐
│  主集群（北京数据中心）                  │
│  ├─ Milvus 集群                          │
│  ├─ 对象存储（MinIO）                    │
│  └─ 元数据存储（etcd）                   │
└─────────────┬───────────────────────────┘
              ↓ 实时/定期同步
┌─────────────────────────────────────────┐
│  灾备集群（上海数据中心）                │
│  ├─ Milvus 集群                          │
│  ├─ 对象存储（MinIO）                    │
│  └─ 元数据存储（etcd）                   │
└─────────────────────────────────────────┘
```

**同步方式对比：**

| 同步方式 | RPO | RTO | 成本 | 适用场景 |
|---------|-----|-----|------|---------|
| 实时同步 | 0-1 分钟 | 5-15 分钟 | 高 | 关键业务 |
| 准实时同步 | 5-15 分钟 | 15-30 分钟 | 中 | 重要业务 |
| 定期同步 | 1-24 小时 | 1-4 小时 | 低 | 一般业务 |

**实现跨数据中心复制：**

```python
"""
跨数据中心数据同步
"""
from pymilvus import connections, Collection, utility
import time

class CrossRegionReplicator:
    """跨数据中心复制器"""

    def __init__(self, primary_host, dr_host, port="19530"):
        self.primary_host = primary_host
        self.dr_host = dr_host
        self.port = port

    def sync_collection(self, collection_name):
        """同步单个 Collection"""
        print(f"开始同步 Collection: {collection_name}")

        # 连接到主集群
        connections.connect(
            alias="primary",
            host=self.primary_host,
            port=self.port
        )

        # 连接到灾备集群
        connections.connect(
            alias="dr",
            host=self.dr_host,
            port=self.port
        )

        # 从主集群导出数据
        primary_collection = Collection(collection_name, using="primary")
        primary_collection.load()

        # 查询所有数据（分批）
        batch_size = 1000
        offset = 0
        total_synced = 0

        while True:
            # 从主集群查询数据
            results = primary_collection.query(
                expr="",
                output_fields=["*"],
                limit=batch_size,
                offset=offset
            )

            if not results:
                break

            # 插入到灾备集群
            dr_collection = Collection(collection_name, using="dr")
            dr_collection.insert(results)

            total_synced += len(results)
            offset += batch_size

            print(f"已同步 {total_synced} 条数据...")

        print(f"✅ 同步完成: {collection_name}，共 {total_synced} 条数据")

    def sync_all_collections(self):
        """同步所有 Collection"""
        connections.connect(alias="primary", host=self.primary_host, port=self.port)
        collections = utility.list_collections(using="primary")

        print(f"发现 {len(collections)} 个 Collection")

        for collection_name in collections:
            try:
                self.sync_collection(collection_name)
            except Exception as e:
                print(f"❌ 同步失败: {collection_name} - {e}")

        print("\n=== 所有 Collection 同步完成 ===")

# 使用示例
replicator = CrossRegionReplicator(
    primary_host="milvus-beijing.example.com",
    dr_host="milvus-shanghai.example.com"
)

# 定期同步（每小时执行一次）
while True:
    replicator.sync_all_collections()
    time.sleep(3600)  # 1 小时
```

---

### 策略3：主备切换（Failover to DR Site）

**原理：** 当主数据中心不可用时，将流量切换到灾备数据中心

```
主备切换流程：
1. 检测主数据中心不可用（心跳超时、健康检查失败）
   ↓
2. 验证灾备数据中心可用（健康检查、数据完整性）
   ↓
3. 更新 DNS 记录，将域名指向灾备数据中心
   ↓
4. 客户端自动连接到灾备数据中心
   ↓
5. 服务恢复（RTO: 1-4 小时）
```

**DNS 切换示例：**

```python
"""
自动化 DNS 切换
"""
import boto3
import time

class DNSFailover:
    """DNS 故障转移"""

    def __init__(self, hosted_zone_id, domain_name):
        self.route53 = boto3.client('route53')
        self.hosted_zone_id = hosted_zone_id
        self.domain_name = domain_name

    def check_primary_health(self, primary_endpoint):
        """检查主集群健康状态"""
        try:
            import requests
            response = requests.get(
                f"http://{primary_endpoint}:9091/healthz",
                timeout=5
            )
            return response.status_code == 200
        except Exception as e:
            print(f"主集群健康检查失败: {e}")
            return False

    def switch_to_dr(self, dr_endpoint):
        """切换到灾备集群"""
        print(f"切换 DNS 到灾备集群: {dr_endpoint}")

        # 更新 DNS 记录
        response = self.route53.change_resource_record_sets(
            HostedZoneId=self.hosted_zone_id,
            ChangeBatch={
                'Changes': [{
                    'Action': 'UPSERT',
                    'ResourceRecordSet': {
                        'Name': self.domain_name,
                        'Type': 'A',
                        'TTL': 60,
                        'ResourceRecords': [{'Value': dr_endpoint}]
                    }
                }]
            }
        )

        print(f"✅ DNS 切换完成: {response['ChangeInfo']['Id']}")
        print(f"   等待 DNS 传播（TTL: 60 秒）...")
        time.sleep(60)

    def monitor_and_failover(self, primary_endpoint, dr_endpoint):
        """监控并自动故障转移"""
        failure_count = 0
        max_failures = 3

        while True:
            is_healthy = self.check_primary_health(primary_endpoint)

            if is_healthy:
                failure_count = 0
                print(f"主集群健康: {primary_endpoint}")
            else:
                failure_count += 1
                print(f"主集群不健康: {primary_endpoint} ({failure_count}/{max_failures})")

                if failure_count >= max_failures:
                    print("\n⚠️  主集群连续失败，开始故障转移...")
                    self.switch_to_dr(dr_endpoint)
                    print("✅ 故障转移完成")
                    break

            time.sleep(30)  # 每 30 秒检查一次

# 使用示例
failover = DNSFailover(
    hosted_zone_id="Z1234567890ABC",
    domain_name="milvus.example.com"
)

failover.monitor_and_failover(
    primary_endpoint="milvus-beijing.example.com",
    dr_endpoint="milvus-shanghai.example.com"
)
```

---

## 灾难恢复演练（DR Drill）

### 为什么需要演练？

```
没有演练的灾难恢复 = 没有灾难恢复

常见问题：
❌ 备份文件损坏，无法恢复
❌ 恢复流程文档过时，步骤错误
❌ 恢复时间远超预期（RTO 不达标）
❌ 恢复后数据不完整（RPO 不达标）
❌ 团队不熟悉恢复流程，手忙脚乱
```

### 演练流程

```python
"""
灾难恢复演练脚本
"""
import datetime
import time

class DRDrill:
    """灾难恢复演练"""

    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.steps = []

    def log_step(self, step_name, status="进行中"):
        """记录演练步骤"""
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {step_name}: {status}")
        self.steps.append({
            "step": step_name,
            "status": status,
            "timestamp": timestamp
        })

    def run_drill(self):
        """执行演练"""
        self.start_time = time.time()
        print("=== 灾难恢复演练开始 ===\n")

        # 步骤1：模拟灾难
        self.log_step("步骤1：模拟主数据中心故障", "开始")
        self.simulate_disaster()
        self.log_step("步骤1：模拟主数据中心故障", "完成")

        # 步骤2：检测灾难
        self.log_step("步骤2：检测灾难", "开始")
        self.detect_disaster()
        self.log_step("步骤2：检测灾难", "完成")

        # 步骤3：启动恢复流程
        self.log_step("步骤3：启动恢复流程", "开始")
        self.initiate_recovery()
        self.log_step("步骤3：启动恢复流程", "完成")

        # 步骤4：恢复数据
        self.log_step("步骤4：从备份恢复数据", "开始")
        self.restore_data()
        self.log_step("步骤4：从备份恢复数据", "完成")

        # 步骤5：验证服务
        self.log_step("步骤5：验证服务可用性", "开始")
        self.verify_service()
        self.log_step("步骤5：验证服务可用性", "完成")

        # 步骤6：切换流量
        self.log_step("步骤6：切换流量到灾备集群", "开始")
        self.switch_traffic()
        self.log_step("步骤6：切换流量到灾备集群", "完成")

        self.end_time = time.time()
        self.generate_report()

    def simulate_disaster(self):
        """模拟灾难"""
        print("  - 关闭主集群的所有 Pod")
        # kubectl scale deployment milvus-proxy --replicas=0
        time.sleep(5)

    def detect_disaster(self):
        """检测灾难"""
        print("  - 健康检查失败")
        print("  - 触发告警")
        time.sleep(3)

    def initiate_recovery(self):
        """启动恢复流程"""
        print("  - 通知运维团队")
        print("  - 启动灾难恢复预案")
        time.sleep(2)

    def restore_data(self):
        """恢复数据"""
        print("  - 从 S3 下载最新备份")
        print("  - 恢复到灾备集群")
        time.sleep(10)

    def verify_service(self):
        """验证服务"""
        print("  - 检查数据完整性")
        print("  - 执行测试查询")
        time.sleep(5)

    def switch_traffic(self):
        """切换流量"""
        print("  - 更新 DNS 记录")
        print("  - 等待 DNS 传播")
        time.sleep(3)

    def generate_report(self):
        """生成演练报告"""
        total_time = self.end_time - self.start_time
        print(f"\n=== 灾难恢复演练完成 ===")
        print(f"总耗时: {total_time:.2f} 秒 ({total_time/60:.2f} 分钟)")
        print(f"\n步骤详情:")
        for step in self.steps:
            print(f"  - {step['step']}: {step['status']} ({step['timestamp']})")

        # 评估 RTO
        if total_time < 3600:  # 1 小时
            print(f"\n✅ RTO 达标: {total_time/60:.2f} 分钟 < 60 分钟")
        else:
            print(f"\n❌ RTO 不达标: {total_time/60:.2f} 分钟 > 60 分钟")

# 执行演练
drill = DRDrill()
drill.run_drill()
```

**演练频率建议：**
- 关键业务：每季度一次
- 重要业务：每半年一次
- 一般业务：每年一次

---

## 在 RAG 系统中的应用

### 场景：企业知识库的灾难恢复

```python
"""
企业知识库的完整灾难恢复方案
"""
from pymilvus import connections, Collection, utility
import datetime

class EnterpriseKnowledgeBaseDR:
    """企业知识库灾难恢复"""

    def __init__(self):
        self.primary_host = "milvus-beijing.example.com"
        self.dr_host = "milvus-shanghai.example.com"
        self.backup_bucket = "s3://kb-backup-bucket"

    def daily_backup(self):
        """每日备份"""
        print("=== 开始每日备份 ===")

        connections.connect("default", host=self.primary_host, port="19530")

        # 备份所有知识库 Collection
        collections = ["company_docs", "product_docs", "faq_docs"]

        for collection_name in collections:
            timestamp = datetime.datetime.now().strftime("%Y%m%d")
            backup_path = f"{self.backup_bucket}/{collection_name}/{timestamp}"

            print(f"备份 {collection_name} 到 {backup_path}")
            # 使用 Milvus Backup 工具
            # milvus-backup create -n {collection_name} -p {backup_path}

        print("✅ 每日备份完成")

    def hourly_sync(self):
        """每小时同步到灾备集群"""
        print("=== 开始每小时同步 ===")

        # 连接到主集群和灾备集群
        connections.connect("primary", host=self.primary_host, port="19530")
        connections.connect("dr", host=self.dr_host, port="19530")

        # 同步增量数据
        collections = ["company_docs", "product_docs", "faq_docs"]

        for collection_name in collections:
            print(f"同步 {collection_name}...")
            # 实现增量同步逻辑
            # ...

        print("✅ 每小时同步完成")

    def disaster_recovery(self):
        """灾难恢复流程"""
        print("=== 开始灾难恢复 ===")

        # 1. 验证灾备集群可用
        print("1. 验证灾备集群...")
        connections.connect("dr", host=self.dr_host, port="19530")
        collections = utility.list_collections(using="dr")
        print(f"   灾备集群有 {len(collections)} 个 Collection")

        # 2. 验证数据完整性
        print("2. 验证数据完整性...")
        for collection_name in collections:
            collection = Collection(collection_name, using="dr")
            count = collection.num_entities
            print(f"   {collection_name}: {count} 条数据")

        # 3. 切换 DNS
        print("3. 切换 DNS 到灾备集群...")
        # 更新 DNS 记录
        # ...

        # 4. 验证服务
        print("4. 验证服务可用性...")
        # 执行测试查询
        # ...

        print("✅ 灾难恢复完成")

# 使用示例
dr = EnterpriseKnowledgeBaseDR()

# 每日备份（Cron: 0 2 * * *）
dr.daily_backup()

# 每小时同步（Cron: 0 * * * *）
dr.hourly_sync()

# 灾难发生时手动执行
# dr.disaster_recovery()
```

---

## 关键要点

1. **RTO vs RPO**：
   - RTO：恢复时间目标（多快恢复服务）
   - RPO：恢复点目标（丢失多少数据）
   - 两者需要权衡：更低的 RTO/RPO = 更高的成本

2. **三层防护**：
   - 多副本：防止硬件故障（RTO: 秒级，RPO: 0）
   - 定期备份：防止逻辑错误（RTO: 小时级，RPO: 小时/天级）
   - 异地容灾：防止数据中心灾难（RTO: 小时级，RPO: 分钟/小时级）

3. **演练的重要性**：
   - 没有演练的灾难恢复计划是不可靠的
   - 定期演练可以发现问题、优化流程、培训团队
   - 建议频率：关键业务每季度一次

4. **成本权衡**：
   - 实时同步：成本高，RPO 低（0-1 分钟）
   - 定期同步：成本低，RPO 高（1-24 小时）
   - 根据业务重要性选择合适的策略
