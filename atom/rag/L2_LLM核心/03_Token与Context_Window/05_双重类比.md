# Token与Context Window - 双重类比

用前端开发和日常生活的类比，帮助理解 Token 与 Context Window。

---

## 类比1：Token ≈ 像素/字节

### 前端类比：像素

**图片由像素组成，文本由 Token 组成。**

```
图片处理                    LLM 处理
────────                    ────────
像素 (pixel)        ←→      Token
分辨率 (1920×1080)  ←→      Token 数量
图片大小 (MB)       ←→      Token 计费
压缩算法            ←→      分词算法 (BPE)
```

```javascript
// 前端：图片有像素限制
const MAX_PIXELS = 1920 * 1080;
if (image.width * image.height > MAX_PIXELS) {
    resizeImage(image);  // 需要压缩
}
```

```python
# LLM：文本有 Token 限制
MAX_TOKENS = 128000
if count_tokens(text) > MAX_TOKENS:
    truncate_text(text)  # 需要截断
```

### 日常生活类比：积木块

**文字是积木块，Context Window 是桌面。**

```
积木游戏                    LLM 处理
────────                    ────────
积木块              ←→      Token
桌面大小            ←→      Context Window
能放多少块          ←→      能处理多少 Token
积木太多放不下      ←→      超出限制报错
```

**想象场景：**
- 你有一张桌子（Context Window）
- 每个汉字是 1-2 块积木（Token）
- 桌子只能放 128000 块积木
- 放不下就会掉到地上（报错/截断）

---

## 类比2：Context Window ≈ 请求体大小限制

### 前端类比：HTTP 请求限制

**HTTP 请求有大小限制，LLM 也有 Token 限制。**

```
HTTP 请求                   LLM 请求
────────                    ────────
请求体大小限制      ←→      Context Window
413 Payload Too Large ←→   Token 超限错误
分页加载            ←→      分块处理
压缩传输            ←→      文本压缩/摘要
```

```javascript
// 前端：请求体有大小限制
const MAX_BODY_SIZE = 10 * 1024 * 1024;  // 10MB

async function uploadFile(file) {
    if (file.size > MAX_BODY_SIZE) {
        throw new Error('文件太大，请分片上传');
    }
    // ...
}
```

```python
# LLM：输入有 Token 限制
MAX_CONTEXT = 128000

def call_llm(messages):
    total_tokens = count_tokens(str(messages))
    if total_tokens > MAX_CONTEXT:
        raise ValueError('输入太长，请截断或分批处理')
    # ...
```

### 日常生活类比：短期记忆

**Context Window 就像人的短期记忆容量。**

```
人的记忆                    LLM 的 Context
────────                    ────────
短期记忆 (7±2 项)   ←→      Context Window
记不住太多东西      ←→      Token 超限
做笔记辅助          ←→      RAG 检索辅助
复习巩固            ←→      多轮对话历史
```

**想象场景：**
- 你能同时记住 7 个电话号码（短期记忆）
- LLM 能同时处理 128K Token（Context Window）
- 超过就会"忘记"或出错

---

## 类比3：Token 预算 ≈ 前端性能预算

### 前端类比：性能预算

**前端有性能预算，RAG 有 Token 预算。**

```
前端性能预算                RAG Token 预算
────────                    ────────
JS 包大小限制       ←→      检索内容限制
首屏加载时间        ←→      响应延迟
懒加载策略          ←→      按需检索
代码分割            ←→      文档分块 (Chunking)
```

```javascript
// 前端：性能预算分配
const PERFORMANCE_BUDGET = {
    js: 200,      // KB
    css: 50,      // KB
    images: 500,  // KB
    fonts: 100,   // KB
    total: 850    // KB
};
```

```python
# RAG：Token 预算分配
TOKEN_BUDGET = {
    "system_prompt": 500,      # Token
    "user_query": 200,         # Token
    "retrieved_docs": 120000,  # Token (主要空间)
    "output_reserved": 4000,   # Token
    "total": 128000            # Token
}
```

### 日常生活类比：行李箱打包

**Token 预算就像行李箱容量分配。**

```
行李箱打包                  RAG Token 分配
────────                    ────────
行李箱容量          ←→      Context Window
衣服                ←→      检索内容
洗漱用品            ←→      系统提示
证件钱包            ←→      用户问题
留点空间买纪念品    ←→      预留输出空间
超重要交罚款        ←→      超限会报错
```

---

## 类比4：分词 ≈ 代码压缩

### 前端类比：代码压缩/混淆

**BPE 分词就像代码压缩，把常见模式合并。**

```
代码压缩                    BPE 分词
────────                    ────────
合并重复代码        ←→      合并常见字符组合
变量名缩短          ←→      高频词变成单个 Token
保持功能不变        ←→      保持语义不变
压缩率              ←→      Token 效率
```

```javascript
// 压缩前
function calculateTotalPrice(items) {
    return items.reduce((sum, item) => sum + item.price, 0);
}

// 压缩后
function a(b){return b.reduce((c,d)=>c+d.price,0)}
```

```python
# BPE 分词示例
"understanding" → ["under", "standing"]  # 2 Token
"the" → ["the"]                          # 1 Token (高频词)
"RAG" → ["R", "AG"] 或 ["RAG"]           # 取决于训练语料
```

### 日常生活类比：速记符号

**Token 就像速记员的速记符号。**

```
速记                        Token
────────                    ────────
常用词有专门符号    ←→      高频词是单个 Token
生僻词要拼写        ←→      罕见词拆成多个 Token
速记效率            ←→      Token 效率
```

---

## 类比5：超限处理 ≈ 分页加载

### 前端类比：分页/虚拟滚动

**内容太多时，前端分页加载，RAG 分块检索。**

```
前端分页                    RAG 分块
────────                    ────────
每页 20 条          ←→      每次检索 Top-K 文档
虚拟滚动            ←→      按需加载上下文
无限滚动            ←→      多轮对话逐步补充
```

```javascript
// 前端：分页加载
async function loadPage(page, pageSize = 20) {
    const offset = page * pageSize;
    return await fetch(`/api/items?offset=${offset}&limit=${pageSize}`);
}
```

```python
# RAG：分块检索
def retrieve_with_limit(query: str, top_k: int = 5, max_tokens: int = 10000):
    """检索文档，限制总 Token 数"""
    docs = vector_store.similarity_search(query, k=top_k)
    return truncate_docs_to_limit(docs, max_tokens)
```

### 日常生活类比：自助餐盘子

**Context Window 就像自助餐的盘子大小。**

```
自助餐                      RAG
────────                    ────────
盘子大小            ←→      Context Window
一次能装多少        ←→      一次能处理多少 Token
吃完再拿            ←→      多轮对话
挑最想吃的          ←→      检索最相关的文档
```

---

## 类比总结表

| RAG 概念 | 前端类比 | 日常生活类比 |
|----------|----------|--------------|
| Token | 像素/字节 | 积木块 |
| Context Window | 请求体大小限制 | 短期记忆/桌面大小 |
| Token 预算 | 性能预算 | 行李箱容量 |
| BPE 分词 | 代码压缩 | 速记符号 |
| 超限截断 | 分页加载 | 自助餐盘子 |
| Token 计费 | 流量计费 | 按字数收费 |
| max_tokens | 响应大小限制 | 答题字数限制 |

---

**上一节：** [04_最小可用.md](./04_最小可用.md)
**下一节：** [06_反直觉点.md](./06_反直觉点.md)
