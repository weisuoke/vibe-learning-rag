# 反直觉点

检索器设计中最常见的 3 个误区，以及正确的理解方式。

---

## 误区1：Top-K 越大越好 ❌

### 错误观点

> "返回更多结果总是更好的，K 设大一点，让 LLM 自己筛选。"

### 为什么错？

**1. Token 成本爆炸**

```
假设每个文档块 500 Token：

K=5  → 2,500 Token  → $0.075（GPT-4）
K=50 → 25,000 Token → $0.75（GPT-4）

成本增加 10 倍！
```

**2. 噪声干扰 LLM**

```
场景：用户问"公司年假政策"

K=5（精准）：
- 年假政策文档 ×3
- 请假流程 ×2
→ LLM 回答准确

K=50（过多）：
- 年假政策文档 ×3
- 请假流程 ×2
- 考勤制度 ×10
- 薪资政策 ×15
- 公司历史 ×20
→ LLM 可能被无关内容干扰，回答质量下降
```

**3. "Lost in the Middle" 问题**

研究表明，LLM 对上下文中间部分的内容关注度较低：

```
┌─────────────────────────────────────────┐
│  LLM 对上下文不同位置的关注度            │
│                                         │
│  开头 ████████████████ 高               │
│  中间 ████             低 ← 容易被忽略   │
│  结尾 ██████████████   较高             │
└─────────────────────────────────────────┘
```

### 为什么人们容易这样错？

- **直觉思维**：更多信息 = 更好的决策
- **保险心理**：怕漏掉重要内容
- **忽视成本**：没有意识到 Token 费用

### 正确理解

```python
# ❌ 错误：K 设得太大
retriever = vectorstore.as_retriever(search_kwargs={"k": 50})

# ✅ 正确：根据场景选择合适的 K
def get_optimal_k(query_type):
    """根据查询类型选择 K 值"""
    if query_type == "factual":      # 事实性问题
        return 3
    elif query_type == "complex":    # 复杂问题
        return 8
    elif query_type == "summary":    # 总结类问题
        return 15
    else:
        return 5  # 默认值
```

**经验法则：从 K=5 开始，根据效果逐步调整。**

---

## 误区2：向量检索能解决所有问题 ❌

### 错误观点

> "向量检索理解语义，比关键词检索先进，用向量检索就够了。"

### 为什么错？

**1. 专有名词的灾难**

```
查询："ERR_CONNECTION_REFUSED 错误怎么解决？"

向量检索结果：
1. "网络连接问题的一般解决方案"（语义相关，但不是这个错误）
2. "HTTP 错误码大全"（语义相关，但没有具体解决方案）
3. "服务器配置指南"（语义相关，但不针对这个错误）

关键词检索结果：
1. "ERR_CONNECTION_REFUSED 错误排查指南"（精确匹配！）
2. "常见 ERR_CONNECTION_REFUSED 原因"（精确匹配！）

向量检索完全没找到包含这个错误码的文档！
```

**2. 代码搜索的失败**

```
查询："getUserById 函数在哪里定义？"

向量检索：
- 可能返回"用户管理模块"、"数据库操作"等语义相关但不包含这个函数的文档

关键词检索：
- 直接找到包含 "getUserById" 的文件
```

**3. 精确数值的问题**

```
查询："2024年Q3财报"

向量检索：
- 可能返回 2023年、2022年的财报（语义相似）

关键词检索：
- 精确匹配 "2024" 和 "Q3"
```

### 为什么人们容易这样错？

- **技术崇拜**：新技术 = 更好
- **过度简化**：忽略了不同场景的需求差异
- **缺乏实践**：没有在真实场景中测试过

### 正确理解

```python
# ❌ 错误：只用向量检索
retriever = vectorstore.as_retriever()

# ✅ 正确：混合检索
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
bm25_retriever = BM25Retriever.from_documents(documents, k=10)

# 混合检索：两者优势互补
hybrid_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.5, 0.5]
)
```

**经验法则：生产环境优先使用混合检索。**

---

## 误区3：相似度高 = 答案相关 ❌

### 错误观点

> "相似度分数 0.95，说明这个文档肯定包含答案。"

### 为什么错？

**1. 相似度衡量的是"语义接近"，不是"能回答问题"**

```
查询："Python 3.12 有什么新特性？"

文档A（相似度 0.92）：
"Python 3.11 的新特性包括..."
→ 语义很接近，但回答的是错误版本！

文档B（相似度 0.85）：
"Python 3.12 发布说明：新增了..."
→ 相似度较低，但这才是正确答案！
```

**2. 问题和陈述的语义差异**

```
查询："如何配置 Nginx？"（问题）

文档（相似度 0.88）：
"Nginx 是一个高性能的 Web 服务器..."（陈述）
→ 语义相关，但没有回答"如何配置"
```

**3. 否定语义的陷阱**

```
查询："Python 支持多线程吗？"

文档（相似度 0.90）：
"Python 的 GIL 限制了真正的多线程并行..."
→ 语义相似，但实际上是在说"不完全支持"
```

### 为什么人们容易这样错？

- **数字迷信**：高分数 = 高质量
- **忽略语义细节**：只看整体相似度，不看具体内容
- **过度信任模型**：认为 Embedding 模型能理解一切

### 正确理解

```python
# ❌ 错误：只看相似度分数
results = vectorstore.similarity_search_with_score(query, k=5)
top_result = results[0]  # 直接取最高分

# ✅ 正确：结合多种信号
def smart_retrieve(query, vectorstore, k=10):
    """综合考虑多种因素"""
    results = vectorstore.similarity_search_with_score(query, k=k)

    scored_results = []
    for doc, similarity_score in results:
        # 1. 基础相似度分数
        score = similarity_score

        # 2. 关键词匹配加分
        query_keywords = set(query.lower().split())
        doc_keywords = set(doc.page_content.lower().split())
        keyword_overlap = len(query_keywords & doc_keywords) / len(query_keywords)
        score += 0.1 * keyword_overlap

        # 3. 时效性加分（如果有时间戳）
        if doc.metadata.get("year") == 2024:
            score += 0.05

        scored_results.append((doc, score))

    # 重新排序
    scored_results.sort(key=lambda x: x[1], reverse=True)
    return [doc for doc, score in scored_results[:k]]
```

**经验法则：相似度是参考，不是真理。结合 ReRank 和多种信号综合判断。**

---

## 误区速查表

| 误区 | 错误做法 | 正确做法 |
|------|----------|----------|
| Top-K 越大越好 | K=50 | 从 K=5 开始调整 |
| 向量检索万能 | 只用向量检索 | 混合检索 |
| 相似度高=答案对 | 只看分数 | 结合多种信号 |

---

## 额外提醒：检索器不是万能的

**检索器只能找到"存在的内容"**

```
场景：知识库里没有"量子计算"相关文档

用户问："公司的量子计算研究进展？"

无论检索器多强大，都无法返回不存在的内容。

正确做法：
1. 设置相似度阈值，过滤低质量结果
2. 当没有相关结果时，让 LLM 诚实回答"没有找到相关信息"
3. 定期更新知识库
```

---

**下一步：** [07_实战代码](./07_实战代码.md) - 完整的检索器实现示例
