# 03_核心概念_03_数据转换与组合

> **学习目标**：掌握 RunnablePassthrough 与 RunnableLambda 的数据转换模式、组合策略和性能优化

---

## 概述

数据转换与组合是 LCEL 的核心能力，RunnablePassthrough 和 RunnableLambda 提供了灵活的数据流控制机制，使得复杂的数据处理管道可以通过简单的组合实现。

**核心价值**：
- 灵活的数据转换模式
- 强大的组合能力
- 清晰的数据流控制
- 高效的性能优化

---

## 数据转换模式

### 模式 1：保留式转换（RunnablePassthrough.assign）

**特点**：保留原始数据，添加新字段

```python
from langchain_core.runnables import RunnablePassthrough

# 保留原始查询，添加检索结果
chain = RunnablePassthrough.assign(
    context=retriever
)

# 数据流
input: {"query": "hello"}
output: {"query": "hello", "context": [...]}
```

**适用场景**：
- RAG 管道中保留查询
- 逐步添加中间结果
- 需要访问原始输入的场景

---

### 模式 2：替换式转换（RunnableLambda）

**特点**：完全替换数据结构

```python
from langchain_core.runnables import RunnableLambda

# 完全替换输入
def transform(x):
    return {"new_field": process(x["old_field"])}

chain = RunnableLambda(transform)

# 数据流
input: {"old_field": "value"}
output: {"new_field": "processed_value"}
```

**适用场景**：
- 数据格式转换
- 提取特定字段
- 重构数据结构

---

### 模式 3：条件转换

**特点**：根据条件选择不同的转换逻辑

```python
def conditional_transform(x):
    if x.get("type") == "code":
        return {"query": x["query"], "language": "python"}
    else:
        return {"query": x["query"], "language": "natural"}

chain = RunnableLambda(conditional_transform)
```

**适用场景**：
- 根据输入类型选择处理方式
- 动态路由
- 多分支逻辑

---

## 组合策略

### 策略 1：串行组合（管道操作符 |）

**特点**：数据按顺序流经多个处理器

```python
# 串行处理
chain = (
    RunnableLambda(preprocess)      # 步骤 1
    | RunnablePassthrough.assign(context=retriever)  # 步骤 2
    | prompt                         # 步骤 3
    | llm                           # 步骤 4
)

# 数据流
input → preprocess → assign → prompt → llm → output
```

**执行顺序**：严格按照定义顺序执行

**性能特点**：
- 总耗时 = 各步骤耗时之和
- 适用于有依赖关系的处理

---

### 策略 2：并行组合（RunnableParallel）

**特点**：多个处理器同时执行

```python
from langchain_core.runnables import RunnableParallel

# 并行处理
parallel = RunnableParallel({
    "original": RunnablePassthrough(),
    "context": retriever,
    "metadata": RunnableLambda(get_metadata)
})

# 数据流
input → ┬→ RunnablePassthrough → original
        ├→ retriever → context
        └→ get_metadata → metadata
```

**执行顺序**：所有分支同时执行

**性能特点**：
- 总耗时 = max(各分支耗时)
- 适用于无依赖关系的处理

**性能对比**：
```python
# 串行：2 秒
chain1 = (
    RunnablePassthrough.assign(
        field1=slow_func1,  # 1 秒
        field2=slow_func2   # 1 秒
    )
)

# 并行：1 秒
chain2 = RunnableParallel({
    "original": RunnablePassthrough(),
    "field1": RunnableLambda(slow_func1),  # 1 秒
    "field2": RunnableLambda(slow_func2)   # 1 秒
})
```

---

### 策略 3：条件组合（RunnableBranch）

**特点**：根据条件选择不同的处理分支

```python
from langchain_core.runnables import RunnableBranch

# 条件路由
branch = RunnableBranch(
    (lambda x: x["type"] == "code", code_chain),
    (lambda x: x["type"] == "docs", docs_chain),
    general_chain  # 默认分支
)

chain = (
    RunnableLambda(classify)  # 分类
    | branch                   # 条件路由
)
```

**适用场景**：
- 多类型查询处理
- 动态选择处理流程
- A/B 测试

---

## 常见组合模式

### 模式 1：RAG 标准模式

```python
# 保留查询 + 添加上下文
rag_chain = (
    RunnablePassthrough.assign(context=retriever)
    | prompt
    | llm
)
```

**数据流**：
```
{"query": "hello"}
  ↓ assign
{"query": "hello", "context": [...]}
  ↓ prompt
PromptValue
  ↓ llm
AIMessage
```

---

### 模式 2：查询改写 + RAG

```python
# 预处理 + 检索 + 生成
chain = (
    RunnableLambda(rewrite_query)  # 改写
    | RunnablePassthrough.assign(context=retriever)  # 检索
    | prompt
    | llm
)
```

**数据流**：
```
{"query": "RAG"}
  ↓ rewrite_query
{"query": "请详细解释：RAG", "original": "RAG"}
  ↓ assign
{"query": "请详细解释：RAG", "original": "RAG", "context": [...]}
  ↓ prompt + llm
答案
```

---

### 模式 3：多级数据增强

```python
# 逐步添加字段
chain = (
    RunnablePassthrough.assign(
        rewritten=rewrite_func
    )
    | RunnablePassthrough.assign(
        context=lambda x: retriever.invoke(x["rewritten"])
    )
    | RunnablePassthrough.assign(
        metadata=get_metadata
    )
    | llm
)
```

**优势**：
- 每一步都可以访问前面的结果
- 清晰的数据流
- 易于调试

---

### 模式 4：并行数据增强

```python
# 同时获取多个数据源
parallel = RunnableParallel({
    "original": RunnablePassthrough(),
    "context": retriever,
    "metadata": RunnableLambda(get_metadata),
    "stats": RunnableLambda(get_stats)
})

chain = parallel | prompt | llm
```

**优势**：
- 性能更好（并行执行）
- 适用于独立的数据源

---

### 模式 5：条件路由

```python
# 根据查询类型选择不同的处理流程
def classify(x):
    query = x["query"]
    if "代码" in query:
        return {"type": "code", "query": query}
    elif "文档" in query:
        return {"type": "docs", "query": query}
    else:
        return {"type": "general", "query": query}

chain = (
    RunnableLambda(classify)
    | RunnableBranch(
        (lambda x: x["type"] == "code", code_chain),
        (lambda x: x["type"] == "docs", docs_chain),
        general_chain
    )
)
```

---

## 性能优化

### 优化 1：使用并行处理

**问题**：串行处理导致总耗时过长

```python
# ❌ 串行：3 秒
chain = RunnablePassthrough.assign(
    field1=slow_func1,  # 1 秒
    field2=slow_func2,  # 1 秒
    field3=slow_func3   # 1 秒
)
```

**解决方案**：使用 RunnableParallel

```python
# ✅ 并行：1 秒
chain = RunnableParallel({
    "original": RunnablePassthrough(),
    "field1": RunnableLambda(slow_func1),
    "field2": RunnableLambda(slow_func2),
    "field3": RunnableLambda(slow_func3)
})
```

**性能提升**：3 倍

---

### 优化 2：使用异步函数

**问题**：同步函数阻塞事件循环

```python
# ❌ 同步：阻塞
import requests

def sync_fetch(x):
    return requests.get(url).json()

chain = RunnableLambda(sync_fetch) | llm
```

**解决方案**：使用异步函数

```python
# ✅ 异步：不阻塞
import httpx

async def async_fetch(x):
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        return response.json()

chain = RunnableLambda(async_fetch) | llm
```

**性能提升**：10 倍+（在高并发场景）

---

### 优化 3：批处理

**问题**：逐个处理效率低

```python
# ❌ 逐个处理
for input_data in inputs:
    result = chain.invoke(input_data)
```

**解决方案**：使用批处理

```python
# ✅ 批处理
results = await chain.abatch(inputs)
```

**性能提升**：3-5 倍

---

### 优化 4：缓存

**问题**：重复计算相同的结果

```python
# ❌ 每次都计算
def expensive_compute(x):
    # 昂贵的计算
    return result

chain = RunnableLambda(expensive_compute) | llm
```

**解决方案**：使用缓存

```python
# ✅ 缓存结果
from functools import lru_cache

@lru_cache(maxsize=1000)
def expensive_compute(x: str):
    # 昂贵的计算
    return result

chain = RunnableLambda(expensive_compute) | llm
```

**性能提升**：100 倍+（对于重复查询）

---

## 数据流控制

### 控制 1：数据过滤

```python
def filter_data(x):
    """只保留需要的字段"""
    return {
        "query": x["query"],
        "user": x.get("user", "anonymous")
    }

chain = (
    RunnableLambda(filter_data)  # 过滤
    | RunnablePassthrough.assign(context=retriever)
    | llm
)
```

---

### 控制 2：数据合并

```python
def merge_data(x):
    """合并多个数据源"""
    return {
        **x["source1"],
        **x["source2"],
        "merged": True
    }

chain = (
    RunnableParallel({
        "source1": retriever1,
        "source2": retriever2
    })
    | RunnableLambda(merge_data)
    | llm
)
```

---

### 控制 3：数据验证

```python
def validate_data(x):
    """验证数据完整性"""
    if "query" not in x:
        raise ValueError("Missing query field")
    if len(x["query"]) < 3:
        raise ValueError("Query too short")
    return x

chain = (
    RunnableLambda(validate_data)  # 验证
    | RunnablePassthrough.assign(context=retriever)
    | llm
)
```

---

## 调试技巧

### 技巧 1：打印中间结果

```python
def debug_print(x):
    print(f"Debug: {x}")
    return x

chain = (
    RunnableLambda(debug_print)  # 打印输入
    | RunnablePassthrough.assign(context=retriever)
    | RunnableLambda(debug_print)  # 打印 assign 后
    | llm
)
```

---

### 技巧 2：使用 LangSmith 追踪

```python
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your-api-key"

# 自动记录所有中间步骤
chain.invoke(input_data)
```

---

### 技巧 3：单元测试

```python
def test_data_transformation():
    """测试数据转换"""
    chain = RunnablePassthrough.assign(
        upper=lambda x: x["text"].upper()
    )

    result = chain.invoke({"text": "hello"})

    assert "text" in result
    assert "upper" in result
    assert result["upper"] == "HELLO"
```

---

## 最佳实践

### 1. 保持数据流清晰

```python
# ✅ 清晰的数据流
chain = (
    RunnableLambda(preprocess)      # 预处理
    | RunnablePassthrough.assign(context=retriever)  # 检索
    | RunnableLambda(postprocess)   # 后处理
    | llm
)

# ❌ 混乱的数据流
chain = (
    RunnableLambda(lambda x: {...})  # 不清楚做什么
    | RunnablePassthrough.assign(a=lambda x: ..., b=lambda x: ...)
    | RunnableLambda(lambda x: {...})
)
```

---

### 2. 使用有意义的字段名

```python
# ✅ 有意义的字段名
chain = RunnablePassthrough.assign(
    retrieved_context=retriever,
    query_metadata=get_metadata
)

# ❌ 无意义的字段名
chain = RunnablePassthrough.assign(
    data1=retriever,
    data2=get_metadata
)
```

---

### 3. 避免过度嵌套

```python
# ✅ 扁平化
chain = (
    step1
    | step2
    | step3
)

# ❌ 过度嵌套
chain = (
    step1 | (
        step2 | (
            step3
        )
    )
)
```

---

### 4. 添加类型注解

```python
from typing import Dict, List

def process(input_dict: Dict[str, str]) -> Dict[str, List[str]]:
    """
    处理输入字典

    Args:
        input_dict: 包含 query 字段的字典

    Returns:
        包含 results 字段的字典
    """
    return {"results": input_dict["query"].split()}
```

---

## 2025-2026 最新模式

### 模式 1：智能路由（LangChain v0.3.20+）

```python
from langchain_core.runnables import RunnableRouter

# 自动路由
router = RunnableRouter({
    "code": code_chain,
    "docs": docs_chain,
    "general": general_chain
})

chain = (
    RunnableLambda(classify)  # 分类
    | router                   # 自动路由
)
```

---

### 模式 2：流式处理

```python
# 流式输出
async for chunk in chain.astream(input_data):
    print(chunk, end="", flush=True)
```

---

### 模式 3：批量流式处理

```python
# 批量流式输出
async for chunks in chain.abatch_as_completed(inputs):
    for chunk in chunks:
        print(chunk)
```

---

## 总结

### 核心要点

1. **数据转换**：保留式（assign）vs 替换式（Lambda）
2. **组合策略**：串行（|）vs 并行（RunnableParallel）vs 条件（RunnableBranch）
3. **性能优化**：并行处理、异步函数、批处理、缓存
4. **数据流控制**：过滤、合并、验证

### 最佳实践

1. **清晰的数据流**：每一步的作用明确
2. **有意义的命名**：字段名和函数名清晰
3. **避免过度嵌套**：保持代码扁平化
4. **添加类型注解**：提高可维护性

### 性能优化建议

1. **并行处理**：独立操作使用 RunnableParallel
2. **异步函数**：I/O 密集型操作使用异步
3. **批处理**：多个输入使用 batch/abatch
4. **缓存**：重复计算使用 lru_cache

---

**下一步**：
- 查看 `07_实战代码_*.md` 系列获取完整示例
- 学习 `06_反直觉点.md` 避免常见陷阱

---

**参考资料**：
- [LangChain LCEL 指南](https://python.langchain.com/docs/concepts/lcel/) (2025)
- [Building Production-Ready AI Pipelines](https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557) (2026)
- [Master LangChain in 2025](https://towardsai.net/p/machine-learning/master-langchain-in-2025-from-rag-to-tools-complete-guide) (2025)

---

**版本**：v1.0
**最后更新**：2026-02-18
