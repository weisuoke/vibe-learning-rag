# 核心概念2：故障转移（Failover）

**故障转移是当主节点失效时，系统自动将服务切换到备用节点的机制，确保服务的连续性。**

---

## 什么是故障转移？

故障转移（Failover）是高可用系统的核心机制，指的是当主节点（Primary）发生故障时，系统自动检测故障并将服务切换到备用节点（Standby），整个过程对用户透明或影响最小。

```
故障转移流程：
主节点正常工作 → 主节点故障 → 检测故障 → 选择备节点 → 切换服务 → 备节点接管
     ↓              ↓           ↓          ↓          ↓          ↓
   用户请求      请求失败    心跳超时    选主算法    更新路由   服务恢复
```

---

## Milvus 中的故障转移机制

### 1. Coordinator 的故障转移（主从切换）

Milvus 的 Coordinator 组件使用 **etcd + Raft 算法**实现故障转移：

```
Coordinator 故障转移架构：
┌─────────────────────────────────────────┐
│  etcd 集群（存储元数据 + 选主）          │
│  [etcd-1] [etcd-2] [etcd-3]             │
└─────────────┬───────────────────────────┘
              ↓
┌─────────────────────────────────────────┐
│  Root Coordinator                        │
│  [主节点] ← 当前处理请求                 │
│  [备节点1] ← 待命，监听主节点心跳        │
│  [备节点2] ← 待命，监听主节点心跳        │
└─────────────────────────────────────────┘
```

**故障转移时间线：**

```
0s:  主 Coordinator 宕机
     ↓
3s:  备 Coordinator 检测到心跳超时（3 次心跳失败）
     ↓
5s:  备 Coordinator 向 etcd 发起选主请求
     ↓
7s:  etcd 通过 Raft 算法选出新主节点
     ↓
9s:  新主节点从 etcd 加载元数据
     ↓
10s: 新主节点开始接收请求
     ↓
12s: 客户端重新连接到新主节点
```

**代码示例：**

```python
"""
模拟 Coordinator 故障转移
"""
from pymilvus import connections, utility
import time

# 连接到 Milvus 集群
connections.connect(
    alias="default",
    host="milvus-cluster.default.svc.cluster.local",
    port="19530"
)

print("=== Coordinator 故障转移测试 ===\n")

# 持续执行元数据操作，观察故障转移
for i in range(60):
    try:
        # 列出所有 Collection（需要访问 Root Coordinator）
        collections = utility.list_collections()
        print(f"操作 {i+1}: 成功，当前有 {len(collections)} 个 Collection")

        # 在第 20 次操作后，手动删除主 Root Coordinator Pod
        if i == 20:
            print("\n⚠️  请在另一个终端执行：")
            print("kubectl delete pod milvus-rootcoord-0 --force\n")

    except Exception as e:
        print(f"操作 {i+1}: 失败 - {e}")

    time.sleep(1)

print("\n=== 测试完成 ===")
```

**预期输出：**

```
操作 1-20: 成功，当前有 5 个 Collection
⚠️  请在另一个终端执行：kubectl delete pod milvus-rootcoord-0 --force
操作 21: 失败 - connection refused
操作 22: 失败 - connection refused
操作 23: 失败 - connection refused
操作 24: 成功，当前有 5 个 Collection  ← 新主节点接管
操作 25-60: 成功，当前有 5 个 Collection
```

**关键观察：**
- 故障检测时间：3 秒（心跳超时）
- 选主时间：2-3 秒（Raft 算法）
- 总 RTO：8-10 秒
- 失败请求数：3-5 次

---

### 2. Worker 的故障转移（负载均衡）

Worker 组件（Proxy、QueryNode、DataNode、IndexNode）使用 **Kubernetes Service + 负载均衡**实现故障转移：

```
Worker 故障转移架构：
┌─────────────────────────────────────────┐
│  Kubernetes Service（负载均衡器）        │
│  milvus-proxy.default.svc.cluster.local │
└─────────────┬───────────────────────────┘
              ↓
┌─────────────────────────────────────────┐
│  Proxy Pods                              │
│  [Pod-1] ✅ 健康 ← 接收流量              │
│  [Pod-2] ❌ 不健康 ← 从负载均衡中移除    │
│  [Pod-3] ✅ 健康 ← 接收流量              │
└─────────────────────────────────────────┘
```

**故障转移时间线：**

```
0s:  Proxy Pod-2 宕机
     ↓
10s: Kubernetes livenessProbe 检测到故障（连续 3 次失败）
     ↓
11s: Kubernetes 将 Pod-2 从 Service 的 Endpoints 中移除
     ↓
12s: 新的请求自动路由到 Pod-1 和 Pod-3
     ↓
15s: Kubernetes 自动重启 Pod-2
     ↓
30s: Pod-2 重启完成，重新加入负载均衡
```

**代码示例：**

```python
"""
模拟 Proxy 故障转移
"""
from pymilvus import connections, Collection
import time

# 连接到 Milvus 集群（通过 Kubernetes Service）
connections.connect(
    alias="default",
    host="milvus-proxy.default.svc.cluster.local",
    port="19530"
)

collection = Collection("test")
collection.load()

print("=== Proxy 故障转移测试 ===\n")

# 持续查询，观察故障转移
for i in range(60):
    try:
        start = time.time()
        results = collection.search(
            data=[[0.1] * 128],
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=10
        )
        latency = (time.time() - start) * 1000

        print(f"查询 {i+1}: 成功，延迟 {latency:.2f} ms")

        # 在第 20 次查询后，手动删除一个 Proxy Pod
        if i == 20:
            print("\n⚠️  请在另一个终端执行：")
            print("kubectl delete pod -l app=milvus-proxy --force\n")

    except Exception as e:
        print(f"查询 {i+1}: 失败 - {e}")

    time.sleep(1)

print("\n=== 测试完成 ===")
```

**预期输出：**

```
查询 1-20: 成功，延迟 50 ms
⚠️  请在另一个终端执行：kubectl delete pod -l app=milvus-proxy --force
查询 21: 失败 - connection refused
查询 22: 成功，延迟 55 ms  ← 自动切换到其他 Proxy
查询 23-60: 成功，延迟 50 ms
```

**关键观察：**
- 故障检测时间：10 秒（Kubernetes livenessProbe）
- 切换时间：1-2 秒（Service 更新 Endpoints）
- 总 RTO：11-12 秒
- 失败请求数：1-2 次

---

## 故障检测机制

### 1. 心跳检测（Heartbeat）

心跳检测是最常用的故障检测机制：

```
心跳检测流程：
主节点 → 每 3 秒发送心跳 → 备节点
备节点 → 监听心跳 → 如果 3 次心跳失败（9 秒）→ 判定主节点故障
```

**etcd 的心跳配置：**

```yaml
# etcd 配置
heartbeat-interval: 100  # 心跳间隔 100ms
election-timeout: 1000   # 选举超时 1000ms（10 次心跳）
```

**Kubernetes 的健康检查配置：**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: milvus-proxy
spec:
  template:
    spec:
      containers:
      - name: proxy
        livenessProbe:
          httpGet:
            path: /healthz
            port: 9091
          initialDelaySeconds: 30  # 启动后 30 秒开始检查
          periodSeconds: 10        # 每 10 秒检查一次
          timeoutSeconds: 5        # 超时时间 5 秒
          failureThreshold: 3      # 连续失败 3 次则判定故障
```

**优化心跳检测：**

```yaml
# 优化后的配置（更快的故障检测）
livenessProbe:
  httpGet:
    path: /healthz
    port: 9091
  initialDelaySeconds: 10  # 减少启动等待时间
  periodSeconds: 3         # 更频繁的检查（每 3 秒）
  timeoutSeconds: 2        # 更短的超时时间
  failureThreshold: 2      # 更少的失败次数（2 次）

# 故障检测时间：3s * 2 = 6s（优化前：10s * 3 = 30s）
```

---

### 2. 选主算法（Leader Election）

Milvus 使用 **etcd 的 Raft 算法**进行选主：

```
Raft 选主流程：
1. 主节点定期发送心跳给备节点
   ↓
2. 备节点在 election-timeout 内没有收到心跳
   ↓
3. 备节点转换为候选者（Candidate），发起选举
   ↓
4. 候选者向其他节点请求投票
   ↓
5. 获得多数派投票（> 50%）的候选者成为新主节点
   ↓
6. 新主节点开始发送心跳，其他节点转换为备节点
```

**代码示例：模拟选主过程**

```python
"""
模拟 Raft 选主算法
"""
import random
import time

class Node:
    def __init__(self, node_id):
        self.node_id = node_id
        self.state = "follower"  # follower, candidate, leader
        self.current_term = 0
        self.voted_for = None
        self.votes_received = 0

    def start_election(self, nodes):
        """发起选举"""
        self.state = "candidate"
        self.current_term += 1
        self.voted_for = self.node_id
        self.votes_received = 1  # 投票给自己

        print(f"节点 {self.node_id} 发起选举（任期 {self.current_term}）")

        # 向其他节点请求投票
        for node in nodes:
            if node.node_id != self.node_id:
                if node.vote(self.current_term):
                    self.votes_received += 1

        # 检查是否获得多数派投票
        majority = len(nodes) // 2 + 1
        if self.votes_received >= majority:
            self.state = "leader"
            print(f"节点 {self.node_id} 成为主节点（获得 {self.votes_received}/{len(nodes)} 票）")
            return True
        else:
            self.state = "follower"
            print(f"节点 {self.node_id} 选举失败（仅获得 {self.votes_received}/{len(nodes)} 票）")
            return False

    def vote(self, term):
        """投票"""
        if term > self.current_term and self.voted_for is None:
            self.voted_for = term
            self.current_term = term
            return True
        return False

# 模拟 3 个节点的选举
nodes = [Node(i) for i in range(3)]

# 节点 0 是主节点
nodes[0].state = "leader"
print("初始状态：节点 0 是主节点\n")

# 模拟主节点故障
print("主节点故障，开始选举...\n")
time.sleep(1)

# 节点 1 发起选举
nodes[1].start_election(nodes)

# 输出：
# 初始状态：节点 0 是主节点
# 主节点故障，开始选举...
# 节点 1 发起选举（任期 1）
# 节点 1 成为主节点（获得 2/3 票）
```

---

## 故障转移的优化策略

### 1. 减少故障检测时间

**优化前：**
```yaml
periodSeconds: 10
failureThreshold: 3
# 故障检测时间：10s * 3 = 30s
```

**优化后：**
```yaml
periodSeconds: 3
failureThreshold: 2
# 故障检测时间：3s * 2 = 6s
```

**权衡：**
- 更快的故障检测 vs 更多的误报（网络抖动）
- 建议：生产环境使用 5-10 秒的检测时间

---

### 2. 预热备节点（Warm Standby）

**冷备（Cold Standby）：**
```
主节点故障 → 启动备节点 → 加载数据 → 开始服务
RTO: 1-5 分钟
```

**热备（Hot Standby）：**
```
备节点一直运行 → 实时同步数据 → 主节点故障 → 立即接管
RTO: 5-15 秒
```

**温备（Warm Standby）：**
```
备节点一直运行 → 定期同步数据 → 主节点故障 → 加载最新数据 → 接管
RTO: 30-60 秒
```

**Milvus 使用热备策略：**
```yaml
# Coordinator 配置 3 个副本（热备）
replicas: 3

# 所有副本都在运行，实时同步元数据
# 主节点故障后，备节点立即接管（RTO < 10s）
```

---

### 3. 客户端重试机制

**基础重试：**

```python
from pymilvus import connections
import time

def connect_with_retry(max_retries=3, retry_delay=2):
    """带重试的连接"""
    for i in range(max_retries):
        try:
            connections.connect(
                alias="default",
                host="milvus-cluster",
                port="19530"
            )
            print("连接成功")
            return True
        except Exception as e:
            print(f"连接失败（第 {i+1} 次尝试）: {e}")
            if i < max_retries - 1:
                time.sleep(retry_delay)
            else:
                raise e

connect_with_retry()
```

**指数退避重试：**

```python
import time
import random

def connect_with_exponential_backoff(max_retries=5):
    """指数退避重试"""
    for i in range(max_retries):
        try:
            connections.connect(
                alias="default",
                host="milvus-cluster",
                port="19530"
            )
            print("连接成功")
            return True
        except Exception as e:
            if i < max_retries - 1:
                # 指数退避：2^i + 随机抖动
                delay = (2 ** i) + random.uniform(0, 1)
                print(f"连接失败（第 {i+1} 次尝试），{delay:.2f} 秒后重试")
                time.sleep(delay)
            else:
                raise e

# 重试延迟：1s, 2s, 4s, 8s, 16s
connect_with_exponential_backoff()
```

---

### 4. 使用服务网格（Service Mesh）

**Istio 的故障转移配置：**

```yaml
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: milvus-proxy
spec:
  host: milvus-proxy.default.svc.cluster.local
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 50
        http2MaxRequests: 100
    outlierDetection:
      consecutiveErrors: 3        # 连续 3 次错误
      interval: 10s               # 每 10 秒检查一次
      baseEjectionTime: 30s       # 驱逐时间 30 秒
      maxEjectionPercent: 50      # 最多驱逐 50% 的实例
```

**效果：**
- 自动检测不健康的实例
- 自动从负载均衡中移除
- 自动重试失败的请求
- RTO < 5 秒

---

## 在 RAG 系统中的应用

### 场景1：文档问答系统的故障转移

```python
"""
RAG 系统中的故障转移
"""
from pymilvus import connections, Collection
import time

class ResilientMilvusClient:
    """具有故障转移能力的 Milvus 客户端"""

    def __init__(self, hosts, port="19530", max_retries=3):
        self.hosts = hosts  # 多个 Milvus 节点地址
        self.port = port
        self.max_retries = max_retries
        self.current_host_index = 0

    def connect(self):
        """连接到 Milvus 集群（带故障转移）"""
        for i in range(self.max_retries):
            host = self.hosts[self.current_host_index]
            try:
                connections.connect(
                    alias="default",
                    host=host,
                    port=self.port
                )
                print(f"连接成功：{host}")
                return True
            except Exception as e:
                print(f"连接失败：{host} - {e}")
                # 切换到下一个节点
                self.current_host_index = (self.current_host_index + 1) % len(self.hosts)
                if i < self.max_retries - 1:
                    time.sleep(2)

        raise Exception("所有节点都不可用")

    def search_with_failover(self, collection_name, query_vector, top_k=5):
        """带故障转移的检索"""
        collection = Collection(collection_name)

        for i in range(self.max_retries):
            try:
                results = collection.search(
                    data=[query_vector],
                    anns_field="embedding",
                    param={"metric_type": "COSINE", "params": {"nprobe": 16}},
                    limit=top_k
                )
                return results
            except Exception as e:
                print(f"检索失败（第 {i+1} 次尝试）: {e}")
                if i < self.max_retries - 1:
                    # 重新连接到其他节点
                    self.connect()
                    collection = Collection(collection_name)
                    time.sleep(1)
                else:
                    raise e

# 使用示例
client = ResilientMilvusClient(
    hosts=[
        "milvus-proxy-1.example.com",
        "milvus-proxy-2.example.com",
        "milvus-proxy-3.example.com"
    ]
)

client.connect()

# 即使某个节点故障，也能自动切换到其他节点
results = client.search_with_failover(
    collection_name="documents",
    query_vector=[0.1] * 768,
    top_k=5
)
```

---

## 关键要点

1. **故障转移类型**：
   - Coordinator：主从切换（Raft 选主）
   - Worker：负载均衡（Kubernetes Service）

2. **RTO 优化**：
   - 优化健康检查参数：6-10 秒
   - 使用热备策略：< 10 秒
   - 客户端重试：减少用户感知的故障时间

3. **故障检测**：
   - 心跳检测：定期发送心跳，超时判定故障
   - 健康检查：HTTP 端点检查，连续失败判定故障

4. **选主算法**：
   - Raft 算法：多数派投票，确保一致性
   - 奇数副本：3/5/7 个副本，避免脑裂

5. **客户端优化**：
   - 重试机制：指数退避，避免雪崩
   - 多节点连接：自动切换到健康节点
   - 服务网格：自动故障检测和重试
