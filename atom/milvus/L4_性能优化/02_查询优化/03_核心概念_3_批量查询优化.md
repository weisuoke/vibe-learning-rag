# 核心概念3：批量查询优化

**一句话定义：** 批量查询优化是通过一次查询多个向量来减少网络往返次数、利用并行计算、提升系统吞吐量的关键技术。

---

## 1. 什么是批量查询？

批量查询是指在一次 API 调用中同时查询多个向量，而不是逐个查询。

**核心思想：** 用略微增加的单次延迟，换取大幅降低的总延迟和显著提升的吞吐量

```python
from pymilvus import Collection
import numpy as np

collection = Collection("documents")

# ❌ 逐个查询（100个向量）
query_vectors = [np.random.rand(768).tolist() for _ in range(100)]

total_time = 0
for query_vector in query_vectors:
    start = time.time()
    results = collection.search(
        data=[query_vector],  # 每次查询1个向量
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
    total_time += time.time() - start

print(f"逐个查询总延迟: {total_time*1000:.2f}ms")
# 输出：逐个查询总延迟: 5000.00ms（100 × 50ms）

# ✅ 批量查询（100个向量）
start = time.time()
results = collection.search(
    data=query_vectors,  # 一次查询100个向量
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)
total_time = time.time() - start

print(f"批量查询总延迟: {total_time*1000:.2f}ms")
# 输出：批量查询总延迟: 200.00ms

# 性能提升：25倍！
```

---

## 2. 批量查询的原理

### 2.1 为什么批量查询更快？

**三个关键原因：**

**1. 减少网络往返次数**
```
逐个查询：
客户端 → 服务器（请求1）→ 客户端（响应1）
客户端 → 服务器（请求2）→ 客户端（响应2）
...
客户端 → 服务器（请求100）→ 客户端（响应100）
总往返：100次

批量查询：
客户端 → 服务器（请求1-100）→ 客户端（响应1-100）
总往返：1次

网络开销：100次 → 1次（减少99%）
```

**2. 减少固定开销**
```
每次查询的固定开销：
- TCP 连接建立/复用
- 请求序列化/反序列化
- 权限验证
- 日志记录
- 等等

逐个查询：固定开销 × 100次
批量查询：固定开销 × 1次

固定开销：100倍 → 1倍
```

**3. 利用并行计算**
```
逐个查询：
CPU/GPU 处理向量1 → 处理向量2 → ... → 处理向量100
串行执行，无法利用并行

批量查询：
CPU/GPU 同时处理向量1-100
并行执行，充分利用硬件资源

计算效率：提升 5-10 倍（取决于硬件）
```

### 2.2 性能对比

```python
# 场景：查询100个向量

# 逐个查询
单次延迟：50ms
网络往返：100次
固定开销：100次
并行度：1
总延迟：100 × 50ms = 5000ms
吞吐量：100 / 5s = 20 QPS

# 批量查询
单次延迟：200ms（略有增加）
网络往返：1次
固定开销：1次
并行度：100
总延迟：200ms
吞吐量：100 / 0.2s = 500 QPS

# 结论：
# - 总延迟降低 25 倍（5000ms → 200ms）
# - 吞吐量提升 25 倍（20 QPS → 500 QPS）
# - 虽然单次延迟增加了 4 倍（50ms → 200ms）
```

---

## 3. 批量查询的使用

### 3.1 基本用法

```python
from pymilvus import Collection, connections
import numpy as np

connections.connect("default", host="localhost", port="19530")
collection = Collection("documents")
collection.load()

# 准备多个查询向量
query_vectors = [
    np.random.rand(768).tolist(),
    np.random.rand(768).tolist(),
    np.random.rand(768).tolist(),
]

# 批量查询
results = collection.search(
    data=query_vectors,  # 传入向量列表
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)

# 处理结果
for i, result in enumerate(results):
    print(f"\n查询 {i+1} 的结果:")
    for j, hit in enumerate(result):
        print(f"  {j+1}. id={hit.id}, distance={hit.distance:.4f}")

# 输出示例：
# 查询 1 的结果:
#   1. id=123, distance=0.4523
#   2. id=456, distance=0.5678
#   ...
#
# 查询 2 的结果:
#   1. id=789, distance=0.3456
#   2. id=012, distance=0.4567
#   ...
```

### 3.2 批量大小的选择

**权衡：** 批量大小 vs 延迟 vs 吞吐量

```python
import time
import numpy as np

# 测试不同批量大小的性能
batch_sizes = [1, 10, 50, 100, 500, 1000]

print("批量大小 | 单次延迟(ms) | 吞吐量(QPS)")
print("---------|--------------|------------")

for batch_size in batch_sizes:
    # 准备查询向量
    query_vectors = [np.random.rand(768).tolist() for _ in range(batch_size)]

    # 批量查询
    start = time.time()
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
    elapsed = time.time() - start

    # 计算吞吐量
    qps = batch_size / elapsed

    print(f"{batch_size:8d} | {elapsed*1000:12.2f} | {qps:11.1f}")

# 输出示例：
# 批量大小 | 单次延迟(ms) | 吞吐量(QPS)
# ---------|--------------|------------
#        1 |        50.00 |        20.0
#       10 |        80.00 |       125.0
#       50 |       150.00 |       333.3
#      100 |       200.00 |       500.0
#      500 |       600.00 |       833.3
#     1000 |      1200.00 |       833.3
```

**选择原则：**

| 场景 | 批量大小 | 原因 |
|-----|---------|------|
| **实时查询**（低延迟） | 1-10 | 单次延迟低（< 100ms） |
| **在线服务**（平衡） | 10-100 | 平衡延迟和吞吐量 |
| **离线处理**（高吞吐） | 100-1000 | 最大化吞吐量 |

### 3.3 动态批量处理

```python
from typing import List
import time
import numpy as np

class BatchProcessor:
    """动态批量处理器"""

    def __init__(self, collection, batch_size=100, timeout=0.1):
        self.collection = collection
        self.batch_size = batch_size  # 批量大小
        self.timeout = timeout  # 超时时间（秒）
        self.buffer = []  # 缓冲区
        self.last_flush = time.time()

    def add(self, query_vector: List[float]) -> List:
        """添加查询向量到缓冲区"""
        self.buffer.append(query_vector)

        # 如果达到批量大小或超时，立即执行
        if len(self.buffer) >= self.batch_size or \
           time.time() - self.last_flush > self.timeout:
            return self.flush()

        return None

    def flush(self) -> List:
        """执行批量查询"""
        if not self.buffer:
            return []

        # 批量查询
        results = self.collection.search(
            data=self.buffer,
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 16}},
            limit=10
        )

        # 清空缓冲区
        self.buffer = []
        self.last_flush = time.time()

        return results

# 使用示例
processor = BatchProcessor(collection, batch_size=10, timeout=0.1)

# 模拟实时查询
for i in range(100):
    query_vector = np.random.rand(768).tolist()
    results = processor.add(query_vector)

    if results:
        print(f"批量查询完成，返回 {len(results)} 个结果")

# 处理剩余的查询
remaining_results = processor.flush()
if remaining_results:
    print(f"最后批量查询完成，返回 {len(remaining_results)} 个结果")
```

---

## 4. 批量查询的优化技巧

### 4.1 预分配内存

```python
# ❌ 差：动态分配内存
query_vectors = []
for i in range(1000):
    query_vectors.append(np.random.rand(768).tolist())

# ✅ 好：预分配内存
query_vectors = [None] * 1000
for i in range(1000):
    query_vectors[i] = np.random.rand(768).tolist()

# 或者使用 NumPy
query_vectors = np.random.rand(1000, 768).tolist()
```

### 4.2 异步批量查询

```python
import asyncio
from pymilvus import Collection, connections

connections.connect("default", host="localhost", port="19530")
collection = Collection("documents")
collection.load()

async def async_batch_search(query_vectors: List[List[float]]) -> List:
    """异步批量查询"""
    # 注意：pymilvus 目前不支持原生异步，这里使用 asyncio.to_thread
    loop = asyncio.get_event_loop()
    results = await loop.run_in_executor(
        None,
        lambda: collection.search(
            data=query_vectors,
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 16}},
            limit=10
        )
    )
    return results

async def main():
    # 准备多个批次
    batches = [
        [np.random.rand(768).tolist() for _ in range(100)],
        [np.random.rand(768).tolist() for _ in range(100)],
        [np.random.rand(768).tolist() for _ in range(100)],
    ]

    # 并发执行多个批量查询
    tasks = [async_batch_search(batch) for batch in batches]
    results = await asyncio.gather(*tasks)

    print(f"完成 {len(results)} 个批量查询")

# 运行
asyncio.run(main())
```

### 4.3 批量查询 + 标量过滤

```python
# 批量查询可以与标量过滤结合使用
query_vectors = [np.random.rand(768).tolist() for _ in range(100)]

results = collection.search(
    data=query_vectors,
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10,
    expr="category == 'technology' and publish_date > '2024-01-01'"  # 标量过滤
)

# 每个查询都会应用相同的标量过滤
```

---

## 5. 在RAG中的应用

### 5.1 批量文档检索

```python
from pymilvus import Collection, connections
from openai import OpenAI
from typing import List

connections.connect("default", host="localhost", port="19530")
collection = Collection("knowledge_base")
collection.load()

client = OpenAI()

def batch_rag_query(questions: List[str]) -> List[str]:
    """批量 RAG 查询"""

    # 1. 批量生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=questions  # 批量编码
    )
    query_vectors = [item.embedding for item in response.data]

    # 2. 批量向量检索
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=5,
        output_fields=["content"]
    )

    # 3. 批量生成答案
    answers = []
    for question, result in zip(questions, results):
        # 构建上下文
        context = "\n\n".join([hit.entity.get("content") for hit in result])

        # 生成答案
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "根据上下文回答问题。"},
                {"role": "user", "content": f"上下文：\n{context}\n\n问题：{question}"}
            ]
        )
        answers.append(response.choices[0].message.content)

    return answers

# 使用
questions = [
    "什么是向量数据库？",
    "如何优化查询性能？",
    "Milvus 支持哪些索引类型？",
]

answers = batch_rag_query(questions)
for q, a in zip(questions, answers):
    print(f"Q: {q}")
    print(f"A: {a}\n")
```

### 5.2 批量推荐系统

```python
def batch_recommend(user_ids: List[str], k: int = 10) -> dict:
    """批量推荐：为多个用户生成推荐"""

    # 1. 批量获取用户向量
    user_vectors = []
    for user_id in user_ids:
        # 从用户画像中获取向量
        user_vector = get_user_profile_vector(user_id)
        user_vectors.append(user_vector)

    # 2. 批量检索相似商品
    results = collection.search(
        data=user_vectors,
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=k,
        output_fields=["product_id", "title", "price"]
    )

    # 3. 构建推荐结果
    recommendations = {}
    for user_id, result in zip(user_ids, results):
        recommendations[user_id] = [
            {
                "product_id": hit.entity.get("product_id"),
                "title": hit.entity.get("title"),
                "price": hit.entity.get("price"),
                "score": hit.distance
            }
            for hit in result
        ]

    return recommendations

# 使用
user_ids = ["user1", "user2", "user3", "user4", "user5"]
recommendations = batch_recommend(user_ids, k=10)

for user_id, items in recommendations.items():
    print(f"\n{user_id} 的推荐:")
    for item in items[:3]:
        print(f"  - {item['title']} (${item['price']})")
```

### 5.3 批量图像搜索

```python
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel

# 加载 CLIP 模型
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

def batch_image_search(image_paths: List[str], k: int = 10) -> List:
    """批量图像搜索"""

    # 1. 批量加载图像
    images = [Image.open(path) for path in image_paths]

    # 2. 批量生成图像向量
    inputs = processor(images=images, return_tensors="pt")
    with torch.no_grad():
        image_features = model.get_image_features(**inputs)
    query_vectors = image_features.cpu().numpy().tolist()

    # 3. 批量向量检索
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=k,
        output_fields=["image_url", "title"]
    )

    return results

# 使用
image_paths = ["image1.jpg", "image2.jpg", "image3.jpg"]
results = batch_image_search(image_paths, k=10)

for i, result in enumerate(results):
    print(f"\n图像 {i+1} 的相似图像:")
    for hit in result[:3]:
        print(f"  - {hit.entity.get('title')}")
```

---

## 6. 性能测试

### 6.1 测试批量查询的性能提升

```python
import time
import numpy as np
from pymilvus import Collection, connections

connections.connect("default", host="localhost", port="19530")
collection = Collection("documents")
collection.load()

# 准备查询向量
num_queries = 100
query_vectors = [np.random.rand(768).tolist() for _ in range(num_queries)]

# 测试1：逐个查询
print("测试1：逐个查询")
start = time.time()
for query_vector in query_vectors:
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
time_sequential = time.time() - start
qps_sequential = num_queries / time_sequential

print(f"  总延迟: {time_sequential*1000:.2f}ms")
print(f"  吞吐量: {qps_sequential:.1f} QPS")

# 测试2：批量查询
print("\n测试2：批量查询")
start = time.time()
results = collection.search(
    data=query_vectors,
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)
time_batch = time.time() - start
qps_batch = num_queries / time_batch

print(f"  总延迟: {time_batch*1000:.2f}ms")
print(f"  吞吐量: {qps_batch:.1f} QPS")

# 性能对比
print(f"\n性能提升:")
print(f"  延迟降低: {time_sequential/time_batch:.1f}x")
print(f"  吞吐量提升: {qps_batch/qps_sequential:.1f}x")

# 输出示例：
# 测试1：逐个查询
#   总延迟: 5000.00ms
#   吞吐量: 20.0 QPS
#
# 测试2：批量查询
#   总延迟: 200.00ms
#   吞吐量: 500.0 QPS
#
# 性能提升:
#   延迟降低: 25.0x
#   吞吐量提升: 25.0x
```

### 6.2 测试不同批量大小的性能

```python
# 测试不同批量大小
batch_sizes = [1, 5, 10, 20, 50, 100, 200, 500]

print("批量大小 | 总延迟(ms) | 单次延迟(ms) | 吞吐量(QPS)")
print("---------|------------|--------------|------------")

for batch_size in batch_sizes:
    query_vectors = [np.random.rand(768).tolist() for _ in range(batch_size)]

    start = time.time()
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
    elapsed = time.time() - start

    avg_latency = elapsed / batch_size
    qps = batch_size / elapsed

    print(f"{batch_size:8d} | {elapsed*1000:10.2f} | {avg_latency*1000:12.2f} | {qps:11.1f}")

# 输出示例：
# 批量大小 | 总延迟(ms) | 单次延迟(ms) | 吞吐量(QPS)
# ---------|------------|--------------|------------
#        1 |      50.00 |        50.00 |        20.0
#        5 |      70.00 |        14.00 |        71.4
#       10 |      80.00 |         8.00 |       125.0
#       20 |     100.00 |         5.00 |       200.0
#       50 |     150.00 |         3.00 |       333.3
#      100 |     200.00 |         2.00 |       500.0
#      200 |     350.00 |         1.75 |       571.4
#      500 |     800.00 |         1.60 |       625.0
```

---

## 7. 常见问题

### Q1: 批量查询会增加单次延迟吗？

**A:** 会略有增加，但总延迟大幅降低。例如：
- 单次查询：50ms × 100次 = 5000ms
- 批量查询：200ms × 1次 = 200ms
- 虽然单次延迟增加了4倍，但总延迟降低了25倍

### Q2: 批量大小应该设置多大？

**A:** 根据场景选择：
- 实时查询（低延迟）：1-10
- 在线服务（平衡）：10-100
- 离线处理（高吞吐）：100-1000

### Q3: 批量查询可以与标量过滤结合吗？

**A:** 可以！每个查询都会应用相同的标量过滤表达式。

### Q4: 批量查询有最大限制吗？

**A:** Milvus 有最大批量大小限制（通常1000-10000），超过需要分批处理。

---

## 8. 总结

**批量查询优化的核心：**
1. **减少网络往返**：100次 → 1次
2. **减少固定开销**：连接、序列化、验证等
3. **利用并行计算**：CPU/GPU 并行处理
4. **权衡延迟和吞吐量**：单次延迟略增，总延迟大降

**最佳实践：**
- 根据场景选择合适的批量大小
- 在 RAG 中使用批量查询处理多个问题
- 结合标量过滤进一步优化性能
- 批量查询能将吞吐量提升 10-100 倍

**性能提升：**
- 总延迟降低：10-25倍
- 吞吐量提升：10-25倍
- 成本降低：90%+（需要更少的机器）
