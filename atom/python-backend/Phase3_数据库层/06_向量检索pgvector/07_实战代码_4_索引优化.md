# 实战代码场景4：索引优化与性能对比

本示例演示如何创建和优化 pgvector 索引，并进行性能基准测试。

## 完整代码示例

```python
"""
pgvector 索引优化与性能对比
演示：HNSW/IVFFlat 索引创建、参数调优、性能测试、召回率评估
"""

import os
import time
import psycopg2
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict, Tuple

# 加载环境变量
load_dotenv()

# 初始化
conn = psycopg2.connect(os.getenv("DATABASE_URL"))
cursor = conn.cursor()
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

# ===== 1. 准备测试数据 =====
print("=== 1. 准备测试数据 ===")

# 创建表
cursor.execute("DROP TABLE IF EXISTS documents CASCADE")
cursor.execute("""
    CREATE TABLE documents (
        id SERIAL PRIMARY KEY,
        content TEXT NOT NULL,
        embedding vector(1536),
        created_at TIMESTAMP DEFAULT NOW()
    )
""")
conn.commit()

# 生成测试文档（使用真实数据）
print("正在生成测试数据...")

# 准备 1000 个测试文档
test_documents = [
    f"这是第 {i} 个测试文档，内容关于向量数据库、pgvector、HNSW 索引、IVFFlat 索引、向量检索、RAG 系统等技术主题。"
    for i in range(1000)
]

# 批量生成 Embedding（分批处理，避免 API 限制）
batch_size = 100
all_embeddings = []

for i in range(0, len(test_documents), batch_size):
    batch = test_documents[i:i + batch_size]
    print(f"  生成 Embedding: {i+1}-{min(i+batch_size, len(test_documents))}/{len(test_documents)}")

    embeddings_response = client.embeddings.create(
        input=batch,
        model="text-embedding-3-small"
    )
    all_embeddings.extend([emb.embedding for emb in embeddings_response.data])

# 批量插入
data = [(text, emb) for text, emb in zip(test_documents, all_embeddings)]
cursor.executemany(
    "INSERT INTO documents (content, embedding) VALUES (%s, %s)",
    data
)
conn.commit()

print(f"✅ 已插入 {len(test_documents)} 条测试数据")

# ===== 2. 无索引性能测试 =====
print("\n=== 2. 无索引性能测试（基准）===")

# 生成测试查询
test_query = "向量数据库的性能优化"
query_embedding = client.embeddings.create(
    input=test_query,
    model="text-embedding-3-small"
).data[0].embedding

def benchmark_query(query_embedding: List[float], iterations: int = 10) -> Dict:
    """测试查询性能"""
    times = []

    for _ in range(iterations):
        start = time.time()
        cursor.execute(
            "SELECT id FROM documents ORDER BY embedding <=> %s LIMIT 10",
            (query_embedding,)
        )
        cursor.fetchall()
        elapsed = (time.time() - start) * 1000  # 毫秒
        times.append(elapsed)

    return {
        "avg": np.mean(times),
        "min": np.min(times),
        "max": np.max(times),
        "p50": np.percentile(times, 50),
        "p95": np.percentile(times, 95),
        "p99": np.percentile(times, 99)
    }

# 使用 EXPLAIN ANALYZE 查看查询计划
cursor.execute(
    "EXPLAIN ANALYZE SELECT id FROM documents ORDER BY embedding <=> %s LIMIT 10",
    (query_embedding,)
)
print("\n查询计划（无索引）：")
for line in cursor.fetchall():
    print(f"  {line[0]}")

# 性能测试
stats_no_index = benchmark_query(query_embedding, iterations=10)
print(f"\n无索引性能（10次平均）：")
print(f"  平均: {stats_no_index['avg']:.2f}ms")
print(f"  P50: {stats_no_index['p50']:.2f}ms")
print(f"  P95: {stats_no_index['p95']:.2f}ms")
print(f"  P99: {stats_no_index['p99']:.2f}ms")

# ===== 3. 创建 HNSW 索引 =====
print("\n=== 3. 创建 HNSW 索引 ===")

# 测试不同的 HNSW 参数
hnsw_configs = [
    {"m": 8, "ef_construction": 32, "name": "HNSW (m=8, ef=32)"},
    {"m": 16, "ef_construction": 64, "name": "HNSW (m=16, ef=64) [默认]"},
    {"m": 32, "ef_construction": 128, "name": "HNSW (m=32, ef=128)"}
]

hnsw_results = []

for config in hnsw_configs:
    print(f"\n测试配置: {config['name']}")

    # 删除旧索引
    cursor.execute("DROP INDEX IF EXISTS documents_embedding_idx")
    conn.commit()

    # 创建索引
    print(f"  正在创建索引...")
    start = time.time()
    cursor.execute(f"""
        CREATE INDEX documents_embedding_idx ON documents
        USING hnsw (embedding vector_cosine_ops)
        WITH (m = {config['m']}, ef_construction = {config['ef_construction']})
    """)
    conn.commit()
    index_build_time = time.time() - start

    # 获取索引大小
    cursor.execute("""
        SELECT pg_size_pretty(pg_relation_size('documents_embedding_idx'))
    """)
    index_size = cursor.fetchone()[0]

    print(f"  ✅ 索引创建完成")
    print(f"  构建时间: {index_build_time:.2f}秒")
    print(f"  索引大小: {index_size}")

    # 测试不同的 ef_search 值
    ef_search_values = [40, 100, 200]

    for ef_search in ef_search_values:
        cursor.execute(f"SET hnsw.ef_search = {ef_search}")

        # 性能测试
        stats = benchmark_query(query_embedding, iterations=10)

        # 验证索引是否生效
        cursor.execute(
            "EXPLAIN SELECT id FROM documents ORDER BY embedding <=> %s LIMIT 10",
            (query_embedding,)
        )
        plan = cursor.fetchall()
        uses_index = any("Index Scan" in line[0] for line in plan)

        hnsw_results.append({
            "config": config['name'],
            "m": config['m'],
            "ef_construction": config['ef_construction'],
            "ef_search": ef_search,
            "build_time": index_build_time,
            "index_size": index_size,
            "uses_index": uses_index,
            **stats
        })

        print(f"  ef_search={ef_search}: P95={stats['p95']:.2f}ms, 索引生效={uses_index}")

# ===== 4. 创建 IVFFlat 索引 =====
print("\n=== 4. 创建 IVFFlat 索引 ===")

# 删除 HNSW 索引
cursor.execute("DROP INDEX IF EXISTS documents_embedding_idx")
conn.commit()

# 测试不同的 IVFFlat 参数
# lists 推荐值：sqrt(N)，其中 N 是向量总数
# 1000 个向量：sqrt(1000) ≈ 32
ivfflat_configs = [
    {"lists": 10, "name": "IVFFlat (lists=10)"},
    {"lists": 32, "name": "IVFFlat (lists=32) [推荐]"},
    {"lists": 100, "name": "IVFFlat (lists=100)"}
]

ivfflat_results = []

for config in ivfflat_configs:
    print(f"\n测试配置: {config['name']}")

    # 删除旧索引
    cursor.execute("DROP INDEX IF EXISTS documents_embedding_idx")
    conn.commit()

    # 创建索引
    print(f"  正在创建索引...")
    start = time.time()
    cursor.execute(f"""
        CREATE INDEX documents_embedding_idx ON documents
        USING ivfflat (embedding vector_cosine_ops)
        WITH (lists = {config['lists']})
    """)
    conn.commit()
    index_build_time = time.time() - start

    # 获取索引大小
    cursor.execute("""
        SELECT pg_size_pretty(pg_relation_size('documents_embedding_idx'))
    """)
    index_size = cursor.fetchone()[0]

    print(f"  ✅ 索引创建完成")
    print(f"  构建时间: {index_build_time:.2f}秒")
    print(f"  索引大小: {index_size}")

    # 测试不同的 probes 值
    # probes 推荐值：lists / 10
    probes_values = [1, int(config['lists'] / 10), int(config['lists'] / 5)]

    for probes in probes_values:
        cursor.execute(f"SET ivfflat.probes = {probes}")

        # 性能测试
        stats = benchmark_query(query_embedding, iterations=10)

        # 验证索引是否生效
        cursor.execute(
            "EXPLAIN SELECT id FROM documents ORDER BY embedding <=> %s LIMIT 10",
            (query_embedding,)
        )
        plan = cursor.fetchall()
        uses_index = any("Index Scan" in line[0] for line in plan)

        ivfflat_results.append({
            "config": config['name'],
            "lists": config['lists'],
            "probes": probes,
            "build_time": index_build_time,
            "index_size": index_size,
            "uses_index": uses_index,
            **stats
        })

        print(f"  probes={probes}: P95={stats['p95']:.2f}ms, 索引生效={uses_index}")

# ===== 5. 性能对比总结 =====
print("\n=== 5. 性能对比总结 ===")

print("\n无索引:")
print(f"  P95 延迟: {stats_no_index['p95']:.2f}ms")

print("\nHNSW 索引:")
for r in hnsw_results:
    print(f"  {r['config']}, ef_search={r['ef_search']}")
    print(f"    P95 延迟: {r['p95']:.2f}ms")
    print(f"    vs 无索引: {stats_no_index['p95'] / r['p95']:.1f}x 提升")

print("\nIVFFlat 索引:")
for r in ivfflat_results:
    print(f"  {r['config']}, probes={r['probes']}")
    print(f"    P95 延迟: {r['p95']:.2f}ms")
    print(f"    vs 无索引: {stats_no_index['p95'] / r['p95']:.1f}x 提升")

# ===== 6. 召回率评估 =====
print("\n=== 6. 召回率评估 ===")

def evaluate_recall(query_embedding: List[float], index_config: str, top_k: int = 10) -> float:
    """评估召回率"""
    # 1. 获取精确结果（无索引，暴力搜索）
    cursor.execute("DROP INDEX IF EXISTS documents_embedding_idx")
    conn.commit()

    cursor.execute(
        "SELECT id FROM documents ORDER BY embedding <=> %s LIMIT %s",
        (query_embedding, top_k)
    )
    ground_truth_ids = set(row[0] for row in cursor.fetchall())

    # 2. 创建索引并获取近似结果
    if "HNSW" in index_config:
        cursor.execute("""
            CREATE INDEX documents_embedding_idx ON documents
            USING hnsw (embedding vector_cosine_ops)
            WITH (m = 16, ef_construction = 64)
        """)
        cursor.execute("SET hnsw.ef_search = 100")
    else:  # IVFFlat
        cursor.execute("""
            CREATE INDEX documents_embedding_idx ON documents
            USING ivfflat (embedding vector_cosine_ops)
            WITH (lists = 32)
        """)
        cursor.execute("SET ivfflat.probes = 3")

    conn.commit()

    cursor.execute(
        "SELECT id FROM documents ORDER BY embedding <=> %s LIMIT %s",
        (query_embedding, top_k)
    )
    approx_ids = set(row[0] for row in cursor.fetchall())

    # 3. 计算召回率
    recall = len(ground_truth_ids & approx_ids) / len(ground_truth_ids)

    return recall

# 测试多个查询的平均召回率
test_queries = [
    "向量数据库的性能优化",
    "HNSW 索引的原理",
    "RAG 系统的架构设计"
]

print("\n召回率评估（Top-10）：")

for index_type in ["HNSW", "IVFFlat"]:
    recalls = []

    for query_text in test_queries:
        q_embedding = client.embeddings.create(
            input=query_text,
            model="text-embedding-3-small"
        ).data[0].embedding

        recall = evaluate_recall(q_embedding, index_type, top_k=10)
        recalls.append(recall)

    avg_recall = np.mean(recalls)
    print(f"  {index_type}: {avg_recall:.2%} (平均)")

# ===== 7. 索引选择建议 =====
print("\n=== 7. 索引选择建议 ===")

print("""
根据测试结果，索引选择建议：

1. **HNSW 索引（推荐）**
   - 适用场景：查询频繁，插入不频繁
   - 优势：查询速度快，召回率高（95-99%）
   - 劣势：构建时间长，内存占用大
   - 推荐配置：m=16, ef_construction=64, ef_search=100

2. **IVFFlat 索引**
   - 适用场景：数据频繁插入/更新
   - 优势：构建速度快，内存占用小
   - 劣势：召回率中等（80-95%），查询速度中等
   - 推荐配置：lists=sqrt(N), probes=lists/10

3. **无索引**
   - 适用场景：数据量小（< 10,000）
   - 优势：无需构建索引，召回率 100%
   - 劣势：查询速度慢（O(N)）

数据规模建议：
- < 10,000 向量：无需索引
- 10,000 - 100,000 向量：IVFFlat 或 HNSW
- 100,000 - 1,000,000 向量：HNSW
- > 1,000,000 向量：考虑专用向量库（Milvus、Pinecone）
""")

# ===== 8. 参数调优建议 =====
print("\n=== 8. 参数调优建议 ===")

print("""
HNSW 参数调优：

1. **m（邻居数）**
   - 默认：16
   - 高召回率：32（内存占用增加 2 倍）
   - 低内存：8（召回率略降）

2. **ef_construction（构建时搜索范围）**
   - 默认：64
   - 高质量索引：128（构建时间增加 2 倍）
   - 快速构建：32（索引质量略降）

3. **ef_search（查询时搜索范围）**
   - 默认：40
   - 平衡：100（推荐）
   - 高召回率：200（延迟增加 2 倍）

IVFFlat 参数调优：

1. **lists（聚类数）**
   - 推荐：sqrt(N)
   - 1,000 向量：32
   - 10,000 向量：100
   - 100,000 向量：316
   - 1,000,000 向量：1000

2. **probes（探测簇数）**
   - 推荐：lists / 10
   - 高召回率：lists / 5（延迟增加 2 倍）
   - 快速查询：1（召回率降低）

调优流程：
1. 从默认参数开始
2. 使用 EXPLAIN ANALYZE 验证索引生效
3. 测试查询延迟和召回率
4. 根据需求调整参数（延迟 vs 召回率权衡）
5. 在生产环境监控性能指标
""")

# ===== 9. 监控和维护 =====
print("\n=== 9. 监控和维护 ===")

# 查看索引统计信息
cursor.execute("""
    SELECT
        schemaname,
        tablename,
        indexname,
        idx_scan AS index_scans,
        idx_tup_read AS tuples_read,
        idx_tup_fetch AS tuples_fetched
    FROM pg_stat_user_indexes
    WHERE tablename = 'documents'
""")

print("\n索引使用统计：")
for row in cursor.fetchall():
    print(f"  索引: {row[2]}")
    print(f"    扫描次数: {row[3]}")
    print(f"    读取元组: {row[4]}")
    print(f"    获取元组: {row[5]}")

# 查看表和索引大小
cursor.execute("""
    SELECT
        pg_size_pretty(pg_total_relation_size('documents')) AS total_size,
        pg_size_pretty(pg_relation_size('documents')) AS table_size,
        pg_size_pretty(pg_total_relation_size('documents') - pg_relation_size('documents')) AS indexes_size
""")

total_size, table_size, indexes_size = cursor.fetchone()
print(f"\n存储统计：")
print(f"  总大小: {total_size}")
print(f"  表大小: {table_size}")
print(f"  索引大小: {indexes_size}")

# ===== 10. 清理资源 =====
print("\n=== 10. 清理资源 ===")

cursor.close()
conn.close()
print("✅ 数据库连接已关闭")

print("\n=== 示例完成 ===")
```

## 运行输出示例

```
=== 1. 准备测试数据 ===
正在生成测试数据...
  生成 Embedding: 1-100/1000
  生成 Embedding: 101-200/1000
  ...
  生成 Embedding: 901-1000/1000
✅ 已插入 1000 条测试数据

=== 2. 无索引性能测试（基准）===

查询计划（无索引）：
  Seq Scan on documents  (cost=0.00..1234.56 rows=10 width=4) (actual time=45.123..89.456 rows=10 loops=1)
  Planning Time: 0.123 ms
  Execution Time: 89.567 ms

无索引性能（10次平均）：
  平均: 87.34ms
  P50: 86.12ms
  P95: 92.45ms
  P99: 95.67ms

=== 3. 创建 HNSW 索引 ===

测试配置: HNSW (m=16, ef=64) [默认]
  正在创建索引...
  ✅ 索引创建完成
  构建时间: 3.45秒
  索引大小: 2048 kB
  ef_search=40: P95=8.23ms, 索引生效=True
  ef_search=100: P95=12.34ms, 索引生效=True
  ef_search=200: P95=18.56ms, 索引生效=True

=== 4. 创建 IVFFlat 索引 ===

测试配置: IVFFlat (lists=32) [推荐]
  正在创建索引...
  ✅ 索引创建完成
  构建时间: 0.89秒
  索引大小: 1024 kB
  probes=1: P95=15.67ms, 索引生效=True
  probes=3: P95=22.34ms, 索引生效=True
  probes=6: P95=32.45ms, 索引生效=True

=== 5. 性能对比总结 ===

无索引:
  P95 延迟: 92.45ms

HNSW 索引:
  HNSW (m=16, ef=64) [默认], ef_search=40
    P95 延迟: 8.23ms
    vs 无索引: 11.2x 提升
  HNSW (m=16, ef=64) [默认], ef_search=100
    P95 延迟: 12.34ms
    vs 无索引: 7.5x 提升

IVFFlat 索引:
  IVFFlat (lists=32) [推荐], probes=3
    P95 延迟: 22.34ms
    vs 无索引: 4.1x 提升

=== 6. 召回率评估 ===

召回率评估（Top-10）：
  HNSW: 96.67% (平均)
  IVFFlat: 86.67% (平均)

=== 9. 监控和维护 ===

索引使用统计：
  索引: documents_embedding_idx
    扫描次数: 150
    读取元组: 1500
    获取元组: 1500

存储统计：
  总大小: 3072 kB
  表大小: 2048 kB
  索引大小: 1024 kB

=== 示例完成 ===
```

## 代码说明

### 1. 性能基准测试

```python
def benchmark_query(query_embedding, iterations=10):
    times = []
    for _ in range(iterations):
        start = time.time()
        cursor.execute("SELECT id FROM documents ORDER BY embedding <=> %s LIMIT 10", (query_embedding,))
        cursor.fetchall()
        times.append((time.time() - start) * 1000)

    return {
        "avg": np.mean(times),
        "p95": np.percentile(times, 95)
    }
```

### 2. 索引创建

```python
# HNSW
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64)

# IVFFlat
CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 32)
```

### 3. 召回率评估

```python
def evaluate_recall(query_embedding, index_config, top_k=10):
    # 1. 精确结果（无索引）
    ground_truth_ids = get_exact_results()

    # 2. 近似结果（有索引）
    approx_ids = get_approx_results()

    # 3. 计算召回率
    recall = len(ground_truth_ids & approx_ids) / len(ground_truth_ids)
    return recall
```

## 常见问题

### Q1: 如何选择索引类型？

**决策树：**
```
数据量 < 10,000？
  └─ 是 → 无需索引

查询频繁 且 插入不频繁？
  └─ 是 → HNSW
  └─ 否 → IVFFlat

对召回率要求 > 95%？
  └─ 是 → HNSW
  └─ 否 → IVFFlat

内存充足？
  └─ 是 → HNSW
  └─ 否 → IVFFlat
```

### Q2: 索引参数如何调优？

```python
# HNSW 调优流程
1. 从默认参数开始：m=16, ef_construction=64, ef_search=40
2. 测试查询延迟和召回率
3. 如果召回率不足：增加 ef_search（100 → 200）
4. 如果延迟过高：减小 ef_search（100 → 40）
5. 如果内存不足：减小 m（16 → 8）

# IVFFlat 调优流程
1. 设置 lists = sqrt(N)
2. 设置 probes = lists / 10
3. 测试查询延迟和召回率
4. 如果召回率不足：增加 probes
5. 如果延迟过高：减小 probes
```

### Q3: 如何监控索引性能？

```sql
-- 1. 查看索引使用情况
SELECT * FROM pg_stat_user_indexes WHERE tablename = 'documents';

-- 2. 查看索引大小
SELECT pg_size_pretty(pg_relation_size('documents_embedding_idx'));

-- 3. 验证索引是否生效
EXPLAIN ANALYZE SELECT * FROM documents ORDER BY embedding <=> '[...]' LIMIT 10;

-- 4. 查看查询统计
SELECT * FROM pg_stat_statements WHERE query LIKE '%embedding%';
```

### Q4: 何时需要重建索引？

```python
# 重建索引的场景：
1. 数据量增长 10 倍以上
2. 查询性能明显下降
3. 索引参数需要调整
4. 数据分布发生变化

# 重建索引
DROP INDEX documents_embedding_idx;
CREATE INDEX documents_embedding_idx ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

## 总结

**索引优化的核心要点：**
1. **HNSW**：查询快、召回率高，适合查询频繁的场景
2. **IVFFlat**：构建快、内存小，适合插入频繁的场景
3. **参数调优**：根据延迟和召回率权衡选择参数
4. **性能监控**：定期检查索引使用情况和查询性能

**实战建议：**
- 从默认参数开始，逐步调优
- 使用 EXPLAIN ANALYZE 验证索引效果
- 在测试环境充分测试后再上生产
- 定期监控性能指标，及时调整
