# 第一性原理：Prompt Engineering进阶

## 核心问题

**为什么基础Prompt技术不够用？**

从第一性原理思考：大模型的本质是什么？

```
大模型 = 概率分布预测器
      ≠ 知识库
      ≠ 推理引擎
      ≠ 任务执行器
```

**基础Prompt的局限：**

```python
# 基础方法：单次预测
prompt = "分析这段代码的性能问题"
response = model.predict(prompt)  # 一次性输出

# 问题：
# 1. 没有推理过程 → 无法验证
# 2. 没有自我纠错 → 容易出错
# 3. 没有工具调用 → 无法完成复杂任务
```

**进阶方法的本质：**

```python
# 进阶方法：多步推理 + 验证
responses = []
for step in reasoning_steps:
    response = model.predict(step)
    if verify(response):
        responses.append(response)
    else:
        # 回溯或重试
        continue

final_answer = synthesize(responses)
```

---

## 第一性原理 1：推理链外化

### 原理

**大模型的内部推理是黑盒，必须外化才能验证和优化。**

### 为什么？

```
传统方法：
输入 → [黑盒推理] → 输出
      ↑
      无法观察、验证、优化

进阶方法：
输入 → 步骤1 → 步骤2 → 步骤3 → 输出
      ↓       ↓       ↓
      可观察  可验证  可优化
```

### 实现方式

**Chain-of-Thought (CoT)：**

```python
# 基础版：直接提问
prompt = "23 * 47 = ?"
# 输出：1081（可能错误，无法验证）

# CoT版：要求推理过程
prompt = """
计算 23 * 47

让我们一步步计算：
1. 先算 23 * 40
2. 再算 23 * 7
3. 最后相加
"""
# 输出：
# 1. 23 * 40 = 920
# 2. 23 * 7 = 161
# 3. 920 + 161 = 1081
# （可以验证每一步）
```

**RAG应用：**

```python
# 基础RAG：直接回答
prompt = f"""
文档：{docs}
问题：{query}
答案：
"""

# CoT RAG：推理过程
prompt = f"""
文档：{docs}
问题：{query}

请按以下步骤回答：
1. 分析问题的核心意图
2. 找出相关的文档片段
3. 综合信息得出答案
4. 说明答案的依据

让我们一步步思考：
"""
```

**来源：** [Chain-of-Thought Prompting (2022)](https://arxiv.org/abs/2201.11903)

---

## 第一性原理 2：多路径验证

### 原理

**单次预测不可靠，多次预测投票可以提升可靠性。**

### 为什么？

大模型的输出是概率分布：

```
P(输出|输入) = 概率分布

单次采样：可能采样到低概率但错误的答案
多次采样：高概率的正确答案会更频繁出现
```

**数学基础：**

```
准确率(单次) = p
准确率(多次投票) = 1 - (1-p)^n

例如：
p = 0.7 (单次70%准确)
n = 5 (5次投票)
准确率 = 1 - (1-0.7)^5 = 1 - 0.00243 = 99.76%
```

### 实现方式

**Self-Consistency：**

```python
# 生成多个推理路径
answers = []
for i in range(5):
    response = model.generate(prompt, temperature=0.7)
    answers.append(extract_answer(response))

# 投票选择最常见的答案
from collections import Counter
final_answer = Counter(answers).most_common(1)[0][0]
```

**RAG应用：**

```python
# 对关键问题多次检索+生成
results = []
for i in range(3):
    # 每次使用不同的检索策略
    docs = retriever.search(query, strategy=strategies[i])
    answer = llm.generate(f"文档：{docs}\n问题：{query}")
    results.append(answer)

# 选择最一致的答案
final_answer = vote(results)
```

**来源：** [Self-Consistency Improves Chain of Thought Reasoning (2022)](https://arxiv.org/abs/2203.11171)

---

## 第一性原理 3：搜索空间探索

### 原理

**复杂问题需要探索多条推理路径，而非线性推理。**

### 为什么？

```
线性推理（CoT）：
A → B → C → D
    ↑
    如果B错了，整个链条失败

树状探索（ToT）：
    A
   /|\
  B C D
 /| |\ |\
E F G H I J
    ↑
    可以探索多条路径，选择最优
```

**类比：**
- CoT = 走一条路到终点
- ToT = 探索多条路，选最短的

### 实现方式

**Tree of Thoughts：**

```python
class ThoughtTree:
    def __init__(self, root_problem):
        self.root = root_problem
        self.branches = []

    def explore(self, depth=3, breadth=3):
        # 从根节点开始
        current_nodes = [self.root]

        for level in range(depth):
            next_nodes = []
            for node in current_nodes:
                # 为每个节点生成多个子思路
                thoughts = model.generate_thoughts(node, n=breadth)
                # 评估每个思路
                scored_thoughts = [(evaluate(t), t) for t in thoughts]
                # 保留最好的
                best_thoughts = sorted(scored_thoughts, reverse=True)[:breadth]
                next_nodes.extend([t for _, t in best_thoughts])

            current_nodes = next_nodes

        # 返回最优路径
        return max(current_nodes, key=evaluate)
```

**RAG应用：**

```python
# 探索多种检索策略
strategies = [
    "直接语义检索",
    "关键词提取后检索",
    "问题改写后检索",
    "分解为子问题后检索"
]

results = {}
for strategy in strategies:
    docs = execute_strategy(strategy, query)
    answer = llm.generate(f"文档：{docs}\n问题：{query}")
    score = evaluate_answer(answer, query)
    results[strategy] = (score, answer)

# 选择得分最高的策略
best_strategy, (score, answer) = max(results.items(), key=lambda x: x[1][0])
```

**来源：** [Tree of Thoughts (2023)](https://arxiv.org/abs/2305.10601)

---

## 第一性原理 4：推理与行动交替

### 原理

**复杂任务需要推理（思考）与行动（工具调用）交替进行。**

### 为什么？

```
纯推理：
思考 → 思考 → 思考 → 答案
      ↑
      信息不足时无法继续

推理+行动：
思考 → 行动（获取信息）→ 思考 → 行动 → 答案
      ↑                    ↑
      可以动态获取所需信息
```

**类比：**
- 纯推理 = 闭卷考试（只能用已有知识）
- ReAct = 开卷考试（可以查资料）

### 实现方式

**ReAct框架：**

```python
def react_loop(query, max_steps=5):
    context = ""

    for step in range(max_steps):
        # Thought: 推理当前状态
        thought = llm.generate(f"""
        任务：{query}
        当前信息：{context}

        思考：下一步应该做什么？
        """)

        if "任务完成" in thought:
            break

        # Action: 执行工具调用
        action = extract_action(thought)
        observation = execute_action(action)

        # 更新上下文
        context += f"\n观察：{observation}"

    # 最终答案
    answer = llm.generate(f"""
    任务：{query}
    完整信息：{context}

    最终答案：
    """)

    return answer
```

**RAG应用：**

```python
def dynamic_rag(query):
    context = initial_retrieval(query)

    while not is_sufficient(context, query):
        # 推理：分析缺少什么信息
        thought = llm.generate(f"""
        问题：{query}
        当前信息：{context}

        还需要什么信息？
        """)

        # 行动：检索新信息
        new_query = extract_query(thought)
        new_docs = retriever.search(new_query)
        context += new_docs

    # 生成最终答案
    return llm.generate(f"基于{context}回答{query}")
```

**来源：** [ReAct: Synergizing Reasoning and Acting (2022)](https://arxiv.org/abs/2210.03629)

---

## 第一性原理 5：结构化约束

### 原理

**自然语言输出不可靠，必须通过结构化约束确保可解析。**

### 为什么？

```
自然语言输出：
"用户名是张三，年龄大概30岁左右"
      ↑
      难以解析，格式不统一

结构化输出：
{"name": "张三", "age": 30}
      ↑
      易于解析，格式统一
```

**问题场景：**

```python
# 基础方法：自然语言输出
response = llm.generate("提取文档中的人名、地名、时间")
# 输出："文档中提到了张三，在北京，时间是2024年"
# 问题：如何解析？正则表达式？不可靠！

# 进阶方法：强制JSON输出
response = llm.generate(
    "提取文档中的人名、地名、时间",
    response_format={"type": "json_object"}
)
# 输出：{"person": "张三", "location": "北京", "time": "2024年"}
# 优势：直接json.loads()解析
```

### 实现方式

**Structured Output (OpenAI)：**

```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4o-2024-08-06",
    messages=[
        {"role": "system", "content": "提取文档信息"},
        {"role": "user", "content": document}
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "document_info",
            "schema": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "author": {"type": "string"},
                    "date": {"type": "string"},
                    "keywords": {
                        "type": "array",
                        "items": {"type": "string"}
                    }
                },
                "required": ["title", "author"]
            }
        }
    }
)

# 保证输出符合schema
data = json.loads(response.choices[0].message.content)
```

**RAG应用：**

```python
# 结构化检索结果
retrieval_result = llm.generate(
    f"从文档中提取与'{query}'相关的信息",
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "retrieval_result",
            "schema": {
                "type": "object",
                "properties": {
                    "relevant_chunks": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "content": {"type": "string"},
                                "relevance_score": {"type": "number"},
                                "reason": {"type": "string"}
                            }
                        }
                    },
                    "answer": {"type": "string"},
                    "confidence": {"type": "number"}
                }
            }
        }
    }
)
```

**来源：** [OpenAI Structured Outputs (2024)](https://openai.com/index/introducing-structured-outputs-in-the-api/)

---

## 第一性原理 6：动态检索迭代

### 原理

**静态检索（一次性）不足以处理复杂查询，需要动态迭代检索。**

### 为什么？

```
静态RAG：
查询 → 检索 → 生成 → 答案
      ↑
      如果检索结果不足，无法补救

动态RAG：
查询 → 检索 → 生成 → 评估 → 补充检索 → 生成 → 答案
              ↑                ↑
              可以迭代优化
```

**问题场景：**

```python
# 静态RAG
query = "比较Python和JavaScript的异步编程差异"
docs = retriever.search(query, top_k=5)
answer = llm.generate(f"文档：{docs}\n问题：{query}")
# 问题：如果检索到的文档只讲了Python，没有JavaScript怎么办？

# 动态RAG (RAT)
query = "比较Python和JavaScript的异步编程差异"
docs = retriever.search(query, top_k=5)

# 第一次生成
answer = llm.generate(f"文档：{docs}\n问题：{query}")

# 评估：是否需要更多信息？
evaluation = llm.generate(f"""
当前答案：{answer}
问题：{query}

是否需要更多信息？如果需要，需要什么信息？
""")

if "需要" in evaluation:
    # 补充检索
    new_query = extract_query(evaluation)
    new_docs = retriever.search(new_query)
    # 重新生成
    answer = llm.generate(f"文档：{docs + new_docs}\n问题：{query}")
```

### 实现方式

**RAT (Retrieval Augmented Thoughts)：**

```python
def rat_pipeline(query, max_iterations=3):
    context = []

    for iteration in range(max_iterations):
        # 检索
        docs = retriever.search(query, context=context)
        context.extend(docs)

        # 推理
        thought = llm.generate(f"""
        问题：{query}
        当前信息：{context}

        分析：
        1. 当前信息是否足够回答问题？
        2. 如果不够，还需要什么信息？
        """)

        if "足够" in thought:
            break

        # 提取新的检索需求
        new_query = extract_need(thought)
        query = new_query  # 更新查询

    # 最终答案
    answer = llm.generate(f"""
    问题：{query}
    完整信息：{context}

    综合以上信息，给出答案：
    """)

    return answer
```

**来源：** [Retrieval Augmented Thoughts (2024)](https://arxiv.org/abs/2403.05313)

---

## 第一性原理 7：示例智能选择

### 原理

**Few-shot示例的质量比数量更重要，应该动态选择最相关的示例。**

### 为什么？

```
固定示例：
示例1、示例2、示例3 → 对所有查询都一样
      ↑
      可能不相关，浪费token

动态示例：
查询 → 选择最相关的示例 → 示例A、示例B → 更好的效果
      ↑
      每个查询都有最优示例
```

**效果对比：**

```python
# 固定示例（不相关）
prompt = """
示例1：计算1+1=2
示例2：计算2+2=4

现在计算：求解方程 x^2 + 2x + 1 = 0
"""
# 效果差：示例与任务不相关

# 动态示例（相关）
prompt = """
示例1：求解 x^2 - 5x + 6 = 0
解：(x-2)(x-3)=0，所以x=2或x=3

示例2：求解 x^2 + 4x + 4 = 0
解：(x+2)^2=0，所以x=-2

现在计算：求解方程 x^2 + 2x + 1 = 0
"""
# 效果好：示例与任务高度相关
```

### 实现方式

**Active Prompting：**

```python
def active_prompting(query, example_pool):
    # 1. 计算查询与所有示例的相似度
    similarities = []
    for example in example_pool:
        sim = compute_similarity(query, example['query'])
        similarities.append((sim, example))

    # 2. 选择最相似的k个示例
    top_k = 3
    selected_examples = sorted(similarities, reverse=True)[:top_k]

    # 3. 构建Few-shot提示
    prompt = "以下是一些示例：\n\n"
    for _, example in selected_examples:
        prompt += f"问题：{example['query']}\n"
        prompt += f"答案：{example['answer']}\n\n"

    prompt += f"现在回答：{query}\n答案："

    return llm.generate(prompt)
```

**RAG应用：**

```python
# 为不同类型的查询选择不同的示例
query_type = classify_query(query)  # "事实查询"、"推理查询"、"比较查询"

# 从示例库中选择相同类型的示例
relevant_examples = [
    ex for ex in example_pool
    if ex['type'] == query_type
]

# 选择最相似的3个
selected = select_top_k(query, relevant_examples, k=3)

# 构建提示
prompt = build_few_shot_prompt(selected, query)
```

**来源：** [Active Prompting (2023)](https://arxiv.org/abs/2302.12246)

---

## 统一框架

所有进阶技术都基于以下统一框架：

```
输入
 ↓
[推理链外化] ← 让推理过程可见
 ↓
[多路径验证] ← 提升可靠性
 ↓
[搜索空间探索] ← 探索多种可能
 ↓
[推理与行动交替] ← 动态获取信息
 ↓
[结构化约束] ← 确保输出可解析
 ↓
[动态检索迭代] ← 持续优化（RAG专用）
 ↓
[示例智能选择] ← 提升Few-shot效果
 ↓
输出
```

---

## 技术选择决策树

```
任务类型？
├─ 简单问答
│  └─ Few-shot + Structured Output
│
├─ 复杂推理
│  ├─ 需要验证？
│  │  ├─ 是 → CoT + Self-Consistency
│  │  └─ 否 → CoT
│  │
│  └─ 需要探索多种可能？
│     └─ 是 → Tree of Thoughts
│
├─ 需要工具调用
│  └─ ReAct
│
└─ RAG任务
   ├─ 简单查询 → Query Decomposition
   ├─ 复杂查询 → RAT (动态迭代)
   └─ 需要示例 → Active Prompting
```

---

## 核心洞察

1. **推理过程比结果更重要**
   - 可见的推理过程可以验证和优化
   - 黑盒输出无法改进

2. **单次预测不可靠**
   - 多次预测投票可以显著提升准确率
   - 探索多条路径可以找到最优解

3. **静态方法有局限**
   - 动态调整策略更适合复杂任务
   - 迭代优化优于一次性生成

4. **结构化是必需的**
   - 自然语言输出难以被程序处理
   - 强制结构化可以确保可靠性

5. **示例质量>数量**
   - 相关的3个示例优于不相关的10个
   - 动态选择示例可以提升效果

---

## 参考文献

1. [Chain-of-Thought Prompting (2022)](https://arxiv.org/abs/2201.11903)
2. [Self-Consistency (2022)](https://arxiv.org/abs/2203.11171)
3. [Tree of Thoughts (2023)](https://arxiv.org/abs/2305.10601)
4. [ReAct (2022)](https://arxiv.org/abs/2210.03629)
5. [Retrieval Augmented Thoughts (2024)](https://arxiv.org/abs/2403.05313)
6. [Active Prompting (2023)](https://arxiv.org/abs/2302.12246)
7. [OpenAI Structured Outputs (2024)](https://openai.com/index/introducing-structured-outputs-in-the-api/)

---

**下一步：** 阅读 `03_核心概念_XX.md` 深入学习每个技术的实现细节
