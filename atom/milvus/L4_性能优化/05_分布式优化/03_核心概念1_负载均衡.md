# 核心概念1：负载均衡策略

## 什么是负载均衡？

**负载均衡**是将工作负载（查询请求、数据分片）均匀分配到多个节点，避免某些节点过载而其他节点空闲的技术。

在 Milvus 分布式集群中，负载均衡发生在两个层面：
1. **查询路由**：将查询请求分配到不同的 QueryNode
2. **Segment 分配**：将数据分片（Segment）分配到不同的 QueryNode

---

## 1. 查询路由（Query Routing）

### 1.1 工作原理

```
客户端查询
    ↓
Proxy（接收请求）
    ↓
QueryCoord（查询负载信息）
    ↓
选择负载最低的 QueryNode
    ↓
发送查询请求
    ↓
返回结果
```

### 1.2 负载评估指标

Milvus 根据以下指标评估 QueryNode 的负载：

| 指标 | 权重 | 说明 |
|------|------|------|
| CPU 使用率 | 30% | 当前 CPU 占用百分比 |
| 内存使用率 | 40% | 当前内存占用百分比 |
| 查询队列长度 | 20% | 等待处理的查询数量 |
| 网络带宽 | 10% | 当前网络流量 |

**负载分数计算公式**：
```
负载分数 = CPU使用率 × 0.3 + 内存使用率 × 0.4 + 队列长度 × 0.2 + 网络带宽 × 0.1

负载分数越低，节点越空闲
```

### 1.3 路由策略

Milvus 支持多种路由策略：

#### 策略1：最少负载优先（默认）

```python
# 伪代码
def select_query_node(query_nodes):
    min_load = float('inf')
    selected_node = None

    for node in query_nodes:
        load = calculate_load(node)
        if load < min_load:
            min_load = load
            selected_node = node

    return selected_node
```

**优点**：
- 自动避免热点节点
- 适应动态负载变化

**缺点**：
- 需要实时监控负载
- 有一定的协调开销

#### 策略2：轮询（Round Robin）

```python
# 伪代码
current_index = 0

def select_query_node(query_nodes):
    global current_index
    node = query_nodes[current_index]
    current_index = (current_index + 1) % len(query_nodes)
    return node
```

**优点**：
- 实现简单
- 无协调开销

**缺点**：
- 不考虑节点实际负载
- 可能导致负载不均

#### 策略3：加权轮询

```python
# 伪代码
def select_query_node(query_nodes):
    # 根据节点性能分配权重
    weights = {
        'node1': 3,  # 高性能节点
        'node2': 2,  # 中等性能节点
        'node3': 1   # 低性能节点
    }

    # 按权重选择节点
    return weighted_random_choice(query_nodes, weights)
```

**优点**：
- 考虑节点性能差异
- 适合异构集群

**缺点**：
- 需要手动配置权重
- 不适应动态负载

### 1.4 实际配置

```yaml
# milvus.yaml
proxy:
  # 查询路由策略
  queryNodeSelector: "least_load"  # 最少负载优先（推荐）
  # queryNodeSelector: "round_robin"  # 轮询

  # 负载更新间隔（秒）
  loadBalanceInterval: 5

  # 负载阈值（超过此值认为节点过载）
  overloadThreshold: 0.9
```

### 1.5 Python 代码示例

```python
from pymilvus import Collection, connections
import time

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("load_balance_demo")
collection.load()

# 并发查询测试
import concurrent.futures

def query_task(task_id):
    start = time.time()
    results = collection.search(
        data=[[0.1] * 128],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10
    )
    elapsed = time.time() - start
    print(f"任务 {task_id}: {elapsed*1000:.1f}ms")
    return elapsed

# 启动 100 个并发查询
with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
    futures = [executor.submit(query_task, i) for i in range(100)]
    results = [f.result() for f in futures]

# 分析延迟分布
import statistics
print(f"平均延迟: {statistics.mean(results)*1000:.1f}ms")
print(f"P95 延迟: {statistics.quantiles(results, n=20)[18]*1000:.1f}ms")
print(f"P99 延迟: {statistics.quantiles(results, n=100)[98]*1000:.1f}ms")

# 如果负载均衡生效，延迟应该比较稳定
# 如果某些查询特别慢，说明存在热点节点
```

---

## 2. Segment 分配（Segment Assignment）

### 2.1 一致性哈希原理

Milvus 使用**一致性哈希**将 Segment 分配到 QueryNode。

**传统哈希的问题**：
```python
# 传统哈希
node_id = hash(segment_id) % num_nodes

# 问题：当节点数变化时，几乎所有 Segment 都需要重新分配
# 例如：3 个节点 → 4 个节点，75% 的 Segment 需要迁移
```

**一致性哈希的优势**：
```python
# 一致性哈希
# 1. 将节点和 Segment 都映射到一个环上（0 - 2^32）
# 2. Segment 顺时针找到最近的节点

# 优势：当节点数变化时，只有少量 Segment 需要迁移
# 例如：3 个节点 → 4 个节点，只有 25% 的 Segment 需要迁移
```

### 2.2 虚拟节点

为了让 Segment 分布更均匀，Milvus 为每个物理节点创建多个虚拟节点。

```python
# 伪代码
class ConsistentHash:
    def __init__(self, nodes, virtual_nodes=100):
        self.ring = {}

        # 为每个物理节点创建 100 个虚拟节点
        for node in nodes:
            for i in range(virtual_nodes):
                virtual_node_id = f"{node}-{i}"
                hash_value = hash(virtual_node_id)
                self.ring[hash_value] = node

        # 排序哈希环
        self.sorted_keys = sorted(self.ring.keys())

    def get_node(self, segment_id):
        # 计算 Segment 的哈希值
        segment_hash = hash(segment_id)

        # 顺时针找到第一个节点
        for key in self.sorted_keys:
            if segment_hash <= key:
                return self.ring[key]

        # 如果没找到，返回第一个节点（环形）
        return self.ring[self.sorted_keys[0]]

# 使用
ch = ConsistentHash(['node1', 'node2', 'node3'])
print(ch.get_node('segment_1'))  # node2
print(ch.get_node('segment_2'))  # node1
print(ch.get_node('segment_3'))  # node3
```

**虚拟节点的作用**：
- 让 Segment 分布更均匀
- 避免某些节点分配到过多 Segment

**示例**：
```
3 个物理节点，每个 100 个虚拟节点
→ 哈希环上有 300 个虚拟节点
→ Segment 分布更均匀

如果没有虚拟节点：
→ 哈希环上只有 3 个节点
→ 可能某个节点分配到 60% 的 Segment
```

### 2.3 动态负载均衡

QueryCoord 会定期检查负载均衡（默认每 60 秒）：

```python
# 伪代码
def check_load_balance():
    while True:
        time.sleep(60)  # 每 60 秒检查一次

        # 1. 收集所有 QueryNode 的负载信息
        nodes_load = {}
        for node in query_nodes:
            nodes_load[node] = {
                'memory_usage': get_memory_usage(node),
                'cpu_usage': get_cpu_usage(node),
                'segment_count': get_segment_count(node)
            }

        # 2. 识别过载节点
        overloaded_nodes = []
        for node, load in nodes_load.items():
            if load['memory_usage'] > 0.9:  # 内存使用超过 90%
                overloaded_nodes.append(node)

        # 3. 迁移 Segment
        for node in overloaded_nodes:
            # 选择负载最低的节点
            target_node = min(nodes_load, key=lambda n: nodes_load[n]['memory_usage'])

            # 迁移部分 Segment
            segments_to_move = select_segments_to_move(node, target_node)
            for segment in segments_to_move:
                move_segment(segment, node, target_node)
```

### 2.4 Segment 迁移流程

```
1. 在目标节点加载 Segment
   ↓
2. 等待加载完成
   ↓
3. 更新路由信息（新查询发送到目标节点）
   ↓
4. 等待源节点的查询完成
   ↓
5. 从源节点释放 Segment
   ↓
6. 迁移完成
```

**关键点**：
- 迁移过程中，查询不会中断
- 先加载再释放，保证服务可用性

### 2.5 实际配置

```yaml
# milvus.yaml
queryCoord:
  # 负载均衡检查间隔（秒）
  balanceIntervalSeconds: 60

  # 内存使用超过此阈值触发均衡
  overloadedMemoryThresholdPercentage: 90

  # Segment 迁移并发数
  balanceConcurrency: 2

  # 是否启用自动负载均衡
  autoBalance: true
```

### 2.6 Python 代码示例

```python
from pymilvus import Collection, connections, utility
import time

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("segment_balance_demo")

# 查看 Segment 分布
def show_segment_distribution():
    # 获取 Collection 的统计信息
    stats = collection.get_stats()
    print(f"总 Segment 数: {stats['row_count']}")

    # 在生产环境中，可以通过 Milvus 的 metrics 接口查看详细分布
    # http://localhost:9091/metrics
    # 搜索 milvus_querynode_segment_num 指标

# 触发手动负载均衡（需要管理员权限）
def trigger_manual_balance():
    # Milvus 会自动进行负载均衡
    # 如果需要手动触发，可以通过 API 调用
    # utility.load_balance(collection_name="segment_balance_demo")
    pass

# 监控负载均衡效果
def monitor_balance():
    while True:
        show_segment_distribution()
        time.sleep(60)

# 运行监控
# monitor_balance()
```

---

## 3. 热点数据处理

### 3.1 什么是热点数据？

**热点数据**：被频繁查询的 Segment

**问题**：
- 热点 Segment 所在的 QueryNode 负载过高
- 其他 QueryNode 空闲
- 整体吞吐量受限于热点节点

### 3.2 热点数据复制

Milvus 可以将热点 Segment 复制到多个节点：

```python
# 伪代码
def handle_hot_segment(segment_id):
    # 1. 识别热点 Segment
    if query_count(segment_id) > threshold:
        # 2. 复制到其他节点
        target_nodes = select_idle_nodes(2)  # 复制到 2 个节点
        for node in target_nodes:
            replicate_segment(segment_id, node)

        # 3. 更新路由信息
        # 查询时，在多个副本中选择负载最低的节点
```

**效果**：
- 热点查询分散到多个节点
- 吞吐量提升 2-3 倍

### 3.3 实际配置

```yaml
# milvus.yaml
queryCoord:
  # 启用热点数据复制
  enableReplica: true

  # 热点阈值（查询次数/分钟）
  hotSegmentThreshold: 1000

  # 热点 Segment 的副本数
  hotSegmentReplicaNum: 2
```

### 3.4 Python 代码示例

```python
from pymilvus import Collection, connections

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("hot_data_demo")

# 加载 Collection 时指定副本数
collection.load(replica_number=2)

# 查询时，Milvus 自动选择负载最低的副本
results = collection.search(
    data=[[0.1] * 128],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10
)

# 如果某些 Segment 是热点数据，Milvus 会自动复制到多个节点
# 查询时，在多个副本中选择负载最低的节点
```

---

## 4. 负载均衡的监控指标

### 4.1 关键指标

| 指标 | 说明 | 目标值 |
|------|------|--------|
| `milvus_querynode_load_balance_latency` | 负载均衡延迟 | < 100ms |
| `milvus_querynode_segment_num` | 每个节点的 Segment 数量 | 均衡分布 |
| `milvus_querynode_memory_usage` | 每个节点的内存使用率 | < 80% |
| `milvus_querynode_cpu_usage` | 每个节点的 CPU 使用率 | < 70% |
| `milvus_querynode_query_latency` | 查询延迟 | P99 < 100ms |

### 4.2 监控示例

```python
# 通过 Prometheus 查询监控指标
import requests

# Milvus metrics 端点
metrics_url = "http://localhost:9091/metrics"

response = requests.get(metrics_url)
metrics = response.text

# 解析关键指标
for line in metrics.split('\n'):
    if 'milvus_querynode_segment_num' in line:
        print(line)
    if 'milvus_querynode_memory_usage' in line:
        print(line)

# 示例输出：
# milvus_querynode_segment_num{node_id="1"} 150
# milvus_querynode_segment_num{node_id="2"} 145
# milvus_querynode_segment_num{node_id="3"} 155
# → Segment 分布比较均衡

# milvus_querynode_memory_usage{node_id="1"} 0.75
# milvus_querynode_memory_usage{node_id="2"} 0.72
# milvus_querynode_memory_usage{node_id="3"} 0.78
# → 内存使用比较均衡
```

---

## 5. 负载均衡的最佳实践

### 5.1 选择合适的路由策略

| 场景 | 推荐策略 | 理由 |
|------|----------|------|
| 同构集群（节点性能相同） | 最少负载优先 | 自动适应动态负载 |
| 异构集群（节点性能不同） | 加权轮询 | 考虑节点性能差异 |
| 低延迟要求（< 10ms） | 轮询 | 避免负载查询开销 |

### 5.2 调整负载均衡参数

```yaml
# 高负载场景（> 10000 QPS）
queryCoord:
  balanceIntervalSeconds: 30  # 缩短均衡周期
  overloadedMemoryThresholdPercentage: 85  # 降低过载阈值

# 低负载场景（< 1000 QPS）
queryCoord:
  balanceIntervalSeconds: 120  # 延长均衡周期
  overloadedMemoryThresholdPercentage: 95  # 提高过载阈值
```

### 5.3 处理热点数据

```python
# 1. 识别热点数据
# 通过监控查询日志，找出被频繁查询的 Segment

# 2. 增加副本数
collection.load(replica_number=3)  # 热点数据场景

# 3. 使用分区
# 将热点数据放到单独的分区，增加该分区的副本数
collection.create_partition("hot_data")
collection.load(partition_names=["hot_data"], replica_number=3)
```

### 5.4 避免负载倾斜

```python
# 1. 合理设计分片键
# 避免某些分片的数据量过大

# 2. 定期 Compaction
# 合并小 Segment，避免 Segment 数量过多
collection.compact()

# 3. 监控 Segment 大小分布
# 确保 Segment 大小相近（目标：每个 Segment 512MB - 1GB）
```

---

## 6. 在 RAG 系统中的应用

### 6.1 文档检索场景

**需求**：
- 1 亿篇文档
- 1000 并发用户
- P99 延迟 < 100ms

**负载均衡策略**：
```yaml
# milvus.yaml
proxy:
  queryNodeSelector: "least_load"  # 最少负载优先

queryCoord:
  balanceIntervalSeconds: 30  # 30 秒检查一次
  overloadedMemoryThresholdPercentage: 85  # 85% 触发均衡
  enableReplica: true  # 启用热点数据复制
  hotSegmentThreshold: 500  # 每分钟 500 次查询视为热点
```

### 6.2 实时推荐场景

**需求**：
- 1000 万用户画像
- 10000 QPS
- P99 延迟 < 50ms

**负载均衡策略**：
```yaml
# milvus.yaml
proxy:
  queryNodeSelector: "round_robin"  # 轮询（低延迟）

queryCoord:
  balanceIntervalSeconds: 60  # 60 秒检查一次
  overloadedMemoryThresholdPercentage: 90  # 90% 触发均衡
```

---

## 总结

**负载均衡的核心要点**：

1. **两个层面**：查询路由 + Segment 分配
2. **一致性哈希**：最小化数据迁移
3. **动态均衡**：定期检查并调整
4. **热点处理**：复制热点数据到多个节点
5. **监控优化**：持续监控并调整参数

**记住**：负载均衡不是一次性配置，而是持续优化的过程。
