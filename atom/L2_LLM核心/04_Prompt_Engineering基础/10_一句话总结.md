# 一句话总结

**RAG Prompt 是通过系统提示词、上下文注入和用户问题模板三个组件，让 LLM 基于检索到的外部文档回答问题的指令设计，是控制 RAG 系统输出质量、防止幻觉、确保回答可追溯的关键技术。**

---

## 核心要点回顾

```
RAG Prompt = 系统提示词 + 上下文注入 + 用户问题模板
              ↓            ↓            ↓
           角色+约束     检索结果      格式化问题
              ↓            ↓            ↓
           控制行为     提供信息      明确任务
```

---

## 记住这三点

1. **系统提示词**：告诉 LLM "你是谁、只能用我给的内容、不能编造"
2. **上下文注入**：把检索结果结构化地放进去，带编号和来源
3. **边界处理**：明确告诉 LLM 找不到答案时怎么回复

---

## 最小可用模板

```python
SYSTEM = "你是问答助手。只基于文档回答，无法回答时说明。"
USER = f"文档：{docs}\n\n问题：{query}"
```

---

## 学习检查清单

- [ ] 理解 RAG Prompt 的三个组成部分
- [ ] 能写出基本的系统提示词（角色+约束+边界）
- [ ] 能格式化注入检索到的文档
- [ ] 知道如何处理"无相关内容"的情况
- [ ] 了解常见的 Prompt 设计误区

---

## 下一步学习

- → [05_Prompt_Engineering进阶](../05_Prompt_Engineering进阶/)：Few-shot、Chain-of-Thought、结构化输出
- → L3_RAG核心流程：完整的 RAG 系统实现

---

**版本：** v1.0
**最后更新：** 2026-02-05
