# 实战代码：生成质量评估

> 使用 LLM-as-Judge 方法评估 RAG 系统的生成质量

---

## 环境准备

```bash
pip install openai python-dotenv numpy
```

**依赖说明：**

| 库 | 用途 |
|------|------|
| `openai` | 调用 LLM 作为评估器（Judge） |
| `python-dotenv` | 从 `.env` 文件加载 API 密钥 |
| `numpy` | 计算平均分等数值操作 |

---

## 完整代码

```python
"""
生成质量评估实战
演示：使用 LLM-as-Judge 评估 RAG 系统的 Faithfulness、Answer Relevancy、Answer Correctness

运行前准备：
1. 在项目根目录创建 .env 文件
2. 添加 OPENAI_API_KEY=your_key_here
3. 可选：添加 OPENAI_BASE_URL=https://your-proxy.com/v1
"""

import os
import json
from dotenv import load_dotenv
from openai import OpenAI

# 加载环境变量（API 密钥）
load_dotenv()

# 验证 API 密钥已设置
assert os.getenv("OPENAI_API_KEY"), "请在 .env 文件中设置 OPENAI_API_KEY"

client = OpenAI()


# ===== 1. 评估函数实现 =====
print("=" * 60)
print("1. 生成质量评估函数")
print("=" * 60)


def evaluate_faithfulness(answer: str, contexts: list[str]) -> dict:
    """
    评估忠实度：答案是否忠于检索到的上下文
    核心思路：将答案拆分为独立陈述，逐一检查是否有上下文支撑
    """
    context_text = "\n---\n".join(contexts)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": "你是一个专业的 RAG 系统评估专家。请严格按照要求评估。"
        }, {
            "role": "user",
            "content": f"""请评估以下答案的忠实度（Faithfulness）。

## 上下文
{context_text}

## 答案
{answer}

## 评估步骤
1. 将答案拆分为独立的事实陈述
2. 检查每个陈述是否可以从上下文中推导出来
3. 计算忠实度分数 = 有支撑的陈述数 / 总陈述数

## 输出格式（JSON）
{{
    "claims": ["陈述1", "陈述2", ...],
    "supported": [true, false, ...],
    "score": 0.0-1.0,
    "explanation": "简要说明"
}}"""
        }],
        temperature=0,
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)


def evaluate_relevancy(question: str, answer: str) -> dict:
    """
    评估答案相关性：答案是否回答了用户的问题
    核心思路：检查答案是否切题，有无跑题内容
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": "你是一个专业的 RAG 系统评估专家。请严格按照要求评估。"
        }, {
            "role": "user",
            "content": f"""请评估以下答案与问题的相关性（Answer Relevancy）。

## 问题
{question}

## 答案
{answer}

## 评分标准
- 1.0: 答案完全针对问题，没有无关内容
- 0.8: 答案基本针对问题，有少量无关内容
- 0.6: 答案部分相关，有较多无关内容
- 0.4: 答案大部分不相关
- 0.2: 答案几乎完全不相关

## 输出格式（JSON）
{{
    "score": 0.0-1.0,
    "relevant_parts": "答案中相关的部分",
    "irrelevant_parts": "答案中不相关的部分",
    "explanation": "简要说明"
}}"""
        }],
        temperature=0,
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)


def evaluate_correctness(answer: str, ground_truth: str) -> dict:
    """
    评估答案正确性：答案与标准答案的一致程度
    核心思路：用 TP/FP/FN 计算 Precision、Recall、F1
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": "你是一个专业的 RAG 系统评估专家。请严格按照要求评估。"
        }, {
            "role": "user",
            "content": f"""请评估生成答案与标准答案的正确性（Answer Correctness）。

## 标准答案
{ground_truth}

## 生成答案
{answer}

## 评估维度
1. TP（True Positive）：生成答案中与标准答案一致的信息
2. FP（False Positive）：生成答案中标准答案没有的信息（可能是错误或多余的）
3. FN（False Negative）：标准答案中生成答案遗漏的信息

## 输出格式（JSON）
{{
    "tp": ["一致的信息点1", ...],
    "fp": ["多余/错误的信息点1", ...],
    "fn": ["遗漏的信息点1", ...],
    "precision": 0.0-1.0,
    "recall": 0.0-1.0,
    "f1_score": 0.0-1.0,
    "explanation": "简要说明"
}}"""
        }],
        temperature=0,
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)


# ===== 2. 单条评估示例 =====
print("\n" + "=" * 60)
print("2. 单条评估示例")
print("=" * 60)

# 模拟 RAG 系统的输入输出
question = "什么是向量数据库？它有什么用途？"
contexts = [
    "向量数据库是一种专门设计用于存储、索引和查询高维向量数据的数据库系统。",
    "向量数据库支持近似最近邻搜索（ANN），常用于语义搜索、推荐系统、图像检索等场景。"
]
answer = (
    "向量数据库是专门存储和检索高维向量数据的数据库，支持基于相似度的快速检索。"
    "它主要用于语义搜索、推荐系统和图像检索。向量数据库使用 GPU 加速计算。"
)
ground_truth = (
    "向量数据库是存储高维向量并支持相似性搜索的专用数据库，"
    "用于语义搜索、推荐系统和图像检索等场景。"
)

# 评估忠实度
print("\n--- 忠实度评估 ---")
faith_result = evaluate_faithfulness(answer, contexts)
print(f"分数: {faith_result['score']}")
print(f"陈述拆分: {faith_result['claims']}")
print(f"支撑情况: {faith_result['supported']}")
print(f"说明: {faith_result['explanation']}")

# 评估相关性
print("\n--- 答案相关性评估 ---")
rel_result = evaluate_relevancy(question, answer)
print(f"分数: {rel_result['score']}")
print(f"说明: {rel_result['explanation']}")

# 评估正确性
print("\n--- 答案正确性评估 ---")
corr_result = evaluate_correctness(answer, ground_truth)
print(f"F1 分数: {corr_result['f1_score']}")
print(f"一致信息: {corr_result['tp']}")
print(f"多余信息: {corr_result['fp']}")
print(f"遗漏信息: {corr_result['fn']}")
print(f"说明: {corr_result['explanation']}")


# ===== 3. 批量评估 =====
print("\n" + "=" * 60)
print("3. 批量评估")
print("=" * 60)

eval_dataset = [
    {
        "question": "什么是 RAG？",
        "contexts": ["RAG（Retrieval-Augmented Generation）是一种结合检索和生成的技术。"],
        "answer": "RAG 是检索增强生成技术，通过检索外部知识来增强 LLM 的回答质量。",
        "ground_truth": "RAG 是一种结合检索和生成的技术，用于增强 LLM 的回答。"
    },
    {
        "question": "Embedding 模型怎么选？",
        "contexts": ["选择 Embedding 模型需要考虑语言支持、维度、性能和成本。中文推荐 BGE 系列。"],
        "answer": "选择 Embedding 模型要看语言支持和性能。中文场景推荐 BGE，英文推荐 OpenAI 的模型。",
        "ground_truth": "选择 Embedding 模型需考虑语言、维度、性能和成本，中文推荐 BGE。"
    },
    {
        "question": "什么是 Chunk 策略？",
        "contexts": ["文本分块是将长文档分割成小片段的方法，常见策略包括固定大小和递归分块。"],
        "answer": "Chunk 策略就是把文档切成小块。Python 是最流行的编程语言。",
        "ground_truth": "Chunk 策略是将长文档分割成小片段的方法，包括固定大小和递归分块。"
    },
]

print(f"\n评估 {len(eval_dataset)} 条数据...")
print(f"\n{'问题':<20} {'忠实度':<8} {'相关性':<8} {'正确性':<8}")
print("-" * 50)

total_faith = 0
total_rel = 0
total_corr = 0

for item in eval_dataset:
    f = evaluate_faithfulness(item["answer"], item["contexts"])
    r = evaluate_relevancy(item["question"], item["answer"])
    c = evaluate_correctness(item["answer"], item["ground_truth"])

    faith_score = f["score"]
    rel_score = r["score"]
    corr_score = c["f1_score"]

    total_faith += faith_score
    total_rel += rel_score
    total_corr += corr_score

    # 截断过长的问题用于对齐显示
    q_short = item["question"][:18] + ".." if len(item["question"]) > 18 else item["question"]
    print(f"{q_short:<20} {faith_score:<8.2f} {rel_score:<8.2f} {corr_score:<8.2f}")

n = len(eval_dataset)
print("-" * 50)
print(f"{'平均值':<20} {total_faith/n:<8.2f} {total_rel/n:<8.2f} {total_corr/n:<8.2f}")


# ===== 4. 综合诊断 =====
print("\n" + "=" * 60)
print("4. 综合诊断")
print("=" * 60)

avg_faith = total_faith / n
avg_rel = total_rel / n
avg_corr = total_corr / n

print(f"\n生成质量诊断报告")
print(f"  忠实度:   {avg_faith:.2f}  ", end="")
print("达标" if avg_faith >= 0.8 else "需优化：建议在 Prompt 中加强「仅根据上下文回答」的约束")
print(f"  相关性:   {avg_rel:.2f}  ", end="")
print("达标" if avg_rel >= 0.8 else "需优化：建议优化 Prompt 设计，要求「直接回答问题」")
print(f"  正确性:   {avg_corr:.2f}  ", end="")
print("达标" if avg_corr >= 0.7 else "需优化：建议检查检索上下文质量，确保覆盖关键信息")
```

---

## 运行输出示例

```
============================================================
1. 生成质量评估函数
============================================================

============================================================
2. 单条评估示例
============================================================

--- 忠实度评估 ---
分数: 0.67
陈述拆分: ['向量数据库是专门存储和检索高维向量数据的数据库', '支持基于相似度的快速检索', '主要用于语义搜索、推荐系统和图像检索', '向量数据库使用 GPU 加速计算']
支撑情况: [True, True, True, False]
说明: 前三条陈述可从上下文推导，但「GPU 加速计算」在上下文中没有依据，属于编造内容

--- 答案相关性评估 ---
分数: 0.9
说明: 答案基本围绕问题展开，回答了定义和用途，但「GPU 加速计算」属于额外信息

--- 答案正确性评估 ---
F1 分数: 0.8
一致信息: ['存储高维向量', '相似性搜索', '语义搜索', '推荐系统', '图像检索']
多余信息: ['GPU 加速计算']
遗漏信息: ['专用数据库']
说明: 生成答案覆盖了标准答案的大部分要点，但多了一条无依据的信息

============================================================
3. 批量评估
============================================================

评估 3 条数据...

问题                  忠实度    相关性    正确性
--------------------------------------------------
什么是 RAG？          1.00     0.95     0.90
Embedding 模型怎么选.. 0.80     0.85     0.75
什么是 Chunk 策略？    0.50     0.50     0.60
--------------------------------------------------
平均值                0.77     0.77     0.75

============================================================
4. 综合诊断
============================================================

生成质量诊断报告
  忠实度:   0.77  需优化：建议在 Prompt 中加强「仅根据上下文回答」的约束
  相关性:   0.77  需优化：建议优化 Prompt 设计，要求「直接回答问题」
  正确性:   0.75  达标
```

**输出解读：**

| 指标 | 第三条数据得分低的原因 |
|------|----------------------|
| 忠实度 0.50 | 答案中「Python 是最流行的编程语言」在上下文中完全没有依据 |
| 相关性 0.50 | 「Python 是最流行的编程语言」与问题「什么是 Chunk 策略」完全无关 |
| 正确性 0.60 | 答案遗漏了「固定大小和递归分块」等关键信息 |

---

## 一句话记住

**生成质量评估的核心是 LLM-as-Judge——用结构化 Prompt 让 LLM 从忠实度、相关性、正确性三个维度打分，快速定位生成环节的问题。**
