# å®æˆ˜ä»£ç 1ï¼šä½¿ç”¨ Backup å·¥å…·å¤‡ä»½æ¢å¤

> å®Œæ•´çš„ Milvus Backup å·¥å…·ä½¿ç”¨ç¤ºä¾‹

---

## åœºæ™¯æ¦‚è¿°

æœ¬åœºæ™¯æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Milvus Backup å·¥å…·è¿›è¡Œï¼š
- Collection çš„å®Œæ•´å¤‡ä»½
- å¤‡ä»½çš„éªŒè¯å’Œç®¡ç†
- æ•°æ®çš„æ¢å¤
- è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

**é€‚ç”¨åœºæ™¯ï¼š**
- ç”Ÿäº§ç¯å¢ƒå®šæœŸå¤‡ä»½
- ç¾éš¾æ¢å¤æ¼”ç»ƒ
- æ•°æ®è¿ç§»å‡†å¤‡

---

## ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£… Milvus Backup

```bash
# ä½¿ç”¨ Docker å®‰è£…ï¼ˆæ¨èï¼‰
docker pull milvusdb/milvus-backup:latest

# æˆ–ä»æºç ç¼–è¯‘
git clone https://github.com/zilliztech/milvus-backup.git
cd milvus-backup
go build -o milvus-backup cmd/backup/main.go
```

### 2. é…ç½®æ–‡ä»¶

åˆ›å»º `backup_config.yaml`ï¼š

```yaml
# Milvus è¿æ¥é…ç½®
milvus:
  address: localhost
  port: 19530
  username: ""
  password: ""

# å¤‡ä»½å­˜å‚¨é…ç½®
storage:
  storageType: local
  local:
    path: /data/milvus-backup

# å¤‡ä»½é…ç½®
backup:
  maxBackupNum: 10
  retentionDays: 30
  compression: true
  compressionAlgorithm: zstd
  compressionLevel: 3

# HTTP æœåŠ¡é…ç½®
http:
  address: 0.0.0.0
  port: 8080

# æ—¥å¿—é…ç½®
log:
  level: info
  file: /var/log/milvus-backup.log
```

### 3. å¯åŠ¨ Backup æœåŠ¡

```bash
# ä½¿ç”¨ Docker å¯åŠ¨
docker run -d \
  --name milvus-backup \
  -p 8080:8080 \
  -v $(pwd)/backup_data:/data/milvus-backup \
  -v $(pwd)/backup_config.yaml:/etc/milvus-backup/config.yaml \
  milvusdb/milvus-backup:latest

# éªŒè¯æœåŠ¡
curl http://localhost:8080/api/v1/health
```

---

## å®Œæ•´ç¤ºä¾‹ä»£ç 

### ç¤ºä¾‹1ï¼šåŸºç¡€å¤‡ä»½æ¢å¤

```python
#!/usr/bin/env python3
"""
Milvus Backup å·¥å…·åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
"""

import requests
import time
import json
from typing import Dict, List, Optional

class MilvusBackupClient:
    """Milvus Backup å®¢æˆ·ç«¯"""

    def __init__(self, host: str = "localhost", port: int = 8080):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        self.base_url = f"http://{host}:{port}/api/v1"

    def create_backup(
        self,
        backup_name: str,
        collections: List[str],
        compression: bool = True
    ) -> Dict:
        """åˆ›å»ºå¤‡ä»½"""
        url = f"{self.base_url}/backup/create"
        payload = {
            "backup_name": backup_name,
            "collections": collections,
            "compression": compression
        }

        print(f"åˆ›å»ºå¤‡ä»½: {backup_name}")
        print(f"Collection: {collections}")

        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"å¤‡ä»½å¤±è´¥: {result['message']}")

        print(f"âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ")
        print(f"  å¤‡ä»½ID: {result['data']['backup_id']}")
        print(f"  æ•°æ®é‡: {result['data']['total_entities']}")
        print(f"  å¤§å°: {result['data']['backup_size'] / 1024 / 1024:.2f} MB")
        print(f"  è€—æ—¶: {result['data']['duration']} ç§’")

        return result["data"]

    def list_backups(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
        url = f"{self.base_url}/backup/list"
        response = requests.get(url)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"è·å–å¤‡ä»½åˆ—è¡¨å¤±è´¥: {result['message']}")

        backups = result["data"]["backups"]
        print(f"\nå¤‡ä»½åˆ—è¡¨ (å…± {len(backups)} ä¸ª):")
        print("-" * 80)
        print(f"{'å¤‡ä»½åç§°':<30} {'Collection':<20} {'å¤§å°':<15} {'åˆ›å»ºæ—¶é—´':<20}")
        print("-" * 80)

        for backup in backups:
            size_mb = backup["backup_size"] / 1024 / 1024
            created_at = time.strftime(
                "%Y-%m-%d %H:%M:%S",
                time.localtime(backup["created_at"])
            )
            collections = ", ".join(backup["collections"])
            print(f"{backup['backup_id']:<30} {collections:<20} {size_mb:>10.2f} MB {created_at:<20}")

        return backups

    def restore_backup(
        self,
        backup_name: str,
        collections: Optional[List[str]] = None,
        target_collection: Optional[str] = None
    ) -> Dict:
        """æ¢å¤å¤‡ä»½"""
        url = f"{self.base_url}/backup/restore"
        payload = {
            "backup_name": backup_name
        }

        if collections:
            payload["collections"] = collections

        if target_collection:
            payload["target_collection"] = target_collection

        print(f"\næ¢å¤å¤‡ä»½: {backup_name}")
        if target_collection:
            print(f"ç›®æ ‡ Collection: {target_collection}")

        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"æ¢å¤å¤±è´¥: {result['message']}")

        print(f"âœ… å¤‡ä»½æ¢å¤æˆåŠŸ")
        print(f"  æ•°æ®é‡: {result['data']['total_entities']}")
        print(f"  è€—æ—¶: {result['data']['duration']} ç§’")

        return result["data"]

    def delete_backup(self, backup_name: str):
        """åˆ é™¤å¤‡ä»½"""
        url = f"{self.base_url}/backup/delete"
        payload = {"backup_name": backup_name}

        print(f"\nåˆ é™¤å¤‡ä»½: {backup_name}")

        response = requests.delete(url, json=payload)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"åˆ é™¤å¤±è´¥: {result['message']}")

        print(f"âœ… å¤‡ä»½å·²åˆ é™¤")

    def verify_backup(self, backup_name: str) -> bool:
        """éªŒè¯å¤‡ä»½"""
        url = f"{self.base_url}/backup/verify"
        payload = {"backup_name": backup_name}

        print(f"\néªŒè¯å¤‡ä»½: {backup_name}")

        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"éªŒè¯å¤±è´¥: {result['message']}")

        is_valid = result["data"]["is_valid"]
        if is_valid:
            print(f"âœ… å¤‡ä»½éªŒè¯é€šè¿‡")
        else:
            print(f"âŒ å¤‡ä»½éªŒè¯å¤±è´¥: {result['data']['error']}")

        return is_valid


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = MilvusBackupClient(host="localhost", port=8080)

    # 1. åˆ›å»ºå¤‡ä»½
    backup_name = f"backup_{time.strftime('%Y%m%d_%H%M%S')}"
    backup_info = client.create_backup(
        backup_name=backup_name,
        collections=["my_collection"],
        compression=True
    )

    # 2. åˆ—å‡ºæ‰€æœ‰å¤‡ä»½
    backups = client.list_backups()

    # 3. éªŒè¯å¤‡ä»½
    is_valid = client.verify_backup(backup_name)

    if is_valid:
        # 4. æ¢å¤å¤‡ä»½åˆ°æ–° Collection
        client.restore_backup(
            backup_name=backup_name,
            target_collection="my_collection_restored"
        )

    # 5. æ¸…ç†æ—§å¤‡ä»½ï¼ˆå¯é€‰ï¼‰
    # client.delete_backup("old_backup_name")


if __name__ == "__main__":
    main()
```

**è¿è¡Œç¤ºä¾‹ï¼š**

```bash
python backup_basic.py
```

**è¾“å‡ºï¼š**

```
åˆ›å»ºå¤‡ä»½: backup_20260210_100000
Collection: ['my_collection']
âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ
  å¤‡ä»½ID: backup_20260210_100000
  æ•°æ®é‡: 1000000
  å¤§å°: 2500.00 MB
  è€—æ—¶: 330 ç§’

å¤‡ä»½åˆ—è¡¨ (å…± 3 ä¸ª):
--------------------------------------------------------------------------------
å¤‡ä»½åç§°                        Collection           å¤§å°            åˆ›å»ºæ—¶é—´
--------------------------------------------------------------------------------
backup_20260210_100000          my_collection        2500.00 MB      2026-02-10 10:00:00
backup_20260209_100000          my_collection        2400.00 MB      2026-02-09 10:00:00
backup_20260208_100000          my_collection        2300.00 MB      2026-02-08 10:00:00

éªŒè¯å¤‡ä»½: backup_20260210_100000
âœ… å¤‡ä»½éªŒè¯é€šè¿‡

æ¢å¤å¤‡ä»½: backup_20260210_100000
ç›®æ ‡ Collection: my_collection_restored
âœ… å¤‡ä»½æ¢å¤æˆåŠŸ
  æ•°æ®é‡: 1000000
  è€—æ—¶: 500 ç§’
```

---

### ç¤ºä¾‹2ï¼šå¢é‡å¤‡ä»½

```python
#!/usr/bin/env python3
"""
å¢é‡å¤‡ä»½ç¤ºä¾‹
"""

import requests
import time
from datetime import datetime, timedelta
from typing import Dict, Optional

class IncrementalBackup:
    """å¢é‡å¤‡ä»½ç®¡ç†å™¨"""

    def __init__(self, host: str = "localhost", port: int = 8080):
        """åˆå§‹åŒ–"""
        self.base_url = f"http://{host}:{port}/api/v1"
        self.last_full_backup = None
        self.incremental_backups = []

    def create_full_backup(self, collection_name: str) -> str:
        """åˆ›å»ºå…¨é‡å¤‡ä»½"""
        backup_name = f"full_{collection_name}_{time.strftime('%Y%m%d_%H%M%S')}"

        print(f"åˆ›å»ºå…¨é‡å¤‡ä»½: {backup_name}")

        url = f"{self.base_url}/backup/create"
        payload = {
            "backup_name": backup_name,
            "collections": [collection_name],
            "compression": True
        }

        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"å…¨é‡å¤‡ä»½å¤±è´¥: {result['message']}")

        self.last_full_backup = backup_name
        print(f"âœ… å…¨é‡å¤‡ä»½å®Œæˆ: {backup_name}")

        return backup_name

    def create_incremental_backup(
        self,
        collection_name: str,
        base_backup: Optional[str] = None
    ) -> str:
        """åˆ›å»ºå¢é‡å¤‡ä»½"""
        if not base_backup:
            base_backup = self.last_full_backup

        if not base_backup:
            raise Exception("æ²¡æœ‰åŸºå‡†å¤‡ä»½ï¼Œè¯·å…ˆåˆ›å»ºå…¨é‡å¤‡ä»½")

        backup_name = f"incr_{collection_name}_{time.strftime('%Y%m%d_%H%M%S')}"

        print(f"åˆ›å»ºå¢é‡å¤‡ä»½: {backup_name}")
        print(f"åŸºäº: {base_backup}")

        url = f"{self.base_url}/backup/create"
        payload = {
            "backup_name": backup_name,
            "collections": [collection_name],
            "base_backup": base_backup,
            "incremental": True,
            "compression": True
        }

        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        if result["code"] != 0:
            raise Exception(f"å¢é‡å¤‡ä»½å¤±è´¥: {result['message']}")

        self.incremental_backups.append(backup_name)
        print(f"âœ… å¢é‡å¤‡ä»½å®Œæˆ: {backup_name}")
        print(f"  å¢é‡æ•°æ®é‡: {result['data']['total_entities']}")
        print(f"  å¤§å°: {result['data']['backup_size'] / 1024 / 1024:.2f} MB")

        return backup_name

    def restore_with_incremental(
        self,
        collection_name: str,
        target_collection: str
    ):
        """æ¢å¤å…¨é‡ + å¢é‡å¤‡ä»½"""
        print(f"\næ¢å¤å¤‡ä»½é“¾:")
        print(f"  å…¨é‡å¤‡ä»½: {self.last_full_backup}")
        print(f"  å¢é‡å¤‡ä»½: {len(self.incremental_backups)} ä¸ª")

        # 1. æ¢å¤å…¨é‡å¤‡ä»½
        print(f"\n[1/2] æ¢å¤å…¨é‡å¤‡ä»½...")
        url = f"{self.base_url}/backup/restore"
        payload = {
            "backup_name": self.last_full_backup,
            "target_collection": target_collection
        }

        response = requests.post(url, json=payload)
        response.raise_for_status()

        # 2. ä¾æ¬¡æ¢å¤å¢é‡å¤‡ä»½
        print(f"\n[2/2] æ¢å¤å¢é‡å¤‡ä»½...")
        for i, incr_backup in enumerate(self.incremental_backups, 1):
            print(f"  [{i}/{len(self.incremental_backups)}] {incr_backup}")

            payload = {
                "backup_name": incr_backup,
                "target_collection": target_collection,
                "merge": True  # åˆå¹¶åˆ°å·²æœ‰æ•°æ®
            }

            response = requests.post(url, json=payload)
            response.raise_for_status()

        print(f"\nâœ… å¤‡ä»½é“¾æ¢å¤å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    manager = IncrementalBackup()
    collection_name = "my_collection"

    # 1. åˆ›å»ºå…¨é‡å¤‡ä»½ï¼ˆæ¯å‘¨ä¸€æ¬¡ï¼‰
    full_backup = manager.create_full_backup(collection_name)

    # 2. æ¨¡æ‹Ÿæ¯å¤©çš„å¢é‡å¤‡ä»½
    for day in range(1, 8):
        print(f"\n--- ç¬¬ {day} å¤© ---")

        # æ¨¡æ‹Ÿæ•°æ®å˜åŒ–
        time.sleep(1)

        # åˆ›å»ºå¢é‡å¤‡ä»½
        incr_backup = manager.create_incremental_backup(collection_name)

    # 3. æ¢å¤å®Œæ•´æ•°æ®
    manager.restore_with_incremental(
        collection_name=collection_name,
        target_collection="my_collection_restored"
    )


if __name__ == "__main__":
    main()
```

---

### ç¤ºä¾‹3ï¼šè‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

```python
#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬
"""

import requests
import time
import schedule
import logging
from datetime import datetime, timedelta
from typing import List, Dict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/milvus-backup.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


class AutoBackupManager:
    """è‡ªåŠ¨åŒ–å¤‡ä»½ç®¡ç†å™¨"""

    def __init__(
        self,
        host: str = "localhost",
        port: int = 8080,
        collections: List[str] = None,
        retention_days: int = 7
    ):
        """åˆå§‹åŒ–"""
        self.base_url = f"http://{host}:{port}/api/v1"
        self.collections = collections or []
        self.retention_days = retention_days

    def backup_all_collections(self):
        """å¤‡ä»½æ‰€æœ‰ Collection"""
        logger.info("å¼€å§‹è‡ªåŠ¨å¤‡ä»½...")

        backup_name = f"auto_{time.strftime('%Y%m%d_%H%M%S')}"

        try:
            # åˆ›å»ºå¤‡ä»½
            url = f"{self.base_url}/backup/create"
            payload = {
                "backup_name": backup_name,
                "collections": self.collections,
                "compression": True
            }

            response = requests.post(url, json=payload, timeout=3600)
            response.raise_for_status()

            result = response.json()
            if result["code"] != 0:
                raise Exception(f"å¤‡ä»½å¤±è´¥: {result['message']}")

            logger.info(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_name}")
            logger.info(f"  æ•°æ®é‡: {result['data']['total_entities']}")
            logger.info(f"  å¤§å°: {result['data']['backup_size'] / 1024 / 1024:.2f} MB")

            # éªŒè¯å¤‡ä»½
            self.verify_backup(backup_name)

            # æ¸…ç†æ—§å¤‡ä»½
            self.cleanup_old_backups()

        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            self.send_alert(f"å¤‡ä»½å¤±è´¥: {e}")

    def verify_backup(self, backup_name: str):
        """éªŒè¯å¤‡ä»½"""
        logger.info(f"éªŒè¯å¤‡ä»½: {backup_name}")

        try:
            url = f"{self.base_url}/backup/verify"
            payload = {"backup_name": backup_name}

            response = requests.post(url, json=payload, timeout=600)
            response.raise_for_status()

            result = response.json()
            if result["code"] != 0 or not result["data"]["is_valid"]:
                raise Exception("å¤‡ä»½éªŒè¯å¤±è´¥")

            logger.info(f"âœ… å¤‡ä»½éªŒè¯é€šè¿‡")

        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½éªŒè¯å¤±è´¥: {e}")
            self.send_alert(f"å¤‡ä»½éªŒè¯å¤±è´¥: {e}")

    def cleanup_old_backups(self):
        """æ¸…ç†æ—§å¤‡ä»½"""
        logger.info(f"æ¸…ç†è¶…è¿‡ {self.retention_days} å¤©çš„å¤‡ä»½...")

        try:
            # è·å–å¤‡ä»½åˆ—è¡¨
            url = f"{self.base_url}/backup/list"
            response = requests.get(url)
            response.raise_for_status()

            result = response.json()
            if result["code"] != 0:
                raise Exception("è·å–å¤‡ä»½åˆ—è¡¨å¤±è´¥")

            backups = result["data"]["backups"]
            cutoff_time = time.time() - (self.retention_days * 86400)

            # åˆ é™¤æ—§å¤‡ä»½
            deleted_count = 0
            for backup in backups:
                if backup["created_at"] < cutoff_time:
                    self.delete_backup(backup["backup_id"])
                    deleted_count += 1

            logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {deleted_count} ä¸ªæ—§å¤‡ä»½")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")

    def delete_backup(self, backup_name: str):
        """åˆ é™¤å¤‡ä»½"""
        url = f"{self.base_url}/backup/delete"
        payload = {"backup_name": backup_name}

        response = requests.delete(url, json=payload)
        response.raise_for_status()

        logger.info(f"åˆ é™¤å¤‡ä»½: {backup_name}")

    def send_alert(self, message: str):
        """å‘é€å‘Šè­¦"""
        # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶ã€Slackã€é’‰é’‰ç­‰å‘Šè­¦æ–¹å¼
        logger.error(f"ğŸš¨ å‘Šè­¦: {message}")

        # ç¤ºä¾‹ï¼šå‘é€é‚®ä»¶
        # send_email(
        #     to="admin@example.com",
        #     subject="Milvus å¤‡ä»½å‘Šè­¦",
        #     body=message
        # )

    def run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å™¨"""
        logger.info("å¯åŠ¨è‡ªåŠ¨å¤‡ä»½è°ƒåº¦å™¨...")

        # æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½
        schedule.every().day.at("02:00").do(self.backup_all_collections)

        # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
        schedule.every().hour.do(self.check_backup_health)

        while True:
            schedule.run_pending()
            time.sleep(60)

    def check_backup_health(self):
        """æ£€æŸ¥å¤‡ä»½å¥åº·çŠ¶æ€"""
        try:
            # è·å–æœ€è¿‘çš„å¤‡ä»½
            url = f"{self.base_url}/backup/list"
            response = requests.get(url)
            response.raise_for_status()

            result = response.json()
            if result["code"] != 0:
                raise Exception("è·å–å¤‡ä»½åˆ—è¡¨å¤±è´¥")

            backups = result["data"]["backups"]

            if not backups:
                self.send_alert("æ²¡æœ‰ä»»ä½•å¤‡ä»½ï¼")
                return

            # æ£€æŸ¥æœ€è¿‘å¤‡ä»½æ—¶é—´
            latest_backup = max(backups, key=lambda x: x["created_at"])
            time_since_last = time.time() - latest_backup["created_at"]

            if time_since_last > 86400:  # 24 å°æ—¶
                self.send_alert(f"æœ€è¿‘å¤‡ä»½æ—¶é—´è¶…è¿‡ 24 å°æ—¶: {time_since_last / 3600:.1f} å°æ—¶")

        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå¤‡ä»½ç®¡ç†å™¨
    manager = AutoBackupManager(
        host="localhost",
        port=8080,
        collections=["collection1", "collection2", "collection3"],
        retention_days=7
    )

    # è¿è¡Œè°ƒåº¦å™¨
    manager.run_scheduler()


if __name__ == "__main__":
    main()
```

**éƒ¨ç½²ä¸ºç³»ç»ŸæœåŠ¡ï¼š**

åˆ›å»º `/etc/systemd/system/milvus-backup.service`ï¼š

```ini
[Unit]
Description=Milvus Auto Backup Service
After=network.target

[Service]
Type=simple
User=milvus
WorkingDirectory=/opt/milvus-backup
ExecStart=/usr/bin/python3 /opt/milvus-backup/auto_backup.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
sudo systemctl daemon-reload
sudo systemctl enable milvus-backup
sudo systemctl start milvus-backup
sudo systemctl status milvus-backup
```

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **Milvus Backup å·¥å…·ç®€å•æ˜“ç”¨**ï¼šé€šè¿‡ HTTP API æˆ–å‘½ä»¤è¡Œå³å¯ä½¿ç”¨
2. **æ”¯æŒå¢é‡å¤‡ä»½**ï¼šå‡å°‘å¤‡ä»½æ—¶é—´å’Œå­˜å‚¨ç©ºé—´
3. **è‡ªåŠ¨åŒ–å¤‡ä»½**ï¼šä½¿ç”¨ schedule åº“å®ç°å®šæ—¶å¤‡ä»½
4. **å¤‡ä»½éªŒè¯**ï¼šæ¯æ¬¡å¤‡ä»½åéƒ½è¦éªŒè¯
5. **æ¸…ç†ç­–ç•¥**ï¼šå®šæœŸæ¸…ç†æ—§å¤‡ä»½

### é€‚ç”¨åœºæ™¯

- âœ… ç”Ÿäº§ç¯å¢ƒå®šæœŸå¤‡ä»½
- âœ… ç¾éš¾æ¢å¤æ¼”ç»ƒ
- âœ… æ•°æ®è¿ç§»å‡†å¤‡
- âœ… çŸ¥è¯†åº“ç‰ˆæœ¬ç®¡ç†

### ä¸‹ä¸€æ­¥

- å­¦ä¹  [Collection å¯¼å‡ºå¯¼å…¥](./07_å®æˆ˜ä»£ç _02_Collectionå¯¼å‡ºå¯¼å…¥.md)
- å­¦ä¹  [è·¨é›†ç¾¤æ•°æ®è¿ç§»](./07_å®æˆ˜ä»£ç _03_è·¨é›†ç¾¤æ•°æ®è¿ç§».md)
