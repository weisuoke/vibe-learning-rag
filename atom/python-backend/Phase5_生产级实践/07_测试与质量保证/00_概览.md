# 测试与质量保证 - 概览

## 为什么 AI Agent 需要测试？

### 生产环境的残酷现实

想象一下这个场景：

你的 AI Agent 在开发环境运行完美，但上线后：
- 用户输入一个特殊字符，整个系统崩溃
- RAG 检索返回空结果，Agent 开始胡言乱语
- 数据库连接池耗尽，所有请求超时
- JWT 过期处理有 bug，用户无法登录
- 流式输出中断，前端卡死

**这些问题在开发时都没发现，因为你没有测试。**

### 测试的本质价值

测试不是为了"完成任务"，而是为了：

1. **提前发现 bug**：在用户发现之前找到问题
2. **保护重构**：修改代码时不怕破坏现有功能
3. **文档化行为**：测试就是最好的使用文档
4. **提升信心**：敢于快速迭代和部署
5. **降低成本**：修复 bug 的成本随时间指数增长

### AI Agent 测试的特殊挑战

AI Agent 不是普通的 CRUD 应用，它有独特的测试难点：

**1. LLM 输出的不确定性**
```python
# 同样的输入，每次输出都可能不同
response1 = agent.run("什么是 RAG?")
response2 = agent.run("什么是 RAG?")
assert response1 == response2  # ❌ 这个测试会失败
```

**解决方案**：
- 测试输出的结构，而非具体内容
- 测试关键信息是否存在
- 使用确定性的 temperature=0

**2. 异步流式输出**
```python
# 流式输出如何测试？
async for chunk in agent.stream("生成一篇文章"):
    print(chunk)  # 如何验证每个 chunk？
```

**解决方案**：
- 收集所有 chunk 后验证完整性
- 测试流的开始和结束事件
- 测试中断和重连逻辑

**3. 外部依赖**
```python
# Agent 依赖 OpenAI API、向量数据库、Redis...
# 测试时如何处理这些依赖？
```

**解决方案**：
- Mock 外部 API 调用
- 使用测试数据库
- 隔离测试环境

**4. 长时间运行**
```python
# Agent 可能需要多轮对话、多次检索
# 测试会很慢
```

**解决方案**：
- 单元测试只测试核心逻辑
- 集成测试使用小数据集
- 端到端测试只测试关键路径

---

## 测试金字塔

### 理想的测试分布

```
        /\
       /  \  E2E 测试 (10%)
      /----\
     /      \  集成测试 (30%)
    /--------\
   /          \  单元测试 (60%)
  /------------\
```

**单元测试（60%）**：
- 测试单个函数、类
- 快速、独立、可重复
- 覆盖边界条件和异常情况

**集成测试（30%）**：
- 测试多个组件协作
- 测试数据库、缓存、消息队列
- 验证业务流程

**端到端测试（10%）**：
- 测试完整的用户场景
- 从 HTTP 请求到数据库再到响应
- 最接近真实使用

### AI Agent 的测试金字塔

```
        /\
       /  \  完整对话测试 (5%)
      /----\
     /      \  RAG 检索链测试 (15%)
    /--------\
   /          \  Agent 组件测试 (30%)
  /------------\
 /              \  工具函数测试 (50%)
/----------------\
```

**工具函数测试（50%）**：
- 文本分块逻辑
- Embedding 计算
- 相似度计算
- 数据验证

**Agent 组件测试（30%）**：
- Prompt 模板渲染
- 工具调用逻辑
- 记忆管理
- 上下文注入

**RAG 检索链测试（15%）**：
- 向量检索
- ReRank 重排序
- 上下文拼接
- 生成结果验证

**完整对话测试（5%）**：
- 多轮对话
- 流式输出
- 错误恢复
- 性能测试

---

## 学习路线图

### 第一阶段：pytest 基础（1-2天）

**目标**：掌握 pytest 核心概念，能写简单的单元测试

**学习内容**：
1. pytest 基本用法
2. fixture 机制
3. 参数化测试
4. 断言和异常测试

**实战练习**：
```python
# 测试一个简单的文本分块函数
def test_chunk_text():
    text = "Hello world. This is a test."
    chunks = chunk_text(text, chunk_size=10)
    assert len(chunks) == 3
    assert chunks[0] == "Hello"
```

### 第二阶段：数据库测试（2-3天）

**目标**：掌握数据库测试策略，能测试 SQLAlchemy 模型

**学习内容**：
1. 测试数据库 setup/teardown
2. 事务回滚策略
3. 测试数据 factory
4. Mock 数据库查询

**实战练习**：
```python
# 测试用户模型的创建和查询
def test_create_user(db_session):
    user = User(username="test", email="test@example.com")
    db_session.add(user)
    db_session.commit()

    found = db_session.query(User).filter_by(username="test").first()
    assert found.email == "test@example.com"
```

### 第三阶段：API 测试（2-3天）

**目标**：掌握 FastAPI 测试，能测试 HTTP 端点

**学习内容**：
1. FastAPI TestClient
2. 测试路由和依赖注入
3. 测试认证和权限
4. 测试异步端点

**实战练习**：
```python
# 测试一个受保护的 API 端点
def test_protected_endpoint(client, auth_token):
    response = client.get(
        "/api/users/me",
        headers={"Authorization": f"Bearer {auth_token}"}
    )
    assert response.status_code == 200
    assert "username" in response.json()
```

### 第四阶段：AI Agent 测试（3-5天）

**目标**：掌握 AI Agent 特有的测试技巧

**学习内容**：
1. Mock LLM 调用
2. 测试 RAG 检索链
3. 测试流式输出
4. 测试对话记忆

**实战练习**：
```python
# 测试 RAG 检索链
def test_rag_retrieval(vector_store, test_documents):
    query = "什么是 RAG?"
    results = vector_store.similarity_search(query, k=3)

    assert len(results) == 3
    assert "RAG" in results[0].page_content
    assert results[0].metadata["source"] is not None
```

### 第五阶段：生产级测试（3-5天）

**目标**：构建完整的测试体系，集成 CI/CD

**学习内容**：
1. 测试组织结构
2. 测试覆盖率
3. CI/CD 集成
4. 性能测试
5. 测试数据管理

**实战练习**：
```python
# 完整的 AI Agent 测试套件
class TestAIAgent:
    def test_basic_query(self, agent):
        """测试基本查询"""
        pass

    def test_rag_retrieval(self, agent, vector_store):
        """测试 RAG 检索"""
        pass

    def test_streaming_output(self, agent):
        """测试流式输出"""
        pass

    def test_conversation_memory(self, agent):
        """测试对话记忆"""
        pass
```

---

## 与其他 Phase5 知识点的关系

### 测试是所有知识点的保障

```
┌─────────────────────────────────────────────────────────┐
│                    测试与质量保证                        │
│                  (保护所有其他功能)                      │
└─────────────────────────────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│  JWT 认证    │    │ 结构化日志   │    │ Redis 缓存   │
│  (测试认证)  │    │ (测试日志)   │    │ (测试缓存)   │
└──────────────┘    └──────────────┘    └──────────────┘
        │                   │                   │
        └───────────────────┼───────────────────┘
                            │
                            ▼
                    ┌──────────────┐
                    │  限流中间件  │
                    │  (测试限流)  │
                    └──────────────┘
                            │
                            ▼
                    ┌──────────────┐
                    │ 错误处理策略 │
                    │ (测试异常)   │
                    └──────────────┘
                            │
                            ▼
                    ┌──────────────┐
                    │ 长任务处理   │
                    │ (测试任务)   │
                    └──────────────┘
```

### 1. JWT 认证 + 测试

**测试场景**：
- 测试 token 生成和验证
- 测试 token 过期处理
- 测试无效 token 拒绝
- 测试受保护端点

**示例**：
```python
def test_jwt_authentication(client):
    # 测试登录获取 token
    response = client.post("/auth/login", json={
        "username": "test",
        "password": "password"
    })
    assert response.status_code == 200
    token = response.json()["access_token"]

    # 测试使用 token 访问受保护端点
    response = client.get(
        "/api/users/me",
        headers={"Authorization": f"Bearer {token}"}
    )
    assert response.status_code == 200
```

### 2. 结构化日志 + 测试

**测试场景**：
- 测试日志记录
- 测试日志级别
- 测试链路追踪 ID
- 测试敏感信息脱敏

**示例**：
```python
def test_structured_logging(caplog):
    with caplog.at_level(logging.INFO):
        logger.info("Test message", extra={"user_id": 123})

    assert len(caplog.records) == 1
    assert caplog.records[0].user_id == 123
```

### 3. Redis 缓存 + 测试

**测试场景**：
- 测试缓存命中和未命中
- 测试缓存失效
- 测试缓存预热
- 测试缓存穿透保护

**示例**：
```python
def test_redis_cache(redis_client):
    # 测试缓存未命中
    result = get_user_from_cache(redis_client, user_id=1)
    assert result is None

    # 测试缓存写入
    set_user_cache(redis_client, user_id=1, data={"name": "test"})

    # 测试缓存命中
    result = get_user_from_cache(redis_client, user_id=1)
    assert result["name"] == "test"
```

### 4. 限流中间件 + 测试

**测试场景**：
- 测试限流触发
- 测试限流恢复
- 测试不同用户的限流隔离
- 测试限流配置

**示例**：
```python
def test_rate_limiting(client):
    # 发送多个请求触发限流
    for i in range(10):
        response = client.get("/api/test")
        if i < 5:
            assert response.status_code == 200
        else:
            assert response.status_code == 429  # Too Many Requests
```

### 5. 错误处理策略 + 测试

**测试场景**：
- 测试各种异常的处理
- 测试错误响应格式
- 测试错误日志记录
- 测试错误恢复

**示例**：
```python
def test_error_handling(client):
    # 测试 404 错误
    response = client.get("/api/nonexistent")
    assert response.status_code == 404
    assert "error" in response.json()

    # 测试 500 错误
    response = client.get("/api/error")
    assert response.status_code == 500
    assert response.json()["error"]["type"] == "InternalServerError"
```

### 6. 长任务处理 + 测试

**测试场景**：
- 测试任务提交
- 测试任务状态查询
- 测试任务取消
- 测试任务超时

**示例**：
```python
def test_background_task(client):
    # 提交任务
    response = client.post("/api/tasks", json={"type": "process_data"})
    task_id = response.json()["task_id"]

    # 查询任务状态
    response = client.get(f"/api/tasks/{task_id}")
    assert response.json()["status"] in ["pending", "running", "completed"]
```

---

## 测试驱动开发（TDD）

### TDD 的三个步骤

```
┌─────────────┐
│  1. Red     │  写一个失败的测试
│  (写测试)   │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│  2. Green   │  写最少的代码让测试通过
│  (写代码)   │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│  3. Refactor│  重构代码，保持测试通过
│  (重构)     │
└──────┬──────┘
       │
       └──────► 重复
```

### TDD 在 AI Agent 开发中的应用

**示例：开发一个文本分块函数**

**Step 1: Red - 写测试**
```python
def test_chunk_text_basic():
    text = "Hello world. This is a test."
    chunks = chunk_text(text, chunk_size=10, overlap=2)

    assert len(chunks) > 0
    assert all(len(chunk) <= 10 for chunk in chunks)
    assert chunks[0].startswith("Hello")
```

**Step 2: Green - 写代码**
```python
def chunk_text(text: str, chunk_size: int, overlap: int) -> list[str]:
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start = end - overlap
    return chunks
```

**Step 3: Refactor - 重构**
```python
def chunk_text(text: str, chunk_size: int, overlap: int) -> list[str]:
    """将文本分块，支持重叠"""
    if chunk_size <= 0:
        raise ValueError("chunk_size must be positive")
    if overlap < 0 or overlap >= chunk_size:
        raise ValueError("overlap must be in [0, chunk_size)")

    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        chunks.append(text[start:end].strip())
        start = end - overlap
    return [c for c in chunks if c]  # 过滤空字符串
```

### TDD 的优势

1. **设计驱动**：先思考接口，再实现细节
2. **快速反馈**：立即知道代码是否正确
3. **重构安全**：有测试保护，敢于重构
4. **文档化**：测试就是最好的使用示例

### TDD 的挑战

1. **初期慢**：写测试需要时间
2. **学习曲线**：需要改变思维方式
3. **过度测试**：可能测试太多细节
4. **维护成本**：测试也需要维护

---

## 测试的最佳实践

### 1. 测试命名

**好的命名**：
```python
def test_user_login_with_valid_credentials_returns_token():
    """测试：使用有效凭证登录应该返回 token"""
    pass

def test_user_login_with_invalid_password_returns_401():
    """测试：使用无效密码登录应该返回 401"""
    pass
```

**不好的命名**：
```python
def test_login():
    """测试登录"""
    pass

def test_login2():
    """测试登录2"""
    pass
```

### 2. 测试独立性

**好的做法**：
```python
def test_create_user(db_session):
    # 每个测试都创建自己的数据
    user = User(username="test")
    db_session.add(user)
    db_session.commit()

    assert user.id is not None
```

**不好的做法**：
```python
# 依赖全局状态
global_user = None

def test_create_user(db_session):
    global global_user
    global_user = User(username="test")
    db_session.add(global_user)
    db_session.commit()

def test_update_user(db_session):
    # 依赖上一个测试的结果
    global_user.email = "new@example.com"
    db_session.commit()
```

### 3. 测试覆盖率

**不要追求 100% 覆盖率**：
- 覆盖率是手段，不是目的
- 重要的是测试质量，不是数量
- 关注核心业务逻辑和边界条件

**合理的覆盖率目标**：
- 核心业务逻辑：90%+
- 工具函数：80%+
- 配置和常量：不需要测试
- 第三方库调用：Mock 测试

### 4. 测试数据管理

**使用 Factory 模式**：
```python
class UserFactory:
    @staticmethod
    def create(username="test", email="test@example.com"):
        return User(username=username, email=email)

def test_user_creation():
    user = UserFactory.create(username="alice")
    assert user.username == "alice"
```

**使用 Fixture**：
```python
@pytest.fixture
def sample_user():
    return User(username="test", email="test@example.com")

def test_user_email(sample_user):
    assert sample_user.email == "test@example.com"
```

---

## 常见误区

### 误区1："测试会拖慢开发速度"

**真相**：
- 短期看：写测试需要时间
- 长期看：测试加速迭代，减少 bug 修复时间
- 生产环境的 bug 修复成本是开发阶段的 10-100 倍

### 误区2："100% 覆盖率就是好测试"

**真相**：
- 覆盖率只是量化指标，不代表质量
- 可以写出覆盖率 100% 但毫无意义的测试
- 重要的是测试关键路径和边界条件

### 误区3："集成测试可以替代单元测试"

**真相**：
- 单元测试快速、独立、易于定位问题
- 集成测试慢、依赖多、难以定位问题
- 两者各有用途，不能互相替代

### 误区4："AI Agent 输出不确定，无法测试"

**真相**：
- 可以测试输出的结构和格式
- 可以测试关键信息是否存在
- 可以使用确定性的 temperature=0
- 可以测试流程和逻辑，而非具体内容

---

## 学习资源

### 官方文档
- pytest 官方文档：https://docs.pytest.org/
- FastAPI 测试文档：https://fastapi.tiangolo.com/tutorial/testing/
- SQLAlchemy 测试文档：https://docs.sqlalchemy.org/en/20/orm/session_transaction.html

### 推荐书籍
- 《测试驱动开发》（Kent Beck）
- 《单元测试的艺术》（Roy Osherove）
- 《Python 测试驱动开发》（Harry Percival）

### 实战项目
- FastAPI 官方示例：https://github.com/tiangolo/fastapi
- LangChain 测试套件：https://github.com/langchain-ai/langchain

---

## 下一步

完成本知识点的学习后，你将能够：

1. ✅ 使用 pytest 编写单元测试
2. ✅ 测试 FastAPI 端点和依赖注入
3. ✅ 测试数据库操作和事务
4. ✅ 测试 AI Agent 的检索和生成
5. ✅ 测试异步代码和流式输出
6. ✅ 构建完整的测试体系
7. ✅ 集成 CI/CD 自动化测试

**开始学习吧！测试是生产级代码的最后一道防线。**
