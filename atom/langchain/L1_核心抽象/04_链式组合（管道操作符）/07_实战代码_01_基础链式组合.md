# 实战代码1：基础链式组合

## 概述

本节提供完整可运行的基础链式组合示例，涵盖最常见的使用场景。

**学习目标**：
- 掌握基础的 `prompt | model | parser` 链
- 理解数据如何在管道中流转
- 能够处理常见错误

---

## 1. 最简单的链

### 1.1 完整示例

```python
"""
最简单的 LangChain 管道
演示：prompt | model | parser 基础链
"""

import os
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 加载环境变量
load_dotenv()

# ===== 1. 创建组件 =====
print("=== 创建组件 ===")

# 提示模板
prompt = ChatPromptTemplate.from_template("讲一个关于{topic}的笑话")
print(f"Prompt 类型: {type(prompt)}")

# 语言模型
model = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
print(f"Model 类型: {type(model)}")

# 输出解析器
parser = StrOutputParser()
print(f"Parser 类型: {type(parser)}")

# ===== 2. 组合成链 =====
print("\n=== 组合成链 ===")

chain = prompt | model | parser
print(f"Chain 类型: {type(chain)}")
print(f"Chain 步骤: {chain.steps}")

# ===== 3. 调用链 =====
print("\n=== 调用链 ===")

result = chain.invoke({"topic": "程序员"})
print(f"结果: {result}")

# ===== 4. 多次调用 =====
print("\n=== 多次调用 ===")

topics = ["AI", "Python", "数据库"]
for topic in topics:
    result = chain.invoke({"topic": topic})
    print(f"\n{topic} 笑话:")
    print(result)
```

**运行输出示例**：
```
=== 创建组件 ===
Prompt 类型: <class 'langchain_core.prompts.chat.ChatPromptTemplate'>
Model 类型: <class 'langchain_openai.chat_models.base.ChatOpenAI'>
Parser 类型: <class 'langchain_core.output_parsers.string.StrOutputParser'>

=== 组合成链 ===
Chain 类型: <class 'langchain_core.runnables.base.RunnableSequence'>
Chain 步骤: [ChatPromptTemplate, ChatOpenAI, StrOutputParser]

=== 调用链 ===
结果: 为什么程序员总是分不清万圣节和圣诞节？因为 Oct 31 == Dec 25！

=== 多次调用 ===

AI 笑话:
为什么 AI 不会感到孤独？因为它总是在云端！

Python 笑话:
为什么 Python 程序员喜欢大自然？因为他们喜欢 import this！

数据库 笑话:
为什么数据库管理员总是很冷静？因为他们知道如何处理关系！
```

---

## 2. 多变量提示链

### 2.1 完整示例

```python
"""
多变量提示链
演示：使用多个变量构建复杂提示
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# ===== 1. 创建多变量提示 =====
print("=== 多变量提示 ===")

prompt = ChatPromptTemplate.from_template(
    """你是一个{role}。

任务：{task}

要求：
- 风格：{style}
- 长度：{length}

请开始："""
)

# 查看提示变量
print(f"提示变量: {prompt.input_variables}")

# ===== 2. 构建链 =====
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = prompt | model | parser

# ===== 3. 使用链 =====
print("\n=== 场景1: 技术博客 ===")

result = chain.invoke({
    "role": "技术博客作者",
    "task": "解释什么是向量数据库",
    "style": "通俗易懂",
    "length": "200字以内"
})
print(result)

print("\n=== 场景2: 诗人 ===")

result = chain.invoke({
    "role": "诗人",
    "task": "描述春天",
    "style": "古典诗词",
    "length": "四句"
})
print(result)

print("\n=== 场景3: 产品经理 ===")

result = chain.invoke({
    "role": "产品经理",
    "task": "写一个 AI 助手的产品需求文档",
    "style": "专业严谨",
    "length": "300字以内"
})
print(result)
```

---

## 3. 链式数据转换

### 3.1 完整示例

```python
"""
链式数据转换
演示：在管道中逐步转换数据
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# ===== 1. 定义转换步骤 =====
print("=== 定义转换步骤 ===")

def normalize_input(text: str) -> dict:
    """步骤1: 标准化输入"""
    print(f"[标准化] 输入: {text}")
    normalized = text.strip().lower()
    return {"text": normalized}

def add_context(data: dict) -> dict:
    """步骤2: 添加上下文"""
    print(f"[添加上下文] 输入: {data}")
    data["context"] = "你是一个友好的助手"
    return data

def format_prompt(data: dict) -> dict:
    """步骤3: 格式化提示"""
    print(f"[格式化] 输入: {data}")
    return {
        "role": data["context"],
        "question": data["text"]
    }

# ===== 2. 构建转换链 =====
print("\n=== 构建转换链 ===")

# 转换步骤
normalize = RunnableLambda(normalize_input)
add_ctx = RunnableLambda(add_context)
format_p = RunnableLambda(format_prompt)

# 提示和模型
prompt = ChatPromptTemplate.from_template("{role}\n\n问题：{question}")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

# 完整链
chain = (
    normalize
    | add_ctx
    | format_p
    | prompt
    | model
    | parser
)

# ===== 3. 使用链 =====
print("\n=== 使用链 ===")

result = chain.invoke("  WHAT IS AI?  ")
print(f"\n最终结果: {result}")
```

**运行输出示例**：
```
=== 定义转换步骤 ===

=== 构建转换链 ===

=== 使用链 ===
[标准化] 输入:   WHAT IS AI?
[添加上下文] 输入: {'text': 'what is ai?'}
[格式化] 输入: {'text': 'what is ai?', 'context': '你是一个友好的助手'}

最终结果: AI（人工智能）是指让计算机模拟人类智能的技术...
```

---

## 4. 错误处理

### 4.1 完整示例

```python
"""
错误处理
演示：处理链执行中的错误
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# ===== 1. 创建可能失败的链 =====
print("=== 创建链 ===")

def validate_input(data: dict) -> dict:
    """验证输入"""
    if "topic" not in data:
        raise ValueError("缺少 topic 字段")
    if len(data["topic"]) < 2:
        raise ValueError("topic 太短")
    return data

validator = RunnableLambda(validate_input)
prompt = ChatPromptTemplate.from_template("讲个关于{topic}的笑话")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = validator | prompt | model | parser

# ===== 2. 正常调用 =====
print("\n=== 正常调用 ===")

try:
    result = chain.invoke({"topic": "程序员"})
    print(f"成功: {result}")
except Exception as e:
    print(f"失败: {e}")

# ===== 3. 错误调用1: 缺少字段 =====
print("\n=== 错误调用1: 缺少字段 ===")

try:
    result = chain.invoke({"name": "test"})  # 缺少 topic
    print(f"成功: {result}")
except Exception as e:
    print(f"失败: {e}")

# ===== 4. 错误调用2: 值太短 =====
print("\n=== 错误调用2: 值太短 ===")

try:
    result = chain.invoke({"topic": "A"})  # topic 太短
    print(f"成功: {result}")
except Exception as e:
    print(f"失败: {e}")

# ===== 5. 带降级的错误处理 =====
print("\n=== 带降级的错误处理 ===")

def safe_invoke(chain, input_data, default="抱歉，出错了"):
    """安全调用，失败时返回默认值"""
    try:
        return chain.invoke(input_data)
    except Exception as e:
        print(f"错误: {e}")
        return default

# 使用安全调用
result = safe_invoke(chain, {"topic": "A"}, default="无法生成笑话")
print(f"结果: {result}")
```

**运行输出示例**：
```
=== 创建链 ===

=== 正常调用 ===
成功: 为什么程序员总是分不清万圣节和圣诞节？...

=== 错误调用1: 缺少字段 ===
失败: 缺少 topic 字段

=== 错误调用2: 值太短 ===
失败: topic 太短

=== 带降级的错误处理 ===
错误: topic 太短
结果: 无法生成笑话
```

---

## 5. 批量处理

### 5.1 完整示例

```python
"""
批量处理
演示：使用 batch 方法批量处理多个输入
"""

import time
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# ===== 1. 创建链 =====
prompt = ChatPromptTemplate.from_template("用一句话解释：{term}")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = prompt | model | parser

# ===== 2. 准备测试数据 =====
terms = [
    {"term": "向量数据库"},
    {"term": "Embedding"},
    {"term": "RAG"},
    {"term": "LangChain"},
    {"term": "Prompt Engineering"}
]

# ===== 3. 方式1: 循环调用（慢） =====
print("=== 方式1: 循环调用 ===")

start = time.time()
results_loop = []
for term in terms:
    result = chain.invoke(term)
    results_loop.append(result)
loop_time = time.time() - start

print(f"循环调用耗时: {loop_time:.2f}秒")
for i, result in enumerate(results_loop):
    print(f"{i+1}. {result}")

# ===== 4. 方式2: 批量调用（快） =====
print("\n=== 方式2: 批量调用 ===")

start = time.time()
results_batch = chain.batch(terms)
batch_time = time.time() - start

print(f"批量调用耗时: {batch_time:.2f}秒")
for i, result in enumerate(results_batch):
    print(f"{i+1}. {result}")

# ===== 5. 性能对比 =====
print("\n=== 性能对比 ===")
print(f"循环调用: {loop_time:.2f}秒")
print(f"批量调用: {batch_time:.2f}秒")
print(f"性能提升: {loop_time / batch_time:.2f}x")
```

---

## 6. 流式输出

### 6.1 完整示例

```python
"""
流式输出
演示：使用 stream 方法实现打字机效果
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# ===== 1. 创建链 =====
prompt = ChatPromptTemplate.from_template("写一段关于{topic}的介绍（100字）")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = prompt | model | parser

# ===== 2. 同步调用（等待完整响应） =====
print("=== 同步调用 ===")
print("等待响应...")

result = chain.invoke({"topic": "人工智能"})
print(result)

# ===== 3. 流式调用（实时输出） =====
print("\n=== 流式调用 ===")
print("实时输出: ", end="")

for chunk in chain.stream({"topic": "人工智能"}):
    print(chunk, end="", flush=True)

print()  # 换行

# ===== 4. 流式调用 + 计数 =====
print("\n=== 流式调用 + 计数 ===")

chunk_count = 0
total_chars = 0

for chunk in chain.stream({"topic": "机器学习"}):
    chunk_count += 1
    total_chars += len(chunk)
    print(chunk, end="", flush=True)

print(f"\n\n统计: {chunk_count} 个块, {total_chars} 个字符")
```

---

## 7. 异步执行

### 7.1 完整示例

```python
"""
异步执行
演示：使用 ainvoke 实现并发处理
"""

import asyncio
import time
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# ===== 1. 创建链 =====
prompt = ChatPromptTemplate.from_template("用一句话解释：{term}")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = prompt | model | parser

# ===== 2. 同步执行（串行） =====
async def sync_execution():
    """同步执行多个请求"""
    print("=== 同步执行 ===")
    start = time.time()

    terms = ["AI", "ML", "DL", "NLP", "CV"]
    results = []

    for term in terms:
        result = await chain.ainvoke({"term": term})
        results.append(result)
        print(f"{term}: {result}")

    elapsed = time.time() - start
    print(f"耗时: {elapsed:.2f}秒\n")
    return results

# ===== 3. 异步执行（并发） =====
async def async_execution():
    """异步并发执行多个请求"""
    print("=== 异步执行 ===")
    start = time.time()

    terms = ["AI", "ML", "DL", "NLP", "CV"]

    # 创建并发任务
    tasks = [chain.ainvoke({"term": term}) for term in terms]

    # 并发执行
    results = await asyncio.gather(*tasks)

    for term, result in zip(terms, results):
        print(f"{term}: {result}")

    elapsed = time.time() - start
    print(f"耗时: {elapsed:.2f}秒\n")
    return results

# ===== 4. 运行对比 =====
async def main():
    """主函数"""
    # 同步执行
    sync_results = await sync_execution()

    # 异步执行
    async_results = await async_execution()

    print("=== 性能对比 ===")
    print("异步执行显著快于同步执行")

# 运行
asyncio.run(main())
```

---

## 8. 组合多个链

### 8.1 完整示例

```python
"""
组合多个链
演示：将多个小链组合成大链
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# ===== 1. 创建子链 =====
print("=== 创建子链 ===")

# 子链1: 生成标题
title_prompt = ChatPromptTemplate.from_template("为以下主题生成一个吸引人的标题：{topic}")
title_model = ChatOpenAI(model="gpt-4o-mini")
title_parser = StrOutputParser()

title_chain = title_prompt | title_model | title_parser
print("子链1: 标题生成器")

# 子链2: 生成内容
content_prompt = ChatPromptTemplate.from_template("写一段关于'{title}'的内容（100字）")
content_model = ChatOpenAI(model="gpt-4o-mini")
content_parser = StrOutputParser()

content_chain = content_prompt | content_model | content_parser
print("子链2: 内容生成器")

# 子链3: 生成摘要
summary_prompt = ChatPromptTemplate.from_template("用一句话总结：{content}")
summary_model = ChatOpenAI(model="gpt-4o-mini")
summary_parser = StrOutputParser()

summary_chain = summary_prompt | summary_model | summary_parser
print("子链3: 摘要生成器")

# ===== 2. 组合成完整流程 =====
print("\n=== 组合成完整流程 ===")

def build_article(topic: str) -> dict:
    """构建完整文章"""
    # 步骤1: 生成标题
    title = title_chain.invoke({"topic": topic})
    print(f"标题: {title}")

    # 步骤2: 生成内容
    content = content_chain.invoke({"title": title})
    print(f"内容: {content[:50]}...")

    # 步骤3: 生成摘要
    summary = summary_chain.invoke({"content": content})
    print(f"摘要: {summary}")

    return {
        "topic": topic,
        "title": title,
        "content": content,
        "summary": summary
    }

# ===== 3. 使用完整流程 =====
print("\n=== 使用完整流程 ===")

article = build_article("人工智能的未来")

print("\n=== 完整文章 ===")
print(f"主题: {article['topic']}")
print(f"标题: {article['title']}")
print(f"内容: {article['content']}")
print(f"摘要: {article['summary']}")
```

---

## 9. 调试技巧

### 9.1 完整示例

```python
"""
调试技巧
演示：如何调试管道执行
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# ===== 1. 添加调试输出 =====
def debug_step(name):
    """创建调试步骤"""
    def _debug(x):
        print(f"\n[{name}]")
        print(f"  类型: {type(x)}")
        print(f"  内容: {str(x)[:100]}...")
        return x
    return RunnableLambda(_debug)

# ===== 2. 构建带调试的链 =====
prompt = ChatPromptTemplate.from_template("讲个关于{topic}的笑话")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = (
    debug_step("输入")
    | prompt
    | debug_step("Prompt后")
    | model
    | debug_step("Model后")
    | parser
    | debug_step("Parser后")
)

# ===== 3. 执行并观察 =====
print("=== 执行链 ===")
result = chain.invoke({"topic": "程序员"})

print("\n=== 最终结果 ===")
print(result)

# ===== 4. 检查链结构 =====
print("\n=== 检查链结构 ===")
print(f"链类型: {type(chain)}")
print(f"步骤数量: {len(chain.steps)}")
print("步骤列表:")
for i, step in enumerate(chain.steps):
    print(f"  {i+1}. {type(step).__name__}")
```

---

## 10. 完整项目示例

### 10.1 完整示例

```python
"""
完整项目示例：智能问答系统
演示：一个完整的基于管道的问答系统
"""

import os
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# 加载环境变量
load_dotenv()

# ===== 1. 定义组件 =====

def validate_question(question: str) -> dict:
    """验证问题"""
    if not question or len(question.strip()) < 3:
        raise ValueError("问题太短")
    return {"question": question.strip()}

def classify_question(data: dict) -> dict:
    """分类问题"""
    question = data["question"].lower()
    if any(word in question for word in ["什么", "是", "定义"]):
        data["type"] = "定义"
    elif any(word in question for word in ["如何", "怎么", "方法"]):
        data["type"] = "方法"
    elif any(word in question for word in ["为什么", "原因"]):
        data["type"] = "原因"
    else:
        data["type"] = "其他"
    return data

def build_prompt(data: dict) -> dict:
    """根据问题类型构建提示"""
    templates = {
        "定义": "请简洁地定义：{question}",
        "方法": "请说明如何：{question}",
        "原因": "请解释为什么：{question}",
        "其他": "请回答：{question}"
    }
    template = templates.get(data["type"], templates["其他"])
    return {"question": data["question"], "template": template}

# ===== 2. 构建链 =====

# 预处理链
validator = RunnableLambda(validate_question)
classifier = RunnableLambda(classify_question)
prompt_builder = RunnableLambda(build_prompt)

# 生成链
def create_prompt(data: dict) -> ChatPromptTemplate:
    return ChatPromptTemplate.from_template(data["template"])

model = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
parser = StrOutputParser()

# 完整链
def qa_chain(question: str) -> str:
    """问答链"""
    # 预处理
    data = validator.invoke(question)
    data = classifier.invoke(data)
    data = prompt_builder.invoke(data)

    # 生成答案
    prompt = ChatPromptTemplate.from_template(data["template"])
    chain = prompt | model | parser
    answer = chain.invoke({"question": data["question"]})

    return answer

# ===== 3. 使用系统 =====

def main():
    """主函数"""
    print("=== 智能问答系统 ===")
    print("输入 'quit' 退出\n")

    while True:
        # 获取用户输入
        question = input("问题: ").strip()

        if question.lower() == 'quit':
            print("再见！")
            break

        if not question:
            continue

        try:
            # 处理问题
            answer = qa_chain(question)
            print(f"\n答案: {answer}\n")
        except Exception as e:
            print(f"\n错误: {e}\n")

if __name__ == "__main__":
    # 测试几个问题
    test_questions = [
        "什么是人工智能？",
        "如何学习 Python？",
        "为什么要使用 LangChain？"
    ]

    print("=== 测试问题 ===\n")
    for q in test_questions:
        print(f"问题: {q}")
        try:
            answer = qa_chain(q)
            print(f"答案: {answer}\n")
        except Exception as e:
            print(f"错误: {e}\n")

    # 交互模式（可选）
    # main()
```

---

## 学习检查

完成本节后，检查是否掌握：

- [ ] 能写出 `prompt | model | parser` 基础链
- [ ] 能处理多变量提示
- [ ] 能在管道中进行数据转换
- [ ] 能处理链执行中的错误
- [ ] 能使用 batch 方法批量处理
- [ ] 能使用 stream 方法实现流式输出
- [ ] 能使用 ainvoke 实现异步执行
- [ ] 能组合多个链
- [ ] 能调试管道执行
- [ ] 能构建完整的应用

---

[Source: LangChain Official Docs - https://python.langchain.com/docs/concepts/]
[Source: Pinecone LCEL Tutorial - https://www.pinecone.io/learn/series/langchain/langchain-expression-language]
