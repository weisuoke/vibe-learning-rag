# 最小可用知识

> 掌握20%的核心知识，解决80%的混合检索问题

---

## 学习目标

掌握以下内容，就能开始使用混合检索策略：

1. 理解混合检索的基本概念
2. 实现简单的BM25+向量检索
3. 使用RRF融合结果
4. 在RAG系统中应用

**学习时间**：30-60分钟
**前置知识**：Python基础、了解RAG概念

---

## 4.1 核心概念：混合检索 = 多路检索 + 融合

### 最简单的理解

```
混合检索 = BM25检索 + 向量检索 + RRF融合

BM25检索：精确关键词匹配
向量检索：语义相似匹配
RRF融合：整合两者结果
```

### 为什么需要混合检索？

```python
# 问题：单一检索方法的局限

# 场景1：精确关键词查询
query = "iPhone 15 Pro"
# BM25：✅ 精确匹配
# 向量：⚠️ 可能匹配到相似产品
# 结论：BM25更好

# 场景2：语义相似查询
query = "如何提升Python代码性能"
# BM25：⚠️ 关键词匹配有限
# 向量：✅ 理解语义意图
# 结论：向量检索更好

# 场景3：混合查询
query = "Python asyncio性能优化"
# BM25：⚠️ 匹配"asyncio"
# 向量：⚠️ 理解"性能优化"
# 混合：✅ 两者结合，效果最佳
```

**结论**：不同查询需要不同方法，混合检索覆盖所有场景。

---

## 4.2 BM25稀疏检索基础

### 核心原理

```
BM25 = 基于关键词的精确匹配

工作方式：
1. 分词：将文本分成词
2. 计算词频：统计每个词出现次数
3. 计算IDF：词的重要性
4. 排序：按分数排序
```

### 最小实现

```python
"""
BM25最小实现
只需要理解这个就够了
"""

# 使用BM25S库（推荐）
import bm25s
from bm25s.tokenization import Tokenizer

# 1. 准备文档
documents = [
    "Python异步编程完全指南",
    "Python async/await教程",
    "asyncio协程详解"
]

# 2. 分词
tokenizer = Tokenizer()
corpus_tokens = tokenizer.tokenize(documents)

# 3. 创建BM25索引
retriever = bm25s.BM25()
retriever.index(corpus_tokens)

# 4. 查询
query = "Python异步编程"
query_tokens = tokenizer.tokenize([query])

# 5. 检索Top-K
results, scores = retriever.retrieve(query_tokens, k=3)

# 输出结果
for i, (doc_id, score) in enumerate(zip(results[0], scores[0])):
    print(f"{i+1}. {documents[doc_id]} (分数: {score:.4f})")
```

**输出示例**：
```
1. Python异步编程完全指南 (分数: 2.8456)
2. Python async/await教程 (分数: 1.2341)
3. asyncio协程详解 (分数: 0.8765)
```

### 关键参数

```python
# BM25有两个关键参数（使用默认值即可）
retriever = bm25s.BM25(
    k1=1.2,  # 词频饱和参数（默认1.2）
    b=0.75   # 文档长度归一化（默认0.75）
)

# 大多数情况下不需要调整
```

---

## 4.3 向量稠密检索基础

### 核心原理

```
向量检索 = 将文本转换为向量 + 计算相似度

工作方式：
1. Embedding：文本 → 向量
2. 存储：向量存入向量库
3. 查询：查询文本 → 向量
4. 检索：找到最相似的向量
5. 返回：对应的文档
```

### 最小实现

```python
"""
向量检索最小实现
使用OpenAI Embedding + ChromaDB
"""

import chromadb
from chromadb.utils import embedding_functions

# 1. 创建ChromaDB客户端
client = chromadb.Client()

# 2. 创建集合（使用OpenAI Embedding）
openai_ef = embedding_functions.OpenAIEmbeddingFunction(
    api_key="your-api-key",
    model_name="text-embedding-3-small"
)

collection = client.get_or_create_collection(
    name="documents",
    embedding_function=openai_ef
)

# 3. 添加文档
documents = [
    "Python异步编程完全指南",
    "Python async/await教程",
    "asyncio协程详解"
]

ids = [f"doc_{i}" for i in range(len(documents))]

collection.add(
    documents=documents,
    ids=ids
)

# 4. 查询
query = "Python异步编程"
results = collection.query(
    query_texts=[query],
    n_results=3
)

# 输出结果
for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):
    similarity = 1 - distance  # 距离转相似度
    print(f"{i+1}. {doc} (相似度: {similarity:.4f})")
```

**输出示例**：
```
1. Python异步编程完全指南 (相似度: 0.8765)
2. Python async/await教程 (相似度: 0.8234)
3. asyncio协程详解 (相似度: 0.7891)
```

### 关键选择

```python
# Embedding模型选择（推荐）
model = "text-embedding-3-small"  # OpenAI，通用场景
# model = "BAAI/bge-m3"  # 开源，中文优化

# 向量库选择（推荐）
# ChromaDB：简单易用，适合小规模
# FAISS：高性能，适合中规模
# Milvus：分布式，适合大规模
```

---

## 4.4 RRF融合算法

### 核心原理

```
RRF = 基于排名位置融合

公式：RRF_score(d) = Σ (1 / (k + rank_i(d)))

其中：
- d: 文档
- rank_i(d): 文档在第i个检索结果中的排名
- k: 常数（默认60）
```

### 为什么使用RRF？

```
问题：BM25和向量检索的分数无法直接比较

BM25分数：[0, +∞)
向量分数：[0, 1]

解决方案：使用排名而非分数
- 排名1 > 排名2 > 排名3
- 排名是统一的尺度
```

### 最小实现

```python
"""
RRF融合最小实现
"""

from collections import defaultdict

def rrf_fusion(
    bm25_results: list,  # [(doc_id, score), ...]
    vector_results: list,  # [(doc_id, score), ...]
    k: int = 60,
    top_k: int = 5
) -> list:
    """
    RRF融合两个检索结果

    Args:
        bm25_results: BM25检索结果
        vector_results: 向量检索结果
        k: RRF参数（默认60）
        top_k: 返回Top-K

    Returns:
        融合后的结果 [(doc_id, rrf_score), ...]
    """
    rrf_scores = defaultdict(float)

    # 计算BM25的RRF分数
    for rank, (doc_id, _) in enumerate(bm25_results, start=1):
        rrf_scores[doc_id] += 1.0 / (k + rank)

    # 计算向量检索的RRF分数
    for rank, (doc_id, _) in enumerate(vector_results, start=1):
        rrf_scores[doc_id] += 1.0 / (k + rank)

    # 排序
    sorted_results = sorted(
        rrf_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )

    return sorted_results[:top_k]


# 使用示例
bm25_results = [
    ("doc_A", 8.5),
    ("doc_B", 7.2),
    ("doc_C", 6.8)
]

vector_results = [
    ("doc_D", 0.95),
    ("doc_A", 0.88),
    ("doc_E", 0.82)
]

# 融合
fused = rrf_fusion(bm25_results, vector_results, k=60, top_k=5)

print("RRF融合结果：")
for i, (doc_id, score) in enumerate(fused, 1):
    print(f"{i}. {doc_id}: {score:.6f}")
```

**输出示例**：
```
RRF融合结果：
1. doc_A: 0.032520  ← 在两个结果中都出现
2. doc_D: 0.016393
3. doc_B: 0.016129
4. doc_C: 0.015873
5. doc_E: 0.015873
```

---

## 4.5 完整混合检索流程

### 标准流程

```
1. 准备文档
   ↓
2. 创建BM25索引
   ↓
3. 创建向量索引
   ↓
4. 用户查询
   ↓
5. BM25检索（并行）
   ↓
6. 向量检索（并行）
   ↓
7. RRF融合
   ↓
8. 返回Top-K结果
```

### 完整代码示例

```python
"""
混合检索完整示例
BM25 + 向量检索 + RRF融合
"""

import bm25s
from bm25s.tokenization import Tokenizer
import chromadb
from chromadb.utils import embedding_functions
from collections import defaultdict

class HybridRetriever:
    """混合检索器"""

    def __init__(self, openai_api_key: str):
        """初始化"""
        # BM25
        self.bm25_tokenizer = Tokenizer()
        self.bm25_retriever = bm25s.BM25()

        # ChromaDB
        self.chroma_client = chromadb.Client()
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=openai_api_key,
            model_name="text-embedding-3-small"
        )
        self.collection = self.chroma_client.get_or_create_collection(
            name="documents",
            embedding_function=openai_ef
        )

        self.documents = []

    def add_documents(self, documents: list):
        """添加文档"""
        self.documents = documents

        # 1. 创建BM25索引
        corpus_tokens = self.bm25_tokenizer.tokenize(documents)
        self.bm25_retriever.index(corpus_tokens)

        # 2. 创建向量索引
        ids = [f"doc_{i}" for i in range(len(documents))]
        self.collection.add(
            documents=documents,
            ids=ids
        )

    def search(self, query: str, top_k: int = 5) -> list:
        """
        混合检索

        Args:
            query: 查询文本
            top_k: 返回Top-K

        Returns:
            [(doc_id, score), ...]
        """
        # 1. BM25检索
        query_tokens = self.bm25_tokenizer.tokenize([query])
        bm25_results, bm25_scores = self.bm25_retriever.retrieve(
            query_tokens,
            k=top_k * 2
        )

        bm25_list = [
            (int(doc_id), float(score))
            for doc_id, score in zip(bm25_results[0], bm25_scores[0])
        ]

        # 2. 向量检索
        vector_results = self.collection.query(
            query_texts=[query],
            n_results=top_k * 2
        )

        vector_list = [
            (int(doc_id.split('_')[1]), 1 - distance)
            for doc_id, distance in zip(
                vector_results['ids'][0],
                vector_results['distances'][0]
            )
        ]

        # 3. RRF融合
        rrf_scores = defaultdict(float)
        k = 60

        for rank, (doc_id, _) in enumerate(bm25_list, start=1):
            rrf_scores[doc_id] += 1.0 / (k + rank)

        for rank, (doc_id, _) in enumerate(vector_list, start=1):
            rrf_scores[doc_id] += 1.0 / (k + rank)

        # 4. 排序
        sorted_results = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return sorted_results[:top_k]


# ===== 使用示例 =====

if __name__ == "__main__":
    # 1. 创建混合检索器
    retriever = HybridRetriever(openai_api_key="your-api-key")

    # 2. 添加文档
    documents = [
        "Python异步编程完全指南",
        "Python async/await教程",
        "asyncio协程详解",
        "Python并发编程",
        "事件循环机制"
    ]

    retriever.add_documents(documents)

    # 3. 查询
    query = "Python异步编程"
    results = retriever.search(query, top_k=3)

    # 4. 输出结果
    print(f"查询: {query}\n")
    print("混合检索结果：")
    for i, (doc_id, score) in enumerate(results, 1):
        print(f"{i}. {documents[doc_id]}")
        print(f"   RRF分数: {score:.6f}")
```

---

## 4.6 在RAG中应用

### RAG系统集成

```python
"""
混合检索在RAG中的应用
"""

from openai import OpenAI

class SimpleRAG:
    """简单RAG系统"""

    def __init__(self, openai_api_key: str):
        self.retriever = HybridRetriever(openai_api_key)
        self.llm_client = OpenAI(api_key=openai_api_key)

    def add_documents(self, documents: list):
        """添加文档"""
        self.retriever.add_documents(documents)

    def query(self, question: str, top_k: int = 3) -> str:
        """
        RAG查询

        Args:
            question: 用户问题
            top_k: 检索Top-K文档

        Returns:
            LLM生成的回答
        """
        # 1. 混合检索
        results = self.retriever.search(question, top_k=top_k)

        # 2. 构建上下文
        context = "\n\n".join([
            f"文档{i+1}: {self.retriever.documents[doc_id]}"
            for i, (doc_id, _) in enumerate(results)
        ])

        # 3. 构建Prompt
        prompt = f"""
基于以下文档回答问题：

{context}

问题：{question}

回答：
"""

        # 4. LLM生成
        response = self.llm_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "你是一个helpful的助手"},
                {"role": "user", "content": prompt}
            ]
        )

        return response.choices[0].message.content


# 使用示例
rag = SimpleRAG(openai_api_key="your-api-key")

# 添加文档
documents = [
    "Python异步编程使用asyncio库实现",
    "asyncio提供了事件循环、协程、任务等核心概念",
    "async/await是Python 3.5引入的语法"
]

rag.add_documents(documents)

# 查询
question = "Python异步编程怎么实现？"
answer = rag.query(question)

print(f"问题: {question}")
print(f"回答: {answer}")
```

---

## 这些知识足以

### 能做什么

✅ **实现基础混合检索系统**
- BM25 + 向量检索
- RRF融合
- 完整检索流程

✅ **在RAG中应用**
- 集成到RAG系统
- 提升检索效果
- 快速原型开发

✅ **理解核心原理**
- 为什么需要混合检索
- 如何融合结果
- 基本参数配置

### 不包含什么

❌ **高级优化**
- 查询扩展
- 自适应权重
- 复杂架构模式

❌ **生产级配置**
- 性能优化
- 错误处理
- 监控日志

❌ **深入原理**
- BM25算法推导
- Embedding模型原理
- 向量索引算法

**这些内容在其他文档中详细讲解**

---

## 快速检查清单

### 学习检查

- [ ] 理解混合检索 = BM25 + 向量 + 融合
- [ ] 能够实现BM25检索
- [ ] 能够实现向量检索
- [ ] 能够使用RRF融合
- [ ] 能够集成到RAG系统

### 代码检查

- [ ] 安装必要的库（bm25s, chromadb, openai）
- [ ] 运行BM25示例代码
- [ ] 运行向量检索示例代码
- [ ] 运行RRF融合示例代码
- [ ] 运行完整混合检索示例

### 实践检查

- [ ] 在自己的数据上测试
- [ ] 对比单一检索和混合检索效果
- [ ] 调整Top-K参数
- [ ] 集成到实际项目

---

## 下一步学习

### 深入理解

1. **BM25算法原理** → `03_核心概念_01_BM25稀疏检索.md`
2. **向量检索原理** → `03_核心概念_02_向量稠密检索.md`
3. **RRF融合算法** → `03_核心概念_03_RRF融合算法.md`

### 进阶技术

1. **查询扩展** → `03_核心概念_06_查询扩展.md`
2. **自适应权重** → `03_核心概念_07_自适应权重.md`
3. **架构模式** → `03_核心概念_08_混合检索架构模式.md`

### 实战应用

1. **基础混合检索** → `07_实战代码_01_基础混合检索.md`
2. **生产级示例** → `07_实战代码_06_生产级完整示例.md`

---

## 常见问题

### Q1: 必须同时使用BM25和向量检索吗？

**A**: 是的，混合检索的核心就是结合两者。如果只用一种，就不是混合检索了。

### Q2: RRF的k参数需要调整吗？

**A**: 大多数情况下使用默认值60即可。只有在特殊场景下才需要调整。

### Q3: 向量检索一定要用OpenAI吗？

**A**: 不是。可以使用开源模型（如BGE-M3）或其他Embedding服务。

### Q4: ChromaDB适合生产环境吗？

**A**: ChromaDB适合小规模应用。大规模生产环境推荐使用Milvus或FAISS。

### Q5: 混合检索一定比单一检索好吗？

**A**: 在大多数场景下是的。实测数据显示混合检索平均提升20-30%准确率。

---

## 核心要点回顾

| 维度 | 内容 |
|------|------|
| **核心概念** | 混合检索 = BM25 + 向量 + RRF融合 |
| **BM25** | 精确关键词匹配，使用bm25s库 |
| **向量检索** | 语义相似匹配，使用ChromaDB |
| **RRF融合** | 基于排名融合，k=60（默认） |
| **应用** | 集成到RAG系统，提升检索效果 |
| **学习时间** | 30-60分钟 |

---

**版本**: v1.0
**最后更新**: 2026-02-16
**字数**: ~350行
