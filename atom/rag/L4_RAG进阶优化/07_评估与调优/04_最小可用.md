# 最小可用

## 20%核心知识解决80%问题

本文档提炼RAG评估与调优的核心知识，让你快速掌握生产环境必备技能。

---

## 一、必须掌握的3个检索指标

### 1. Recall@K (召回率)

**定义**: 所有相关文档中，被检索到的比例

**公式**:
```
Recall@K = 检索到的相关文档数 / 总相关文档数
```

**为什么重要**:
- 衡量检索系统是否"漏掉"了重要信息
- RAG系统的基础：检索不到就无法生成正确答案

**快速实现**:
```python
def calculate_recall_at_k(retrieved_docs, relevant_docs, k):
    """计算Recall@K"""
    retrieved_k = set(retrieved_docs[:k])
    relevant_set = set(relevant_docs)

    if len(relevant_set) == 0:
        return 0.0

    hits = len(retrieved_k & relevant_set)
    return hits / len(relevant_set)

# 示例
retrieved = ['doc1', 'doc2', 'doc3', 'doc4', 'doc5']
relevant = ['doc1', 'doc3', 'doc6', 'doc7']

recall_5 = calculate_recall_at_k(retrieved, relevant, k=5)
print(f"Recall@5: {recall_5:.2f}")  # 0.50 (找到2个/共4个)
```

**RAG应用场景**:
```
场景: 企业知识库问答
问题: "公司的年假政策是什么？"

相关文档: [HR手册第3章, 员工福利政策, 假期管理规定]
检索结果: [HR手册第3章, 员工福利政策, 公司简介, 薪资制度, 考勤制度]

Recall@5 = 2/3 = 0.67
→ 漏掉了"假期管理规定"，可能导致答案不完整
```

**优化建议**:
- Recall@5 < 0.7: 检索策略有问题，考虑混合检索
- Recall@5 > 0.85: 检索质量良好

### 2. Precision@K (精确率)

**定义**: 检索结果中，相关文档的比例

**公式**:
```
Precision@K = 检索到的相关文档数 / K
```

**为什么重要**:
- 衡量检索结果的"纯净度"
- 过多无关文档会干扰LLM生成，增加成本

**快速实现**:
```python
def calculate_precision_at_k(retrieved_docs, relevant_docs, k):
    """计算Precision@K"""
    retrieved_k = set(retrieved_docs[:k])
    relevant_set = set(relevant_docs)

    if k == 0:
        return 0.0

    hits = len(retrieved_k & relevant_set)
    return hits / k

# 示例
precision_5 = calculate_precision_at_k(retrieved, relevant, k=5)
print(f"Precision@5: {precision_5:.2f}")  # 0.40 (2个相关/共5个)
```

**RAG应用场景**:
```
场景: 技术文档问答
问题: "如何配置Redis缓存？"

检索结果Top5:
1. Redis配置指南 ✓ (相关)
2. Redis性能优化 ✓ (相关)
3. MySQL配置指南 ✗ (无关)
4. 缓存策略概述 ✓ (相关)
5. Nginx配置 ✗ (无关)

Precision@5 = 3/5 = 0.60
→ 40%的无关文档会浪费Token和干扰生成
```

**优化建议**:
- Precision@5 < 0.6: 检索噪音太多，考虑ReRank
- Precision@5 > 0.8: 检索精度良好

### 3. MRR (Mean Reciprocal Rank)

**定义**: 第一个相关结果的排名倒数的平均值

**公式**:
```
MRR = 1 / 第一个相关文档的排名
```

**为什么重要**:
- 用户体验：第一个结果最重要
- RAG系统：排名靠前的文档权重更高

**快速实现**:
```python
def calculate_mrr(retrieved_docs, relevant_docs):
    """计算MRR"""
    for i, doc in enumerate(retrieved_docs, 1):
        if doc in relevant_docs:
            return 1.0 / i
    return 0.0

# 示例
mrr = calculate_mrr(retrieved, relevant)
print(f"MRR: {mrr:.2f}")  # 1.0 (第1个就是相关的)
```

**RAG应用场景**:
```
场景A: 第一个就命中
检索结果: [相关文档, 无关, 无关, ...]
MRR = 1/1 = 1.0 ✓ 完美

场景B: 第三个才命中
检索结果: [无关, 无关, 相关文档, ...]
MRR = 1/3 = 0.33 ✗ 用户体验差
```

**优化建议**:
- MRR < 0.5: 排序有问题，考虑ReRank
- MRR > 0.8: 排序质量良好

---

## 二、必须掌握的2个生成指标

### 1. Faithfulness (忠实度)

**定义**: 生成内容是否忠实于检索到的上下文

**为什么重要**:
- 防止幻觉：LLM不能"编造"信息
- 可信度：答案必须有依据

**快速评估方法**:
```python
from openai import OpenAI

def evaluate_faithfulness(answer, context):
    """使用LLM评估忠实度"""
    client = OpenAI()

    prompt = f"""
你是一个严格的评估者。判断答案是否完全基于给定的上下文。

上下文:
{context}

答案:
{answer}

评估标准:
- 如果答案中的所有信息都能在上下文中找到依据，返回1
- 如果答案包含上下文中没有的信息，返回0

只返回0或1，不要解释。
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    score = int(response.choices[0].message.content.strip())
    return score

# 示例
context = "公司年假为10天，工作满5年增加到15天。"
answer_good = "公司年假为10天。"
answer_bad = "公司年假为10天，包括法定节假日。"

print(f"Good answer faithfulness: {evaluate_faithfulness(answer_good, context)}")  # 1
print(f"Bad answer faithfulness: {evaluate_faithfulness(answer_bad, context)}")    # 0
```

**RAG应用场景**:
```
场景: 医疗问答系统

上下文: "阿司匹林用于缓解轻至中度疼痛，如头痛、牙痛。"

答案A: "阿司匹林可以缓解头痛和牙痛。"
→ Faithfulness = 1.0 ✓ (完全基于上下文)

答案B: "阿司匹林可以缓解头痛、牙痛和关节炎。"
→ Faithfulness = 0.0 ✗ (关节炎未在上下文中提及)
```

**优化建议**:
- Faithfulness < 0.85: Prompt需要强调"仅基于上下文回答"
- Faithfulness > 0.95: 生成质量良好

### 2. Answer Relevancy (答案相关性)

**定义**: 生成答案是否回答了用户问题

**为什么重要**:
- 用户满意度：答非所问会导致差评
- 系统有效性：检索正确但生成跑题也没用

**快速评估方法**:
```python
def evaluate_relevancy(question, answer):
    """使用LLM评估相关性"""
    client = OpenAI()

    prompt = f"""
你是一个严格的评估者。判断答案是否直接回答了问题。

问题:
{question}

答案:
{answer}

评估标准:
- 如果答案直接回答了问题，返回1
- 如果答案偏离主题或答非所问，返回0

只返回0或1，不要解释。
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    score = int(response.choices[0].message.content.strip())
    return score

# 示例
question = "公司的年假政策是什么？"
answer_good = "公司年假为10天，工作满5年增加到15天。"
answer_bad = "公司有完善的福利制度，包括五险一金、带薪年假等。"

print(f"Good answer relevancy: {evaluate_relevancy(question, answer_good)}")  # 1
print(f"Bad answer relevancy: {evaluate_relevancy(question, answer_bad)}")    # 0
```

**RAG应用场景**:
```
场景: 客服机器人

问题: "如何退货？"

答案A: "退货流程：1. 登录账户 2. 进入订单页面 3. 点击退货申请..."
→ Relevancy = 1.0 ✓ (直接回答)

答案B: "我们提供7天无理由退货服务，退货政策详见用户协议。"
→ Relevancy = 0.5 ✗ (提到退货但没说怎么操作)
```

**优化建议**:
- Relevancy < 0.8: Prompt需要强调"直接回答问题"
- Relevancy > 0.9: 生成质量良好

---

## 三、快速评估方法: RAGAS框架基础使用

### 为什么选择RAGAS？

**优势**:
1. **端到端评估**: 同时评估检索和生成
2. **标准化指标**: 行业认可的评估标准
3. **易于集成**: 与LangChain/LlamaIndex无缝集成
4. **自动化**: 无需人工标注

### 最小可用示例

```python
from ragas import evaluate
from ragas.metrics import (
    context_precision,
    context_recall,
    faithfulness,
    answer_relevancy
)
from datasets import Dataset

# 准备评估数据
data = {
    'question': [
        "公司的年假政策是什么？",
        "如何申请病假？"
    ],
    'answer': [
        "公司年假为10天，工作满5年增加到15天。",
        "病假需要提供医院证明，通过OA系统申请。"
    ],
    'contexts': [
        ["公司年假为10天，工作满5年增加到15天。员工可在每年1月申请。"],
        ["病假申请流程：1. 就医获取证明 2. 登录OA系统 3. 提交病假申请。"]
    ],
    'ground_truth': [
        "年假10天，满5年15天",
        "提供医院证明，OA系统申请"
    ]
}

dataset = Dataset.from_dict(data)

# 执行评估
result = evaluate(
    dataset,
    metrics=[
        context_precision,
        context_recall,
        faithfulness,
        answer_relevancy
    ]
)

# 查看结果
print(result)
```

**输出示例**:
```
{
    'context_precision': 0.95,
    'context_recall': 0.90,
    'faithfulness': 0.98,
    'answer_relevancy': 0.92
}
```

### RAGAS核心指标解读

| 指标 | 含义 | 及格线 | 优秀线 |
|------|------|--------|--------|
| Context Precision | 检索上下文的精确度 | 0.70 | 0.85+ |
| Context Recall | 检索上下文的召回率 | 0.70 | 0.85+ |
| Faithfulness | 答案忠实于上下文 | 0.85 | 0.95+ |
| Answer Relevancy | 答案回答了问题 | 0.80 | 0.90+ |

---

## 四、性能监控: 延迟和成本追踪

### 延迟监控

**为什么重要**: 用户体验直接受延迟影响

**快速实现**:
```python
import time
from functools import wraps

def track_latency(func):
    """装饰器：追踪函数延迟"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        latency = time.time() - start
        print(f"{func.__name__} latency: {latency:.3f}s")
        return result, latency
    return wrapper

@track_latency
def rag_query(question):
    """RAG查询"""
    # 检索阶段
    time.sleep(0.5)  # 模拟检索

    # 生成阶段
    time.sleep(1.0)  # 模拟生成

    return "答案"

# 使用
answer, latency = rag_query("测试问题")
print(f"Total latency: {latency:.3f}s")
```

**性能标准**:
- P50延迟 < 1.5秒: 及格
- P95延迟 < 3.0秒: 及格
- P50延迟 < 0.8秒: 优秀

### 成本监控

**为什么重要**: 控制运营成本

**快速实现**:
```python
class CostTracker:
    """成本追踪器"""

    # 价格表 (2025-2026年)
    PRICES = {
        'gpt-4o': {'input': 0.005, 'output': 0.015},      # per 1K tokens
        'gpt-4o-mini': {'input': 0.00015, 'output': 0.0006},
        'text-embedding-3-small': {'input': 0.00002, 'output': 0}
    }

    def __init__(self):
        self.total_cost = 0.0
        self.call_count = 0

    def track_llm_call(self, model, input_tokens, output_tokens):
        """追踪LLM调用成本"""
        prices = self.PRICES.get(model, {'input': 0, 'output': 0})

        input_cost = (input_tokens / 1000) * prices['input']
        output_cost = (output_tokens / 1000) * prices['output']
        call_cost = input_cost + output_cost

        self.total_cost += call_cost
        self.call_count += 1

        return call_cost

    def get_average_cost(self):
        """获取平均成本"""
        if self.call_count == 0:
            return 0.0
        return self.total_cost / self.call_count

    def report(self):
        """生成成本报告"""
        return {
            'total_cost': f"${self.total_cost:.4f}",
            'call_count': self.call_count,
            'avg_cost_per_call': f"${self.get_average_cost():.4f}"
        }

# 使用示例
tracker = CostTracker()

# 模拟RAG查询
tracker.track_llm_call('text-embedding-3-small', 100, 0)  # Embedding
tracker.track_llm_call('gpt-4o-mini', 500, 200)           # Generation

print(tracker.report())
```

**成本标准**:
- 每次查询 < $0.10: 及格
- 每次查询 < $0.05: 优秀

---

## 五、最小可用代码示例

### 完整的最小评估系统

```python
from openai import OpenAI
import time

class MinimalRAGEvaluator:
    """最小可用RAG评估器"""

    def __init__(self):
        self.client = OpenAI()

    def evaluate_retrieval(self, retrieved_docs, relevant_docs, k=5):
        """评估检索质量"""
        retrieved_k = set(retrieved_docs[:k])
        relevant_set = set(relevant_docs)

        # Recall@K
        recall = len(retrieved_k & relevant_set) / len(relevant_set) if relevant_set else 0

        # Precision@K
        precision = len(retrieved_k & relevant_set) / k if k > 0 else 0

        # MRR
        mrr = 0.0
        for i, doc in enumerate(retrieved_docs, 1):
            if doc in relevant_set:
                mrr = 1.0 / i
                break

        return {
            'recall@k': recall,
            'precision@k': precision,
            'mrr': mrr
        }

    def evaluate_generation(self, question, answer, context):
        """评估生成质量"""
        # Faithfulness
        faithfulness_prompt = f"""
判断答案是否完全基于上下文。只返回0或1。

上下文: {context}
答案: {answer}
"""
        faithfulness = self._llm_judge(faithfulness_prompt)

        # Relevancy
        relevancy_prompt = f"""
判断答案是否直接回答了问题。只返回0或1。

问题: {question}
答案: {answer}
"""
        relevancy = self._llm_judge(relevancy_prompt)

        return {
            'faithfulness': faithfulness,
            'answer_relevancy': relevancy
        }

    def _llm_judge(self, prompt):
        """LLM评估"""
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return int(response.choices[0].message.content.strip())

    def evaluate_performance(self, func, *args, **kwargs):
        """评估性能"""
        start = time.time()
        result = func(*args, **kwargs)
        latency = time.time() - start

        return result, {'latency': latency}

# 使用示例
evaluator = MinimalRAGEvaluator()

# 评估检索
retrieval_scores = evaluator.evaluate_retrieval(
    retrieved_docs=['doc1', 'doc2', 'doc3'],
    relevant_docs=['doc1', 'doc4'],
    k=3
)
print("Retrieval scores:", retrieval_scores)

# 评估生成
generation_scores = evaluator.evaluate_generation(
    question="公司年假多少天？",
    answer="公司年假为10天。",
    context="公司年假为10天，工作满5年增加到15天。"
)
print("Generation scores:", generation_scores)
```

---

## 六、快速检查清单

### 开发阶段

- [ ] 实现Recall@K、Precision@K、MRR计算
- [ ] 实现Faithfulness和Answer Relevancy评估
- [ ] 集成RAGAS框架进行端到端评估
- [ ] 添加延迟和成本追踪

### 测试阶段

- [ ] Recall@5 ≥ 0.70
- [ ] Precision@5 ≥ 0.60
- [ ] Faithfulness ≥ 0.85
- [ ] Answer Relevancy ≥ 0.80
- [ ] P95延迟 < 3秒
- [ ] 每次查询成本 < $0.10

### 生产阶段

- [ ] 实时监控质量指标
- [ ] 实时监控性能指标
- [ ] 实时监控成本指标
- [ ] 设置告警阈值
- [ ] 建立评估报告

---

## 七、常见问题速查

### Q1: 评估需要多少测试数据？

**最小**: 50-100条
**推荐**: 200-500条
**理想**: 1000+条

### Q2: 评估频率？

**开发阶段**: 每次重大变更后
**测试阶段**: 每日自动评估
**生产阶段**: 实时监控 + 每周报告

### Q3: 如何快速提升Recall？

1. 增加检索数量K
2. 使用混合检索（向量+关键词）
3. 优化Embedding模型
4. 改进Query改写

### Q4: 如何快速提升Faithfulness？

1. Prompt中强调"仅基于上下文"
2. 使用更强的LLM模型
3. 减少上下文噪音（提升Precision）
4. 添加引用机制

### Q5: 如何降低延迟？

1. 使用缓存（语义缓存）
2. 批处理请求
3. 并行处理检索和生成
4. 使用更快的模型（如gpt-4o-mini）

---

## 八、下一步学习路径

掌握了最小可用知识后，可以深入学习：

1. **检索优化**: NDCG、Hit Rate等高级指标
2. **生成优化**: Correctness、Fluency等细粒度指标
3. **端到端框架**: RAGAS高级用法、DeepEval、TruLens
4. **LLM-as-judge**: 自定义评估器、多judge ensemble
5. **性能优化**: 缓存策略、批处理、并行化
6. **成本优化**: 模型选择、Token压缩、动态路由

---

## 总结

**20%核心知识**:
1. 3个检索指标: Recall@K, Precision@K, MRR
2. 2个生成指标: Faithfulness, Answer Relevancy
3. 1个评估框架: RAGAS
4. 2个监控维度: 延迟、成本

**解决80%问题**:
- 快速发现检索问题
- 快速发现生成问题
- 快速评估系统质量
- 快速监控系统性能

**记住**: 评估不是目的，优化才是。用这些指标指导你的优化方向！
