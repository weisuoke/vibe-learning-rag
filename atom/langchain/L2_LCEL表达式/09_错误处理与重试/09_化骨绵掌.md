# 化骨绵掌：10个2分钟知识卡片

## 卡片1：直觉理解 - 错误处理就像"备用计划"

**一句话：** 错误处理与重试就是为你的 AI 应用准备"Plan B"和"Plan C"

**举例：**
想象你要去机场，但主路堵车了：
- **没有备用计划**：被堵在路上，错过航班 ❌
- **有备用计划**：立即切换到地铁，准时到达 ✅

在 AI 应用中：
```python
# 没有错误处理
response = llm.invoke("你好")  # API 失败 → 应用崩溃 ❌

# 有错误处理
llm_with_retry = llm.with_retry(stop_after_attempt=3)
response = llm_with_retry.invoke("你好")  # API 失败 → 自动重试 → 成功 ✅
```

**应用：** 在生产环境中，错误处理不是"锦上添花"，而是"必需品"

---

## 卡片2：形式化定义 - 两种核心机制

**一句话：** 错误处理有两种核心机制：重试（Retry）和降级（Fallback）

**精确定义：**

1. **重试（Retry）**：当操作失败时，自动重复执行相同操作，直到成功或达到最大次数
   ```python
   llm.with_retry(stop_after_attempt=3)
   ```

2. **降级（Fallback）**：当主方案失败时，自动切换到备选方案
   ```python
   primary.with_fallbacks([fallback])
   ```

**数学表示：**
```
重试：f(x) → 失败 → f(x) → 失败 → f(x) → 成功
降级：f(x) → 失败 → g(x) → 成功
```

**应用：** 重试解决临时问题，降级提供备选方案

---

## 卡片3：关键概念1 - 重试策略

**一句话：** 重试不是简单的"再试一次"，而是智能的策略

**核心要素：**

1. **最大重试次数**：避免无限重试
   ```python
   stop_after_attempt=3  # 最多重试 3 次
   ```

2. **等待策略**：指数退避避免雪崩
   ```python
   wait_exponential_jitter=True  # 1秒 → 2秒 → 4秒
   ```

3. **异常过滤**：只重试可恢复的错误
   ```python
   retry_if_exception_type=(RateLimitError, APIError)
   ```

**举例：**
```python
llm = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True,
    retry_if_exception_type=(RateLimitError, APIError)
)
```

**应用：** 处理 API 速率限制、网络超时、临时服务器过载

---

## 卡片4：关键概念2 - 降级策略

**一句话：** 降级是"退而求其次"的艺术

**核心思想：**
- 主方案失败时，不是直接失败，而是尝试备选方案
- 备选方案可能质量略低，但仍然可用

**多级降级：**
```python
# 第1级：GPT-4（最好，最贵）
primary = ChatOpenAI(model="gpt-4")

# 第2级：GPT-3.5（次好，便宜）
fallback1 = ChatOpenAI(model="gpt-3.5-turbo")

# 第3级：GPT-3.5 temperature=0（保底）
fallback2 = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# 组合
llm = primary.with_fallbacks([fallback1, fallback2])
```

**执行流程：**
```
GPT-4 失败 → GPT-3.5 → 成功 ✅
```

**应用：** 成本优化、高可用性、多云部署

---

## 卡片5：编程实现 - LCEL 的声明式设计

**一句话：** LCEL 通过 Runnable 协议实现可组合的错误处理

**核心类：**

1. **RunnableRetry**：重试包装器
   ```python
   llm.with_retry(...)  # 返回 RunnableRetry 实例
   ```

2. **RunnableWithFallbacks**：降级包装器
   ```python
   llm.with_fallbacks([...])  # 返回 RunnableWithFallbacks 实例
   ```

**可组合性：**
```python
# 每个 Runnable 都可以添加错误处理
chain = (
    prompt
    | llm.with_retry(stop_after_attempt=3)
    | parser.with_fallbacks([backup_parser])
)
```

**内部实现：**
- 基于 `tenacity` 库实现重试逻辑
- 保持 Runnable 接口的一致性
- 支持流式、批处理、异步等所有 Runnable 特性

**应用：** 构建生产级的可靠 AI 应用

---

## 卡片6：对比区分 - 重试 vs 降级

**一句话：** 重试是"再试一次"，降级是"换个方案"

**对比表：**

| 维度 | 重试（Retry） | 降级（Fallback） |
|------|---------------|------------------|
| **目标** | 让同一操作成功 | 使用备选方案 |
| **适用场景** | 临时故障 | 永久故障或成本优化 |
| **示例错误** | RateLimitError, Timeout | ServiceUnavailable, 成本过高 |
| **等待时间** | 有（指数退避） | 无（立即切换） |
| **质量** | 相同 | 可能略低 |

**组合使用：**
```python
# 先重试主方案，失败后降级
primary = llm.with_retry(stop_after_attempt=3)
fallback = backup_llm.with_retry(stop_after_attempt=2)

chain = primary.with_fallbacks([fallback])
```

**应用：** 生产环境通常组合使用，提供多层保护

---

## 卡片7：进阶理解 - 指数退避的数学原理

**一句话：** 指数退避通过递增等待时间，避免"雪崩效应"

**数学公式：**
```
等待时间 = min(base * 2^attempt, max_wait)
```

**实际例子：**
```python
# base=1秒, max_wait=60秒
# 第1次失败：等待 1 秒
# 第2次失败：等待 2 秒
# 第3次失败：等待 4 秒
# 第4次失败：等待 8 秒
# 第5次失败：等待 16 秒
# 第6次失败：等待 32 秒
# 第7次失败：等待 60 秒（达到上限）
```

**为什么需要 jitter（抖动）？**
```python
# 没有 jitter：所有客户端同时重试
# 时间 0s：1000 个请求失败
# 时间 1s：1000 个请求同时重试 → 服务器再次过载 ❌

# 有 jitter：随机化等待时间
# 时间 0s：1000 个请求失败
# 时间 0.8-1.2s：请求分散重试 → 服务器逐渐恢复 ✅
```

**应用：** 所有生产级重试都应该使用指数退避 + jitter

---

## 卡片8：高级应用 - 断路器模式

**一句话：** 断路器模式避免对已知故障的服务持续重试

**核心思想：**
```
正常状态（Closed）→ 多次失败 → 断开状态（Open）→ 等待恢复 → 半开状态（Half-Open）→ 测试成功 → 正常状态
```

**实现示例：**
```python
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
def call_llm(input):
    return llm.invoke(input)

# 前5次失败：正常重试
# 第6次失败：断路器打开，直接返回错误（不再重试）
# 60秒后：断路器半开，尝试一次
# 成功：断路器关闭，恢复正常
```

**为什么需要断路器？**
- 避免浪费资源在已知故障的服务上
- 快速失败，快速反馈
- 给故障服务恢复时间

**应用：** 微服务架构、高并发场景

---

## 卡片9：在 LangChain 中的使用 - 实战模式

**一句话：** LangChain 的错误处理遵循"分层防护"原则

**三层防护：**

1. **组件级**：为每个组件添加重试
   ```python
   llm = ChatOpenAI(model="gpt-4").with_retry(stop_after_attempt=3)
   parser = JsonOutputParser().with_retry(stop_after_attempt=2)
   ```

2. **链级**：为整个链添加降级
   ```python
   primary_chain = prompt | llm | parser
   fallback_chain = prompt | backup_llm | simple_parser

   chain = primary_chain.with_fallbacks([fallback_chain])
   ```

3. **应用级**：全局错误处理
   ```python
   try:
       result = chain.invoke(input)
   except Exception as e:
       logger.error(f"Chain failed: {e}")
       return default_response
   ```

**最佳实践：**
- 关键组件：更多重试（5-7次）
- 普通组件：基础重试（3次）
- 整个链：至少一个降级方案

**应用：** RAG 系统、Agent 应用、批量处理

---

## 卡片10：总结与延伸 - 构建可靠的 AI 应用

**一句话：** 错误处理是生产级 AI 应用的基石

**核心要点总结：**

1. **重试**：解决临时故障（速率限制、网络超时）
2. **降级**：提供备选方案（成本优化、高可用性）
3. **组合**：多层防护（重试 + 降级）
4. **智能**：指数退避、异常过滤、断路器

**生产级检查清单：**
- [ ] 所有 LLM 调用都有重试（3-5次）
- [ ] 关键服务有降级方案
- [ ] 使用指数退避 + jitter
- [ ] 过滤不可重试的错误
- [ ] 监控重试率和降级率
- [ ] 设置告警阈值

**延伸学习：**
1. **LangGraph 错误处理**：节点级重试、图级异常处理
2. **自愈 Agent**：自动检测和修复错误
3. **成本优化**：基于成本的智能降级
4. **可观测性**：使用 LangSmith 追踪错误

**最终建议：**
```python
# 生产级模板
primary = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True,
    retry_if_exception_type=(RateLimitError, APIError, Timeout)
)
fallback = ChatOpenAI(model="gpt-3.5-turbo").with_retry(
    stop_after_attempt=2
)

llm = primary.with_fallbacks([fallback])
```

**应用：** 从第一天就考虑错误处理，而不是等到生产环境出问题

---

**记住：可靠的 AI 应用 = 核心功能 + 完善的错误处理**
