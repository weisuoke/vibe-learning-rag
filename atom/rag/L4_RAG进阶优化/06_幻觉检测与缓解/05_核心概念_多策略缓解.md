# 核心概念：多策略缓解

> 在检索、生成、验证各阶段降低幻觉风险的综合防护体系

---

## 原理讲解

### 为什么需要多策略缓解？

**核心问题：** 单一防护措施可能失效，需要多层防护

**类比：** 就像网络安全的"纵深防御"策略

```
单一防护：
只在生成后检测 → 发现问题已经晚了，浪费了 LLM 调用成本

多层防护：
检索过滤 → 约束生成 → 一致性检测 → 置信度评分 → 降级策略
每一层都降低风险，层层把关
```

### 多策略缓解的四个层次

#### 层次1：检索质量过滤（预防）

**目标：** 在检索阶段就过滤掉低质量文档

**策略：**
1. **相似度阈值**：只保留相似度 > 0.7 的文档
2. **文档长度过滤**：过滤太短的文档（< 50 字符）
3. **重复内容去重**：移除重复或高度相似的文档
4. **来源可信度**：优先选择权威来源

```python
def filter_retrieval_quality(docs, min_score=0.7, min_length=50):
    """检索质量过滤"""
    filtered = []
    for doc in docs:
        # 检查1：相似度分数
        if doc.score < min_score:
            continue

        # 检查2：文档长度
        if len(doc.content) < min_length:
            continue

        # 检查3：来源可信度（可选）
        if hasattr(doc, 'source_authority'):
            if doc.source_authority < 0.5:
                continue

        filtered.append(doc)

    return filtered
```

#### 层次2：约束生成（控制）

**目标：** 通过 Prompt 工程限制 LLM 的生成行为

**策略：**
1. **明确指令**：要求严格基于文档内容
2. **禁止编造**：明确禁止添加文档外信息
3. **要求引用**：强制添加引用标记
4. **示例引导**：提供正确的示例

```python
def create_constrained_prompt(query, docs):
    """创建约束性 Prompt"""
    context = "\n\n".join([f"文档{i+1}: {doc}" for i, doc in enumerate(docs)])

    prompt = f"""基于以下文档回答问题。

{context}

问题：{query}

严格要求：
1. 只使用文档中的信息，不要添加任何文档外的内容
2. 每个事实性陈述都要标注来源 [1], [2]
3. 如果文档中没有答案，明确说"文档中没有相关信息"
4. 不要推测、猜测或编造任何信息

正确示例：
问题：Python 3.9 什么时候发布？
文档：Python 3.9 于 2020 年 10 月发布
答案：Python 3.9 于 2020 年 10 月发布 [1]

错误示例：
答案：Python 3.9 于 2020 年 10 月发布，这是一个重大更新
（错误：添加了"重大更新"这个文档中没有的信息）

现在请回答：
"""
    return prompt
```

#### 层次3：一致性检测（验证）

**目标：** 验证生成内容与检索内容的一致性

**策略：**
1. **NLI 检测**：使用自然语言推理模型
2. **关键词匹配**：检查关键信息是否在文档中
3. **语义相似度**：计算答案与文档的相似度
4. **综合评分**：结合多个指标

```python
def comprehensive_consistency_check(answer, docs):
    """综合一致性检测"""
    # 方法1：NLI 检测（50%权重）
    nli_score = nli_model.predict(docs, answer)

    # 方法2：关键词匹配（30%权重）
    keywords = extract_keywords(answer)
    keyword_coverage = sum(
        any(kw in doc for doc in docs)
        for kw in keywords
    ) / len(keywords)

    # 方法3：语义相似度（20%权重）
    semantic_sim = calculate_similarity(answer, docs)

    # 综合评分
    final_score = (
        nli_score * 0.5 +
        keyword_coverage * 0.3 +
        semantic_sim * 0.2
    )

    return final_score
```

#### 层次4：置信度评分与降级策略（兜底）

**目标：** 综合评估可信度，低置信度时拒绝回答

**策略：**
1. **置信度计算**：综合多个指标
2. **阈值判断**：根据场景设置不同阈值
3. **降级策略**：提供备选方案
4. **日志记录**：记录低置信度案例

```python
def confidence_based_response(answer, docs, consistency_score, scenario="general"):
    """基于置信度的响应策略"""
    # 计算置信度
    citation_coverage = calculate_citation_coverage(answer)
    retrieval_quality = calculate_retrieval_quality(docs)

    confidence = (
        consistency_score * 0.5 +
        citation_coverage * 0.3 +
        retrieval_quality * 0.2
    )

    # 根据场景设置阈值
    thresholds = {
        "medical": 0.9,
        "legal": 0.85,
        "general": 0.7,
        "entertainment": 0.6
    }
    threshold = thresholds.get(scenario, 0.7)

    # 降级策略
    if confidence >= threshold:
        return {"answer": answer, "confidence": confidence}
    elif confidence >= threshold - 0.2:
        return {
            "answer": f"（不太确定）{answer}",
            "confidence": confidence,
            "warning": "置信度较低，建议谨慎参考"
        }
    else:
        return {
            "answer": "抱歉，我对这个答案不够确定",
            "confidence": confidence,
            "suggestion": "建议查阅原始文档或咨询专家"
        }
```

---

## 手写实现

### 实现1：完整的多层防护系统

```python
from typing import List, Dict, Optional
from sentence_transformers import CrossEncoder, SentenceTransformer, util
from openai import OpenAI
import numpy as np

class MultiLayerHallucinationMitigation:
    """
    多层幻觉缓解系统
    在检索、生成、验证各阶段设置防护
    """

    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.nli_model = CrossEncoder('cross-encoder/nli-deberta-v3-base')
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')

    def layer1_filter_retrieval(
        self,
        docs: List[Dict],
        min_score: float = 0.7,
        min_length: int = 50
    ) -> List[Dict]:
        """
        第1层：检索质量过滤
        """
        filtered = []

        for doc in docs:
            # 检查相似度分数
            if doc.get('score', 0) < min_score:
                continue

            # 检查文档长度
            if len(doc['content']) < min_length:
                continue

            filtered.append(doc)

        return filtered

    def layer2_constrained_generation(
        self,
        query: str,
        docs: List[Dict],
        model: str = "gpt-4"
    ) -> str:
        """
        第2层：约束生成
        """
        # 构建严格的 Prompt
        context = "\n\n".join([
            f"文档{i+1}: {doc['content']}"
            for i, doc in enumerate(docs)
        ])

        prompt = f"""基于以下文档回答问题，严格遵守要求。

{context}

问题：{query}

严格要求：
1. 只使用文档中的信息
2. 每个事实都要标注来源 [1], [2]
3. 不要添加文档外的信息
4. 文档中没有答案就说"没有相关信息"

答案："""

        response = self.client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1  # 低温度，减少随机性
        )

        return response.choices[0].message.content

    def layer3_consistency_check(
        self,
        answer: str,
        docs: List[Dict]
    ) -> float:
        """
        第3层：一致性检测
        """
        # NLI 检测
        nli_scores = []
        for doc in docs:
            scores = self.nli_model.predict([(doc['content'], answer)])
            nli_scores.append(scores[0][2])  # 蕴含分数

        nli_score = max(nli_scores) if nli_scores else 0.0

        # 关键词匹配
        answer_words = set(answer.lower().split())
        doc_words = set()
        for doc in docs:
            doc_words.update(doc['content'].lower().split())

        keyword_coverage = len(answer_words & doc_words) / len(answer_words) if answer_words else 0.0

        # 语义相似度
        answer_emb = self.encoder.encode(answer)
        doc_embs = self.encoder.encode([doc['content'] for doc in docs])
        similarities = util.cos_sim(answer_emb, doc_embs)[0].numpy()
        semantic_sim = float(np.max(similarities)) if len(similarities) > 0 else 0.0

        # 综合评分
        consistency = (
            nli_score * 0.5 +
            keyword_coverage * 0.3 +
            semantic_sim * 0.2
        )

        return consistency

    def layer4_confidence_decision(
        self,
        answer: str,
        consistency: float,
        threshold: float = 0.7
    ) -> Dict:
        """
        第4层：置信度决策
        """
        if consistency >= threshold:
            return {
                "status": "approved",
                "answer": answer,
                "confidence": consistency
            }
        elif consistency >= threshold - 0.2:
            return {
                "status": "warning",
                "answer": f"（不太确定）{answer}",
                "confidence": consistency,
                "message": "置信度较低，建议谨慎参考"
            }
        else:
            return {
                "status": "rejected",
                "answer": "抱歉，我对这个答案不够确定",
                "confidence": consistency,
                "message": "建议查阅原始文档"
            }

    def process(
        self,
        query: str,
        docs: List[Dict],
        threshold: float = 0.7
    ) -> Dict:
        """
        完整的多层防护流程
        """
        # 第1层：过滤检索结果
        filtered_docs = self.layer1_filter_retrieval(docs)

        if len(filtered_docs) == 0:
            return {
                "status": "no_docs",
                "answer": "没有找到相关信息",
                "confidence": 0.0
            }

        # 第2层：约束生成
        answer = self.layer2_constrained_generation(query, filtered_docs)

        # 第3层：一致性检测
        consistency = self.layer3_consistency_check(answer, filtered_docs)

        # 第4层：置信度决策
        result = self.layer4_confidence_decision(answer, consistency, threshold)

        return result


# 使用示例
if __name__ == "__main__":
    import os

    system = MultiLayerHallucinationMitigation(api_key=os.getenv("OPENAI_API_KEY"))

    # 模拟检索结果
    docs = [
        {
            "content": "Python 3.9 于 2020 年 10 月 5 日发布",
            "score": 0.85
        },
        {
            "content": "Python 3.9 新增了字典合并运算符 |",
            "score": 0.82
        },
        {
            "content": "这是一个不相关的文档",
            "score": 0.45  # 低分，会被过滤
        }
    ]

    query = "Python 3.9 有什么新特性？"

    # 执行多层防护
    result = system.process(query, docs, threshold=0.7)

    print(f"状态: {result['status']}")
    print(f"答案: {result['answer']}")
    print(f"置信度: {result['confidence']:.2f}")
```

### 实现2：场景化的缓解策略

```python
class ScenarioBasedMitigation:
    """
    场景化的幻觉缓解策略
    不同场景使用不同的防护强度
    """

    def __init__(self, base_system: MultiLayerHallucinationMitigation):
        self.base_system = base_system

        # 场景配置
        self.scenarios = {
            "medical": {
                "threshold": 0.9,
                "min_retrieval_score": 0.8,
                "temperature": 0.0,
                "require_citations": True,
                "fallback": "请咨询专业医生"
            },
            "legal": {
                "threshold": 0.85,
                "min_retrieval_score": 0.75,
                "temperature": 0.1,
                "require_citations": True,
                "fallback": "请咨询专业律师"
            },
            "customer_service": {
                "threshold": 0.7,
                "min_retrieval_score": 0.6,
                "temperature": 0.3,
                "require_citations": False,
                "fallback": "让我为您转接人工客服"
            },
            "entertainment": {
                "threshold": 0.6,
                "min_retrieval_score": 0.5,
                "temperature": 0.5,
                "require_citations": False,
                "fallback": "抱歉，我不太确定"
            }
        }

    def process_with_scenario(
        self,
        query: str,
        docs: List[Dict],
        scenario: str = "general"
    ) -> Dict:
        """
        根据场景处理查询
        """
        # 获取场景配置
        config = self.scenarios.get(scenario, {
            "threshold": 0.7,
            "min_retrieval_score": 0.6,
            "temperature": 0.3,
            "require_citations": False,
            "fallback": "抱歉，我对这个答案不够确定"
        })

        # 调整检索过滤阈值
        filtered_docs = self.base_system.layer1_filter_retrieval(
            docs,
            min_score=config["min_retrieval_score"]
        )

        if len(filtered_docs) == 0:
            return {
                "status": "no_docs",
                "answer": config["fallback"],
                "confidence": 0.0,
                "scenario": scenario
            }

        # 生成答案
        answer = self.base_system.layer2_constrained_generation(
            query,
            filtered_docs
        )

        # 一致性检测
        consistency = self.base_system.layer3_consistency_check(
            answer,
            filtered_docs
        )

        # 置信度决策
        result = self.base_system.layer4_confidence_decision(
            answer,
            consistency,
            threshold=config["threshold"]
        )

        # 添加场景信息
        result["scenario"] = scenario
        result["config"] = config

        # 如果被拒绝，使用场景特定的降级策略
        if result["status"] == "rejected":
            result["answer"] = config["fallback"]

        return result
```

---

## RAG应用场景

### 场景1：高风险医疗问答

```python
def medical_qa_with_mitigation(query: str, medical_docs: List[Dict]):
    """
    医疗问答系统，使用最严格的防护
    """
    system = MultiLayerHallucinationMitigation(api_key=os.getenv("OPENAI_API_KEY"))

    # 医疗场景：极高阈值
    result = system.process(query, medical_docs, threshold=0.9)

    # 添加免责声明
    if result["status"] == "approved":
        result["answer"] += "\n\n免责声明：以上信息仅供参考，请咨询专业医生。"

    return result
```

### 场景2：客服聊天机器人

```python
def customer_service_with_mitigation(query: str, kb_docs: List[Dict]):
    """
    客服系统，平衡准确性和用户体验
    """
    system = MultiLayerHallucinationMitigation(api_key=os.getenv("OPENAI_API_KEY"))
    scenario_system = ScenarioBasedMitigation(system)

    # 客服场景：中等阈值
    result = scenario_system.process_with_scenario(
        query,
        kb_docs,
        scenario="customer_service"
    )

    # 如果置信度低，提供人工转接
    if result["status"] == "rejected":
        result["transfer_to_human"] = True

    return result
```

### 场景3：教育内容生成

```python
def educational_content_with_mitigation(topic: str, reference_docs: List[Dict]):
    """
    教育内容生成，确保准确性
    """
    system = MultiLayerHallucinationMitigation(api_key=os.getenv("OPENAI_API_KEY"))

    # 教育场景：较高阈值
    result = system.process(topic, reference_docs, threshold=0.8)

    # 添加参考资料链接
    if result["status"] == "approved":
        result["references"] = [
            doc.get("url", doc.get("title", ""))
            for doc in reference_docs
        ]

    return result
```

---

## 完整代码示例

```python
"""
完整的多策略缓解系统演示
展示从检索到生成到验证的完整防护流程
"""

from sentence_transformers import CrossEncoder, SentenceTransformer, util
from openai import OpenAI
import os
import numpy as np

# ===== 初始化 =====
print("=== 初始化多策略缓解系统 ===\n")

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
nli_model = CrossEncoder('cross-encoder/nli-deberta-v3-base')
encoder = SentenceTransformer('all-MiniLM-L6-v2')

# ===== 模拟检索结果 =====
query = "Python 3.9 有什么新特性？"

docs = [
    {"content": "Python 3.9 于 2020 年 10 月 5 日发布", "score": 0.88},
    {"content": "Python 3.9 新增了字典合并运算符 |", "score": 0.85},
    {"content": "Python 3.9 改进了类型提示功能", "score": 0.82},
    {"content": "这是一个不太相关的文档", "score": 0.45},
    {"content": "很短", "score": 0.75}
]

print(f"查询: {query}")
print(f"检索到 {len(docs)} 个文档\n")

# ===== 第1层：检索质量过滤 =====
print("=== 第1层：检索质量过滤 ===")

filtered_docs = []
for doc in docs:
    if doc['score'] >= 0.7 and len(doc['content']) >= 50:
        filtered_docs.append(doc)
        print(f"✓ 保留: {doc['content'][:30]}... (分数: {doc['score']})")
    else:
        reason = "分数过低" if doc['score'] < 0.7 else "文档过短"
        print(f"✗ 过滤: {doc['content'][:30]}... ({reason})")

print(f"\n过滤后剩余 {len(filtered_docs)} 个文档\n")

# ===== 第2层：约束生成 =====
print("=== 第2层：约束生成 ===")

context = "\n\n".join([
    f"文档{i+1}: {doc['content']}"
    for i, doc in enumerate(filtered_docs)
])

prompt = f"""基于以下文档回答问题，严格遵守要求。

{context}

问题：{query}

严格要求：
1. 只使用文档中的信息
2. 每个事实都要标注来源 [1], [2]
3. 不要添加文档外的信息

答案："""

print("生成答案中...")
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.1
)

answer = response.choices[0].message.content
print(f"生成答案: {answer}\n")

# ===== 第3层：一致性检测 =====
print("=== 第3层：一致性检测 ===")

# 3.1 NLI 检测
nli_scores = []
for i, doc in enumerate(filtered_docs):
    scores = nli_model.predict([(doc['content'], answer)])
    nli_score = scores[0][2]
    nli_scores.append(nli_score)
    print(f"文档{i+1} NLI 分数: {nli_score:.2f}")

max_nli = max(nli_scores)
print(f"最高 NLI 分数: {max_nli:.2f}")

# 3.2 关键词匹配
answer_words = set(answer.lower().split())
doc_words = set()
for doc in filtered_docs:
    doc_words.update(doc['content'].lower().split())

keyword_coverage = len(answer_words & doc_words) / len(answer_words)
print(f"关键词覆盖率: {keyword_coverage:.2f}")

# 3.3 语义相似度
answer_emb = encoder.encode(answer)
doc_embs = encoder.encode([doc['content'] for doc in filtered_docs])
similarities = util.cos_sim(answer_emb, doc_embs)[0].numpy()
max_sim = float(np.max(similarities))
print(f"最高语义相似度: {max_sim:.2f}")

# 综合评分
consistency = max_nli * 0.5 + keyword_coverage * 0.3 + max_sim * 0.2
print(f"\n综合一致性分数: {consistency:.2f}\n")

# ===== 第4层：置信度决策 =====
print("=== 第4层：置信度决策 ===")

threshold = 0.7
print(f"阈值: {threshold}")

if consistency >= threshold:
    print(f"✓ 通过检测 ({consistency:.2f} >= {threshold})")
    final_answer = answer
    status = "approved"
elif consistency >= threshold - 0.2:
    print(f"⚠ 置信度较低 ({consistency:.2f})")
    final_answer = f"（不太确定）{answer}"
    status = "warning"
else:
    print(f"✗ 未通过检测 ({consistency:.2f} < {threshold})")
    final_answer = "抱歉，我对这个答案不够确定"
    status = "rejected"

print(f"\n最终状态: {status}")
print(f"最终答案: {final_answer}")

# ===== 总结 =====
print("\n=== 防护总结 ===")
print(f"第1层过滤: {len(docs)} → {len(filtered_docs)} 个文档")
print(f"第2层生成: 使用约束 Prompt，温度 0.1")
print(f"第3层检测: 一致性分数 {consistency:.2f}")
print(f"第4层决策: {status}")
```

---

## 关键要点

### 1. 四层防护的作用

| 层次 | 作用 | 成本 | 收益 |
|------|------|------|------|
| 检索过滤 | 预防低质量输入 | 低 | 高 |
| 约束生成 | 控制 LLM 行为 | 低 | 高 |
| 一致性检测 | 验证输出质量 | 中 | 中 |
| 置信度决策 | 兜底保障 | 低 | 中 |

### 2. 场景化配置

**不同场景使用不同阈值：**
- 医疗/法律：0.85-0.9（极高要求）
- 客服/问答：0.7-0.8（中等要求）
- 推荐/娱乐：0.6-0.7（较低要求）

### 3. 性能优化

**优化策略：**
- 异步检测：不阻塞用户响应
- 批量处理：减少模型调用次数
- 缓存结果：相同查询不重复检测
- 分层检测：低风险查询跳过部分层次

### 4. 监控与迭代

**关键指标：**
- 各层过滤率
- 最终通过率
- 假阳性/假阴性率
- 用户满意度

---

## 总结

**多策略缓解的核心价值：**

1. **纵深防御**：多层防护，层层把关
2. **预防为主**：在检索和生成阶段就降低风险
3. **场景化**：根据不同场景调整策略
4. **可控性**：通过阈值灵活控制严格程度

**四层防护体系：**

1. **检索过滤**：过滤低质量文档
2. **约束生成**：限制 LLM 行为
3. **一致性检测**：验证输出质量
4. **置信度决策**：兜底保障

**在 RAG 开发中的应用：**

- 高风险场景（医疗、法律）：使用最严格的防护
- 中风险场景（客服、问答）：平衡准确性和体验
- 低风险场景（推荐、娱乐）：适当放宽要求

**记住：**

> **多策略缓解不是"过度设计"，而是生产环境的必需品。**
>
> **预防胜于治疗，在各阶段都设置防护，才能构建真正可信赖的 RAG 系统。**
