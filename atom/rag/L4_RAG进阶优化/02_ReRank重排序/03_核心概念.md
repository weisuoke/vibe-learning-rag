# 核心概念

掌握三个最核心的概念，覆盖 90% 的 RAG ReRank 场景。

---

## 核心概念1：Bi-Encoder vs Cross-Encoder

**这是理解 ReRank 的关键：两种编码架构的本质区别。**

### Bi-Encoder（双塔模型）

```
用于：向量检索（Embedding）

Query: "Python读取JSON"     Document: "使用json.load()读取"
         ↓                            ↓
    [Encoder A]                  [Encoder B]
         ↓                            ↓
    Query向量                     Doc向量
    [0.1, 0.2, ...]              [0.15, 0.18, ...]
                    ↓
              余弦相似度 = 0.85
```

**特点：**
- Query 和 Doc **分别独立编码**
- 编码后只通过向量相似度比较
- **优点**：Doc 向量可以预计算并索引，检索速度快
- **缺点**：Query 和 Doc 没有交互，精度有限

```python
# Bi-Encoder 示例（sentence-transformers）
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

# 分别编码
query_embedding = model.encode("Python读取JSON")
doc_embedding = model.encode("使用json.load()读取")

# 计算相似度
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]
print(f"相似度: {similarity:.4f}")  # 0.85
```

### Cross-Encoder（交叉编码器）

```
用于：ReRank 精排

输入: "[CLS] Python读取JSON [SEP] 使用json.load()读取 [EOS]"
                              ↓
                    [单个 Transformer]
                              ↓
                    Query 和 Doc 的每个 Token
                    都能相互 Attention
                              ↓
                    相关性分数 = 0.95
```

**特点：**
- Query 和 Doc **拼接后一起编码**
- 每个 Token 都能看到对方的所有 Token
- **优点**：深度交互，精度高
- **缺点**：无法预计算，每次都要重新计算，速度慢

```python
# Cross-Encoder 示例（sentence-transformers）
from sentence_transformers import CrossEncoder

model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# Query 和 Doc 一起输入
pairs = [
    ("Python读取JSON", "使用json.load()读取"),
    ("Python读取JSON", "Python是一种编程语言"),
]

# 直接输出相关性分数
scores = model.predict(pairs)
print(f"分数: {scores}")  # [0.95, 0.12]
```

### 对比总结

| 对比项 | Bi-Encoder | Cross-Encoder |
|--------|------------|---------------|
| 编码方式 | 分别编码 | 拼接后一起编码 |
| 交互深度 | 无交互 | Token 级深度交互 |
| 输出 | 向量 | 相关性分数 |
| 速度 | 快（可预计算） | 慢（每次重算） |
| 精度 | 较高 | 更高 |
| 用途 | 大规模召回 | 小规模精排 |

### 为什么需要两者配合？

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   100万文档                                                  │
│       ↓                                                     │
│   Bi-Encoder 检索 ← 1ms 内完成                               │
│       ↓                                                     │
│   Top 100 候选                                               │
│       ↓                                                     │
│   Cross-Encoder ReRank ← 100-500ms                          │
│       ↓                                                     │
│   Top 5 精排结果                                             │
│                                                             │
│   总耗时：~500ms，精度提升 10%+                               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 核心概念2：相关性分数（Relevance Score）

**Cross-Encoder 输出的分数，表示 Query 和 Document 的相关程度。**

### 分数的含义

```python
from sentence_transformers import CrossEncoder

model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

query = "如何在Python中读取JSON文件？"
documents = [
    "使用 json.load() 函数可以读取 JSON 文件",
    "Python 是一种流行的编程语言",
    "JSON 是 JavaScript Object Notation 的缩写",
    "import json; data = json.load(open('file.json'))",
]

# 计算相关性分数
pairs = [(query, doc) for doc in documents]
scores = model.predict(pairs)

for doc, score in zip(documents, scores):
    print(f"分数: {score:.4f} | {doc[:30]}...")
```

**输出：**
```
分数: 0.9234 | 使用 json.load() 函数可以读取 JSON...
分数: 0.0156 | Python 是一种流行的编程语言...
分数: 0.0089 | JSON 是 JavaScript Object Nota...
分数: 0.8876 | import json; data = json.load(...
```

### 分数范围

不同的 Cross-Encoder 模型，分数范围可能不同：

| 模型 | 分数范围 | 说明 |
|------|----------|------|
| ms-marco 系列 | 约 [-10, 10] | 原始 logits，需要 sigmoid 转换 |
| Cohere Rerank | [0, 1] | 已归一化 |
| BGE Reranker | [0, 1] | 已归一化 |

```python
# 将原始分数转换为 0-1 范围
import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

raw_scores = model.predict(pairs)
normalized_scores = sigmoid(raw_scores)
```

### 分数的使用方式

**方式1：直接排序**

```python
# 按分数降序排列
ranked_results = sorted(
    zip(documents, scores),
    key=lambda x: x[1],
    reverse=True
)

# 取 Top-K
top_k = ranked_results[:5]
```

**方式2：设置阈值过滤**

```python
# 只保留分数高于阈值的结果
threshold = 0.5
filtered_results = [
    (doc, score) for doc, score in zip(documents, scores)
    if score > threshold
]
```

**方式3：结合原始分数加权**

```python
# 综合向量相似度和 ReRank 分数
def combined_score(vector_sim, rerank_score, alpha=0.3):
    """
    alpha: ReRank 分数的权重
    """
    return (1 - alpha) * vector_sim + alpha * rerank_score
```

---

## 核心概念3：两阶段检索架构

**ReRank 的标准使用模式：先召回，后精排。**

### 架构图

```
┌─────────────────────────────────────────────────────────────┐
│                    两阶段检索架构                             │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              第一阶段：召回（Retrieval）               │   │
│  │                                                     │   │
│  │  Query ──→ Bi-Encoder ──→ 向量检索 ──→ Top-N 候选    │   │
│  │                                                     │   │
│  │  特点：快速、大规模、近似匹配                          │   │
│  │  目标：高召回率（不漏掉相关文档）                       │   │
│  │  N 通常：50-100                                      │   │
│  └─────────────────────────────────────────────────────┘   │
│                          ↓                                  │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              第二阶段：精排（ReRank）                  │   │
│  │                                                     │   │
│  │  Top-N ──→ Cross-Encoder ──→ 重新打分 ──→ Top-K 结果  │   │
│  │                                                     │   │
│  │  特点：精确、小规模、深度匹配                          │   │
│  │  目标：高精确率（排序准确）                            │   │
│  │  K 通常：5-10                                        │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 代码实现

```python
from sentence_transformers import SentenceTransformer, CrossEncoder
import numpy as np

class TwoStageRetriever:
    def __init__(self):
        # 第一阶段：Bi-Encoder
        self.bi_encoder = SentenceTransformer('all-MiniLM-L6-v2')
        # 第二阶段：Cross-Encoder
        self.cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

        self.documents = []
        self.doc_embeddings = None

    def index(self, documents: list[str]):
        """索引文档（离线）"""
        self.documents = documents
        self.doc_embeddings = self.bi_encoder.encode(documents)

    def retrieve(self, query: str, top_n: int = 50, top_k: int = 5):
        """两阶段检索"""
        # === 第一阶段：向量检索召回 Top-N ===
        query_embedding = self.bi_encoder.encode(query)

        # 计算相似度
        similarities = np.dot(self.doc_embeddings, query_embedding)

        # 取 Top-N
        top_n_indices = np.argsort(similarities)[-top_n:][::-1]
        candidates = [(self.documents[i], similarities[i]) for i in top_n_indices]

        print(f"第一阶段召回 {len(candidates)} 个候选")

        # === 第二阶段：Cross-Encoder 精排 ===
        pairs = [(query, doc) for doc, _ in candidates]
        rerank_scores = self.cross_encoder.predict(pairs)

        # 按 ReRank 分数排序
        reranked = sorted(
            zip([doc for doc, _ in candidates], rerank_scores),
            key=lambda x: x[1],
            reverse=True
        )

        # 返回 Top-K
        return reranked[:top_k]

# 使用示例
retriever = TwoStageRetriever()
retriever.index([
    "Python 使用 json.load() 读取 JSON 文件",
    "Python 是一种编程语言",
    "JSON 是一种数据格式",
    "使用 open() 函数打开文件",
    # ... 更多文档
])

results = retriever.retrieve("如何用Python读取JSON？", top_n=50, top_k=3)
for doc, score in results:
    print(f"{score:.4f}: {doc}")
```

### 参数选择指南

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| Top-N（召回数量） | 50-100 | 太少可能漏掉相关文档，太多会增加 ReRank 耗时 |
| Top-K（最终数量） | 3-10 | 根据 LLM Context Window 和业务需求决定 |
| 召回/精排比例 | 10:1 ~ 20:1 | 例如召回 100，精排后取 5-10 |

### 在 RAG 中的完整流程

```python
def rag_with_rerank(query: str, retriever, llm):
    """带 ReRank 的 RAG 流程"""

    # 1. 两阶段检索
    results = retriever.retrieve(query, top_n=50, top_k=5)

    # 2. 构建上下文
    context = "\n\n".join([doc for doc, score in results])

    # 3. 生成回答
    prompt = f"""基于以下参考资料回答问题。

参考资料：
{context}

问题：{query}

回答："""

    answer = llm.generate(prompt)
    return answer
```

---

## 扩展概念：常用 ReRank 模型

### 开源模型

| 模型 | 来源 | 特点 |
|------|------|------|
| `cross-encoder/ms-marco-MiniLM-L-6-v2` | sentence-transformers | 轻量快速，适合入门 |
| `cross-encoder/ms-marco-MiniLM-L-12-v2` | sentence-transformers | 更大更准 |
| `BAAI/bge-reranker-base` | 智源 | 中文效果好 |
| `BAAI/bge-reranker-large` | 智源 | 更大更准 |

### 商业 API

| 服务 | 特点 | 价格 |
|------|------|------|
| Cohere Rerank | 效果好，易用 | $1/1000 次 |
| Jina Reranker | 多语言支持 | 有免费额度 |

---

**下一步：** [04_最小可用](./04_最小可用.md) - 掌握 20% 核心知识解决 80% 问题
