# 最小可用

> 掌握以下内容，就能开始使用生成器与迭代器

---

## 4.1 理解迭代器协议（最基础）

**核心：** 实现 `__iter__` 和 `__next__` 两个方法

```python
class SimpleIterator:
    def __init__(self, data):
        self.data = data
        self.index = 0

    def __iter__(self):
        return self  # 返回自己

    def __next__(self):
        if self.index >= len(self.data):
            raise StopIteration  # 结束信号
        value = self.data[self.index]
        self.index += 1
        return value

# 使用
for item in SimpleIterator([1, 2, 3]):
    print(item)  # 1, 2, 3
```

**记住：**
- `__iter__`：返回迭代器对象（通常是 self）
- `__next__`：返回下一个值，结束时抛出 `StopIteration`
- `for` 循环会自动调用这两个方法

---

## 4.2 使用 yield 创建生成器（最常用）

**核心：** 函数中使用 `yield` 关键字，自动变成生成器

```python
def simple_generator(n):
    """生成 0 到 n-1 的数字"""
    for i in range(n):
        yield i  # 暂停并返回值

# 使用
for num in simple_generator(5):
    print(num)  # 0, 1, 2, 3, 4
```

**记住：**
- `yield` = 暂停点，返回值并保存状态
- 下次调用 `next()` 时从 `yield` 后继续执行
- 函数结束时自动抛出 `StopIteration`

**对比普通函数：**
```python
# 普通函数：一次性返回全部
def normal_function(n):
    result = []
    for i in range(n):
        result.append(i)
    return result  # 一次性返回

# 生成器函数：按需返回
def generator_function(n):
    for i in range(n):
        yield i  # 每次返回一个
```

---

## 4.3 使用生成器表达式（最简洁）

**核心：** 用 `()` 替代列表推导式的 `[]`

```python
# 列表推导式：一次性生成全部
squares_list = [x**2 for x in range(1000)]  # 立即计算全部

# 生成器表达式：按需生成
squares_gen = (x**2 for x in range(1000))  # 不计算任何值

# 使用
for square in squares_gen:
    print(square)  # 每次计算一个
```

**记住：**
- `[]` = 列表推导式（立即计算）
- `()` = 生成器表达式（惰性计算）
- 语法完全相同，只是括号不同

**内存对比：**
```python
import sys

# 列表：占用大量内存
list_comp = [x for x in range(1_000_000)]
print(sys.getsizeof(list_comp))  # ~8MB

# 生成器：几乎不占内存
gen_exp = (x for x in range(1_000_000))
print(sys.getsizeof(gen_exp))  # ~128 字节
```

---

## 4.4 处理大文件（实战必备）

**核心：** 逐行读取而非一次性加载

```python
def read_large_file(filename):
    """逐行读取大文件"""
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:  # 文件对象本身就是迭代器
            yield line.strip()  # 返回处理后的行

# 使用：处理 10GB 文件也不会内存爆炸
for line in read_large_file('large_file.log'):
    if 'ERROR' in line:
        print(line)
```

**为什么高效？**
- 每次只读取一行到内存
- 处理完立即释放
- 内存占用 = 单行大小（几 KB）

**对比传统方式：**
```python
# ❌ 传统方式：内存爆炸
def read_file_bad(filename):
    with open(filename) as f:
        lines = f.readlines()  # 一次性读取全部（10GB）
    return lines

# ✅ 生成器方式：内存高效
def read_file_good(filename):
    with open(filename) as f:
        for line in f:
            yield line.strip()
```

---

## 4.5 在 FastAPI 中实现流式响应（AI Agent 必备）

**核心：** 使用生成器实现 AI 流式输出

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from typing import Generator

app = FastAPI()

def generate_stream() -> Generator[str, None, None]:
    """生成流式数据"""
    for i in range(10):
        yield f"data: {i}\n\n"  # Server-Sent Events 格式

@app.get("/stream")
async def stream_endpoint():
    """流式响应端点"""
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream"
    )
```

**AI 流式响应示例：**
```python
from openai import OpenAI

def stream_ai_response(prompt: str) -> Generator[str, None, None]:
    """流式返回 AI 响应"""
    client = OpenAI()

    # 调用 OpenAI API，启用流式响应
    stream = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        stream=True  # 关键：启用流式
    )

    # 逐个 token 返回
    for chunk in stream:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

@app.get("/chat")
async def chat(prompt: str):
    """AI 聊天端点"""
    return StreamingResponse(
        stream_ai_response(prompt),
        media_type="text/plain"
    )
```

**用户体验：**
- 非流式：等待 10 秒 → 突然显示全部内容
- 流式：立即开始显示 → 逐字输出（像打字机）

---

## 这些知识足以

掌握以上 5 个核心知识点，你就能：

### ✅ 能做什么

1. **处理大文件**
   - 逐行读取日志文件
   - 处理 GB 级数据而不耗尽内存

2. **实现流式响应**
   - FastAPI 流式端点
   - AI 聊天流式输出

3. **优化内存使用**
   - 用生成器表达式替代列表推导式
   - 处理大数据集

4. **构建数据管道**
   - 链式处理数据流
   - 惰性求值

### ✅ 为后续学习打基础

- 异步生成器（`async def` + `yield`）
- 协程与生成器（`send`、`throw`、`close`）
- 高级迭代工具（`itertools` 模块）

---

## 快速参考卡

### 迭代器协议

```python
class MyIterator:
    def __iter__(self):
        return self
    def __next__(self):
        # 返回下一个值
        # 结束时 raise StopIteration
```

### 生成器函数

```python
def my_generator():
    yield value  # 暂停并返回
```

### 生成器表达式

```python
gen = (expression for item in iterable)
```

### 大文件处理

```python
def read_file(filename):
    with open(filename) as f:
        for line in f:
            yield line.strip()
```

### FastAPI 流式响应

```python
from fastapi.responses import StreamingResponse

@app.get("/stream")
async def stream():
    return StreamingResponse(
        generator_function(),
        media_type="text/plain"
    )
```

---

## 常见模式速查

### 模式1：过滤数据流

```python
def filter_lines(filename, keyword):
    """只返回包含关键词的行"""
    with open(filename) as f:
        for line in f:
            if keyword in line:
                yield line.strip()
```

### 模式2：转换数据流

```python
def transform_data(data_stream):
    """转换数据流中的每一项"""
    for item in data_stream:
        yield transform(item)
```

### 模式3：批量处理

```python
def batch_generator(data, batch_size):
    """将数据分批返回"""
    batch = []
    for item in data:
        batch.append(item)
        if len(batch) >= batch_size:
            yield batch
            batch = []
    if batch:  # 返回最后一批
        yield batch
```

### 模式4：无限序列

```python
def infinite_counter(start=0):
    """无限计数器"""
    n = start
    while True:
        yield n
        n += 1
```

---

## 实战检查清单

完成以下练习，确保掌握最小可用知识：

- [ ] 手写一个简单的迭代器类
- [ ] 编写一个生成器函数，生成斐波那契数列
- [ ] 用生成器表达式替代一个列表推导式
- [ ] 编写一个函数，逐行读取大文件并过滤特定内容
- [ ] 在 FastAPI 中实现一个简单的流式响应端点
- [ ] 对比列表和生成器的内存占用（使用 `sys.getsizeof`）

---

## 下一步学习

掌握最小可用知识后，可以深入学习：

1. **迭代器协议详解**（核心概念1）
   - `__iter__` 和 `__next__` 的细节
   - 可迭代对象 vs 迭代器
   - 自定义迭代逻辑

2. **生成器函数详解**（核心概念2）
   - `yield` 的执行机制
   - 生成器的状态保存
   - `send`、`throw`、`close` 方法

3. **生成器表达式详解**（核心概念3）
   - 语法细节
   - 性能优化
   - 与 `itertools` 结合使用

4. **高级应用**
   - 异步生成器
   - 协程
   - 数据管道设计模式

---

**版本：** v1.0
**最后更新：** 2026-02-11
