# 实战代码1: 基础并行执行

> **完整可运行的基础并行执行示例**

---

## 环境准备

```bash
# 安装依赖
uv add langchain langchain-openai python-dotenv

# 配置 API Key
echo "OPENAI_API_KEY=your_key_here" > .env
```

---

## 示例1: 基础并行执行

```python
"""
基础并行执行示例
演示字典语法的基本用法
"""
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 定义三个独立任务
summary_chain = ChatPromptTemplate.from_template(
    "用一句话总结:\n\n{text}"
) | model

keywords_chain = ChatPromptTemplate.from_template(
    "提取3-5个关键词:\n\n{text}"
) | model

sentiment_chain = ChatPromptTemplate.from_template(
    "分析情感（积极/中性/消极）:\n\n{text}"
) | model

# 字典语法：并行执行
parallel_chain = {
    "summary": summary_chain,
    "keywords": keywords_chain,
    "sentiment": sentiment_chain,
}

# 执行
text = "LangChain 让 AI 应用开发变得简单高效，深受开发者喜爱"
result = parallel_chain.invoke({"text": text})

print("摘要:", result["summary"].content)
print("关键词:", result["keywords"].content)
print("情感:", result["sentiment"].content)
```

---

## 示例2: 字典语法 vs 显式构造

```python
"""
对比两种等价的写法
"""
from langchain_core.runnables import RunnableParallel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 方式1: 字典语法（推荐）
chain1 = {
    "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
    "keywords": ChatPromptTemplate.from_template("关键词: {text}") | model,
}

# 方式2: 显式构造
chain2 = RunnableParallel(
    summary=ChatPromptTemplate.from_template("总结: {text}") | model,
    keywords=ChatPromptTemplate.from_template("关键词: {text}") | model,
)

# 验证等价性
print("类型1:", type(chain1))
print("类型2:", type(chain2))
print("等价:", type(chain1) == type(chain2))

# 执行结果相同
result1 = chain1.invoke({"text": "LangChain 很强大"})
result2 = chain2.invoke({"text": "LangChain 很强大"})
```

---

## 示例3: 嵌套并行

```python
"""
多层嵌套的并行执行
"""
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 嵌套并行结构
chain = {
    "content_analysis": {
        "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
        "keywords": ChatPromptTemplate.from_template("关键词: {text}") | model,
    },
    "metadata": {
        "length": RunnableLambda(lambda x: len(x["text"])),
        "word_count": RunnableLambda(lambda x: len(x["text"].split())),
    },
}

result = chain.invoke({"text": "LangChain 是一个强大的 AI 框架"})

print("=== 内容分析 ===")
print("摘要:", result["content_analysis"]["summary"].content)
print("关键词:", result["content_analysis"]["keywords"].content)

print("\n=== 元数据 ===")
print("长度:", result["metadata"]["length"])
print("词数:", result["metadata"]["word_count"])
```

---

## 示例4: 性能对比

```python
"""
串行 vs 并行性能对比
"""
import time
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 定义任务
task1 = ChatPromptTemplate.from_template("任务1: {input}") | model
task2 = ChatPromptTemplate.from_template("任务2: {input}") | model
task3 = ChatPromptTemplate.from_template("任务3: {input}") | model

input_data = {"input": "测试数据"}

# 串行执行
print("=== 串行执行 ===")
start = time.time()
r1 = task1.invoke(input_data)
r2 = task2.invoke(input_data)
r3 = task3.invoke(input_data)
serial_time = time.time() - start
print(f"耗时: {serial_time:.2f}秒")

# 并行执行
print("\n=== 并行执行 ===")
start = time.time()
result = {
    "task1": task1,
    "task2": task2,
    "task3": task3,
}.invoke(input_data)
parallel_time = time.time() - start
print(f"耗时: {parallel_time:.2f}秒")

# 性能提升
improvement = (1 - parallel_time / serial_time) * 100
print(f"\n性能提升: {improvement:.1f}%")
```

---

## 示例5: 与管道操作符结合

```python
"""
并行执行与串行处理的组合
"""
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 并行 + 串行组合
chain = (
    # 步骤1: 预处理（串行）
    RunnableLambda(lambda x: {"text": x["text"].strip()})
    # 步骤2: 并行分析
    | {
        "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
        "keywords": ChatPromptTemplate.from_template("关键词: {text}") | model,
    }
    # 步骤3: 后处理（串行）
    | RunnableLambda(lambda x: {
        "summary": x["summary"].content,
        "keywords": x["keywords"].content,
        "combined": f"摘要: {x['summary'].content}\n关键词: {x['keywords'].content}"
    })
)

result = chain.invoke({"text": "  LangChain 很强大  "})
print(result["combined"])
```

---

## 示例6: 动态并行

```python
"""
根据输入动态创建并行任务
"""
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

def create_multi_perspective_chain(perspectives: list[str]):
    """动态创建多视角分析链"""
    tasks = {}
    for perspective in perspectives:
        tasks[f"perspective_{perspective}"] = ChatPromptTemplate.from_template(
            f"从{perspective}角度分析: {{text}}"
        ) | model
    return tasks

# 创建3个视角的分析
perspectives = ["技术", "商业", "用户"]
chain = create_multi_perspective_chain(perspectives)

result = chain.invoke({"text": "LangChain 的优势"})

for key, value in result.items():
    print(f"{key}:")
    print(value.content)
    print()
```

---

## 示例7: 错误处理

```python
"""
基础错误处理示例
"""
from langchain_core.runnables import RunnableLambda

def safe_task(func, name: str):
    """安全包装任务"""
    def wrapper(x):
        try:
            return {"success": True, "result": func(x)}
        except Exception as e:
            return {"success": False, "error": str(e)}
    return RunnableLambda(wrapper)

# 定义任务
def success_task(x):
    return "成功"

def failure_task(x):
    raise ValueError("失败")

# 使用安全包装
chain = {
    "task1": safe_task(success_task, "任务1"),
    "task2": safe_task(failure_task, "任务2"),
}

result = chain.invoke("input")

for key, value in result.items():
    if value["success"]:
        print(f"✅ {key}: {value['result']}")
    else:
        print(f"❌ {key}: {value['error']}")
```

---

## 示例8: 完整的文本分析链

```python
"""
完整的文本多维度分析示例
"""
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 构建完整分析链
analysis_chain = (
    # 并行执行多个分析任务
    {
        "summary": ChatPromptTemplate.from_template(
            "用一句话总结:\n\n{text}"
        ) | model,
        "keywords": ChatPromptTemplate.from_template(
            "提取5个关键词（逗号分隔）:\n\n{text}"
        ) | model,
        "sentiment": ChatPromptTemplate.from_template(
            "分析情感倾向（只回答：积极/中性/消极）:\n\n{text}"
        ) | model,
        "category": ChatPromptTemplate.from_template(
            "分类（只回答：技术/商业/教育/其他）:\n\n{text}"
        ) | model,
        "metadata": RunnableLambda(lambda x: {
            "length": len(x["text"]),
            "word_count": len(x["text"].split()),
        }),
    }
    # 格式化输出
    | RunnableLambda(lambda x: {
        "summary": x["summary"].content,
        "keywords": x["keywords"].content.split(","),
        "sentiment": x["sentiment"].content.strip(),
        "category": x["category"].content.strip(),
        "metadata": x["metadata"],
    })
)

# 测试
text = """
LangChain 是一个强大的 AI 应用开发框架，它提供了丰富的组件和工具，
让开发者能够轻松构建复杂的 AI 应用。通过 LCEL 表达式语言，
开发者可以用声明式的方式组合各种 AI 组件，大大提高了开发效率。
"""

result = analysis_chain.invoke({"text": text})

print("=== 文本分析结果 ===")
print(f"摘要: {result['summary']}")
print(f"关键词: {', '.join(result['keywords'])}")
print(f"情感: {result['sentiment']}")
print(f"分类: {result['category']}")
print(f"长度: {result['metadata']['length']} 字符")
print(f"词数: {result['metadata']['word_count']} 词")
```

---

## 常见模式总结

### 模式1: 基础并行

```python
chain = {
    "task1": runnable1,
    "task2": runnable2,
}
```

### 模式2: 嵌套并行

```python
chain = {
    "group1": {
        "task1a": runnable1a,
        "task1b": runnable1b,
    },
    "group2": runnable2,
}
```

### 模式3: 并行 + 串行

```python
chain = preprocess | {"task1": r1, "task2": r2} | postprocess
```

### 模式4: 动态并行

```python
tasks = {f"task{i}": create_task(i) for i in range(n)}
chain = tasks
```

### 模式5: 安全包装

```python
chain = {
    "task1": safe_runnable(task1),
    "task2": safe_runnable(task2),
}
```

---

## 性能优化建议

1. **只并行独立任务**
   ```python
   # ✅ 正确
   {"summary": summary, "keywords": keywords}

   # ❌ 错误（有依赖）
   {"retrieve": retriever, "generate": generator}
   ```

2. **控制并发数量**
   ```python
   # 避免过多并发
   # 建议: 10-20 个任务一批
   ```

3. **优先并行 I/O 密集型任务**
   ```python
   # ✅ 适合并行
   {"api1": api_call, "api2": api_call}

   # ⚠️ 提升有限
   {"calc1": cpu_task, "calc2": cpu_task}
   ```

---

## 调试技巧

### 添加日志

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def logged_task(func, name):
    def wrapper(x):
        logger.info(f"[{name}] 开始")
        result = func(x)
        logger.info(f"[{name}] 完成")
        return result
    return RunnableLambda(wrapper)
```

### 性能监控

```python
import time

def timed_task(func, name):
    def wrapper(x):
        start = time.time()
        result = func(x)
        elapsed = time.time() - start
        print(f"[{name}] 耗时: {elapsed:.2f}s")
        return result
    return RunnableLambda(wrapper)
```

---

## 下一步学习

- [实战代码2: RAG检索场景](./07_实战代码_02_RAG检索场景.md) - RAG 中的并行检索
- [实战代码3: 多任务处理](./07_实战代码_03_多任务处理.md) - 多模型并行调用
- [实战代码4: 上下文保持](./07_实战代码_04_上下文保持.md) - RunnablePassthrough.assign()

---

**版本**: v1.0
**最后更新**: 2026-02-19
**适用**: LangChain 0.3+, Python 3.13+
