# 核心概念4：错误传播与处理

> 理解错误如何在 RunnableSequence 中传播和处理

---

## 错误传播的本质

**一句话**：任何组件抛出异常，整个链立即中断，异常向上传播到调用者。

```python
chain = step1 | step2 | step3

# 如果 step2 失败
# step1 ✅ 执行
# step2 ❌ 失败，抛出异常
# step3 ⏭️ 不执行
# 异常传播到调用者
```

---

## 基础错误传播

### 默认行为：立即中断

```python
from langchain_core.runnables import RunnableLambda

def step1(x):
    print("Step 1 执行")
    return x + 1

def step2(x):
    print("Step 2 执行")
    raise ValueError("Step 2 失败！")

def step3(x):
    print("Step 3 执行")
    return x * 2

chain = (
    RunnableLambda(step1)
    | RunnableLambda(step2)
    | RunnableLambda(step3)
)

try:
    result = chain.invoke(10)
except ValueError as e:
    print(f"捕获异常: {e}")

# 输出：
# Step 1 执行
# Step 2 执行
# 捕获异常: Step 2 失败！
# （Step 3 没有执行）
```

**关键点**：
- step2 抛出异常后，step3 不会执行
- 异常直接传播到调用者
- 没有自动重试或降级

---

## 错误处理策略

### 策略1：with_retry - 自动重试

**适用场景**：临时性错误（网络抖动、API 限流）

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("解释：{topic}")
llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

base_chain = prompt | llm | parser

# 添加重试逻辑
chain_with_retry = base_chain.with_retry(
    stop_after_attempt=3,           # 最多重试3次
    wait_exponential_jitter=True,   # 指数退避 + 随机抖动
    retry_if_exception_type=(       # 只重试特定错误
        RateLimitError,
        APIConnectionError
    )
)

# 使用
result = chain_with_retry.invoke({"topic": "AI"})
# 如果失败，自动重试最多3次
```

**重试策略**：

| 参数 | 说明 | 示例 |
|------|------|------|
| `stop_after_attempt` | 最大重试次数 | `3`（总共执行4次） |
| `wait_exponential_jitter` | 指数退避 + 随机抖动 | 1s → 2s → 4s |
| `retry_if_exception_type` | 只重试特定错误 | `(RateLimitError,)` |
| `wait_fixed` | 固定等待时间 | `2`（每次等待2秒） |

**来源**：Medium - 7 Retry & Timeout Policies for Flaky LangChain Tools

### 策略2：with_fallbacks - 降级方案

**适用场景**：永久性错误（模型不可用、成本过高）

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("解释：{topic}")
parser = StrOutputParser()

# 主链：使用 GPT-4
main_llm = ChatOpenAI(model="gpt-4")
main_chain = prompt | main_llm | parser

# 备用链1：使用 GPT-3.5
fallback_llm1 = ChatOpenAI(model="gpt-3.5-turbo")
fallback_chain1 = prompt | fallback_llm1 | parser

# 备用链2：使用本地模型
fallback_llm2 = ChatOpenAI(base_url="http://localhost:8000", model="local")
fallback_chain2 = prompt | fallback_llm2 | parser

# 组合：主链 → 备用链1 → 备用链2
chain_with_fallbacks = main_chain.with_fallbacks([
    fallback_chain1,
    fallback_chain2
])

# 使用
result = chain_with_fallbacks.invoke({"topic": "AI"})
# 如果主链失败，自动切换到备用链1
# 如果备用链1也失败，切换到备用链2
```

**降级策略**：

```
主链（GPT-4）
  ↓ 失败
备用链1（GPT-3.5）
  ↓ 失败
备用链2（本地模型）
  ↓ 失败
抛出异常
```

### 策略3：组合使用（生产级）

```python
# 生产级错误处理：重试 + 降级
production_chain = (
    base_chain
    .with_retry(
        stop_after_attempt=3,
        wait_exponential_jitter=True
    )
    .with_fallbacks([fallback_chain])
)

# 执行流程：
# 1. 尝试主链
# 2. 如果失败，重试最多3次
# 3. 如果重试后仍失败，切换到备用链
# 4. 如果备用链也失败，抛出异常
```

---

## 手写错误处理实现

### 版本1：基础重试

```python
import time
from typing import Any, Callable

class RetryableRunnable:
    """支持重试的 Runnable"""

    def __init__(self, func: Callable, max_retries: int = 3):
        self.func = func
        self.max_retries = max_retries

    def invoke(self, input: Any) -> Any:
        """执行，支持重试"""
        last_exception = None

        for attempt in range(self.max_retries + 1):
            try:
                print(f"尝试 {attempt + 1}/{self.max_retries + 1}")
                result = self.func(input)
                print(f"成功！")
                return result
            except Exception as e:
                last_exception = e
                print(f"失败: {e}")

                if attempt < self.max_retries:
                    # 指数退避
                    wait_time = 2 ** attempt
                    print(f"等待 {wait_time} 秒后重试...")
                    time.sleep(wait_time)
                else:
                    print(f"达到最大重试次数，放弃")

        # 所有重试都失败，抛出最后一个异常
        raise last_exception


# ===== 测试 =====

attempt_count = 0

def flaky_function(x):
    """不稳定的函数，前2次失败，第3次成功"""
    global attempt_count
    attempt_count += 1

    if attempt_count < 3:
        raise ValueError(f"临时错误（第{attempt_count}次）")

    return x * 2


if __name__ == "__main__":
    runnable = RetryableRunnable(flaky_function, max_retries=3)

    try:
        result = runnable.invoke(10)
        print(f"\n最终结果: {result}")
    except Exception as e:
        print(f"\n最终失败: {e}")

# 输出：
# 尝试 1/4
# 失败: 临时错误（第1次）
# 等待 1 秒后重试...
# 尝试 2/4
# 失败: 临时错误（第2次）
# 等待 2 秒后重试...
# 尝试 3/4
# 成功！
#
# 最终结果: 20
```

### 版本2：支持降级

```python
from typing import Any, List, Callable

class FallbackRunnable:
    """支持降级的 Runnable"""

    def __init__(self, main_func: Callable, fallback_funcs: List[Callable]):
        self.main_func = main_func
        self.fallback_funcs = fallback_funcs

    def invoke(self, input: Any) -> Any:
        """执行，支持降级"""
        # 尝试主函数
        try:
            print("尝试主函数...")
            result = self.main_func(input)
            print("主函数成功！")
            return result
        except Exception as e:
            print(f"主函数失败: {e}")

        # 尝试备用函数
        for i, fallback_func in enumerate(self.fallback_funcs, 1):
            try:
                print(f"尝试备用函数 {i}...")
                result = fallback_func(input)
                print(f"备用函数 {i} 成功！")
                return result
            except Exception as e:
                print(f"备用函数 {i} 失败: {e}")

        # 所有函数都失败
        raise RuntimeError("所有函数都失败")


# ===== 测试 =====

def main_func(x):
    """主函数（总是失败）"""
    raise ValueError("主函数不可用")

def fallback1(x):
    """备用函数1（总是失败）"""
    raise ValueError("备用函数1不可用")

def fallback2(x):
    """备用函数2（成功）"""
    return x * 2


if __name__ == "__main__":
    runnable = FallbackRunnable(main_func, [fallback1, fallback2])

    try:
        result = runnable.invoke(10)
        print(f"\n最终结果: {result}")
    except Exception as e:
        print(f"\n最终失败: {e}")

# 输出：
# 尝试主函数...
# 主函数失败: 主函数不可用
# 尝试备用函数 1...
# 备用函数 1 失败: 备用函数1不可用
# 尝试备用函数 2...
# 备用函数 2 成功！
#
# 最终结果: 20
```

### 版本3：组合重试和降级

```python
class ProductionRunnable:
    """生产级 Runnable：重试 + 降级"""

    def __init__(
        self,
        main_func: Callable,
        fallback_funcs: List[Callable],
        max_retries: int = 3
    ):
        self.main_func = main_func
        self.fallback_funcs = fallback_funcs
        self.max_retries = max_retries

    def _invoke_with_retry(self, func: Callable, input: Any) -> Any:
        """执行函数，支持重试"""
        last_exception = None

        for attempt in range(self.max_retries + 1):
            try:
                return func(input)
            except Exception as e:
                last_exception = e
                if attempt < self.max_retries:
                    time.sleep(2 ** attempt)

        raise last_exception

    def invoke(self, input: Any) -> Any:
        """执行，支持重试和降级"""
        # 尝试主函数（带重试）
        try:
            print("尝试主函数（带重试）...")
            result = self._invoke_with_retry(self.main_func, input)
            print("主函数成功！")
            return result
        except Exception as e:
            print(f"主函数失败（重试后）: {e}")

        # 尝试备用函数（带重试）
        for i, fallback_func in enumerate(self.fallback_funcs, 1):
            try:
                print(f"尝试备用函数 {i}（带重试）...")
                result = self._invoke_with_retry(fallback_func, input)
                print(f"备用函数 {i} 成功！")
                return result
            except Exception as e:
                print(f"备用函数 {i} 失败（重试后）: {e}")

        raise RuntimeError("所有函数都失败")
```

---

## 回调系统中的错误处理

### 错误回调

```python
from langchain.callbacks.base import BaseCallbackHandler

class ErrorHandler(BaseCallbackHandler):
    """错误处理回调"""

    def on_chain_error(
        self,
        error: Exception,
        **kwargs
    ) -> None:
        """链执行失败时调用"""
        print(f"❌ 链执行失败: {error}")
        print(f"   类型: {type(error).__name__}")
        print(f"   详情: {kwargs}")

        # 记录日志
        # 发送告警
        # 等等

    def on_llm_error(
        self,
        error: Exception,
        **kwargs
    ) -> None:
        """LLM 调用失败时调用"""
        print(f"❌ LLM 调用失败: {error}")

    def on_tool_error(
        self,
        error: Exception,
        **kwargs
    ) -> None:
        """工具调用失败时调用"""
        print(f"❌ 工具调用失败: {error}")


# 使用
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("解释：{topic}")
llm = ChatOpenAI(model="gpt-4o-mini")

chain = prompt | llm

try:
    result = chain.invoke(
        {"topic": "AI"},
        config={"callbacks": [ErrorHandler()]}
    )
except Exception as e:
    print(f"最终异常: {e}")
```

---

## 2025-2026 错误处理最佳实践

### 1. 指数退避策略

**来源**：Medium - 7 Retry & Timeout Policies

```python
# ✅ 推荐：指数退避 + 随机抖动
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True  # 1s → 2s → 4s（加随机抖动）
)

# ❌ 不推荐：固定等待时间
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,
    wait_fixed=2  # 每次都等待2秒
)
```

**为什么使用指数退避？**
- 避免雪崩效应：如果服务过载，固定重试会加剧问题
- 给服务恢复时间：等待时间逐渐增加
- 随机抖动：避免多个客户端同时重试

### 2. 选择性重试

```python
from openai import RateLimitError, APIConnectionError, APIError

# ✅ 只重试临时性错误
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,
    retry_if_exception_type=(
        RateLimitError,        # API 限流
        APIConnectionError,    # 网络错误
        TimeoutError          # 超时
    )
)

# ❌ 不要重试永久性错误
# 如 AuthenticationError（认证失败）、ValidationError（输入错误）
```

### 3. 多层降级

```python
# ✅ 多层降级：性能 → 成本 → 可用性
main_chain = prompt | ChatOpenAI(model="gpt-4") | parser
fallback1 = prompt | ChatOpenAI(model="gpt-3.5-turbo") | parser
fallback2 = prompt | ChatOpenAI(base_url="http://localhost:8000") | parser

production_chain = main_chain.with_fallbacks([fallback1, fallback2])
```

### 4. 超时控制

```python
# ✅ 设置超时
chain_with_timeout = chain.with_config({
    "timeout": 30  # 30秒超时
})

# 组合使用
production_chain = (
    chain
    .with_config({"timeout": 30})
    .with_retry(stop_after_attempt=3)
    .with_fallbacks([fallback_chain])
)
```

### 5. 可观测性集成

```python
import os
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = "your_key"

# LangSmith 自动追踪所有错误
result = chain.invoke(input)
# 在 LangSmith 控制台查看错误详情
```

---

## 实战场景

### 场景1：RAG 链的错误处理

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 构建 RAG 链
vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

prompt = ChatPromptTemplate.from_template("""
上下文：{context}
问题：{question}
答案：
""")

# 主 LLM
main_llm = ChatOpenAI(model="gpt-4o-mini")

# 备用 LLM
fallback_llm = ChatOpenAI(model="gpt-3.5-turbo")

parser = StrOutputParser()

# 构建链
base_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | main_llm
    | parser
)

# 添加错误处理
production_chain = (
    base_chain
    .with_retry(
        stop_after_attempt=3,
        wait_exponential_jitter=True,
        retry_if_exception_type=(RateLimitError, APIConnectionError)
    )
    .with_fallbacks([
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | fallback_llm
        | parser
    ])
)

# 使用
try:
    answer = production_chain.invoke("什么是向量数据库？")
    print(answer)
except Exception as e:
    print(f"所有尝试都失败: {e}")
    # 记录日志、发送告警
```

### 场景2：批量处理的错误处理

```python
from typing import List

def safe_batch_invoke(chain, inputs: List, max_workers: int = 5):
    """安全的批量调用，单个失败不影响其他"""
    results = []
    errors = []

    for i, input in enumerate(inputs):
        try:
            result = chain.invoke(input)
            results.append({"index": i, "success": True, "result": result})
        except Exception as e:
            results.append({"index": i, "success": False, "error": str(e)})
            errors.append({"index": i, "input": input, "error": e})

    return results, errors


# 使用
inputs = [
    {"topic": "AI"},
    {"topic": "ML"},
    {"topic": "DL"}
]

results, errors = safe_batch_invoke(chain, inputs)

print(f"成功: {sum(1 for r in results if r['success'])}/{len(inputs)}")
print(f"失败: {len(errors)}")

for error in errors:
    print(f"  输入 {error['index']}: {error['error']}")
```

---

## 常见错误类型

### LangChain 常见错误

| 错误类型 | 原因 | 处理策略 |
|---------|------|----------|
| `RateLimitError` | API 限流 | 重试 + 指数退避 |
| `APIConnectionError` | 网络错误 | 重试 |
| `AuthenticationError` | 认证失败 | 不重试，检查 API key |
| `ValidationError` | 输入错误 | 不重试，修复输入 |
| `TimeoutError` | 超时 | 重试 + 增加超时时间 |
| `ModelNotFoundError` | 模型不存在 | 降级到其他模型 |

### 错误处理决策树

```
错误发生
  ↓
是临时性错误？
  ├─ 是 → 重试（最多3次）
  │       ↓
  │     重试成功？
  │       ├─ 是 → 返回结果
  │       └─ 否 → 降级
  │
  └─ 否 → 降级
          ↓
        有备用方案？
          ├─ 是 → 尝试备用方案
          │       ↓
          │     备用方案成功？
          │       ├─ 是 → 返回结果
          │       └─ 否 → 抛出异常
          │
          └─ 否 → 抛出异常
```

---

## 学习检查清单

- [ ] 理解错误传播机制
- [ ] 理解 with_retry 的使用
- [ ] 理解 with_fallbacks 的使用
- [ ] 能手写重试和降级逻辑
- [ ] 理解回调系统中的错误处理
- [ ] 了解 2025-2026 最佳实践
- [ ] 能构建生产级错误处理链

---

**版本**: v1.0
**最后更新**: 2026-02-18
**参考来源**:
- LangChain 官方文档
- Medium - 7 Retry & Timeout Policies for Flaky LangChain Tools
- LangChain 错误处理指南
