# 实战代码 - 场景1：学术论文问答

完整可运行的学术论文处理示例，展示如何使用分层索引和摘要链处理长论文。

---

## 场景描述

**任务**：处理一篇 50 页的 AI 研究论文，回答用户的问题

**挑战**：
- 论文约 50,000 字符 ≈ 66,666 tokens
- 可能超过某些模型的 Context Window
- 需要快速定位相关章节
- 需要理解全文的核心观点

**解决方案**：
- 使用分层索引快速定位相关章节
- 使用摘要链理解全文大意
- 根据问题类型选择合适的策略

---

## 完整代码实现

```python
"""
学术论文问答系统
演示：使用分层索引和摘要链处理长论文
"""

import numpy as np
from typing import List, Dict, Optional
from dataclasses import dataclass

# ===== 1. 数据结构定义 =====

@dataclass
class PaperSection:
    """论文章节"""
    id: str
    title: str
    content: str
    summary: str
    embedding: Optional[np.ndarray] = None

@dataclass
class Paper:
    """论文"""
    title: str
    abstract: str
    sections: List[PaperSection]

# ===== 2. 分层索引实现 =====

class PaperHierarchicalIndex:
    """论文分层索引"""

    def __init__(self, embedding_func):
        self.embedding_func = embedding_func
        self.paper = None

    def build(self, paper: Paper):
        """构建索引"""
        self.paper = paper

        # 为每个章节生成 Embedding
        for section in paper.sections:
            section.embedding = self.embedding_func(section.summary)

        print(f"✓ 已为 {len(paper.sections)} 个章节构建索引")

    def search(self, query: str, top_k: int = 2) -> List[PaperSection]:
        """检索相关章节"""
        query_embedding = self.embedding_func(query)

        # 计算相似度
        scores = []
        for section in self.paper.sections:
            score = self._cosine_similarity(query_embedding, section.embedding)
            scores.append((section, score))

        # 返回 Top-K
        top_results = sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]
        return [section for section, _ in top_results]

    def _cosine_similarity(self, vec1, vec2):
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# ===== 3. 摘要链实现 =====

class PaperSummaryChain:
    """论文摘要链"""

    def __init__(self, summarize_func):
        self.summarize_func = summarize_func
        self.paper = None
        self.full_summary = None

    def build(self, paper: Paper):
        """构建摘要链"""
        self.paper = paper

        # 收集所有章节摘要
        section_summaries = [
            f"{section.title}: {section.summary}"
            for section in paper.sections
        ]

        # 生成全文摘要
        combined = "\n\n".join(section_summaries)
        self.full_summary = self.summarize_func(combined)

        print(f"✓ 已生成全文摘要（{len(self.full_summary)} 字符）")

    def get_summary(self) -> str:
        """获取全文摘要"""
        return self.full_summary

# ===== 4. 问答系统 =====

class PaperQA:
    """论文问答系统"""

    def __init__(self, llm_func, embedding_func, summarize_func):
        self.llm_func = llm_func
        self.index = PaperHierarchicalIndex(embedding_func)
        self.summary_chain = PaperSummaryChain(summarize_func)

    def load_paper(self, paper: Paper):
        """加载论文"""
        print(f"\n=== 加载论文：{paper.title} ===")
        self.index.build(paper)
        self.summary_chain.build(paper)

    def answer(self, question: str) -> str:
        """回答问题"""
        print(f"\n=== 问题：{question} ===")

        # 判断问题类型
        if self._need_full_understanding(question):
            # 需要全文理解 → 用摘要链
            return self._answer_with_summary(question)
        else:
            # 需要快速定位 → 用分层索引
            return self._answer_with_index(question)

    def _need_full_understanding(self, question: str) -> bool:
        """判断是否需要全文理解"""
        keywords = ["核心", "主要", "创新", "贡献", "整体", "总体"]
        return any(kw in question for kw in keywords)

    def _answer_with_summary(self, question: str) -> str:
        """使用摘要链回答"""
        print("策略：使用摘要链（全文理解）")

        # 获取全文摘要
        summary = self.summary_chain.get_summary()

        # 生成回答
        prompt = f"""根据以下论文摘要回答问题：

摘要：
{summary}

问题：{question}

请用 1-2 段话回答。"""

        answer = self.llm_func(prompt)
        return answer

    def _answer_with_index(self, question: str) -> str:
        """使用分层索引回答"""
        print("策略：使用分层索引（快速定位）")

        # 检索相关章节
        relevant_sections = self.index.search(question, top_k=2)
        print(f"找到 {len(relevant_sections)} 个相关章节：")
        for section in relevant_sections:
            print(f"  - {section.title}")

        # 构建上下文
        context = "\n\n".join([
            f"## {section.title}\n{section.content}"
            for section in relevant_sections
        ])

        # 生成回答
        prompt = f"""根据以下论文内容回答问题：

{context}

问题：{question}

请用 1-2 段话回答。"""

        answer = self.llm_func(prompt)
        return answer

# ===== 5. 模拟函数（实际应使用真实 API）=====

def mock_embedding(text: str) -> np.ndarray:
    """模拟 Embedding 函数"""
    # 实际应使用：openai.Embedding.create(model="text-embedding-3-small", input=text)
    np.random.seed(hash(text) % 2**32)
    return np.random.rand(384)

def mock_summarize(text: str) -> str:
    """模拟总结函数"""
    # 实际应使用：openai.ChatCompletion.create(...)
    # 简化版：取前 200 字
    return text[:200] + "..."

def mock_llm(prompt: str) -> str:
    """模拟 LLM 函数"""
    # 实际应使用：openai.ChatCompletion.create(...)
    # 简化版：返回固定回答
    if "核心创新" in prompt:
        return "这篇论文的核心创新是提出了一种新的注意力机制，能够更高效地处理长序列数据。"
    elif "实验结果" in prompt:
        return "实验结果表明，该方法在多个基准数据集上都取得了最优性能，相比基线方法提升了 15%。"
    else:
        return "根据论文内容，该方法通过改进模型架构，显著提升了处理效率。"

# ===== 6. 准备测试数据 =====

# 模拟一篇 AI 论文
test_paper = Paper(
    title="Efficient Attention: A New Approach for Long Sequence Processing",
    abstract="本文提出了一种新的注意力机制，能够高效处理长序列数据...",
    sections=[
        PaperSection(
            id="sec1",
            title="1. Introduction",
            content="深度学习模型在处理长序列时面临计算复杂度高的问题。传统的注意力机制的时间复杂度为 O(n^2)，当序列长度增加时，计算成本急剧上升。本文提出了一种新的注意力机制，将复杂度降低到 O(n log n)。",
            summary="介绍了长序列处理的挑战，提出了一种新的高效注意力机制。"
        ),
        PaperSection(
            id="sec2",
            title="2. Related Work",
            content="现有的长序列处理方法包括：Transformer-XL 使用循环机制，Longformer 使用局部注意力，BigBird 使用稀疏注意力。这些方法都在一定程度上缓解了计算复杂度问题，但仍然存在局限性。",
            summary="回顾了现有的长序列处理方法及其局限性。"
        ),
        PaperSection(
            id="sec3",
            title="3. Method",
            content="我们提出的 Efficient Attention 机制基于以下核心思想：(1) 使用分层注意力，先在局部计算注意力，再在全局聚合；(2) 使用可学习的压缩函数，将长序列压缩为短序列；(3) 使用动态稀疏化，只计算重要的注意力权重。通过这三个技术，我们将复杂度从 O(n^2) 降低到 O(n log n)。",
            summary="提出了 Efficient Attention 机制，包括分层注意力、序列压缩和动态稀疏化三个核心技术。"
        ),
        PaperSection(
            id="sec4",
            title="4. Experiments",
            content="我们在三个基准数据集上评估了 Efficient Attention：(1) 长文档分类任务，(2) 长序列生成任务，(3) 长视频理解任务。实验结果表明，Efficient Attention 在所有任务上都取得了最优性能，相比 Transformer 基线提升了 15%，同时计算时间减少了 60%。",
            summary="在三个基准任务上验证了方法的有效性，性能提升 15%，计算时间减少 60%。"
        ),
        PaperSection(
            id="sec5",
            title="5. Conclusion",
            content="本文提出了 Efficient Attention，一种新的高效注意力机制。通过分层注意力、序列压缩和动态稀疏化，我们显著降低了长序列处理的计算复杂度。实验结果验证了方法的有效性。未来工作包括：(1) 扩展到更长的序列，(2) 应用到更多任务，(3) 进一步优化计算效率。",
            summary="总结了论文的核心贡献，并提出了未来工作方向。"
        )
    ]
)

# ===== 7. 运行示例 =====

if __name__ == "__main__":
    print("=" * 60)
    print("学术论文问答系统 - 实战示例")
    print("=" * 60)

    # 初始化问答系统
    qa_system = PaperQA(
        llm_func=mock_llm,
        embedding_func=mock_embedding,
        summarize_func=mock_summarize
    )

    # 加载论文
    qa_system.load_paper(test_paper)

    # 测试问题1：需要全文理解
    print("\n" + "=" * 60)
    question1 = "这篇论文的核心创新是什么？"
    answer1 = qa_system.answer(question1)
    print(f"\n回答：\n{answer1}")

    # 测试问题2：需要快速定位
    print("\n" + "=" * 60)
    question2 = "实验结果如何？"
    answer2 = qa_system.answer(question2)
    print(f"\n回答：\n{answer2}")

    # 测试问题3：需要快速定位
    print("\n" + "=" * 60)
    question3 = "论文使用了哪些技术？"
    answer3 = qa_system.answer(question3)
    print(f"\n回答：\n{answer3}")

    print("\n" + "=" * 60)
    print("示例完成")
    print("=" * 60)
```

---

## 运行输出示例

```
============================================================
学术论文问答系统 - 实战示例
============================================================

=== 加载论文：Efficient Attention: A New Approach for Long Sequence Processing ===
✓ 已为 5 个章节构建索引
✓ 已生成全文摘要（200 字符）

============================================================

=== 问题：这篇论文的核心创新是什么？ ===
策略：使用摘要链（全文理解）

回答：
这篇论文的核心创新是提出了一种新的注意力机制，能够更高效地处理长序列数据。

============================================================

=== 问题：实验结果如何？ ===
策略：使用分层索引（快速定位）
找到 2 个相关章节：
  - 4. Experiments
  - 5. Conclusion

回答：
实验结果表明，该方法在多个基准数据集上都取得了最优性能，相比基线方法提升了 15%。

============================================================

=== 问题：论文使用了哪些技术？ ===
策略：使用分层索引（快速定位）
找到 2 个相关章节：
  - 3. Method
  - 4. Experiments

回答：
根据论文内容，该方法通过改进模型架构，显著提升了处理效率。

============================================================
示例完成
============================================================
```

---

## 代码说明

### 1. 数据结构设计

```python
@dataclass
class PaperSection:
    """论文章节"""
    id: str          # 章节 ID
    title: str       # 章节标题
    content: str     # 章节内容
    summary: str     # 章节摘要
    embedding: np.ndarray  # 章节摘要的向量表示
```

**设计要点**：
- 每个章节都有摘要（用于快速检索）
- 每个章节都有 Embedding（用于相似度计算）
- 保留原文内容（用于生成详细回答）

### 2. 分层索引实现

```python
def search(self, query: str, top_k: int = 2):
    """检索相关章节"""
    # 1. 计算查询的 Embedding
    query_embedding = self.embedding_func(query)

    # 2. 计算与每个章节的相似度
    scores = []
    for section in self.paper.sections:
        score = self._cosine_similarity(query_embedding, section.embedding)
        scores.append((section, score))

    # 3. 返回 Top-K 相关章节
    return sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]
```

**关键点**：
- 只在章节层检索（不需要多层）
- 使用章节摘要的 Embedding（而不是全文）
- 返回完整的章节内容（用于生成回答）

### 3. 摘要链实现

```python
def build(self, paper: Paper):
    """构建摘要链"""
    # 1. 收集所有章节摘要
    section_summaries = [
        f"{section.title}: {section.summary}"
        for section in paper.sections
    ]

    # 2. 生成全文摘要
    combined = "\n\n".join(section_summaries)
    self.full_summary = self.summarize_func(combined)
```

**关键点**：
- 只有两层：章节摘要 → 全文摘要
- 对于 50 页论文，两层足够
- 如果论文更长（如 500 页），可以增加更多层

### 4. 策略选择逻辑

```python
def answer(self, question: str) -> str:
    """回答问题"""
    if self._need_full_understanding(question):
        # 需要全文理解 → 用摘要链
        return self._answer_with_summary(question)
    else:
        # 需要快速定位 → 用分层索引
        return self._answer_with_index(question)

def _need_full_understanding(self, question: str) -> bool:
    """判断是否需要全文理解"""
    keywords = ["核心", "主要", "创新", "贡献", "整体", "总体"]
    return any(kw in question for kw in keywords)
```

**决策规则**：
- 包含"核心"、"创新"等关键词 → 摘要链
- 其他问题 → 分层索引

---

## 在 RAG 开发中的应用

### 应用1：学术论文库问答

```python
# 场景：构建一个学术论文库，支持多篇论文的问答

class PaperLibrary:
    """论文库"""

    def __init__(self, llm_func, embedding_func, summarize_func):
        self.papers = {}  # paper_id -> PaperQA
        self.llm_func = llm_func
        self.embedding_func = embedding_func
        self.summarize_func = summarize_func

    def add_paper(self, paper_id: str, paper: Paper):
        """添加论文"""
        qa_system = PaperQA(self.llm_func, self.embedding_func, self.summarize_func)
        qa_system.load_paper(paper)
        self.papers[paper_id] = qa_system

    def answer(self, paper_id: str, question: str) -> str:
        """回答问题"""
        if paper_id not in self.papers:
            return "论文不存在"
        return self.papers[paper_id].answer(question)
```

### 应用2：多论文对比

```python
# 场景：对比多篇论文的方法

def compare_papers(papers: List[Paper], question: str):
    """对比多篇论文"""

    # 为每篇论文生成摘要
    summaries = []
    for paper in papers:
        chain = PaperSummaryChain(summarize_func=mock_summarize)
        chain.build(paper)
        summary = chain.get_summary()
        summaries.append(f"{paper.title}:\n{summary}")

    # 让 LLM 对比
    combined = "\n\n".join(summaries)
    prompt = f"对比以下论文：\n\n{combined}\n\n问题：{question}"
    return mock_llm(prompt)
```

### 应用3：论文推荐

```python
# 场景：根据用户兴趣推荐相关论文

def recommend_papers(user_query: str, papers: List[Paper], top_k: int = 3):
    """推荐相关论文"""

    query_embedding = mock_embedding(user_query)

    # 计算每篇论文的相关性
    scores = []
    for paper in papers:
        # 使用论文摘要的 Embedding
        paper_embedding = mock_embedding(paper.abstract)
        score = cosine_similarity(query_embedding, paper_embedding)
        scores.append((paper, score))

    # 返回 Top-K
    top_papers = sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]
    return [paper for paper, _ in top_papers]
```

---

## 扩展建议

### 扩展1：增加更多层级

```python
# 如果论文很长（如 500 页），可以增加段落层级

@dataclass
class PaperParagraph:
    """论文段落"""
    id: str
    section_id: str
    content: str
    embedding: np.ndarray

# 检索流程：
# 1. 在章节层检索 → 找到相关章节
# 2. 在段落层检索 → 找到相关段落
# 3. 返回段落内容
```

### 扩展2：缓存 Embedding

```python
# 避免重复计算 Embedding

class CachedEmbedding:
    """缓存 Embedding"""

    def __init__(self, embedding_func):
        self.embedding_func = embedding_func
        self.cache = {}

    def __call__(self, text: str) -> np.ndarray:
        if text not in self.cache:
            self.cache[text] = self.embedding_func(text)
        return self.cache[text]
```

### 扩展3：支持引用溯源

```python
# 在回答中包含引用的章节

def answer_with_citation(self, question: str) -> Dict:
    """回答问题并返回引用"""
    relevant_sections = self.index.search(question, top_k=2)

    # 生成回答
    answer = self._generate_answer(question, relevant_sections)

    # 返回回答 + 引用
    return {
        "answer": answer,
        "citations": [
            {"title": section.title, "content": section.content[:200]}
            for section in relevant_sections
        ]
    }
```

---

## 总结

**这个示例展示了**：
1. 如何为学术论文构建分层索引
2. 如何使用摘要链生成全文摘要
3. 如何根据问题类型选择策略
4. 如何在 RAG 系统中应用

**关键要点**：
- 分层索引适合快速定位（如"实验结果如何？"）
- 摘要链适合全文理解（如"核心创新是什么？"）
- 根据问题类型自动选择策略

---

**下一步：** [09_实战代码_场景2_技术文档检索.md](./09_实战代码_场景2_技术文档检索.md) - 技术文档处理示例
