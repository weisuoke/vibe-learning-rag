# 核心概念4：漏桶算法

> 流量整形算法，输出速率恒定

---

## 概述

**漏桶算法**（Leaky Bucket）用于流量整形，请求进入队列，以固定速率处理，队列满了就拒绝。

**核心思想：**
```
请求进入漏桶队列
以固定速率从桶底漏出（处理）
队列满了就拒绝新请求
输出速率恒定，平滑流量
```

---

## 算法原理

### 基本概念

**漏桶 = 队列 + 固定处理速率**

```
输入流量（可变） → 漏桶队列 → 输出流量（恒定）
                    ↓
                处理速率（固定）

队列容量（capacity）：最多存储多少请求
处理速率（rate）：每秒处理多少请求
当前队列长度（queue_size）：队列里现在有多少请求
```

### 可视化

```
漏桶：capacity=10, rate=2个/秒

时间 0秒：
┌─────────────────────────┐
│                         │ queue=0
│                         │
│                         │
└───────────┬─────────────┘
            ↓ 2个/秒

时间 1秒（5个请求进入）：
┌─────────────────────────┐
│ ●●●●●                   │ queue=5
│                         │
│                         │
└───────────┬─────────────┘
            ↓ 2个/秒

时间 2秒（无新请求）：
┌─────────────────────────┐
│ ●●●                     │ queue=3 (处理了2个)
│                         │
│                         │
└───────────┬─────────────┘
            ↓ 2个/秒

时间 3秒（10个请求进入）：
┌─────────────────────────┐
│ ●●●●●●●●●●              │ queue=10 (满)
│ ❌❌❌                   │ 拒绝3个
│                         │
└───────────┬─────────────┘
            ↓ 2个/秒
```

---

## 手写实现

### 版本1：最简单的实现

```python
import time
from collections import deque

class LeakyBucket:
    """
    漏桶限流器

    原理：请求进入队列，以固定速率处理
    """

    def __init__(self, rate: float, capacity: int):
        """
        Args:
            rate: 处理速率（个/秒）
            capacity: 队列容量
        """
        self.rate = rate
        self.capacity = capacity
        self.queue = deque()
        self.last_time = time.time()

    def acquire(self) -> bool:
        """
        尝试添加请求到队列

        Returns:
            True: 添加成功
            False: 队列满，拒绝请求
        """
        now = time.time()
        elapsed = now - self.last_time

        # 处理队列中的请求
        processed = int(elapsed * self.rate)
        for _ in range(min(processed, len(self.queue))):
            self.queue.popleft()

        self.last_time = now

        # 检查队列是否满
        if len(self.queue) < self.capacity:
            self.queue.append(now)
            return True

        return False

    def get_status(self) -> dict:
        """获取当前状态"""
        now = time.time()
        elapsed = now - self.last_time

        # 计算当前队列长度（不更新状态）
        processed = int(elapsed * self.rate)
        current_size = max(0, len(self.queue) - processed)

        return {
            "queue_size": current_size,
            "capacity": self.capacity,
            "rate": self.rate
        }


# 使用示例
if __name__ == "__main__":
    # 每秒处理2个请求，队列容量10个
    limiter = LeakyBucket(rate=2, capacity=10)

    # 模拟请求
    for i in range(15):
        if limiter.acquire():
            print(f"请求{i}: ✅ 进入队列")
        else:
            print(f"请求{i}: ❌ 队列满")

        status = limiter.get_status()
        print(f"  队列: {status['queue_size']}/{status['capacity']}")

        time.sleep(0.5)
```

---

### 版本2：Redis 实现

```python
import redis
import time

class RedisLeakyBucket:
    """
    基于 Redis 的漏桶限流器

    使用 Redis List 存储队列
    使用 Lua 脚本保证原子性
    """

    LUA_SCRIPT = """
    local key = KEYS[1]
    local rate = tonumber(ARGV[1])
    local capacity = tonumber(ARGV[2])
    local now = tonumber(ARGV[3])

    -- 获取上次处理时间
    local last_time_key = key .. ':last_time'
    local last_time = tonumber(redis.call('GET', last_time_key)) or now

    -- 计算需要处理的请求数
    local elapsed = now - last_time
    local processed = math.floor(elapsed * rate)

    -- 处理队列中的请求
    if processed > 0 then
        for i = 1, processed do
            redis.call('LPOP', key)
        end
        redis.call('SET', last_time_key, now)
        redis.call('EXPIRE', last_time_key, 3600)
    end

    -- 获取当前队列长度
    local queue_size = redis.call('LLEN', key)

    -- 检查队列是否满
    if queue_size < capacity then
        redis.call('RPUSH', key, now)
        redis.call('EXPIRE', key, 3600)
        return 1
    end

    return 0
    """

    def __init__(
        self,
        redis_client: redis.Redis,
        key: str,
        rate: float,
        capacity: int
    ):
        self.redis = redis_client
        self.key = key
        self.rate = rate
        self.capacity = capacity
        self.script_sha = self.redis.script_load(self.LUA_SCRIPT)

    def acquire(self) -> bool:
        """尝试添加请求到队列"""
        now = time.time()

        result = self.redis.evalsha(
            self.script_sha,
            1,
            self.key,
            self.rate,
            self.capacity,
            now
        )

        return result == 1

    def get_status(self) -> dict:
        """获取当前状态"""
        queue_size = self.redis.llen(self.key)

        return {
            "queue_size": queue_size,
            "capacity": self.capacity,
            "rate": self.rate
        }
```

---

## 漏桶 vs 令牌桶

### 核心区别

| 特性 | 漏桶 | 令牌桶 |
|------|------|--------|
| **控制对象** | 处理速率 | 发送速率 |
| **突发流量** | ❌ 不支持 | ✅ 支持 |
| **输出速率** | 恒定 | 可变 |
| **队列** | 有队列 | 无队列 |
| **适用场景** | 流量整形 | API 网关 |

### 行为对比

```python
def compare_leaky_vs_token():
    """对比漏桶和令牌桶"""
    leaky = LeakyBucket(rate=2, capacity=10)
    token = TokenBucket(rate=2, capacity=10)

    print("=== 突发流量测试 ===\n")

    # 突发流量：一次性10个请求
    print("突发流量（一次性10个请求）：")

    leaky_success = sum(1 for _ in range(10) if leaky.acquire())
    token_success = sum(1 for _ in range(10) if token.acquire())

    print(f"漏桶: {leaky_success}/10 进入队列")
    print(f"令牌桶: {token_success}/10 立即通过")

    print(f"\n漏桶状态: {leaky.get_status()}")
    print(f"令牌桶状态: {token.get_status()}")

    # 等待5秒
    time.sleep(5)

    print("\n5秒后：")
    print(f"漏桶状态: {leaky.get_status()}")  # 队列还在处理
    print(f"令牌桶状态: {token.get_status()}")  # 令牌已恢复
```

**输出：**
```
=== 突发流量测试 ===

突发流量（一次性10个请求）：
漏桶: 10/10 进入队列
令牌桶: 10/10 立即通过

漏桶状态: {'queue_size': 10, 'capacity': 10, 'rate': 2}
令牌桶状态: {'tokens': 0, 'capacity': 10, 'rate': 2}

5秒后：
漏桶状态: {'queue_size': 0, 'capacity': 10, 'rate': 2}  # 全部处理完
令牌桶状态: {'tokens': 10, 'capacity': 10, 'rate': 2}  # 令牌恢复
```

---

## 优缺点分析

### 优点

1. **流量整形**
   - 输出速率恒定
   - 保护下游服务

2. **平滑流量**
   - 避免突发流量冲击
   - 适合消息队列

3. **实现简单**
   - 只需要一个队列
   - 时间复杂度 O(1)

---

### 缺点

1. **不支持突发流量**
   - 请求需要排队
   - 延迟增加

2. **队列可能积压**
   - 队列满了就拒绝
   - 需要合理设置容量

3. **用户体验差**
   - 请求需要等待
   - 不适合实时性要求高的场景

---

## 适用场景

### ✅ 适合的场景

1. **流量整形**
   - 保护下游服务
   - 平滑流量

2. **消息队列**
   - 异步处理
   - 不需要实时响应

3. **批量处理**
   - 定时任务
   - 数据同步

---

### ❌ 不适合的场景

1. **实时性要求高**
   - 用户等待时间长
   - 体验差

2. **突发流量场景**
   - 无法利用空闲时间
   - 推荐使用令牌桶

---

## 在 AI Agent 开发中的应用

### 场景1：保护数据库

```python
from fastapi import FastAPI, BackgroundTasks

app = FastAPI()

# 数据库写入限流（每秒最多10个写入）
db_limiter = LeakyBucket(rate=10, capacity=100)


@app.post("/save")
async def save_data(data: dict, background_tasks: BackgroundTasks):
    """保存数据（异步处理）"""
    if not db_limiter.acquire():
        raise HTTPException(status_code=429, detail="Too many writes")

    # 添加到后台任务队列
    background_tasks.add_task(save_to_db, data)

    return {"status": "queued"}


async def save_to_db(data: dict):
    """实际的数据库写入"""
    # 以固定速率写入数据库
    await db.insert(data)
```

---

### 场景2：消息队列限流

```python
class MessageQueueLimiter:
    """消息队列限流器"""

    def __init__(self, rate: float, capacity: int):
        self.limiter = LeakyBucket(rate=rate, capacity=capacity)

    async def publish(self, message: dict):
        """发布消息"""
        if not self.limiter.acquire():
            raise Exception("Queue full")

        # 消息进入队列
        await queue.put(message)


# 使用示例
mq_limiter = MessageQueueLimiter(rate=100, capacity=1000)

@app.post("/publish")
async def publish_message(message: dict):
    try:
        await mq_limiter.publish(message)
        return {"status": "queued"}
    except Exception as e:
        raise HTTPException(status_code=429, detail=str(e))
```

---

## 总结

### 核心要点

1. **漏桶用于流量整形**
   - 输出速率恒定
   - 保护下游服务

2. **不支持突发流量**
   - 请求需要排队
   - 延迟增加

3. **适合异步处理场景**
   - 消息队列
   - 批量处理
   - 数据同步

4. **不适合实时性要求高的场景**
   - 推荐使用令牌桶

---

### 学习检查清单

- [ ] 理解漏桶的原理（队列 + 固定处理速率）
- [ ] 能手写一个简单的漏桶实现
- [ ] 理解漏桶和令牌桶的区别
- [ ] 知道漏桶的适用场景
- [ ] 能用 Redis 实现分布式漏桶

---

**记住：** 漏桶用于流量整形，输出速率恒定，适合保护下游服务。在 AI Agent 开发中，可以用于保护数据库、消息队列等场景。
