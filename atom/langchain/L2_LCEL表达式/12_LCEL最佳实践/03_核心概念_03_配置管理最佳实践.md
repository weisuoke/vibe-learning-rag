# 核心概念：配置管理最佳实践

> **本节目标**：掌握LCEL的配置管理机制，学会使用RunnableConfig实现灵活的运行时配置。

---

## 一、为什么需要配置管理？

### 1.1 多环境部署

**挑战**：同一代码需要在不同环境运行
- 开发环境：详细日志、无限流
- 测试环境：中等日志、模拟限流
- 生产环境：最小日志、严格限流

### 1.2 A/B测试

**需求**：同时运行多个版本
- 版本A：原始prompt
- 版本B：优化prompt
- 需要动态切换

---

## 二、RunnableConfig：核心配置对象

### 2.1 基础结构

```python
from langchain_core.runnables import RunnableConfig

config = RunnableConfig(
    run_name="my_chain",           # 运行名称
    tags=["prod", "v1.0"],         # 标签
    metadata={"user_id": "123"},   # 元数据
    callbacks=[callback],          # 回调
    max_concurrency=10,            # 最大并发
    recursion_limit=25             # 递归限制
)
```

### 2.2 使用方式

```python
# 方式1：with_config（永久配置）
chain = base_chain.with_config({
    "run_name": "production_chain",
    "tags": ["prod"]
})

# 方式2：invoke时传递（临时配置）
result = chain.invoke(
    input,
    config={"tags": ["test"]}
)
```

---

## 三、configurable_fields：动态参数

### 3.1 基础用法

```python
from langchain_core.runnables import ConfigurableField

# 定义可配置字段
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0
).configurable_fields(
    temperature=ConfigurableField(
        id="llm_temperature",
        name="LLM Temperature",
        description="Controls randomness"
    )
)

# 运行时指定
result = chain.invoke(
    input,
    config={"configurable": {"llm_temperature": 0.7}}
)
```

### 3.2 实战场景：用户个性化

```python
# 定义可配置的LLM
llm = ChatOpenAI().configurable_fields(
    temperature=ConfigurableField(id="temp"),
    model=ConfigurableField(id="model")
)

chain = prompt | llm | parser

# 用户A：保守配置
result_a = chain.invoke(
    input,
    config={"configurable": {"temp": 0, "model": "gpt-3.5-turbo"}}
)

# 用户B：创意配置
result_b = chain.invoke(
    input,
    config={"configurable": {"temp": 0.9, "model": "gpt-4o"}}
)
```

---

## 四、configurable_alternatives：组件切换

### 4.1 基础用法

```python
from langchain_core.runnables import ConfigurableField

# 定义可切换的LLM
llm = ChatOpenAI(model="gpt-4o").configurable_alternatives(
    ConfigurableField(id="llm_provider"),
    default_key="openai",
    anthropic=ChatAnthropic(model="claude-3-sonnet"),
    local=Ollama(model="llama2")
)

# 运行时切换
result = chain.invoke(
    input,
    config={"configurable": {"llm_provider": "anthropic"}}
)
```

### 4.2 实战场景：成本优化

```python
# 定义多个模型选项
llm = ChatOpenAI(model="gpt-4o").configurable_alternatives(
    ConfigurableField(id="model_tier"),
    default_key="premium",
    standard=ChatOpenAI(model="gpt-3.5-turbo"),
    budget=Ollama(model="llama2")
)

# 根据用户等级选择
def get_model_tier(user_id: str) -> str:
    user = get_user(user_id)
    if user.is_premium:
        return "premium"
    elif user.is_standard:
        return "standard"
    else:
        return "budget"

# 使用
tier = get_model_tier(user_id)
result = chain.invoke(
    input,
    config={"configurable": {"model_tier": tier}}
)
```

---

## 五、环境变量管理

### 5.1 基础配置

```python
# .env文件
OPENAI_API_KEY=sk-...
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_PROJECT=my_project

# 环境特定配置
ENV=production
LOG_LEVEL=INFO
MAX_CONCURRENCY=10
```

### 5.2 加载配置

```python
from dotenv import load_dotenv
import os

# 加载环境变量
load_dotenv()

# 使用
llm = ChatOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    max_retries=int(os.getenv("MAX_RETRIES", "3"))
)
```

### 5.3 多环境配置

```python
# config.py
import os

ENV = os.getenv("ENV", "development")

if ENV == "production":
    CONFIG = {
        "log_level": "WARNING",
        "max_concurrency": 50,
        "enable_cache": True,
        "debug": False
    }
elif ENV == "staging":
    CONFIG = {
        "log_level": "INFO",
        "max_concurrency": 20,
        "enable_cache": True,
        "debug": False
    }
else:  # development
    CONFIG = {
        "log_level": "DEBUG",
        "max_concurrency": 5,
        "enable_cache": False,
        "debug": True
    }

# 使用
from config import CONFIG

chain = base_chain.with_config({
    "max_concurrency": CONFIG["max_concurrency"]
})
```

---

## 六、配置继承与合并

### 6.1 配置继承

```python
# 基础配置
base_config = {
    "tags": ["prod"],
    "metadata": {"version": "1.0"}
}

# 子链继承配置
chain = (
    step1.with_config(base_config)
    | step2.with_config(base_config)
    | step3.with_config(base_config)
)
```

### 6.2 配置合并

```python
# 全局配置
global_config = {
    "tags": ["prod"],
    "max_concurrency": 10
}

# 运行时合并
result = chain.invoke(
    input,
    config={
        **global_config,
        "run_name": "specific_run",  # 添加新配置
        "tags": ["prod", "test"]     # 覆盖配置
    }
)
```

---

## 七、实战案例

### 7.1 多租户配置

```python
class TenantConfig:
    """租户配置管理"""

    def __init__(self):
        self.configs = {
            "tenant_a": {
                "model": "gpt-4o",
                "max_tokens": 4000,
                "temperature": 0
            },
            "tenant_b": {
                "model": "gpt-3.5-turbo",
                "max_tokens": 2000,
                "temperature": 0.7
            }
        }

    def get_config(self, tenant_id: str) -> dict:
        return self.configs.get(tenant_id, self.configs["tenant_b"])

# 使用
tenant_config = TenantConfig()

llm = ChatOpenAI().configurable_fields(
    model=ConfigurableField(id="model"),
    max_tokens=ConfigurableField(id="max_tokens"),
    temperature=ConfigurableField(id="temperature")
)

chain = prompt | llm | parser

# 为不同租户执行
def process_for_tenant(tenant_id: str, input: str):
    config = tenant_config.get_config(tenant_id)
    return chain.invoke(
        input,
        config={"configurable": config}
    )
```

### 7.2 A/B测试框架

```python
import random

class ABTestConfig:
    """A/B测试配置"""

    def __init__(self):
        self.variants = {
            "A": {
                "prompt_version": "v1",
                "temperature": 0
            },
            "B": {
                "prompt_version": "v2",
                "temperature": 0.3
            }
        }

    def get_variant(self, user_id: str) -> str:
        # 基于user_id哈希分组
        return "A" if hash(user_id) % 2 == 0 else "B"

    def get_config(self, user_id: str) -> dict:
        variant = self.get_variant(user_id)
        return {
            **self.variants[variant],
            "metadata": {"variant": variant, "user_id": user_id}
        }

# 使用
ab_test = ABTestConfig()

prompt_v1 = ChatPromptTemplate.from_template("简洁回答：{question}")
prompt_v2 = ChatPromptTemplate.from_template("详细回答：{question}")

prompt = prompt_v1.configurable_alternatives(
    ConfigurableField(id="prompt_version"),
    default_key="v1",
    v2=prompt_v2
)

chain = prompt | llm | parser

# 执行A/B测试
def process_with_ab_test(user_id: str, question: str):
    config = ab_test.get_config(user_id)
    result = chain.invoke(
        {"question": question},
        config={"configurable": config}
    )
    # 记录指标
    log_ab_test_result(user_id, config["metadata"]["variant"], result)
    return result
```

---

## 八、最佳实践

### 8.1 配置分层

```
全局配置（所有环境共享）
  ↓
环境配置（dev/staging/prod）
  ↓
租户配置（多租户场景）
  ↓
用户配置（个性化）
  ↓
运行时配置（临时覆盖）
```

### 8.2 配置验证

```python
from pydantic import BaseModel, Field

class ChainConfig(BaseModel):
    """配置验证模型"""
    model: str = Field(..., pattern="^gpt-|^claude-")
    temperature: float = Field(ge=0, le=2)
    max_tokens: int = Field(gt=0, le=8000)
    max_concurrency: int = Field(gt=0, le=100)

# 使用
def validate_config(config: dict) -> dict:
    validated = ChainConfig(**config)
    return validated.dict()

# 应用
config = validate_config({
    "model": "gpt-4o",
    "temperature": 0.7,
    "max_tokens": 2000,
    "max_concurrency": 10
})
```

### 8.3 配置文档化

```python
# config_schema.py
"""
配置说明文档

## 环境变量
- OPENAI_API_KEY: OpenAI API密钥（必需）
- ENV: 环境名称（development/staging/production）
- LOG_LEVEL: 日志级别（DEBUG/INFO/WARNING/ERROR）
- MAX_CONCURRENCY: 最大并发数（默认：10）

## 可配置字段
- llm_temperature: LLM温度（0-2，默认：0）
- llm_model: LLM模型（gpt-4o/gpt-3.5-turbo）
- max_tokens: 最大Token数（默认：2000）

## 示例
```python
config = {
    "configurable": {
        "llm_temperature": 0.7,
        "llm_model": "gpt-4o"
    },
    "tags": ["prod"],
    "max_concurrency": 20
}
```
"""
```

---

## 九、总结

### 核心要点

1. **RunnableConfig**：统一的配置对象
2. **configurable_fields**：动态参数调整
3. **configurable_alternatives**：组件热切换
4. **环境变量**：敏感信息管理

### 配置策略

| 场景 | 推荐方案 |
|------|----------|
| 多环境部署 | 环境变量 + 配置文件 |
| A/B测试 | configurable_alternatives |
| 用户个性化 | configurable_fields |
| 租户隔离 | 配置管理类 |

### 实施建议

- ✅ 使用环境变量管理敏感信息
- ✅ 配置分层管理（全局→环境→租户→用户）
- ✅ 配置验证（Pydantic）
- ✅ 配置文档化
- ✅ 运行时动态调整

---

**下一步**：学习【并发与批处理优化】，掌握高性能LCEL应用开发。
