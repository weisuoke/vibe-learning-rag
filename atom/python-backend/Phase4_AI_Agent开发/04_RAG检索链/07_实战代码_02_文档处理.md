# RAG检索链 - 实战代码2：文档处理

> 加载和处理各种格式的文档（PDF、TXT、Markdown）

---

## 完整代码

```python
"""
文档处理完整示例
演示：加载不同格式文档、分块、元数据管理
"""

import os
from dotenv import load_dotenv
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredMarkdownLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

load_dotenv()

# ===== 1. 加载 PDF 文档 =====
print("=== 1. 加载 PDF 文档 ===")

# 创建示例 PDF（实际使用时替换为真实文件）
pdf_path = "example.pdf"
if not os.path.exists(pdf_path):
    print(f"⚠️  {pdf_path} 不存在，跳过 PDF 加载")
    pdf_docs = []
else:
    loader = PyPDFLoader(pdf_path)
    pdf_docs = loader.load()
    print(f"✓ 加载了 {len(pdf_docs)} 页 PDF")
    for i, doc in enumerate(pdf_docs[:2], 1):
        print(f"  页{i}: {doc.page_content[:100]}...")
        print(f"  元数据: {doc.metadata}")

# ===== 2. 加载 TXT 文档 =====
print("\n=== 2. 加载 TXT 文档 ===")

# 创建示例 TXT 文件
txt_path = "example.txt"
with open(txt_path, "w", encoding="utf-8") as f:
    f.write("""Python 是一门高级编程语言。

Python 的设计哲学强调代码可读性。

Python 支持多种编程范式。
""")

loader = TextLoader(txt_path, encoding="utf-8")
txt_docs = loader.load()
print(f"✓ 加载了 {len(txt_docs)} 个 TXT 文档")
print(f"  内容: {txt_docs[0].page_content[:100]}...")

# ===== 3. 加载 Markdown 文档 =====
print("\n=== 3. 加载 Markdown 文档 ===")

# 创建示例 Markdown 文件
md_path = "example.md"
with open(md_path, "w", encoding="utf-8") as f:
    f.write("""# Python 教程

## 简介

Python 是一门编程语言。

## 特点

- 简洁
- 易读
- 强大
""")

loader = UnstructuredMarkdownLoader(md_path)
md_docs = loader.load()
print(f"✓ 加载了 {len(md_docs)} 个 Markdown 文档")
print(f"  内容: {md_docs[0].page_content[:100]}...")

# ===== 4. 文本分块 =====
print("\n=== 4. 文本分块 ===")

# 合并所有文档
all_docs = pdf_docs + txt_docs + md_docs

# 创建分块器
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=200,        # 每块 200 字符
    chunk_overlap=20,      # 重叠 20 字符
    separators=["\n\n", "\n", " ", ""]  # 分隔符优先级
)

# 分块
chunks = text_splitter.split_documents(all_docs)
print(f"✓ 分成 {len(chunks)} 个块")

# 显示前 3 个块
for i, chunk in enumerate(chunks[:3], 1):
    print(f"\n块 {i}:")
    print(f"  内容: {chunk.page_content[:80]}...")
    print(f"  长度: {len(chunk.page_content)} 字符")
    print(f"  元数据: {chunk.metadata}")

# ===== 5. 元数据管理 =====
print("\n=== 5. 元数据管理 ===")

# 为每个块添加自定义元数据
for i, chunk in enumerate(chunks):
    chunk.metadata.update({
        "chunk_id": i,
        "doc_type": "tutorial",
        "language": "zh"
    })

print(f"✓ 为 {len(chunks)} 个块添加了元数据")
print(f"示例元数据: {chunks[0].metadata}")

# ===== 6. 创建向量库 =====
print("\n=== 6. 创建向量库 ===")

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db_docs"
)

print(f"✓ 向量库创建成功，存储了 {len(chunks)} 个块")

# ===== 7. 测试检索（带元数据过滤） =====
print("\n=== 7. 测试检索 ===")

query = "Python 的特点"

# 普通检索
results = vectorstore.similarity_search(query, k=2)
print(f"\n普通检索结果:")
for i, doc in enumerate(results, 1):
    print(f"  [{i}] {doc.page_content[:60]}...")

# 带元数据过滤的检索
results_filtered = vectorstore.similarity_search(
    query,
    k=2,
    filter={"doc_type": "tutorial"}
)
print(f"\n带过滤的检索结果:")
for i, doc in enumerate(results_filtered, 1):
    print(f"  [{i}] {doc.page_content[:60]}...")
    print(f"      元数据: {doc.metadata}")

# ===== 8. 清理临时文件 =====
print("\n=== 8. 清理 ===")
os.remove(txt_path)
os.remove(md_path)
print("✓ 清理完成")

print("\n✓ 文档处理演示完成！")
```

---

## 运行输出示例

```
=== 1. 加载 PDF 文档 ===
⚠️  example.pdf 不存在，跳过 PDF 加载

=== 2. 加载 TXT 文档 ===
✓ 加载了 1 个 TXT 文档
  内容: Python 是一门高级编程语言。

Python 的设计哲学强调代码可读性。

Python 支持多种编程范式。...

=== 3. 加载 Markdown 文档 ===
✓ 加载了 1 个 Markdown 文档
  内容: # Python 教程

## 简介

Python 是一门编程语言。

## 特点

- 简洁
- 易读
- 强大...

=== 4. 文本分块 ===
✓ 分成 3 个块

块 1:
  内容: Python 是一门高级编程语言。

Python 的设计哲学强调代码可读性。...
  长度: 87 字符
  元数据: {'source': 'example.txt'}

块 2:
  内容: # Python 教程

## 简介

Python 是一门编程语言。...
  长度: 156 字符
  元数据: {'source': 'example.md'}

块 3:
  内容: ## 特点

- 简洁
- 易读
- 强大...
  长度: 28 字符
  元数据: {'source': 'example.md'}

=== 5. 元数据管理 ===
✓ 为 3 个块添加了元数据
示例元数据: {'source': 'example.txt', 'chunk_id': 0, 'doc_type': 'tutorial', 'language': 'zh'}

=== 6. 创建向量库 ===
✓ 向量库创建成功，存储了 3 个块

=== 7. 测试检索 ===

普通检索结果:
  [1] Python 是一门高级编程语言。

Python 的设计哲学强调代码可读性。...
  [2] # Python 教程

## 简介

Python 是一门编程语言。...

带过滤的检索结果:
  [1] Python 是一门高级编程语言。

Python 的设计哲学强调代码可读性。...
      元数据: {'source': 'example.txt', 'chunk_id': 0, 'doc_type': 'tutorial', 'language': 'zh'}
  [2] # Python 教程

## 简介

Python 是一门编程语言。...
      元数据: {'source': 'example.md', 'chunk_id': 1, 'doc_type': 'tutorial', 'language': 'zh'}

=== 8. 清理 ===
✓ 清理完成

✓ 文档处理演示完成！
```

---

## 关键技术点

### 1. 文档加载器选择

| 格式 | 加载器 | 特点 |
|------|--------|------|
| PDF | `PyPDFLoader` | 按页分割，保留页码 |
| TXT | `TextLoader` | 简单文本，需指定编码 |
| Markdown | `UnstructuredMarkdownLoader` | 保留结构 |
| HTML | `UnstructuredHTMLLoader` | 提取正文 |

### 2. 分块策略

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=200,        # 块大小
    chunk_overlap=20,      # 重叠避免语义截断
    separators=["\n\n", "\n", " ", ""]  # 优先按段落分割
)
```

### 3. 元数据管理

```python
# 添加元数据
chunk.metadata.update({
    "chunk_id": i,
    "doc_type": "tutorial",
    "language": "zh"
})

# 检索时过滤
results = vectorstore.similarity_search(
    query,
    filter={"doc_type": "tutorial"}
)
```

---

## 最佳实践

1. **chunk_size 选择**：500-1000 字符（中文）
2. **chunk_overlap**：chunk_size 的 10-20%
3. **元数据**：添加来源、类型、时间等信息
4. **编码**：明确指定 `encoding="utf-8"`

---

**下一步**：学习 [07_实战代码_03_向量存储](./07_实战代码_03_向量存储.md)
