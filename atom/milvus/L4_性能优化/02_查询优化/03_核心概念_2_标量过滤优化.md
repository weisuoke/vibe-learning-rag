# 核心概念2：标量过滤优化

**一句话定义：** 标量过滤优化是通过在向量检索前使用标量字段（如类别、时间、用户ID）提前过滤数据，从而大幅减少搜索范围、提升查询性能的关键技术。

---

## 1. 什么是标量过滤？

标量过滤是在向量检索之前，使用标量字段（非向量字段）对数据进行筛选的过程。

**核心思想：** 先用快速的标量过滤缩小范围，再用慢速的向量检索找到最相似的结果

```python
from pymilvus import Collection

collection = Collection("documents")

# 标量过滤示例
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10,
    expr="category == 'technology' and publish_date > '2024-01-01'"  # 标量过滤
)

# 执行顺序：
# 1. 标量过滤：1000万 → 10万（使用标量索引，1ms）
# 2. 向量检索：在 10万 中搜索（50ms）
# 总延迟：51ms

# 如果不用标量过滤：
# 1. 向量检索：在 1000万 中搜索（500ms）
# 总延迟：500ms

# 性能提升：10倍！
```

---

## 2. 标量过滤的原理

### 2.1 执行顺序

```
查询流程：
1. 解析 expr 表达式
2. 使用标量索引快速定位满足条件的数据
3. 在过滤后的数据中进行向量检索
4. 返回 top_k 结果

关键：标量过滤先执行，向量检索后执行
```

### 2.2 为什么标量过滤更快？

**标量过滤：** O(log n) - 使用 B-tree 索引
**向量检索：** O(n × d) - 需要计算距离

```python
# 场景：1000万数据，768维向量

# 标量过滤（使用 B-tree 索引）
# 时间复杂度：O(log n) = O(log 10000000) ≈ 23 次比较
# 实际耗时：1ms

# 向量检索（计算距离）
# 时间复杂度：O(n × d) = O(10000000 × 768) = 76.8亿次运算
# 实际耗时：500ms

# 结论：标量过滤比向量检索快 500 倍！
```

---

## 3. 标量过滤表达式（expr）

### 3.1 基本语法

**比较运算符：**
```python
# 等于
expr="category == 'technology'"

# 不等于
expr="status != 'deleted'"

# 大于/小于
expr="price > 100"
expr="publish_date < '2024-01-01'"

# 大于等于/小于等于
expr="rating >= 4.5"
expr="age <= 30"
```

**逻辑运算符：**
```python
# AND（与）
expr="category == 'tech' and price > 100"

# OR（或）
expr="category == 'tech' or category == 'science'"

# NOT（非）
expr="not (status == 'deleted')"

# 组合
expr="(category == 'tech' or category == 'science') and price > 100"
```

**成员运算符：**
```python
# IN（包含）
expr="category in ['tech', 'science', 'engineering']"

# NOT IN（不包含）
expr="status not in ['deleted', 'archived']"
```

**范围运算符：**
```python
# BETWEEN（范围）
expr="price between 100 and 500"

# 等价于
expr="price >= 100 and price <= 500"
```

### 3.2 字符串匹配

```python
# LIKE（模糊匹配）
expr="title like 'Python%'"  # 以 Python 开头

# 注意：Milvus 2.3+ 支持 LIKE
```

### 3.3 数组字段

```python
# 数组包含
expr="array_contains(tags, 'python')"

# 数组长度
expr="array_length(tags) > 3"
```

---

## 4. 标量索引

### 4.1 为什么需要标量索引？

**没有索引：** 全表扫描，O(n)
**有索引：** 快速定位，O(log n)

```python
# 场景：1000万数据，查询 category == 'tech'

# 没有索引：
# - 扫描全部 1000万 条数据
# - 耗时：1000ms

# 有索引：
# - 使用 B-tree 索引快速定位
# - 耗时：1ms

# 性能提升：1000 倍！
```

### 4.2 创建标量索引

```python
from pymilvus import Collection

collection = Collection("documents")

# 为标量字段创建索引
collection.create_index(
    field_name="category",
    index_params={"index_type": "STL_SORT"}  # 标量索引类型
)

collection.create_index(
    field_name="publish_date",
    index_params={"index_type": "STL_SORT"}
)

collection.create_index(
    field_name="user_id",
    index_params={"index_type": "STL_SORT"}
)

# 注意：必须先创建索引，标量过滤才会快
```

### 4.3 标量索引类型

| 索引类型 | 适用场景 | 说明 |
|---------|---------|------|
| **STL_SORT** | 通用场景 | 默认标量索引，支持所有比较运算 |
| **Trie** | 字符串前缀匹配 | 适用于 LIKE 'prefix%' |
| **INVERTED** | 全文检索 | 适用于文本搜索（Milvus 2.4+） |

---

## 5. 标量过滤的性能优化

### 5.1 选择性高的字段优先

**选择性：** 过滤后剩余数据的比例

```python
# 高选择性（好）：过滤掉 99% 的数据
expr="user_id == 'user123'"  # 1000万 → 1万

# 低选择性（差）：只过滤掉 10% 的数据
expr="status == 'active'"  # 1000万 → 900万

# 原则：优先使用高选择性的字段
```

### 5.2 多条件过滤的顺序

```python
# ✅ 好：高选择性字段在前
expr="user_id == 'user123' and category == 'tech'"
# 执行：1000万 → 1万 → 5000

# ❌ 差：低选择性字段在前
expr="category == 'tech' and user_id == 'user123'"
# 执行：1000万 → 100万 → 5000

# 注意：Milvus 会自动优化顺序，但显式指定更好
```

### 5.3 避免复杂表达式

```python
# ✅ 好：简单表达式
expr="category == 'tech' and price > 100"

# ❌ 差：复杂表达式（函数调用、嵌套）
expr="lower(category) == 'tech' and (price * 1.1) > 100"

# 原则：尽量使用简单的比较运算
```

---

## 6. 在RAG中的应用

### 6.1 多租户知识库

```python
from pymilvus import Collection, connections
from openai import OpenAI

connections.connect("default", host="localhost", port="19530")
collection = Collection("knowledge_base")
collection.load()

client = OpenAI()

def multi_tenant_search(user_id: str, question: str) -> list:
    """多租户搜索：每个用户只能搜索自己的文档"""

    # 生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=question
    )
    query_vector = response.data[0].embedding

    # 向量检索（添加用户过滤）
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=5,
        output_fields=["content"],
        expr=f"user_id == '{user_id}'"  # 只搜索该用户的文档
    )

    return results[0]

# 使用
docs = multi_tenant_search(user_id="user123", question="如何使用API？")
```

### 6.2 时间范围过滤

```python
def recent_docs_search(question: str, days: int = 30) -> list:
    """搜索最近N天的文档"""
    from datetime import datetime, timedelta

    # 计算时间范围
    cutoff_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

    # 生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=question
    )
    query_vector = response.data[0].embedding

    # 向量检索（添加时间过滤）
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=10,
        output_fields=["title", "content", "publish_date"],
        expr=f"publish_date > '{cutoff_date}'"  # 只搜索最近的文档
    )

    return results[0]

# 使用
recent_docs = recent_docs_search("AI 最新进展", days=30)
```

### 6.3 类别过滤

```python
def category_search(question: str, categories: list) -> list:
    """在指定类别中搜索"""

    # 生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=question
    )
    query_vector = response.data[0].embedding

    # 构建类别过滤表达式
    category_expr = " or ".join([f"category == '{cat}'" for cat in categories])

    # 向量检索（添加类别过滤）
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=10,
        output_fields=["title", "content", "category"],
        expr=f"({category_expr})"  # 只搜索指定类别
    )

    return results[0]

# 使用
tech_docs = category_search("机器学习", categories=["tech", "ai", "ml"])
```

### 6.4 组合过滤

```python
def advanced_search(
    user_id: str,
    question: str,
    categories: list = None,
    min_rating: float = 0.0,
    days: int = None
) -> list:
    """高级搜索：组合多个过滤条件"""
    from datetime import datetime, timedelta

    # 生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=question
    )
    query_vector = response.data[0].embedding

    # 构建过滤表达式
    filters = [f"user_id == '{user_id}'"]  # 用户过滤（必须）

    if categories:
        category_expr = " or ".join([f"category == '{cat}'" for cat in categories])
        filters.append(f"({category_expr})")

    if min_rating > 0:
        filters.append(f"rating >= {min_rating}")

    if days:
        cutoff_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        filters.append(f"publish_date > '{cutoff_date}'")

    expr = " and ".join(filters)

    # 向量检索
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"nprobe": 16}},
        limit=10,
        output_fields=["title", "content", "category", "rating", "publish_date"],
        expr=expr
    )

    return results[0]

# 使用
docs = advanced_search(
    user_id="user123",
    question="深度学习教程",
    categories=["tech", "ai"],
    min_rating=4.0,
    days=90
)
```

---

## 7. 性能测试

### 7.1 测试标量过滤的性能提升

```python
import time
import numpy as np
from pymilvus import Collection, connections

connections.connect("default", host="localhost", port="19530")
collection = Collection("documents")
collection.load()

query_vector = np.random.rand(768).tolist()

# 测试1：不使用标量过滤
start = time.time()
results_no_filter = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)
time_no_filter = time.time() - start

# 测试2：使用标量过滤
start = time.time()
results_with_filter = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10,
    expr="category == 'technology'"
)
time_with_filter = time.time() - start

# 输出结果
print(f"不使用标量过滤：{time_no_filter*1000:.2f}ms")
print(f"使用标量过滤：{time_with_filter*1000:.2f}ms")
print(f"性能提升：{time_no_filter/time_with_filter:.1f}x")

# 输出示例：
# 不使用标量过滤：500.23ms
# 使用标量过滤：50.45ms
# 性能提升：9.9x
```

### 7.2 测试不同选择性的影响

```python
# 测试不同选择性的标量过滤
filters = [
    ("user_id == 'user123'", "高选择性（0.1%）"),
    ("category == 'technology'", "中选择性（10%）"),
    ("status == 'active'", "低选择性（90%）"),
]

print("过滤条件 | 选择性 | 延迟(ms) | 提升")
print("---------|--------|----------|------")

for expr, desc in filters:
    start = time.time()
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10,
        expr=expr
    )
    elapsed = time.time() - start
    speedup = time_no_filter / elapsed

    print(f"{desc:20s} | {elapsed*1000:8.2f} | {speedup:5.1f}x")

# 输出示例：
# 过滤条件 | 选择性 | 延迟(ms) | 提升
# ---------|--------|----------|------
# 高选择性（0.1%）   |    10.23 |  48.9x
# 中选择性（10%）    |    50.45 |   9.9x
# 低选择性（90%）    |   450.67 |   1.1x
```

---

## 8. 常见问题

### Q1: 标量过滤会降低性能吗？

**A:** 不会！标量过滤使用索引，速度极快（1ms），而且能大幅减少向量检索的范围，总体性能反而提升。

### Q2: 标量字段必须创建索引吗？

**A:** 强烈建议创建索引。没有索引的标量过滤会变成全表扫描，反而降低性能。

### Q3: 可以在多个字段上过滤吗？

**A:** 可以！使用 `and`、`or` 组合多个条件。建议高选择性字段在前。

### Q4: 标量过滤支持哪些数据类型？

**A:** 支持 int、float、string、bool、array 等常见类型。

---

## 9. 总结

**标量过滤优化的核心：**
1. **先过滤，再检索**：标量过滤在向量检索之前执行
2. **使用索引**：必须为标量字段创建索引
3. **高选择性优先**：优先使用能过滤掉更多数据的字段
4. **简单表达式**：避免复杂的函数调用和嵌套

**最佳实践：**
- 为常用的过滤字段创建索引（user_id、category、date）
- 在 RAG 中使用标量过滤实现多租户、时间范围、类别过滤
- 测试不同过滤条件的性能，选择最优方案
- 标量过滤能将查询性能提升 10-100 倍
