# 自定义Tool - 第一性原理

> 从最基础的真理理解为什么需要自定义Tool

---

## 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题，而不是基于类比或经验。

**应用到自定义Tool：**
- 不是"因为别人都这样做"
- 不是"因为框架提供了这个功能"
- 而是从LLM的本质和限制出发，理解为什么需要Tool

---

## 自定义Tool的第一性原理

### 1. 最基础的定义

**自定义Tool = 让LLM能够调用的函数**

仅此而已！没有更基础的了。

**拆解：**
- **函数**：输入 → 处理 → 输出
- **LLM能够调用**：LLM能理解何时调用、如何调用
- **自定义**：开发者定义功能，不是框架内置的

---

## 2. 为什么需要自定义Tool？

### 核心问题：LLM的本质限制

**LLM是什么？**
- 一个**文本生成模型**
- 基于训练数据的**统计模式**
- 只能处理**文本输入**，生成**文本输出**

**LLM能做什么？**
- ✅ 理解自然语言
- ✅ 生成自然语言
- ✅ 推理和分析
- ✅ 总结和翻译

**LLM不能做什么？**
- ❌ 获取实时数据（天气、新闻、股票）
- ❌ 访问外部系统（数据库、API、文件）
- ❌ 执行精确计算（复杂数学、数据处理）
- ❌ 修改外部状态（发送邮件、更新数据库）

### 从第一性原理推导

```
前提1：LLM只能处理文本
    ↓
前提2：用户需要LLM完成实际任务（查询数据、调用API）
    ↓
推导：LLM需要一种方式来执行"非文本"操作
    ↓
解决方案：Tool（函数调用）
    ↓
LLM生成"调用Tool"的指令 → Tool执行 → 结果返回给LLM → LLM生成回答
```

**类比：**
- **LLM** = 大脑（思考、决策）
- **Tool** = 手脚（执行、操作）
- **Agent** = 大脑 + 手脚（完整的行动者）

---

## 3. 自定义Tool的三层价值

### 价值1：突破LLM的能力边界

**问题：** LLM的训练数据是静态的，无法获取实时信息

**示例：**
```
用户："北京今天天气怎么样？"

没有Tool的LLM：
"抱歉，我无法获取实时天气信息。我的训练数据截止到2025年1月。"

有Tool的LLM：
1. 理解用户需要天气信息
2. 调用get_weather("北京")
3. Tool返回："晴天，25°C"
4. 生成回答："北京今天天气晴朗，温度25°C。"
```

**价值：** Tool让LLM能够访问实时数据，突破训练数据的限制。

### 价值2：实现精确操作

**问题：** LLM是概率模型，不擅长精确计算和操作

**示例：**
```
用户："帮我查询订单ORD-123456的状态"

没有Tool的LLM：
"我无法直接查询数据库。您可以登录系统查看订单状态。"

有Tool的LLM：
1. 理解用户需要查询订单
2. 调用query_order("ORD-123456")
3. Tool查询数据库，返回："订单状态：已发货，预计3天到达"
4. 生成回答："您的订单ORD-123456已发货，预计3天内送达。"
```

**价值：** Tool让LLM能够执行精确的数据库查询、API调用等操作。

### 价值3：扩展LLM的行动能力

**问题：** LLM只能生成文本，无法修改外部状态

**示例：**
```
用户："帮我发邮件给客户，告知订单已发货"

没有Tool的LLM：
"我可以帮您起草邮件内容：
主题：您的订单已发货
内容：尊敬的客户，您的订单已发货...
请您复制这些内容发送给客户。"

有Tool的LLM：
1. 理解用户需要发送邮件
2. 调用send_email(to="customer@example.com", subject="订单已发货", body="...")
3. Tool发送邮件，返回："邮件已发送"
4. 生成回答："我已经给客户发送了订单发货通知邮件。"
```

**价值：** Tool让LLM能够执行实际操作，不仅是生成文本建议。

---

## 4. 从第一性原理推导Tool的设计原则

### 推理链1：为什么Tool必须返回字符串？

```
前提1：LLM只能处理文本
    ↓
前提2：Tool的返回值要给LLM使用
    ↓
推导：Tool的返回值必须是文本（字符串）
    ↓
结论：Tool必须返回字符串，不能返回对象、数组等复杂类型
```

**实践：**
```python
# ❌ 返回对象（LLM无法理解）
@tool
def get_order(order_id: str) -> Order:
    return Order(id=order_id, status="shipped")

# ✅ 返回字符串（LLM可以理解）
@tool
def get_order(order_id: str) -> str:
    order = db.get_order(order_id)
    return f"订单{order.id}的状态是{order.status}"
```

### 推理链2：为什么Tool描述比代码更重要？

```
前提1：LLM通过描述选择Tool
    ↓
前提2：LLM无法"看到"或"理解"代码实现
    ↓
推导：描述是LLM选择Tool的唯一依据
    ↓
结论：描述的质量直接决定Tool是否被正确调用
```

**实践：**
```python
# ❌ 描述不清晰（LLM可能选错）
@tool
def get_data(id: str) -> str:
    """获取数据"""
    return db.query(id)

# ✅ 描述清晰（LLM能准确选择）
@tool
def get_order_details(order_id: str) -> str:
    """获取订单详细信息

    根据订单ID查询订单的完整信息，包括订单状态、商品列表、总金额、收货地址。

    适用场景：
    - 用户询问"我的订单XXX怎么样了？"
    - 用户询问"订单XXX的物流信息"

    Args:
        order_id: 订单ID，格式为ORD-XXXXXX
    """
    return db.query(order_id)
```

### 推理链3：为什么Tool应该返回错误信息而非抛出异常？

```
前提1：Tool的调用者是LLM，不是人类开发者
    ↓
前提2：LLM需要理解错误原因才能做出反应
    ↓
前提3：异常会被框架捕获，LLM看不到
    ↓
推导：错误信息必须以文本形式返回给LLM
    ↓
结论：Tool应该返回错误信息，不是抛出异常
```

**实践：**
```python
# ❌ 抛出异常（LLM看不到错误信息）
@tool
def query_order(order_id: str) -> str:
    order = db.get_order(order_id)
    if not order:
        raise ValueError(f"订单{order_id}不存在")
    return str(order)

# ✅ 返回错误信息（LLM可以理解并处理）
@tool
def query_order(order_id: str) -> str:
    order = db.get_order(order_id)
    if not order:
        return f"错误：订单{order_id}不存在。请检查订单号是否正确。"
    return str(order)
```

### 推理链4：为什么Tool数量要适中？

```
前提1：LLM需要分析所有Tool的描述来选择
    ↓
前提2：Tool越多，描述占用的token越多
    ↓
前提3：token有限制（context window）
    ↓
推导：Tool太多会挤压对话空间，增加选择难度
    ↓
结论：Tool数量要适中（5-10个最佳）
```

**实践：**
```python
# ❌ 提供所有Tool（50个）
all_tools = [tool1, tool2, ..., tool50]
agent = create_agent(tools=all_tools)

# ✅ 根据场景选择Tool（5-10个）
def get_tools_for_scenario(scenario: str):
    if scenario == "customer_service":
        return [query_order, query_user, send_email]
    elif scenario == "data_analysis":
        return [query_database, generate_chart]
    # ...
```

### 推理链5：为什么Tool要异步？

```
前提1：Agent可能需要调用多个Tool
    ↓
前提2：Tool调用通常涉及I/O操作（API、数据库）
    ↓
前提3：同步调用会阻塞，浪费等待时间
    ↓
推导：异步调用可以并发执行，提升效率
    ↓
结论：Tool应该设计为异步（async/await）
```

**实践：**
```python
# ❌ 同步Tool（串行执行，慢）
@tool
def fetch_weather(city: str) -> str:
    response = httpx.get(f"/weather?city={city}")
    return response.text

# 用户问："北京和上海的天气"
# 执行：fetch_weather("北京") → 3秒
#      fetch_weather("上海") → 3秒
# 总耗时：6秒

# ✅ 异步Tool（并发执行，快）
@tool
async def fetch_weather(city: str) -> str:
    async with httpx.AsyncClient() as client:
        response = await client.get(f"/weather?city={city}")
        return response.text

# 用户问："北京和上海的天气"
# 执行：并发调用
#      fetch_weather("北京") ← 3秒
#      fetch_weather("上海") ← 3秒
# 总耗时：3秒（快一倍！）
```

---

## 5. 从第一性原理推导Tool的架构

### 架构推导

```
需求：让LLM能够调用外部功能
    ↓
问题1：LLM如何知道有哪些Tool可用？
    → 解决：Tool列表（tools=[tool1, tool2, ...]）
    ↓
问题2：LLM如何知道何时调用哪个Tool？
    → 解决：Tool描述（文档字符串）
    ↓
问题3：LLM如何知道Tool需要什么参数？
    → 解决：参数Schema（Pydantic BaseModel）
    ↓
问题4：LLM如何调用Tool？
    → 解决：Agent执行器（AgentExecutor）
    ↓
问题5：Tool如何返回结果给LLM？
    → 解决：返回字符串
    ↓
问题6：Tool执行失败怎么办？
    → 解决：返回错误信息（不抛出异常）
```

### 完整架构

```
用户输入
    ↓
LLM分析（需要什么信息？）
    ↓
查看Tool列表（有哪些Tool可用？）
    ↓
读取Tool描述（哪个Tool能解决问题？）
    ↓
提取参数（从对话中提取参数值）
    ↓
验证参数（Pydantic Schema验证）
    ↓
调用Tool（执行实际操作）
    ↓
Tool返回结果（字符串形式）
    ↓
LLM整合结果（生成最终回答）
    ↓
输出给用户
```

---

## 6. 从第一性原理理解Tool的本质

### Tool的本质：LLM的"手脚"

**类比人类：**
```
人类 = 大脑 + 手脚
    ├── 大脑：思考、决策、理解
    └── 手脚：执行、操作、行动

LLM Agent = LLM + Tools
    ├── LLM：理解、推理、生成文本
    └── Tools：查询数据、调用API、执行操作
```

**为什么这个类比准确？**

1. **大脑不能直接操作物理世界**
   - 大脑只能发出指令
   - 手脚执行指令
   - 结果反馈给大脑

2. **LLM不能直接操作外部系统**
   - LLM只能生成"调用Tool"的指令
   - Tool执行操作
   - 结果返回给LLM

### Tool的本质：函数调用的抽象

**从编程角度：**
```python
# 普通函数调用（开发者直接调用）
result = get_weather("北京")
print(result)

# Tool调用（LLM间接调用）
user_input = "北京今天天气怎么样？"
    ↓
llm_decision = "需要调用get_weather工具"
    ↓
tool_call = get_weather("北京")
    ↓
tool_result = "晴天，25°C"
    ↓
llm_response = "北京今天天气晴朗，温度25°C。"
```

**关键区别：**
- **普通函数**：开发者明确知道调用哪个函数
- **Tool**：LLM根据描述推断应该调用哪个Tool

### Tool的本质：接口契约

**Tool定义了三个契约：**

1. **功能契约**（Tool描述）
   - 这个Tool做什么？
   - 何时应该调用？
   - 返回什么信息？

2. **输入契约**（参数Schema）
   - 需要什么参数？
   - 参数的类型和格式？
   - 参数的验证规则？

3. **输出契约**（返回值）
   - 返回什么格式？（字符串）
   - 成功时返回什么？
   - 失败时返回什么？

**类比API契约：**
```
API契约（给开发者）
├── 端点：POST /api/orders
├── 请求体：{ "order_id": "ORD-123456" }
└── 响应：{ "status": "shipped", "amount": 299.00 }

Tool契约（给LLM）
├── 功能：查询订单详细信息
├── 参数：order_id（订单ID，格式ORD-XXXXXX）
└── 返回：订单状态、商品、金额、地址的文本描述
```

---

## 7. 一句话总结第一性原理

**自定义Tool是LLM突破文本生成限制的唯一方式，通过清晰的描述让LLM理解何时调用，通过严格的Schema验证参数，通过字符串返回值让LLM理解结果，从而实现从"文本生成器"到"任务执行者"的转变。**

---

## 从第一性原理到实践

### 设计Tool的思维框架

**第一步：明确Tool的目的**
```
问自己：
- 这个Tool要解决什么问题？
- LLM为什么需要这个Tool？
- 没有这个Tool，LLM能完成任务吗？
```

**第二步：设计Tool的描述**
```
问自己：
- LLM如何知道何时调用这个Tool？
- 描述是否包含具体的适用场景？
- 描述是否清晰说明返回什么信息？
```

**第三步：定义Tool的参数**
```
问自己：
- 需要哪些参数？
- 参数的类型和格式是什么？
- 如何验证参数的有效性？
```

**第四步：实现Tool的逻辑**
```
问自己：
- 如何执行实际操作？
- 如何处理错误情况？
- 如何返回LLM能理解的结果？
```

### 示例：从第一性原理设计订单查询Tool

**第一步：明确目的**
```
目的：让LLM能够查询订单信息
原因：LLM无法直接访问数据库
价值：用户可以通过对话查询订单，无需登录系统
```

**第二步：设计描述**
```python
@tool
def get_order_details(order_id: str) -> str:
    """获取订单详细信息

    根据订单ID查询订单的完整信息，包括：
    - 订单状态（待支付、已支付、已发货、已完成）
    - 商品列表
    - 总金额
    - 收货地址

    适用场景：
    - 用户询问"我的订单XXX怎么样了？"
    - 用户询问"订单XXX的物流信息"
    - 客服需要查看订单详情

    Args:
        order_id: 订单ID，格式为ORD-XXXXXX

    Returns:
        订单详细信息的文本描述
    """
    pass
```

**第三步：定义参数**
```python
from pydantic import BaseModel, Field

class OrderInput(BaseModel):
    order_id: str = Field(
        description="订单ID，格式为ORD-XXXXXX",
        pattern=r'^ORD-\d{6}$'  # 正则验证格式
    )

@tool(args_schema=OrderInput)
def get_order_details(order_id: str) -> str:
    """..."""
    pass
```

**第四步：实现逻辑**
```python
@tool(args_schema=OrderInput)
def get_order_details(order_id: str) -> str:
    """获取订单详细信息"""
    try:
        # 查询数据库
        order = db.query(Order).filter_by(id=order_id).first()

        # 处理不存在的情况
        if not order:
            return f"错误：订单{order_id}不存在。请检查订单号是否正确。"

        # 格式化返回结果（字符串）
        return f"""订单信息：
订单号：{order.id}
状态：{order.status}
商品：{', '.join([item.name for item in order.items])}
金额：¥{order.total_amount}
地址：{order.shipping_address}
"""
    except DatabaseError as e:
        # 返回错误信息（不抛出异常）
        return f"数据库错误：{str(e)}。请稍后重试。"
    except Exception as e:
        return f"系统错误：{str(e)}。请联系客服。"
```

---

## 核心洞察

### 1. Tool是LLM的能力扩展

**没有Tool的LLM：**
- 只能生成文本
- 无法获取实时数据
- 无法执行实际操作

**有Tool的LLM：**
- 可以查询数据库
- 可以调用API
- 可以发送邮件
- 可以操作文件
- 可以执行计算

**类比：**
- 没有Tool的LLM = 只有大脑的人（只能思考，不能行动）
- 有Tool的LLM = 完整的人（既能思考，又能行动）

### 2. 描述是Tool的灵魂

**为什么？**
- LLM无法"看到"代码
- LLM只能"读懂"描述
- 描述决定Tool是否被调用

**类比：**
- 代码 = 工具的内部结构（用户看不到）
- 描述 = 工具的说明书（用户必须看）

### 3. 字符串是LLM的语言

**为什么Tool必须返回字符串？**
- LLM只能处理文本
- 对象、数组等复杂类型LLM无法理解
- 字符串是LLM和Tool之间的通用语言

**类比：**
- 人类之间用自然语言交流
- LLM和Tool之间用字符串交流

### 4. 错误信息是沟通的一部分

**为什么不抛出异常？**
- 异常会中断执行
- LLM看不到异常信息
- 错误信息要让LLM理解并处理

**类比：**
- 抛出异常 = 挂断电话
- 返回错误 = 解释问题并提供建议

---

## 总结：自定义Tool的第一性原理

**从LLM的本质出发：**
1. LLM只能处理文本 → Tool必须返回字符串
2. LLM通过描述选择Tool → 描述比代码更重要
3. LLM需要理解错误 → 返回错误信息而非抛出异常
4. LLM的token有限 → Tool数量要适中
5. LLM可能并发调用Tool → Tool要异步

**Tool的本质：**
- Tool是LLM的"手脚"
- Tool是函数调用的抽象
- Tool是接口契约

**设计原则：**
- 清晰的描述（让LLM理解何时调用）
- 严格的验证（确保参数有效）
- 友好的错误（让LLM能处理失败）
- 异步的执行（提升并发效率）
- 适中的数量（避免选择困难）

---

**记住：** 理解第一性原理，就能设计出好的Tool，而不是盲目模仿示例代码。
