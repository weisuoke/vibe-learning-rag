# 实战代码 - 场景1：基础性能测试

> 单向量检索性能测试，测试基础性能指标

---

## 场景描述

**测试目标：** 测试 Milvus 的基础检索性能，获取 QPS、延迟、召回率等核心指标

**适用场景：**
- 快速验证系统是否正常工作
- 对比不同索引类型的性能
- 对比不同参数配置的性能
- 建立性能基线

---

## 完整代码

```python
"""
Milvus 基础性能测试
场景：单向量检索性能测试
"""

import time
import numpy as np
from typing import Dict, List
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType
from dataclasses import dataclass
import json

# ===== 1. 配置参数 =====

CONFIG = {
    "milvus_host": "localhost",
    "milvus_port": "19530",
    "collection_name": "benchmark_basic",
    "dim": 768,
    "num_vectors": 1_000_000,  # 100万向量
    "test_iterations": 100,     # 测试100次
    "warmup_iterations": 10     # 预热10次
}

# ===== 2. 数据结构定义 =====

@dataclass
class BenchmarkResult:
    """性能测试结果"""
    config_name: str
    index_type: str
    qps: float
    avg_latency: float
    p50_latency: float
    p95_latency: float
    p99_latency: float
    max_latency: float
    min_latency: float
    std_latency: float
    recall: float

    def to_dict(self):
        """转换为字典"""
        return {
            "配置名称": self.config_name,
            "索引类型": self.index_type,
            "QPS": f"{self.qps:.2f}",
            "平均延迟": f"{self.avg_latency:.2f}ms",
            "P50延迟": f"{self.p50_latency:.2f}ms",
            "P95延迟": f"{self.p95_latency:.2f}ms",
            "P99延迟": f"{self.p99_latency:.2f}ms",
            "最大延迟": f"{self.max_latency:.2f}ms",
            "最小延迟": f"{self.min_latency:.2f}ms",
            "标准差": f"{self.std_latency:.2f}ms",
            "召回率": f"{self.recall:.2%}"
        }

# ===== 3. 数据准备 =====

def prepare_test_data(num_vectors: int, dim: int):
    """准备测试数据"""
    print(f"\n=== 准备测试数据 ===")
    print(f"向量数量: {num_vectors:,}")
    print(f"向量维度: {dim}")

    # 生成随机向量（使用正态分布，更接近真实 Embedding）
    vectors = np.random.normal(0, 1, (num_vectors, dim)).astype(np.float32)

    # 归一化（如果使用 IP 距离）
    vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)

    # 生成 ID 和元数据
    ids = list(range(num_vectors))
    categories = np.random.choice(["A", "B", "C", "D"], num_vectors).tolist()

    print(f"✅ 数据准备完成")

    return {
        "ids": ids,
        "vectors": vectors.tolist(),
        "categories": categories
    }

def create_collection(collection_name: str, dim: int):
    """创建 Collection"""
    print(f"\n=== 创建 Collection: {collection_name} ===")

    # 定义 Schema
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim),
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=10)
    ]

    schema = CollectionSchema(fields=fields, description="Basic benchmark test")

    # 创建 Collection
    collection = Collection(name=collection_name, schema=schema)

    print(f"✅ Collection 创建完成")

    return collection

def insert_data(collection: Collection, data: Dict):
    """插入数据"""
    print(f"\n=== 插入数据 ===")

    start_time = time.time()

    # 批量插入（每次10000条）
    batch_size = 10000
    total = len(data['ids'])

    for i in range(0, total, batch_size):
        batch_data = [
            data['ids'][i:i+batch_size],
            data['vectors'][i:i+batch_size],
            data['categories'][i:i+batch_size]
        ]
        collection.insert(batch_data)

        if (i + batch_size) % 100000 == 0:
            print(f"  已插入: {i + batch_size:,} / {total:,}")

    elapsed = time.time() - start_time
    print(f"✅ 数据插入完成，耗时: {elapsed:.2f}秒")

# ===== 4. 索引创建 =====

def create_index(collection: Collection, index_config: Dict):
    """创建索引"""
    print(f"\n=== 创建索引: {index_config['index_type']} ===")

    start_time = time.time()

    collection.create_index(
        field_name="embedding",
        index_params=index_config
    )

    elapsed = time.time() - start_time
    print(f"✅ 索引创建完成，耗时: {elapsed:.2f}秒")

# ===== 5. 性能测试 =====

def benchmark_search(
    collection: Collection,
    search_params: Dict,
    iterations: int = 100,
    warmup: int = 10
) -> List[float]:
    """执行性能测试"""

    # 准备测试向量
    test_vector = [[0.1] * CONFIG['dim']]

    # 预热系统
    print(f"  预热系统（{warmup}次）...")
    for _ in range(warmup):
        collection.search(
            data=test_vector,
            anns_field="embedding",
            param=search_params,
            limit=10
        )

    # 正式测试
    print(f"  执行测试（{iterations}次）...")
    latencies = []

    for i in range(iterations):
        start = time.time()
        collection.search(
            data=test_vector,
            anns_field="embedding",
            param=search_params,
            limit=10
        )
        latency = (time.time() - start) * 1000
        latencies.append(latency)

        # 进度显示
        if (i + 1) % 20 == 0:
            print(f"    进度: {i + 1}/{iterations}")

    return latencies

def calculate_recall(
    collection: Collection,
    test_vector: List[List[float]],
    search_params: Dict,
    k: int = 10
) -> float:
    """计算召回率"""

    # 1. 使用 FLAT 索引获取 ground truth
    # 注意：需要先创建 FLAT 索引或使用暴力搜索
    ground_truth = collection.search(
        data=test_vector,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {}},
        limit=k
    )
    ground_truth_ids = set([hit.id for hit in ground_truth[0]])

    # 2. 使用目标索引获取检索结果
    search_result = collection.search(
        data=test_vector,
        anns_field="embedding",
        param=search_params,
        limit=k
    )
    search_result_ids = set([hit.id for hit in search_result[0]])

    # 3. 计算召回率
    intersection = ground_truth_ids & search_result_ids
    recall = len(intersection) / len(ground_truth_ids)

    return recall

def analyze_latencies(latencies: List[float]) -> Dict:
    """分析延迟数据"""

    latencies_array = np.array(latencies)

    return {
        "avg": np.mean(latencies_array),
        "p50": np.percentile(latencies_array, 50),
        "p95": np.percentile(latencies_array, 95),
        "p99": np.percentile(latencies_array, 99),
        "max": np.max(latencies_array),
        "min": np.min(latencies_array),
        "std": np.std(latencies_array)
    }

def run_benchmark(
    collection: Collection,
    config_name: str,
    index_config: Dict,
    search_params: Dict
) -> BenchmarkResult:
    """运行完整的性能测试"""

    print(f"\n{'='*60}")
    print(f"测试配置: {config_name}")
    print(f"{'='*60}")

    # 1. 创建索引
    collection.release()
    collection.drop_index()
    create_index(collection, index_config)

    # 2. 加载 Collection
    print(f"\n=== 加载 Collection ===")
    start_time = time.time()
    collection.load()
    load_time = time.time() - start_time
    print(f"✅ Collection 加载完成，耗时: {load_time:.2f}秒")

    # 3. 执行性能测试
    print(f"\n=== 执行性能测试 ===")
    latencies = benchmark_search(
        collection,
        search_params,
        iterations=CONFIG['test_iterations'],
        warmup=CONFIG['warmup_iterations']
    )

    # 4. 分析延迟
    latency_stats = analyze_latencies(latencies)

    # 5. 计算 QPS
    total_time = sum(latencies) / 1000  # 转换为秒
    qps = CONFIG['test_iterations'] / total_time

    # 6. 计算召回率
    print(f"\n=== 计算召回率 ===")
    test_vector = [[0.1] * CONFIG['dim']]
    recall = calculate_recall(collection, test_vector, search_params)

    # 7. 生成结果
    result = BenchmarkResult(
        config_name=config_name,
        index_type=index_config['index_type'],
        qps=qps,
        avg_latency=latency_stats['avg'],
        p50_latency=latency_stats['p50'],
        p95_latency=latency_stats['p95'],
        p99_latency=latency_stats['p99'],
        max_latency=latency_stats['max'],
        min_latency=latency_stats['min'],
        std_latency=latency_stats['std'],
        recall=recall
    )

    # 8. 打印结果
    print(f"\n=== 测试结果 ===")
    for key, value in result.to_dict().items():
        print(f"  {key}: {value}")

    return result

# ===== 6. 主函数 =====

def main():
    """主函数"""

    print("="*60)
    print("Milvus 基础性能测试")
    print("="*60)

    # 1. 连接 Milvus
    print(f"\n=== 连接 Milvus ===")
    connections.connect(
        "default",
        host=CONFIG['milvus_host'],
        port=CONFIG['milvus_port']
    )
    print(f"✅ 连接成功: {CONFIG['milvus_host']}:{CONFIG['milvus_port']}")

    # 2. 准备数据
    data = prepare_test_data(CONFIG['num_vectors'], CONFIG['dim'])

    # 3. 创建 Collection
    collection = create_collection(CONFIG['collection_name'], CONFIG['dim'])

    # 4. 插入数据
    insert_data(collection, data)

    # 5. 定义测试配置
    test_configs = [
        {
            "name": "HNSW (M=16, ef=64)",
            "index": {
                "metric_type": "L2",
                "index_type": "HNSW",
                "params": {"M": 16, "efConstruction": 200}
            },
            "search": {
                "metric_type": "L2",
                "params": {"ef": 64}
            }
        },
        {
            "name": "IVF_FLAT (nlist=1024, nprobe=10)",
            "index": {
                "metric_type": "L2",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            },
            "search": {
                "metric_type": "L2",
                "params": {"nprobe": 10}
            }
        },
        {
            "name": "IVF_FLAT (nlist=1024, nprobe=50)",
            "index": {
                "metric_type": "L2",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            },
            "search": {
                "metric_type": "L2",
                "params": {"nprobe": 50}
            }
        }
    ]

    # 6. 执行测试
    results = []
    for config in test_configs:
        result = run_benchmark(
            collection,
            config['name'],
            config['index'],
            config['search']
        )
        results.append(result)

    # 7. 生成对比报告
    print(f"\n{'='*60}")
    print("性能对比报告")
    print(f"{'='*60}")

    print(f"\n{'配置':<40} {'QPS':<10} {'P95延迟':<12} {'召回率':<10}")
    print("-" * 72)
    for result in results:
        print(f"{result.config_name:<40} {result.qps:<10.2f} {result.p95_latency:<12.2f} {result.recall:<10.2%}")

    # 8. 找出最佳配置
    print(f"\n=== 最佳配置 ===")

    best_qps = max(results, key=lambda x: x.qps)
    print(f"  最高 QPS: {best_qps.config_name} ({best_qps.qps:.2f})")

    best_latency = min(results, key=lambda x: x.p95_latency)
    print(f"  最低延迟: {best_latency.config_name} ({best_latency.p95_latency:.2f}ms)")

    best_recall = max(results, key=lambda x: x.recall)
    print(f"  最高召回率: {best_recall.config_name} ({best_recall.recall:.2%})")

    # 9. 保存结果到 JSON
    output_file = "benchmark_results.json"
    with open(output_file, 'w') as f:
        json.dump([r.to_dict() for r in results], f, indent=2, ensure_ascii=False)
    print(f"\n✅ 结果已保存到: {output_file}")

    # 10. 清理
    print(f"\n=== 清理资源 ===")
    collection.release()
    collection.drop()
    print(f"✅ 清理完成")

if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
Milvus 基础性能测试
============================================================

=== 连接 Milvus ===
✅ 连接成功: localhost:19530

=== 准备测试数据 ===
向量数量: 1,000,000
向量维度: 768
✅ 数据准备完成

=== 创建 Collection: benchmark_basic ===
✅ Collection 创建完成

=== 插入数据 ===
  已插入: 100,000 / 1,000,000
  已插入: 200,000 / 1,000,000
  ...
✅ 数据插入完成，耗时: 45.23秒

============================================================
测试配置: HNSW (M=16, ef=64)
============================================================

=== 创建索引: HNSW ===
✅ 索引创建完成，耗时: 120.45秒

=== 加载 Collection ===
✅ Collection 加载完成，耗时: 8.32秒

=== 执行性能测试 ===
  预热系统（10次）...
  执行测试（100次）...
    进度: 20/100
    进度: 40/100
    进度: 60/100
    进度: 80/100
    进度: 100/100

=== 计算召回率 ===

=== 测试结果 ===
  配置名称: HNSW (M=16, ef=64)
  索引类型: HNSW
  QPS: 1250.32
  平均延迟: 18.45ms
  P50延迟: 17.23ms
  P95延迟: 25.67ms
  P99延迟: 32.18ms
  最大延迟: 45.23ms
  最小延迟: 15.12ms
  标准差: 5.34ms
  召回率: 97.50%

============================================================
测试配置: IVF_FLAT (nlist=1024, nprobe=10)
============================================================
...

============================================================
性能对比报告
============================================================

配置                                      QPS        P95延迟      召回率
------------------------------------------------------------------------
HNSW (M=16, ef=64)                       1250.32    25.67        97.50%
IVF_FLAT (nlist=1024, nprobe=10)         980.45     35.23        92.00%
IVF_FLAT (nlist=1024, nprobe=50)         520.18     68.45        98.50%

=== 最佳配置 ===
  最高 QPS: HNSW (M=16, ef=64) (1250.32)
  最低延迟: HNSW (M=16, ef=64) (25.67ms)
  最高召回率: IVF_FLAT (nlist=1024, nprobe=50) (98.50%)

✅ 结果已保存到: benchmark_results.json

=== 清理资源 ===
✅ 清理完成
```

---

## 代码说明

### 1. 数据准备

```python
# 使用正态分布生成向量，更接近真实 Embedding
vectors = np.random.normal(0, 1, (num_vectors, dim)).astype(np.float32)

# 归一化（如果使用 IP 距离）
vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
```

### 2. 预热系统

```python
# 预热系统，让缓存生效
for _ in range(warmup):
    collection.search(...)
```

**为什么需要预热？**
- 首次查询会触发数据加载、缓存预热
- 预热后的性能更稳定、更接近真实情况

### 3. 百分位数计算

```python
# 使用 numpy 计算百分位数
p95_latency = np.percentile(latencies, 95)
p99_latency = np.percentile(latencies, 99)
```

### 4. 召回率计算

```python
# 使用 FLAT 索引作为 ground truth
ground_truth_ids = set([hit.id for hit in ground_truth[0]])
search_result_ids = set([hit.id for hit in search_result[0]])

# 计算交集
recall = len(ground_truth_ids & search_result_ids) / len(ground_truth_ids)
```

---

## 在 RAG 开发中的应用

### 场景1：选择索引类型

```python
# 测试不同索引类型，选择最适合的
test_configs = [
    {"name": "HNSW", "index": {...}, "search": {...}},
    {"name": "IVF_FLAT", "index": {...}, "search": {...}},
    {"name": "IVF_SQ8", "index": {...}, "search": {...}}
]

# 根据业务需求选择
if 业务需求 == "实时对话":
    选择 = "P95延迟最低的配置"
elif 业务需求 == "批量推荐":
    选择 = "QPS最高的配置"
elif 业务需求 == "高精度检索":
    选择 = "召回率最高的配置"
```

### 场景2：参数调优

```python
# 测试不同 nprobe 值
for nprobe in [5, 10, 20, 50, 100]:
    result = run_benchmark(collection, f"nprobe={nprobe}", ...)
    print(f"nprobe={nprobe}: QPS={result.qps}, 召回率={result.recall}")

# 找到性能和召回率的平衡点
```

### 场景3：容量规划

```python
# 测试不同数据规模
for num_vectors in [100_000, 1_000_000, 10_000_000]:
    result = run_benchmark(collection, f"{num_vectors}向量", ...)
    print(f"{num_vectors}向量: QPS={result.qps}, 内存={memory_usage}GB")

# 预估需要多少台服务器
```

---

## 关键洞察

1. **预热很重要**
   - 首次查询慢10倍以上
   - 预热后性能才稳定

2. **百分位数比平均值重要**
   - P95/P99 代表最差情况
   - 平均值容易被异常值影响

3. **召回率和性能需要权衡**
   - 高召回率 → 高延迟
   - 需要根据业务需求平衡

4. **批量插入提高效率**
   - 每次插入10000条
   - 比单条插入快100倍

5. **结果保存便于对比**
   - 保存为 JSON 格式
   - 方便后续分析和对比

---

## 下一步

完成基础性能测试后，可以进行：
- **场景2：压力测试** - 测试高并发场景
- **场景3：并发测试** - 测试多线程并发
- **场景4：RAG场景测试** - 测试端到端性能
