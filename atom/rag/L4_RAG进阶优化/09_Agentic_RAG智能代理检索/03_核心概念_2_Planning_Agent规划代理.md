# æ ¸å¿ƒæ¦‚å¿µ 2: Planning Agent è§„åˆ’ä»£ç†

## ä¸€å¥è¯å®šä¹‰

**Planning Agent æ˜¯ä»»åŠ¡åˆ†è§£ä¸“å®¶,å°†å¤æ‚æŸ¥è¯¢æ‹†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡åºåˆ—,åœ¨ Agentic RAG ä¸­å®ç°å¤šæ­¥éª¤æ¨ç†å’Œè¿­ä»£æ£€ç´¢ã€‚**

---

## è¯¦ç»†è§£é‡Š

### ä»€ä¹ˆæ˜¯ Planning Agent?

Planning Agent æ˜¯ Agentic RAG çš„"æˆ˜ç•¥è§„åˆ’å¸ˆ",è´Ÿè´£:
- **ä»»åŠ¡åˆ†è§£**: å°†å¤æ‚æŸ¥è¯¢æ‹†åˆ†ä¸ºå­ä»»åŠ¡
- **æ‰§è¡Œè§„åˆ’**: ç¡®å®šå­ä»»åŠ¡çš„æ‰§è¡Œé¡ºåº
- **åŠ¨æ€è°ƒæ•´**: æ ¹æ®æ‰§è¡Œç»“æœé‡æ–°è§„åˆ’

**æ ¸å¿ƒä»·å€¼**: è®© RAG ç³»ç»Ÿèƒ½å¤Ÿå¤„ç†éœ€è¦å¤šæ­¥æ¨ç†çš„å¤æ‚æŸ¥è¯¢ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ Planning Agent?

ä¼ ç»Ÿ RAG çš„å±€é™:
```python
# ä¼ ç»Ÿ RAG: ä¸€æ¬¡æ£€ç´¢,ä¸€æ¬¡ç”Ÿæˆ
query = "æ¯”è¾ƒ 2022 å’Œ 2023 å¹´çš„è¥æ”¶å¢é•¿ç‡,å¹¶åˆ†æåŸå› "
results = retriever.search(query)  # ä¸€æ¬¡æ£€ç´¢
answer = llm.generate(results)     # ä¸€æ¬¡ç”Ÿæˆ
# é—®é¢˜: æ— æ³•åˆ†æ­¥å¤„ç†å¤æ‚é€»è¾‘
```

**å¤æ‚æŸ¥è¯¢éœ€è¦å¤šæ­¥éª¤**:
1. æ£€ç´¢ 2022 å¹´è¥æ”¶æ•°æ®
2. æ£€ç´¢ 2023 å¹´è¥æ”¶æ•°æ®
3. è®¡ç®—å¢é•¿ç‡
4. æ£€ç´¢ç›¸å…³åˆ†ææŠ¥å‘Š
5. ç»¼åˆç”Ÿæˆç­”æ¡ˆ

### Planning Agent å¦‚ä½•å·¥ä½œ?

**Plan-and-Execute æ¨¡å¼**:
```
å¤æ‚æŸ¥è¯¢
    â†“
[è§„åˆ’é˜¶æ®µ] â†’ ç”Ÿæˆä»»åŠ¡åˆ—è¡¨
    â†“
[æ‰§è¡Œé˜¶æ®µ] â†’ é€ä¸ªæ‰§è¡Œä»»åŠ¡
    â†“
[åæ€é˜¶æ®µ] â†’ è¯„ä¼°ç»“æœ,é‡æ–°è§„åˆ’
    â†“
æœ€ç»ˆç­”æ¡ˆ
```

---

## æ ¸å¿ƒåŸç†

### åŸç†å›¾è§£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Planning Agent å·¥ä½œæµç¨‹           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  æŸ¥è¯¢: "æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹"      â”‚
â”‚       â†“                                 â”‚
â”‚  [è§„åˆ’å™¨ Planner]                       â”‚
â”‚   ç”Ÿæˆè®¡åˆ’:                             â”‚
â”‚   1. æ£€ç´¢ BERT çš„æŠ€æœ¯ç‰¹ç‚¹               â”‚
â”‚   2. æ£€ç´¢ GPT çš„æŠ€æœ¯ç‰¹ç‚¹                â”‚
â”‚   3. å¯¹æ¯”ä¸¤è€…çš„ä¼˜ç¼ºç‚¹                   â”‚
â”‚   4. ç”Ÿæˆç»¼åˆåˆ†æ                       â”‚
â”‚       â†“                                 â”‚
â”‚  [æ‰§è¡Œå™¨ Executor]                      â”‚
â”‚   æ‰§è¡Œä»»åŠ¡ 1 â†’ ç»“æœ 1                   â”‚
â”‚   æ‰§è¡Œä»»åŠ¡ 2 â†’ ç»“æœ 2                   â”‚
â”‚   æ‰§è¡Œä»»åŠ¡ 3 â†’ ç»“æœ 3                   â”‚
â”‚   æ‰§è¡Œä»»åŠ¡ 4 â†’ æœ€ç»ˆç­”æ¡ˆ                 â”‚
â”‚       â†“                                 â”‚
â”‚  [åæ€å™¨ Reflector]                     â”‚
â”‚   è¯„ä¼°: ç­”æ¡ˆæ˜¯å¦å®Œæ•´?                   â”‚
â”‚   å†³ç­–: éœ€è¦è¡¥å……ä¿¡æ¯? â†’ é‡æ–°è§„åˆ’        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å·¥ä½œæµç¨‹

**Step 1: è§„åˆ’ (Planning)**
```python
def plan(query: str) -> List[Task]:
    """ç”Ÿæˆä»»åŠ¡è®¡åˆ’"""
    prompt = f"""
    å°†ä»¥ä¸‹æŸ¥è¯¢åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡:
    æŸ¥è¯¢: {query}

    è¦æ±‚:
    - æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹å¯æ‰§è¡Œ
    - ä»»åŠ¡ä¹‹é—´æœ‰é€»è¾‘é¡ºåº
    - æœ€åä¸€ä¸ªä»»åŠ¡æ˜¯ç»¼åˆç­”æ¡ˆ

    ä»»åŠ¡åˆ—è¡¨:
    """
    tasks = llm.predict(prompt)
    return parse_tasks(tasks)
```

**Step 2: æ‰§è¡Œ (Execution)**
```python
def execute(tasks: List[Task]) -> List[Result]:
    """æ‰§è¡Œä»»åŠ¡åˆ—è¡¨"""
    results = []
    for task in tasks:
        result = execute_task(task)
        results.append(result)
    return results
```

**Step 3: åæ€ (Reflection)**
```python
def reflect(results: List[Result]) -> Decision:
    """è¯„ä¼°ç»“æœå¹¶å†³ç­–"""
    prompt = f"""
    è¯„ä¼°ä»¥ä¸‹æ‰§è¡Œç»“æœ:
    {results}

    é—®é¢˜:
    1. ç­”æ¡ˆæ˜¯å¦å®Œæ•´?
    2. æ˜¯å¦éœ€è¦è¡¥å……ä¿¡æ¯?
    3. ä¸‹ä¸€æ­¥è¡ŒåŠ¨?

    å†³ç­–:
    """
    decision = llm.predict(prompt)
    return decision
```

### å…³é”®æŠ€æœ¯

**1. Plan-and-Solve (2023)**
```python
# å— Plan-and-Solve è®ºæ–‡å¯å‘
def plan_and_solve(query: str):
    # Step 1: ç”Ÿæˆè®¡åˆ’
    plan = generate_plan(query)

    # Step 2: æ‰§è¡Œè®¡åˆ’
    results = []
    for step in plan:
        result = execute_step(step)
        results.append(result)

    # Step 3: ç»¼åˆç­”æ¡ˆ
    answer = synthesize(results)
    return answer
```

**2. ReAct + Planning (2025)**
```python
# ç»“åˆ ReAct çš„æ¨ç†å’Œè§„åˆ’
def react_planning(query: str):
    plan = generate_plan(query)

    for step in plan:
        # Thought: æ€è€ƒ
        thought = think(step)

        # Action: è¡ŒåŠ¨
        action = decide_action(thought)
        observation = execute_action(action)

        # Reflection: åæ€
        if not is_satisfactory(observation):
            plan = replan(plan, observation)

    return final_answer
```

**3. LangGraph çŠ¶æ€å›¾ (2026)**
```python
from langgraph.graph import StateGraph

# å®šä¹‰çŠ¶æ€å›¾
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("plan", plan_node)
workflow.add_node("execute", execute_node)
workflow.add_node("reflect", reflect_node)

# æ·»åŠ è¾¹
workflow.add_edge("plan", "execute")
workflow.add_conditional_edges(
    "reflect",
    should_continue,
    {
        "continue": "plan",  # é‡æ–°è§„åˆ’
        "end": END           # ç»“æŸ
    }
)
```

---

## æ‰‹å†™å®ç°

```python
"""
Planning Agent ä»é›¶å®ç°
æ¼”ç¤º: Plan-and-Execute æ¨¡å¼
"""

from typing import List, Dict
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===== 1. æ•°æ®ç»“æ„ =====
class Task:
    def __init__(self, description: str, task_id: int):
        self.description = description
        self.task_id = task_id
        self.result = None

class Plan:
    def __init__(self, tasks: List[Task]):
        self.tasks = tasks
        self.current_index = 0

# ===== 2. è§„åˆ’å™¨ =====
def generate_plan(query: str) -> Plan:
    """ç”Ÿæˆä»»åŠ¡è®¡åˆ’"""
    prompt = f"""
    å°†æŸ¥è¯¢åˆ†è§£ä¸º 3-5 ä¸ªå­ä»»åŠ¡,æ¯è¡Œä¸€ä¸ªä»»åŠ¡:

    æŸ¥è¯¢: {query}

    å­ä»»åŠ¡:
    1.
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    # è§£æä»»åŠ¡
    content = response.choices[0].message.content
    task_lines = [line.strip() for line in content.split("\n") if line.strip()]

    tasks = []
    for i, line in enumerate(task_lines):
        # ç§»é™¤ç¼–å·
        description = line.split(".", 1)[-1].strip()
        tasks.append(Task(description, i + 1))

    return Plan(tasks)

# ===== 3. æ‰§è¡Œå™¨ =====
def execute_task(task: Task, context: List[str]) -> str:
    """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
    prompt = f"""
    æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡:
    ä»»åŠ¡: {task.description}

    ä¸Šä¸‹æ–‡:
    {chr(10).join(context)}

    ç»“æœ:
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    return response.choices[0].message.content

# ===== 4. åæ€å™¨ =====
def reflect_on_results(query: str, results: List[str]) -> Dict:
    """è¯„ä¼°ç»“æœè´¨é‡"""
    prompt = f"""
    åŸå§‹æŸ¥è¯¢: {query}

    æ‰§è¡Œç»“æœ:
    {chr(10).join(results)}

    è¯„ä¼°:
    1. ç­”æ¡ˆæ˜¯å¦å®Œæ•´? (æ˜¯/å¦)
    2. æ˜¯å¦éœ€è¦è¡¥å……? (æ˜¯/å¦)
    3. å»ºè®®:

    åªè¿”å› JSON: {{"complete": true/false, "need_more": true/false, "suggestion": "..."}}
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
        response_format={"type": "json_object"}
    )

    import json
    return json.loads(response.choices[0].message.content)

# ===== 5. Planning Agent =====
class PlanningAgent:
    """è§„åˆ’ä»£ç†"""

    def __init__(self):
        self.max_iterations = 3

    def run(self, query: str) -> str:
        """æ‰§è¡Œ Plan-and-Execute"""
        print(f"\n{'='*50}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*50}\n")

        # Step 1: ç”Ÿæˆè®¡åˆ’
        print("ğŸ“‹ ç”Ÿæˆè®¡åˆ’...")
        plan = generate_plan(query)

        for i, task in enumerate(plan.tasks, 1):
            print(f"  {i}. {task.description}")

        # Step 2: æ‰§è¡Œè®¡åˆ’
        print("\nâš™ï¸  æ‰§è¡Œä»»åŠ¡...")
        context = []

        for task in plan.tasks:
            print(f"\n  æ‰§è¡Œä»»åŠ¡ {task.task_id}: {task.description}")
            result = execute_task(task, context)
            task.result = result
            context.append(f"ä»»åŠ¡ {task.task_id} ç»“æœ: {result}")
            print(f"  âœ“ å®Œæˆ")

        # Step 3: åæ€
        print("\nğŸ¤” åæ€ç»“æœ...")
        results = [task.result for task in plan.tasks]
        reflection = reflect_on_results(query, results)

        print(f"  å®Œæ•´æ€§: {'âœ“' if reflection['complete'] else 'âœ—'}")
        print(f"  éœ€è¦è¡¥å……: {'æ˜¯' if reflection['need_more'] else 'å¦'}")

        # Step 4: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        print("\nğŸ“ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
        final_answer = self._synthesize_answer(query, results)

        return final_answer

    def _synthesize_answer(self, query: str, results: List[str]) -> str:
        """ç»¼åˆç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
        prompt = f"""
        åŸºäºä»¥ä¸‹æ‰§è¡Œç»“æœ,å›ç­”åŸå§‹æŸ¥è¯¢:

        æŸ¥è¯¢: {query}

        æ‰§è¡Œç»“æœ:
        {chr(10).join(results)}

        æœ€ç»ˆç­”æ¡ˆ:
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        return response.choices[0].message.content

# ===== 6. æµ‹è¯• =====
if __name__ == "__main__":
    agent = PlanningAgent()

    test_queries = [
        "æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹",
        "è§£é‡Š Transformer çš„å·¥ä½œåŸç†å¹¶ä¸¾ä¾‹è¯´æ˜",
    ]

    for query in test_queries:
        answer = agent.run(query)
        print(f"\n{'='*50}")
        print(f"æœ€ç»ˆç­”æ¡ˆ:\n{answer}")
        print(f"{'='*50}\n")
```

---

## åœ¨ RAG ä¸­çš„åº”ç”¨

### åº”ç”¨åœºæ™¯ 1: å¤šæ–‡æ¡£å¯¹æ¯”åˆ†æ

**é—®é¢˜**: "æ¯”è¾ƒ 2022 å’Œ 2023 å¹´çš„è´¢æŠ¥æ•°æ®"

**Planning Agent æ–¹æ¡ˆ**:
```python
def compare_financial_reports(query: str):
    # ç”Ÿæˆè®¡åˆ’
    plan = [
        "æ£€ç´¢ 2022 å¹´è´¢æŠ¥æ•°æ®",
        "æ£€ç´¢ 2023 å¹´è´¢æŠ¥æ•°æ®",
        "æå–å…³é”®æŒ‡æ ‡",
        "è®¡ç®—å¢é•¿ç‡",
        "ç”Ÿæˆå¯¹æ¯”åˆ†æ"
    ]

    # æ‰§è¡Œè®¡åˆ’
    results = {}
    results["2022"] = retrieve("2022å¹´è´¢æŠ¥")
    results["2023"] = retrieve("2023å¹´è´¢æŠ¥")
    results["metrics"] = extract_metrics(results)
    results["growth"] = calculate_growth(results["metrics"])

    # ç”Ÿæˆç­”æ¡ˆ
    return synthesize_comparison(results)
```

### åº”ç”¨åœºæ™¯ 2: å¤æ‚æŠ€æœ¯é—®é¢˜

**é—®é¢˜**: "å¦‚ä½•ä¼˜åŒ– RAG ç³»ç»Ÿçš„æ£€ç´¢æ€§èƒ½?"

**Planning Agent æ–¹æ¡ˆ**:
```python
def optimize_rag_performance(query: str):
    # ç”Ÿæˆè®¡åˆ’
    plan = [
        "æ£€ç´¢å½“å‰æ€§èƒ½ç“¶é¢ˆ",
        "æ£€ç´¢ä¼˜åŒ–æ–¹æ¡ˆ",
        "è¯„ä¼°æ–¹æ¡ˆå¯è¡Œæ€§",
        "ç”Ÿæˆå®æ–½å»ºè®®"
    ]

    # æ‰§è¡Œè®¡åˆ’
    bottlenecks = retrieve("RAG æ€§èƒ½ç“¶é¢ˆ")
    solutions = retrieve("RAG ä¼˜åŒ–æ–¹æ¡ˆ")
    evaluation = evaluate_solutions(solutions, bottlenecks)
    recommendations = generate_recommendations(evaluation)

    return recommendations
```

### åº”ç”¨åœºæ™¯ 3: ç ”ç©¶åŠ©æ‰‹

**é—®é¢˜**: "æ€»ç»“ 2025 å¹´ Agentic RAG çš„ç ”ç©¶è¿›å±•"

**Planning Agent æ–¹æ¡ˆ**:
```python
def research_summary(query: str):
    # ç”Ÿæˆè®¡åˆ’
    plan = [
        "æ£€ç´¢ 2025 å¹´ç›¸å…³è®ºæ–‡",
        "æå–æ ¸å¿ƒåˆ›æ–°ç‚¹",
        "åˆ†ç±»æ•´ç†",
        "ç”Ÿæˆç»¼è¿°"
    ]

    # æ‰§è¡Œè®¡åˆ’
    papers = retrieve("2025 Agentic RAG è®ºæ–‡")
    innovations = extract_innovations(papers)
    categorized = categorize(innovations)
    summary = generate_summary(categorized)

    return summary
```

---

## ä¸»æµæ¡†æ¶å®ç°

### LangGraph å®ç° (æ¨è)

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List

class AgentState(TypedDict):
    query: str
    plan: List[str]
    results: List[str]
    final_answer: str

def plan_node(state: AgentState):
    """è§„åˆ’èŠ‚ç‚¹"""
    query = state["query"]
    plan = generate_plan(query)
    return {"plan": plan.tasks}

def execute_node(state: AgentState):
    """æ‰§è¡ŒèŠ‚ç‚¹"""
    plan = state["plan"]
    results = []
    for task in plan:
        result = execute_task(task, results)
        results.append(result)
    return {"results": results}

def reflect_node(state: AgentState):
    """åæ€èŠ‚ç‚¹"""
    reflection = reflect_on_results(state["query"], state["results"])
    return {"reflection": reflection}

def should_continue(state: AgentState):
    """å†³ç­–å‡½æ•°"""
    if state.get("reflection", {}).get("complete"):
        return "synthesize"
    return "replan"

# æ„å»ºå›¾
workflow = StateGraph(AgentState)
workflow.add_node("plan", plan_node)
workflow.add_node("execute", execute_node)
workflow.add_node("reflect", reflect_node)

workflow.set_entry_point("plan")
workflow.add_edge("plan", "execute")
workflow.add_edge("execute", "reflect")
workflow.add_conditional_edges(
    "reflect",
    should_continue,
    {
        "synthesize": END,
        "replan": "plan"
    }
)

app = workflow.compile()
```

### LangChain å®ç°

```python
from langchain.agents import AgentExecutor, create_plan_and_execute_agent
from langchain_openai import ChatOpenAI
from langchain.tools import Tool

# å®šä¹‰å·¥å…·
tools = [
    Tool(
        name="Search",
        func=vector_search,
        description="æœç´¢ç›¸å…³æ–‡æ¡£"
    ),
    Tool(
        name="Calculate",
        func=calculator,
        description="æ‰§è¡Œè®¡ç®—"
    )
]

# åˆ›å»º Plan-and-Execute Agent
llm = ChatOpenAI(model="gpt-4o")
agent = create_plan_and_execute_agent(llm, tools)

# æ‰§è¡Œ
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
result = executor.run("æ¯”è¾ƒ 2022 å’Œ 2023 å¹´è¥æ”¶")
```

### LlamaIndex å®ç°

```python
from llama_index.core.agent import ReActAgent
from llama_index.core.tools import QueryEngineTool

# åˆ›å»ºæŸ¥è¯¢å¼•æ“å·¥å…·
query_engine = index.as_query_engine()
query_tool = QueryEngineTool.from_defaults(
    query_engine=query_engine,
    name="search",
    description="æœç´¢æ–‡æ¡£"
)

# åˆ›å»º ReAct Agent (å¸¦è§„åˆ’èƒ½åŠ›)
agent = ReActAgent.from_tools(
    [query_tool],
    llm=llm,
    verbose=True
)

# æ‰§è¡Œ
response = agent.chat("æ¯”è¾ƒ BERT å’Œ GPT")
```

---

## æœ€ä½³å®è·µ (2025-2026)

### æ€§èƒ½ä¼˜åŒ–

**1. å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡**
```python
import asyncio

async def parallel_execute(tasks: List[Task]):
    """å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡"""
    # è¯†åˆ«ç‹¬ç«‹ä»»åŠ¡
    independent_tasks = identify_independent(tasks)

    # å¹¶è¡Œæ‰§è¡Œ
    results = await asyncio.gather(*[
        execute_task_async(task)
        for task in independent_tasks
    ])

    return results
```

**2. ç¼“å­˜ä¸­é—´ç»“æœ**
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def execute_task_cached(task_description: str):
    """ç¼“å­˜ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    return execute_task(task_description)
```

### æˆæœ¬æ§åˆ¶

**1. é™åˆ¶è§„åˆ’æ·±åº¦**
```python
def generate_plan(query: str, max_tasks: int = 5):
    """é™åˆ¶ä»»åŠ¡æ•°é‡"""
    prompt = f"åˆ†è§£ä¸ºæœ€å¤š {max_tasks} ä¸ªå­ä»»åŠ¡: {query}"
    # ...
```

**2. ä½¿ç”¨å°æ¨¡å‹è§„åˆ’**
```python
# è§„åˆ’ç”¨å°æ¨¡å‹
planner_llm = ChatOpenAI(model="gpt-4o-mini")

# æ‰§è¡Œç”¨å¤§æ¨¡å‹
executor_llm = ChatOpenAI(model="gpt-4o")
```

### é”™è¯¯å¤„ç†

**1. ä»»åŠ¡å¤±è´¥é‡è¯•**
```python
def execute_with_retry(task: Task, max_retries: int = 3):
    """ä»»åŠ¡å¤±è´¥é‡è¯•"""
    for attempt in range(max_retries):
        try:
            return execute_task(task)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            print(f"é‡è¯• {attempt + 1}/{max_retries}")
```

**2. åŠ¨æ€é‡æ–°è§„åˆ’**
```python
def adaptive_planning(query: str):
    """è‡ªé€‚åº”è§„åˆ’"""
    plan = generate_plan(query)

    for task in plan.tasks:
        result = execute_task(task)

        # æ ¹æ®ç»“æœè°ƒæ•´è®¡åˆ’
        if not is_satisfactory(result):
            plan = replan(plan, result)

    return plan
```

---

## å¸¸è§é—®é¢˜

### é—®é¢˜ 1: è§„åˆ’å¤ªå¤æ‚å¯¼è‡´æ•ˆç‡ä½?

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. é™åˆ¶è§„åˆ’æ·±åº¦
def simple_plan(query: str):
    """ç®€åŒ–è§„åˆ’"""
    prompt = f"""
    å°†æŸ¥è¯¢åˆ†è§£ä¸º 3 ä¸ªæ ¸å¿ƒæ­¥éª¤:
    {query}

    æ­¥éª¤:
    """
    return generate_plan(prompt)

# 2. å¿«é€Ÿè·¯å¾„
def fast_path_check(query: str):
    """æ£€æŸ¥æ˜¯å¦éœ€è¦è§„åˆ’"""
    if is_simple_query(query):
        return direct_answer(query)
    else:
        return planning_agent(query)
```

### é—®é¢˜ 2: å¦‚ä½•è¯„ä¼°è§„åˆ’è´¨é‡?

**è¯„ä¼°æŒ‡æ ‡**:
```python
def evaluate_plan(plan: Plan, query: str):
    """è¯„ä¼°è§„åˆ’è´¨é‡"""
    metrics = {
        "completeness": check_completeness(plan, query),
        "efficiency": count_redundant_tasks(plan),
        "feasibility": check_feasibility(plan)
    }

    score = (
        metrics["completeness"] * 0.5 +
        (1 - metrics["efficiency"]) * 0.3 +
        metrics["feasibility"] * 0.2
    )

    return score, metrics
```

### é—®é¢˜ 3: è§„åˆ’å¤±è´¥æ€ä¹ˆåŠ?

**å›é€€ç­–ç•¥**:
```python
def robust_planning(query: str):
    """é²æ£’è§„åˆ’"""
    try:
        # å°è¯•è§„åˆ’
        plan = generate_plan(query)
        return execute_plan(plan)
    except Exception as e:
        # å›é€€åˆ°ç®€å•æ¨¡å¼
        print(f"è§„åˆ’å¤±è´¥: {e}, ä½¿ç”¨ç®€å•æ¨¡å¼")
        return simple_rag(query)
```

---

## å‚è€ƒèµ„æº

### è®ºæ–‡
- "Plan-and-Solve Prompting" (arXiv 2305.04091, 2023)
- "Agentic RAG: A Survey" (arXiv 2501.09136, 2025)
- "ReAct: Synergizing Reasoning and Acting" (arXiv 2210.03629, 2022)

### åšå®¢
- LangGraph: "Plan-and-Execute Agent" (2026)
  https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/
- "Building an Agentic RAG System with LangGraph" (Medium, 2025)
- Vellum AI: "Agentic Workflows Guide" (2026)

### æ¡†æ¶æ–‡æ¡£
- LangGraph State Graphs: https://langchain-ai.github.io/langgraph/
- LangChain Plan-and-Execute: https://python.langchain.com/docs/modules/agents/
- LlamaIndex Workflow Agents: https://docs.llamaindex.ai/

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-17
**å­—æ•°**: ~450 è¡Œ
