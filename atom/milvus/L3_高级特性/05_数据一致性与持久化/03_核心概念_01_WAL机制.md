# 核心概念 01：WAL (Write-Ahead Log) 机制

## 什么是 WAL？

**WAL (Write-Ahead Log) 是一种"先记录操作日志，再执行实际操作"的持久化机制，确保即使系统崩溃也能恢复数据。**

---

## 一句话定义

**WAL 是数据库在修改数据前，先将操作记录到日志文件中，确保数据不丢失的机制。**

---

## WAL 的核心原理

### 1. 为什么需要 WAL？

**问题：直接写入磁盘的困境**

```python
# 传统方式：直接写入磁盘
def insert_data_traditional(data):
    # 直接写入存储引擎（随机写，慢）
    storage.write(data)  # 耗时：100ms
    return "OK"

# 问题：
# 1. 随机写很慢（~10MB/s）
# 2. 如果在写入过程中崩溃，数据丢失
# 3. 无法恢复到崩溃前的状态
```

**解决方案：WAL 机制**

```python
# WAL 方式：先记录日志，再写入磁盘
def insert_data_with_wal(data):
    # 1. 先写入 WAL（顺序写，快）
    wal.append(f"INSERT {data}")  # 耗时：10ms

    # 2. 写入内存（快速响应）
    memory.write(data)  # 耗时：1ms

    # 3. 异步刷新到磁盘（后台慢速写）
    background_task.schedule(lambda: storage.write(data))

    return "OK"

# 优势：
# 1. 顺序写很快（~100MB/s）
# 2. 即使崩溃，可以从 WAL 恢复
# 3. 用户体验好（快速响应）
```

---

## WAL 的工作流程

### 完整流程图

```
用户插入数据
    ↓
┌─────────────────────────────────────┐
│ 1. 写入 WAL（顺序写到磁盘）          │
│    - 记录操作类型（INSERT/DELETE）   │
│    - 记录数据内容                    │
│    - 记录时间戳                      │
│    - fsync() 确保持久化              │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ 2. 写入内存（快速响应用户）          │
│    - 更新内存中的数据结构            │
│    - 返回成功给用户                  │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ 3. 异步刷新到存储引擎（后台）        │
│    - 批量写入磁盘                    │
│    - 更新索引                        │
│    - 标记 WAL 为"已刷新"             │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ 4. 定期清理 WAL                      │
│    - 删除已刷新的 WAL                │
│    - 保留最近的 WAL（用于恢复）      │
└─────────────────────────────────────┘
```

---

## WAL 的数据结构

### WAL 文件格式

```python
# WAL 文件结构
class WALEntry:
    def __init__(self, operation, data, timestamp):
        self.operation = operation  # INSERT, DELETE, UPDATE
        self.data = data            # 实际数据
        self.timestamp = timestamp  # 时间戳
        self.checksum = self._calculate_checksum()  # 校验和

    def _calculate_checksum(self):
        # 计算校验和，确保数据完整性
        import hashlib
        content = f"{self.operation}{self.data}{self.timestamp}"
        return hashlib.md5(content.encode()).hexdigest()

# WAL 文件示例
"""
[2024-02-10 10:00:00.123] INSERT id=1 vector=[0.1,0.2,0.3] checksum=abc123
[2024-02-10 10:00:00.456] INSERT id=2 vector=[0.4,0.5,0.6] checksum=def456
[2024-02-10 10:00:01.789] DELETE id=1 checksum=ghi789
"""
```

### WAL 的存储位置

```bash
# Milvus 数据目录结构
/var/lib/milvus/
├── wal/                    # WAL 目录
│   ├── wal_000001.log      # WAL 文件 1
│   ├── wal_000002.log      # WAL 文件 2
│   └── wal_000003.log      # WAL 文件 3（当前）
├── data/                   # 实际数据目录
│   ├── segment_001/
│   └── segment_002/
└── meta/                   # 元数据目录
```

---

## WAL 的崩溃恢复机制

### 崩溃恢复流程

```python
def recover_from_crash():
    """
    系统崩溃后的恢复流程
    """
    print("系统崩溃，开始恢复...")

    # 1. 读取所有 WAL 文件
    wal_files = read_wal_files("/var/lib/milvus/wal/")
    print(f"找到 {len(wal_files)} 个 WAL 文件")

    # 2. 读取最后一次成功刷新的时间戳
    last_flush_timestamp = read_last_flush_timestamp()
    print(f"最后一次刷新时间戳: {last_flush_timestamp}")

    # 3. 重放未刷新的操作
    for entry in wal_files:
        if entry.timestamp > last_flush_timestamp:
            # 验证校验和
            if entry.checksum != entry._calculate_checksum():
                print(f"警告：WAL 条目损坏，跳过: {entry}")
                continue

            # 重放操作
            if entry.operation == "INSERT":
                storage.write(entry.data)
            elif entry.operation == "DELETE":
                storage.delete(entry.data)

            print(f"重放操作: {entry.operation} {entry.data}")

    # 4. 恢复完成
    print("恢复完成！")
    return "OK"

# 恢复示例
"""
系统崩溃，开始恢复...
找到 3 个 WAL 文件
最后一次刷新时间戳: 2024-02-10 09:59:00
重放操作: INSERT id=100 vector=[0.1,0.2,0.3]
重放操作: INSERT id=101 vector=[0.4,0.5,0.6]
重放操作: DELETE id=50
恢复完成！
"""
```

### 崩溃场景分析

```python
# 场景1：写入 WAL 后崩溃（数据安全）
def scenario_1():
    wal.append("INSERT id=1")  # ✓ 已写入 WAL
    # 系统崩溃
    # 重启后：从 WAL 恢复，数据不丢失

# 场景2：写入内存后崩溃（数据安全）
def scenario_2():
    wal.append("INSERT id=1")  # ✓ 已写入 WAL
    memory.write(data)         # ✓ 已写入内存
    # 系统崩溃
    # 重启后：从 WAL 恢复，数据不丢失

# 场景3：刷新到磁盘前崩溃（数据安全）
def scenario_3():
    wal.append("INSERT id=1")  # ✓ 已写入 WAL
    memory.write(data)         # ✓ 已写入内存
    # 系统崩溃（还未刷新到磁盘）
    # 重启后：从 WAL 恢复，数据不丢失

# 场景4：刷新到磁盘后崩溃（数据安全）
def scenario_4():
    wal.append("INSERT id=1")  # ✓ 已写入 WAL
    memory.write(data)         # ✓ 已写入内存
    storage.write(data)        # ✓ 已刷新到磁盘
    # 系统崩溃
    # 重启后：数据已在磁盘，无需恢复
```

---

## WAL 的性能优化

### 1. 批量写入

```python
# 优化前：每次操作都写入 WAL
def insert_one_by_one(data_list):
    for data in data_list:
        wal.append(f"INSERT {data}")  # 每次都 fsync()，慢
        wal.fsync()

# 优化后：批量写入 WAL
def insert_batch(data_list):
    for data in data_list:
        wal.append(f"INSERT {data}")  # 先写入缓冲区
    wal.fsync()  # 一次性 fsync()，快

# 性能对比：
# 优化前：1000 次插入 = 1000 次 fsync() = 10 秒
# 优化后：1000 次插入 = 1 次 fsync() = 0.1 秒
# 性能提升：100 倍
```

### 2. 异步刷新

```python
import threading
import queue

# WAL 异步刷新机制
class AsyncWAL:
    def __init__(self):
        self.buffer = queue.Queue()
        self.flush_thread = threading.Thread(target=self._flush_loop)
        self.flush_thread.start()

    def append(self, entry):
        # 写入缓冲区（快速返回）
        self.buffer.put(entry)

    def _flush_loop(self):
        # 后台线程定期刷新
        while True:
            entries = []
            while not self.buffer.empty():
                entries.append(self.buffer.get())

            if entries:
                # 批量写入磁盘
                with open("/var/lib/milvus/wal/current.log", "a") as f:
                    for entry in entries:
                        f.write(f"{entry}\n")
                    f.flush()
                    os.fsync(f.fileno())

            time.sleep(0.1)  # 每 100ms 刷新一次

# 使用示例
wal = AsyncWAL()
wal.append("INSERT id=1")  # 立即返回，不阻塞
wal.append("INSERT id=2")  # 立即返回，不阻塞
# 后台线程会批量刷新到磁盘
```

### 3. WAL 文件轮转

```python
# WAL 文件轮转机制
class WALRotation:
    def __init__(self, max_size=100 * 1024 * 1024):  # 100MB
        self.max_size = max_size
        self.current_file = None
        self.file_index = 0

    def append(self, entry):
        # 检查当前文件大小
        if self.current_file is None or self._get_file_size() > self.max_size:
            self._rotate()

        # 写入当前文件
        self.current_file.write(f"{entry}\n")

    def _rotate(self):
        # 关闭当前文件
        if self.current_file:
            self.current_file.close()

        # 创建新文件
        self.file_index += 1
        filename = f"/var/lib/milvus/wal/wal_{self.file_index:06d}.log"
        self.current_file = open(filename, "a")
        print(f"轮转到新 WAL 文件: {filename}")

    def _get_file_size(self):
        return os.path.getsize(self.current_file.name)

# 使用示例
wal = WALRotation()
for i in range(1000000):
    wal.append(f"INSERT id={i}")
# 自动轮转到多个 WAL 文件
```

---

## WAL 的清理策略

### 清理流程

```python
def cleanup_wal():
    """
    清理已刷新的 WAL 文件
    """
    # 1. 获取最后一次刷新的时间戳
    last_flush_timestamp = get_last_flush_timestamp()

    # 2. 遍历所有 WAL 文件
    wal_files = list_wal_files("/var/lib/milvus/wal/")

    for wal_file in wal_files:
        # 3. 读取 WAL 文件的最后一条记录
        last_entry = read_last_entry(wal_file)

        # 4. 如果 WAL 文件的所有记录都已刷新，删除文件
        if last_entry.timestamp < last_flush_timestamp:
            os.remove(wal_file)
            print(f"删除已刷新的 WAL 文件: {wal_file}")
        else:
            print(f"保留未刷新的 WAL 文件: {wal_file}")

# 清理示例
"""
删除已刷新的 WAL 文件: wal_000001.log
删除已刷新的 WAL 文件: wal_000002.log
保留未刷新的 WAL 文件: wal_000003.log
"""
```

### 保留策略

```python
# WAL 保留策略配置
class WALRetentionPolicy:
    def __init__(self):
        self.min_wal_files = 3        # 最少保留 3 个 WAL 文件
        self.max_wal_age = 7 * 24 * 3600  # 最多保留 7 天
        self.max_wal_size = 1024 * 1024 * 1024  # 最多保留 1GB

    def should_delete(self, wal_file):
        # 检查是否应该删除 WAL 文件

        # 1. 保留最近的 N 个文件
        recent_files = get_recent_wal_files(self.min_wal_files)
        if wal_file in recent_files:
            return False

        # 2. 删除超过 N 天的文件
        file_age = time.time() - os.path.getmtime(wal_file)
        if file_age > self.max_wal_age:
            return True

        # 3. 删除超过总大小限制的文件
        total_size = sum(os.path.getsize(f) for f in list_wal_files())
        if total_size > self.max_wal_size:
            return True

        return False
```

---

## 在 Milvus 中的实现

### Milvus WAL 的特点

```python
from pymilvus import Collection, connections

connections.connect("default", host="localhost", port="19530")
collection = Collection("test_collection")

# Milvus 自动使用 WAL，用户无需配置
collection.insert([
    {"id": 1, "vector": [0.1, 0.2, 0.3]},
    {"id": 2, "vector": [0.4, 0.5, 0.6]},
])

# WAL 的工作流程（自动）：
# 1. 写入 WAL（持久化）
# 2. 写入内存（快速响应）
# 3. 异步刷新到存储引擎
# 4. 定期清理 WAL

# 用户无需关心 WAL 的细节，Milvus 自动管理
```

### WAL 配置参数

```yaml
# Milvus 配置文件（milvus.yaml）
wal:
  # WAL 文件大小（默认 256MB）
  max_size: 268435456

  # WAL 保留时间（默认 7 天）
  retention_days: 7

  # WAL 刷新间隔（默认 1 秒）
  flush_interval: 1

  # WAL 文件数量上限（默认 64）
  max_files: 64
```

---

## 在 RAG 系统中的应用

### 场景：企业知识库导入

```python
from pymilvus import Collection, connections
import numpy as np

connections.connect("default", host="localhost", port="19530")
collection = Collection("enterprise_kb")

# 场景：导入 100 万条企业文档
print("开始导入企业文档...")

documents = []
for i in range(1000000):
    embedding = np.random.rand(128).tolist()
    documents.append({
        "id": i,
        "vector": embedding,
        "text": f"企业文档 {i}",
        "timestamp": int(time.time())
    })

# 批量插入（自动使用 WAL）
batch_size = 10000
for i in range(0, len(documents), batch_size):
    batch = documents[i:i+batch_size]
    collection.insert(batch)
    print(f"已导入 {i+len(batch)} / {len(documents)} 条文档")

print("导入完成！")

# WAL 的价值：
# 1. 如果在导入过程中系统崩溃，已导入的数据不会丢失
# 2. 重启后自动从 WAL 恢复，继续导入
# 3. 用户无感知，体验良好
```

---

## 核心要点总结

1. **WAL 是"先记账，再转账"**：确保操作不丢失
2. **顺序写比随机写快 10 倍**：WAL 使用顺序写，性能高
3. **崩溃恢复自动化**：系统崩溃后自动从 WAL 恢复
4. **批量写入优化性能**：批量写入 WAL，减少 fsync() 次数
5. **自动清理节省空间**：定期清理已刷新的 WAL 文件
6. **用户无需配置**：Milvus 自动管理 WAL，用户无感知

WAL 是 Milvus 数据持久化的基石，确保数据不丢失！
