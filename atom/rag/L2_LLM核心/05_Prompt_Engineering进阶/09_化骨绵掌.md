# 化骨绵掌：Prompt Engineering进阶

## 知识卡片1：Few-shot Learning核心

**正面：**
```
Few-shot Learning的本质是什么？
```

**背面：**
```
本质：上下文学习(In-Context Learning)

工作原理：
1. 模型在预训练时见过"示例→任务"模式
2. 推理时从2-5个示例中识别模式
3. 应用模式到新输入

关键公式：
示例质量 > 示例数量
3个相关示例 > 10个不相关示例

最佳实践：
- 示例数量：2-5个
- 选择策略：与查询最相关
- 排序：最相关的放最后

RAG应用：
引导模型按特定格式从文档中提取答案

来源：GPT-3 Paper (2020)
```

---

## 知识卡片2：Chain-of-Thought魔法提示词

**正面：**
```
CoT最有效的触发词是什么？
```

**背面：**
```
魔法提示词：
中文："让我们一步步思考："
英文："Let's think step by step:"

为什么有效？
1. 简洁引导优于详细指令
2. 给模型推理自由度
3. 符合人类思考习惯

性能提升：
- 数学推理：+130% (17.7% → 40.7%)
- 常识推理：+14% (69.0% → 79.0%)
- 符号推理：+400% (5.0% → 25.0%)

使用场景：
✅ 数学计算
✅ 逻辑推理
✅ 多步任务
❌ 简单事实查询

来源：Large Language Models are Zero-Shot Reasoners (2022)
```

---

## 知识卡片3：Self-Consistency数学原理

**正面：**
```
Self-Consistency为什么能提升准确率？
```

**背面：**
```
数学原理：
P(n) = 1 - (1-p)^n

其中：
- p = 单次准确率
- n = 采样次数
- P(n) = 投票后准确率

实例计算：
p=0.7, n=5
P(5) = 1 - (1-0.7)^5 = 99.76%

最佳配置：
- 采样次数：5-7次（性价比最高）
- Temperature：0.7（保持多样性）
- 投票策略：简单多数

收益递减：
n=1→3: +8.4%
n=3→5: +5.3%
n=5→7: +3.7%
n=7→10: +3.0%

成本权衡：
n=5时成本是单次的5倍，但准确率提升40%

来源：Self-Consistency Paper (2022)
```

---

## 知识卡片4：ToT vs CoT核心差异

**正面：**
```
Tree of Thoughts与CoT的本质区别？
```

**背面：**
```
结构差异：

CoT（线性）：
问题 → 步骤1 → 步骤2 → 步骤3 → 答案
      ↑ 一条路径，无法回溯

ToT（树形）：
问题 → 思路A → 结果A
    → 思路B → 结果B ✓
    → 思路C → 结果C
      ↑ 多条路径，可比较选择

性能对比：
- 24点游戏：CoT 4% vs ToT 74% (+1750%)
- 创意写作：CoT 12% vs ToT 56% (+367%)

适用场景：
CoT：线性推理（数学、逻辑）
ToT：需要探索（创意、策略、游戏）

成本：
CoT：O(n) 其中n=步骤数
ToT：O(depth × breadth^depth)

来源：Tree of Thoughts (2023)
```

---

## 知识卡片5：ReAct推理-行动循环

**正面：**
```
ReAct的核心循环是什么？
```

**背面：**
```
核心循环：Thought → Action → Observation

Thought（推理）：
- 分析当前状态
- 决定下一步行动

Action（行动）：
- 调用工具（搜索、计算、API）
- 获取新信息

Observation（观察）：
- 查看行动结果
- 更新上下文

vs 静态RAG：
静态：查询 → 检索 → 生成 → 答案
ReAct：查询 → 检索 → 推理 → 再检索 → 答案

性能提升：
- 多跳问答：+38% (45% → 62%)
- 事实验证：+27% (56% → 71%)

适用场景：
✅ 多跳问答
✅ 需要工具调用
✅ 信息不确定
❌ 简单问答（成本高）

来源：ReAct Paper (2022)
```

---

## 知识卡片6：Structured Output必要性

**正面：**
```
为什么需要Structured Output？
```

**背面：**
```
问题：自然语言输出不可靠

示例：
输入："提取姓名和年龄"
可能输出：
- "姓名是张三，年龄30岁"
- "张三\n30"
- "name: 张三, age: 30"
→ 格式不统一，难以解析

解决：强制JSON Schema

response_format = {
    "type": "json_schema",
    "json_schema": {
        "name": "person",
        "schema": {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
            }
        }
    }
}

输出：{"name": "张三", "age": 30}
→ 100%可解析

性能提升：
- 格式准确率：70% → 100% (+43%)
- 解析成功率：75% → 100% (+33%)
- 后处理时间：100ms → 10ms (-90%)

支持模型：
✅ gpt-4o-2024-08-06
✅ gpt-4o-mini-2024-07-18
❌ gpt-3.5-turbo（不支持）

来源：OpenAI Structured Outputs (2024)
```

---

## 知识卡片7：Query Decomposition策略

**正面：**
```
Query Decomposition的拆分策略？
```

**背面：**
```
拆分原则：
复杂查询 → 多个简单子查询

拆分策略：

1. 按主题拆分：
"比较A和B" → ["A的特点", "B的特点"]

2. 按维度拆分：
"从X、Y、Z分析A" → ["A的X", "A的Y", "A的Z"]

3. 按时间拆分：
"A的发展历程" → ["A的早期", "A的中期", "A的现在"]

并行检索：
串行：O(n × t) 其中n=子查询数，t=单次时间
并行：O(t) 理论上与单次相同

性能提升：
- 信息覆盖率：65% → 92% (+42%)
- 答案完整性：70% → 95% (+36%)

适用场景：
✅ 比较类查询
✅ 多维度查询
✅ 时间序列查询
❌ 简单事实查询

来源：NVIDIA RAG Blueprint (2025)
```

---

## 知识卡片8：RAT迭代检索

**正面：**
```
RAT与静态RAG的核心差异？
```

**背面：**
```
核心差异：动态迭代 vs 一次性

静态RAG：
查询 → 检索 → 生成 → 答案
      ↑ 一次性，无法调整

RAT：
查询 → 检索1 → 推理1 → 信息不足
              ↓
         检索2 → 推理2 → 信息充足 → 答案
              ↑ 动态迭代

关键机制：
1. 信息充分性判断
2. 查询改写
3. 迭代优化

性能提升：
- 多跳问答：52% → 73% (+40%)
- 信息完整性：68% → 89% (+31%)
- 时间推理：45% → 78% (+73%)

成本：
迭代次数 × (推理成本 + 检索成本)
通常3-5次迭代

适用场景：
✅ 多跳问答
✅ 时间推理
✅ 信息验证
❌ 简单问答（成本过高）

来源：RAT Paper (2024)
```

---

## 知识卡片9：Meta Prompting自适应

**正面：**
```
Meta Prompting的工作流程？
```

**背面：**
```
工作流程：分析 → 生成 → 执行

步骤1：分析查询类型
查询 → 分类器 → 类型（fact/reasoning/comparison/how-to）

步骤2：生成提示词
类型 → 模板库/LLM → 针对性提示词

步骤3：执行提示词
提示词 → LLM → 答案

两种方法：

模板方法：
- 优势：快速、稳定、成本低
- 劣势：灵活性有限

LLM生成：
- 优势：灵活、适应性强
- 劣势：成本高、不确定性

性能提升：
- 适应性：60% → 85% (+42%)
- 答案质量：72% → 88% (+22%)

成本：
模板：1次LLM调用
LLM生成：2次LLM调用（分析+生成）

来源：Meta Prompting (2024)
```

---

## 知识卡片10：Active Prompting动态选择

**正面：**
```
Active Prompting如何选择示例？
```

**背面：**
```
核心：基于相似度动态选择

vs 固定示例：
固定：所有查询用相同示例
Active：每个查询选择最相关示例

选择算法：

1. 计算相似度：
query_emb = embedding(query)
for example in pool:
    sim = cosine_similarity(query_emb, example_emb)

2. 排序选择：
top_k = sorted(similarities, reverse=True)[:k]

3. 多样性优化（可选）：
score = (1-w) × relevance + w × diversity

性能提升：
- 答案准确率：75% → 89% (+19%)
- 格式一致性：82% → 95% (+16%)
- 适应性：60% → 92% (+53%)

最佳配置：
- 示例池大小：50-100个
- 选择数量：3-5个
- 多样性权重：0.3

适用场景：
✅ 示例池 > 10个
✅ 查询类型多样
❌ 示例池 < 10个（优势不明显）

来源：Active Prompting (2023)
```

---

## 快速记忆口诀

```
Few-shot靠示例，2到5个最合适
CoT要推理，一步步来别着急
Self多次投，5到7次性价比
ToT像树形，多路探索选最优
ReAct推理动，思考行动交替行
Structured强格式，JSON输出最可靠
Query要拆分，复杂问题变简单
RAT能迭代，动态检索补信息
Meta会生成，提示词也能自动化
Active选示例，相似度高效果好
```

---

## 技术选择速查表

| 场景 | 推荐技术 | 原因 |
|------|---------|------|
| 格式引导 | Few-shot | 快速、有效 |
| 推理任务 | CoT | 提升准确率 |
| 关键任务 | Self-Consistency | 高可靠性 |
| 探索任务 | ToT | 多路径比较 |
| 工具调用 | ReAct | 动态交互 |
| 数据提取 | Structured Output | 100%可解析 |
| 复杂查询 | Query Decomposition | 拆分简化 |
| 多跳问答 | RAT | 迭代优化 |
| 多任务 | Meta Prompting | 自适应 |
| 大示例池 | Active Prompting | 智能选择 |

---

## 成本vs效果对比

| 技术 | 成本 | 效果提升 | 性价比 |
|------|------|---------|--------|
| Few-shot | ★☆☆☆☆ | +20% | ★★★★★ |
| CoT | ★★☆☆☆ | +30% | ★★★★☆ |
| Self-Consistency | ★★★★☆ | +40% | ★★★☆☆ |
| ToT | ★★★★★ | +50% | ★★☆☆☆ |
| ReAct | ★★★☆☆ | +35% | ★★★☆☆ |
| Structured Output | ★☆☆☆☆ | +25% | ★★★★★ |
| Query Decomposition | ★★★☆☆ | +35% | ★★★★☆ |
| RAT | ★★★★★ | +50% | ★★☆☆☆ |
| Meta Prompting | ★★★★☆ | +30% | ★★☆☆☆ |
| Active Prompting | ★★☆☆☆ | +25% | ★★★★☆ |

---

## 参考资源

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [OpenAI Documentation](https://platform.openai.com/docs/)
- [Anthropic Prompt Engineering](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [NVIDIA RAG Blueprint](https://docs.nvidia.com/rag/2.3.0/)
