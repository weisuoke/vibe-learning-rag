# 核心概念6：查询扩展

> 查询扩展是通过增加同义词、相关词或使用LLM改写查询来提升召回率的技术，2025-2026年已成为混合检索优化的重要手段

---

## 什么是查询扩展？

### 一句话定义

**查询扩展（Query Expansion）是通过添加同义词、相关词或使用LLM改写原始查询，生成多个查询变体来提升检索召回率的技术。**

### 核心特点

1. **提升召回率**：覆盖更多相关文档
2. **多样化查询**：生成多个查询变体
3. **语义扩展**：理解查询意图并扩展
4. **LLM驱动**：2025-2026年主流使用LLM

---

## 查询扩展原理

### 1. 为什么需要查询扩展？

**问题：用户查询表达不完整**

```
用户查询："Python异步"

问题：
- 表达不完整（缺少"编程"）
- 缺少同义词（"asyncio"、"协程"）
- 缺少相关概念（"事件循环"、"并发"）

结果：
- 遗漏相关文档
- 召回率低
```

**解决方案：查询扩展**

```
原始查询："Python异步"

扩展后：
1. "Python异步编程"
2. "Python asyncio"
3. "Python协程"
4. "Python并发编程"
5. "Python事件循环"

结果：
- 覆盖更多相关文档
- 召回率提升30-50%
```

### 2. 查询扩展方法

#### 方法1：同义词扩展

**原理**：添加同义词和相关词

```
查询："汽车"

同义词扩展：
- "汽车"
- "车辆"
- "轿车"
- "机动车"

优点：简单直接
缺点：需要维护同义词库
```

#### 方法2：LLM查询改写

**原理**：使用LLM理解查询意图并改写

```
查询："Python异步"

LLM改写：
1. "Python异步编程完整指南"
2. "如何使用Python的asyncio库"
3. "Python协程和异步函数详解"
4. "Python并发编程最佳实践"

优点：理解语义，生成高质量查询
缺点：需要LLM API调用
```

#### 方法3：HyDE (Hypothetical Document Embeddings)

**原理**：生成假设性文档，然后检索

```
查询："Python异步编程"

HyDE流程：
1. 使用LLM生成假设性文档：
   "Python异步编程使用asyncio库实现，
    通过async/await语法定义协程，
    事件循环负责调度协程执行..."

2. 将假设性文档转换为Embedding

3. 使用Embedding检索相似文档

优点：语义理解深入
缺点：计算成本高
```

#### 方法4：多查询融合

**原理**：生成多个查询，分别检索后融合

```
查询："Python异步编程"

生成多个查询：
1. "Python asyncio库使用"
2. "Python协程编程"
3. "Python并发编程"

分别检索后使用RRF融合

优点：覆盖多个角度
缺点：检索次数增加
```

---

## 2025-2026年技术

### 1. Exp4Fuse框架

**Exp4Fuse**（2025年发布）：

**特点**：
- LLM驱动的查询扩展框架
- 自动生成多个查询变体
- 智能融合检索结果
- 开源免费

**工作流程**：

```
1. 原始查询 → LLM分析意图
2. 生成多个查询变体
3. 并行检索
4. RRF融合结果
```

**示例**：

```python
from exp4fuse import QueryExpander

# 创建查询扩展器
expander = QueryExpander(
    llm_model="gpt-4",
    num_queries=5
)

# 扩展查询
original_query = "Python异步编程"
expanded_queries = expander.expand(original_query)

print("扩展后的查询：")
for i, query in enumerate(expanded_queries, 1):
    print(f"{i}. {query}")

# 输出：
# 1. Python异步编程完整指南
# 2. 如何使用Python的asyncio库
# 3. Python协程和异步函数详解
# 4. Python并发编程最佳实践
# 5. Python事件循环机制
```

### 2. LLM查询改写

**2025-2026年主流方法**：

**Prompt模板**：

```python
QUERY_REWRITE_PROMPT = """
你是一个查询优化专家。用户的原始查询可能表达不完整或不够精确。

原始查询：{query}

请生成5个改写后的查询，要求：
1. 保持原始意图
2. 补充缺失信息
3. 使用更精确的表达
4. 包含相关概念和同义词
5. 适合文档检索

请以JSON格式返回：
{{
  "queries": [
    "改写查询1",
    "改写查询2",
    "改写查询3",
    "改写查询4",
    "改写查询5"
  ]
}}
"""
```

**实现**：

```python
from openai import OpenAI
import json

client = OpenAI()

def llm_query_expansion(
    query: str,
    num_queries: int = 5
) -> list[str]:
    """
    使用LLM扩展查询

    Args:
        query: 原始查询
        num_queries: 生成查询数量

    Returns:
        扩展后的查询列表
    """
    prompt = QUERY_REWRITE_PROMPT.format(query=query)

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是查询优化专家"},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    return result["queries"][:num_queries]


# 使用示例
query = "Python异步"
expanded = llm_query_expansion(query, num_queries=5)

print("原始查询:", query)
print("\n扩展后的查询：")
for i, q in enumerate(expanded, 1):
    print(f"{i}. {q}")
```

### 3. HyDE实现

**HyDE原理**：

```
传统检索：
查询 → Embedding → 检索

HyDE检索：
查询 → LLM生成假设文档 → Embedding → 检索

优势：
- 假设文档包含更多上下文
- 语义理解更深入
- 召回率提升20-30%
```

**实现**：

```python
from openai import OpenAI

client = OpenAI()

def hyde_expansion(query: str) -> str:
    """
    HyDE查询扩展

    Args:
        query: 原始查询

    Returns:
        假设性文档
    """
    prompt = f"""
请根据以下查询，生成一个假设性的文档片段（200-300字），
这个文档应该是回答该查询的理想文档。

查询：{query}

假设性文档：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是文档生成专家"},
            {"role": "user", "content": prompt}
        ]
    )

    hypothetical_doc = response.choices[0].message.content
    return hypothetical_doc


# 使用示例
query = "Python异步编程"
hypo_doc = hyde_expansion(query)

print("原始查询:", query)
print("\n假设性文档:")
print(hypo_doc)

# 然后使用假设性文档的Embedding进行检索
# embedding = get_embedding(hypo_doc)
# results = vector_search(embedding)
```

### 4. 多查询融合

**Multi-Query Fusion**：

```python
def multi_query_fusion(
    original_query: str,
    retriever,
    num_queries: int = 3
) -> list:
    """
    多查询融合检索

    Args:
        original_query: 原始查询
        retriever: 检索器
        num_queries: 生成查询数量

    Returns:
        融合后的检索结果
    """
    # 1. 生成多个查询
    expanded_queries = llm_query_expansion(
        original_query,
        num_queries=num_queries
    )

    # 2. 并行检索
    all_results = []
    for query in expanded_queries:
        results = retriever.search(query, k=10)
        all_results.append(results)

    # 3. RRF融合
    from rrf_fusion import RRFFusion
    rrf = RRFFusion(k=60)
    fused_results = rrf.fuse(all_results, top_k=10)

    return fused_results


# 使用示例
query = "Python异步编程"
results = multi_query_fusion(query, retriever, num_queries=3)
```

---

## 完整实现

### Python手写查询扩展

```python
"""
查询扩展完整实现
演示：LLM查询改写 + 多查询融合
"""

from openai import OpenAI
from typing import List, Tuple
import json

client = OpenAI()

class QueryExpander:
    """查询扩展器"""

    def __init__(
        self,
        model: str = "gpt-4",
        num_queries: int = 5
    ):
        """
        初始化查询扩展器

        Args:
            model: LLM模型
            num_queries: 生成查询数量
        """
        self.model = model
        self.num_queries = num_queries

    def expand_with_llm(self, query: str) -> List[str]:
        """
        使用LLM扩展查询

        Args:
            query: 原始查询

        Returns:
            扩展后的查询列表
        """
        prompt = f"""
你是一个查询优化专家。用户的原始查询可能表达不完整或不够精确。

原始查询：{query}

请生成{self.num_queries}个改写后的查询，要求：
1. 保持原始意图
2. 补充缺失信息
3. 使用更精确的表达
4. 包含相关概念和同义词
5. 适合文档检索

请以JSON格式返回：
{{
  "queries": [
    "改写查询1",
    "改写查询2",
    ...
  ]
}}
"""

        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是查询优化专家"},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        return result["queries"][:self.num_queries]

    def expand_with_hyde(self, query: str) -> str:
        """
        使用HyDE扩展查询

        Args:
            query: 原始查询

        Returns:
            假设性文档
        """
        prompt = f"""
请根据以下查询，生成一个假设性的文档片段（200-300字），
这个文档应该是回答该查询的理想文档。

查询：{query}

假设性文档：
"""

        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是文档生成专家"},
                {"role": "user", "content": prompt}
            ]
        )

        return response.choices[0].message.content

    def multi_query_retrieval(
        self,
        query: str,
        retriever,
        fusion_method: str = "rrf"
    ) -> List[Tuple[str, float]]:
        """
        多查询融合检索

        Args:
            query: 原始查询
            retriever: 检索器
            fusion_method: 融合方法 (rrf, weighted)

        Returns:
            融合后的检索结果
        """
        # 1. 生成多个查询
        expanded_queries = self.expand_with_llm(query)

        print(f"原始查询: {query}")
        print(f"\n扩展后的查询：")
        for i, q in enumerate(expanded_queries, 1):
            print(f"{i}. {q}")

        # 2. 并行检索
        all_results = []
        for exp_query in expanded_queries:
            results = retriever.search(exp_query, k=10)
            all_results.append(results)

        # 3. 融合结果
        if fusion_method == "rrf":
            from rrf_fusion import RRFFusion
            fusion = RRFFusion(k=60)
        else:
            from weighted_fusion import WeightedFusion
            fusion = WeightedFusion(lambda_weight=0.7)

        fused_results = fusion.fuse(all_results, top_k=10)

        return fused_results


# ===== 使用示例 =====

if __name__ == "__main__":
    # 1. 创建查询扩展器
    print("=== 查询扩展示例 ===\n")
    expander = QueryExpander(
        model="gpt-4",
        num_queries=5
    )

    # 2. LLM查询改写
    query = "Python异步"
    print(f"原始查询: {query}\n")

    expanded_queries = expander.expand_with_llm(query)
    print("LLM改写后的查询：")
    for i, q in enumerate(expanded_queries, 1):
        print(f"{i}. {q}")

    # 3. HyDE扩展
    print("\n=== HyDE扩展示例 ===\n")
    hypo_doc = expander.expand_with_hyde(query)
    print(f"原始查询: {query}\n")
    print("假设性文档:")
    print(hypo_doc)

    # 4. 多查询融合检索（需要实际的检索器）
    # results = expander.multi_query_retrieval(
    #     query=query,
    #     retriever=your_retriever,
    #     fusion_method="rrf"
    # )
```

**运行输出示例**：

```
=== 查询扩展示例 ===

原始查询: Python异步

LLM改写后的查询：
1. Python异步编程完整指南
2. 如何使用Python的asyncio库进行异步编程
3. Python协程和异步函数详解
4. Python并发编程：异步IO vs 多线程
5. Python事件循环机制和异步任务管理

=== HyDE扩展示例 ===

原始查询: Python异步

假设性文档:
Python异步编程是一种高效的并发编程范式，主要通过asyncio库实现。
异步编程使用async/await语法定义协程，通过事件循环调度协程的执行。
相比传统的多线程编程，异步编程在处理I/O密集型任务时具有更高的性能和更低的资源消耗。
asyncio提供了丰富的API，包括创建任务、管理事件循环、处理异步上下文等。
在实际应用中，异步编程常用于网络请求、文件读写、数据库操作等场景。
```

---

## 在RAG中的应用

### 1. 提升召回率

**场景**：用户查询表达不完整

```python
# 原始查询
query = "Python异步"

# 问题：
# - 表达不完整
# - 缺少关键词
# - 召回率低

# 解决方案：查询扩展
expanded = query_expander.expand_with_llm(query)

# 扩展后：
# 1. "Python异步编程完整指南"
# 2. "Python asyncio库使用"
# 3. "Python协程编程"
# ...

# 结果：召回率提升30-50%
```

### 2. 处理模糊查询

**场景**：用户查询模糊不清

```python
# 模糊查询
query = "怎么做异步"

# 扩展后：
# 1. "Python异步编程实现方法"
# 2. "JavaScript异步编程技术"
# 3. "异步编程最佳实践"
# ...

# 覆盖多种可能的意图
```

### 3. 多语言查询

**场景**：跨语言查询

```python
# 中文查询
query = "Python异步编程"

# 扩展后：
# 1. "Python异步编程"
# 2. "Python async programming"
# 3. "Pythonの非同期プログラミング"
# ...

# 支持多语言检索
```

### 4. 专业术语扩展

**场景**：专业术语查询

```python
# 专业术语
query = "asyncio"

# 扩展后：
# 1. "Python asyncio库"
# 2. "Python异步编程"
# 3. "Python协程"
# 4. "Python事件循环"
# ...

# 补充上下文信息
```

---

## 查询扩展的优势与局限

### 优势

1. **提升召回率**
   - 覆盖更多相关文档
   - 召回率提升30-50%
   - 减少遗漏

2. **理解用户意图**
   - LLM理解查询语义
   - 补充缺失信息
   - 生成高质量查询

3. **多样化检索**
   - 多个查询角度
   - 覆盖不同表达
   - 提升鲁棒性

4. **适应模糊查询**
   - 处理不完整查询
   - 理解模糊表达
   - 提升用户体验

### 局限

1. **计算成本高**
   - LLM API调用成本
   - 多次检索开销
   - 延迟增加

2. **可能引入噪声**
   - 扩展查询可能偏离原意
   - 召回无关文档
   - 需要精确控制

3. **依赖LLM质量**
   - LLM理解能力影响结果
   - 需要好的Prompt设计
   - 模型选择重要

4. **复杂度增加**
   - 系统复杂度提升
   - 调试困难
   - 维护成本高

---

## 2025-2026年最佳实践

### 1. 使用LLM查询改写

```python
# 推荐：使用LLM查询改写
# 2025-2026年主流方法

expander = QueryExpander(
    model="gpt-4",  # 或 gpt-3.5-turbo
    num_queries=3-5  # 3-5个查询变体
)

expanded = expander.expand_with_llm(query)
```

### 2. 控制扩展数量

```python
# 推荐：3-5个查询变体
# 平衡召回率和计算成本

num_queries = 3  # 成本敏感
num_queries = 5  # 召回率优先
num_queries = 7  # 极致召回（不推荐）
```

### 3. 结合混合检索

```python
# 推荐：查询扩展 + 混合检索 + RRF融合

# 1. 查询扩展
expanded_queries = expander.expand_with_llm(query)

# 2. 每个查询都使用混合检索
all_results = []
for exp_query in expanded_queries:
    bm25_results = bm25_search(exp_query)
    vector_results = vector_search(exp_query)
    hybrid_results = rrf_fusion(bm25_results, vector_results)
    all_results.append(hybrid_results)

# 3. 最终融合
final_results = rrf_fusion(all_results)
```

### 4. 监控扩展质量

```python
# 监控扩展查询的质量
def monitor_expansion_quality(original, expanded):
    """监控查询扩展质量"""
    print(f"原始查询: {original}")
    print(f"扩展数量: {len(expanded)}")
    print("扩展查询：")
    for i, q in enumerate(expanded, 1):
        print(f"{i}. {q}")
        # 检查是否偏离原意
        # 检查是否包含关键信息
```

---

## 研究来源

1. **Exp4Fuse: LLM-based Query Expansion**
   - [arXiv Paper](https://arxiv.org/abs/2506.04760)
   - 2025年发布的LLM驱动查询扩展框架

2. **Dense vs Sparse Retrieval: Mastering Hybrid Search**
   - [Dev.to Article](https://dev.to/qvfagundes/dense-vs-sparse-retrieval-mastering-faiss-bm25-and-hybrid-search-4kb1)
   - 混合检索中的查询扩展技术

3. **HyDE: Hypothetical Document Embeddings**
   - [Research Paper](https://arxiv.org/abs/2212.10496)
   - HyDE查询扩展方法

4. **Multi-Query Retrieval in RAG Systems**
   - [LangChain Blog](https://blog.langchain.dev/query-transformations/)
   - RAG系统中的查询转换技术

---

**版本**: v1.0
**最后更新**: 2026-02-16
**字数**: ~400行
