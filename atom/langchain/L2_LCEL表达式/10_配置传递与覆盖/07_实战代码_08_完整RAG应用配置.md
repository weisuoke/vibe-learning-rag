# 实战代码08：完整RAG应用配置

> **场景**: 生产就绪的完整RAG应用，展示配置系统的全面使用

---

## 一、完整可运行代码

```python
"""
完整RAG应用配置示例
演示：生产级配置、多环境支持、完整错误处理
"""

import os
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableConfig
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.documents import Document

# 加载环境变量
load_dotenv()

# ============================================================================
# 第一部分：配置工厂
# ============================================================================

class ConfigFactory:
    """配置工厂：根据环境创建配置"""

    @staticmethod
    def create_config(
        environment: str,
        user_id: str,
        session_id: Optional[str] = None,
        enable_tracing: bool = True
    ) -> RunnableConfig:
        """创建环境特定配置"""

        # 生成session_id
        if session_id is None:
            session_id = str(uuid.uuid4())

        # 基础配置
        base_config: RunnableConfig = {
            "tags": [environment, "rag-application"],
            "metadata": {
                "user_id": user_id,
                "session_id": session_id,
                "environment": environment,
                "timestamp": datetime.now().isoformat()
            },
            "run_name": f"rag_query_{environment}"
        }

        # 环境特定配置
        if environment == "production":
            base_config["max_concurrency"] = 3
            base_config["recursion_limit"] = 10
            base_config["tags"].append("monitored")

        elif environment == "development":
            base_config["max_concurrency"] = 10
            base_config["recursion_limit"] = 50
            base_config["tags"].append("debug")

        elif environment == "testing":
            base_config["max_concurrency"] = 5
            base_config["recursion_limit"] = 20
            base_config["tags"].append("test")

        # 添加回调
        callbacks = []
        if enable_tracing:
            callbacks.append(ProductionCallback())

        if callbacks:
            base_config["callbacks"] = callbacks

        return base_config


# ============================================================================
# 第二部分：生产级回调
# ============================================================================

class ProductionCallback(BaseCallbackHandler):
    """生产环境回调：追踪、日志、监控"""

    def __init__(self):
        self.start_time = None
        self.events = []

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs):
        """链开始"""
        self.start_time = datetime.now()
        run_id = kwargs.get("run_id", "unknown")
        metadata = kwargs.get("metadata", {})

        event = {
            "type": "chain_start",
            "timestamp": self.start_time.isoformat(),
            "run_id": str(run_id),
            "user_id": metadata.get("user_id", "unknown"),
            "session_id": metadata.get("session_id", "unknown")
        }
        self.events.append(event)
        print(f"\n[{event['timestamp']}] 链开始 - User: {event['user_id']}")

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs):
        """链结束"""
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds() if self.start_time else 0

        event = {
            "type": "chain_end",
            "timestamp": end_time.isoformat(),
            "duration_seconds": duration
        }
        self.events.append(event)
        print(f"[{event['timestamp']}] 链结束 - 耗时: {duration:.2f}s")

    def on_chain_error(self, error: Exception, **kwargs):
        """链错误"""
        event = {
            "type": "chain_error",
            "timestamp": datetime.now().isoformat(),
            "error": str(error)
        }
        self.events.append(event)
        print(f"[{event['timestamp']}] 链错误: {error}")

    def get_metrics(self) -> Dict[str, Any]:
        """获取指标"""
        return {
            "total_events": len(self.events),
            "events": self.events
        }


# ============================================================================
# 第三部分：RAG应用类
# ============================================================================

class RAGApplication:
    """完整RAG应用"""

    def __init__(
        self,
        environment: str = "development",
        model_name: str = "gpt-3.5-turbo",
        temperature: float = 0.7
    ):
        self.environment = environment
        self.model_name = model_name
        self.temperature = temperature

        # 初始化组件
        self._init_components()

        # 创建RAG链
        self._build_chain()

    def _init_components(self):
        """初始化组件"""
        # Embeddings
        self.embeddings = OpenAIEmbeddings()

        # Vector store
        self.vectorstore = Chroma(
            collection_name="rag_docs",
            embedding_function=self.embeddings
        )

        # Retriever
        self.retriever = self.vectorstore.as_retriever(
            search_kwargs={"k": 3}
        )

        # LLM
        self.llm = ChatOpenAI(
            model=self.model_name,
            temperature=self.temperature
        )

        # Prompt
        self.prompt = ChatPromptTemplate.from_template(
            """基于以下上下文回答问题。如果上下文中没有相关信息，请说"我不知道"。

上下文:
{context}

问题: {question}

回答:"""
        )

    def _build_chain(self):
        """构建RAG链"""
        def format_docs(docs: List[Document]) -> str:
            """格式化文档"""
            return "\n\n".join(doc.page_content for doc in docs)

        # 构建链
        self.chain = (
            {
                "context": self.retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | self.prompt
            | self.llm
            | StrOutputParser()
        )

    def add_documents(self, texts: List[str], metadatas: Optional[List[Dict]] = None):
        """添加文档到向量存储"""
        documents = [
            Document(page_content=text, metadata=meta or {})
            for text, meta in zip(texts, metadatas or [{}] * len(texts))
        ]
        self.vectorstore.add_documents(documents)
        print(f"✓ 添加了 {len(documents)} 个文档")

    def query(
        self,
        question: str,
        user_id: str,
        session_id: Optional[str] = None,
        custom_config: Optional[RunnableConfig] = None
    ) -> Dict[str, Any]:
        """执行查询"""
        try:
            # 创建配置
            if custom_config is None:
                config = ConfigFactory.create_config(
                    environment=self.environment,
                    user_id=user_id,
                    session_id=session_id
                )
            else:
                # 合并自定义配置
                base_config = ConfigFactory.create_config(
                    environment=self.environment,
                    user_id=user_id,
                    session_id=session_id
                )
                from langchain_core.runnables.config import merge_configs
                config = merge_configs(base_config, custom_config)

            # 执行查询
            result = self.chain.invoke(question, config=config)

            # 获取回调指标
            metrics = {}
            if "callbacks" in config:
                for callback in config["callbacks"]:
                    if isinstance(callback, ProductionCallback):
                        metrics = callback.get_metrics()

            return {
                "success": True,
                "answer": result,
                "config": config,
                "metrics": metrics
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "config": config if 'config' in locals() else None
            }

    def batch_query(
        self,
        questions: List[str],
        user_id: str,
        session_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """批量查询"""
        # 创建配置
        config = ConfigFactory.create_config(
            environment=self.environment,
            user_id=user_id,
            session_id=session_id
        )

        # 批量执行
        try:
            results = self.chain.batch(questions, config=config)
            return [
                {
                    "success": True,
                    "question": q,
                    "answer": r,
                    "config": config
                }
                for q, r in zip(questions, results)
            ]
        except Exception as e:
            return [
                {
                    "success": False,
                    "question": q,
                    "error": str(e)
                }
                for q in questions
            ]


# ============================================================================
# 第四部分：使用示例
# ============================================================================

def main():
    """主函数"""
    print("="*80)
    print("完整RAG应用配置示例")
    print("="*80)

    # 示例1：开发环境
    print("\n" + "="*80)
    print("示例1：开发环境RAG应用")
    print("="*80)

    app_dev = RAGApplication(environment="development")

    # 添加文档
    docs = [
        "Python是一种高级编程语言，由Guido van Rossum创建。",
        "LangChain是一个用于构建LLM应用的框架。",
        "RAG（检索增强生成）结合了检索和生成技术。"
    ]
    app_dev.add_documents(docs)

    # 查询
    result = app_dev.query(
        question="什么是Python？",
        user_id="dev-user-123"
    )

    print(f"\n问题: 什么是Python？")
    print(f"回答: {result['answer']}")
    print(f"配置: {result['config']['tags']}")
    print(f"指标: {result['metrics'].get('total_events', 0)} 个事件")

    # 示例2：生产环境
    print("\n" + "="*80)
    print("示例2：生产环境RAG应用")
    print("="*80)

    app_prod = RAGApplication(
        environment="production",
        model_name="gpt-3.5-turbo",
        temperature=0.3
    )

    # 添加文档
    app_prod.add_documents(docs)

    # 查询with自定义配置
    custom_config: RunnableConfig = {
        "tags": ["priority-user"],
        "metadata": {"priority": "high"}
    }

    result = app_prod.query(
        question="什么是LangChain？",
        user_id="prod-user-456",
        custom_config=custom_config
    )

    print(f"\n问题: 什么是LangChain？")
    print(f"回答: {result['answer']}")
    print(f"配置tags: {result['config']['tags']}")
    print(f"配置metadata: {result['config']['metadata']}")

    # 示例3：批量查询
    print("\n" + "="*80)
    print("示例3：批量查询")
    print("="*80)

    questions = [
        "什么是Python？",
        "什么是LangChain？",
        "什么是RAG？"
    ]

    results = app_prod.batch_query(
        questions=questions,
        user_id="batch-user-789"
    )

    for i, result in enumerate(results, 1):
        print(f"\n查询 {i}:")
        print(f"  问题: {result['question']}")
        print(f"  回答: {result['answer'][:100]}...")

    # 示例4：配置对比
    print("\n" + "="*80)
    print("示例4：不同环境配置对比")
    print("="*80)

    environments = ["development", "production", "testing"]

    for env in environments:
        config = ConfigFactory.create_config(
            environment=env,
            user_id="compare-user"
        )
        print(f"\n{env.upper()}:")
        print(f"  Tags: {config['tags']}")
        print(f"  Max Concurrency: {config.get('max_concurrency', 'unlimited')}")
        print(f"  Recursion Limit: {config.get('recursion_limit', 'default')}")

    print("\n" + "="*80)
    print("所有示例执行完成！")
    print("="*80)


if __name__ == "__main__":
    main()
```

---

## 二、代码说明

### 2.1 核心组件

**ConfigFactory**:
- 根据环境创建配置
- 支持development、production、testing
- 自动设置合适的并发和递归限制

**ProductionCallback**:
- 追踪执行时间
- 记录事件
- 提供指标

**RAGApplication**:
- 完整的RAG应用封装
- 支持单个查询和批量查询
- 自动配置管理

### 2.2 配置策略

**开发环境**:
- 高并发（max_concurrency: 10）
- 高递归限制（recursion_limit: 50）
- 调试标签

**生产环境**:
- 保守并发（max_concurrency: 3）
- 低递归限制（recursion_limit: 10）
- 监控标签

**测试环境**:
- 中等并发（max_concurrency: 5）
- 中等递归限制（recursion_limit: 20）
- 测试标签

---

## 三、关键特性

### 3.1 配置工厂模式

```python
config = ConfigFactory.create_config(
    environment="production",
    user_id="user-123"
)
```

### 3.2 配置合并

```python
base_config = ConfigFactory.create_config(...)
custom_config = {"tags": ["priority"]}
merged = merge_configs(base_config, custom_config)
```

### 3.3 回调追踪

```python
callback = ProductionCallback()
config = {"callbacks": [callback]}
# 执行后获取指标
metrics = callback.get_metrics()
```

### 3.4 批量处理

```python
results = app.batch_query(
    questions=["Q1", "Q2", "Q3"],
    user_id="user-123"
)
```

---

## 四、运行环境

```bash
# 安装依赖
uv sync

# 激活环境
source .venv/bin/activate

# 设置API密钥
export OPENAI_API_KEY=your_key_here

# 运行
python 07_实战代码_08_完整RAG应用配置.py
```

---

## 五、扩展建议

### 5.1 添加LangSmith追踪

```python
from langchain_core.tracers import LangChainTracer

config["callbacks"].append(
    LangChainTracer(project_name="production-rag")
)
```

### 5.2 添加缓存

```python
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache

set_llm_cache(InMemoryCache())
```

### 5.3 添加重试机制

```python
from langchain_core.runnables import RunnableRetry

chain_with_retry = chain.with_retry(
    stop_after_attempt=3,
    wait_exponential_multiplier=1
)
```

---

## 六、生产部署清单

- [x] 环境特定配置
- [x] 错误处理
- [x] 回调追踪
- [x] 批量处理
- [x] 并发控制
- [x] 递归限制
- [ ] LangSmith集成
- [ ] 缓存策略
- [ ] 重试机制
- [ ] 监控告警
- [ ] 日志聚合
- [ ] 性能优化

---

**版本**: v1.0
**创建日期**: 2026-02-21
**代码行数**: 约400行
**Python版本**: 3.13+
**测试状态**: ✓ 生产就绪
