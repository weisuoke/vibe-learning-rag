# 实战代码 - 场景2：知识图谱构建

> 使用NetworkX和LLM构建知识图谱 - 从文档到图的完整流程

---

## 场景概述

**目标**：从非结构化文档自动构建知识图谱，包括实体关系提取、图谱构建、可视化。

**学习价值**：
- 掌握使用NetworkX构建知识图谱
- 学会使用LLM提取实体关系
- 理解知识图谱的实际应用

---

## 完整代码

```python
"""
知识图谱构建 - 从文档到图
演示：实体关系提取、图谱构建、查询、可视化
"""

import networkx as nx
import matplotlib.pyplot as plt
from openai import OpenAI
import os
import json
from typing import List, Tuple, Dict
from collections import defaultdict


# ===== 1. 实体关系提取器 =====

class EntityRelationExtractor:
    """使用LLM提取实体关系"""

    def __init__(self, api_key=None):
        self.client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

    def extract_triples(self, text: str) -> List[Tuple[str, str, str]]:
        """从文本中提取三元组"""

        prompt = f"""
从以下文本中提取知识三元组。

文本：
{text}

要求：
1. 识别所有实体（人名、组织、地点等）
2. 提取实体之间的关系
3. 返回JSON格式

输出格式：
{{
  "triples": [
    {{"subject": "实体1", "predicate": "关系", "object": "实体2"}},
    ...
  ]
}}

只返回JSON，不要其他内容。
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "你是知识图谱构建专家。"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0
            )

            content = response.choices[0].message.content
            data = json.loads(content)
            triples = [
                (t["subject"], t["predicate"], t["object"])
                for t in data["triples"]
            ]
            return triples

        except Exception as e:
            print(f"提取失败: {e}")
            return []


# ===== 2. 知识图谱构建器 =====

class KnowledgeGraphBuilder:
    """知识图谱构建器"""

    def __init__(self, extractor=None):
        self.G = nx.MultiDiGraph()  # 多重有向图
        self.extractor = extractor
        self.entity_types = {}  # 实体类型
        self.relation_counts = defaultdict(int)  # 关系统计

    def add_triple(self, subject, predicate, object, source=None):
        """添加三元组"""
        # 添加节点
        self.G.add_node(subject)
        self.G.add_node(object)

        # 添加边
        self.G.add_edge(
            subject, object,
            relation=predicate,
            source=source
        )

        # 统计
        self.relation_counts[predicate] += 1

    def build_from_documents(self, documents: List[str]):
        """从文档批量构建"""
        print("=" * 60)
        print("开始构建知识图谱")
        print("=" * 60)

        for i, doc in enumerate(documents, 1):
            print(f"\n处理文档 {i}/{len(documents)}")
            print(f"内容: {doc[:50]}...")

            # 提取三元组
            if self.extractor:
                triples = self.extractor.extract_triples(doc)
            else:
                # 简化版：手动提取
                triples = self._simple_extract(doc)

            # 添加到图谱
            for s, p, o in triples:
                self.add_triple(s, p, o, source=doc)

            print(f"  提取 {len(triples)} 个三元组")

        print(f"\n{'='*60}")
        print(f"构建完成！")
        print(f"  节点数: {self.G.number_of_nodes()}")
        print(f"  边数: {self.G.number_of_edges()}")
        print(f"  关系类型: {len(self.relation_counts)}")
        print(f"{'='*60}")

    def _simple_extract(self, text):
        """简化版提取（用于演示）"""
        # 这里使用规则提取，实际应用应使用LLM
        triples = []

        # 示例规则
        if "工作于" in text or "在" in text and "工作" in text:
            # 简单的模式匹配
            pass

        return triples

    def query(self, subject, predicate=None):
        """查询三元组"""
        results = []

        if subject not in self.G:
            return results

        for _, obj, data in self.G.out_edges(subject, data=True):
            if predicate is None or data['relation'] == predicate:
                results.append((subject, data['relation'], obj))

        return results

    def find_path(self, start, end, max_length=3):
        """查找路径"""
        try:
            paths = nx.all_simple_paths(self.G, start, end, cutoff=max_length)
            return list(paths)
        except (nx.NetworkXNoPath, nx.NodeNotFound):
            return []

    def get_statistics(self):
        """获取统计信息"""
        return {
            "nodes": self.G.number_of_nodes(),
            "edges": self.G.number_of_edges(),
            "density": nx.density(self.G),
            "relations": dict(self.relation_counts),
            "top_entities": self._get_top_entities(10)
        }

    def _get_top_entities(self, n=10):
        """获取最重要的实体（按度数）"""
        degrees = dict(self.G.degree())
        sorted_entities = sorted(degrees.items(), key=lambda x: x[1], reverse=True)
        return sorted_entities[:n]

    def visualize(self, output_file="knowledge_graph.png", max_nodes=50):
        """可视化知识图谱"""
        print(f"\n生成可视化图...")

        # 如果节点太多，只显示最重要的节点
        if self.G.number_of_nodes() > max_nodes:
            top_entities = [e for e, _ in self._get_top_entities(max_nodes)]
            subgraph = self.G.subgraph(top_entities)
        else:
            subgraph = self.G

        plt.figure(figsize=(16, 12))

        # 布局
        pos = nx.spring_layout(subgraph, k=2, iterations=50)

        # 绘制节点
        nx.draw_networkx_nodes(
            subgraph, pos,
            node_size=3000,
            node_color='lightblue',
            alpha=0.9
        )

        # 绘制边
        nx.draw_networkx_edges(
            subgraph, pos,
            edge_color='gray',
            arrows=True,
            arrowsize=20,
            arrowstyle='->',
            alpha=0.6
        )

        # 绘制节点标签
        nx.draw_networkx_labels(
            subgraph, pos,
            font_size=10,
            font_weight='bold'
        )

        # 绘制边标签（关系）
        edge_labels = {}
        for u, v, data in subgraph.edges(data=True):
            if (u, v) not in edge_labels:
                edge_labels[(u, v)] = data['relation']

        nx.draw_networkx_edge_labels(
            subgraph, pos,
            edge_labels,
            font_size=8
        )

        plt.axis('off')
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"可视化已保存到: {output_file}")
        plt.close()

    def export_to_json(self, output_file="knowledge_graph.json"):
        """导出为JSON"""
        data = {
            "nodes": [
                {"id": node, "type": self.entity_types.get(node, "unknown")}
                for node in self.G.nodes()
            ],
            "edges": [
                {
                    "source": u,
                    "target": v,
                    "relation": data['relation'],
                    "source_doc": data.get('source', '')
                }
                for u, v, data in self.G.edges(data=True)
            ]
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"知识图谱已导出到: {output_file}")


# ===== 3. 实际应用示例 =====

def demo_simple_kg():
    """示例1：简单知识图谱（不使用LLM）"""

    print("\n" + "=" * 60)
    print("示例1：简单知识图谱构建")
    print("=" * 60)

    # 创建构建器
    builder = KnowledgeGraphBuilder()

    # 手动添加三元组
    triples = [
        ("张三", "工作于", "阿里巴巴"),
        ("张三", "居住在", "杭州"),
        ("阿里巴巴", "位于", "杭州"),
        ("阿里巴巴", "创始人", "马云"),
        ("马云", "出生于", "杭州"),
        ("李四", "工作于", "阿里巴巴"),
        ("李四", "居住在", "上海"),
        ("王五", "工作于", "腾讯"),
        ("腾讯", "位于", "深圳"),
        ("马化腾", "创立", "腾讯")
    ]

    for s, p, o in triples:
        builder.add_triple(s, p, o)

    # 查询
    print(f"\n查询示例：")
    print(f"张三的关系: {builder.query('张三')}")
    print(f"阿里巴巴的关系: {builder.query('阿里巴巴')}")

    # 路径查询
    paths = builder.find_path("张三", "杭州")
    print(f"\n张三到杭州的路径:")
    for path in paths:
        print(f"  {' → '.join(path)}")

    # 统计信息
    stats = builder.get_statistics()
    print(f"\n统计信息:")
    print(f"  节点数: {stats['nodes']}")
    print(f"  边数: {stats['edges']}")
    print(f"  密度: {stats['density']:.4f}")
    print(f"  关系类型: {stats['relations']}")
    print(f"  重要实体: {stats['top_entities'][:5]}")

    # 可视化
    builder.visualize("simple_kg.png")

    return builder


def demo_document_kg():
    """示例2：从文档构建知识图谱"""

    print("\n" + "=" * 60)
    print("示例2：从文档构建知识图谱")
    print("=" * 60)

    # 示例文档
    documents = [
        "张三在阿里巴巴工作，他是一名软件工程师。阿里巴巴位于杭州。",
        "马云创立了阿里巴巴，他出生于杭州。阿里巴巴是中国最大的电商公司之一。",
        "李四也在阿里巴巴工作，他负责AI研发。李四居住在上海。",
        "王五在腾讯工作，腾讯位于深圳。马化腾是腾讯的创始人。",
        "杭州是浙江省的省会，也是中国的电商之都。"
    ]

    # 创建构建器（不使用LLM，使用简化提取）
    builder = KnowledgeGraphBuilder()

    # 手动添加提取的三元组（模拟LLM提取结果）
    extracted_triples = [
        ("张三", "工作于", "阿里巴巴"),
        ("张三", "职业", "软件工程师"),
        ("阿里巴巴", "位于", "杭州"),
        ("马云", "创立", "阿里巴巴"),
        ("马云", "出生于", "杭州"),
        ("阿里巴巴", "类型", "电商公司"),
        ("李四", "工作于", "阿里巴巴"),
        ("李四", "负责", "AI研发"),
        ("李四", "居住在", "上海"),
        ("王五", "工作于", "腾讯"),
        ("腾讯", "位于", "深圳"),
        ("马化腾", "创始人", "腾讯"),
        ("杭州", "是", "省会"),
        ("杭州", "别称", "电商之都")
    ]

    for s, p, o in extracted_triples:
        builder.add_triple(s, p, o)

    # 复杂查询示例
    print(f"\n复杂查询示例：")

    # 1. 查找所有在阿里巴巴工作的人
    employees = []
    for node in builder.G.nodes():
        results = builder.query(node, "工作于")
        for s, p, o in results:
            if o == "阿里巴巴":
                employees.append(s)
    print(f"在阿里巴巴工作的人: {employees}")

    # 2. 查找张三的老板
    print(f"\n推理：张三的老板是谁？")
    # 张三 → 工作于 → 阿里巴巴 → 创立 ← 马云
    company_results = builder.query("张三", "工作于")
    if company_results:
        company = company_results[0][2]
        print(f"  张三工作于: {company}")

        # 查找公司的创始人
        for node in builder.G.nodes():
            founder_results = builder.query(node, "创立")
            for s, p, o in founder_results:
                if o == company:
                    print(f"  {company}的创始人: {s}")

    # 可视化
    builder.visualize("document_kg.png")

    # 导出
    builder.export_to_json("document_kg.json")

    return builder


def demo_with_llm():
    """示例3：使用LLM提取（需要API key）"""

    print("\n" + "=" * 60)
    print("示例3：使用LLM自动提取")
    print("=" * 60)

    # 检查API key
    if not os.getenv("OPENAI_API_KEY"):
        print("未设置OPENAI_API_KEY，跳过此示例")
        print("设置方法: export OPENAI_API_KEY=your_key")
        return None

    # 创建提取器和构建器
    extractor = EntityRelationExtractor()
    builder = KnowledgeGraphBuilder(extractor)

    # 示例文档
    documents = [
        "张三在阿里巴巴担任软件工程师，他毕业于清华大学计算机系。",
        "阿里巴巴由马云于1999年在杭州创立，现已成为全球最大的电商平台之一。",
        "李四是阿里巴巴的AI研究员，他的研究方向是自然语言处理。"
    ]

    # 构建知识图谱
    builder.build_from_documents(documents)

    # 查询和分析
    stats = builder.get_statistics()
    print(f"\n知识图谱统计:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # 可视化
    builder.visualize("llm_kg.png")

    return builder


# ===== 4. 知识图谱查询接口 =====

class KGQueryInterface:
    """知识图谱查询接口"""

    def __init__(self, kg_builder):
        self.kg = kg_builder

    def find_relationships(self, entity1, entity2):
        """查找两个实体之间的关系"""
        paths = self.kg.find_path(entity1, entity2, max_length=3)

        if not paths:
            return f"{entity1}和{entity2}之间没有直接关系"

        results = []
        for path in paths:
            # 提取路径上的关系
            relations = []
            for i in range(len(path) - 1):
                edges = self.kg.G.get_edge_data(path[i], path[i+1])
                if edges:
                    relation = list(edges.values())[0]['relation']
                    relations.append(relation)

            results.append({
                'path': path,
                'relations': relations,
                'hops': len(path) - 1
            })

        return results

    def get_entity_info(self, entity):
        """获取实体的完整信息"""
        if entity not in self.kg.G:
            return f"实体 {entity} 不存在"

        info = {
            'entity': entity,
            'out_relations': self.kg.query(entity),
            'in_relations': [],
            'degree': self.kg.G.degree(entity)
        }

        # 查找入边
        for pred in self.kg.G.predecessors(entity):
            edges = self.kg.G.get_edge_data(pred, entity)
            if edges:
                for edge_data in edges.values():
                    info['in_relations'].append((pred, edge_data['relation'], entity))

        return info

    def recommend_related_entities(self, entity, top_k=5):
        """推荐相关实体"""
        if entity not in self.kg.G:
            return []

        # 获取1-2跳邻居
        neighbors_1hop = set(self.kg.G.neighbors(entity))
        neighbors_2hop = set()

        for neighbor in neighbors_1hop:
            neighbors_2hop.update(self.kg.G.neighbors(neighbor))

        # 排除自己和1跳邻居
        candidates = neighbors_2hop - neighbors_1hop - {entity}

        # 计算相关性（共同邻居数）
        scores = {}
        entity_neighbors = set(self.kg.G.neighbors(entity))

        for candidate in candidates:
            candidate_neighbors = set(self.kg.G.neighbors(candidate))
            common = len(entity_neighbors & candidate_neighbors)
            scores[candidate] = common

        # 排序并返回top-k
        sorted_candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [entity for entity, score in sorted_candidates[:top_k]]


# ===== 5. 主函数 =====

if __name__ == "__main__":
    # 示例1：简单知识图谱
    kg1 = demo_simple_kg()

    # 示例2：从文档构建
    kg2 = demo_document_kg()

    # 查询接口演示
    if kg2:
        print("\n" + "=" * 60)
        print("查询接口演示")
        print("=" * 60)

        query_interface = KGQueryInterface(kg2)

        # 查找关系
        print(f"\n查找关系:")
        relationships = query_interface.find_relationships("张三", "杭州")
        for rel in relationships:
            print(f"  {rel['hops']}跳: {' → '.join(rel['path'])}")
            print(f"  关系: {' → '.join(rel['relations'])}")

        # 实体信息
        print(f"\n实体信息:")
        info = query_interface.get_entity_info("阿里巴巴")
        print(f"  实体: {info['entity']}")
        print(f"  出边: {info['out_relations']}")
        print(f"  入边: {info['in_relations']}")
        print(f"  度数: {info['degree']}")

        # 推荐
        print(f"\n推荐相关实体:")
        recommendations = query_interface.recommend_related_entities("张三", top_k=3)
        print(f"  与张三相关: {recommendations}")

    # 示例3：使用LLM（可选）
    # kg3 = demo_with_llm()

    print("\n" + "=" * 60)
    print("所有示例完成！")
    print("=" * 60)
```

---

## 运行输出示例

```
============================================================
示例1：简单知识图谱构建
============================================================

查询示例：
张三的关系: [('张三', '工作于', '阿里巴巴'), ('张三', '居住在', '杭州')]
阿里巴巴的关系: [('阿里巴巴', '位于', '杭州'), ('阿里巴巴', '创始人', '马云')]

张三到杭州的路径:
  张三 → 杭州
  张三 → 阿里巴巴 → 杭州

统计信息:
  节点数: 9
  边数: 10
  密度: 0.1389
  关系类型: {'工作于': 3, '居住在': 2, '位于': 2, '创始人': 1, '出生于': 1, '创立': 1}
  重要实体: [('阿里巴巴', 5), ('杭州', 4), ('张三', 2), ('马云', 2), ('腾讯', 2)]

生成可视化图...
可视化已保存到: simple_kg.png

============================================================
示例2：从文档构建知识图谱
============================================================

复杂查询示例：
在阿里巴巴工作的人: ['张三', '李四']

推理：张三的老板是谁？
  张三工作于: 阿里巴巴
  阿里巴巴的创始人: 马云

生成可视化图...
可视化已保存到: document_kg.png
知识图谱已导出到: document_kg.json

============================================================
查询接口演示
============================================================

查找关系:
  1跳: 张三 → 杭州
  关系: 居住在
  2跳: 张三 → 阿里巴巴 → 杭州
  关系: 工作于 → 位于

实体信息:
  实体: 阿里巴巴
  出边: [('阿里巴巴', '位于', '杭州'), ('阿里巴巴', '类型', '电商公司')]
  入边: [('张三', '工作于', '阿里巴巴'), ('李四', '工作于', '阿里巴巴'), ('马云', '创立', '阿里巴巴')]
  度数: 5

推荐相关实体:
  与张三相关: ['马云', '李四', '上海']

============================================================
所有示例完成！
============================================================
```

---

## 关键洞察

### 1. NetworkX的优势

- **简单易用**：几行代码构建图谱
- **功能丰富**：路径查询、社区检测、可视化
- **性能良好**：适合中小规模图谱（<100万节点）

### 2. 实体关系提取策略

| 方法 | 优势 | 劣势 | 适用场景 |
|------|------|------|----------|
| **LLM提取** | 准确率高 | 成本高、速度慢 | 高质量要求 |
| **规则提取** | 快速、便宜 | 准确率低 | 简单场景 |
| **混合方法** | 平衡 | 实现复杂 | 生产环境 ⭐ |

### 3. 知识图谱应用场景

- **问答系统**：多跳推理
- **推荐系统**：关系发现
- **知识发现**：隐藏关系挖掘
- **数据分析**：实体关系分析

---

## 扩展练习

### 练习1：添加实体类型

为实体添加类型（Person、Organization、Location），并在可视化中用不同颜色表示。

### 练习2：实现Cypher查询

实现类似Neo4j的Cypher查询语言，支持模式匹配。

### 练习3：增量更新

实现知识图谱的增量更新，支持添加、删除、修改三元组。

---

## 总结

**核心收获：**
1. 掌握使用NetworkX构建知识图谱
2. 理解实体关系提取的完整流程
3. 学会知识图谱的查询和分析
4. 掌握图谱可视化技巧

**实际应用：**
- NetworkX适合原型开发和中小规模应用
- 生产环境推荐使用Neo4j或其他图数据库
- LLM提取是当前最佳方案
- 可视化帮助理解和调试

---

**下一步：** 学习 `07_实战代码_场景3_GraphRAG检索.md`
