# docker-compose编排 - 实战代码：生产级配置

## 概述

本文提供一个完整的生产级 AI Agent 环境配置，包含资源限制、日志管理、监控集成、安全配置等生产环境必备功能。

**目标：**
- 生产级资源限制
- 完整的监控和日志
- 安全配置
- 高可用性
- 完整可运行

---

## 1. 项目结构

```
production-env/
├── docker-compose.yml          # 生产环境配置
├── Dockerfile                  # 生产镜像
├── requirements.txt            # Python 依赖
├── .env.prod                   # 生产环境变量（不提交）
├── nginx.conf                  # Nginx 配置
├── prometheus.yml              # Prometheus 配置
└── app/
    ├── __init__.py
    └── main.py                # FastAPI 应用
```

---

## 2. docker-compose.yml（生产配置）

```yaml
version: '3.8'

services:
  # Nginx 反向代理
  nginx:
    image: nginx:alpine
    container_name: prod-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api
    networks:
      - frontend
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # FastAPI 应用（多实例）
  api:
    build:
      context: .
      dockerfile: Dockerfile
    image: ai-agent-api:${APP_VERSION:-latest}
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - DEBUG=false
      - LOG_LEVEL=warning
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: always
    stop_grace_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"

  # PostgreSQL 数据库
  db:
    image: postgres:14-alpine
    container_name: prod-db
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis 缓存
  redis:
    image: redis:7-alpine
    container_name: prod-redis
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Prometheus 监控
  prometheus:
    image: prom/prometheus
    container_name: prod-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    networks:
      - backend
    restart: always

  # Grafana 可视化
  grafana:
    image: grafana/grafana
    container_name: prod-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - backend
    restart: always

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true  # 内部网络，不能访问外网
```

---

## 3. 生产级 Dockerfile

```dockerfile
# 多阶段构建
FROM python:3.13-slim AS builder

WORKDIR /app

# 安装构建依赖
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# 安装 Python 依赖
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# 最终镜像
FROM python:3.13-slim

WORKDIR /app

# 安装运行时依赖
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖
COPY --from=builder /root/.local /root/.local
ENV PATH=/root/.local/bin:$PATH

# 复制代码
COPY app/ ./app/

# 创建非 root 用户
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app
USER appuser

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--workers", "4"]
```

---

## 4. Nginx 配置

```nginx
upstream api_backend {
    least_conn;  # 最少连接负载均衡
    server api:8000 max_fails=3 fail_timeout=30s;
}

# HTTP 重定向到 HTTPS
server {
    listen 80;
    server_name example.com;
    return 301 https://$server_name$request_uri;
}

# HTTPS 服务器
server {
    listen 443 ssl http2;
    server_name example.com;

    # SSL 证书
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    # 安全头
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # 日志
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # API 代理
    location / {
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # 超时设置
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # 缓冲设置
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }

    # 健康检查
    location /health {
        proxy_pass http://api_backend/health;
        access_log off;
    }

    # 静态文件缓存
    location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

---

## 5. Prometheus 配置

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'

  - job_name: 'postgres'
    static_configs:
      - targets: ['db:5432']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
```

---

## 6. 生产级 FastAPI 应用

```python
"""
生产级 AI Agent API
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
import logging
from prometheus_client import Counter, Histogram, generate_latest
from starlette.responses import Response

# 配置日志
logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Prometheus 指标
REQUEST_COUNT = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'API request duration')

app = FastAPI(
    title="Production AI Agent API",
    docs_url=None,  # 生产环境禁用文档
    redoc_url=None
)

# 请求计时中间件
@app.middleware("http")
async def add_process_time_header(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time

    # 记录指标
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path,
        status=response.status_code
    ).inc()
    REQUEST_DURATION.observe(process_time)

    response.headers["X-Process-Time"] = str(process_time)
    return response

# 全局异常处理
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"Global exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"}
    )

@app.get("/")
async def root():
    return {"message": "Production AI Agent API", "status": "running"}

@app.get("/health")
async def health():
    """健康检查"""
    return {"status": "healthy"}

@app.get("/metrics")
async def metrics():
    """Prometheus 指标"""
    return Response(content=generate_latest(), media_type="text/plain")
```

---

## 7. 环境变量

```bash
# .env.prod
APP_VERSION=v1.0.0
DATABASE_URL=postgresql://prod_user:prod_pass@db:5432/agent_prod
POSTGRES_USER=prod_user
POSTGRES_PASSWORD=prod_pass
POSTGRES_DB=agent_prod
REDIS_URL=redis://redis:6379
GRAFANA_PASSWORD=admin_password
```

---

## 8. 部署流程

### 8.1 构建镜像

```bash
# 构建生产镜像
docker-compose build

# 标记版本
docker tag ai-agent-api:latest ai-agent-api:v1.0.0
```

### 8.2 启动服务

```bash
# 启动生产环境
docker-compose up -d

# 查看状态
docker-compose ps

# 查看日志
docker-compose logs -f
```

### 8.3 健康检查

```bash
# 检查 API
curl https://example.com/health

# 检查 Prometheus
curl http://localhost:9090/-/healthy

# 检查 Grafana
curl http://localhost:3000/api/health
```

---

## 9. 监控和告警

### 9.1 访问监控

- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000

### 9.2 配置 Grafana

1. 添加 Prometheus 数据源
2. 导入仪表板
3. 配置告警规则

---

## 10. 总结

**生产级配置包含：**
1. ✅ 资源限制（CPU、内存）
2. ✅ 日志管理（轮转、压缩）
3. ✅ 监控集成（Prometheus、Grafana）
4. ✅ 负载均衡（Nginx）
5. ✅ 安全配置（HTTPS、内部网络）
6. ✅ 健康检查和优雅关闭
7. ✅ 高可用性（多实例）

**适用场景：**
- 生产环境部署
- 高可用要求
- 需要监控和告警

---

**版本：** v1.0
**最后更新：** 2026-02-12
