# 30字核心

**文本分块（Chunking）是将长文档切分成适合检索的小片段的技术，2025-2026年演进出代理式与上下文感知分块，直接决定 RAG 系统的检索精度和召回质量。**

---

## 拆解理解

| 关键词 | 含义 |
|-------|------|
| **文本分块（Chunking）** | 将长文本切割成多个小片段的过程 |
| **适合检索** | 大小适中，语义完整，便于向量化和匹配 |
| **小片段（Chunk）** | 分块后的单个文本单元，是检索的最小粒度 |
| **2025-2026年演进** | 从固定规则到智能分块的技术跃迁 |
| **代理式分块** | 使用 LLM 动态确定分块边界（IBM 2025-2026） |
| **上下文感知分块** | 为每个块添加上下文信息（Anthropic 2024-2025） |
| **检索精度** | 找到的内容与问题的相关程度 |
| **召回质量** | 能否找到所有相关的内容 |

---

## 为什么这句话重要？

理解这句话，你就理解了：

1. **分块是检索的基础** → 检索系统返回的是 Chunk，不是整个文档
2. **分块策略影响答案质量** → 分块不当会导致"找到了但答案不完整"或"找不到"
3. **2025-2026是分块演进年** → 从规则驱动到智能驱动的技术革命
4. **没有万能的分块策略** → 不同场景需要不同的分块方式

---

## 文本分块的演进公式

### 传统分块（2024年前）
```
文本分块 = 确定切分点 + 控制块大小 + 保持语义完整
```

### 智能分块（2025-2026）
```
文本分块 = LLM理解语义 + 动态边界 + 上下文注入 + 元数据标注
```

用前端的话说：

```
传统分块 = 虚拟列表分页 + 每页大小限制 + 确保内容不被截断
智能分块 = AI驱动的智能分页 + 自适应大小 + 上下文预加载
```

---

## 2025-2026 分块技术突破

### 1. 代理式分块（Agentic Chunking）
**来源**: IBM Research 2025-2026

**核心思想**: 让 LLM 像人类编辑一样理解文档结构，智能确定分块边界

**效果**: 比传统方法提升 15-20% 检索准确率

### 2. 上下文感知分块（Contextual Retrieval）
**来源**: Anthropic 2024-2025

**核心思想**: 为每个 chunk 添加 50-100 token 的上下文说明

**效果**:
- 单独使用：减少 49% 检索失败
- 结合 reranking：减少 67% 检索失败

### 3. 页面级分块（Page-level Chunking）
**来源**: NVIDIA 2025 Benchmark

**核心发现**:
- 页面级分块准确率最高（0.648）
- 方差最低（0.107），最稳定
- 不同查询类型需要不同块大小：
  - 事实查询：256-512 tokens
  - 分析查询：1024+ tokens

---

## 在 RAG 系统中的位置

```
┌─────────────────────────────────────────────────────────────┐
│                    离线索引阶段                               │
│                                                             │
│  文档加载        ★文本分块★       向量化          向量存储      │
│  ┌─────┐       ┌─────┐       ┌─────┐         ┌─────┐       │
│  │ 原始 │       │chunk│       │ vec │         │     │       │
│  │ 文本 │  ──→  │chunk│  ──→  │ vec │   ──→   │ DB  │       │
│  │     │       │chunk│       │ vec │         │     │       │
│  └─────┘       └─────┘       └─────┘         └─────┘       │
│                   ↑                                         │
│              你在这里                                         │
│         2025-2026: 智能分块                                  │
└─────────────────────────────────────────────────────────────┘
```

---

## 分块的核心权衡

```
        太小的 Chunk                    太大的 Chunk
        ┌─────────┐                    ┌─────────┐
        │ 精度高   │                    │ 上下文全 │
        │ 但上下文 │     ←  平衡  →     │ 但噪音多 │
        │ 不完整   │                    │ 检索不准 │
        └─────────┘                    └─────────┘
              ↓                              ↓
        "找到了，但信息不够"           "信息太多，找不准"

        2025-2026 解决方案：
        ┌─────────────────────────────┐
        │ 代理式分块 + 上下文感知       │
        │ = 智能大小 + 完整上下文       │
        └─────────────────────────────┘
```

---

## 五大分块策略速览（2025-2026）

| 策略 | 适用场景 | 优势 | 年份 |
|------|---------|------|------|
| **固定大小** | 简单文档、快速原型 | 实现简单、速度快 | 传统 |
| **递归字符** | 通用场景、结构化文档 | 保持结构、平衡性好 | 传统 |
| **语义分块** | 高质量要求、长文档 | 语义完整、准确率高 | 2024 |
| **代理式分块** | 复杂文档、高价值场景 | 智能边界、最高质量 | 2025-2026 |
| **上下文感知** | 生产环境、关键应用 | 减少49-67%失败率 | 2024-2025 |

---

## 研究来源

**NVIDIA 2025 Benchmark**: [Finding the Best Chunking Strategy](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses)

**Anthropic Contextual Retrieval**: [Introducing Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)

**IBM Agentic Chunking**: [What is Agentic Chunking](https://www.ibm.com/think/topics/agentic-chunking)

---

**下一步：** [02_第一性原理](./02_第一性原理.md) - 从根本理解为什么需要文本分块
