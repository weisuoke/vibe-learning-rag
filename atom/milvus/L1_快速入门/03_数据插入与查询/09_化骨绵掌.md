# åŒ–éª¨ç»µæŒï¼š10 å¼ çŸ¥è¯†å¡ç‰‡

> **ç›®æ ‡**ï¼šé€šè¿‡ 10 å¼ çŸ¥è¯†å¡ç‰‡ï¼ˆæ¯å¼  2 åˆ†é’Ÿï¼‰ï¼Œç³»ç»ŸæŒæ¡ Milvus æ•°æ®æ’å…¥ä¸æŸ¥è¯¢çš„å®Œæ•´çŸ¥è¯†ä½“ç³»ã€‚

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 1ï¼šEmbedding Functions æ ¸å¿ƒæœºåˆ¶

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### æ ¸å¿ƒæ¦‚å¿µ

**Embedding Functions** æ˜¯ Milvus 2.6 çš„æ ¸å¿ƒç‰¹æ€§ï¼Œå°†å‘é‡åŒ–ä»å¤–éƒ¨æœåŠ¡å˜æˆæ•°æ®åº“çš„å†…ç½®åŠŸèƒ½ã€‚

### å·¥ä½œåŸç†

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·æ’å…¥åŸå§‹æ–‡æœ¬                        â”‚
â”‚         â†“                                â”‚
â”‚  Milvus Function æ¨¡å—                    â”‚
â”‚         â†“                                â”‚
â”‚  è‡ªåŠ¨è°ƒç”¨ Embedding Provider             â”‚
â”‚  (OpenAI/Cohere/Bedrock)                â”‚
â”‚         â†“                                â”‚
â”‚  ç”Ÿæˆå‘é‡å¹¶å­˜å‚¨                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### é…ç½®æ­¥éª¤

1. **é…ç½®å‡­è¯**ï¼ˆmilvus.yamlï¼‰ï¼š
```yaml
credential:
  apikey_openai:
    apikey: "sk-your-key"

function:
  textEmbedding:
    providers:
      openai:
        credential: apikey_openai
```

2. **å®šä¹‰ Function**ï¼ˆSchemaï¼‰ï¼š
```python
text_embedding_function = Function(
    name="openai_embedding",
    function_type=FunctionType.TEXTEMBEDDING,
    input_field_names=["document"],
    output_field_names=["dense"],
    params={"provider": "openai", "model_name": "text-embedding-3-small"}
)
schema.add_function(text_embedding_function)
```

### å…³é”®ç‚¹

- **è‡ªåŠ¨æ‰¹å¤„ç†**ï¼šMilvus å†…éƒ¨è‡ªåŠ¨ä¼˜åŒ–æ‰¹é‡è¯·æ±‚
- **è¿æ¥æ± ç®¡ç†**ï¼šç»´æŠ¤ä¸ Provider çš„è¿æ¥æ± 
- **ç¼“å­˜æœºåˆ¶**ï¼šç›¸åŒæ–‡æœ¬çš„å‘é‡ä¼šè¢«ç¼“å­˜

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 2ï¼šæ•°æ®æ’å…¥æ“ä½œè¯¦è§£

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### ä¸‰ç§æ’å…¥æ–¹å¼

| æ“ä½œ | ç”¨é€” | åœºæ™¯ |
|------|------|------|
| **Insert** | æ’å…¥æ–°æ•°æ® | å®æ—¶æ·»åŠ æ–‡æ¡£ |
| **Upsert** | æ’å…¥æˆ–æ›´æ–° | å¤„ç†é‡å¤æ•°æ® |
| **Bulk Insert** | æ‰¹é‡æ’å…¥ | åˆå§‹åŒ–çŸ¥è¯†åº“ |

### Insert ç¤ºä¾‹

```python
# ç›´æ¥æ’å…¥åŸå§‹æ–‡æœ¬
data = [
    {'id': 1, 'document': 'AI is transforming industries.'},
    {'id': 2, 'document': 'ML enables computers to learn.'},
]
result = client.insert(collection_name='my_collection', data=data)
```

### Upsert ä¸¤ç§æ¨¡å¼

**Override æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼š**
```python
# å®Œå…¨æ›¿æ¢ç°æœ‰å®ä½“
client.upsert(collection_name='my_collection', data=data)
```

**Merge æ¨¡å¼ï¼ˆ2.6.2+ï¼‰ï¼š**
```python
# åªæ›´æ–°æŒ‡å®šå­—æ®µ
client.upsert(
    collection_name='my_collection',
    data=data,
    partial_update=True  # å¯ç”¨ Merge æ¨¡å¼
)
```

### Bulk Insert ä¼˜åŒ–

```python
batch_size = 1000
for i in range(0, len(documents), batch_size):
    batch = documents[i:i + batch_size]
    client.insert(collection_name='my_collection', data=batch)
```

### å…³é”®ç‚¹

- **Insert**ï¼šç¡®å®šæ•°æ®ä¸å­˜åœ¨æ—¶ä½¿ç”¨
- **Upsert**ï¼šä¸ç¡®å®šæˆ–éœ€è¦æ›´æ–°æ—¶ä½¿ç”¨
- **Bulk Insert**ï¼šå¤§é‡æ•°æ®æ—¶ä½¿ç”¨æ‰¹å¤„ç†

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 3ï¼šç›¸ä¼¼åº¦æ£€ç´¢æ ¸å¿ƒ

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### æ£€ç´¢ç±»å‹

| ç±»å‹ | åŸç† | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|------|------|------|
| **è¯­ä¹‰æ£€ç´¢** | Dense Vector | ç†è§£è¯­ä¹‰ | å¯èƒ½å¿½ç•¥å…³é”®è¯ |
| **å…³é”®è¯æ£€ç´¢** | BM25 Sparse | ç²¾ç¡®åŒ¹é… | æ— æ³•ç†è§£è¯­ä¹‰ |
| **æ··åˆæ£€ç´¢** | Dense + Sparse | ç»¼åˆä¼˜åŠ¿ | ç¨æ…¢ |

### è¯­ä¹‰æ£€ç´¢ç¤ºä¾‹

```python
# ç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬æŸ¥è¯¢
results = client.search(
    collection_name='my_collection',
    data=['What is AI?'],  # åŸå§‹æ–‡æœ¬
    anns_field='dense',
    limit=5,
    output_fields=['document']
)
```

### æ··åˆæ£€ç´¢ç¤ºä¾‹

```python
from pymilvus import AnnSearchRequest, RRFRanker

# Dense æ£€ç´¢è¯·æ±‚
dense_request = AnnSearchRequest(
    [query], "dense", {"metric_type": "COSINE"}, limit=5
)

# Sparse æ£€ç´¢è¯·æ±‚ï¼ˆBM25ï¼‰
sparse_request = AnnSearchRequest(
    [query], "sparse_vector", {"metric_type": "BM25"}, limit=5
)

# æ‰§è¡Œæ··åˆæ£€ç´¢
results = client.hybrid_search(
    collection_name='my_collection',
    [dense_request, sparse_request],
    ranker=RRFRanker(),  # ä½¿ç”¨ RRF èåˆç»“æœ
    limit=5
)
```

### å…³é”®ç‚¹

- **2026 å¹´æ ‡å‡†**ï¼šæ··åˆæ£€ç´¢æ˜¯ç”Ÿäº§ç¯å¢ƒçš„æ ‡å‡†é…ç½®
- **å‡†ç¡®ç‡æå‡**ï¼šä» 70% æå‡åˆ° 85%
- **RRFRanker**ï¼šReciprocal Rank Fusionï¼Œèåˆå¤šç§æ£€ç´¢ç»“æœ

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 4ï¼šæ··åˆæ£€ç´¢æ·±åº¦è§£æ

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ£€ç´¢ï¼Ÿ

**è¯­ä¹‰æ£€ç´¢çš„å±€é™æ€§ï¼š**
- æŸ¥è¯¢ï¼š"Python æœºå™¨å­¦ä¹ åº“"
- å¯èƒ½è¿”å›ï¼š"Java æœºå™¨å­¦ä¹ åº“"ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼Œä½†è¯­è¨€ä¸å¯¹ï¼‰

**å…³é”®è¯æ£€ç´¢çš„å±€é™æ€§ï¼š**
- æŸ¥è¯¢ï¼š"AI"
- æ— æ³•åŒ¹é…ï¼š"äººå·¥æ™ºèƒ½"ï¼ˆåŒä¹‰è¯ï¼‰

### BM25 Function é…ç½®

```python
# åœ¨ Schema ä¸­æ·»åŠ  BM25 Function
bm25_function = Function(
    name="bm25",
    function_type=FunctionType.BM25,
    input_field_names=["document"],
    output_field_names="sparse_vector"
)
schema.add_function(bm25_function)

# æ·»åŠ  Sparse Vector å­—æ®µ
schema.add_field("sparse_vector", DataType.SPARSE_FLOAT_VECTOR)

# é…ç½®ç´¢å¼•
index_params.add_index(
    field_name="sparse_vector",
    index_type="SPARSE_INVERTED_INDEX",
    metric_type="BM25"
)
```

### Reranking ç­–ç•¥

| Ranker | åŸç† | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|
| **RRFRanker** | Reciprocal Rank Fusion | é€šç”¨åœºæ™¯ |
| **WeightedRanker** | åŠ æƒèåˆ | éœ€è¦è°ƒæ•´æƒé‡ |

### å…³é”®ç‚¹

- **BM25 è‡ªåŠ¨ç”Ÿæˆ**ï¼šMilvus 2.6 å†…ç½® BM25ï¼Œæ— éœ€å¤–éƒ¨å®ç°
- **Sparse Vector ä¸éœ€è¦é‡æ–°è®¡ç®—**ï¼šæ·»åŠ æ–°æ–‡æ¡£æ—¶ï¼ŒBM25 è‡ªåŠ¨æ›´æ–°
- **æ··åˆæ£€ç´¢æ˜¯æ ‡å‡†**ï¼š70% çš„ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æ··åˆæ£€ç´¢

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 5ï¼šæ€§èƒ½ä¼˜åŒ–ç­–ç•¥

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### æ‰¹é‡æ’å…¥ä¼˜åŒ–

**é€‰æ‹©åˆé€‚çš„ Batch Sizeï¼š**

```python
# æ ¹æ®æ–‡æ¡£å¤§å°é€‰æ‹©
if avg_doc_length < 500:
    batch_size = 2000  # çŸ­æ–‡æ¡£
elif avg_doc_length < 2000:
    batch_size = 1000  # ä¸­ç­‰æ–‡æ¡£
else:
    batch_size = 500   # é•¿æ–‡æ¡£
```

**å¹¶è¡Œæ’å…¥ï¼š**

```python
from concurrent.futures import ThreadPoolExecutor

def insert_batch(batch):
    return client.insert(collection_name='my_collection', data=batch)

with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(insert_batch, batch) for batch in batches]
    for future in futures:
        result = future.result()
```

### æ£€ç´¢ä¼˜åŒ–

**ä½¿ç”¨è¿‡æ»¤è¡¨è¾¾å¼ï¼š**

```python
# ç¼©å°æœç´¢èŒƒå›´
results = client.search(
    collection_name='my_collection',
    data=[query],
    anns_field='dense',
    limit=5,
    filter='category == "AI" and year >= 2020'  # è¿‡æ»¤æ¡ä»¶
)
```

**è°ƒæ•´ Top-Kï¼š**

```python
# æ··åˆæ£€ç´¢æ—¶ä½¿ç”¨æ›´å¤§çš„ Top-K
dense_request = AnnSearchRequest([query], "dense", {"metric_type": "COSINE"}, limit=35)
sparse_request = AnnSearchRequest([query], "sparse_vector", {"metric_type": "BM25"}, limit=35)

# æœ€ç»ˆè¿”å› Top-5
results = client.hybrid_search(
    collection_name='my_collection',
    [dense_request, sparse_request],
    ranker=RRFRanker(),
    limit=5  # æœ€ç»ˆè¿”å› 5 æ¡
)
```

### æ€§èƒ½å¯¹æ¯”

| ä¼˜åŒ–æ–¹å¼ | 10,000 æ¡æ•°æ® | æå‡ |
|----------|---------------|------|
| **å•çº¿ç¨‹æ’å…¥** | ~2 åˆ†é’Ÿ | åŸºå‡† |
| **æ‰¹å¤„ç†ï¼ˆbatch=1000ï¼‰** | ~2 åˆ†é’Ÿ | 0% |
| **4 çº¿ç¨‹å¹¶è¡Œ** | ~30 ç§’ | 75% |
| **8 çº¿ç¨‹å¹¶è¡Œ** | ~20 ç§’ | 83% |

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 6ï¼šé”™è¯¯å¤„ç†ä¸é‡è¯•

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### å¸¸è§é”™è¯¯ç±»å‹

| é”™è¯¯ç±»å‹ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|----------|------|----------|
| **API é™æµ** | è¯·æ±‚è¿‡å¿« | æŒ‡æ•°é€€é¿é‡è¯• |
| **ç½‘ç»œè¶…æ—¶** | ç½‘ç»œä¸ç¨³å®š | é‡è¯•æœºåˆ¶ |
| **å‘é‡ç»´åº¦ä¸åŒ¹é…** | é…ç½®é”™è¯¯ | æ£€æŸ¥ Schema é…ç½® |
| **ä¸»é”®é‡å¤** | æ•°æ®é‡å¤ | ä½¿ç”¨ Upsert |

### é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
import time

def insert_with_retry(batch, max_retries=3):
    """å¸¦é‡è¯•çš„æ’å…¥"""
    for attempt in range(max_retries):
        try:
            result = client.insert(collection_name='my_collection', data=batch)
            return result['insert_count']
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                print(f"âš ï¸ æ’å…¥å¤±è´¥ï¼Œ{wait_time} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            else:
                print(f"âŒ æ’å…¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼š{e}")
                raise
```

### æ‰¹é‡æ’å…¥é”™è¯¯å¤„ç†

```python
failed_batches = []

for i, batch in enumerate(batches):
    try:
        result = client.insert(collection_name='my_collection', data=batch)
        print(f"âœ… æ‰¹æ¬¡ {i} å®Œæˆï¼š{result['insert_count']} æ¡æ•°æ®")
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡ {i} å¤±è´¥ï¼š{e}")
        failed_batches.append((i, batch))

# é‡è¯•å¤±è´¥çš„æ‰¹æ¬¡
for i, batch in failed_batches:
    try:
        result = insert_with_retry(batch)
        print(f"âœ… æ‰¹æ¬¡ {i} é‡è¯•æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡ {i} é‡è¯•å¤±è´¥ï¼š{e}")
```

### å…³é”®ç‚¹

- **æŒ‡æ•°é€€é¿**ï¼šé‡è¯•é—´éš”é€æ¸å¢åŠ ï¼ˆ1s, 2s, 4s, 8s...ï¼‰
- **è®°å½•å¤±è´¥æ‰¹æ¬¡**ï¼šä¾¿äºåç»­é‡è¯•
- **æ—¥å¿—è®°å½•**ï¼šè®°å½•æ‰€æœ‰é”™è¯¯ä¿¡æ¯

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 7ï¼šç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### é…ç½®ç®¡ç†

**ç»Ÿä¸€é…ç½®ï¼ˆmilvus.yamlï¼‰ï¼š**

```yaml
credential:
  # å¼€å‘ç¯å¢ƒ
  apikey_dev:
    apikey: "sk-dev-key"

  # ç”Ÿäº§ç¯å¢ƒ
  apikey_prod:
    apikey: "sk-prod-key"

function:
  textEmbedding:
    providers:
      openai:
        credential: apikey_prod  # åˆ‡æ¢ç¯å¢ƒåªéœ€ä¿®æ”¹è¿™é‡Œ
```

### ç›‘æ§ä¸æ—¥å¿—

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è®°å½•æ’å…¥æ“ä½œ
try:
    result = client.insert(collection_name='my_collection', data=data)
    logger.info(f"âœ… æ’å…¥æˆåŠŸï¼š{result['insert_count']} æ¡æ•°æ®")
except Exception as e:
    logger.error(f"âŒ æ’å…¥å¤±è´¥ï¼š{e}")
    raise
```

### æ€§èƒ½ç›‘æ§

```python
import time

start_time = time.time()
result = client.insert(collection_name='my_collection', data=data)
elapsed_time = time.time() - start_time

logger.info(f"æ’å…¥ {result['insert_count']} æ¡æ•°æ®ï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’")
```

### æ•°æ®éªŒè¯

```python
# æ’å…¥å‰éªŒè¯æ•°æ®
def validate_data(data):
    for item in data:
        if 'id' not in item:
            raise ValueError("ç¼ºå°‘ä¸»é”® 'id'")
        if 'document' not in item:
            raise ValueError("ç¼ºå°‘æ–‡æœ¬å­—æ®µ 'document'")
        if len(item['document']) == 0:
            raise ValueError("æ–‡æœ¬å­—æ®µä¸èƒ½ä¸ºç©º")
    return True

# ä½¿ç”¨
validate_data(data)
result = client.insert(collection_name='my_collection', data=data)
```

### å…³é”®ç‚¹

- **ç¯å¢ƒéš”ç¦»**ï¼šå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒåˆ†ç¦»
- **æ—¥å¿—è®°å½•**ï¼šè®°å½•æ‰€æœ‰å…³é”®æ“ä½œ
- **æ€§èƒ½ç›‘æ§**ï¼šç›‘æ§æ’å…¥å’ŒæŸ¥è¯¢æ€§èƒ½
- **æ•°æ®éªŒè¯**ï¼šæ’å…¥å‰éªŒè¯æ•°æ®å®Œæ•´æ€§

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 8ï¼šé«˜çº§ç‰¹æ€§åº”ç”¨

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### å¤šå‘é‡å­—æ®µ

```python
# ä¸ºæ–‡æœ¬å’Œå›¾ç‰‡åˆ†åˆ«é…ç½® Embedding Function
text_embedding_function = Function(
    name="text_embedding",
    function_type=FunctionType.TEXTEMBEDDING,
    input_field_names=["text"],
    output_field_names=["text_vector"],
    params={"provider": "openai", "model_name": "text-embedding-3-small"}
)

image_embedding_function = Function(
    name="image_embedding",
    function_type=FunctionType.TEXTEMBEDDING,
    input_field_names=["image_description"],
    output_field_names=["image_vector"],
    params={"provider": "cohere", "model_name": "embed-english-v3.0"}
)

schema.add_function(text_embedding_function)
schema.add_function(image_embedding_function)
```

### åŠ¨æ€å­—æ®µ

```python
# å¯ç”¨åŠ¨æ€å­—æ®µ
schema = client.create_schema(enable_dynamic_field=True)

# æ’å…¥æ—¶å¯ä»¥æ·»åŠ ä»»æ„å­—æ®µ
data = [
    {
        'id': 1,
        'document': 'AI document',
        'custom_field_1': 'value1',  # åŠ¨æ€å­—æ®µ
        'custom_field_2': 'value2'   # åŠ¨æ€å­—æ®µ
    }
]
```

### åˆ†åŒºç®¡ç†

```python
# åˆ›å»ºåˆ†åŒº
client.create_partition(collection_name='my_collection', partition_name='2024')

# æ’å…¥åˆ°ç‰¹å®šåˆ†åŒº
client.insert(
    collection_name='my_collection',
    data=data,
    partition_name='2024'
)

# åœ¨ç‰¹å®šåˆ†åŒºä¸­æ£€ç´¢
results = client.search(
    collection_name='my_collection',
    data=[query],
    anns_field='dense',
    limit=5,
    partition_names=['2024']  # åªåœ¨ 2024 åˆ†åŒºä¸­æ£€ç´¢
)
```

### å…³é”®ç‚¹

- **å¤šå‘é‡å­—æ®µ**ï¼šæ”¯æŒå¤šæ¨¡æ€æ£€ç´¢ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
- **åŠ¨æ€å­—æ®µ**ï¼šçµæ´»æ·»åŠ å…ƒæ•°æ®
- **åˆ†åŒºç®¡ç†**ï¼šæŒ‰æ—¶é—´æˆ–ç±»åˆ«åˆ†åŒºï¼Œæé«˜æ£€ç´¢æ•ˆç‡

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 9ï¼šæ•…éšœæ’æŸ¥æŒ‡å—

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### å¸¸è§é—®é¢˜è¯Šæ–­

**é—®é¢˜ 1ï¼šæ’å…¥é€Ÿåº¦æ…¢**

**å¯èƒ½åŸå› ï¼š**
- Batch Size å¤ªå°
- ç½‘ç»œå»¶è¿Ÿé«˜
- Embedding API é™æµ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# å¢å¤§ Batch Size
batch_size = 2000  # ä» 100 å¢åŠ åˆ° 2000

# ä½¿ç”¨å¹¶è¡Œæ’å…¥
with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(insert_batch, batch) for batch in batches]
```

**é—®é¢˜ 2ï¼šæ£€ç´¢ç»“æœä¸å‡†ç¡®**

**å¯èƒ½åŸå› ï¼š**
- åªä½¿ç”¨è¯­ä¹‰æ£€ç´¢
- Top-K å¤ªå°
- æ²¡æœ‰ä½¿ç”¨ Reranking

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# ä½¿ç”¨æ··åˆæ£€ç´¢
results = client.hybrid_search(
    collection_name='my_collection',
    [dense_request, sparse_request],
    ranker=RRFRanker(),
    limit=5
)

# å¢å¤§ Top-K
dense_request = AnnSearchRequest([query], "dense", {"metric_type": "COSINE"}, limit=35)
```

**é—®é¢˜ 3ï¼šå‘é‡ç»´åº¦ä¸åŒ¹é…**

**å¯èƒ½åŸå› ï¼š**
- Schema ä¸­çš„ dim ä¸ Embedding æ¨¡å‹è¾“å‡ºä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ£€æŸ¥ Embedding æ¨¡å‹çš„è¾“å‡ºç»´åº¦
# text-embedding-3-small: 1536
# text-embedding-3-large: 3072

# ç¡®ä¿ Schema ä¸­çš„ dim ä¸€è‡´
schema.add_field("dense", DataType.FLOAT_VECTOR, dim=1536)
```

### è°ƒè¯•æŠ€å·§

```python
# æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
import traceback

try:
    result = client.insert(collection_name='my_collection', data=data)
except Exception as e:
    print(f"é”™è¯¯ç±»å‹ï¼š{type(e).__name__}")
    print(f"é”™è¯¯ä¿¡æ¯ï¼š{str(e)}")
    print("è¯¦ç»†å †æ ˆï¼š")
    traceback.print_exc()
```

---

## ğŸ“‡ çŸ¥è¯†å¡ç‰‡ 10ï¼šå®Œæ•´å·¥ä½œæµæ€»ç»“

**é˜…è¯»æ—¶é—´ï¼š2 åˆ†é’Ÿ**

### ç«¯åˆ°ç«¯å·¥ä½œæµ

```python
from pymilvus import MilvusClient, DataType, Function, FunctionType, AnnSearchRequest, RRFRanker

# ========== æ­¥éª¤ 1ï¼šè¿æ¥ Milvus ==========
client = MilvusClient(uri="http://localhost:19530")

# ========== æ­¥éª¤ 2ï¼šåˆ›å»º Schema ==========
schema = client.create_schema()
schema.add_field("id", DataType.INT64, is_primary=True, auto_id=False)
schema.add_field("document", DataType.VARCHAR, max_length=9000)
schema.add_field("dense", DataType.FLOAT_VECTOR, dim=1536)
schema.add_field("sparse_vector", DataType.SPARSE_FLOAT_VECTOR)

# ========== æ­¥éª¤ 3ï¼šé…ç½® Embedding Functions ==========
# Dense Embedding Function
text_embedding_function = Function(
    name="openai_embedding",
    function_type=FunctionType.TEXTEMBEDDING,
    input_field_names=["document"],
    output_field_names=["dense"],
    params={"provider": "openai", "model_name": "text-embedding-3-small"}
)
schema.add_function(text_embedding_function)

# BM25 Function
bm25_function = Function(
    name="bm25",
    function_type=FunctionType.BM25,
    input_field_names=["document"],
    output_field_names="sparse_vector"
)
schema.add_function(bm25_function)

# ========== æ­¥éª¤ 4ï¼šé…ç½®ç´¢å¼• ==========
index_params = client.prepare_index_params()
index_params.add_index(field_name="dense", index_type="AUTOINDEX", metric_type="COSINE")
index_params.add_index(field_name="sparse_vector", index_type="SPARSE_INVERTED_INDEX", metric_type="BM25")

# ========== æ­¥éª¤ 5ï¼šåˆ›å»º Collection ==========
client.create_collection(collection_name='my_collection', schema=schema, index_params=index_params)

# ========== æ­¥éª¤ 6ï¼šæ’å…¥æ•°æ® ==========
data = [
    {'id': 1, 'document': 'Artificial Intelligence is transforming industries.'},
    {'id': 2, 'document': 'Machine Learning enables computers to learn from data.'},
    {'id': 3, 'document': 'Deep Learning uses neural networks for complex tasks.'},
]
result = client.insert(collection_name='my_collection', data=data)
print(f"âœ… æ’å…¥æˆåŠŸï¼š{result['insert_count']} æ¡æ•°æ®")

# ========== æ­¥éª¤ 7ï¼šæ··åˆæ£€ç´¢ ==========
query = "What is AI?"

# Dense æ£€ç´¢è¯·æ±‚
dense_request = AnnSearchRequest([query], "dense", {"metric_type": "COSINE"}, limit=5)

# Sparse æ£€ç´¢è¯·æ±‚ï¼ˆBM25ï¼‰
sparse_request = AnnSearchRequest([query], "sparse_vector", {"metric_type": "BM25"}, limit=5)

# æ‰§è¡Œæ··åˆæ£€ç´¢
results = client.hybrid_search(
    collection_name='my_collection',
    [dense_request, sparse_request],
    ranker=RRFRanker(),
    limit=5,
    output_fields=['document']
)

# ========== æ­¥éª¤ 8ï¼šè¾“å‡ºç»“æœ ==========
print("\nğŸ” æ£€ç´¢ç»“æœï¼š")
for i, result in enumerate(results[0]):
    print(f"{i+1}. Score: {result['distance']:.4f}, Content: {result['entity']['document']}")
```

### æ ¸å¿ƒè¦ç‚¹æ€»ç»“

1. **Embedding Functions**ï¼šè‡ªåŠ¨å‘é‡åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨ API
2. **æ··åˆæ£€ç´¢**ï¼šç»“åˆ Dense å’Œ Sparseï¼Œæé«˜å‡†ç¡®æ€§
3. **æ‰¹é‡æ’å…¥**ï¼šä½¿ç”¨æ‰¹å¤„ç†å’Œå¹¶è¡Œæé«˜æ•ˆç‡
4. **é”™è¯¯å¤„ç†**ï¼šä½¿ç”¨é‡è¯•æœºåˆ¶å’Œæ—¥å¿—è®°å½•
5. **ç”Ÿäº§ä¼˜åŒ–**ï¼šç›‘æ§æ€§èƒ½ï¼Œä¼˜åŒ–é…ç½®

### å­¦ä¹ è·¯å¾„

```
åŸºç¡€ â†’ è¿›é˜¶ â†’ é«˜çº§ â†’ ç”Ÿäº§
  â†“      â†“      â†“      â†“
å¡ç‰‡1-3  å¡ç‰‡4-6  å¡ç‰‡7-8  å¡ç‰‡9-10
```

**æ­å–œï¼** ä½ å·²ç»æŒæ¡äº† Milvus æ•°æ®æ’å…¥ä¸æŸ¥è¯¢çš„å®Œæ•´çŸ¥è¯†ä½“ç³»ã€‚
