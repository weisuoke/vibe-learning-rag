# 实战代码 - 场景1：基础混合检索操作

完整的混合检索工作流程，从创建 Collection 到执行查询。

---

## 场景描述

**目标**：构建一个文档检索系统，支持语义搜索 + 精确过滤

**需求**：
- 存储文档的标题、内容、年份、类别、评分
- 支持语义搜索（向量检索）
- 支持按年份、类别、评分过滤（标量过滤）

**数据规模**：1000条文档

---

## 完整代码

```python
"""
场景1：基础混合检索操作
演示：创建 Collection → 插入数据 → 执行混合检索
"""

from pymilvus import (
    connections,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
    utility
)
import numpy as np
from typing import List
import time

# ===== 1. 连接 Milvus =====
print("=== 1. 连接 Milvus ===")

connections.connect(
    alias="default",
    host="localhost",
    port="19530"
)

print("✓ 连接成功")

# ===== 2. 定义 Schema =====
print("\n=== 2. 定义 Schema ===")

# 定义字段
fields = [
    # 主键字段
    FieldSchema(
        name="id",
        dtype=DataType.INT64,
        is_primary=True,
        auto_id=True,
        description="文档ID"
    ),

    # 向量字段（用于语义搜索）
    FieldSchema(
        name="embedding",
        dtype=DataType.FLOAT_VECTOR,
        dim=768,
        description="文档向量（768维）"
    ),

    # 标量字段（用于精确过滤）
    FieldSchema(
        name="title",
        dtype=DataType.VARCHAR,
        max_length=500,
        description="文档标题"
    ),

    FieldSchema(
        name="content",
        dtype=DataType.VARCHAR,
        max_length=2000,
        description="文档内容"
    ),

    FieldSchema(
        name="year",
        dtype=DataType.INT64,
        description="发布年份"
    ),

    FieldSchema(
        name="category",
        dtype=DataType.VARCHAR,
        max_length=100,
        description="文档类别"
    ),

    FieldSchema(
        name="rating",
        dtype=DataType.FLOAT,
        description="文档评分（0-5）"
    )
]

# 创建 Schema
schema = CollectionSchema(
    fields=fields,
    description="文档检索系统"
)

print("✓ Schema 定义完成")
print(f"  - 字段数量: {len(fields)}")
print(f"  - 向量维度: 768")

# ===== 3. 创建 Collection =====
print("\n=== 3. 创建 Collection ===")

collection_name = "documents_basic"

# 删除已存在的 Collection（如果有）
if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)
    print(f"✓ 删除旧 Collection: {collection_name}")

# 创建新 Collection
collection = Collection(
    name=collection_name,
    schema=schema
)

print(f"✓ Collection 创建成功: {collection_name}")

# ===== 4. 创建索引 =====
print("\n=== 4. 创建索引 ===")

# 4.1 创建向量索引
print("  4.1 创建向量索引...")

index_params = {
    "index_type": "HNSW",      # 使用 HNSW 算法
    "metric_type": "L2",       # 欧氏距离
    "params": {
        "M": 16,               # 每个节点的连接数
        "efConstruction": 200  # 构建时的搜索深度
    }
}

collection.create_index(
    field_name="embedding",
    index_params=index_params
)

print("  ✓ 向量索引创建成功（HNSW）")

# 4.2 创建标量索引
print("  4.2 创建标量索引...")

# 为年份创建索引
collection.create_index(
    field_name="year",
    index_name="year_index"
)

# 为类别创建索引
collection.create_index(
    field_name="category",
    index_name="category_index"
)

print("  ✓ 标量索引创建成功（year, category）")

# ===== 5. 准备测试数据 =====
print("\n=== 5. 准备测试数据 ===")

def generate_random_embedding(dim: int = 768) -> List[float]:
    """生成随机向量（模拟 Embedding）"""
    return np.random.rand(dim).tolist()

# 准备1000条文档数据
documents = []

categories = ["tutorial", "guide", "documentation", "blog", "paper"]
years = [2020, 2021, 2022, 2023, 2024]

for i in range(1000):
    doc = {
        "embedding": generate_random_embedding(768),
        "title": f"Document {i+1}: Python Programming",
        "content": f"This is the content of document {i+1}. It covers Python programming concepts.",
        "year": np.random.choice(years),
        "category": np.random.choice(categories),
        "rating": round(np.random.uniform(3.0, 5.0), 1)
    }
    documents.append(doc)

print(f"✓ 生成 {len(documents)} 条测试数据")

# ===== 6. 插入数据 =====
print("\n=== 6. 插入数据 ===")

# 批量插入
insert_result = collection.insert(documents)

# 刷新数据（确保持久化）
collection.flush()

print(f"✓ 插入 {len(documents)} 条数据")
print(f"  - 插入的 ID 范围: {insert_result.primary_keys[0]} - {insert_result.primary_keys[-1]}")

# ===== 7. 加载 Collection =====
print("\n=== 7. 加载 Collection ===")

collection.load()

print("✓ Collection 加载到内存")

# 等待加载完成
time.sleep(2)

# 检查加载状态
print(f"  - 数据量: {collection.num_entities}")

# ===== 8. 执行混合检索 =====
print("\n=== 8. 执行混合检索 ===")

# 8.1 准备查询向量
print("  8.1 准备查询向量...")

query_vector = generate_random_embedding(768)

print("  ✓ 查询向量准备完成")

# 8.2 纯向量检索（无过滤）
print("\n  8.2 纯向量检索（无过滤）...")

start = time.time()

results_no_filter = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"ef": 64}},
    limit=10,
    output_fields=["title", "year", "category", "rating"]
)

time_no_filter = time.time() - start

print(f"  ✓ 查询完成，耗时: {time_no_filter*1000:.2f}ms")
print(f"  ✓ 返回结果数: {len(results_no_filter[0])}")

# 输出前3条结果
print("\n  前3条结果:")
for i, hit in enumerate(results_no_filter[0][:3]):
    print(f"    {i+1}. ID: {hit.id}, Distance: {hit.distance:.4f}")
    print(f"       Title: {hit.entity.get('title')}")
    print(f"       Year: {hit.entity.get('year')}, Category: {hit.entity.get('category')}, Rating: {hit.entity.get('rating')}")

# 8.3 混合检索：年份过滤
print("\n  8.3 混合检索：年份过滤（year == 2024）...")

start = time.time()

results_year = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"ef": 64}},
    limit=10,
    expr="year == 2024",  # 只查询2024年的文档
    output_fields=["title", "year", "category", "rating"]
)

time_year = time.time() - start

print(f"  ✓ 查询完成，耗时: {time_year*1000:.2f}ms")
print(f"  ✓ 返回结果数: {len(results_year[0])}")

# 验证所有结果都是2024年
all_2024 = all(hit.entity.get('year') == 2024 for hit in results_year[0])
print(f"  ✓ 所有结果都是2024年: {all_2024}")

# 输出前3条结果
print("\n  前3条结果:")
for i, hit in enumerate(results_year[0][:3]):
    print(f"    {i+1}. ID: {hit.id}, Distance: {hit.distance:.4f}")
    print(f"       Title: {hit.entity.get('title')}")
    print(f"       Year: {hit.entity.get('year')}, Category: {hit.entity.get('category')}, Rating: {hit.entity.get('rating')}")

# 8.4 混合检索：类别过滤
print("\n  8.4 混合检索：类别过滤（category == 'tutorial'）...")

start = time.time()

results_category = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"ef": 64}},
    limit=10,
    expr="category == 'tutorial'",  # 只查询教程类文档
    output_fields=["title", "year", "category", "rating"]
)

time_category = time.time() - start

print(f"  ✓ 查询完成，耗时: {time_category*1000:.2f}ms")
print(f"  ✓ 返回结果数: {len(results_category[0])}")

# 验证所有结果都是 tutorial
all_tutorial = all(hit.entity.get('category') == 'tutorial' for hit in results_category[0])
print(f"  ✓ 所有结果都是 tutorial: {all_tutorial}")

# 8.5 混合检索：评分过滤
print("\n  8.5 混合检索：评分过滤（rating >= 4.5）...")

start = time.time()

results_rating = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"ef": 64}},
    limit=10,
    expr="rating >= 4.5",  # 只查询高评分文档
    output_fields=["title", "year", "category", "rating"]
)

time_rating = time.time() - start

print(f"  ✓ 查询完成，耗时: {time_rating*1000:.2f}ms")
print(f"  ✓ 返回结果数: {len(results_rating[0])}")

# 验证所有结果评分 >= 4.5
all_high_rating = all(hit.entity.get('rating') >= 4.5 for hit in results_rating[0])
print(f"  ✓ 所有结果评分 >= 4.5: {all_high_rating}")

# 8.6 混合检索：多条件组合
print("\n  8.6 混合检索：多条件组合（year == 2024 AND category == 'tutorial' AND rating >= 4.5）...")

start = time.time()

results_combined = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"ef": 64}},
    limit=10,
    expr="year == 2024 and category == 'tutorial' and rating >= 4.5",
    output_fields=["title", "year", "category", "rating"]
)

time_combined = time.time() - start

print(f"  ✓ 查询完成，耗时: {time_combined*1000:.2f}ms")
print(f"  ✓ 返回结果数: {len(results_combined[0])}")

# 验证所有结果都满足条件
if len(results_combined[0]) > 0:
    all_match = all(
        hit.entity.get('year') == 2024 and
        hit.entity.get('category') == 'tutorial' and
        hit.entity.get('rating') >= 4.5
        for hit in results_combined[0]
    )
    print(f"  ✓ 所有结果都满足条件: {all_match}")

    # 输出前3条结果
    print("\n  前3条结果:")
    for i, hit in enumerate(results_combined[0][:3]):
        print(f"    {i+1}. ID: {hit.id}, Distance: {hit.distance:.4f}")
        print(f"       Title: {hit.entity.get('title')}")
        print(f"       Year: {hit.entity.get('year')}, Category: {hit.entity.get('category')}, Rating: {hit.entity.get('rating')}")
else:
    print("  ⚠ 没有找到满足所有条件的结果")

# ===== 9. 性能对比 =====
print("\n=== 9. 性能对比 ===")

print(f"  - 无过滤:     {time_no_filter*1000:.2f}ms")
print(f"  - 年份过滤:   {time_year*1000:.2f}ms")
print(f"  - 类别过滤:   {time_category*1000:.2f}ms")
print(f"  - 评分过滤:   {time_rating*1000:.2f}ms")
print(f"  - 多条件组合: {time_combined*1000:.2f}ms")

# ===== 10. 清理资源 =====
print("\n=== 10. 清理资源 ===")

# 释放 Collection
collection.release()
print("✓ Collection 已释放")

# 断开连接
connections.disconnect("default")
print("✓ 连接已断开")

print("\n=== 场景1完成 ===")
```

---

## 运行输出示例

```
=== 1. 连接 Milvus ===
✓ 连接成功

=== 2. 定义 Schema ===
✓ Schema 定义完成
  - 字段数量: 7
  - 向量维度: 768

=== 3. 创建 Collection ===
✓ 删除旧 Collection: documents_basic
✓ Collection 创建成功: documents_basic

=== 4. 创建索引 ===
  4.1 创建向量索引...
  ✓ 向量索引创建成功（HNSW）
  4.2 创建标量索引...
  ✓ 标量索引创建成功（year, category）

=== 5. 准备测试数据 ===
✓ 生成 1000 条测试数据

=== 6. 插入数据 ===
✓ 插入 1000 条数据
  - 插入的 ID 范围: 450215494041395200 - 450215494041396199

=== 7. 加载 Collection ===
✓ Collection 加载到内存
  - 数据量: 1000

=== 8. 执行混合检索 ===
  8.1 准备查询向量...
  ✓ 查询向量准备完成

  8.2 纯向量检索（无过滤）...
  ✓ 查询完成，耗时: 12.34ms
  ✓ 返回结果数: 10

  前3条结果:
    1. ID: 450215494041395456, Distance: 45.2341
       Title: Document 257: Python Programming
       Year: 2023, Category: guide, Rating: 4.2
    2. ID: 450215494041395789, Distance: 45.8912
       Title: Document 590: Python Programming
       Year: 2024, Category: tutorial, Rating: 4.8
    3. ID: 450215494041395321, Distance: 46.1234
       Title: Document 122: Python Programming
       Year: 2022, Category: blog, Rating: 3.9

  8.3 混合检索：年份过滤（year == 2024）...
  ✓ 查询完成，耗时: 8.56ms
  ✓ 返回结果数: 10
  ✓ 所有结果都是2024年: True

  前3条结果:
    1. ID: 450215494041395789, Distance: 45.8912
       Title: Document 590: Python Programming
       Year: 2024, Category: tutorial, Rating: 4.8
    2. ID: 450215494041395912, Distance: 47.3456
       Title: Document 713: Python Programming
       Year: 2024, Category: documentation, Rating: 4.5
    3. ID: 450215494041396045, Distance: 48.2341
       Title: Document 846: Python Programming
       Year: 2024, Category: guide, Rating: 4.1

  8.4 混合检索：类别过滤（category == 'tutorial'）...
  ✓ 查询完成，耗时: 9.12ms
  ✓ 返回结果数: 10
  ✓ 所有结果都是 tutorial: True

  8.5 混合检索：评分过滤（rating >= 4.5）...
  ✓ 查询完成，耗时: 10.23ms
  ✓ 返回结果数: 10
  ✓ 所有结果评分 >= 4.5: True

  8.6 混合检索：多条件组合（year == 2024 AND category == 'tutorial' AND rating >= 4.5）...
  ✓ 查询完成，耗时: 7.89ms
  ✓ 返回结果数: 3
  ✓ 所有结果都满足条件: True

  前3条结果:
    1. ID: 450215494041395789, Distance: 45.8912
       Title: Document 590: Python Programming
       Year: 2024, Category: tutorial, Rating: 4.8
    2. ID: 450215494041396123, Distance: 52.1234
       Title: Document 924: Python Programming
       Year: 2024, Category: tutorial, Rating: 4.7
    3. ID: 450215494041395567, Distance: 53.4567
       Title: Document 368: Python Programming
       Year: 2024, Category: tutorial, Rating: 4.6

=== 9. 性能对比 ===
  - 无过滤:     12.34ms
  - 年份过滤:   8.56ms
  - 类别过滤:   9.12ms
  - 评分过滤:   10.23ms
  - 多条件组合: 7.89ms

=== 10. 清理资源 ===
✓ Collection 已释放
✓ 连接已断开

=== 场景1完成 ===
```

---

## 关键要点

### 1. Schema 设计

```python
# 向量字段：用于语义搜索
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)

# 标量字段：用于精确过滤
FieldSchema(name="year", dtype=DataType.INT64)
FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100)
FieldSchema(name="rating", dtype=DataType.FLOAT)
```

### 2. 索引创建

```python
# 向量索引：HNSW（高召回率）
index_params = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {"M": 16, "efConstruction": 200}
}

# 标量索引：为常用过滤字段创建
collection.create_index(field_name="year")
collection.create_index(field_name="category")
```

### 3. 混合检索语法

```python
# 基础语法
results = collection.search(
    data=[query_vector],        # 查询向量
    anns_field="embedding",     # 向量字段名
    param={...},                # 检索参数
    limit=10,                   # Top-K
    expr="year == 2024",        # 标量过滤
    output_fields=[...]         # 返回字段
)
```

### 4. 性能观察

- **无过滤**：12.34ms（基准）
- **单条件过滤**：8-10ms（略快，因为数据量减少）
- **多条件组合**：7.89ms（最快，因为过滤掉更多数据）

**结论**：合理的过滤条件可以提升性能。

---

## 扩展练习

1. **修改向量维度**：将 768 维改为 384 维，观察性能变化
2. **测试不同索引**：将 HNSW 改为 IVF_FLAT，对比性能
3. **增加数据量**：将 1000 条增加到 10000 条，观察性能变化
4. **测试复杂表达式**：使用 OR、IN、范围查询等

---

**下一步**：学习 [10_实战代码_场景2_复杂过滤条件组合.md](./10_实战代码_场景2_复杂过滤条件组合.md)
