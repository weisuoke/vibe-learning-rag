# æ ¸å¿ƒæ¦‚å¿µ8ï¼šç¼–ç ä¸é”™è¯¯å¤„ç†

> æŒæ¡æ–‡æ¡£åŠ è½½ä¸­çš„ç¼–ç æ£€æµ‹å’Œå¥å£®çš„é”™è¯¯å¤„ç†ç­–ç•¥

---

## ä¸ºä»€ä¹ˆç¼–ç ä¸é”™è¯¯å¤„ç†é‡è¦ï¼Ÿ

æ–‡æ¡£åŠ è½½è¿‡ç¨‹ä¸­æœ€å¸¸è§çš„ä¸¤ç±»é—®é¢˜ï¼š
1. **ç¼–ç é—®é¢˜**ï¼šæ–‡ä»¶ç¼–ç ä¸æ­£ç¡®å¯¼è‡´ä¹±ç 
2. **åŠ è½½å¤±è´¥**ï¼šæ–‡ä»¶æŸåã€æ ¼å¼ä¸æ”¯æŒã€æƒé™é—®é¢˜

**åœ¨RAGç³»ç»Ÿä¸­ï¼Œå¥å£®çš„é”™è¯¯å¤„ç†ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§å’Œæ•°æ®è´¨é‡ã€‚**

---

## 1. æ–‡ä»¶ç¼–ç é—®é¢˜

### 1.1 å¸¸è§ç¼–ç ç±»å‹

```python
"""
å¸¸è§æ–‡ä»¶ç¼–ç ç±»å‹
"""

COMMON_ENCODINGS = {
    "UTF-8": "é€šç”¨ç¼–ç ï¼Œæ”¯æŒæ‰€æœ‰è¯­è¨€",
    "GBK": "ä¸­æ–‡Windowsç³»ç»Ÿå¸¸ç”¨",
    "GB2312": "ç®€ä½“ä¸­æ–‡",
    "Big5": "ç¹ä½“ä¸­æ–‡",
    "ISO-8859-1": "è¥¿æ¬§è¯­è¨€",
    "ASCII": "è‹±æ–‡",
    "UTF-16": "Unicodeç¼–ç ",
    "Shift-JIS": "æ—¥æ–‡"
}

# ç¼–ç é—®é¢˜ç¤ºä¾‹
text_utf8 = "ä½ å¥½ä¸–ç•Œ".encode('utf-8')
print(text_utf8)  # b'\xe4\xbd\xa0\xe5\xa5\xbd\xe4\xb8\x96\xe7\x95\x8c'

# é”™è¯¯çš„è§£ç æ–¹å¼
try:
    text_gbk = text_utf8.decode('gbk')  # ä¼šäº§ç”Ÿä¹±ç 
    print(text_gbk)
except UnicodeDecodeError as e:
    print(f"è§£ç é”™è¯¯: {e}")
```

### 1.2 ä½¿ç”¨chardetæ£€æµ‹ç¼–ç 

```python
"""
ä½¿ç”¨chardetè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç 
"""

import chardet

def detect_encoding(file_path: str) -> dict:
    """æ£€æµ‹æ–‡ä»¶ç¼–ç """
    with open(file_path, 'rb') as f:
        raw_data = f.read()

    # æ£€æµ‹ç¼–ç 
    result = chardet.detect(raw_data)

    return {
        "encoding": result['encoding'],
        "confidence": result['confidence'],
        "language": result.get('language', 'unknown')
    }

# ä½¿ç”¨ç¤ºä¾‹
result = detect_encoding("document.txt")
print(f"æ£€æµ‹åˆ°ç¼–ç : {result['encoding']}")
print(f"ç½®ä¿¡åº¦: {result['confidence']:.2%}")

# ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç è¯»å–æ–‡ä»¶
with open("document.txt", 'r', encoding=result['encoding']) as f:
    content = f.read()
    print(content[:100])
```

### 1.3 å¤šç¼–ç å°è¯•ç­–ç•¥

```python
"""
å¤šç¼–ç å°è¯•ç­–ç•¥
æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒç¼–ç 
"""

from typing import Optional

def read_file_with_fallback(file_path: str) -> tuple[str, str]:
    """
    ä½¿ç”¨å›é€€ç­–ç•¥è¯»å–æ–‡ä»¶
    è¿”å›: (content, encoding)
    """
    # ç¼–ç ä¼˜å…ˆçº§åˆ—è¡¨
    encodings = ['utf-8', 'gbk', 'gb2312', 'big5', 'iso-8859-1', 'ascii']

    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                content = f.read()
                print(f"âœ… æˆåŠŸä½¿ç”¨ç¼–ç : {encoding}")
                return content, encoding
        except UnicodeDecodeError:
            print(f"âŒ {encoding} è§£ç å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
            continue
        except Exception as e:
            print(f"âŒ {encoding} è¯»å–å¤±è´¥: {e}")
            continue

    # æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨errors='ignore'
    print("âš ï¸  æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨UTF-8å¹¶å¿½ç•¥é”™è¯¯")
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
        return content, 'utf-8 (with errors ignored)'

# ä½¿ç”¨ç¤ºä¾‹
content, encoding = read_file_with_fallback("document.txt")
print(f"\nä½¿ç”¨ç¼–ç : {encoding}")
print(f"å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
```

### 1.4 æ™ºèƒ½ç¼–ç æ£€æµ‹ä¸è¯»å–

```python
"""
ç»“åˆchardetå’Œå›é€€ç­–ç•¥çš„æ™ºèƒ½è¯»å–
"""

import chardet
from typing import Tuple

class SmartFileReader:
    """æ™ºèƒ½æ–‡ä»¶è¯»å–å™¨"""

    def __init__(self, confidence_threshold: float = 0.7):
        self.confidence_threshold = confidence_threshold
        self.fallback_encodings = ['utf-8', 'gbk', 'gb2312', 'iso-8859-1']

    def read(self, file_path: str) -> Tuple[str, str]:
        """
        æ™ºèƒ½è¯»å–æ–‡ä»¶
        è¿”å›: (content, encoding)
        """
        # 1. æ£€æµ‹ç¼–ç 
        detected = self._detect_encoding(file_path)

        # 2. å¦‚æœç½®ä¿¡åº¦é«˜ï¼Œç›´æ¥ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç 
        if detected['confidence'] >= self.confidence_threshold:
            try:
                content = self._read_with_encoding(file_path, detected['encoding'])
                print(f"âœ… ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç : {detected['encoding']} (ç½®ä¿¡åº¦: {detected['confidence']:.2%})")
                return content, detected['encoding']
            except Exception as e:
                print(f"âš ï¸  æ£€æµ‹åˆ°çš„ç¼–ç å¤±è´¥: {e}")

        # 3. ç½®ä¿¡åº¦ä½æˆ–å¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥
        print("ä½¿ç”¨å›é€€ç­–ç•¥...")
        return self._read_with_fallback(file_path)

    def _detect_encoding(self, file_path: str) -> dict:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        with open(file_path, 'rb') as f:
            raw_data = f.read()
        result = chardet.detect(raw_data)
        return {
            "encoding": result['encoding'],
            "confidence": result['confidence']
        }

    def _read_with_encoding(self, file_path: str, encoding: str) -> str:
        """ä½¿ç”¨æŒ‡å®šç¼–ç è¯»å–"""
        with open(file_path, 'r', encoding=encoding) as f:
            return f.read()

    def _read_with_fallback(self, file_path: str) -> Tuple[str, str]:
        """å›é€€ç­–ç•¥è¯»å–"""
        for encoding in self.fallback_encodings:
            try:
                content = self._read_with_encoding(file_path, encoding)
                print(f"âœ… å›é€€æˆåŠŸ: {encoding}")
                return content, encoding
            except:
                continue

        # æœ€åçš„æ‰‹æ®µï¼šå¿½ç•¥é”™è¯¯
        print("âš ï¸  ä½¿ç”¨UTF-8å¹¶å¿½ç•¥é”™è¯¯")
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read(), 'utf-8 (errors ignored)'

# ä½¿ç”¨ç¤ºä¾‹
reader = SmartFileReader(confidence_threshold=0.7)
content, encoding = reader.read("document.txt")
print(f"\næœ€ç»ˆä½¿ç”¨ç¼–ç : {encoding}")
```

---

## 2. é”™è¯¯å¤„ç†ç­–ç•¥

### 2.1 é”™è¯¯åˆ†ç±»

```python
"""
æ–‡æ¡£åŠ è½½é”™è¯¯åˆ†ç±»
"""

from enum import Enum

class LoadErrorType(Enum):
    """åŠ è½½é”™è¯¯ç±»å‹"""
    FILE_NOT_FOUND = "æ–‡ä»¶ä¸å­˜åœ¨"
    PERMISSION_DENIED = "æƒé™ä¸è¶³"
    ENCODING_ERROR = "ç¼–ç é”™è¯¯"
    FORMAT_ERROR = "æ ¼å¼é”™è¯¯"
    CORRUPTED_FILE = "æ–‡ä»¶æŸå"
    TIMEOUT = "è¶…æ—¶"
    NETWORK_ERROR = "ç½‘ç»œé”™è¯¯"
    UNKNOWN = "æœªçŸ¥é”™è¯¯"

class LoadError(Exception):
    """åŠ è½½é”™è¯¯åŸºç±»"""

    def __init__(self, error_type: LoadErrorType, message: str, file_path: str = None):
        self.error_type = error_type
        self.message = message
        self.file_path = file_path
        super().__init__(f"{error_type.value}: {message}")

# ä½¿ç”¨ç¤ºä¾‹
try:
    # æ¨¡æ‹ŸåŠ è½½å¤±è´¥
    raise LoadError(
        LoadErrorType.ENCODING_ERROR,
        "æ— æ³•ä½¿ç”¨UTF-8è§£ç ",
        "document.txt"
    )
except LoadError as e:
    print(f"é”™è¯¯ç±»å‹: {e.error_type.value}")
    print(f"é”™è¯¯ä¿¡æ¯: {e.message}")
    print(f"æ–‡ä»¶è·¯å¾„: {e.file_path}")
```

### 2.2 å¥å£®çš„æ–‡æ¡£åŠ è½½å™¨

```python
"""
å¥å£®çš„æ–‡æ¡£åŠ è½½å™¨
åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†
"""

from typing import List, Optional
from langchain.schema import Document
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RobustDocumentLoader:
    """å¥å£®çš„æ–‡æ¡£åŠ è½½å™¨"""

    def __init__(self, max_retries: int = 3, timeout: int = 30):
        self.max_retries = max_retries
        self.timeout = timeout
        self.failed_files = []

    def load_batch(self, file_paths: List[str]) -> tuple[List[Document], List[dict]]:
        """
        æ‰¹é‡åŠ è½½æ–‡æ¡£
        è¿”å›: (æˆåŠŸçš„æ–‡æ¡£, å¤±è´¥çš„æ–‡ä»¶ä¿¡æ¯)
        """
        successful_docs = []

        for file_path in file_paths:
            try:
                doc = self._load_single_file(file_path)
                if doc:
                    successful_docs.append(doc)
                    logger.info(f"âœ… æˆåŠŸåŠ è½½: {file_path}")
            except Exception as e:
                self._handle_error(file_path, e)

        return successful_docs, self.failed_files

    def _load_single_file(self, file_path: str) -> Optional[Document]:
        """åŠ è½½å•ä¸ªæ–‡ä»¶ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(self.max_retries):
            try:
                return self._load_file(file_path)
            except Exception as e:
                if attempt < self.max_retries - 1:
                    logger.warning(f"å°è¯• {attempt + 1}/{self.max_retries} å¤±è´¥: {file_path}")
                    continue
                else:
                    raise

    def _load_file(self, file_path: str) -> Document:
        """å®é™…çš„æ–‡ä»¶åŠ è½½é€»è¾‘"""
        # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            raise LoadError(LoadErrorType.FILE_NOT_FOUND, f"æ–‡ä»¶ä¸å­˜åœ¨", file_path)

        # 2. æ£€æŸ¥æ–‡ä»¶æƒé™
        if not os.access(file_path, os.R_OK):
            raise LoadError(LoadErrorType.PERMISSION_DENIED, f"æ— è¯»å–æƒé™", file_path)

        # 3. æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size == 0:
            raise LoadError(LoadErrorType.CORRUPTED_FILE, f"æ–‡ä»¶ä¸ºç©º", file_path)

        # 4. æ™ºèƒ½è¯»å–æ–‡ä»¶
        reader = SmartFileReader()
        try:
            content, encoding = reader.read(file_path)
        except Exception as e:
            raise LoadError(LoadErrorType.ENCODING_ERROR, str(e), file_path)

        # 5. éªŒè¯å†…å®¹è´¨é‡
        if len(content.strip()) < 10:
            raise LoadError(LoadErrorType.CORRUPTED_FILE, f"å†…å®¹è¿‡çŸ­", file_path)

        # 6. åˆ›å»ºDocument
        return Document(
            page_content=content,
            metadata={
                "source": file_path,
                "encoding": encoding,
                "file_size": file_size
            }
        )

    def _handle_error(self, file_path: str, error: Exception):
        """å¤„ç†é”™è¯¯"""
        error_info = {
            "file_path": file_path,
            "error_type": type(error).__name__,
            "error_message": str(error),
            "timestamp": datetime.now().isoformat()
        }

        self.failed_files.append(error_info)
        logger.error(f"âŒ åŠ è½½å¤±è´¥: {file_path} - {error}")

    def get_failure_report(self) -> str:
        """ç”Ÿæˆå¤±è´¥æŠ¥å‘Š"""
        if not self.failed_files:
            return "æ‰€æœ‰æ–‡ä»¶åŠ è½½æˆåŠŸ"

        report = f"å¤±è´¥æ–‡ä»¶æ•°: {len(self.failed_files)}\n\n"
        for failure in self.failed_files:
            report += f"æ–‡ä»¶: {failure['file_path']}\n"
            report += f"é”™è¯¯ç±»å‹: {failure['error_type']}\n"
            report += f"é”™è¯¯ä¿¡æ¯: {failure['error_message']}\n"
            report += f"æ—¶é—´: {failure['timestamp']}\n\n"

        return report

# ä½¿ç”¨ç¤ºä¾‹
loader = RobustDocumentLoader(max_retries=3)

file_paths = [
    "doc1.txt",
    "doc2.txt",
    "corrupted.txt",  # å‡è®¾è¿™ä¸ªæ–‡ä»¶æŸå
    "missing.txt"     # å‡è®¾è¿™ä¸ªæ–‡ä»¶ä¸å­˜åœ¨
]

docs, failures = loader.load_batch(file_paths)

print(f"\næˆåŠŸåŠ è½½: {len(docs)} ä¸ªæ–‡æ¡£")
print(f"å¤±è´¥: {len(failures)} ä¸ªæ–‡ä»¶")
print("\nå¤±è´¥æŠ¥å‘Š:")
print(loader.get_failure_report())
```

### 2.3 é™çº§ç­–ç•¥

```python
"""
é™çº§ç­–ç•¥ï¼šå½“é«˜çº§è§£æå™¨å¤±è´¥æ—¶ï¼Œé™çº§åˆ°ç®€å•è§£æå™¨
"""

from typing import List, Callable
from langchain.schema import Document

class FallbackLoader:
    """æ”¯æŒé™çº§çš„æ–‡æ¡£åŠ è½½å™¨"""

    def __init__(self):
        # è§£æå™¨ä¼˜å…ˆçº§åˆ—è¡¨ï¼ˆä»é«˜åˆ°ä½ï¼‰
        self.parsers = [
            ("é«˜çº§è§£æå™¨", self._advanced_parser),
            ("æ ‡å‡†è§£æå™¨", self._standard_parser),
            ("ç®€å•è§£æå™¨", self._simple_parser),
            ("æœ€åæ‰‹æ®µ", self._last_resort_parser)
        ]

    def load(self, file_path: str) -> Document:
        """ä½¿ç”¨é™çº§ç­–ç•¥åŠ è½½æ–‡æ¡£"""
        last_error = None

        for parser_name, parser_func in self.parsers:
            try:
                logger.info(f"å°è¯• {parser_name}...")
                doc = parser_func(file_path)
                logger.info(f"âœ… {parser_name} æˆåŠŸ")
                return doc
            except Exception as e:
                logger.warning(f"âŒ {parser_name} å¤±è´¥: {e}")
                last_error = e
                continue

        # æ‰€æœ‰è§£æå™¨éƒ½å¤±è´¥
        raise Exception(f"æ‰€æœ‰è§£æå™¨éƒ½å¤±è´¥: {last_error}")

    def _advanced_parser(self, file_path: str) -> Document:
        """é«˜çº§è§£æå™¨ï¼ˆå¯èƒ½å¤±è´¥ï¼‰"""
        # æ¨¡æ‹Ÿé«˜çº§è§£æé€»è¾‘
        reader = SmartFileReader(confidence_threshold=0.9)
        content, encoding = reader.read(file_path)

        # é«˜çº§å¤„ç†ï¼šæ¸…æ´—ã€æ ¼å¼åŒ–ç­‰
        content = self._advanced_processing(content)

        return Document(
            page_content=content,
            metadata={"source": file_path, "parser": "advanced", "encoding": encoding}
        )

    def _standard_parser(self, file_path: str) -> Document:
        """æ ‡å‡†è§£æå™¨"""
        reader = SmartFileReader(confidence_threshold=0.7)
        content, encoding = reader.read(file_path)

        return Document(
            page_content=content,
            metadata={"source": file_path, "parser": "standard", "encoding": encoding}
        )

    def _simple_parser(self, file_path: str) -> Document:
        """ç®€å•è§£æå™¨"""
        # ç›´æ¥ä½¿ç”¨UTF-8ï¼Œå¿½ç•¥é”™è¯¯
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        return Document(
            page_content=content,
            metadata={"source": file_path, "parser": "simple", "encoding": "utf-8"}
        )

    def _last_resort_parser(self, file_path: str) -> Document:
        """æœ€åæ‰‹æ®µï¼šè¯»å–äºŒè¿›åˆ¶å¹¶å°è¯•è§£ç """
        with open(file_path, 'rb') as f:
            raw_data = f.read()

        # å°è¯•å¤šç§è§£ç æ–¹å¼
        for encoding in ['utf-8', 'gbk', 'iso-8859-1']:
            try:
                content = raw_data.decode(encoding, errors='ignore')
                if len(content.strip()) > 0:
                    return Document(
                        page_content=content,
                        metadata={
                            "source": file_path,
                            "parser": "last_resort",
                            "encoding": encoding
                        }
                    )
            except:
                continue

        raise Exception("æ— æ³•è§£ç æ–‡ä»¶")

    def _advanced_processing(self, content: str) -> str:
        """é«˜çº§å†…å®¹å¤„ç†"""
        # æ¸…ç†å¤šä½™ç©ºç™½
        import re
        content = re.sub(r'\n{3,}', '\n\n', content)
        content = re.sub(r' {2,}', ' ', content)
        return content.strip()

# ä½¿ç”¨ç¤ºä¾‹
loader = FallbackLoader()
doc = loader.load("document.txt")
print(f"ä½¿ç”¨çš„è§£æå™¨: {doc.metadata['parser']}")
```

---

## 3. åœ¨RAGä¸­çš„åº”ç”¨

### 3.1 æ„å»ºå¥å£®çš„çŸ¥è¯†åº“

```python
"""
æ„å»ºå¥å£®çš„RAGçŸ¥è¯†åº“
åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œç¼–ç å¤„ç†
"""

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from datetime import datetime

def build_robust_knowledge_base(
    file_paths: List[str],
    output_dir: str = "./robust_kb"
):
    """æ„å»ºå¥å£®çš„çŸ¥è¯†åº“"""

    # 1. åŠ è½½æ–‡æ¡£ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
    print("=== 1. åŠ è½½æ–‡æ¡£ ===")
    loader = RobustDocumentLoader(max_retries=3)
    documents, failures = loader.load_batch(file_paths)

    print(f"æˆåŠŸåŠ è½½: {len(documents)} ä¸ªæ–‡æ¡£")
    print(f"å¤±è´¥: {len(failures)} ä¸ªæ–‡ä»¶")

    if not documents:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£")
        return

    # 2. åˆ†å—
    print("\n=== 2. æ–‡æœ¬åˆ†å— ===")
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    chunks = splitter.split_documents(documents)
    print(f"åˆ†å—åå¾—åˆ°: {len(chunks)} ä¸ªæ–‡æœ¬å—")

    # 3. å‘é‡åŒ–å¹¶å­˜å‚¨
    print("\n=== 3. å‘é‡åŒ–å¹¶å­˜å‚¨ ===")
    try:
        embeddings = OpenAIEmbeddings()
        vectorstore = Chroma.from_documents(
            chunks,
            embeddings,
            persist_directory=output_dir
        )
        print(f"âœ… çŸ¥è¯†åº“æ„å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")
        return

    # 4. ç”ŸæˆæŠ¥å‘Š
    print("\n=== 4. ç”ŸæˆæŠ¥å‘Š ===")
    report = {
        "timestamp": datetime.now().isoformat(),
        "total_files": len(file_paths),
        "successful_files": len(documents),
        "failed_files": len(failures),
        "total_chunks": len(chunks),
        "failures": failures
    }

    # ä¿å­˜æŠ¥å‘Š
    import json
    with open(f"{output_dir}/build_report.json", 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir}/build_report.json")

    # 5. æ˜¾ç¤ºå¤±è´¥æ–‡ä»¶
    if failures:
        print("\n=== å¤±è´¥æ–‡ä»¶åˆ—è¡¨ ===")
        print(loader.get_failure_report())

# ä½¿ç”¨ç¤ºä¾‹
file_paths = [
    "docs/report1.txt",
    "docs/report2.txt",
    "docs/report3.txt"
]

build_robust_knowledge_base(file_paths)
```

### 3.2 ç›‘æ§å’Œå‘Šè­¦

```python
"""
æ–‡æ¡£åŠ è½½ç›‘æ§å’Œå‘Šè­¦
"""

class LoadingMonitor:
    """åŠ è½½ç›‘æ§å™¨"""

    def __init__(self, failure_threshold: float = 0.2):
        self.failure_threshold = failure_threshold
        self.stats = {
            "total": 0,
            "success": 0,
            "failure": 0,
            "encoding_errors": 0,
            "format_errors": 0,
            "other_errors": 0
        }

    def record_success(self):
        """è®°å½•æˆåŠŸ"""
        self.stats["total"] += 1
        self.stats["success"] += 1

    def record_failure(self, error_type: LoadErrorType):
        """è®°å½•å¤±è´¥"""
        self.stats["total"] += 1
        self.stats["failure"] += 1

        if error_type == LoadErrorType.ENCODING_ERROR:
            self.stats["encoding_errors"] += 1
        elif error_type == LoadErrorType.FORMAT_ERROR:
            self.stats["format_errors"] += 1
        else:
            self.stats["other_errors"] += 1

    def get_failure_rate(self) -> float:
        """è·å–å¤±è´¥ç‡"""
        if self.stats["total"] == 0:
            return 0.0
        return self.stats["failure"] / self.stats["total"]

    def should_alert(self) -> bool:
        """æ˜¯å¦åº”è¯¥å‘Šè­¦"""
        return self.get_failure_rate() > self.failure_threshold

    def get_report(self) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        failure_rate = self.get_failure_rate()

        report = f"""
=== åŠ è½½ç›‘æ§æŠ¥å‘Š ===
æ€»æ–‡ä»¶æ•°: {self.stats['total']}
æˆåŠŸ: {self.stats['success']} ({self.stats['success']/self.stats['total']*100:.1f}%)
å¤±è´¥: {self.stats['failure']} ({failure_rate*100:.1f}%)

å¤±è´¥ç±»å‹åˆ†å¸ƒ:
- ç¼–ç é”™è¯¯: {self.stats['encoding_errors']}
- æ ¼å¼é”™è¯¯: {self.stats['format_errors']}
- å…¶ä»–é”™è¯¯: {self.stats['other_errors']}

å‘Šè­¦çŠ¶æ€: {'ğŸš¨ éœ€è¦å…³æ³¨' if self.should_alert() else 'âœ… æ­£å¸¸'}
"""
        return report

# ä½¿ç”¨ç¤ºä¾‹
monitor = LoadingMonitor(failure_threshold=0.2)

# æ¨¡æ‹ŸåŠ è½½è¿‡ç¨‹
for i in range(100):
    if i % 10 == 0:  # 10%å¤±è´¥ç‡
        monitor.record_failure(LoadErrorType.ENCODING_ERROR)
    else:
        monitor.record_success()

print(monitor.get_report())
```

---

## æ€»ç»“

**ç¼–ç ä¸é”™è¯¯å¤„ç†çš„æ ¸å¿ƒè¦ç‚¹ï¼š**

1. **ç¼–ç æ£€æµ‹**: ä½¿ç”¨chardetè‡ªåŠ¨æ£€æµ‹ï¼Œé…åˆå›é€€ç­–ç•¥
2. **é”™è¯¯åˆ†ç±»**: æ˜ç¡®åŒºåˆ†ä¸åŒç±»å‹çš„é”™è¯¯
3. **é™çº§ç­–ç•¥**: é«˜çº§è§£æå™¨å¤±è´¥æ—¶é™çº§åˆ°ç®€å•è§£æå™¨
4. **é‡è¯•æœºåˆ¶**: å¯¹ä¸´æ—¶æ€§é”™è¯¯è¿›è¡Œé‡è¯•
5. **ç›‘æ§å‘Šè­¦**: è·Ÿè¸ªå¤±è´¥ç‡ï¼ŒåŠæ—¶å‘ç°é—®é¢˜

**åœ¨RAGä¸­çš„æœ€ä½³å®è·µ:**
- æ‰¹é‡åŠ è½½æ—¶ä¸è¦å› ä¸ªåˆ«æ–‡ä»¶å¤±è´¥è€Œä¸­æ–­
- è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ä¾¿äºåç»­åˆ†æ
- æä¾›å¤±è´¥æ–‡ä»¶çš„æŠ¥å‘Šå’Œç»Ÿè®¡
- è®¾ç½®å¤±è´¥ç‡é˜ˆå€¼è¿›è¡Œå‘Šè­¦

---

## å‚è€ƒæ¥æº

> **å‚è€ƒæ¥æºï¼š**
> - [chardet Documentation](https://chardet.readthedocs.io/) - ç¼–ç æ£€æµ‹ (2025)
> - [Python Unicode HOWTO](https://docs.python.org/3/howto/unicode.html) - Unicodeå¤„ç† (2025)
> - [Error Handling Best Practices](https://realpython.com/python-exceptions/) (2025)

---

**ç‰ˆæœ¬ï¼š** v1.0
**æœ€åæ›´æ–°ï¼š** 2026-02-15
**ä¸‹ä¸€æ­¥ï¼š** é˜…è¯»å®æˆ˜ä»£ç  [07_å®æˆ˜ä»£ç _01_åŸºç¡€PDFåŠ è½½.md](./07_å®æˆ˜ä»£ç _01_åŸºç¡€PDFåŠ è½½.md)
