# 实战代码 03: 对话历史管理

> **本文目标**: 掌握对话历史的管理技巧和最佳实践

---

## 概述

对话历史管理是构建有记忆的聊天应用的核心。本文提供完整的代码示例，涵盖历史管理的各种场景。

---

## 1. 基础历史管理

### 1.1 简单历史追加

```python
"""
示例1: 简单的历史管理
演示：手动管理对话历史
"""
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

load_dotenv()

# ===== 1. 初始化 =====
model = ChatOpenAI(model="gpt-4o-mini")
history = []

# ===== 2. 第一轮对话 =====
print("=== 第一轮 ===")
messages = [
    SystemMessage(content="你是助手"),
    *history,
    HumanMessage(content="我叫张三")
]

response = model.invoke(messages)
print(f"用户: 我叫张三")
print(f"AI: {response.content}\n")

# 更新历史
history.append(HumanMessage(content="我叫张三"))
history.append(response)

# ===== 3. 第二轮对话 =====
print("=== 第二轮 ===")
messages = [
    SystemMessage(content="你是助手"),
    *history,
    HumanMessage(content="我喜欢Python")
]

response = model.invoke(messages)
print(f"用户: 我喜欢Python")
print(f"AI: {response.content}\n")

# 更新历史
history.append(HumanMessage(content="我喜欢Python"))
history.append(response)

# ===== 4. 第三轮对话（测试记忆）=====
print("=== 第三轮（测试记忆）===")
messages = [
    SystemMessage(content="你是助手"),
    *history,
    HumanMessage(content="我叫什么名字？我喜欢什么？")
]

response = model.invoke(messages)
print(f"用户: 我叫什么名字？我喜欢什么？")
print(f"AI: {response.content}\n")

print(f"历史消息数: {len(history)}")
```

### 1.2 使用 MessagesPlaceholder

```python
"""
示例2: 使用 MessagesPlaceholder 管理历史
演示：更优雅的历史管理方式
"""
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

load_dotenv()

# ===== 1. 创建模板 =====
template = ChatPromptTemplate.from_messages([
    ("system", "你是助手"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}")
])

model = ChatOpenAI(model="gpt-4o-mini")
chain = template | model

# ===== 2. 对话循环 =====
history = []

questions = [
    "我叫李四",
    "我在学习LangChain",
    "我叫什么名字？我在学什么？"
]

for q in questions:
    print(f"用户: {q}")

    response = chain.invoke({
        "history": history,
        "question": q
    })

    print(f"AI: {response.content}\n")

    # 更新历史
    history.append(HumanMessage(content=q))
    history.append(response)

print(f"最终历史消息数: {len(history)}")
```

---

## 2. 历史长度限制

### 2.1 固定长度限制

```python
"""
示例3: 限制历史长度
演示：避免历史无限增长
"""
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

load_dotenv()

class ChatWithLimitedHistory:
    """带历史长度限制的聊天"""

    def __init__(self, max_history: int = 10):
        self.model = ChatOpenAI(model="gpt-4o-mini")
        self.template = ChatPromptTemplate.from_messages([
            ("system", "你是助手"),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}")
        ])
        self.chain = self.template | self.model
        self.history = []
        self.max_history = max_history

    def chat(self, question: str) -> str:
        """发送消息"""
        # 限制历史长度（保留最近的N条）
        limited_history = self.history[-self.max_history:]

        response = self.chain.invoke({
            "history": limited_history,
            "question": question
        })

        # 更新完整历史
        self.history.append(HumanMessage(content=question))
        self.history.append(response)

        return response.content

# ===== 使用示例 =====
chat = ChatWithLimitedHistory(max_history=4)  # 只保留最近4条

print("=== 测试历史限制 ===\n")

# 发送多条消息
for i in range(6):
    response = chat.chat(f"这是第{i+1}条消息")
    print(f"第{i+1}轮: {response[:50]}...")

print(f"\n完整历史: {len(chat.history)} 条")
print(f"实际使用: 最近 {chat.max_history} 条")
```

### 2.2 Token 限制

```python
"""
示例4: 基于 Token 的历史限制
演示：根据 Token 数量限制历史
"""
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

load_dotenv()

def estimate_tokens(text: str) -> int:
    """估算 token 数量"""
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    other_chars = len(text) - chinese_chars
    return int(chinese_chars / 1.5 + other_chars / 4)

class TokenLimitedChat:
    """基于 Token 限制的聊天"""

    def __init__(self, max_tokens: int = 1000):
        self.model = ChatOpenAI(model="gpt-4o-mini")
        self.template = ChatPromptTemplate.from_messages([
            ("system", "你是助手"),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}")
        ])
        self.chain = self.template | self.model
        self.history = []
        self.max_tokens = max_tokens

    def get_limited_history(self):
        """获取符合 token 限制的历史"""
        total_tokens = 0
        limited_history = []

        # 从最新的消息开始倒序遍历
        for msg in reversed(self.history):
            msg_tokens = estimate_tokens(msg.content)
            if total_tokens + msg_tokens > self.max_tokens:
                break
            limited_history.insert(0, msg)
            total_tokens += msg_tokens

        return limited_history, total_tokens

    def chat(self, question: str) -> str:
        """发送消息"""
        limited_history, used_tokens = self.get_limited_history()

        response = self.chain.invoke({
            "history": limited_history,
            "question": question
        })

        self.history.append(HumanMessage(content=question))
        self.history.append(response)

        print(f"[使用 {used_tokens}/{self.max_tokens} tokens, {len(limited_history)}/{len(self.history)} 条消息]")

        return response.content

# ===== 使用示例 =====
chat = TokenLimitedChat(max_tokens=200)

print("=== 基于 Token 的历史限制 ===\n")

questions = [
    "介绍一下Python",
    "它有什么特点？",
    "适合什么场景？",
    "和Java比呢？"
]

for q in questions:
    print(f"用户: {q}")
    response = chat.chat(q)
    print(f"AI: {response[:50]}...\n")
```

---

## 3. 历史总结

### 3.1 定期总结历史

```python
"""
示例5: 历史总结
演示：定期总结历史以节省 tokens
"""
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, SystemMessage

load_dotenv()

class SummarizedChat:
    """带历史总结的聊天"""

    def __init__(self, summarize_threshold: int = 6):
        self.model = ChatOpenAI(model="gpt-4o-mini")
        self.template = ChatPromptTemplate.from_messages([
            ("system", "你是助手"),
            MessagesPlaceholder(variable_name="summary", optional=True),
            MessagesPlaceholder(variable_name="recent_history"),
            ("human", "{question}")
        ])
        self.chain = self.template | self.model
        self.recent_history = []
        self.summary = None
        self.summarize_threshold = summarize_threshold

    def summarize_history(self):
        """总结历史"""
        if len(self.recent_history) < self.summarize_threshold:
            return

        print("[正在总结历史...]")

        # 构建总结提示
        history_text = "\n".join([
            f"{msg.type}: {msg.content}"
            for msg in self.recent_history
        ])

        summary_prompt = f"""请总结以下对话的关键信息：

{history_text}

总结要点：
- 用户的基本信息
- 讨论的主要话题
- 重要的上下文信息

总结："""

        summary_response = self.model.invoke([
            HumanMessage(content=summary_prompt)
        ])

        # 更新总结
        if self.summary:
            self.summary = [SystemMessage(
                content=f"之前的对话总结：{self.summary[0].content}\n\n最新总结：{summary_response.content}"
            )]
        else:
            self.summary = [SystemMessage(
                content=f"对话总结：{summary_response.content}"
            )]

        # 清空最近历史
        self.recent_history = []

        print(f"[总结完成，历史已清空]\n")

    def chat(self, question: str) -> str:
        """发送消息"""
        response = self.chain.invoke({
            "summary": self.summary,
            "recent_history": self.recent_history,
            "question": question
        })

        self.recent_history.append(HumanMessage(content=question))
        self.recent_history.append(response)

        # 检查是否需要总结
        if len(self.recent_history) >= self.summarize_threshold:
            self.summarize_history()

        return response.content

# ===== 使用示例 =====
chat = SummarizedChat(summarize_threshold=4)

print("=== 带历史总结的聊天 ===\n")

questions = [
    "我叫王五",
    "我在学习AI",
    "我喜欢Python",
    "我在做RAG项目",  # 触发总结
    "我叫什么名字？",
    "我在做什么？"
]

for q in questions:
    print(f"用户: {q}")
    response = chat.chat(q)
    print(f"AI: {response}\n")
```

---

## 4. 完整的对话管理器

### 4.1 生产级对话管理器

```python
"""
示例6: 生产级对话管理器
演示：完整的对话历史管理解决方案
"""
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from typing import List, Optional
from datetime import datetime

load_dotenv()

class ConversationManager:
    """生产级对话管理器"""

    def __init__(
        self,
        system_message: str = "你是助手",
        max_history: int = 20,
        max_tokens: int = 2000,
        enable_summary: bool = True,
        summary_threshold: int = 10
    ):
        self.model = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
        self.system_message = system_message
        self.max_history = max_history
        self.max_tokens = max_tokens
        self.enable_summary = enable_summary
        self.summary_threshold = summary_threshold

        # 历史和总结
        self.history: List = []
        self.summary: Optional[str] = None

        # 创建模板
        self.template = ChatPromptTemplate.from_messages([
            ("system", "{system_message}"),
            MessagesPlaceholder(variable_name="summary", optional=True),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}")
        ])

        self.chain = self.template | self.model

    def estimate_tokens(self, text: str) -> int:
        """估算 token 数量"""
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        other_chars = len(text) - chinese_chars
        return int(chinese_chars / 1.5 + other_chars / 4)

    def get_limited_history(self) -> List:
        """获取符合限制的历史"""
        # 1. 数量限制
        history = self.history[-self.max_history:]

        # 2. Token 限制
        total_tokens = 0
        limited_history = []

        for msg in reversed(history):
            msg_tokens = self.estimate_tokens(msg.content)
            if total_tokens + msg_tokens > self.max_tokens:
                break
            limited_history.insert(0, msg)
            total_tokens += msg_tokens

        return limited_history

    def summarize_history(self):
        """总结历史"""
        if not self.enable_summary or len(self.history) < self.summary_threshold:
            return

        # 构建总结提示
        history_text = "\n".join([
            f"{msg.type}: {msg.content}"
            for msg in self.history
        ])

        summary_prompt = f"""请简洁总结以下对话的关键信息（不超过100字）：

{history_text}

总结："""

        summary_response = self.model.invoke([
            HumanMessage(content=summary_prompt)
        ])

        self.summary = summary_response.content
        self.history = []  # 清空历史

    def chat(self, question: str) -> dict:
        """
        发送消息

        Returns:
            dict: {
                "answer": str,
                "history_count": int,
                "summary": Optional[str]
            }
        """
        # 获取限制后的历史
        limited_history = self.get_limited_history()

        # 准备总结消息
        summary_messages = []
        if self.summary:
            summary_messages = [SystemMessage(content=f"对话总结：{self.summary}")]

        # 调用模型
        response = self.chain.invoke({
            "system_message": self.system_message,
            "summary": summary_messages,
            "history": limited_history,
            "question": question
        })

        # 更新历史
        self.history.append(HumanMessage(content=question))
        self.history.append(response)

        # 检查是否需要总结
        if self.enable_summary and len(self.history) >= self.summary_threshold:
            self.summarize_history()

        return {
            "answer": response.content,
            "history_count": len(self.history),
            "summary": self.summary
        }

    def clear(self):
        """清空历史和总结"""
        self.history = []
        self.summary = None

    def get_stats(self) -> dict:
        """获取统计信息"""
        total_tokens = sum(
            self.estimate_tokens(msg.content)
            for msg in self.history
        )

        return {
            "history_count": len(self.history),
            "total_tokens": total_tokens,
            "has_summary": self.summary is not None,
            "summary_length": len(self.summary) if self.summary else 0
        }

# ===== 使用示例 =====
print("=== 生产级对话管理器 ===\n")

manager = ConversationManager(
    system_message="你是专业的Python助手",
    max_history=10,
    max_tokens=500,
    enable_summary=True,
    summary_threshold=6
)

# 模拟对话
questions = [
    "我叫赵六",
    "我在学习LangChain",
    "我想构建一个RAG应用",
    "需要用到哪些组件？",
    "如何管理对话历史？",
    "有什么最佳实践？",  # 触发总结
    "我叫什么名字？",  # 测试总结后的记忆
    "我在做什么项目？"
]

for i, q in enumerate(questions, 1):
    print(f"=== 第{i}轮 ===")
    print(f"用户: {q}")

    result = manager.chat(q)

    print(f"AI: {result['answer']}")

    stats = manager.get_stats()
    print(f"[历史: {stats['history_count']}条, Tokens: {stats['total_tokens']}, 总结: {'是' if stats['has_summary'] else '否'}]")
    print()
```

---

## 5. 持久化历史

### 5.1 文件持久化

```python
"""
示例7: 历史持久化
演示：将历史保存到文件
"""
import json
from pathlib import Path
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, messages_from_dict, messages_to_dict

load_dotenv()

class PersistentChat:
    """带持久化的聊天"""

    def __init__(self, session_id: str, storage_dir: str = "./chat_sessions"):
        self.session_id = session_id
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        self.session_file = self.storage_dir / f"{session_id}.json"

        self.model = ChatOpenAI(model="gpt-4o-mini")
        self.template = ChatPromptTemplate.from_messages([
            ("system", "你是助手"),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}")
        ])
        self.chain = self.template | self.model

        # 加载历史
        self.history = self.load_history()

    def load_history(self) -> list:
        """从文件加载历史"""
        if not self.session_file.exists():
            return []

        with open(self.session_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return messages_from_dict(data)

    def save_history(self):
        """保存历史到文件"""
        data = messages_to_dict(self.history)
        with open(self.session_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def chat(self, question: str) -> str:
        """发送消息"""
        response = self.chain.invoke({
            "history": self.history,
            "question": question
        })

        self.history.append(HumanMessage(content=question))
        self.history.append(response)

        # 保存历史
        self.save_history()

        return response.content

    def clear(self):
        """清空历史"""
        self.history = []
        if self.session_file.exists():
            self.session_file.unlink()

# ===== 使用示例 =====
print("=== 持久化聊天 ===\n")

# 会话1
print("--- 会话1 ---")
chat1 = PersistentChat(session_id="user_123")
print(f"用户: 我叫孙七")
print(f"AI: {chat1.chat('我叫孙七')}\n")

print(f"用户: 我喜欢Python")
print(f"AI: {chat1.chat('我喜欢Python')}\n")

print(f"历史已保存到: {chat1.session_file}")
print(f"历史消息数: {len(chat1.history)}\n")

# 会话2（加载之前的历史）
print("--- 会话2（重新加载）---")
chat2 = PersistentChat(session_id="user_123")
print(f"加载的历史消息数: {len(chat2.history)}")

print(f"用户: 我叫什么名字？我喜欢什么？")
print(f"AI: {chat2.chat('我叫什么名字？我喜欢什么？')}")
```

---

## 6. 最佳实践总结

### 6.1 推荐做法

```python
"""
最佳实践示例
"""

# ✅ 1. 限制历史长度
MAX_HISTORY = 20
history = history[-MAX_HISTORY:]

# ✅ 2. 基于 Token 限制
def get_limited_history(history, max_tokens=2000):
    total_tokens = 0
    limited = []
    for msg in reversed(history):
        tokens = estimate_tokens(msg.content)
        if total_tokens + tokens > max_tokens:
            break
        limited.insert(0, msg)
        total_tokens += tokens
    return limited

# ✅ 3. 定期总结
if len(history) >= SUMMARY_THRESHOLD:
    summary = summarize_history(history)
    history = []

# ✅ 4. 持久化重要会话
save_history(session_id, history)

# ✅ 5. 使用 MessagesPlaceholder
template = ChatPromptTemplate.from_messages([
    ("system", "你是助手"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}")
])
```

### 6.2 避免的做法

```python
# ❌ 1. 历史无限增长
history.append(message)  # 最终超过 context window

# ❌ 2. 不考虑 Token 限制
# 只按数量限制，不考虑实际 token 使用

# ❌ 3. 硬编码历史
template = ChatPromptTemplate.from_messages([
    ("system", "你是助手"),
    ("human", "历史问题1"),
    ("ai", "历史回答1"),
    ("human", "{question}")
])  # 不灵活

# ❌ 4. 不持久化
# 用户刷新页面后丢失所有历史

# ❌ 5. 不清理旧会话
# 磁盘空间无限增长
```

---

## 检查清单

完成本节实战后，你应该能够：

- [ ] 手动管理对话历史
- [ ] 使用 MessagesPlaceholder 管理历史
- [ ] 实现固定长度限制
- [ ] 实现基于 Token 的限制
- [ ] 实现历史总结
- [ ] 构建生产级对话管理器
- [ ] 实现历史持久化
- [ ] 应用最佳实践

---

**下一步**: 阅读 `07_实战代码_04_结构化输出.md` 学习结构化输出的实现
