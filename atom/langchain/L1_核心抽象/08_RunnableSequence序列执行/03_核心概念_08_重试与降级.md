# 核心概念8：重试与降级

> 理解 with_retry 和 with_fallbacks 的实现机制

---

## 重试与降级的本质

**一句话**：重试解决临时性错误，降级解决永久性错误。

```python
# 重试：临时性错误（网络抖动、API 限流）
chain_with_retry = chain.with_retry(stop_after_attempt=3)

# 降级：永久性错误（模型不可用、成本过高）
chain_with_fallback = main_chain.with_fallbacks([fallback_chain])
```

---

## 为什么需要重试与降级

### 问题：生产环境不稳定

```python
# 没有错误处理的链
chain = prompt | llm | parser

# 生产环境中可能遇到的错误
try:
    result = chain.invoke(input)
except RateLimitError:
    # API 限流
    pass
except APIConnectionError:
    # 网络错误
    pass
except ModelNotFoundError:
    # 模型不可用
    pass
```

**痛点**：
- 临时性错误导致失败（网络抖动）
- 永久性错误无法恢复（模型下线）
- 用户体验差（频繁失败）
- 稳定性低（无容错机制）

### 解决方案：重试 + 降级

```python
# 生产级错误处理
production_chain = (
    chain
    .with_retry(stop_after_attempt=3)      # 重试临时性错误
    .with_fallbacks([fallback_chain])      # 降级永久性错误
)

# 稳定性提升到 99.9%
result = production_chain.invoke(input)
```

---

## 重试机制：with_retry

### 基础用法

**来源**：LangChain 官方文档

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("解释：{topic}")
llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

base_chain = prompt | llm | parser

# 添加重试逻辑
chain_with_retry = base_chain.with_retry(
    stop_after_attempt=3,           # 最多重试3次
    wait_exponential_jitter=True,   # 指数退避 + 随机抖动
    retry_if_exception_type=(       # 只重试特定错误
        RateLimitError,
        APIConnectionError
    )
)

# 使用
result = chain_with_retry.invoke({"topic": "AI"})
# 如果失败，自动重试最多3次
```

### 重试策略

**来源**：Medium - 7 Retry & Timeout Policies

| 策略 | 说明 | 示例 |
|------|------|------|
| **固定等待** | 每次重试等待固定时间 | 1s → 1s → 1s |
| **线性退避** | 等待时间线性增加 | 1s → 2s → 3s |
| **指数退避** | 等待时间指数增加 | 1s → 2s → 4s |
| **指数退避+抖动** | 指数退避+随机抖动 | 1s → 2.3s → 4.7s |

**推荐**：指数退避 + 随机抖动

```python
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True  # 推荐
)
```

**为什么使用指数退避 + 抖动？**
- 避免雪崩效应：如果服务过载，固定重试会加剧问题
- 给服务恢复时间：等待时间逐渐增加
- 随机抖动：避免多个客户端同时重试

### 选择性重试

```python
from openai import RateLimitError, APIConnectionError, AuthenticationError

# ✅ 只重试临时性错误
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,
    retry_if_exception_type=(
        RateLimitError,        # API 限流（临时）
        APIConnectionError,    # 网络错误（临时）
        TimeoutError          # 超时（临时）
    )
)

# ❌ 不要重试永久性错误
# AuthenticationError（认证失败）
# ValidationError（输入错误）
# ModelNotFoundError（模型不存在）
```

---

## 降级机制：with_fallbacks

### 基础用法

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("解释：{topic}")
parser = StrOutputParser()

# 主链：使用 GPT-4
main_llm = ChatOpenAI(model="gpt-4")
main_chain = prompt | main_llm | parser

# 备用链：使用 GPT-3.5
fallback_llm = ChatOpenAI(model="gpt-3.5-turbo")
fallback_chain = prompt | fallback_llm | parser

# 组合：主链失败时自动切换
chain_with_fallback = main_chain.with_fallbacks([fallback_chain])

# 使用
result = chain_with_fallback.invoke({"topic": "AI"})
# 如果主链失败，自动切换到备用链
```

### 多层降级

```python
# 多层降级：性能 → 成本 → 可用性
main_chain = prompt | ChatOpenAI(model="gpt-4") | parser
fallback1 = prompt | ChatOpenAI(model="gpt-3.5-turbo") | parser
fallback2 = prompt | ChatOpenAI(base_url="http://localhost:8000") | parser

production_chain = main_chain.with_fallbacks([fallback1, fallback2])

# 执行流程：
# 1. 尝试 GPT-4
# 2. 如果失败，尝试 GPT-3.5
# 3. 如果仍失败，尝试本地模型
# 4. 如果都失败，抛出异常
```

### 降级策略

| 策略 | 说明 | 示例 |
|------|------|------|
| **性能降级** | 从高性能模型降级到低性能模型 | GPT-4 → GPT-3.5 |
| **成本降级** | 从昂贵模型降级到便宜模型 | GPT-4 → GPT-3.5-turbo |
| **可用性降级** | 从云端模型降级到本地模型 | OpenAI → 本地模型 |
| **功能降级** | 从复杂功能降级到简单功能 | RAG → 简单问答 |

---

## 手写重试与降级实现

### 版本1：简单重试

```python
import time
from typing import Any, Callable

def simple_retry(
    func: Callable,
    input: Any,
    max_retries: int = 3,
    wait_time: float = 1.0
) -> Any:
    """简单的重试实现"""
    last_exception = None

    for attempt in range(max_retries + 1):
        try:
            print(f"尝试 {attempt + 1}/{max_retries + 1}")
            result = func(input)
            print(f"成功！")
            return result
        except Exception as e:
            last_exception = e
            print(f"失败: {e}")

            if attempt < max_retries:
                print(f"等待 {wait_time} 秒后重试...")
                time.sleep(wait_time)
            else:
                print(f"达到最大重试次数，放弃")

    raise last_exception


# 测试
attempt_count = 0

def flaky_function(x):
    """不稳定的函数，前2次失败，第3次成功"""
    global attempt_count
    attempt_count += 1

    if attempt_count < 3:
        raise ValueError(f"临时错误（第{attempt_count}次）")

    return x * 2


result = simple_retry(flaky_function, 10, max_retries=3)
print(f"最终结果: {result}")
```

### 版本2：指数退避

```python
import time
import random

def exponential_backoff_retry(
    func: Callable,
    input: Any,
    max_retries: int = 3,
    base_wait: float = 1.0,
    jitter: bool = True
) -> Any:
    """指数退避重试"""
    last_exception = None

    for attempt in range(max_retries + 1):
        try:
            return func(input)
        except Exception as e:
            last_exception = e

            if attempt < max_retries:
                # 指数退避：1s → 2s → 4s
                wait_time = base_wait * (2 ** attempt)

                # 添加随机抖动
                if jitter:
                    wait_time *= (0.5 + random.random())

                print(f"等待 {wait_time:.2f} 秒后重试...")
                time.sleep(wait_time)

    raise last_exception
```

### 版本3：选择性重试

```python
from typing import Tuple, Type

def selective_retry(
    func: Callable,
    input: Any,
    max_retries: int = 3,
    retry_exceptions: Tuple[Type[Exception], ...] = (Exception,)
) -> Any:
    """选择性重试：只重试特定错误"""
    last_exception = None

    for attempt in range(max_retries + 1):
        try:
            return func(input)
        except retry_exceptions as e:
            # 可重试的错误
            last_exception = e
            print(f"可重试错误: {e}")

            if attempt < max_retries:
                time.sleep(2 ** attempt)
        except Exception as e:
            # 不可重试的错误，立即抛出
            print(f"不可重试错误: {e}")
            raise

    raise last_exception


# 使用
class TemporaryError(Exception):
    pass

class PermanentError(Exception):
    pass

def selective_function(x):
    import random
    if random.random() < 0.5:
        raise TemporaryError("临时错误")
    elif random.random() < 0.7:
        raise PermanentError("永久错误")
    return x * 2

try:
    result = selective_retry(
        selective_function,
        10,
        max_retries=3,
        retry_exceptions=(TemporaryError,)  # 只重试临时错误
    )
except PermanentError:
    print("永久错误，不重试")
```

### 版本4：降级实现

```python
from typing import List, Callable

def fallback_invoke(
    main_func: Callable,
    fallback_funcs: List[Callable],
    input: Any
) -> Any:
    """降级实现"""
    # 尝试主函数
    try:
        print("尝试主函数...")
        result = main_func(input)
        print("主函数成功！")
        return result
    except Exception as e:
        print(f"主函数失败: {e}")

    # 尝试备用函数
    for i, fallback_func in enumerate(fallback_funcs, 1):
        try:
            print(f"尝试备用函数 {i}...")
            result = fallback_func(input)
            print(f"备用函数 {i} 成功！")
            return result
        except Exception as e:
            print(f"备用函数 {i} 失败: {e}")

    # 所有函数都失败
    raise RuntimeError("所有函数都失败")


# 测试
def main_func(x):
    raise ValueError("主函数不可用")

def fallback1(x):
    raise ValueError("备用函数1不可用")

def fallback2(x):
    return x * 2

result = fallback_invoke(main_func, [fallback1, fallback2], 10)
print(f"最终结果: {result}")
```

### 版本5：组合重试和降级

```python
def production_invoke(
    main_func: Callable,
    fallback_funcs: List[Callable],
    input: Any,
    max_retries: int = 3
) -> Any:
    """生产级实现：重试 + 降级"""

    def invoke_with_retry(func: Callable, input: Any) -> Any:
        """执行函数，支持重试"""
        for attempt in range(max_retries + 1):
            try:
                return func(input)
            except Exception as e:
                if attempt < max_retries:
                    time.sleep(2 ** attempt)
                else:
                    raise

    # 尝试主函数（带重试）
    try:
        print("尝试主函数（带重试）...")
        result = invoke_with_retry(main_func, input)
        print("主函数成功！")
        return result
    except Exception as e:
        print(f"主函数失败（重试后）: {e}")

    # 尝试备用函数（带重试）
    for i, fallback_func in enumerate(fallback_funcs, 1):
        try:
            print(f"尝试备用函数 {i}（带重试）...")
            result = invoke_with_retry(fallback_func, input)
            print(f"备用函数 {i} 成功！")
            return result
        except Exception as e:
            print(f"备用函数 {i} 失败（重试后）: {e}")

    raise RuntimeError("所有函数都失败")
```

---

## 2025-2026 最佳实践

### 1. 错误分类

**来源**：Medium - 7 Retry & Timeout Policies

| 错误类型 | 是否重试 | 是否降级 | 处理策略 |
|---------|---------|---------|----------|
| `RateLimitError` | ✅ | ❌ | 重试 + 指数退避 |
| `APIConnectionError` | ✅ | ❌ | 重试 |
| `TimeoutError` | ✅ | ❌ | 重试 + 增加超时 |
| `AuthenticationError` | ❌ | ❌ | 立即失败，检查配置 |
| `ValidationError` | ❌ | ❌ | 立即失败，修复输入 |
| `ModelNotFoundError` | ❌ | ✅ | 降级到其他模型 |
| `InsufficientQuotaError` | ❌ | ✅ | 降级到便宜模型 |

### 2. 重试配置

```python
# ✅ 推荐配置
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,           # 最多重试3次
    wait_exponential_jitter=True,   # 指数退避 + 抖动
    retry_if_exception_type=(       # 只重试临时性错误
        RateLimitError,
        APIConnectionError,
        TimeoutError
    )
)
```

### 3. 降级配置

```python
# ✅ 多层降级
main_chain = prompt | ChatOpenAI(model="gpt-4") | parser
fallback1 = prompt | ChatOpenAI(model="gpt-3.5-turbo") | parser
fallback2 = prompt | ChatOpenAI(base_url="http://localhost:8000") | parser

production_chain = main_chain.with_fallbacks([fallback1, fallback2])
```

### 4. 组合使用

```python
# ✅ 生产级配置：重试 + 降级
production_chain = (
    base_chain
    .with_retry(
        stop_after_attempt=3,
        wait_exponential_jitter=True,
        retry_if_exception_type=(RateLimitError, APIConnectionError)
    )
    .with_fallbacks([fallback_chain])
    .with_config({
        "run_name": "production",
        "timeout": 30
    })
)
```

### 5. 可观测性

```python
import os

# 集成 LangSmith
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = "your_key"

# 自动追踪所有重试和降级
result = production_chain.invoke(input)
# 在 LangSmith 控制台查看：
# - 重试次数
# - 降级路径
# - 错误详情
```

---

## 实战场景

### 场景1：RAG 链的容错

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 构建 RAG 链
vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

prompt = ChatPromptTemplate.from_template("""
上下文：{context}
问题：{question}
答案：
""")

# 主 LLM
main_llm = ChatOpenAI(model="gpt-4o-mini")

# 备用 LLM
fallback_llm = ChatOpenAI(model="gpt-3.5-turbo")

parser = StrOutputParser()

# 构建链
base_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | main_llm
    | parser
)

# 添加容错
production_chain = (
    base_chain
    .with_retry(
        stop_after_attempt=3,
        wait_exponential_jitter=True,
        retry_if_exception_type=(RateLimitError, APIConnectionError)
    )
    .with_fallbacks([
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | fallback_llm
        | parser
    ])
)

# 使用
try:
    answer = production_chain.invoke("什么是向量数据库？")
    print(answer)
except Exception as e:
    print(f"所有尝试都失败: {e}")
```

### 场景2：批量处理的容错

```python
def safe_batch_with_retry(chain, inputs):
    """安全的批量处理，带重试和降级"""
    results = []
    errors = []

    for i, input in enumerate(inputs):
        try:
            # 每个输入都有重试和降级
            result = chain.invoke(input)
            results.append({
                "index": i,
                "success": True,
                "result": result
            })
        except Exception as e:
            results.append({
                "index": i,
                "success": False,
                "error": str(e)
            })
            errors.append({
                "index": i,
                "input": input,
                "error": e
            })

    return results, errors


# 使用
inputs = [{"topic": f"Topic {i}"} for i in range(100)]
results, errors = safe_batch_with_retry(production_chain, inputs)

print(f"成功: {sum(1 for r in results if r['success'])}/{len(inputs)}")
print(f"失败: {len(errors)}")
```

### 场景3：实时对话的容错

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 构建对话链
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个友好的助手"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

main_llm = ChatOpenAI(model="gpt-4o-mini")
fallback_llm = ChatOpenAI(model="gpt-3.5-turbo")
parser = StrOutputParser()

# 主链
main_chain = prompt | main_llm | parser

# 备用链
fallback_chain = prompt | fallback_llm | parser

# 生产链
chat_chain = (
    main_chain
    .with_retry(stop_after_attempt=3)
    .with_fallbacks([fallback_chain])
)

# 流式对话（带容错）
def chat_stream_with_fallback(user_input: str, history: list):
    """流式对话，带容错"""
    try:
        print("助手: ", end="", flush=True)
        for chunk in chat_chain.stream({
            "input": user_input,
            "history": history
        }):
            print(chunk, end="", flush=True)
        print()
    except Exception as e:
        print(f"\n错误: {e}")
```

---

## 性能影响

### 重试的性能影响

```python
import time

# 测试重试的性能影响
def benchmark_retry():
    """基准测试：重试的性能影响"""

    # 模拟不稳定的函数
    attempt_count = 0

    def unstable_func(x):
        nonlocal attempt_count
        attempt_count += 1
        if attempt_count < 2:
            raise ValueError("临时错误")
        return x * 2

    # 不重试
    attempt_count = 0
    start = time.time()
    try:
        result = unstable_func(10)
    except:
        pass
    no_retry_time = time.time() - start

    # 重试
    attempt_count = 0
    start = time.time()
    result = simple_retry(unstable_func, 10, max_retries=3)
    retry_time = time.time() - start

    print(f"不重试: {no_retry_time:.2f}s（失败）")
    print(f"重试: {retry_time:.2f}s（成功）")
    print(f"额外开销: {retry_time - no_retry_time:.2f}s")

benchmark_retry()
```

**结论**：
- 重试会增加延迟（等待时间）
- 但提升了成功率（从 0% 到 100%）
- 权衡：延迟 vs 成功率

### 降级的性能影响

```python
def benchmark_fallback():
    """基准测试：降级的性能影响"""

    def main_func(x):
        raise ValueError("主函数失败")

    def fallback_func(x):
        return x * 2

    # 不降级
    start = time.time()
    try:
        result = main_func(10)
    except:
        pass
    no_fallback_time = time.time() - start

    # 降级
    start = time.time()
    result = fallback_invoke(main_func, [fallback_func], 10)
    fallback_time = time.time() - start

    print(f"不降级: {no_fallback_time:.2f}s（失败）")
    print(f"降级: {fallback_time:.2f}s（成功）")
    print(f"额外开销: {fallback_time - no_fallback_time:.2f}s")

benchmark_fallback()
```

**结论**：
- 降级会增加延迟（尝试主函数的时间）
- 但提供了备用方案（从失败到成功）
- 权衡：延迟 vs 可用性

---

## 常见问题

### Q1: 重试和降级有什么区别？

**A**:
- **重试**：多次尝试同一个函数（临时性错误）
- **降级**：尝试不同的函数（永久性错误）

### Q2: 如何选择重试次数？

**A**: 通常 3 次足够：
- 1次：原始尝试
- 2次：第1次重试
- 3次：第2次重试
- 4次：第3次重试

### Q3: 降级会影响质量吗？

**A**: 会。降级通常意味着：
- 性能下降（GPT-4 → GPT-3.5）
- 成本下降（昂贵 → 便宜）
- 可用性提升（云端 → 本地）

权衡：质量 vs 可用性

### Q4: 如何监控重试和降级？

**A**: 使用 LangSmith：
- 自动追踪重试次数
- 自动追踪降级路径
- 可视化错误分布

---

## 学习检查清单

- [ ] 理解重试和降级的区别
- [ ] 理解指数退避的原理
- [ ] 掌握 with_retry 的使用
- [ ] 掌握 with_fallbacks 的使用
- [ ] 能手写重试和降级实现
- [ ] 理解错误分类
- [ ] 了解 2025-2026 最佳实践
- [ ] 能构建生产级容错链

---

**版本**: v1.0
**最后更新**: 2026-02-18
**参考来源**:
- LangChain 官方文档
- Medium - 7 Retry & Timeout Policies for Flaky LangChain Tools
- LangChain 错误处理指南
