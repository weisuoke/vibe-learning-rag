# 核心概念1：向量存储

## 什么是向量存储？

**向量存储是将高维数字数组（向量）持久化到数据库的能力。**

在 AI Agent 开发中，文本、图像、音频等数据都可以通过 Embedding 模型转换为向量，然后存储到数据库中，用于后续的相似度检索。

## vector 数据类型

### 基本语法

```sql
-- 创建包含向量列的表
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    embedding vector(1536),  -- 1536 维向量
    created_at TIMESTAMP DEFAULT NOW()
);
```

**关键点：**
- `vector(N)` 中的 N 是向量维度，必须是固定值
- N 必须与 Embedding 模型的输出维度一致
- 常见维度：
  - OpenAI `text-embedding-3-small`: 1536
  - OpenAI `text-embedding-3-large`: 3072
  - Sentence-Transformers `all-MiniLM-L6-v2`: 384

### 向量的表示格式

```python
# Python 中的向量（列表）
embedding = [0.1, 0.2, 0.3, ..., 0.9]  # 1536 个浮点数

# PostgreSQL 中的向量（字符串格式）
'[0.1, 0.2, 0.3, ..., 0.9]'

# psycopg2 自动转换
cursor.execute(
    "INSERT INTO documents (embedding) VALUES (%s)",
    (embedding,)  # Python 列表自动转换为 PostgreSQL vector
)
```

## 向量的 CRUD 操作

### 1. 插入向量（Create）

```python
import psycopg2
from openai import OpenAI

# 连接数据库
conn = psycopg2.connect("postgresql://localhost/mydb")
cursor = conn.cursor()

# 生成 Embedding
client = OpenAI()
text = "什么是向量数据库？"
embedding = client.embeddings.create(
    input=text,
    model="text-embedding-3-small"
).data[0].embedding

# 插入向量
cursor.execute(
    """
    INSERT INTO documents (content, embedding)
    VALUES (%s, %s)
    RETURNING id
    """,
    (text, embedding)
)
doc_id = cursor.fetchone()[0]
conn.commit()

print(f"✅ 插入成功，文档 ID: {doc_id}")
```

### 2. 批量插入向量

```python
# 批量生成 Embedding
texts = [
    "什么是向量数据库？",
    "如何使用 pgvector？",
    "RAG 系统的架构设计"
]

embeddings = client.embeddings.create(
    input=texts,
    model="text-embedding-3-small"
).data

# 批量插入
data = [(text, emb.embedding) for text, emb in zip(texts, embeddings)]
cursor.executemany(
    "INSERT INTO documents (content, embedding) VALUES (%s, %s)",
    data
)
conn.commit()

print(f"✅ 批量插入成功，共 {len(texts)} 条")
```

### 3. 查询向量（Read）

```python
# 查询单个向量
cursor.execute("SELECT id, content, embedding FROM documents WHERE id = %s", (1,))
doc_id, content, embedding = cursor.fetchone()

print(f"文档 ID: {doc_id}")
print(f"内容: {content}")
print(f"向量维度: {len(embedding)}")
print(f"向量前5维: {embedding[:5]}")
```

### 4. 更新向量（Update）

```python
# 重新生成 Embedding
new_text = "什么是向量数据库？（更新版）"
new_embedding = client.embeddings.create(
    input=new_text,
    model="text-embedding-3-small"
).data[0].embedding

# 更新向量
cursor.execute(
    """
    UPDATE documents
    SET content = %s, embedding = %s
    WHERE id = %s
    """,
    (new_text, new_embedding, 1)
)
conn.commit()

print("✅ 更新成功")
```

### 5. 删除向量（Delete）

```python
# 删除单个文档
cursor.execute("DELETE FROM documents WHERE id = %s", (1,))
conn.commit()

# 批量删除
cursor.execute("DELETE FROM documents WHERE created_at < '2024-01-01'")
conn.commit()

print("✅ 删除成功")
```

## 向量维度的选择

### 常见 Embedding 模型的维度

| 模型 | 维度 | 适用场景 | 性能 |
|------|------|----------|------|
| OpenAI `text-embedding-3-small` | 1536 | 通用文本检索 | 快，成本低 |
| OpenAI `text-embedding-3-large` | 3072 | 高精度检索 | 慢，成本高 |
| Sentence-Transformers `all-MiniLM-L6-v2` | 384 | 轻量级检索 | 很快，免费 |
| Sentence-Transformers `all-mpnet-base-v2` | 768 | 平衡性能和精度 | 中等，免费 |
| CLIP `ViT-B/32` | 512 | 图像+文本检索 | 中等 |

### 维度选择策略

```python
# 1. 使用模型默认维度（推荐）
embedding = client.embeddings.create(
    input=text,
    model="text-embedding-3-small"  # 1536 维
).data[0].embedding

# 2. 降维（牺牲精度换取性能）
from sklearn.decomposition import PCA

# 将 1536 维降到 768 维
pca = PCA(n_components=768)
reduced_embedding = pca.fit_transform([embedding])[0]

# 3. 自定义维度（OpenAI 支持）
embedding = client.embeddings.create(
    input=text,
    model="text-embedding-3-small",
    dimensions=768  # 指定输出维度
).data[0].embedding
```

**权衡：**
- **高维度（1536+）**：精度高，但计算慢、存储大
- **中维度（768）**：平衡性能和精度
- **低维度（384）**：速度快，但精度略低

## 向量的存储优化

### 1. 使用 halfvec 类型（半精度）

```sql
-- 使用半精度浮点（16 位），减少存储 50%
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding halfvec(1536)  -- 半精度向量
);
```

**权衡：**
- 存储减少 50%（1536 维：12KB → 6KB）
- 精度略微下降（通常 < 1%）
- 查询速度提升（内存占用减少）

### 2. 分区存储

```sql
-- 按时间分区
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding vector(1536),
    created_at TIMESTAMP
) PARTITION BY RANGE (created_at);

-- 创建分区
CREATE TABLE documents_2024 PARTITION OF documents
    FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

CREATE TABLE documents_2025 PARTITION OF documents
    FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
```

**优势：**
- 查询只扫描相关分区，减少搜索空间
- 历史数据可以归档到只读副本
- 便于数据管理和备份

### 3. 压缩存储

```sql
-- 启用表压缩
ALTER TABLE documents SET (
    toast_compression = lz4  -- 使用 LZ4 压缩
);
```

## 在 AI Agent 开发中的应用

### 场景1：文档知识库

```python
# 1. 文档入库
def ingest_document(content: str, metadata: dict):
    """将文档存入向量数据库"""
    # 生成 Embedding
    embedding = client.embeddings.create(
        input=content,
        model="text-embedding-3-small"
    ).data[0].embedding

    # 存入数据库
    cursor.execute(
        """
        INSERT INTO documents (content, embedding, metadata)
        VALUES (%s, %s, %s)
        RETURNING id
        """,
        (content, embedding, metadata)
    )
    return cursor.fetchone()[0]

# 2. 批量入库
documents = [
    {"content": "什么是向量数据库？", "metadata": {"category": "tech"}},
    {"content": "如何使用 pgvector？", "metadata": {"category": "tutorial"}},
    # ...
]

for doc in documents:
    doc_id = ingest_document(doc["content"], doc["metadata"])
    print(f"✅ 文档 {doc_id} 入库成功")
```

### 场景2：对话历史存储

```python
# 存储用户对话历史
def store_conversation(user_id: int, message: str, role: str):
    """存储对话消息"""
    # 生成 Embedding
    embedding = client.embeddings.create(
        input=message,
        model="text-embedding-3-small"
    ).data[0].embedding

    # 存入数据库
    cursor.execute(
        """
        INSERT INTO conversations (user_id, message, role, embedding)
        VALUES (%s, %s, %s, %s)
        """,
        (user_id, message, role, embedding)
    )
    conn.commit()

# 使用
store_conversation(123, "什么是向量数据库？", "user")
store_conversation(123, "向量数据库是...", "assistant")
```

### 场景3：多模态存储（文本+图像）

```python
from transformers import CLIPProcessor, CLIPModel

# 加载 CLIP 模型
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# 存储图像 Embedding
def store_image(image_path: str, caption: str):
    """存储图像和文本的联合 Embedding"""
    # 加载图像
    from PIL import Image
    image = Image.open(image_path)

    # 生成图像 Embedding
    inputs = processor(images=image, return_tensors="pt")
    image_embedding = model.get_image_features(**inputs).detach().numpy()[0]

    # 生成文本 Embedding
    text_inputs = processor(text=caption, return_tensors="pt", padding=True)
    text_embedding = model.get_text_features(**text_inputs).detach().numpy()[0]

    # 存入数据库
    cursor.execute(
        """
        INSERT INTO images (path, caption, image_embedding, text_embedding)
        VALUES (%s, %s, %s, %s)
        """,
        (image_path, caption, image_embedding.tolist(), text_embedding.tolist())
    )
    conn.commit()
```

## 常见问题

### Q1: 向量维度不匹配怎么办？

```python
# 错误示例
embedding = [0.1, 0.2, 0.3]  # 3 维
cursor.execute("INSERT INTO documents (embedding) VALUES (%s)", (embedding,))
# 报错：expected 1536 dimensions, not 3

# 解决方案1：检查 Embedding 模型的维度
print(len(embedding))  # 确认维度

# 解决方案2：修改表定义
ALTER TABLE documents ALTER COLUMN embedding TYPE vector(3);

# 解决方案3：使用正确的模型
embedding = client.embeddings.create(
    input=text,
    model="text-embedding-3-small"  # 确保是 1536 维
).data[0].embedding
```

### Q2: 如何查看向量的实际内容？

```python
# 查询向量
cursor.execute("SELECT embedding FROM documents WHERE id = 1")
embedding = cursor.fetchone()[0]

# 查看向量信息
print(f"类型: {type(embedding)}")  # <class 'list'>
print(f"维度: {len(embedding)}")   # 1536
print(f"前5维: {embedding[:5]}")   # [0.1, 0.2, 0.3, 0.4, 0.5]
print(f"数据类型: {type(embedding[0])}")  # <class 'float'>
```

### Q3: 向量存储占用多少空间？

```python
# 计算存储大小
# 单精度浮点（float32）：4 字节/维
# 半精度浮点（float16）：2 字节/维

# 1536 维向量
单精度存储 = 1536 * 4 = 6144 字节 = 6 KB
半精度存储 = 1536 * 2 = 3072 字节 = 3 KB

# 50 万文档
单精度总存储 = 500000 * 6 KB = 3 GB
半精度总存储 = 500000 * 3 KB = 1.5 GB
```

### Q4: 如何验证向量是否正确存储？

```python
# 1. 插入向量
original_embedding = [0.1, 0.2, 0.3, ..., 0.9]
cursor.execute(
    "INSERT INTO documents (embedding) VALUES (%s) RETURNING id",
    (original_embedding,)
)
doc_id = cursor.fetchone()[0]

# 2. 读取向量
cursor.execute("SELECT embedding FROM documents WHERE id = %s", (doc_id,))
retrieved_embedding = cursor.fetchone()[0]

# 3. 验证一致性
import numpy as np
assert np.allclose(original_embedding, retrieved_embedding, atol=1e-6)
print("✅ 向量存储正确")
```

## 总结

**向量存储的核心要点：**
1. 使用 `vector(N)` 类型存储 N 维向量
2. 维度必须与 Embedding 模型一致
3. 支持标准的 CRUD 操作
4. 可以使用 `halfvec` 减少存储 50%
5. 分区和压缩可以进一步优化存储

**在 AI Agent 开发中：**
- 文档知识库：存储文档 Embedding
- 对话历史：存储对话消息 Embedding
- 多模态应用：存储图像、音频 Embedding
- RAG 系统：向量存储是数据层基础
