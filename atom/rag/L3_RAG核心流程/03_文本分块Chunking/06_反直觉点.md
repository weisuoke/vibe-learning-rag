# 反直觉点

文本分块看似简单，但有几个常见误区会严重影响 RAG 系统效果。

---

## 误区1：Chunk 越小检索越精准 ❌

### 错误观点

"块越小，向量表示越精确，检索就越准确。所以应该把块切得越小越好。"

### 为什么错？

**块太小会导致三个问题：**

1. **上下文丢失**
```
原文：
"Python 的 GIL（全局解释器锁）是一个互斥锁，
它防止多个线程同时执行 Python 字节码。
这意味着在 CPU 密集型任务中，多线程并不能提升性能。"

切成小块后：
Chunk 1: "Python 的 GIL（全局解释器锁）是一个互斥锁，"
Chunk 2: "它防止多个线程同时执行 Python 字节码。"
Chunk 3: "这意味着在 CPU 密集型任务中，多线程并不能提升性能。"

问题：
- 用户问"GIL 对性能有什么影响？"
- 检索到 Chunk 1，但它没有提到性能
- 检索到 Chunk 3，但它没有提到 GIL
- 上下文被切断了！
```

2. **语义不完整**
```python
# 小块的向量可能无法准确表达语义
chunk = "它防止多个线程同时执行"
# 这个"它"指什么？向量无法知道
# 语义模糊，检索效果差
```

3. **检索噪音增加**
```
块数量 = 文档长度 / 块大小

块大小 500 → 1000 个块
块大小 100 → 5000 个块

块越多：
- 相似的块越多
- Top-K 中可能都是相似但不完整的片段
- 真正有用的信息被稀释
```

### 为什么人们容易这样错？

**直觉误导：** 我们习惯于"越精细越好"的思维。就像搜索引擎，关键词越精确结果越好。但文本分块不是关键词匹配，而是语义匹配，需要足够的上下文才能准确表达语义。

### 正确理解

```python
# ❌ 错误：追求极小的块
splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,  # 太小！
    chunk_overlap=10,
)

# ✅ 正确：保持适中的块大小
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # 适中
    chunk_overlap=50,
)

# 经验法则：
# - 问答场景：300-500 字符
# - 摘要场景：1000-2000 字符
# - 最小不要低于 200 字符
```

---

## 误区2：分块策略一劳永逸 ❌

### 错误观点

"找到一个好的分块配置后，所有文档都用这个配置就行了。"

### 为什么错？

**不同文档类型需要不同策略：**

```
┌─────────────────────────────────────────────────────────┐
│  文档类型          最佳策略              原因            │
├─────────────────────────────────────────────────────────┤
│  技术文档          按标题分块            保持章节完整    │
│  代码文件          按函数/类分块         保持代码完整    │
│  对话记录          按对话轮次分块        保持问答配对    │
│  法律合同          按条款分块            保持条款完整    │
│  新闻文章          按段落分块            段落是自然单元  │
│  表格数据          按行分块              保持行完整      │
└─────────────────────────────────────────────────────────┘
```

**同一策略在不同文档上的效果差异：**

```python
# 通用配置
splitter = RecursiveCharacterTextSplitter(chunk_size=500)

# 对于普通文章：效果好
article = "第一段...\n\n第二段...\n\n第三段..."
# ✅ 按段落自然切分

# 对于代码文件：效果差
code = """
def function_a():
    # 100行代码
    pass

def function_b():
    # 100行代码
    pass
"""
# ❌ 可能把函数切成两半！

# 对于 FAQ：效果差
faq = """
Q: 什么是 Python？
A: Python 是一种编程语言...

Q: 如何安装 Python？
A: 可以从官网下载...
"""
# ❌ 可能把问题和答案分开！
```

### 为什么人们容易这样错？

**懒惰心理：** 调参很麻烦，找到一个"能用"的配置后就不想再改了。但"能用"不等于"好用"，不同场景需要不同优化。

### 正确理解

```python
# ✅ 正确：根据文档类型选择策略

def get_splitter(doc_type: str):
    """根据文档类型返回合适的分块器"""

    if doc_type == "code":
        from langchain.text_splitter import Language, RecursiveCharacterTextSplitter
        return RecursiveCharacterTextSplitter.from_language(
            language=Language.PYTHON,
            chunk_size=1000,
            chunk_overlap=100,
        )

    elif doc_type == "markdown":
        from langchain.text_splitter import MarkdownHeaderTextSplitter
        return MarkdownHeaderTextSplitter(
            headers_to_split_on=[
                ("#", "h1"),
                ("##", "h2"),
                ("###", "h3"),
            ]
        )

    elif doc_type == "faq":
        # 自定义 FAQ 分块器
        return FAQSplitter(qa_separator="\n\nQ:")

    else:
        # 默认通用分块器
        return RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
        )
```

---

## 误区3：Overlap 越大越好 ❌

### 错误观点

"重叠部分可以保证上下文连续，所以重叠越大越好。"

### 为什么错？

**重叠过大会导致：**

1. **存储浪费**
```
chunk_size = 500, overlap = 400 (80% 重叠)

原文 1000 字符：
- 理论上 2 个块就够
- 实际需要 ~5 个块（因为每块只新增 100 字符）
- 存储量增加 2.5 倍！
```

2. **检索冗余**
```
用户问题："什么是 GIL？"

高重叠导致：
Chunk 1: "...GIL 是全局解释器锁..."
Chunk 2: "GIL 是全局解释器锁，它..."  ← 80% 内容重复
Chunk 3: "是全局解释器锁，它防止..."  ← 80% 内容重复

Top-3 检索结果几乎相同，浪费了检索配额
```

3. **向量相似度失真**
```python
# 高重叠的块向量非常相似
similarity(chunk1_vec, chunk2_vec) = 0.95  # 几乎相同

# 这会导致：
# - 检索结果高度重复
# - 难以覆盖文档的不同部分
# - 多样性差
```

### 为什么人们容易这样错？

**过度保险心理：** 担心切断重要信息，所以想"多重叠一点保险"。但过度重叠就像买了太多保险，成本高但收益递减。

### 正确理解

```python
# ❌ 错误：过大的重叠
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=400,  # 80% 重叠，太多了！
)

# ✅ 正确：适度的重叠
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,   # 10% 重叠，刚刚好
)

# 经验法则：
# - 重叠比例：10-20%
# - 绝对值：50-100 字符
# - 目的：覆盖边界处的句子，不是复制大段内容
```

**重叠的正确用法：**

```
正确的重叠（10-20%）：
┌─────────────────────┐
│      Chunk 1        │
└───────────────┬─────┘
                │ 小重叠
            ┌───┴─────────────────┐
            │      Chunk 2        │
            └─────────────────────┘

作用：确保边界处的句子完整

错误的重叠（80%）：
┌─────────────────────────────────┐
│           Chunk 1               │
└─────────────────────────┬───────┘
                          │ 大重叠
    ┌─────────────────────┴───────────────┐
    │           Chunk 2                   │
    └─────────────────────────────────────┘

问题：大量重复内容，浪费存储和检索配额
```

---

## 误区总结

| 误区 | 正确理解 | 推荐做法 |
|------|----------|----------|
| Chunk 越小越精准 | 太小会丢失上下文 | 300-500 字符为宜 |
| 一个配置通吃 | 不同文档需要不同策略 | 根据文档类型选择 |
| Overlap 越大越好 | 过大会造成冗余 | 10-20% 重叠即可 |

---

## 自检清单

在设计分块策略时，问自己：

- [ ] 块大小是否足够表达完整语义？（不低于 200 字符）
- [ ] 是否考虑了文档的特殊结构？（代码、FAQ、表格等）
- [ ] 重叠比例是否合理？（10-20%）
- [ ] 是否在实际数据上验证过效果？

---

**下一步：** [07_实战代码](./07_实战代码.md) - 完整可运行的分块示例
