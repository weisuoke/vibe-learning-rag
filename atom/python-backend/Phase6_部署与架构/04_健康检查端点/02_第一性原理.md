# 第一性原理

### 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题

---

## 健康检查端点的第一性原理

### 1. 最基础的定义

**健康检查端点 = 一个返回服务状态的 HTTP 接口**

仅此而已！没有更基础的了。

就像一个简单的函数：

```python
def health():
    return {"status": "ok"}
```

这就是健康检查的本质：**告诉外界"我还活着"或"我准备好了"**。

---

### 2. 为什么需要健康检查端点？

**核心问题：在分布式系统中，如何知道一个服务是否可用？**

#### 问题场景

想象你有一个 AI Agent API 服务：

```
用户 → 负载均衡器 → [服务A, 服务B, 服务C]
```

**问题1：服务崩溃了怎么办？**
- 服务 B 突然崩溃（进程退出）
- 负载均衡器还在把流量发给服务 B
- 用户请求失败，体验很差

**问题2：服务启动中怎么办？**
- 服务 C 刚启动，数据库连接还没建立
- 负载均衡器已经开始发流量
- 请求失败，因为服务还没准备好

**问题3：依赖服务挂了怎么办？**
- 服务 A 运行正常，但数据库连接断了
- 负载均衡器认为服务 A 是健康的
- 请求到达服务 A，但无法访问数据库，返回 500 错误

**根本问题：没有一个标准化的方式让服务告诉外界"我的状态"**

---

### 3. 健康检查端点的三层价值

#### 价值1：服务发现与路由

**让负载均衡器知道哪些服务可用**

```
负载均衡器每隔 5 秒检查：
- 服务 A: /health → 200 OK ✅ 继续发流量
- 服务 B: /health → 超时 ❌ 停止发流量
- 服务 C: /health → 503 ❌ 停止发流量
```

**类比：**
- **前端类比**：Service Worker 检查后台服务是否可用，决定是否使用缓存
- **日常生活类比**：餐厅门口的"营业中"标志，告诉顾客是否可以进来

#### 价值2：故障检测与自愈

**让容器编排系统（如 Kubernetes）自动重启失败的服务**

```
Kubernetes 每隔 10 秒检查：
- Pod A: /health → 200 OK ✅ 继续运行
- Pod B: /health → 连续 3 次失败 ❌ 自动重启 Pod
```

**类比：**
- **前端类比**：React Error Boundary 捕获错误并重新渲染组件
- **日常生活类比**：保险丝跳闸后自动断电，保护电路

#### 价值3：监控与告警

**让监控系统知道服务的健康趋势**

```
Prometheus 每隔 15 秒抓取指标：
- health_check_status{service="api"} = 1 (健康)
- health_check_duration_seconds = 0.05 (检查耗时)

如果连续 5 分钟 health_check_status = 0，触发告警
```

**类比：**
- **前端类比**：Sentry 监控前端错误率，超过阈值发送告警
- **日常生活类比**：体检报告，定期检查身体指标

---

### 4. 从第一性原理推导健康检查的设计

**推理链：**

```
1. 服务有两种状态：存活（Alive）和就绪（Ready）
   ↓
2. 存活 = 进程还在运行（Liveness）
   就绪 = 可以处理请求（Readiness）
   ↓
3. 需要两个端点：
   - /health：检查存活（简单快速）
   - /ready：检查就绪（检查依赖服务）
   ↓
4. 就绪检查需要验证依赖服务：
   - 数据库连接是否正常？
   - Redis 是否可访问？
   - 外部 API 是否可用？
   ↓
5. 依赖检查不能太慢，否则影响性能
   ↓
6. 需要缓存机制：
   - 每 30 秒检查一次依赖服务
   - 其他时间返回缓存结果
   ↓
7. 需要降级策略：
   - 依赖服务部分失败时，服务降级但不完全不可用
   ↓
8. 需要监控集成：
   - 暴露健康检查指标给 Prometheus
   - 记录健康检查日志
   ↓
9. 最终设计：生产级健康检查系统
   - 多层次检查（浅层/深层）
   - 缓存策略（避免频繁检查）
   - 降级策略（部分失败时降级）
   - 监控集成（指标暴露）
```

---

### 5. 健康检查的两种哲学

#### 哲学1：乐观健康检查（Optimistic）

**假设：服务默认是健康的，除非明确检测到问题**

```python
@app.get("/health")
async def health():
    # 只检查进程是否运行
    return {"status": "healthy"}
```

**优点：**
- 响应快（几乎没有延迟）
- 不会因为依赖服务问题而误报

**缺点：**
- 可能漏报（依赖服务挂了但健康检查还是通过）

**适用场景：**
- Liveness 探测（只关心进程是否存活）
- 对可用性要求极高的服务

#### 哲学2：悲观健康检查（Pessimistic）

**假设：服务默认是不健康的，除非所有依赖都正常**

```python
@app.get("/ready")
async def ready():
    # 检查所有依赖服务
    if not check_database():
        raise HTTPException(503, "Database unavailable")
    if not check_redis():
        raise HTTPException(503, "Redis unavailable")
    if not check_llm_api():
        raise HTTPException(503, "LLM API unavailable")
    return {"status": "ready"}
```

**优点：**
- 准确（只有真正可用时才返回健康）
- 避免把流量发给不可用的服务

**缺点：**
- 响应慢（需要检查多个依赖）
- 可能误报（依赖服务短暂抖动导致健康检查失败）

**适用场景：**
- Readiness 探测（确保服务真正可用）
- 对数据一致性要求高的服务

---

### 6. 健康检查的三个层次

#### 层次1：进程级健康检查

**检查：进程是否还在运行？**

```python
@app.get("/health")
async def health():
    return {"status": "healthy"}
```

**对应：Kubernetes Liveness Probe**

#### 层次2：服务级健康检查

**检查：服务是否准备好处理请求？**

```python
@app.get("/ready")
async def ready():
    # 检查数据库连接
    await db.execute("SELECT 1")
    return {"status": "ready"}
```

**对应：Kubernetes Readiness Probe**

#### 层次3：业务级健康检查

**检查：业务功能是否正常？**

```python
@app.get("/health/deep")
async def deep_health():
    # 端到端测试
    result = await test_rag_pipeline()
    return {"status": "healthy", "rag_test": result}
```

**对应：定期的端到端测试**

---

### 7. 一句话总结第一性原理

**健康检查端点是服务向外界暴露自身状态的标准化接口，通过区分存活（Liveness）和就绪（Readiness）两种状态，结合依赖检查、缓存策略和监控集成，实现分布式系统的自动化故障检测和流量管理。**

---

## 在 AI Agent 后端中的应用

### AI Agent 的特殊健康检查需求

#### 1. LLM API 可用性检查

```python
async def check_llm_api():
    """检查 OpenAI/Anthropic API 是否可用"""
    try:
        # 发送一个简单的测试请求
        response = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1
        )
        return True
    except Exception:
        return False
```

#### 2. 向量数据库连接检查

```python
async def check_vector_db():
    """检查 pgvector 是否可用"""
    try:
        # 执行一个简单的向量查询
        await db.execute("SELECT 1 FROM embeddings LIMIT 1")
        return True
    except Exception:
        return False
```

#### 3. Embedding 模型加载状态

```python
async def check_embedding_model():
    """检查 Embedding 模型是否已加载"""
    global embedding_model
    if embedding_model is None:
        return False
    # 测试模型是否可用
    try:
        _ = embedding_model.encode("test")
        return True
    except Exception:
        return False
```

#### 4. Agent 任务队列健康检查

```python
async def check_task_queue():
    """检查后台任务队列是否正常"""
    try:
        # 检查 Redis 队列长度
        queue_length = await redis.llen("agent_tasks")
        # 如果队列积压超过 1000，认为不健康
        return queue_length < 1000
    except Exception:
        return False
```

---

## 关键洞察

### 洞察1：健康检查不是越详细越好

**误区：** 健康检查应该检查所有可能的问题

**真相：** 健康检查应该快速返回，只检查关键依赖

**原因：**
- 健康检查会被频繁调用（每 5-10 秒一次）
- 过于详细的检查会影响性能
- 应该用监控系统（Prometheus）做详细检查

### 洞察2：健康检查应该有缓存

**误区：** 每次健康检查都实时检查依赖服务

**真相：** 应该缓存健康检查结果，定期更新

**原因：**
- 避免频繁检查影响依赖服务性能
- 避免短暂抖动导致误报
- 提高健康检查响应速度

### 洞察3：健康检查应该区分 Liveness 和 Readiness

**误区：** 一个 /health 端点就够了

**真相：** 应该有 /health（存活）和 /ready（就绪）两个端点

**原因：**
- Liveness 失败 → 重启容器
- Readiness 失败 → 停止发流量，但不重启
- 两者的处理策略完全不同

---

## 总结

健康检查端点的第一性原理：

1. **本质**：一个返回服务状态的 HTTP 接口
2. **目的**：让外界知道服务是否可用
3. **价值**：服务发现、故障检测、监控告警
4. **设计**：区分存活和就绪，检查依赖服务，使用缓存策略
5. **实现**：简单快速，避免过度检查

在 AI Agent 后端中，健康检查不仅要检查基础设施（数据库、Redis），还要检查 AI 特定的依赖（LLM API、向量数据库、Embedding 模型），确保整个 RAG 系统的可用性。
