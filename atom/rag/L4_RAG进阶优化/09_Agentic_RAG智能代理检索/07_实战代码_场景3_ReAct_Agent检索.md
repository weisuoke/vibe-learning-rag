# å®æˆ˜ä»£ç  - åœºæ™¯ 3: ReAct Agent æ£€ç´¢

## åœºæ™¯æè¿°

**ç›®æ ‡**: ä½¿ç”¨ LangChain æ„å»º ReAct é£æ ¼çš„æ£€ç´¢ä»£ç†,å®ç°"æ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ åæ€"å¾ªç¯

**éš¾ç‚¹**:
- å®ç°æ¨ç†å’Œè¡ŒåŠ¨çš„äº¤æ›¿å¾ªç¯
- ç®¡ç†ä¸­é—´æ­¥éª¤å’Œè§‚å¯Ÿç»“æœ
- å†³å®šä½•æ—¶åœæ­¢è¿­ä»£

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ LangChain ReAct Agent æ¡†æ¶,ç»“åˆæ£€ç´¢å·¥å…·å®ç°è¿­ä»£å¼æ£€ç´¢

---

## ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
uv add langchain langchain-openai chromadb python-dotenv
```

---

## å®Œæ•´ä»£ç 

```python
"""
ReAct Agent æ£€ç´¢ - æ¨ç†è¡ŒåŠ¨å¾ªç¯
æ¼”ç¤º: Thought â†’ Action â†’ Observation è¿­ä»£æ£€ç´¢

æŠ€æœ¯æ ˆ:
- LangChain: 0.1.0+
- OpenAI: 1.0.0+
- ChromaDB: 0.4.0+
"""

import os
from typing import List
from dotenv import load_dotenv

from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.schema import Document
from langchain.tools import Tool
from langchain.prompts import PromptTemplate

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ===== 1. åˆå§‹åŒ–ç»„ä»¶ =====
print("åˆå§‹åŒ–ç»„ä»¶...")

# LLM
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    api_key=os.getenv("OPENAI_API_KEY")
)

# Embeddings
embeddings = OpenAIEmbeddings(api_key=os.getenv("OPENAI_API_KEY"))

# ===== 2. å‡†å¤‡çŸ¥è¯†åº“ =====
print("å‡†å¤‡çŸ¥è¯†åº“...")

documents = [
    Document(
        page_content="BERT (Bidirectional Encoder Representations from Transformers) æ˜¯ Google åœ¨ 2018 å¹´æå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚",
        metadata={"source": "bert_intro", "topic": "bert"}
    ),
    Document(
        page_content="BERT ä½¿ç”¨åŒå‘ Transformer ç¼–ç å™¨,é€šè¿‡ Masked Language Model (MLM) å’Œ Next Sentence Prediction (NSP) è¿›è¡Œé¢„è®­ç»ƒã€‚",
        metadata={"source": "bert_training", "topic": "bert"}
    ),
    Document(
        page_content="BERT çš„ä¼˜ç‚¹åŒ…æ‹¬:å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½ã€å¯ä»¥è¿›è¡Œ fine-tuningã€‚",
        metadata={"source": "bert_advantages", "topic": "bert"}
    ),
    Document(
        page_content="BERT çš„ç¼ºç‚¹åŒ…æ‹¬:æ¨¡å‹è¾ƒå¤§ã€æ¨ç†é€Ÿåº¦æ…¢ã€ä¸é€‚åˆç”Ÿæˆä»»åŠ¡ã€‚",
        metadata={"source": "bert_disadvantages", "topic": "bert"}
    ),
    Document(
        page_content="GPT (Generative Pre-trained Transformer) æ˜¯ OpenAI æå‡ºçš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ç³»åˆ—ã€‚",
        metadata={"source": "gpt_intro", "topic": "gpt"}
    ),
    Document(
        page_content="GPT ä½¿ç”¨å•å‘ Transformer è§£ç å™¨,é€šè¿‡è‡ªå›å½’æ–¹å¼é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚",
        metadata={"source": "gpt_architecture", "topic": "gpt"}
    ),
    Document(
        page_content="GPT çš„ä¼˜ç‚¹åŒ…æ‹¬:å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€æµç•…çš„è¯­è¨€è¾“å‡ºã€é€‚åˆå¯¹è¯å’Œåˆ›ä½œä»»åŠ¡ã€‚",
        metadata={"source": "gpt_advantages", "topic": "gpt"}
    ),
    Document(
        page_content="GPT çš„ç¼ºç‚¹åŒ…æ‹¬:ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹ã€å¯èƒ½äº§ç”Ÿå¹»è§‰ã€è®­ç»ƒæˆæœ¬é«˜ã€‚",
        metadata={"source": "gpt_disadvantages", "topic": "gpt"}
    ),
    Document(
        page_content="Transformer æ˜¯ 2017 å¹´æå‡ºçš„æ³¨æ„åŠ›æœºåˆ¶æ¶æ„,ä½¿ç”¨ Self-Attention å®ç°å¹¶è¡Œå¤„ç†ã€‚",
        metadata={"source": "transformer_intro", "topic": "transformer"}
    ),
    Document(
        page_content="Self-Attention æœºåˆ¶å…è®¸æ¨¡å‹å…³æ³¨è¾“å…¥åºåˆ—çš„ä¸åŒä½ç½®,è®¡ç®—æ¯ä¸ªä½ç½®ä¸å…¶ä»–ä½ç½®çš„ç›¸å…³æ€§ã€‚",
        metadata={"source": "transformer_attention", "topic": "transformer"}
    )
]

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = Chroma.from_documents(
    documents=documents,
    embedding=embeddings,
    collection_name="react_demo"
)

# ===== 3. å®šä¹‰å·¥å…· =====

def search_documents(query: str) -> str:
    """æœç´¢ç›¸å…³æ–‡æ¡£"""
    results = vectorstore.similarity_search(query, k=2)
    if not results:
        return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"

    output = []
    for i, doc in enumerate(results, 1):
        output.append(f"{i}. {doc.page_content}")
        output.append(f"   æ¥æº: {doc.metadata.get('source', 'unknown')}")

    return "\n".join(output)

def search_by_topic(topic: str) -> str:
    """æŒ‰ä¸»é¢˜æœç´¢æ–‡æ¡£"""
    results = vectorstore.similarity_search(
        topic,
        k=3,
        filter={"topic": topic.lower()}
    )

    if not results:
        return f"æœªæ‰¾åˆ°å…³äº {topic} çš„æ–‡æ¡£"

    output = []
    for i, doc in enumerate(results, 1):
        output.append(f"{i}. {doc.page_content}")

    return "\n".join(output)

# åˆ›å»ºå·¥å…·åˆ—è¡¨
tools = [
    Tool(
        name="Search",
        func=search_documents,
        description="æœç´¢ç›¸å…³æ–‡æ¡£ã€‚è¾“å…¥:æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚é€‚åˆä¸€èˆ¬æ€§æœç´¢ã€‚"
    ),
    Tool(
        name="SearchByTopic",
        func=search_by_topic,
        description="æŒ‰ä¸»é¢˜æœç´¢æ–‡æ¡£ã€‚è¾“å…¥:ä¸»é¢˜åç§°(bert/gpt/transformer)ã€‚é€‚åˆé’ˆå¯¹ç‰¹å®šä¸»é¢˜çš„æ·±å…¥æœç´¢ã€‚"
    )
]

# ===== 4. å®šä¹‰ ReAct Prompt =====

react_prompt = PromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”é—®é¢˜:

Question: ç”¨æˆ·çš„é—®é¢˜
Thought: ä½ åº”è¯¥æ€è€ƒä¸‹ä¸€æ­¥åšä»€ä¹ˆ
Action: æ‰§è¡Œçš„å·¥å…·åç§°
Action Input: å·¥å…·çš„è¾“å…¥
Observation: å·¥å…·çš„è¾“å‡ºç»“æœ
... (é‡å¤ Thought/Action/Action Input/Observation)
Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆç­”æ¡ˆ

å¯ç”¨å·¥å…·:
{tools}

å·¥å…·åç§°: {tool_names}

Question: {input}
{agent_scratchpad}
""")

# ===== 5. åˆ›å»º ReAct Agent =====

print("åˆ›å»º ReAct Agent...")

agent = create_react_agent(
    llm=llm,
    tools=tools,
    prompt=react_prompt
)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=5,
    handle_parsing_errors=True
)

# ===== 6. æµ‹è¯• =====

def main():
    """ä¸»å‡½æ•°"""
    test_queries = [
        "ä»€ä¹ˆæ˜¯ BERT?",
        "æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹",
        "Transformer çš„æ ¸å¿ƒæœºåˆ¶æ˜¯ä»€ä¹ˆ?"
    ]

    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*60}\n")

        try:
            result = agent_executor.invoke({"input": query})
            print(f"\n{'='*60}")
            print(f"æœ€ç»ˆç­”æ¡ˆ:")
            print(result["output"])
            print(f"{'='*60}\n")

        except Exception as e:
            print(f"é”™è¯¯: {e}\n")

if __name__ == "__main__":
    main()
```

---

## è¿è¡Œè¾“å‡º

```
åˆå§‹åŒ–ç»„ä»¶...
å‡†å¤‡çŸ¥è¯†åº“...
åˆ›å»º ReAct Agent...

============================================================
æŸ¥è¯¢: ä»€ä¹ˆæ˜¯ BERT?
============================================================


> Entering new AgentExecutor chain...
Thought: æˆ‘éœ€è¦æœç´¢å…³äº BERT çš„ä¿¡æ¯
Action: SearchByTopic
Action Input: bert

Observation:
1. BERT (Bidirectional Encoder Representations from Transformers) æ˜¯ Google åœ¨ 2018 å¹´æå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚
2. BERT ä½¿ç”¨åŒå‘ Transformer ç¼–ç å™¨,é€šè¿‡ Masked Language Model (MLM) å’Œ Next Sentence Prediction (NSP) è¿›è¡Œé¢„è®­ç»ƒã€‚
3. BERT çš„ä¼˜ç‚¹åŒ…æ‹¬:å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½ã€å¯ä»¥è¿›è¡Œ fine-tuningã€‚

Thought: æˆ‘ç°åœ¨æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜äº†
Final Answer: BERT (Bidirectional Encoder Representations from Transformers) æ˜¯ Google åœ¨ 2018 å¹´æå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚å®ƒä½¿ç”¨åŒå‘ Transformer ç¼–ç å™¨,é€šè¿‡ Masked Language Model (MLM) å’Œ Next Sentence Prediction (NSP) è¿›è¡Œé¢„è®­ç»ƒã€‚BERT çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½,ä»¥åŠå¯ä»¥è¿›è¡Œ fine-tuningã€‚

> Finished chain.

============================================================
æœ€ç»ˆç­”æ¡ˆ:
BERT (Bidirectional Encoder Representations from Transformers) æ˜¯ Google åœ¨ 2018 å¹´æå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚å®ƒä½¿ç”¨åŒå‘ Transformer ç¼–ç å™¨,é€šè¿‡ Masked Language Model (MLM) å’Œ Next Sentence Prediction (NSP) è¿›è¡Œé¢„è®­ç»ƒã€‚BERT çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½,ä»¥åŠå¯ä»¥è¿›è¡Œ fine-tuningã€‚
============================================================

============================================================
æŸ¥è¯¢: æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹
============================================================


> Entering new AgentExecutor chain...
Thought: æˆ‘éœ€è¦åˆ†åˆ«æœç´¢ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹
Action: SearchByTopic
Action Input: bert

Observation:
1. BERT çš„ä¼˜ç‚¹åŒ…æ‹¬:å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½ã€å¯ä»¥è¿›è¡Œ fine-tuningã€‚
2. BERT çš„ç¼ºç‚¹åŒ…æ‹¬:æ¨¡å‹è¾ƒå¤§ã€æ¨ç†é€Ÿåº¦æ…¢ã€ä¸é€‚åˆç”Ÿæˆä»»åŠ¡ã€‚

Thought: ç°åœ¨æˆ‘éœ€è¦æœç´¢ GPT çš„ä¼˜ç¼ºç‚¹
Action: SearchByTopic
Action Input: gpt

Observation:
1. GPT çš„ä¼˜ç‚¹åŒ…æ‹¬:å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€æµç•…çš„è¯­è¨€è¾“å‡ºã€é€‚åˆå¯¹è¯å’Œåˆ›ä½œä»»åŠ¡ã€‚
2. GPT çš„ç¼ºç‚¹åŒ…æ‹¬:ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹ã€å¯èƒ½äº§ç”Ÿå¹»è§‰ã€è®­ç»ƒæˆæœ¬é«˜ã€‚

Thought: æˆ‘ç°åœ¨æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å¯¹æ¯” BERT å’Œ GPT äº†
Final Answer:
BERT å’Œ GPT çš„å¯¹æ¯”:

**BERT ä¼˜ç‚¹:**
- å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
- åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½
- å¯ä»¥è¿›è¡Œ fine-tuning

**BERT ç¼ºç‚¹:**
- æ¨¡å‹è¾ƒå¤§
- æ¨ç†é€Ÿåº¦æ…¢
- ä¸é€‚åˆç”Ÿæˆä»»åŠ¡

**GPT ä¼˜ç‚¹:**
- å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›
- æµç•…çš„è¯­è¨€è¾“å‡º
- é€‚åˆå¯¹è¯å’Œåˆ›ä½œä»»åŠ¡

**GPT ç¼ºç‚¹:**
- ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹
- å¯èƒ½äº§ç”Ÿå¹»è§‰
- è®­ç»ƒæˆæœ¬é«˜

> Finished chain.

============================================================
æœ€ç»ˆç­”æ¡ˆ:
BERT å’Œ GPT çš„å¯¹æ¯”:

**BERT ä¼˜ç‚¹:**
- å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
- åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾— SOTA æ€§èƒ½
- å¯ä»¥è¿›è¡Œ fine-tuning

**BERT ç¼ºç‚¹:**
- æ¨¡å‹è¾ƒå¤§
- æ¨ç†é€Ÿåº¦æ…¢
- ä¸é€‚åˆç”Ÿæˆä»»åŠ¡

**GPT ä¼˜ç‚¹:**
- å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›
- æµç•…çš„è¯­è¨€è¾“å‡º
- é€‚åˆå¯¹è¯å’Œåˆ›ä½œä»»åŠ¡

**GPT ç¼ºç‚¹:**
- ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹
- å¯èƒ½äº§ç”Ÿå¹»è§‰
- è®­ç»ƒæˆæœ¬é«˜
============================================================
```

---

## ä»£ç è§£æ

### å…³é”®ç‚¹ 1: ReAct Prompt è®¾è®¡

```python
react_prompt = PromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”é—®é¢˜:

Question: ç”¨æˆ·çš„é—®é¢˜
Thought: ä½ åº”è¯¥æ€è€ƒä¸‹ä¸€æ­¥åšä»€ä¹ˆ
Action: æ‰§è¡Œçš„å·¥å…·åç§°
Action Input: å·¥å…·çš„è¾“å…¥
Observation: å·¥å…·çš„è¾“å‡ºç»“æœ
... (é‡å¤ Thought/Action/Action Input/Observation)
Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆç­”æ¡ˆ
""")
```

**è¦ç‚¹**:
- æ˜ç¡®çš„æ ¼å¼å®šä¹‰
- Thought â†’ Action â†’ Observation å¾ªç¯
- æ¸…æ™°çš„ç»“æŸæ ‡å¿—(Final Answer)

### å…³é”®ç‚¹ 2: å·¥å…·å®šä¹‰

```python
tools = [
    Tool(
        name="Search",
        func=search_documents,
        description="æœç´¢ç›¸å…³æ–‡æ¡£ã€‚è¾“å…¥:æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚é€‚åˆä¸€èˆ¬æ€§æœç´¢ã€‚"
    ),
    Tool(
        name="SearchByTopic",
        func=search_by_topic,
        description="æŒ‰ä¸»é¢˜æœç´¢æ–‡æ¡£ã€‚è¾“å…¥:ä¸»é¢˜åç§°(bert/gpt/transformer)ã€‚é€‚åˆé’ˆå¯¹ç‰¹å®šä¸»é¢˜çš„æ·±å…¥æœç´¢ã€‚"
    )
]
```

**è¦ç‚¹**:
- æ¸…æ™°çš„å·¥å…·æè¿°(å¸®åŠ© LLM é€‰æ‹©)
- æ˜ç¡®çš„è¾“å…¥æ ¼å¼è¯´æ˜
- é€‚ç”¨åœºæ™¯è¯´æ˜

### å…³é”®ç‚¹ 3: Agent Executor é…ç½®

```python
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,              # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
    max_iterations=5,          # é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°
    handle_parsing_errors=True # å¤„ç†è§£æé”™è¯¯
)
```

**è¦ç‚¹**:
- `verbose=True` æ˜¾ç¤ºå®Œæ•´æ¨ç†è¿‡ç¨‹
- `max_iterations` é˜²æ­¢æ— é™å¾ªç¯
- `handle_parsing_errors` æé«˜é²æ£’æ€§

---

## æ‰©å±•æ€è€ƒ

### å¦‚ä½•ä¼˜åŒ–?

**1. æ·»åŠ æ›´å¤šå·¥å…·**
```python
def calculate(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {e}"

tools.append(
    Tool(
        name="Calculator",
        func=calculate,
        description="æ‰§è¡Œæ•°å­¦è®¡ç®—ã€‚è¾“å…¥:æ•°å­¦è¡¨è¾¾å¼ã€‚"
    )
)
```

**2. æ·»åŠ è®°å¿†åŠŸèƒ½**
```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,  # æ·»åŠ è®°å¿†
    verbose=True
)
```

**3. è‡ªå®šä¹‰åœæ­¢æ¡ä»¶**
```python
def custom_stopping_condition(intermediate_steps):
    """è‡ªå®šä¹‰åœæ­¢æ¡ä»¶"""
    # å¦‚æœå·²ç»æ‰§è¡Œäº†3æ¬¡æœç´¢,åœæ­¢
    search_count = sum(1 for step in intermediate_steps if "Search" in str(step))
    return search_count >= 3

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    early_stopping_method="force",
    max_iterations=10
)
```

### å¦‚ä½•æ‰©å±•?

**1. æ”¯æŒæµå¼è¾“å‡º**
```python
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    callbacks=[StreamingStdOutCallbackHandler()],
    verbose=True
)
```

**2. æ·»åŠ å·¥å…·éªŒè¯**
```python
def validate_tool_input(tool_name: str, tool_input: str) -> bool:
    """éªŒè¯å·¥å…·è¾“å…¥"""
    if tool_name == "SearchByTopic":
        valid_topics = ["bert", "gpt", "transformer"]
        return tool_input.lower() in valid_topics
    return True

# åœ¨å·¥å…·å‡½æ•°ä¸­ä½¿ç”¨
def search_by_topic_validated(topic: str) -> str:
    if not validate_tool_input("SearchByTopic", topic):
        return f"æ— æ•ˆçš„ä¸»é¢˜: {topic}ã€‚æœ‰æ•ˆä¸»é¢˜: bert, gpt, transformer"
    return search_by_topic(topic)
```

**3. æ·»åŠ ç»“æœè¯„åˆ†**
```python
def evaluate_result(result: str, query: str) -> float:
    """è¯„ä¼°ç»“æœè´¨é‡"""
    # ç®€å•çš„è¯„åˆ†é€»è¾‘
    if len(result) < 50:
        return 0.3  # å¤ªçŸ­
    if "æœªæ‰¾åˆ°" in result:
        return 0.1  # æœªæ‰¾åˆ°ç»“æœ
    return 0.9  # æ­£å¸¸ç»“æœ

# åœ¨ agent ä¸­ä½¿ç”¨
def search_with_evaluation(query: str) -> str:
    result = search_documents(query)
    score = evaluate_result(result, query)

    if score < 0.5:
        # å°è¯•æ”¹å†™æŸ¥è¯¢
        refined_query = refine_query(query)
        result = search_documents(refined_query)

    return result
```

### ç”Ÿäº§çº§æ”¹è¿›

**1. é”™è¯¯å¤„ç†å’Œé‡è¯•**
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def robust_agent_run(query: str):
    """å¸¦é‡è¯•çš„ agent æ‰§è¡Œ"""
    try:
        return agent_executor.invoke({"input": query})
    except Exception as e:
        print(f"æ‰§è¡Œå¤±è´¥: {e}, é‡è¯•ä¸­...")
        raise
```

**2. æ€§èƒ½ç›‘æ§**
```python
import time
from typing import Dict

def run_with_metrics(query: str) -> Dict:
    """å¸¦æ€§èƒ½ç›‘æ§çš„æ‰§è¡Œ"""
    start_time = time.time()

    result = agent_executor.invoke({"input": query})

    metrics = {
        "query": query,
        "execution_time": time.time() - start_time,
        "iterations": len(result.get("intermediate_steps", [])),
        "tools_used": [step[0].tool for step in result.get("intermediate_steps", [])]
    }

    print(f"\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
    print(f"  æ‰§è¡Œæ—¶é—´: {metrics['execution_time']:.2f}s")
    print(f"  è¿­ä»£æ¬¡æ•°: {metrics['iterations']}")
    print(f"  ä½¿ç”¨å·¥å…·: {', '.join(metrics['tools_used'])}")

    return result
```

**3. æ—¥å¿—è®°å½•**
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('react_agent.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def logged_agent_run(query: str):
    """å¸¦æ—¥å¿—çš„ agent æ‰§è¡Œ"""
    logger.info(f"æ”¶åˆ°æŸ¥è¯¢: {query}")

    try:
        result = agent_executor.invoke({"input": query})
        logger.info(f"æŸ¥è¯¢æˆåŠŸ: {query}")
        return result
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å¤±è´¥: {query}, é”™è¯¯: {e}")
        raise
```

**4. ç»“æœç¼“å­˜**
```python
from functools import lru_cache
import hashlib

def cache_key(query: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    return hashlib.md5(query.encode()).hexdigest()

result_cache = {}

def cached_agent_run(query: str):
    """å¸¦ç¼“å­˜çš„ agent æ‰§è¡Œ"""
    key = cache_key(query)

    if key in result_cache:
        print("ä»ç¼“å­˜è¿”å›ç»“æœ")
        return result_cache[key]

    result = agent_executor.invoke({"input": query})
    result_cache[key] = result

    return result
```

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- LangChain ReAct Agent: https://python.langchain.com/docs/modules/agents/agent_types/react
- LangChain Tools: https://python.langchain.com/docs/modules/agents/tools/

### ç›¸å…³è®ºæ–‡
- "ReAct: Synergizing Reasoning and Acting in Language Models" (arXiv 2210.03629, 2022)

### ç›¸å…³åšå®¢
- "Building ReAct Agents with LangChain" (LangChain Blog, 2025)
- "ReAct Framework Explained" (Medium, 2026)

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-17
**ä»£ç è¡Œæ•°**: ~180 è¡Œ
