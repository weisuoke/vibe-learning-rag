# 实战代码 - 场景 2: 批量插入与索引优化

本文档展示大规模数据插入的性能优化技巧，以及不同索引类型的性能对比。

---

## 场景描述

**目标**: 优化大规模数据插入和索引创建的性能

**关键问题**:
- 如何快速插入 10 万+ 数据？
- 不同索引类型的性能差异？
- 如何选择合适的索引参数？

**适用场景**:
- 大规模文档导入
- RAG 知识库构建
- 生产环境部署

---

## 完整代码实现

### 环境准备

```python
# 安装依赖
# pip install pymilvus numpy

from pymilvus import (
    connections,
    Collection,
    FieldSchema,
    CollectionSchema,
    DataType,
    utility
)
import numpy as np
import time
from typing import List, Tuple
```

---

## 第一部分: 批量插入策略对比

### 1. 单条插入（不推荐）

```python
def single_insert_test(collection: Collection, num_entities: int = 1000):
    """
    单条插入性能测试
    """
    print("=" * 60)
    print("测试 1: 单条插入（不推荐）")
    print("=" * 60)

    start_time = time.time()

    for i in range(num_entities):
        # 每次插入一条数据
        embedding = np.random.rand(128).tolist()
        text = f"单条插入测试数据 {i}"

        data = [
            [embedding],  # 单个向量
            [text]        # 单个文本
        ]

        collection.insert(data)

        # 每 100 条打印一次进度
        if (i + 1) % 100 == 0:
            print(f"  已插入 {i + 1}/{num_entities} 条数据")

    end_time = time.time()
    total_time = end_time - start_time

    print(f"\n单条插入结果:")
    print(f"  - 总数据量: {num_entities} 条")
    print(f"  - 总耗时: {total_time:.2f} 秒")
    print(f"  - 平均速度: {num_entities / total_time:.2f} 条/秒")
    print(f"  - 单条耗时: {total_time / num_entities * 1000:.2f} 毫秒")
    print()

    return total_time
```

---

### 2. 批量插入（推荐）

```python
def batch_insert_test(collection: Collection, num_entities: int = 10000, batch_size: int = 1000):
    """
    批量插入性能测试
    """
    print("=" * 60)
    print(f"测试 2: 批量插入（batch_size={batch_size}）")
    print("=" * 60)

    start_time = time.time()

    for i in range(0, num_entities, batch_size):
        # 准备批量数据
        current_batch_size = min(batch_size, num_entities - i)

        embeddings = np.random.rand(current_batch_size, 128).tolist()
        texts = [f"批量插入测试数据 {i + j}" for j in range(current_batch_size)]

        data = [embeddings, texts]

        # 批量插入
        collection.insert(data)

        print(f"  已插入 {min(i + batch_size, num_entities)}/{num_entities} 条数据")

    end_time = time.time()
    total_time = end_time - start_time

    print(f"\n批量插入结果:")
    print(f"  - 总数据量: {num_entities} 条")
    print(f"  - 批量大小: {batch_size} 条/批")
    print(f"  - 总耗时: {total_time:.2f} 秒")
    print(f"  - 平均速度: {num_entities / total_time:.2f} 条/秒")
    print(f"  - 单批耗时: {total_time / (num_entities / batch_size):.2f} 秒")
    print()

    return total_time
```

---

### 3. 不同批量大小对比

```python
def compare_batch_sizes(collection_name: str = "batch_size_test"):
    """
    对比不同批量大小的性能
    """
    print("=" * 60)
    print("批量大小性能对比")
    print("=" * 60)

    connections.connect(host="localhost", port="19530")

    # 测试配置
    num_entities = 10000
    batch_sizes = [100, 500, 1000, 2000, 5000]

    results = []

    for batch_size in batch_sizes:
        # 创建新 Collection
        if utility.has_collection(collection_name):
            utility.drop_collection(collection_name)

        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500)
        ]
        schema = CollectionSchema(fields)
        collection = Collection(collection_name, schema)

        # 测试插入
        print(f"\n测试 batch_size = {batch_size}")
        insert_time = batch_insert_test(collection, num_entities, batch_size)

        results.append({
            "batch_size": batch_size,
            "time": insert_time,
            "speed": num_entities / insert_time
        })

        # 清理
        utility.drop_collection(collection_name)

    # 打印对比结果
    print("\n" + "=" * 60)
    print("批量大小性能对比结果")
    print("=" * 60)
    print(f"{'批量大小':<15} {'耗时(秒)':<15} {'速度(条/秒)':<15} {'相对性能':<15}")
    print("-" * 60)

    baseline_speed = results[0]["speed"]
    for result in results:
        relative_perf = result["speed"] / baseline_speed
        print(f"{result['batch_size']:<15} {result['time']:<15.2f} {result['speed']:<15.2f} {relative_perf:<15.2f}x")

    print()
```

**输出示例**:
```
==============================================================
批量大小性能对比结果
==============================================================
批量大小           耗时(秒)         速度(条/秒)       相对性能
--------------------------------------------------------------
100            12.34          810.37         1.00x
500            3.45           2898.55        3.58x
1000           2.12           4716.98        5.82x
2000           1.89           5291.01        6.53x
5000           1.76           5681.82        7.01x
```

---

## 第二部分: 索引类型性能对比

### 1. 创建测试数据

```python
def prepare_test_collection(collection_name: str, num_entities: int = 50000):
    """
    准备测试 Collection 和数据
    """
    print("=" * 60)
    print("准备测试数据")
    print("=" * 60)

    connections.connect(host="localhost", port="19530")

    # 删除旧 Collection
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)

    # 创建 Collection
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500)
    ]
    schema = CollectionSchema(fields)
    collection = Collection(collection_name, schema)

    # 批量插入数据
    print(f"插入 {num_entities} 条数据...")
    batch_size = 5000
    for i in range(0, num_entities, batch_size):
        current_batch_size = min(batch_size, num_entities - i)
        embeddings = np.random.rand(current_batch_size, 128).tolist()
        texts = [f"测试数据 {i + j}" for j in range(current_batch_size)]
        collection.insert([embeddings, texts])
        print(f"  已插入 {min(i + batch_size, num_entities)}/{num_entities}")

    # 刷新数据
    collection.flush()
    print(f"数据准备完成，共 {collection.num_entities} 条\n")

    return collection
```

---

### 2. FLAT 索引测试

```python
def test_flat_index(collection: Collection):
    """
    测试 FLAT 索引性能
    """
    print("=" * 60)
    print("测试 FLAT 索引")
    print("=" * 60)

    # 删除旧索引
    if collection.has_index():
        collection.drop_index()

    # 创建 FLAT 索引
    index_params = {
        "index_type": "FLAT",
        "metric_type": "COSINE",
        "params": {}
    }

    print("创建 FLAT 索引...")
    start_time = time.time()
    collection.create_index("embedding", index_params)
    index_time = time.time() - start_time
    print(f"索引创建耗时: {index_time:.2f} 秒\n")

    # 加载到内存
    print("加载 Collection...")
    collection.load()

    # 测试检索性能
    print("测试检索性能...")
    query_vector = np.random.rand(128).tolist()
    search_params = {"metric_type": "COSINE", "params": {}}

    # 预热
    collection.search([query_vector], "embedding", search_params, limit=10)

    # 正式测试
    num_queries = 100
    start_time = time.time()
    for _ in range(num_queries):
        collection.search([query_vector], "embedding", search_params, limit=10)
    search_time = time.time() - start_time

    avg_latency = search_time / num_queries * 1000

    print(f"\nFLAT 索引结果:")
    print(f"  - 索引创建时间: {index_time:.2f} 秒")
    print(f"  - 平均检索延迟: {avg_latency:.2f} 毫秒")
    print(f"  - QPS: {num_queries / search_time:.2f}")
    print()

    collection.release()

    return {
        "index_type": "FLAT",
        "index_time": index_time,
        "avg_latency": avg_latency,
        "qps": num_queries / search_time
    }
```

---

### 3. IVF_FLAT 索引测试

```python
def test_ivf_flat_index(collection: Collection):
    """
    测试 IVF_FLAT 索引性能
    """
    print("=" * 60)
    print("测试 IVF_FLAT 索引")
    print("=" * 60)

    # 删除旧索引
    if collection.has_index():
        collection.drop_index()

    # 创建 IVF_FLAT 索引
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "COSINE",
        "params": {"nlist": 128}
    }

    print("创建 IVF_FLAT 索引...")
    start_time = time.time()
    collection.create_index("embedding", index_params)
    index_time = time.time() - start_time
    print(f"索引创建耗时: {index_time:.2f} 秒\n")

    # 加载到内存
    print("加载 Collection...")
    collection.load()

    # 测试检索性能
    print("测试检索性能...")
    query_vector = np.random.rand(128).tolist()
    search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}

    # 预热
    collection.search([query_vector], "embedding", search_params, limit=10)

    # 正式测试
    num_queries = 100
    start_time = time.time()
    for _ in range(num_queries):
        collection.search([query_vector], "embedding", search_params, limit=10)
    search_time = time.time() - start_time

    avg_latency = search_time / num_queries * 1000

    print(f"\nIVF_FLAT 索引结果:")
    print(f"  - 索引创建时间: {index_time:.2f} 秒")
    print(f"  - 平均检索延迟: {avg_latency:.2f} 毫秒")
    print(f"  - QPS: {num_queries / search_time:.2f}")
    print()

    collection.release()

    return {
        "index_type": "IVF_FLAT",
        "index_time": index_time,
        "avg_latency": avg_latency,
        "qps": num_queries / search_time
    }
```

---

### 4. HNSW 索引测试

```python
def test_hnsw_index(collection: Collection):
    """
    测试 HNSW 索引性能
    """
    print("=" * 60)
    print("测试 HNSW 索引")
    print("=" * 60)

    # 删除旧索引
    if collection.has_index():
        collection.drop_index()

    # 创建 HNSW 索引
    index_params = {
        "index_type": "HNSW",
        "metric_type": "COSINE",
        "params": {"M": 16, "efConstruction": 256}
    }

    print("创建 HNSW 索引...")
    start_time = time.time()
    collection.create_index("embedding", index_params)
    index_time = time.time() - start_time
    print(f"索引创建耗时: {index_time:.2f} 秒\n")

    # 加载到内存
    print("加载 Collection...")
    collection.load()

    # 测试检索性能
    print("测试检索性能...")
    query_vector = np.random.rand(128).tolist()
    search_params = {"metric_type": "COSINE", "params": {"ef": 64}}

    # 预热
    collection.search([query_vector], "embedding", search_params, limit=10)

    # 正式测试
    num_queries = 100
    start_time = time.time()
    for _ in range(num_queries):
        collection.search([query_vector], "embedding", search_params, limit=10)
    search_time = time.time() - start_time

    avg_latency = search_time / num_queries * 1000

    print(f"\nHNSW 索引结果:")
    print(f"  - 索引创建时间: {index_time:.2f} 秒")
    print(f"  - 平均检索延迟: {avg_latency:.2f} 毫秒")
    print(f"  - QPS: {num_queries / search_time:.2f}")
    print()

    collection.release()

    return {
        "index_type": "HNSW",
        "index_time": index_time,
        "avg_latency": avg_latency,
        "qps": num_queries / search_time
    }
```

---

### 5. 索引类型对比

```python
def compare_index_types():
    """
    对比不同索引类型的性能
    """
    collection_name = "index_comparison_test"

    # 准备测试数据
    collection = prepare_test_collection(collection_name, num_entities=50000)

    # 测试各种索引
    results = []
    results.append(test_flat_index(collection))
    results.append(test_ivf_flat_index(collection))
    results.append(test_hnsw_index(collection))

    # 打印对比结果
    print("=" * 80)
    print("索引类型性能对比结果")
    print("=" * 80)
    print(f"{'索引类型':<15} {'创建时间(秒)':<20} {'检索延迟(毫秒)':<20} {'QPS':<15}")
    print("-" * 80)

    for result in results:
        print(f"{result['index_type']:<15} {result['index_time']:<20.2f} "
              f"{result['avg_latency']:<20.2f} {result['qps']:<15.2f}")

    print()

    # 清理
    utility.drop_collection(collection_name)
```

**输出示例**:
```
================================================================================
索引类型性能对比结果
================================================================================
索引类型           创建时间(秒)          检索延迟(毫秒)        QPS
--------------------------------------------------------------------------------
FLAT           2.34                 45.67              21.90
IVF_FLAT       5.12                 8.23               121.55
HNSW           12.45                3.45               289.86
```

---

## 第三部分: HNSW 参数调优

### 1. ef 参数对检索性能的影响

```python
def test_hnsw_ef_parameter(collection_name: str = "hnsw_ef_test"):
    """
    测试 HNSW 索引的 ef 参数对检索性能的影响
    """
    print("=" * 60)
    print("HNSW ef 参数性能测试")
    print("=" * 60)

    # 准备测试数据
    collection = prepare_test_collection(collection_name, num_entities=50000)

    # 创建 HNSW 索引
    index_params = {
        "index_type": "HNSW",
        "metric_type": "COSINE",
        "params": {"M": 16, "efConstruction": 256}
    }
    collection.create_index("embedding", index_params)
    collection.load()

    # 测试不同 ef 值
    ef_values = [16, 32, 64, 128, 256]
    results = []

    for ef in ef_values:
        print(f"\n测试 ef = {ef}")

        query_vector = np.random.rand(128).tolist()
        search_params = {"metric_type": "COSINE", "params": {"ef": ef}}

        # 预热
        collection.search([query_vector], "embedding", search_params, limit=10)

        # 正式测试
        num_queries = 100
        start_time = time.time()
        for _ in range(num_queries):
            collection.search([query_vector], "embedding", search_params, limit=10)
        search_time = time.time() - start_time

        avg_latency = search_time / num_queries * 1000
        qps = num_queries / search_time

        print(f"  平均延迟: {avg_latency:.2f} 毫秒")
        print(f"  QPS: {qps:.2f}")

        results.append({
            "ef": ef,
            "avg_latency": avg_latency,
            "qps": qps
        })

    # 打印对比结果
    print("\n" + "=" * 60)
    print("ef 参数性能对比结果")
    print("=" * 60)
    print(f"{'ef 值':<15} {'检索延迟(毫秒)':<20} {'QPS':<15} {'相对延迟':<15}")
    print("-" * 60)

    baseline_latency = results[0]["avg_latency"]
    for result in results:
        relative_latency = result["avg_latency"] / baseline_latency
        print(f"{result['ef']:<15} {result['avg_latency']:<20.2f} "
              f"{result['qps']:<15.2f} {relative_latency:<15.2f}x")

    print()

    # 清理
    collection.release()
    utility.drop_collection(collection_name)
```

**输出示例**:
```
==============================================================
ef 参数性能对比结果
==============================================================
ef 值            检索延迟(毫秒)        QPS            相对延迟
--------------------------------------------------------------
16             2.34               427.35         1.00x
32             3.12               320.51         1.33x
64             4.56               219.30         1.95x
128            7.89               126.74         3.37x
256            14.23              70.27          6.08x
```

---

## 完整测试脚本

```python
"""
Milvus 批量插入与索引优化 - 完整测试
"""

from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
import numpy as np
import time


def main():
    """
    主函数：完整的性能测试流程
    """
    print("=" * 80)
    print("Milvus 批量插入与索引优化 - 性能测试")
    print("=" * 80)
    print()

    # 连接 Milvus
    connections.connect(host="localhost", port="19530")

    # 测试 1: 批量大小对比
    print("\n" + "=" * 80)
    print("第一部分: 批量插入策略对比")
    print("=" * 80)
    compare_batch_sizes()

    # 测试 2: 索引类型对比
    print("\n" + "=" * 80)
    print("第二部分: 索引类型性能对比")
    print("=" * 80)
    compare_index_types()

    # 测试 3: HNSW ef 参数调优
    print("\n" + "=" * 80)
    print("第三部分: HNSW ef 参数调优")
    print("=" * 80)
    test_hnsw_ef_parameter()

    print("\n" + "=" * 80)
    print("所有测试完成！")
    print("=" * 80)


if __name__ == "__main__":
    main()
```

---

## 性能优化建议

### 1. 批量插入优化

| 数据规模 | 推荐批量大小 | 预期速度 |
|---------|-------------|---------|
| < 1 万 | 1000 | 3000-5000 条/秒 |
| 1-10 万 | 2000-5000 | 5000-8000 条/秒 |
| > 10 万 | 5000-10000 | 8000-12000 条/秒 |

### 2. 索引选择建议

| 数据规模 | 推荐索引 | 创建时间 | 检索延迟 |
|---------|---------|---------|---------|
| < 1 万 | FLAT | 快 | 中 |
| 1-10 万 | IVF_FLAT | 中 | 快 |
| > 10 万 | HNSW | 慢 | 极快 |

### 3. HNSW 参数建议

| 场景 | M | efConstruction | ef | 特点 |
|------|---|----------------|----|----|
| 快速构建 | 8 | 128 | 32 | 构建快，精度低 |
| 平衡性能 | 16 | 256 | 64 | 推荐配置 |
| 高精度 | 32 | 512 | 128 | 构建慢，精度高 |

---

## 关键要点总结

1. **批量插入**: 批量大小 1000-5000 最优
2. **索引选择**: HNSW 适合大规模数据
3. **参数调优**: ef=64 是平衡点
4. **性能监控**: 关注 QPS 和延迟

---

## 下一步

学习 **实战代码 - 场景 3: 混合检索与过滤**，了解如何结合向量检索和标量过滤。
