# 核心概念1: 字典式并行执行

> **深入理解字典语法和并发执行机制**

---

## 概述

**字典式并行执行**是 RunnableParallel 的核心特性，它通过简洁的字典语法实现了复杂的并发执行逻辑。

**本文内容**：
- 字典字面量语法详解
- 自动转换机制
- 并发执行原理
- 与 asyncio.gather 的关系
- 性能特性分析

**学习目标**：
- 理解字典语法如何工作
- 掌握并发执行机制
- 理解底层实现原理
- 能够优化并行性能

---

## 字典字面量语法

### 基础语法

```python
# 最简单的字典语法
chain = {
    "key1": runnable1,
    "key2": runnable2,
}
```

**语法要素**：
- **键（key）**：字符串，定义输出字典的键名
- **值（value）**：Runnable 对象，定义要执行的任务
- **字典**：Python 原生字典字面量

---

### 自动转换机制

#### 转换过程

```python
# 步骤1：你写的代码
chain = {
    "task1": runnable1,
    "task2": runnable2,
}

# 步骤2：LCEL 自动识别
# 检测到字典，且值都是 Runnable

# 步骤3：自动转换
from langchain_core.runnables import RunnableParallel
chain = RunnableParallel(
    task1=runnable1,
    task2=runnable2,
)

# 步骤4：返回 RunnableParallel 实例
print(type(chain))  # <class 'RunnableParallel'>
```

---

#### 转换条件

**何时会自动转换？**

```python
# ✅ 会转换：字典的值都是 Runnable
chain = {
    "task1": ChatOpenAI(),
    "task2": ChatPromptTemplate.from_template("...") | model,
}

# ✅ 会转换：嵌套字典
chain = {
    "group1": {
        "task1a": runnable1a,
        "task1b": runnable1b,
    },
    "group2": runnable2,
}

# ❌ 不会转换：字典的值不是 Runnable
data = {
    "name": "Alice",
    "age": 30,
}
```

---

#### 转换时机

```python
# 转换发生在管道操作符 | 或 invoke 调用时
chain = {
    "task1": runnable1,
    "task2": runnable2,
}

# 此时还是普通字典
print(type(chain))  # <class 'dict'>

# 当与管道操作符结合时，自动转换
full_chain = chain | next_step
print(type(full_chain))  # <class 'RunnableSequence'>
print(type(full_chain.first))  # <class 'RunnableParallel'>

# 或者直接调用 invoke 时转换
result = chain.invoke(input)  # 自动转换并执行
```

---

### 语法变体

#### 变体1：内联定义

```python
# 直接在管道中使用字典
chain = (
    preprocess
    | {
        "task1": runnable1,
        "task2": runnable2,
    }
    | postprocess
)
```

---

#### 变体2：嵌套字典

```python
# 多层嵌套
chain = {
    "level1": {
        "level2a": {
            "level3": runnable3,
        },
        "level2b": runnable2b,
    },
    "task2": runnable2,
}

result = chain.invoke(input)
# {
#     "level1": {
#         "level2a": {"level3": ...},
#         "level2b": ...
#     },
#     "task2": ...
# }
```

---

#### 变体3：动态构造

```python
# 动态添加任务
tasks = {}
for i in range(n):
    tasks[f"task{i}"] = create_runnable(i)

chain = tasks  # 自动转换为 RunnableParallel
```

---

## 并发执行机制

### 执行流程

```python
# 用户代码
chain = {
    "task1": runnable1,
    "task2": runnable2,
    "task3": runnable3,
}

result = chain.invoke({"input": "data"})
```

**内部执行流程**：

```
1. 输入分发
   input = {"input": "data"}
   ├─> runnable1 接收 {"input": "data"}
   ├─> runnable2 接收 {"input": "data"}
   └─> runnable3 接收 {"input": "data"}

2. 并发执行
   ┌─ runnable1.invoke(input) ─┐
   ├─ runnable2.invoke(input) ─┤ 同时执行
   └─ runnable3.invoke(input) ─┘

3. 结果收集
   result1 ← runnable1
   result2 ← runnable2
   result3 ← runnable3

4. 映射为字典
   {
       "task1": result1,
       "task2": result2,
       "task3": result3,
   }
```

---

### 底层实现

#### 简化版实现

```python
from typing import Dict, Any
import asyncio

class RunnableParallel:
    def __init__(self, **steps):
        self.steps = steps

    def invoke(self, input: Any) -> Dict[str, Any]:
        """同步调用"""
        # 转换为异步调用
        return asyncio.run(self.ainvoke(input))

    async def ainvoke(self, input: Any) -> Dict[str, Any]:
        """异步调用"""
        # 创建所有任务
        tasks = {
            key: step.ainvoke(input)
            for key, step in self.steps.items()
        }

        # 并发执行所有任务
        results = await asyncio.gather(*tasks.values())

        # 映射为字典
        return dict(zip(tasks.keys(), results))
```

---

#### 关键点解析

**1. asyncio.gather 的作用**

```python
# asyncio.gather 并发执行多个协程
results = await asyncio.gather(
    coroutine1,
    coroutine2,
    coroutine3,
)
# results = [result1, result2, result3]
```

**特性**：
- 并发执行所有协程
- 等待所有协程完成
- 按顺序返回结果
- 一个失败，全部失败（默认）

---

**2. 输入复制**

```python
# 每个 Runnable 接收输入的副本
async def ainvoke(self, input: Any) -> Dict[str, Any]:
    tasks = {
        key: step.ainvoke(input)  # input 被复制
        for key, step in self.steps.items()
    }
```

**为什么复制？**
- 避免并发修改冲突
- 保证每个分支独立
- 防止状态共享问题

---

**3. 结果映射**

```python
# 保持键名和结果的对应关系
return dict(zip(tasks.keys(), results))

# 等价于
return {
    "task1": results[0],
    "task2": results[1],
    "task3": results[2],
}
```

---

### 并发 vs 并行

**重要区别**：

```python
# 并发（Concurrency）
# - 多个任务交替执行
# - 适合 I/O 密集型任务
# - Python asyncio 实现

async def concurrent():
    await asyncio.gather(
        api_call_1(),  # 等待 I/O 时释放控制权
        api_call_2(),  # 等待 I/O 时释放控制权
    )

# 并行（Parallelism）
# - 多个任务同时执行
# - 适合 CPU 密集型任务
# - Python multiprocessing 实现

from multiprocessing import Pool

def parallel():
    with Pool(2) as pool:
        pool.map(cpu_intensive_task, [data1, data2])
```

**RunnableParallel 使用并发**：
- 基于 asyncio.gather
- 适合 I/O 密集型任务（API 调用、数据库查询）
- CPU 密集型任务受 GIL 限制

---

## 完整示例

### 示例1: 基础并行执行

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv
import time

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 定义三个独立任务
summary_chain = ChatPromptTemplate.from_template(
    "用一句话总结以下文本:\n\n{text}"
) | model

keywords_chain = ChatPromptTemplate.from_template(
    "提取3-5个关键词:\n\n{text}"
) | model

sentiment_chain = ChatPromptTemplate.from_template(
    "分析情感倾向（积极/中性/消极）:\n\n{text}"
) | model

# 串行执行
print("=== 串行执行 ===")
start = time.time()
summary = summary_chain.invoke({"text": "LangChain 让 AI 开发更简单"})
keywords = keywords_chain.invoke({"text": "LangChain 让 AI 开发更简单"})
sentiment = sentiment_chain.invoke({"text": "LangChain 让 AI 开发更简单"})
serial_time = time.time() - start
print(f"串行时间: {serial_time:.2f}秒")
print(f"摘要: {summary.content}")
print(f"关键词: {keywords.content}")
print(f"情感: {sentiment.content}")

# 并行执行
print("\n=== 并行执行 ===")
start = time.time()
parallel_chain = {
    "summary": summary_chain,
    "keywords": keywords_chain,
    "sentiment": sentiment_chain,
}
result = parallel_chain.invoke({"text": "LangChain 让 AI 开发更简单"})
parallel_time = time.time() - start
print(f"并行时间: {parallel_time:.2f}秒")
print(f"摘要: {result['summary'].content}")
print(f"关键词: {result['keywords'].content}")
print(f"情感: {result['sentiment'].content}")

# 性能提升
improvement = (1 - parallel_time / serial_time) * 100
print(f"\n性能提升: {improvement:.1f}%")
```

**预期输出**：
```
=== 串行执行 ===
串行时间: 6.2秒
摘要: LangChain 简化了 AI 应用开发流程
关键词: LangChain, AI, 开发, 简化, 框架
情感: 积极

=== 并行执行 ===
并行时间: 2.8秒
摘要: LangChain 简化了 AI 应用开发流程
关键词: LangChain, AI, 开发, 简化, 框架
情感: 积极

性能提升: 54.8%
```

---

### 示例2: 嵌套并行

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 嵌套并行：分组执行
chain = {
    "content_analysis": {
        "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
        "keywords": ChatPromptTemplate.from_template("关键词: {text}") | model,
    },
    "sentiment_analysis": {
        "sentiment": ChatPromptTemplate.from_template("情感: {text}") | model,
        "tone": ChatPromptTemplate.from_template("语气: {text}") | model,
    },
    "metadata": {
        "length": RunnableLambda(lambda x: len(x["text"])),
        "word_count": RunnableLambda(lambda x: len(x["text"].split())),
    },
}

result = chain.invoke({"text": "LangChain 是一个强大的 AI 框架"})

print("内容分析:")
print(f"  摘要: {result['content_analysis']['summary'].content}")
print(f"  关键词: {result['content_analysis']['keywords'].content}")

print("\n情感分析:")
print(f"  情感: {result['sentiment_analysis']['sentiment'].content}")
print(f"  语气: {result['sentiment_analysis']['tone'].content}")

print("\n元数据:")
print(f"  长度: {result['metadata']['length']}")
print(f"  词数: {result['metadata']['word_count']}")
```

---

### 示例3: 动态并行

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

def create_analysis_chain(n: int):
    """动态创建 n 个分析任务"""
    tasks = {}
    for i in range(n):
        tasks[f"analysis_{i}"] = ChatPromptTemplate.from_template(
            f"从角度{i}分析: {{text}}"
        ) | model
    return tasks

# 创建5个并行分析任务
chain = create_analysis_chain(5)

result = chain.invoke({"text": "LangChain 的优势是什么？"})

for key, value in result.items():
    print(f"{key}: {value.content}")
```

---

## 性能特性

### I/O 密集型任务

```python
import time
from langchain_core.runnables import RunnableLambda

def simulate_io_task(duration: float):
    """模拟 I/O 任务（如 API 调用）"""
    def task(x):
        time.sleep(duration)
        return f"完成（{duration}秒）"
    return RunnableLambda(task)

# 串行执行
start = time.time()
r1 = simulate_io_task(1.0).invoke("input")
r2 = simulate_io_task(1.0).invoke("input")
r3 = simulate_io_task(1.0).invoke("input")
serial_time = time.time() - start
print(f"串行: {serial_time:.2f}秒")  # ~3秒

# 并行执行
start = time.time()
result = {
    "task1": simulate_io_task(1.0),
    "task2": simulate_io_task(1.0),
    "task3": simulate_io_task(1.0),
}.invoke("input")
parallel_time = time.time() - start
print(f"并行: {parallel_time:.2f}秒")  # ~1秒

print(f"提升: {(1 - parallel_time/serial_time) * 100:.1f}%")  # ~67%
```

---

### CPU 密集型任务

```python
import time
from langchain_core.runnables import RunnableLambda

def simulate_cpu_task():
    """模拟 CPU 密集型任务"""
    def task(x):
        result = 0
        for i in range(10000000):
            result += i
        return result
    return RunnableLambda(task)

# 串行执行
start = time.time()
r1 = simulate_cpu_task().invoke("input")
r2 = simulate_cpu_task().invoke("input")
r3 = simulate_cpu_task().invoke("input")
serial_time = time.time() - start
print(f"串行: {serial_time:.2f}秒")

# 并行执行
start = time.time()
result = {
    "task1": simulate_cpu_task(),
    "task2": simulate_cpu_task(),
    "task3": simulate_cpu_task(),
}.invoke("input")
parallel_time = time.time() - start
print(f"并行: {parallel_time:.2f}秒")

print(f"提升: {(1 - parallel_time/serial_time) * 100:.1f}%")
# CPU 密集型提升有限，因为 Python GIL
```

---

### 任务大小影响

```python
import time
from langchain_core.runnables import RunnableLambda

def benchmark_task_size(task_duration: float):
    """测试不同任务大小的并行效果"""
    def task(x):
        time.sleep(task_duration)
        return "done"

    # 串行
    start = time.time()
    for _ in range(3):
        RunnableLambda(task).invoke("input")
    serial_time = time.time() - start

    # 并行
    start = time.time()
    {
        "task1": RunnableLambda(task),
        "task2": RunnableLambda(task),
        "task3": RunnableLambda(task),
    }.invoke("input")
    parallel_time = time.time() - start

    improvement = (1 - parallel_time / serial_time) * 100
    return serial_time, parallel_time, improvement

# 测试不同任务大小
print("任务大小 | 串行 | 并行 | 提升")
print("-" * 40)
for duration in [0.001, 0.01, 0.1, 1.0]:
    serial, parallel, improvement = benchmark_task_size(duration)
    print(f"{duration:6.3f}s | {serial:.3f}s | {parallel:.3f}s | {improvement:5.1f}%")
```

**预期输出**：
```
任务大小 | 串行 | 并行 | 提升
----------------------------------------
 0.001s | 0.003s | 0.005s | -66.7%  # 微小任务，并行更慢
 0.010s | 0.030s | 0.015s |  50.0%
 0.100s | 0.300s | 0.105s |  65.0%
 1.000s | 3.000s | 1.005s |  66.5%  # 大任务，并行效果好
```

---

## 与 asyncio.gather 的对比

### 功能对比

| 特性 | RunnableParallel | asyncio.gather |
|------|-----------------|----------------|
| **编程范式** | 声明式 | 命令式 |
| **语法** | 字典 `{"key": runnable}` | `gather(coro1, coro2)` |
| **输出格式** | 字典 | 列表 |
| **键值映射** | 自动 | 手动 |
| **可组合性** | 与 LCEL 集成 | 独立使用 |
| **学习曲线** | 低 | 中 |

---

### 代码对比

```python
# RunnableParallel（声明式）
chain = {
    "summary": summary_chain,
    "keywords": keywords_chain,
}
result = chain.invoke({"text": "..."})
print(result["summary"])

# asyncio.gather（命令式）
async def manual_parallel(text):
    summary, keywords = await asyncio.gather(
        summary_chain.ainvoke({"text": text}),
        keywords_chain.ainvoke({"text": text}),
    )
    return {"summary": summary, "keywords": keywords}

result = asyncio.run(manual_parallel("..."))
print(result["summary"])
```

---

## 最佳实践

### 1. 优先使用字典语法

```python
# ✅ 推荐：字典语法
chain = {
    "task1": runnable1,
    "task2": runnable2,
}

# ⚠️ 可选：显式构造（语义更清晰）
from langchain_core.runnables import RunnableParallel
chain = RunnableParallel(
    task1=runnable1,
    task2=runnable2,
)
```

---

### 2. 使用描述性键名

```python
# ✅ 好：键名有意义
chain = {
    "user_profile": get_profile,
    "recent_posts": get_posts,
    "recommendations": get_recommendations,
}

# ❌ 不好：键名不清晰
chain = {
    "data1": get_profile,
    "x": get_posts,
    "result": get_recommendations,
}
```

---

### 3. 只并行独立任务

```python
# ✅ 正确：独立任务
chain = {
    "summary": summary_task,
    "keywords": keywords_task,
}

# ❌ 错误：有依赖关系
chain = {
    "retrieve": retriever,
    "generate": generator,  # 依赖 retrieve 的结果
}
```

---

### 4. 控制并发数量

```python
# ❌ 错误：无限制并发
chain = {f"task{i}": task for i in range(1000)}

# ✅ 正确：分批并行
async def batch_parallel(tasks, batch_size=10):
    results = {}
    for i in range(0, len(tasks), batch_size):
        batch = dict(list(tasks.items())[i:i+batch_size])
        batch_results = await batch.ainvoke(input)
        results.update(batch_results)
    return results
```

---

## 总结

### 核心要点

1. **字典语法**：最简洁的并行执行方式
2. **自动转换**：字典自动转换为 RunnableParallel
3. **并发执行**：基于 asyncio.gather 实现
4. **输入复制**：每个分支接收输入的副本
5. **字典输出**：结果自动映射为字典

### 性能特性

- **I/O 密集型**：提升 40-50%
- **CPU 密集型**：提升 10-20%（受 GIL 限制）
- **微小任务**：可能更慢（并行开销）
- **大任务**：提升明显

### 使用建议

- 优先并行 I/O 密集型任务
- 使用描述性键名
- 只并行独立任务
- 控制并发数量
- 根据实际测试决策

---

## 下一步学习

- [核心概念2: 键值映射](./03_核心概念_02_键值映射.md) - 输入分发和输出映射
- [核心概念3: 结果合并策略](./03_核心概念_03_结果合并策略.md) - 字典合并和错误处理
- [实战代码1: 基础并行执行](./07_实战代码_01_基础并行执行.md) - 完整可运行示例

---

## 参考资源

**官方文档**：
- [RunnableParallel API Reference](https://reference.langchain.com/v0.3/python/core/runnables/langchain_core.runnables.base.RunnableParallel.html)
- [asyncio.gather Documentation](https://docs.python.org/3/library/asyncio-task.html#asyncio.gather)

**2025-2026 最佳实践**：
- [Building Production-Ready AI Pipelines](https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557)

---

**版本**: v1.0
**最后更新**: 2026-02-19
**适用**: LangChain 0.3+, Python 3.13+
