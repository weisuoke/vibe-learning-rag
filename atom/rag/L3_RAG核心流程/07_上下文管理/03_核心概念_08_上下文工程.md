# 核心概念8：上下文工程

> **2026年从RAG到Context的演进**

---

## 什么是上下文工程？

**上下文工程（Context Engineering）** 是Anthropic在2026年提出的概念，指管理完整上下文状态和生命周期的系统化方法，是Prompt Engineering的自然演进。

**核心定义**：
```
Prompt Engineering: 单次请求的提示词优化
Context Engineering: 完整会话的上下文状态管理
```

---

## 从Prompt到Context的演进

### 演进历程

```
2022-2023: Prompt Engineering时代
- 聚焦单次请求
- 静态模板设计
- 关注指令清晰度

2024: RAG时代
- 检索 + 生成
- 外部知识注入
- 上下文管理初现

2025: 长上下文时代
- 百万级窗口
- 强检索协同
- 上下文优化

2026: Context Engineering时代
- 完整生命周期管理
- MCP协议标准化
- 智能上下文组装
```

### 核心区别

| 维度 | Prompt Engineering | Context Engineering |
|------|-------------------|---------------------|
| **范围** | 单次请求 | 完整生命周期 |
| **动态性** | 静态模板 | 智能组装 |
| **协议化** | 临时方案 | MCP标准化 |
| **状态管理** | 无 | 完整状态管理 |
| **数据源** | 单一 | 多源融合 |
| **优化目标** | 单次质量 | 系统效率 |

---

## 上下文工程的核心组件

### 组件1：上下文状态管理

```python
class ContextState:
    """上下文状态管理"""
    def __init__(self):
        self.conversation_history = []
        self.retrieved_documents = []
        self.user_preferences = {}
        self.session_metadata = {}
        self.external_resources = []

    def add_message(self, role: str, content: str):
        """添加对话消息"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now()
        })

    def add_documents(self, documents: list[str], source: str):
        """添加检索文档"""
        self.retrieved_documents.append({
            "documents": documents,
            "source": source,
            "timestamp": datetime.now()
        })

    def update_preferences(self, preferences: dict):
        """更新用户偏好"""
        self.user_preferences.update(preferences)

    def get_context_snapshot(self) -> dict:
        """获取上下文快照"""
        return {
            "history_length": len(self.conversation_history),
            "documents_count": sum(len(d["documents"]) for d in self.retrieved_documents),
            "preferences": self.user_preferences,
            "metadata": self.session_metadata
        }
```

### 组件2：智能上下文组装

```python
class ContextAssembler:
    """智能上下文组装器"""
    def __init__(self, max_tokens: int = 8000):
        self.max_tokens = max_tokens

    def assemble(
        self,
        query: str,
        state: ContextState,
        strategy: str = "adaptive"
    ) -> str:
        """
        智能组装上下文
        根据查询和状态动态选择内容
        """
        if strategy == "adaptive":
            return self._adaptive_assembly(query, state)
        elif strategy == "minimal":
            return self._minimal_assembly(query, state)
        elif strategy == "comprehensive":
            return self._comprehensive_assembly(query, state)
        else:
            return self._adaptive_assembly(query, state)

    def _adaptive_assembly(self, query: str, state: ContextState) -> str:
        """自适应组装"""
        components = []
        remaining_tokens = self.max_tokens

        # 1. 系统指令（固定）
        system = self._get_system_prompt()
        components.append(system)
        remaining_tokens -= count_tokens(system)

        # 2. 用户偏好（如果有）
        if state.user_preferences:
            prefs = self._format_preferences(state.user_preferences)
            if count_tokens(prefs) < remaining_tokens * 0.1:
                components.append(prefs)
                remaining_tokens -= count_tokens(prefs)

        # 3. 相关对话历史
        history = self._select_relevant_history(
            query,
            state.conversation_history,
            max_tokens=int(remaining_tokens * 0.3)
        )
        components.append(history)
        remaining_tokens -= count_tokens(history)

        # 4. 检索文档
        documents = self._select_relevant_documents(
            query,
            state.retrieved_documents,
            max_tokens=int(remaining_tokens * 0.6)
        )
        components.append(documents)

        # 5. 当前查询
        components.append(f"\n\n当前问题：{query}")

        return "\n\n".join(components)
```

### 组件3：上下文生命周期管理

```python
class ContextLifecycleManager:
    """上下文生命周期管理器"""
    def __init__(self):
        self.sessions = {}

    def create_session(self, session_id: str) -> ContextState:
        """创建会话"""
        state = ContextState()
        self.sessions[session_id] = {
            "state": state,
            "created_at": datetime.now(),
            "last_accessed": datetime.now()
        }
        return state

    def get_session(self, session_id: str) -> ContextState:
        """获取会话"""
        if session_id in self.sessions:
            self.sessions[session_id]["last_accessed"] = datetime.now()
            return self.sessions[session_id]["state"]
        else:
            return self.create_session(session_id)

    def cleanup_expired_sessions(self, max_age_hours: int = 24):
        """清理过期会话"""
        now = datetime.now()
        expired = []

        for session_id, session in self.sessions.items():
            age = (now - session["last_accessed"]).total_seconds() / 3600
            if age > max_age_hours:
                expired.append(session_id)

        for session_id in expired:
            del self.sessions[session_id]

        return len(expired)

    def persist_session(self, session_id: str, storage_path: str):
        """持久化会话"""
        if session_id in self.sessions:
            session = self.sessions[session_id]
            with open(storage_path, 'w') as f:
                json.dump({
                    "state": session["state"].__dict__,
                    "metadata": {
                        "created_at": session["created_at"].isoformat(),
                        "last_accessed": session["last_accessed"].isoformat()
                    }
                }, f)

    def restore_session(self, session_id: str, storage_path: str) -> ContextState:
        """恢复会话"""
        with open(storage_path, 'r') as f:
            data = json.load(f)

        state = ContextState()
        state.__dict__.update(data["state"])

        self.sessions[session_id] = {
            "state": state,
            "created_at": datetime.fromisoformat(data["metadata"]["created_at"]),
            "last_accessed": datetime.now()
        }

        return state
```

---

## MCP协议集成

### MCP概述

**Model Context Protocol (MCP)** 是Anthropic在2024年底推出的标准化上下文管理协议。

**核心特性**：
- 标准化的上下文接口
- 资源（Resources）管理
- 工具（Tools）集成
- 提示（Prompts）模板

### MCP资源管理

```python
from mcp import MCPServer, Resource

class MCPContextManager:
    """MCP上下文管理器"""
    def __init__(self):
        self.server = MCPServer()
        self.resources = {}

    def register_resource(
        self,
        uri: str,
        name: str,
        description: str,
        fetch_func: callable
    ):
        """注册MCP资源"""
        resource = Resource(
            uri=uri,
            name=name,
            description=description,
            mimeType="text/plain"
        )

        self.resources[uri] = {
            "resource": resource,
            "fetch_func": fetch_func
        }

        self.server.add_resource(resource)

    def fetch_resource(self, uri: str) -> str:
        """获取资源内容"""
        if uri in self.resources:
            fetch_func = self.resources[uri]["fetch_func"]
            return fetch_func()
        else:
            raise ValueError(f"Resource not found: {uri}")

    def list_resources(self) -> list[dict]:
        """列出所有资源"""
        return [
            {
                "uri": uri,
                "name": info["resource"].name,
                "description": info["resource"].description
            }
            for uri, info in self.resources.items()
        ]

# 使用示例
manager = MCPContextManager()

# 注册文档资源
manager.register_resource(
    uri="docs://company/policies",
    name="Company Policies",
    description="Internal company policies and guidelines",
    fetch_func=lambda: load_company_policies()
)

# 注册数据库资源
manager.register_resource(
    uri="db://users/profile",
    name="User Profile",
    description="Current user profile information",
    fetch_func=lambda: fetch_user_profile()
)

# 获取资源
policies = manager.fetch_resource("docs://company/policies")
```

### MCP工具集成

```python
from mcp import Tool

class MCPToolManager:
    """MCP工具管理器"""
    def __init__(self):
        self.tools = {}

    def register_tool(
        self,
        name: str,
        description: str,
        parameters: dict,
        execute_func: callable
    ):
        """注册MCP工具"""
        tool = Tool(
            name=name,
            description=description,
            inputSchema=parameters
        )

        self.tools[name] = {
            "tool": tool,
            "execute_func": execute_func
        }

    def execute_tool(self, name: str, arguments: dict) -> any:
        """执行工具"""
        if name in self.tools:
            execute_func = self.tools[name]["execute_func"]
            return execute_func(**arguments)
        else:
            raise ValueError(f"Tool not found: {name}")

# 使用示例
tool_manager = MCPToolManager()

# 注册搜索工具
tool_manager.register_tool(
    name="search_documents",
    description="Search internal documents",
    parameters={
        "type": "object",
        "properties": {
            "query": {"type": "string"},
            "limit": {"type": "integer", "default": 10}
        },
        "required": ["query"]
    },
    execute_func=lambda query, limit=10: search_docs(query, limit)
)

# 执行工具
results = tool_manager.execute_tool(
    "search_documents",
    {"query": "RAG best practices", "limit": 5}
)
```

---

## 完整上下文工程系统

### 系统架构

```python
class ContextEngineeringSystem:
    """完整的上下文工程系统"""
    def __init__(self):
        self.lifecycle_manager = ContextLifecycleManager()
        self.assembler = ContextAssembler()
        self.mcp_context = MCPContextManager()
        self.mcp_tools = MCPToolManager()

    def process_query(
        self,
        session_id: str,
        query: str,
        use_mcp: bool = True
    ) -> str:
        """处理查询"""
        # 1. 获取或创建会话
        state = self.lifecycle_manager.get_session(session_id)

        # 2. 如果启用MCP，获取相关资源
        if use_mcp:
            relevant_resources = self._fetch_relevant_mcp_resources(query)
            state.external_resources.extend(relevant_resources)

        # 3. 执行检索
        documents = self._retrieve_documents(query)
        state.add_documents(documents, source="vector_store")

        # 4. 智能组装上下文
        context = self.assembler.assemble(query, state, strategy="adaptive")

        # 5. 调用LLM
        response = self._call_llm(context)

        # 6. 更新状态
        state.add_message("user", query)
        state.add_message("assistant", response)

        return response

    def _fetch_relevant_mcp_resources(self, query: str) -> list[dict]:
        """获取相关的MCP资源"""
        # 简化实现：获取所有资源
        resources = self.mcp_context.list_resources()
        relevant = []

        for resource in resources:
            # 判断相关性（简化）
            if any(keyword in query.lower() for keyword in resource["description"].lower().split()):
                content = self.mcp_context.fetch_resource(resource["uri"])
                relevant.append({
                    "uri": resource["uri"],
                    "name": resource["name"],
                    "content": content
                })

        return relevant

    def _retrieve_documents(self, query: str) -> list[str]:
        """检索文档"""
        # 实际实现中调用向量存储
        return vector_store.similarity_search(query, k=5)

    def _call_llm(self, context: str) -> str:
        """调用LLM"""
        return llm.generate(context)
```

---

## 2026年最佳实践

### 实践1：多源上下文融合

```python
class MultiSourceContextFusion:
    """多源上下文融合"""
    def __init__(self):
        self.sources = {
            "vector_store": VectorStoreRetriever(),
            "knowledge_graph": KnowledgeGraphRetriever(),
            "mcp_resources": MCPResourceFetcher(),
            "web_search": WebSearchTool()
        }

    def fuse_context(self, query: str, max_tokens: int = 8000) -> str:
        """融合多源上下文"""
        results = {}

        # 1. 并行获取各源数据
        for source_name, source in self.sources.items():
            try:
                results[source_name] = source.retrieve(query)
            except Exception as e:
                print(f"Error fetching from {source_name}: {e}")
                results[source_name] = []

        # 2. 去重和排序
        all_items = []
        for source_name, items in results.items():
            for item in items:
                all_items.append({
                    "content": item,
                    "source": source_name,
                    "relevance": calculate_relevance(query, item)
                })

        # 去重
        unique_items = self._deduplicate(all_items)

        # 排序
        sorted_items = sorted(unique_items, key=lambda x: x["relevance"], reverse=True)

        # 3. 组装上下文
        context_parts = []
        current_tokens = 0

        for item in sorted_items:
            item_tokens = count_tokens(item["content"])
            if current_tokens + item_tokens <= max_tokens:
                context_parts.append(f"[来源: {item['source']}]\n{item['content']}")
                current_tokens += item_tokens
            else:
                break

        return "\n\n---\n\n".join(context_parts)

    def _deduplicate(self, items: list[dict]) -> list[dict]:
        """去重"""
        seen = set()
        unique = []

        for item in items:
            # 使用内容哈希去重
            content_hash = hashlib.md5(item["content"].encode()).hexdigest()
            if content_hash not in seen:
                seen.add(content_hash)
                unique.append(item)

        return unique
```

### 实践2：上下文版本控制

```python
class ContextVersionControl:
    """上下文版本控制"""
    def __init__(self):
        self.versions = {}

    def save_version(
        self,
        session_id: str,
        context: str,
        metadata: dict = None
    ) -> str:
        """保存上下文版本"""
        version_id = f"{session_id}_{datetime.now().isoformat()}"

        self.versions[version_id] = {
            "context": context,
            "metadata": metadata or {},
            "timestamp": datetime.now()
        }

        return version_id

    def get_version(self, version_id: str) -> dict:
        """获取特定版本"""
        return self.versions.get(version_id)

    def compare_versions(self, version_id1: str, version_id2: str) -> dict:
        """对比两个版本"""
        v1 = self.versions.get(version_id1)
        v2 = self.versions.get(version_id2)

        if not v1 or not v2:
            return {"error": "Version not found"}

        return {
            "version1": version_id1,
            "version2": version_id2,
            "token_diff": count_tokens(v2["context"]) - count_tokens(v1["context"]),
            "time_diff": (v2["timestamp"] - v1["timestamp"]).total_seconds()
        }

    def rollback(self, session_id: str, version_id: str) -> str:
        """回滚到特定版本"""
        version = self.versions.get(version_id)
        if version:
            return version["context"]
        else:
            raise ValueError(f"Version not found: {version_id}")
```

---

## 监控与优化

### 监控指标

```python
class ContextMetrics:
    """上下文指标监控"""
    def __init__(self):
        self.metrics = []

    def log(
        self,
        session_id: str,
        context_size: int,
        assembly_time: float,
        sources_used: list[str],
        quality_score: float
    ):
        """记录指标"""
        self.metrics.append({
            "session_id": session_id,
            "context_size": context_size,
            "assembly_time": assembly_time,
            "sources_used": sources_used,
            "quality_score": quality_score,
            "timestamp": datetime.now()
        })

    def report(self) -> dict:
        """生成报告"""
        if not self.metrics:
            return {}

        return {
            "avg_context_size": sum(m["context_size"] for m in self.metrics) / len(self.metrics),
            "avg_assembly_time": sum(m["assembly_time"] for m in self.metrics) / len(self.metrics),
            "avg_quality_score": sum(m["quality_score"] for m in self.metrics) / len(self.metrics),
            "total_sessions": len(set(m["session_id"] for m in self.metrics)),
            "source_usage": self._count_source_usage()
        }

    def _count_source_usage(self) -> dict:
        """统计数据源使用情况"""
        usage = {}
        for metric in self.metrics:
            for source in metric["sources_used"]:
                usage[source] = usage.get(source, 0) + 1
        return usage
```

---

## 总结

### 核心要点

1. **定义**：完整上下文生命周期管理，Prompt Engineering的演进
2. **组件**：状态管理、智能组装、生命周期管理
3. **MCP**：标准化协议，资源和工具集成
4. **趋势**：多源融合、版本控制、智能优化

### 记忆口诀

**"状态组装生命周期，MCP标准多源融合"**

### 下一步

理解了上下文工程后，接下来学习：
- **MCP协议集成**：深入MCP技术细节
- **生产级优化**：监控、调优、部署

---

**记住**：上下文工程是2026年AI应用的核心能力！
