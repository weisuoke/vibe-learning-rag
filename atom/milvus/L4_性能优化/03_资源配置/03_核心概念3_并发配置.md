# 核心概念3：并发配置

## 一句话定义

**并发配置是通过限制同时处理的请求数量和管理请求队列，在保证系统吞吐量的同时避免资源耗尽和性能下降。**

---

## 详细解释

### 为什么需要并发控制？

在向量检索系统中，**无限制的并发会导致系统崩溃**：

```
问题场景：
- 1000 个并发请求同时到达
- 每个请求需要 100MB 内存
- 总需求：100GB 内存
- 实际可用：16GB 内存
→ 结果：OOM（内存溢出），系统崩溃

解决方案：
- 限制最大并发：50
- 请求排队：超过 50 的请求进入队列
- 超时机制：队列等待超过 30s 的请求返回错误
→ 结果：系统稳定运行，吞吐量可控
```

### Milvus 的并发模型

```
┌─────────────────────────────────────────┐
│      Milvus 并发处理流程                │
├─────────────────────────────────────────┤
│ 1. 客户端请求                           │
│    ↓                                    │
│ 2. Proxy 接收（连接池）                 │
│    ↓                                    │
│ 3. 请求队列（限流）                     │
│    ↓                                    │
│ 4. QueryNode 处理（并发限制）           │
│    ↓                                    │
│ 5. 返回结果                             │
└─────────────────────────────────────────┘
```

---

## 核心配置参数

### 1. Proxy 并发配置

**Proxy** 是 Milvus 的网关，负责接收客户端请求。

```yaml
# milvus.yaml
proxy:
  # 最大并发连接数
  maxConnectionNum: 1000

  # 每个连接的最大并发请求数
  maxConcurrentRequests: 100

  # 请求队列大小
  requestQueueSize: 500

  # 请求超时时间（单位：秒）
  requestTimeout: 30
```

**Python 配置示例**：

```python
from pymilvus import connections

# 连接时配置并发参数
connections.connect(
    alias="default",
    host="localhost",
    port="19530",
    # 连接池大小
    pool_size=50,
    # 最大并发请求
    max_request_size=100
)
```

### 2. QueryNode 并发配置

**QueryNode** 负责执行查询，需要控制并发查询数。

```yaml
# milvus.yaml
queryNode:
  # 最大并发查询数
  maxConcurrentQueries: 50

  # 查询队列大小
  queryQueueSize: 200

  # 查询超时时间（单位：秒）
  queryTimeout: 10
```

**并发数计算公式**：

```python
def calculate_max_concurrent_queries(
    available_memory_gb: int,
    avg_query_memory_mb: int,
    cpu_cores: int
) -> int:
    """
    计算最大并发查询数

    参数：
    - available_memory_gb: 可用内存（GB）
    - avg_query_memory_mb: 平均每个查询的内存需求（MB）
    - cpu_cores: CPU 核心数

    返回：
    - 推荐的最大并发数
    """
    # 1. 基于内存的限制
    memory_limit = (available_memory_gb * 1024) // avg_query_memory_mb

    # 2. 基于 CPU 的限制（每个核心处理 2-4 个查询）
    cpu_limit = cpu_cores * 3

    # 3. 取较小值
    max_concurrent = min(memory_limit, cpu_limit)

    # 4. 安全余量（80%）
    safe_concurrent = int(max_concurrent * 0.8)

    return safe_concurrent


# 示例
max_queries = calculate_max_concurrent_queries(
    available_memory_gb=16,
    avg_query_memory_mb=200,
    cpu_cores=16
)

print(f"推荐最大并发数: {max_queries}")
# 输出: 推荐最大并发数: 38
```

### 3. 连接池配置

**连接池**管理客户端连接，避免频繁创建和销毁连接。

```python
"""
连接池配置示例
"""

from pymilvus import connections
import threading
import time

class MilvusConnectionPool:
    def __init__(
        self,
        host: str,
        port: str,
        pool_size: int = 10
    ):
        self.host = host
        self.port = port
        self.pool_size = pool_size
        self.connections = []
        self.lock = threading.Lock()

        # 初始化连接池
        self._init_pool()

    def _init_pool(self):
        """初始化连接池"""
        for i in range(self.pool_size):
            alias = f"conn_{i}"
            connections.connect(
                alias=alias,
                host=self.host,
                port=self.port
            )
            self.connections.append(alias)

    def get_connection(self) -> str:
        """获取一个连接"""
        with self.lock:
            if self.connections:
                return self.connections.pop()
            else:
                # 连接池已满，等待
                raise Exception("连接池已满，请稍后重试")

    def release_connection(self, alias: str):
        """释放连接"""
        with self.lock:
            self.connections.append(alias)


# 使用示例
pool = MilvusConnectionPool(
    host="localhost",
    port="19530",
    pool_size=10
)

# 获取连接
conn_alias = pool.get_connection()
print(f"获取连接: {conn_alias}")

# 使用连接执行查询
# ...

# 释放连接
pool.release_connection(conn_alias)
print(f"释放连接: {conn_alias}")
```

---

## 并发控制策略

### 1. 限流策略

```python
"""
令牌桶限流算法
"""

import time
import threading

class TokenBucket:
    def __init__(self, rate: int, capacity: int):
        """
        令牌桶限流器

        参数：
        - rate: 每秒生成的令牌数（QPS）
        - capacity: 桶的容量（最大突发请求数）
        """
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity
        self.last_time = time.time()
        self.lock = threading.Lock()

    def acquire(self) -> bool:
        """
        获取一个令牌

        返回：
        - True: 获取成功
        - False: 获取失败（限流）
        """
        with self.lock:
            now = time.time()
            # 计算新增的令牌数
            elapsed = now - self.last_time
            new_tokens = elapsed * self.rate
            self.tokens = min(self.capacity, self.tokens + new_tokens)
            self.last_time = now

            # 尝试获取令牌
            if self.tokens >= 1:
                self.tokens -= 1
                return True
            else:
                return False


# 示例：限制 QPS 为 100
limiter = TokenBucket(rate=100, capacity=200)

# 模拟请求
success_count = 0
reject_count = 0

for i in range(1000):
    if limiter.acquire():
        success_count += 1
        # 处理请求
    else:
        reject_count += 1
        # 拒绝请求

print(f"成功: {success_count}, 拒绝: {reject_count}")
```

### 2. 队列管理

```python
"""
请求队列管理
"""

import queue
import threading
import time

class RequestQueue:
    def __init__(
        self,
        max_size: int = 500,
        timeout: int = 30
    ):
        """
        请求队列

        参数：
        - max_size: 队列最大长度
        - timeout: 请求超时时间（秒）
        """
        self.queue = queue.Queue(maxsize=max_size)
        self.timeout = timeout

    def enqueue(self, request: dict) -> bool:
        """
        将请求加入队列

        返回：
        - True: 加入成功
        - False: 队列已满
        """
        try:
            self.queue.put(request, block=False)
            return True
        except queue.Full:
            return False

    def dequeue(self) -> dict:
        """
        从队列中取出请求

        返回：
        - 请求对象，如果超时则返回 None
        """
        try:
            request = self.queue.get(timeout=self.timeout)
            return request
        except queue.Empty:
            return None


# 示例：请求队列
request_queue = RequestQueue(max_size=500, timeout=30)

# 生产者：接收请求
def producer():
    for i in range(100):
        request = {"id": i, "query": f"query_{i}"}
        if request_queue.enqueue(request):
            print(f"请求 {i} 加入队列")
        else:
            print(f"请求 {i} 被拒绝（队列已满）")
        time.sleep(0.01)

# 消费者：处理请求
def consumer():
    while True:
        request = request_queue.dequeue()
        if request:
            print(f"处理请求 {request['id']}")
            time.sleep(0.1)  # 模拟处理时间
        else:
            break

# 启动生产者和消费者
producer_thread = threading.Thread(target=producer)
consumer_thread = threading.Thread(target=consumer)

producer_thread.start()
consumer_thread.start()

producer_thread.join()
consumer_thread.join()
```

### 3. 熔断机制

```python
"""
熔断器：当错误率过高时，自动停止请求
"""

import time
from enum import Enum

class CircuitState(Enum):
    CLOSED = "closed"      # 正常状态
    OPEN = "open"          # 熔断状态
    HALF_OPEN = "half_open"  # 半开状态（尝试恢复）

class CircuitBreaker:
    def __init__(
        self,
        failure_threshold: int = 5,
        timeout: int = 60
    ):
        """
        熔断器

        参数：
        - failure_threshold: 失败次数阈值
        - timeout: 熔断超时时间（秒）
        """
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED

    def call(self, func, *args, **kwargs):
        """
        执行函数调用，带熔断保护

        返回：
        - 函数执行结果
        """
        # 检查熔断状态
        if self.state == CircuitState.OPEN:
            # 检查是否可以尝试恢复
            if time.time() - self.last_failure_time > self.timeout:
                self.state = CircuitState.HALF_OPEN
                print("熔断器进入半开状态，尝试恢复")
            else:
                raise Exception("熔断器已打开，请求被拒绝")

        try:
            # 执行函数
            result = func(*args, **kwargs)

            # 成功，重置失败计数
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                print("熔断器恢复正常")
            self.failure_count = 0

            return result

        except Exception as e:
            # 失败，增加失败计数
            self.failure_count += 1
            self.last_failure_time = time.time()

            # 检查是否达到阈值
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"熔断器打开（失败次数: {self.failure_count}）")

            raise e


# 示例：使用熔断器
breaker = CircuitBreaker(failure_threshold=3, timeout=10)

def unstable_query():
    """模拟不稳定的查询"""
    import random
    if random.random() < 0.7:  # 70% 失败率
        raise Exception("查询失败")
    return "查询成功"

# 测试熔断器
for i in range(10):
    try:
        result = breaker.call(unstable_query)
        print(f"请求 {i}: {result}")
    except Exception as e:
        print(f"请求 {i}: {e}")
    time.sleep(1)
```

---

## 在 RAG 系统中的应用

### 场景：高并发文档检索

```python
"""
场景：电商平台商品搜索
- 峰值 QPS：5000
- 平均 QPS：1000
- 要求：P99 延迟 < 100ms
"""

from pymilvus import Collection, connections
import threading
import time

class ConcurrentRAGSystem:
    def __init__(
        self,
        collection_name: str,
        max_concurrent: int = 50
    ):
        self.collection = Collection(collection_name)
        self.max_concurrent = max_concurrent
        self.semaphore = threading.Semaphore(max_concurrent)
        self.limiter = TokenBucket(rate=1000, capacity=2000)

    def search(self, query_vector: list) -> dict:
        """
        并发控制的检索

        参数：
        - query_vector: 查询向量

        返回：
        - 检索结果
        """
        # 1. 限流检查
        if not self.limiter.acquire():
            return {
                "error": "请求过于频繁，请稍后重试",
                "status": 429
            }

        # 2. 并发控制
        acquired = self.semaphore.acquire(blocking=True, timeout=5)
        if not acquired:
            return {
                "error": "系统繁忙，请稍后重试",
                "status": 503
            }

        try:
            # 3. 执行检索
            start_time = time.time()

            results = self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=10
            )

            latency_ms = (time.time() - start_time) * 1000

            return {
                "results": results,
                "latency_ms": latency_ms,
                "status": 200
            }

        finally:
            # 4. 释放信号量
            self.semaphore.release()


# 示例：模拟高并发请求
connections.connect("default", host="localhost", port="19530")
rag_system = ConcurrentRAGSystem("product_search", max_concurrent=50)

def simulate_request(request_id: int):
    """模拟单个请求"""
    import numpy as np
    query_vector = np.random.rand(768).tolist()

    result = rag_system.search(query_vector)

    if result["status"] == 200:
        print(f"请求 {request_id}: 成功 ({result['latency_ms']:.2f}ms)")
    else:
        print(f"请求 {request_id}: {result['error']}")

# 模拟 100 个并发请求
threads = []
for i in range(100):
    thread = threading.Thread(target=simulate_request, args=(i,))
    threads.append(thread)
    thread.start()

# 等待所有请求完成
for thread in threads:
    thread.join()
```

---

## 总结

**并发配置的核心原则**：
1. **限制最大并发**：根据内存和 CPU 资源计算
2. **请求队列**：缓冲突发流量
3. **限流机制**：保护系统不被压垮
4. **熔断保护**：快速失败，避免雪崩
5. **监控告警**：实时跟踪并发指标
