# 实战代码：手写LRU缓存

> **从零实现生产级 LRU 缓存**

---

## 学习目标

- 掌握 LRU 缓存的两种实现方式
- 理解双向链表 + 哈希表的数据结构设计
- 能够手写 O(1) 时间复杂度的 LRU 缓存
- 了解线程安全和 TTL 扩展

---

## 实现1：使用 OrderedDict

### 基础版本

```python
from collections import OrderedDict
from typing import Any, Optional

class LRUCache:
    """LRU 缓存（OrderedDict 实现）"""

    def __init__(self, capacity: int):
        """
        初始化 LRU 缓存

        Args:
            capacity: 缓存容量
        """
        if capacity <= 0:
            raise ValueError("Capacity must be positive")

        self.cache = OrderedDict()
        self.capacity = capacity

    def get(self, key: str) -> Optional[Any]:
        """
        获取缓存值

        Args:
            key: 缓存键

        Returns:
            缓存值，如果不存在返回 None
        """
        if key not in self.cache:
            return None

        # 移到末尾（标记为最近使用）
        self.cache.move_to_end(key)
        return self.cache[key]

    def put(self, key: str, value: Any) -> None:
        """
        存入缓存

        Args:
            key: 缓存键
            value: 缓存值
        """
        if key in self.cache:
            # 更新已有数据
            self.cache.move_to_end(key)
        else:
            # 新增数据
            if len(self.cache) >= self.capacity:
                # 缓存已满，删除最久未使用的（第一个）
                self.cache.popitem(last=False)

        self.cache[key] = value

    def delete(self, key: str) -> bool:
        """
        删除缓存

        Args:
            key: 缓存键

        Returns:
            是否删除成功
        """
        if key in self.cache:
            del self.cache[key]
            return True
        return False

    def clear(self) -> None:
        """清空缓存"""
        self.cache.clear()

    def size(self) -> int:
        """获取当前缓存大小"""
        return len(self.cache)

    def keys(self) -> list:
        """获取所有键（按使用顺序）"""
        return list(self.cache.keys())

# 测试
if __name__ == "__main__":
    cache = LRUCache(capacity=3)

    # 测试基本操作
    cache.put("a", 1)
    cache.put("b", 2)
    cache.put("c", 3)
    print(f"缓存键: {cache.keys()}")  # ['a', 'b', 'c']

    # 访问 a，a 变成最近使用
    print(f"获取 a: {cache.get('a')}")  # 1
    print(f"缓存键: {cache.keys()}")  # ['b', 'c', 'a']

    # 添加 d，淘汰 b
    cache.put("d", 4)
    print(f"缓存键: {cache.keys()}")  # ['c', 'a', 'd']
    print(f"获取 b: {cache.get('b')}")  # None（已被淘汰）
```

**输出**：
```
缓存键: ['a', 'b', 'c']
获取 a: 1
缓存键: ['b', 'c', 'a']
缓存键: ['c', 'a', 'd']
获取 b: None
```

---

## 实现2：手写双向链表

### 节点定义

```python
class Node:
    """双向链表节点"""

    def __init__(self, key: str = "", value: Any = None):
        self.key = key
        self.value = value
        self.prev: Optional[Node] = None
        self.next: Optional[Node] = None

    def __repr__(self) -> str:
        return f"Node(key={self.key}, value={self.value})"
```

### 完整实现

```python
from typing import Any, Optional

class Node:
    """双向链表节点"""
    def __init__(self, key: str = "", value: Any = None):
        self.key = key
        self.value = value
        self.prev: Optional[Node] = None
        self.next: Optional[Node] = None

class LRUCache:
    """LRU 缓存（手写双向链表实现）"""

    def __init__(self, capacity: int):
        """
        初始化 LRU 缓存

        Args:
            capacity: 缓存容量
        """
        if capacity <= 0:
            raise ValueError("Capacity must be positive")

        self.capacity = capacity
        self.cache: dict[str, Node] = {}

        # 虚拟头尾节点（简化边界处理）
        self.head = Node()
        self.tail = Node()
        self.head.next = self.tail
        self.tail.prev = self.head

    def _add_to_head(self, node: Node) -> None:
        """将节点添加到头部（标记为最近使用）"""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node

    def _remove_node(self, node: Node) -> None:
        """从链表中移除节点"""
        node.prev.next = node.next
        node.next.prev = node.prev

    def _move_to_head(self, node: Node) -> None:
        """将节点移到头部"""
        self._remove_node(node)
        self._add_to_head(node)

    def _remove_tail(self) -> Node:
        """移除尾部节点（最久未使用）"""
        node = self.tail.prev
        self._remove_node(node)
        return node

    def get(self, key: str) -> Optional[Any]:
        """
        O(1) 获取缓存值

        Args:
            key: 缓存键

        Returns:
            缓存值，如果不存在返回 None
        """
        if key not in self.cache:
            return None

        node = self.cache[key]
        self._move_to_head(node)  # 标记为最近使用
        return node.value

    def put(self, key: str, value: Any) -> None:
        """
        O(1) 存入缓存

        Args:
            key: 缓存键
            value: 缓存值
        """
        if key in self.cache:
            # 更新已有节点
            node = self.cache[key]
            node.value = value
            self._move_to_head(node)
        else:
            # 新增节点
            node = Node(key, value)
            self.cache[key] = node
            self._add_to_head(node)

            if len(self.cache) > self.capacity:
                # 缓存已满，删除尾部节点
                removed = self._remove_tail()
                del self.cache[removed.key]

    def delete(self, key: str) -> bool:
        """
        删除缓存

        Args:
            key: 缓存键

        Returns:
            是否删除成功
        """
        if key not in self.cache:
            return False

        node = self.cache[key]
        self._remove_node(node)
        del self.cache[key]
        return True

    def clear(self) -> None:
        """清空缓存"""
        self.cache.clear()
        self.head.next = self.tail
        self.tail.prev = self.head

    def size(self) -> int:
        """获取当前缓存大小"""
        return len(self.cache)

    def keys(self) -> list:
        """获取所有键（按使用顺序，从最近到最久）"""
        keys = []
        node = self.head.next
        while node != self.tail:
            keys.append(node.key)
            node = node.next
        return keys

    def __repr__(self) -> str:
        return f"LRUCache(capacity={self.capacity}, size={self.size()}, keys={self.keys()})"

# 测试
if __name__ == "__main__":
    cache = LRUCache(capacity=2)

    cache.put("a", 1)
    cache.put("b", 2)
    print(cache.get("a"))  # 1

    cache.put("c", 3)  # 淘汰 b
    print(cache.get("b"))  # None

    cache.put("d", 4)  # 淘汰 a
    print(cache.get("a"))  # None
    print(cache.get("c"))  # 3
    print(cache.get("d"))  # 4

    print(cache)  # LRUCache(capacity=2, size=2, keys=['d', 'c'])
```

---

## 扩展1：线程安全版本

```python
import threading
from typing import Any, Optional

class ThreadSafeLRUCache(LRUCache):
    """线程安全的 LRU 缓存"""

    def __init__(self, capacity: int):
        super().__init__(capacity)
        self.lock = threading.RLock()  # 可重入锁

    def get(self, key: str) -> Optional[Any]:
        """线程安全的获取"""
        with self.lock:
            return super().get(key)

    def put(self, key: str, value: Any) -> None:
        """线程安全的存入"""
        with self.lock:
            super().put(key, value)

    def delete(self, key: str) -> bool:
        """线程安全的删除"""
        with self.lock:
            return super().delete(key)

    def clear(self) -> None:
        """线程安全的清空"""
        with self.lock:
            super().clear()

# 测试多线程
if __name__ == "__main__":
    import time

    cache = ThreadSafeLRUCache(capacity=100)

    def worker(thread_id: int):
        """工作线程"""
        for i in range(100):
            cache.put(f"key_{thread_id}_{i}", f"value_{thread_id}_{i}")
            cache.get(f"key_{thread_id}_{i}")

    # 创建10个线程
    threads = []
    for i in range(10):
        t = threading.Thread(target=worker, args=(i,))
        threads.append(t)
        t.start()

    # 等待所有线程完成
    for t in threads:
        t.join()

    print(f"最终缓存大小: {cache.size()}")  # 100
```

---

## 扩展2：带 TTL 的 LRU 缓存

```python
import time
from typing import Any, Optional

class NodeWithTTL:
    """带过期时间的节点"""
    def __init__(self, key: str = "", value: Any = None, ttl: Optional[float] = None):
        self.key = key
        self.value = value
        self.expire_time = time.time() + ttl if ttl else None
        self.prev: Optional[NodeWithTTL] = None
        self.next: Optional[NodeWithTTL] = None

    def is_expired(self) -> bool:
        """检查是否过期"""
        if self.expire_time is None:
            return False
        return time.time() > self.expire_time

class LRUCacheWithTTL:
    """带 TTL 的 LRU 缓存"""

    def __init__(self, capacity: int, default_ttl: Optional[float] = None):
        """
        初始化

        Args:
            capacity: 缓存容量
            default_ttl: 默认过期时间（秒），None 表示永不过期
        """
        self.capacity = capacity
        self.default_ttl = default_ttl
        self.cache: dict[str, NodeWithTTL] = {}

        self.head = NodeWithTTL()
        self.tail = NodeWithTTL()
        self.head.next = self.tail
        self.tail.prev = self.head

    def _add_to_head(self, node: NodeWithTTL) -> None:
        """添加到头部"""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node

    def _remove_node(self, node: NodeWithTTL) -> None:
        """移除节点"""
        node.prev.next = node.next
        node.next.prev = node.prev

    def _move_to_head(self, node: NodeWithTTL) -> None:
        """移到头部"""
        self._remove_node(node)
        self._add_to_head(node)

    def _remove_tail(self) -> NodeWithTTL:
        """移除尾部"""
        node = self.tail.prev
        self._remove_node(node)
        return node

    def get(self, key: str) -> Optional[Any]:
        """获取缓存（检查过期）"""
        if key not in self.cache:
            return None

        node = self.cache[key]

        # 检查是否过期
        if node.is_expired():
            self._remove_node(node)
            del self.cache[key]
            return None

        self._move_to_head(node)
        return node.value

    def put(self, key: str, value: Any, ttl: Optional[float] = None) -> None:
        """
        存入缓存

        Args:
            key: 缓存键
            value: 缓存值
            ttl: 过期时间（秒），None 使用默认值
        """
        if ttl is None:
            ttl = self.default_ttl

        if key in self.cache:
            node = self.cache[key]
            node.value = value
            node.expire_time = time.time() + ttl if ttl else None
            self._move_to_head(node)
        else:
            node = NodeWithTTL(key, value, ttl)
            self.cache[key] = node
            self._add_to_head(node)

            if len(self.cache) > self.capacity:
                removed = self._remove_tail()
                del self.cache[removed.key]

    def cleanup_expired(self) -> int:
        """清理过期数据"""
        expired_keys = []

        for key, node in self.cache.items():
            if node.is_expired():
                expired_keys.append(key)

        for key in expired_keys:
            node = self.cache[key]
            self._remove_node(node)
            del self.cache[key]

        return len(expired_keys)

# 测试 TTL
if __name__ == "__main__":
    cache = LRUCacheWithTTL(capacity=10, default_ttl=2)

    cache.put("key1", "value1", ttl=1)  # 1秒过期
    cache.put("key2", "value2", ttl=5)  # 5秒过期

    print(f"立即获取 key1: {cache.get('key1')}")  # value1

    time.sleep(1.5)
    print(f"1.5秒后获取 key1: {cache.get('key1')}")  # None（已过期）
    print(f"1.5秒后获取 key2: {cache.get('key2')}")  # value2

    # 清理过期数据
    cleaned = cache.cleanup_expired()
    print(f"清理了 {cleaned} 个过期数据")
```

---

## 扩展3：带统计的 LRU 缓存

```python
from dataclasses import dataclass
from typing import Any, Optional

@dataclass
class CacheStats:
    """缓存统计"""
    hits: int = 0
    misses: int = 0
    evictions: int = 0

    @property
    def hit_rate(self) -> float:
        """命中率"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0

    def __repr__(self) -> str:
        return (f"CacheStats(hits={self.hits}, misses={self.misses}, "
                f"evictions={self.evictions}, hit_rate={self.hit_rate:.2%})")

class MonitoredLRUCache(LRUCache):
    """带监控的 LRU 缓存"""

    def __init__(self, capacity: int):
        super().__init__(capacity)
        self.stats = CacheStats()

    def get(self, key: str) -> Optional[Any]:
        """获取缓存（记录统计）"""
        result = super().get(key)

        if result is not None:
            self.stats.hits += 1
        else:
            self.stats.misses += 1

        return result

    def put(self, key: str, value: Any) -> None:
        """存入缓存（记录淘汰）"""
        # 检查是否会触发淘汰
        will_evict = (key not in self.cache and len(self.cache) >= self.capacity)

        super().put(key, value)

        if will_evict:
            self.stats.evictions += 1

    def get_stats(self) -> CacheStats:
        """获取统计信息"""
        return self.stats

    def reset_stats(self) -> None:
        """重置统计"""
        self.stats = CacheStats()

# 测试统计
if __name__ == "__main__":
    cache = MonitoredLRUCache(capacity=3)

    # 模拟访问
    cache.put("a", 1)
    cache.put("b", 2)
    cache.put("c", 3)

    cache.get("a")  # 命中
    cache.get("a")  # 命中
    cache.get("d")  # 未命中

    cache.put("d", 4)  # 触发淘汰

    print(cache.get_stats())
    # CacheStats(hits=2, misses=1, evictions=1, hit_rate=66.67%)
```

---

## 完整测试套件

```python
import unittest

class TestLRUCache(unittest.TestCase):
    """LRU 缓存测试"""

    def setUp(self):
        """测试前准备"""
        self.cache = LRUCache(capacity=2)

    def test_basic_operations(self):
        """测试基本操作"""
        self.cache.put("a", 1)
        self.cache.put("b", 2)

        self.assertEqual(self.cache.get("a"), 1)
        self.assertEqual(self.cache.get("b"), 2)
        self.assertIsNone(self.cache.get("c"))

    def test_eviction(self):
        """测试淘汰策略"""
        self.cache.put("a", 1)
        self.cache.put("b", 2)
        self.cache.put("c", 3)  # 淘汰 a

        self.assertIsNone(self.cache.get("a"))
        self.assertEqual(self.cache.get("b"), 2)
        self.assertEqual(self.cache.get("c"), 3)

    def test_update_existing(self):
        """测试更新已有数据"""
        self.cache.put("a", 1)
        self.cache.put("a", 10)

        self.assertEqual(self.cache.get("a"), 10)

    def test_lru_order(self):
        """测试 LRU 顺序"""
        self.cache.put("a", 1)
        self.cache.put("b", 2)
        self.cache.get("a")  # a 变成最近使用
        self.cache.put("c", 3)  # 应该淘汰 b

        self.assertEqual(self.cache.get("a"), 1)
        self.assertIsNone(self.cache.get("b"))
        self.assertEqual(self.cache.get("c"), 3)

    def test_delete(self):
        """测试删除"""
        self.cache.put("a", 1)
        self.assertTrue(self.cache.delete("a"))
        self.assertIsNone(self.cache.get("a"))
        self.assertFalse(self.cache.delete("a"))

    def test_clear(self):
        """测试清空"""
        self.cache.put("a", 1)
        self.cache.put("b", 2)
        self.cache.clear()

        self.assertEqual(self.cache.size(), 0)
        self.assertIsNone(self.cache.get("a"))

    def test_capacity_zero(self):
        """测试容量为0"""
        with self.assertRaises(ValueError):
            LRUCache(capacity=0)

if __name__ == "__main__":
    unittest.main()
```

---

## 性能基准测试

```python
import time
import random

def benchmark_lru_cache():
    """性能基准测试"""
    cache = LRUCache(capacity=1000)

    # 测试写入性能
    start = time.time()
    for i in range(10000):
        cache.put(f"key_{i}", f"value_{i}")
    write_time = time.time() - start

    # 测试读取性能（命中）
    start = time.time()
    for i in range(10000):
        cache.get(f"key_{i % 1000}")
    read_hit_time = time.time() - start

    # 测试读取性能（未命中）
    start = time.time()
    for i in range(10000):
        cache.get(f"nonexistent_{i}")
    read_miss_time = time.time() - start

    print(f"写入 10000 次: {write_time:.3f}秒 ({10000/write_time:.0f} ops/s)")
    print(f"读取 10000 次（命中）: {read_hit_time:.3f}秒 ({10000/read_hit_time:.0f} ops/s)")
    print(f"读取 10000 次（未命中）: {read_miss_time:.3f}秒 ({10000/read_miss_time:.0f} ops/s)")

if __name__ == "__main__":
    benchmark_lru_cache()
```

**输出示例**：
```
写入 10000 次: 0.015秒 (666667 ops/s)
读取 10000 次（命中）: 0.012秒 (833333 ops/s)
读取 10000 次（未命中）: 0.008秒 (1250000 ops/s)
```

---

## 总结

### 两种实现对比

| 特性 | OrderedDict | 手写链表 |
|------|-------------|----------|
| **代码量** | 少（~30行） | 多（~100行） |
| **可读性** | 高 | 中等 |
| **面试认可度** | 低 | 高 |
| **性能** | 相同（O(1)） | 相同（O(1)） |
| **扩展性** | 低 | 高 |

### 关键要点

1. **数据结构选择**：哈希表 + 双向链表
2. **虚拟节点**：简化边界处理
3. **时间复杂度**：所有操作 O(1)
4. **线程安全**：使用锁保护
5. **TTL 支持**：记录过期时间

### 下一步

- 学习 LFU 缓存实现
- 了解多级缓存系统
- 实践 AI Agent 记忆管理

---

## 参考资源

- [LeetCode 146: LRU Cache](https://leetcode.com/problems/lru-cache/)
- [Python OrderedDict Documentation](https://docs.python.org/3/library/collections.html#collections.OrderedDict)
- [Redis LRU Implementation](https://redis.io/docs/reference/eviction/)
