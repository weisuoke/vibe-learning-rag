# 第一性原理

## 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题

不是问"别人用什么向量数据库"，而是问"为什么需要向量存储"。

---

## 向量存储的第一性原理

### 1. 最基础的定义

**向量存储 = 存储向量 + 快速找到相似向量**

仅此而已！没有更基础的了。

把这个定义拆开：
- **存储向量**：把高维浮点数数组保存下来
- **快速找到相似向量**：给定一个查询向量，找出最接近的 K 个

```python
# 最简单的"向量存储"
vectors = []  # 存储
vectors.append([0.1, 0.2, 0.3, ...])  # 添加

# 查询：找最相似的
def find_similar(query, vectors, k=5):
    distances = [cosine_distance(query, v) for v in vectors]
    return sorted(range(len(distances)), key=lambda i: distances[i])[:k]
```

### 2. 为什么需要向量存储？

**核心问题：如何在海量文本中快速找到语义相关的内容？**

让我们从三个约束条件推导：

#### 约束1：内存有限，向量需要持久化

```
┌─────────────────────────────────────────┐
│  100万个文档，每个 1536 维向量           │
│                                         │
│  内存占用：1,000,000 × 1536 × 4 bytes   │
│          = 6.14 GB                      │
│                                         │
│  问题：                                  │
│  - 程序重启，数据丢失                    │
│  - 内存不够，无法加载                    │
│  → 需要持久化到磁盘                      │
└─────────────────────────────────────────┘
```

#### 约束2：暴力搜索太慢，需要索引

```
┌─────────────────────────────────────────┐
│  暴力搜索复杂度：O(N × D)               │
│                                         │
│  N = 100万文档                          │
│  D = 1536 维度                          │
│                                         │
│  每次查询：100万 × 1536 = 15.36亿次运算  │
│  耗时：约 1-2 秒                         │
│                                         │
│  用户体验要求：< 100ms                   │
│  → 需要索引加速                          │
└─────────────────────────────────────────┘
```

#### 约束3：Embedding 计算成本高，不能重复计算

```python
# 不用向量存储：每次都要重新计算
def search_without_storage(query, documents):
    query_vec = embed(query)  # 1次 API 调用
    doc_vecs = [embed(doc) for doc in documents]  # N次 API 调用！
    return find_similar(query_vec, doc_vecs)

# 用向量存储：文档向量只算一次
def search_with_storage(query, vector_store):
    query_vec = embed(query)  # 1次 API 调用
    return vector_store.search(query_vec)  # 直接查，不用重算
```

### 3. 向量存储的三层价值

#### 价值1：持久化（Persistence）

**问题**：Embedding 计算成本高（调用 API 要钱，本地计算要时间）

**解决**：计算一次，存储起来，重复使用

```
计算成本对比：

不持久化（每次查询都重算）：
- 100万文档 × $0.0001/次 = $100/次查询
- 每天1000次查询 = $100,000/天

持久化（只算一次）：
- 100万文档 × $0.0001/次 = $100（一次性）
- 每天1000次查询 = $0/天（查询不需要重算）
```

#### 价值2：索引加速（Indexing）

**问题**：暴力搜索 O(N) 太慢

**解决**：建立索引，实现近似最近邻搜索（ANN）

| 数据规模 | 暴力搜索 | 索引搜索（HNSW） |
|----------|----------|-----------------|
| 1万条 | 10ms | 1ms |
| 100万条 | 1000ms | 5ms |
| 1亿条 | 100s | 50ms |

#### 价值3：元数据过滤（Metadata Filtering）

**问题**：只想在特定范围内搜索

**解决**：向量 + 元数据联合查询

```python
# 只在"技术文档"类别、2024年的文档中搜索
results = vector_store.search(
    query_vector,
    filter={"category": "技术文档", "year": 2024}
)
```

### 4. 从第一性原理推导 RAG 向量存储需求

**推理链：**

```
1. RAG 需要检索相关文档
   ↓
2. "相关"= 语义相似 = 向量距离近
   ↓
3. 文档量大（几万~几百万）
   ↓
4. 需要毫秒级响应（用户体验）
   ↓
5. 暴力搜索太慢 → 需要索引
   ↓
6. 向量不能每次重算 → 需要持久化
   ↓
7. 可能需要按条件过滤 → 需要元数据支持
   ↓
8. 结论：需要专门的向量存储系统
```

### 5. 一句话总结第一性原理

**向量存储的本质是解决"如何在海量高维向量中快速找到相似项"这个问题，通过持久化避免重复计算，通过索引实现亚线性搜索。**

---

## 第一性原理的实践指导

| 原理 | 实践指导 |
|------|----------|
| 内存有限 | 数据量大时必须用向量存储 |
| 暴力搜索太慢 | 选择支持 ANN 索引的向量库 |
| Embedding 成本高 | 持久化存储，避免重复计算 |
| 需要过滤 | 选择支持元数据过滤的向量库 |

---

## 什么时候不需要向量存储？

| 场景 | 是否需要 | 原因 |
|------|----------|------|
| 数据量 < 1000 条 | ❌ 可选 | 暴力搜索够快，内存放得下 |
| 一次性任务 | ❌ 可选 | 不需要持久化 |
| 数据量 > 1万条 | ✅ 需要 | 暴力搜索太慢 |
| 生产环境 | ✅ 需要 | 需要持久化和高可用 |

---

**核心洞察**：向量存储不是"高级功能"，而是 RAG 系统在数据量增长后的必然需求。

---

**下一步：** [03_核心概念](./03_核心概念.md) - 掌握索引类型、相似度度量、元数据过滤
