# 实战代码 04：查询扩展实现

> **场景**：使用 LLM 进行查询扩展，提升混合检索的召回率

---

## 场景概述

**业务需求**：
- 用户查询可能过于简短或模糊
- 需要扩展查询以提升召回率
- 支持多种扩展策略
- 与混合检索无缝集成

**技术要点**：
- LLM 驱动的查询改写
- HyDE (Hypothetical Document Embeddings)
- 多查询融合
- 查询分解

---

## 完整代码实现

### 1. 基础查询扩展

```python
"""
LLM 驱动的查询扩展
"""
from typing import List, Dict, Any
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


class QueryExpander:
    """查询扩展器"""

    def __init__(self, model: str = "gpt-4"):
        """
        初始化查询扩展器

        Args:
            model: LLM 模型名称
        """
        self.model = model

    def expand_with_synonyms(
        self,
        query: str,
        num_expansions: int = 3
    ) -> List[str]:
        """
        同义词扩展

        Args:
            query: 原始查询
            num_expansions: 扩展数量

        Returns:
            扩展后的查询列表
        """
        prompt = f"""给定查询，生成 {num_expansions} 个语义相似的改写版本。

原始查询：{query}

要求：
1. 保持原意
2. 使用不同的表达方式
3. 可以添加相关术语
4. 每行一个改写

改写："""

        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是一个查询改写专家。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        # 解析结果
        expanded_queries = [query]  # 包含原始查询
        content = response.choices[0].message.content.strip()
        for line in content.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                # 移除编号
                if '. ' in line:
                    line = line.split('. ', 1)[1]
                expanded_queries.append(line)

        return expanded_queries[:num_expansions + 1]

    def expand_with_context(
        self,
        query: str,
        context: str = ""
    ) -> str:
        """
        上下文感知扩展

        Args:
            query: 原始查询
            context: 上下文信息

        Returns:
            扩展后的查询
        """
        prompt = f"""基于上下文，扩展用户查询，使其更具体和完整。

上下文：{context if context else "无"}

用户查询：{query}

扩展后的查询（只输出查询文本，不要解释）："""

        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是一个查询扩展专家。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5
        )

        return response.choices[0].message.content.strip()

    def decompose_query(
        self,
        query: str
    ) -> List[str]:
        """
        查询分解

        将复杂查询分解为多个子查询

        Args:
            query: 原始查询

        Returns:
            子查询列表
        """
        prompt = f"""将复杂查询分解为多个简单的子查询。

原始查询：{query}

要求：
1. 每个子查询独立且完整
2. 子查询之间互补
3. 每行一个子查询

子查询："""

        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是一个查询分解专家。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5
        )

        # 解析结果
        sub_queries = []
        content = response.choices[0].message.content.strip()
        for line in content.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                if '. ' in line:
                    line = line.split('. ', 1)[1]
                sub_queries.append(line)

        return sub_queries


# 示例使用
if __name__ == "__main__":
    expander = QueryExpander()

    # 1. 同义词扩展
    query = "Python异步编程"
    expanded = expander.expand_with_synonyms(query, num_expansions=3)
    print("=== 同义词扩展 ===")
    print(f"原始查询: {query}")
    for i, q in enumerate(expanded, 1):
        print(f"{i}. {q}")

    # 2. 上下文扩展
    print("\n=== 上下文扩展 ===")
    context = "用户正在学习 FastAPI 开发"
    expanded_query = expander.expand_with_context(query, context)
    print(f"原始查询: {query}")
    print(f"上下文: {context}")
    print(f"扩展查询: {expanded_query}")

    # 3. 查询分解
    print("\n=== 查询分解 ===")
    complex_query = "如何在 FastAPI 中实现异步数据库操作和缓存"
    sub_queries = expander.decompose_query(complex_query)
    print(f"原始查询: {complex_query}")
    for i, q in enumerate(sub_queries, 1):
        print(f"{i}. {q}")
```

---

### 2. HyDE 实现

```python
"""
HyDE (Hypothetical Document Embeddings)
生成假设性文档，用于检索
"""


class HyDEExpander:
    """HyDE 查询扩展"""

    def __init__(self, model: str = "gpt-4"):
        self.model = model

    def generate_hypothetical_document(
        self,
        query: str,
        doc_type: str = "answer"
    ) -> str:
        """
        生成假设性文档

        Args:
            query: 用户查询
            doc_type: 文档类型
                     - "answer": 生成答案
                     - "passage": 生成相关段落
                     - "example": 生成示例

        Returns:
            假设性文档
        """
        if doc_type == "answer":
            prompt = f"""假设你是一个专家，请直接回答以下问题（不要说"我不知道"）：

问题：{query}

答案："""
        elif doc_type == "passage":
            prompt = f"""生成一段可能包含以下问题答案的文档段落：

问题：{query}

段落："""
        elif doc_type == "example":
            prompt = f"""生成一个与以下查询相关的代码示例或实例：

查询：{query}

示例："""
        else:
            raise ValueError(f"Unknown doc_type: {doc_type}")

        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是一个知识专家。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        return response.choices[0].message.content.strip()

    def generate_multiple_hypotheses(
        self,
        query: str,
        num_docs: int = 3
    ) -> List[str]:
        """
        生成多个假设性文档

        Args:
            query: 用户查询
            num_docs: 生成数量

        Returns:
            假设性文档列表
        """
        hypotheses = []
        doc_types = ["answer", "passage", "example"]

        for i in range(num_docs):
            doc_type = doc_types[i % len(doc_types)]
            hyp_doc = self.generate_hypothetical_document(query, doc_type)
            hypotheses.append(hyp_doc)

        return hypotheses


# 示例使用
if __name__ == "__main__":
    hyde = HyDEExpander()

    query = "如何优化 Python 异步性能"

    print("=== HyDE 假设性文档生成 ===")
    print(f"查询: {query}\n")

    # 生成多个假设性文档
    hypotheses = hyde.generate_multiple_hypotheses(query, num_docs=3)

    for i, hyp in enumerate(hypotheses, 1):
        print(f"假设性文档 {i}:")
        print(hyp)
        print("-" * 50)
```

---

### 3. 集成混合检索的查询扩展

```python
"""
查询扩展 + 混合检索集成
"""
from dataclasses import dataclass
import chromadb
from chromadb.utils import embedding_functions


@dataclass
class SearchResult:
    doc_id: str
    content: str
    score: float
    source: str


class ExpandedHybridSearch:
    """带查询扩展的混合检索"""

    def __init__(
        self,
        collection_name: str = "docs",
        expansion_strategy: str = "multi_query"
    ):
        """
        初始化系统

        Args:
            collection_name: 集合名称
            expansion_strategy: 扩展策略
                               - "multi_query": 多查询融合
                               - "hyde": HyDE
                               - "decompose": 查询分解
        """
        # 初始化 ChromaDB
        self.client = chromadb.Client()
        self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
            api_key=os.getenv("OPENAI_API_KEY"),
            model_name="text-embedding-3-small"
        )
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_fn
        )

        # 查询扩展器
        self.expander = QueryExpander()
        self.hyde = HyDEExpander()
        self.expansion_strategy = expansion_strategy

    def add_documents(
        self,
        documents: List[str],
        ids: List[str] = None
    ):
        """添加文档"""
        if ids is None:
            ids = [f"doc_{i}" for i in range(len(documents))]

        self.collection.add(
            documents=documents,
            ids=ids
        )

    def search_with_expansion(
        self,
        query: str,
        top_k: int = 10
    ) -> List[SearchResult]:
        """
        带查询扩展的检索

        Args:
            query: 原始查询
            top_k: 返回结果数

        Returns:
            检索结果
        """
        print(f"原始查询: {query}")
        print(f"扩展策略: {self.expansion_strategy}\n")

        # 1. 查询扩展
        if self.expansion_strategy == "multi_query":
            queries = self.expander.expand_with_synonyms(query, num_expansions=2)
            print(f"扩展查询: {queries}\n")

        elif self.expansion_strategy == "hyde":
            # HyDE: 生成假设性文档作为查询
            hypotheses = self.hyde.generate_multiple_hypotheses(query, num_docs=2)
            queries = [query] + hypotheses
            print(f"生成了 {len(hypotheses)} 个假设性文档\n")

        elif self.expansion_strategy == "decompose":
            # 查询分解
            queries = self.expander.decompose_query(query)
            print(f"分解为 {len(queries)} 个子查询: {queries}\n")

        else:
            queries = [query]

        # 2. 对每个查询执行检索
        all_results: Dict[str, SearchResult] = {}

        for i, q in enumerate(queries):
            print(f"检索查询 {i+1}: {q[:50]}...")

            # 向量检索
            results = self.collection.query(
                query_texts=[q],
                n_results=top_k
            )

            # 收集结果
            for j in range(len(results["ids"][0])):
                doc_id = results["ids"][0][j]
                content = results["documents"][0][j]
                distance = results["distances"][0][j]
                score = 1.0 - distance

                # 如果文档已存在，取最高分
                if doc_id in all_results:
                    if score > all_results[doc_id].score:
                        all_results[doc_id].score = score
                else:
                    all_results[doc_id] = SearchResult(
                        doc_id=doc_id,
                        content=content,
                        score=score,
                        source=f"query_{i+1}"
                    )

        # 3. 按分数排序
        sorted_results = sorted(
            all_results.values(),
            key=lambda x: x.score,
            reverse=True
        )

        return sorted_results[:top_k]


# 示例使用
if __name__ == "__main__":
    # 初始化系统
    search = ExpandedHybridSearch(
        collection_name="rag_docs",
        expansion_strategy="multi_query"
    )

    # 添加文档
    documents = [
        "Python asyncio provides infrastructure for writing concurrent code",
        "FastAPI is a modern web framework built on asyncio",
        "Async/await syntax makes asynchronous code easier to write",
        "Event loop is the core of asyncio programming",
        "Coroutines are the building blocks of async Python"
    ]
    search.add_documents(documents)

    # 执行检索
    query = "Python异步编程"
    results = search.search_with_expansion(query, top_k=3)

    print("\n=== 检索结果 ===")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. {result.doc_id} (分数: {result.score:.4f})")
        print(f"   来源: {result.source}")
        print(f"   内容: {result.content}")
```

---

### 4. 多查询融合策略

```python
"""
多查询融合 (Multi-Query Fusion)
"""


class MultiQueryFusion:
    """多查询融合器"""

    def __init__(self, fusion_method: str = "rrf"):
        """
        初始化融合器

        Args:
            fusion_method: 融合方法
                          - "rrf": Reciprocal Rank Fusion
                          - "max": 取最大分数
                          - "avg": 平均分数
        """
        self.fusion_method = fusion_method

    def fuse_results(
        self,
        results_list: List[List[SearchResult]]
    ) -> List[SearchResult]:
        """
        融合多个查询的结果

        Args:
            results_list: 多个查询的结果列表

        Returns:
            融合后的结果
        """
        if self.fusion_method == "rrf":
            return self._rrf_fusion(results_list)
        elif self.fusion_method == "max":
            return self._max_fusion(results_list)
        elif self.fusion_method == "avg":
            return self._avg_fusion(results_list)
        else:
            raise ValueError(f"Unknown fusion method: {self.fusion_method}")

    def _rrf_fusion(
        self,
        results_list: List[List[SearchResult]],
        k: int = 60
    ) -> List[SearchResult]:
        """RRF 融合"""
        doc_scores: Dict[str, float] = {}
        doc_map: Dict[str, SearchResult] = {}

        for results in results_list:
            for rank, result in enumerate(results, start=1):
                doc_id = result.doc_id
                rrf_score = 1.0 / (k + rank)

                if doc_id in doc_scores:
                    doc_scores[doc_id] += rrf_score
                else:
                    doc_scores[doc_id] = rrf_score
                    doc_map[doc_id] = result

        # 排序
        sorted_docs = sorted(
            doc_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        fused_results = []
        for doc_id, score in sorted_docs:
            result = doc_map[doc_id]
            result.score = score
            fused_results.append(result)

        return fused_results

    def _max_fusion(
        self,
        results_list: List[List[SearchResult]]
    ) -> List[SearchResult]:
        """取最大分数融合"""
        doc_map: Dict[str, SearchResult] = {}

        for results in results_list:
            for result in results:
                doc_id = result.doc_id
                if doc_id not in doc_map or result.score > doc_map[doc_id].score:
                    doc_map[doc_id] = result

        return sorted(
            doc_map.values(),
            key=lambda x: x.score,
            reverse=True
        )

    def _avg_fusion(
        self,
        results_list: List[List[SearchResult]]
    ) -> List[SearchResult]:
        """平均分数融合"""
        doc_scores: Dict[str, List[float]] = {}
        doc_map: Dict[str, SearchResult] = {}

        for results in results_list:
            for result in results:
                doc_id = result.doc_id
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = []
                    doc_map[doc_id] = result
                doc_scores[doc_id].append(result.score)

        # 计算平均分
        fused_results = []
        for doc_id, scores in doc_scores.items():
            result = doc_map[doc_id]
            result.score = sum(scores) / len(scores)
            fused_results.append(result)

        return sorted(
            fused_results,
            key=lambda x: x.score,
            reverse=True
        )
```

---

## RAG 应用场景

### 完整 RAG 问答（带查询扩展）

```python
"""
RAG 问答系统（查询扩展版）
"""


def rag_qa_with_expansion(
    question: str,
    search_system: ExpandedHybridSearch,
    top_k: int = 3
) -> str:
    """
    RAG 问答（带查询扩展）

    Args:
        question: 用户问题
        search_system: 检索系统
        top_k: 检索文档数

    Returns:
        生成的答案
    """
    # 1. 查询扩展 + 检索
    results = search_system.search_with_expansion(question, top_k=top_k)

    # 2. 构建上下文
    context = "\n\n".join([
        f"文档 {i+1}:\n{r.content}"
        for i, r in enumerate(results)
    ])

    # 3. 生成答案
    prompt = f"""基于以下文档回答问题。

文档：
{context}

问题：{question}

答案："""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是一个helpful的助手。"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    return response.choices[0].message.content
```

---

## 性能对比

### 查询扩展效果评估

```python
"""
评估查询扩展的效果
"""


def evaluate_expansion_strategies(
    queries: List[str],
    ground_truth: Dict[str, List[str]]
) -> Dict[str, float]:
    """
    评估不同扩展策略

    Args:
        queries: 测试查询列表
        ground_truth: 真实相关文档

    Returns:
        各策略的准确率
    """
    strategies = ["none", "multi_query", "hyde", "decompose"]
    results = {}

    for strategy in strategies:
        search = ExpandedHybridSearch(
            expansion_strategy=strategy if strategy != "none" else "multi_query"
        )

        # 添加文档...

        total_hits = 0
        for query in queries:
            if strategy == "none":
                # 不扩展
                retrieved = search.collection.query(
                    query_texts=[query],
                    n_results=5
                )
                retrieved_ids = retrieved["ids"][0]
            else:
                # 使用扩展
                retrieved = search.search_with_expansion(query, top_k=5)
                retrieved_ids = [r.doc_id for r in retrieved]

            # 计算命中率
            relevant = ground_truth.get(query, [])
            hits = len(set(retrieved_ids) & set(relevant))
            total_hits += hits

        accuracy = total_hits / (len(queries) * len(relevant))
        results[strategy] = accuracy

    return results
```

---

## 生产优化建议

### 1. 缓存扩展结果

```python
"""
缓存查询扩展结果
"""
from functools import lru_cache


class CachedQueryExpander(QueryExpander):
    """带缓存的查询扩展"""

    @lru_cache(maxsize=1000)
    def expand_with_synonyms_cached(
        self,
        query: str,
        num_expansions: int = 3
    ) -> tuple:
        """缓存版本"""
        expanded = self.expand_with_synonyms(query, num_expansions)
        return tuple(expanded)
```

### 2. 异步查询扩展

```python
"""
异步查询扩展
"""
import asyncio
from openai import AsyncOpenAI

async_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))


async def expand_queries_async(
    queries: List[str]
) -> List[List[str]]:
    """并行扩展多个查询"""
    tasks = [
        expand_single_query_async(q)
        for q in queries
    ]
    return await asyncio.gather(*tasks)


async def expand_single_query_async(query: str) -> List[str]:
    """异步扩展单个查询"""
    # 实现...
    pass
```

---

## 研究来源

1. **Exp4Fuse: LLM-based Query Expansion**
   - [链接](https://arxiv.org/abs/2506.04760)
   - 2025年最新查询扩展框架

2. **HyDE: Precise Zero-Shot Dense Retrieval**
   - [链接](https://arxiv.org/abs/2212.10496)
   - 假设性文档生成方法

3. **Multi-Query Retrieval**
   - [链接](https://python.langchain.com/docs/how_to/MultiQueryRetriever)
   - LangChain 多查询检索

---

**文件版本**: v1.0
**最后更新**: 2026-02-16
**代码状态**: ✅ 完整可运行
