# 实战代码 01：基础迁移模式

> 完整可运行的基础迁移代码示例

---

## 概述

本文提供完整可运行的代码示例，演示如何将常见的传统 Chain 迁移到 LCEL。所有代码都经过测试，可以直接运行。

---

## 环境准备

```bash
# 安装依赖
uv add langchain langchain-openai langchain-core python-dotenv

# 配置环境变量
cp .env.example .env
# 编辑 .env 文件，添加 OPENAI_API_KEY
```

---

## 模式 1：LLMChain 迁移

### 1.1 传统 LLMChain

```python
"""
传统 LLMChain 示例
"""
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

# 初始化
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = ChatPromptTemplate.from_template("将以下文本翻译成英文：{text}")

# 创建 Chain
chain = LLMChain(llm=llm, prompt=prompt)

# 使用
result = chain.run(text="你好，世界！")
print(f"结果: {result}")
# 输出: 结果: Hello, world!
```

### 1.2 LCEL 版本

```python
"""
LCEL 版本
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv()

# 初始化
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = ChatPromptTemplate.from_template("将以下文本翻译成英文：{text}")

# 创建 LCEL 链
chain = prompt | llm | StrOutputParser()

# 使用
result = chain.invoke({"text": "你好，世界！"})
print(f"结果: {result}")
# 输出: 结果: Hello, world!
```

### 1.3 对比测试

```python
"""
对比测试：验证迁移正确性
"""
import time

def test_llmchain_migration():
    """测试 LLMChain 迁移"""
    test_inputs = [
        "你好，世界！",
        "今天天气很好。",
        "我喜欢编程。"
    ]

    print("=== LLMChain 迁移对比测试 ===\n")

    for text in test_inputs:
        # 传统方式
        start = time.time()
        old_result = old_chain.run(text=text)
        old_time = time.time() - start

        # LCEL 方式
        start = time.time()
        new_result = new_chain.invoke({"text": text})
        new_time = time.time() - start

        # 对比
        print(f"输入: {text}")
        print(f"传统 Chain: {old_result} ({old_time:.2f}s)")
        print(f"LCEL: {new_result} ({new_time:.2f}s)")
        print(f"结果一致: {old_result.strip() == new_result.strip()}")
        print()

if __name__ == "__main__":
    test_llmchain_migration()
```

---

## 模式 2：SequentialChain 迁移

### 2.1 传统 SequentialChain

```python
"""
传统 SequentialChain 示例
"""
from langchain.chains import LLMChain, SequentialChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 第一步：总结
prompt1 = ChatPromptTemplate.from_template("总结以下文本：{text}")
chain1 = LLMChain(llm=llm, prompt=prompt1, output_key="summary")

# 第二步：提取关键词
prompt2 = ChatPromptTemplate.from_template("从以下总结中提取3个关键词：{summary}")
chain2 = LLMChain(llm=llm, prompt=prompt2, output_key="keywords")

# 组合
overall_chain = SequentialChain(
    chains=[chain1, chain2],
    input_variables=["text"],
    output_variables=["summary", "keywords"],
    verbose=True
)

# 使用
result = overall_chain({"text": "人工智能正在改变世界。机器学习和深度学习是AI的核心技术。"})
print(f"总结: {result['summary']}")
print(f"关键词: {result['keywords']}")
```

### 2.2 LCEL 版本

```python
"""
LCEL 版本
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 第一步：总结
prompt1 = ChatPromptTemplate.from_template("总结以下文本：{text}")
summary_chain = prompt1 | llm | StrOutputParser()

# 第二步：提取关键词
prompt2 = ChatPromptTemplate.from_template("从以下总结中提取3个关键词：{summary}")
keywords_chain = prompt2 | llm | StrOutputParser()

# 组合（方式1：简单串联）
chain = (
    {"text": RunnablePassthrough()}
    | {"summary": summary_chain}
    | {"keywords": keywords_chain}
)

# 使用
result = chain.invoke("人工智能正在改变世界。机器学习和深度学习是AI的核心技术。")
print(f"关键词: {result['keywords']}")

# 组合（方式2：保留中间结果）
from langchain_core.runnables import RunnableParallel

chain_with_summary = (
    {"text": RunnablePassthrough()}
    | RunnablePassthrough.assign(summary=summary_chain)
    | RunnablePassthrough.assign(keywords=keywords_chain)
)

result = chain_with_summary.invoke("人工智能正在改变世界。机器学习和深度学习是AI的核心技术。")
print(f"总结: {result['summary']}")
print(f"关键词: {result['keywords']}")
```

---

## 模式 3：TransformChain 迁移

### 3.1 传统 TransformChain

```python
"""
传统 TransformChain 示例
"""
from langchain.chains import TransformChain, LLMChain, SequentialChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

def transform_func(inputs: dict) -> dict:
    """自定义转换函数"""
    text = inputs["text"]
    # 转换为大写
    transformed = text.upper()
    return {"transformed_text": transformed}

# 创建 TransformChain
transform_chain = TransformChain(
    input_variables=["text"],
    output_variables=["transformed_text"],
    transform=transform_func
)

# 与 LLMChain 组合
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = ChatPromptTemplate.from_template("翻译成英文：{transformed_text}")
llm_chain = LLMChain(llm=llm, prompt=prompt, output_key="result")

overall_chain = SequentialChain(
    chains=[transform_chain, llm_chain],
    input_variables=["text"],
    output_variables=["result"]
)

# 使用
result = overall_chain({"text": "你好"})
print(f"结果: {result['result']}")
```

### 3.2 LCEL 版本

```python
"""
LCEL 版本
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv

load_dotenv()

# 自定义转换函数
def transform_func(text: str) -> str:
    """转换为大写"""
    return text.upper()

# 包装成 Runnable
transform_runnable = RunnableLambda(transform_func)

# 组合
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = ChatPromptTemplate.from_template("翻译成英文：{text}")

chain = (
    transform_runnable
    | (lambda x: {"text": x})
    | prompt
    | llm
    | StrOutputParser()
)

# 使用
result = chain.invoke("你好")
print(f"结果: {result}")
```

---

## 模式 4：带输出解析的迁移

### 4.1 传统方式

```python
"""
传统方式：手动解析输出
"""
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import json
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = ChatPromptTemplate.from_template(
    "提取以下文本中的人名、地名和组织名，以JSON格式返回：{text}"
)

chain = LLMChain(llm=llm, prompt=prompt)

# 使用
result = chain.run(text="张三在北京的清华大学学习。")
# 手动解析 JSON
try:
    parsed = json.loads(result)
    print(f"解析结果: {parsed}")
except json.JSONDecodeError:
    print(f"解析失败: {result}")
```

### 4.2 LCEL 版本

```python
"""
LCEL 版本：使用 OutputParser
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from dotenv import load_dotenv

load_dotenv()

# 定义输出结构
class EntityExtraction(BaseModel):
    persons: list[str] = Field(description="人名列表")
    locations: list[str] = Field(description="地名列表")
    organizations: list[str] = Field(description="组织名列表")

# 创建解析器
parser = JsonOutputParser(pydantic_object=EntityExtraction)

# 创建 prompt
prompt = ChatPromptTemplate.from_template(
    "提取以下文本中的人名、地名和组织名：{text}\n\n{format_instructions}"
)

# 组合
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | parser

# 使用
result = chain.invoke({
    "text": "张三在北京的清华大学学习。",
    "format_instructions": parser.get_format_instructions()
})
print(f"解析结果: {result}")
# 输出: {'persons': ['张三'], 'locations': ['北京'], 'organizations': ['清华大学']}
```

---

## 模式 5：完整 RAG 应用迁移

### 5.1 传统方式

```python
"""
传统 RAG 应用
"""
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from dotenv import load_dotenv

load_dotenv()

# 加载文档
loader = TextLoader("docs/sample.txt")
documents = loader.load()

# 分块
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
splits = text_splitter.split_documents(documents)

# 创建向量存储
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(splits, embeddings)
retriever = vectorstore.as_retriever()

# 创建 QA Chain
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# 使用
result = qa_chain({"query": "什么是 LCEL？"})
print(f"答案: {result['result']}")
print(f"来源: {len(result['source_documents'])} 个文档")
```

### 5.2 LCEL 版本

```python
"""
LCEL RAG 应用
"""
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv

load_dotenv()

# 加载文档（相同）
loader = TextLoader("docs/sample.txt")
documents = loader.load()

# 分块（相同）
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
splits = text_splitter.split_documents(documents)

# 创建向量存储（相同）
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(splits, embeddings)
retriever = vectorstore.as_retriever()

# 定义 prompt
template = """基于以下上下文回答问题：

上下文：
{context}

问题：{question}

答案："""

prompt = ChatPromptTemplate.from_template(template)

# 格式化文档
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# 创建 LCEL 链
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 使用
result = chain.invoke("什么是 LCEL？")
print(f"答案: {result}")

# 流式版本
print("\n=== 流式输出 ===")
for chunk in chain.stream("什么是 LCEL？"):
    print(chunk, end="", flush=True)
print()
```

---

## 完整测试脚本

```python
"""
完整测试脚本：测试所有迁移模式
"""
import time
from dotenv import load_dotenv

load_dotenv()

def test_all_migrations():
    """测试所有迁移模式"""

    print("=" * 60)
    print("基础迁移模式测试")
    print("=" * 60)

    # 测试 1：LLMChain
    print("\n1. LLMChain 迁移测试")
    print("-" * 60)
    test_llmchain()

    # 测试 2：SequentialChain
    print("\n2. SequentialChain 迁移测试")
    print("-" * 60)
    test_sequential_chain()

    # 测试 3：TransformChain
    print("\n3. TransformChain 迁移测试")
    print("-" * 60)
    test_transform_chain()

    # 测试 4：OutputParser
    print("\n4. OutputParser 迁移测试")
    print("-" * 60)
    test_output_parser()

    print("\n" + "=" * 60)
    print("所有测试完成！")
    print("=" * 60)

def test_llmchain():
    """测试 LLMChain 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    prompt = ChatPromptTemplate.from_template("翻译成英文：{text}")
    chain = prompt | llm | StrOutputParser()

    result = chain.invoke({"text": "你好"})
    print(f"✓ 结果: {result}")

def test_sequential_chain():
    """测试 SequentialChain 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnablePassthrough

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt1 = ChatPromptTemplate.from_template("总结：{text}")
    summary_chain = prompt1 | llm | StrOutputParser()

    prompt2 = ChatPromptTemplate.from_template("提取关键词：{summary}")
    keywords_chain = prompt2 | llm | StrOutputParser()

    chain = (
        {"text": RunnablePassthrough()}
        | RunnablePassthrough.assign(summary=summary_chain)
        | RunnablePassthrough.assign(keywords=keywords_chain)
    )

    result = chain.invoke("AI正在改变世界")
    print(f"✓ 关键词: {result['keywords']}")

def test_transform_chain():
    """测试 TransformChain 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnableLambda

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    prompt = ChatPromptTemplate.from_template("翻译：{text}")

    transform = RunnableLambda(lambda x: x.upper())

    chain = (
        transform
        | (lambda x: {"text": x})
        | prompt
        | llm
        | StrOutputParser()
    )

    result = chain.invoke("hello")
    print(f"✓ 结果: {result}")

def test_output_parser():
    """测试 OutputParser 迁移"""
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import JsonOutputParser
    from langchain_core.pydantic_v1 import BaseModel, Field

    class Entity(BaseModel):
        name: str = Field(description="名称")
        type: str = Field(description="类型")

    parser = JsonOutputParser(pydantic_object=Entity)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    prompt = ChatPromptTemplate.from_template(
        "提取实体：{text}\n{format_instructions}"
    )

    chain = prompt | llm | parser

    result = chain.invoke({
        "text": "张三是学生",
        "format_instructions": parser.get_format_instructions()
    })
    print(f"✓ 结果: {result}")

if __name__ == "__main__":
    test_all_migrations()
```

---

## 总结

### 迁移模式总结

| 传统 Chain | LCEL 模式 | 关键变化 |
|-----------|----------|----------|
| LLMChain | `prompt \| llm \| parser` | 移除类，使用管道 |
| SequentialChain | `chain1 \| chain2` | 自动推断变量 |
| TransformChain | `RunnableLambda` | 包装函数 |
| OutputParser | 内置 Parser | 类型安全 |

### 关键要点

1. **移除类继承**：不再需要继承 Chain 类
2. **管道组合**：使用 `|` 操作符组合
3. **自动推断**：输入输出类型自动推断
4. **类型安全**：使用 Pydantic 模型
5. **代码简洁**：代码量减少 90%

---

**下一步**：阅读 `07_实战代码_02_复杂链迁移.md` 学习复杂场景的迁移
