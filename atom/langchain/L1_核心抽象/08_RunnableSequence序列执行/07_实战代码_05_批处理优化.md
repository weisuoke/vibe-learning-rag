# 实战代码5：批处理优化

> 批量文档评估和分析

---

## 场景描述

**目标**：构建一个高效的批量文档评估系统，使用批处理优化性能。

**功能需求**：
1. 批量加载文档
2. 并行评估质量
3. 性能对比分析
4. 成本优化
5. 结果汇总

---

## 完整代码

```python
"""
批处理优化示例
演示：使用 batch 提升性能和降低成本
"""

import os
import time
import json
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from typing import List, Dict

load_dotenv()

# ===== 1. 准备测试文档 =====
print("=== 步骤1: 准备测试文档 ===\n")

test_documents = [
    {
        "id": 1,
        "title": "人工智能的未来",
        "content": "人工智能技术正在快速发展，将深刻改变我们的生活和工作方式。"
    },
    {
        "id": 2,
        "title": "气候变化挑战",
        "content": "全球气候变化是人类面临的严峻挑战，需要立即采取行动。"
    },
    {
        "id": 3,
        "title": "量子计算突破",
        "content": "量子计算技术的突破将revolutionize计算领域，解决传统计算机无法处理的问题。"
    },
    {
        "id": 4,
        "title": "可再生能源发展",
        "content": "太阳能和风能等可再生能源技术不断进步，为可持续发展提供了新的可能。"
    },
    {
        "id": 5,
        "title": "生物技术创新",
        "content": "基因编辑和合成生物学等技术的发展，为医疗和农业带来了革命性变化。"
    },
    {
        "id": 6,
        "title": "区块链应用",
        "content": "区块链技术不仅应用于加密货币，还在供应链、金融等领域展现出巨大潜力。"
    },
    {
        "id": 7,
        "title": "5G网络部署",
        "content": "5G网络的广泛部署将推动物联网、自动驾驶等新兴技术的发展。"
    },
    {
        "id": 8,
        "title": "太空探索进展",
        "content": "商业航天的兴起和火星探测任务的成功，标志着人类太空探索进入新时代。"
    },
    {
        "id": 9,
        "title": "教育技术革新",
        "content": "在线教育和AI辅助学习正在改变传统教育模式，使教育更加个性化和普及化。"
    },
    {
        "id": 10,
        "title": "智慧城市建设",
        "content": "物联网、大数据和AI技术的结合，正在推动智慧城市的建设和发展。"
    }
]

print(f"准备了 {len(test_documents)} 个测试文档")
for doc in test_documents[:3]:
    print(f"  {doc['id']}. {doc['title']}")
print(f"  ...")
print()

# ===== 2. 构建评估链 =====
print("=== 步骤2: 构建评估链 ===\n")

eval_prompt = ChatPromptTemplate.from_template("""
请评估以下文档的质量（1-10分）：

标题：{title}
内容：{content}

评估标准：
1. 内容清晰度
2. 信息价值
3. 语言质量

请以 JSON 格式返回：
{{
  "score": 8,
  "reason": "..."
}}
""")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
parser = StrOutputParser()

eval_chain = (
    eval_prompt
    | llm
    | parser
)

print("评估链构建完成")
print()

# ===== 3. 方法1：循环执行（串行）=====
print("=== 步骤3: 方法1 - 循环执行（串行）===\n")

def evaluate_serial(documents: List[Dict]) -> List[Dict]:
    """串行评估"""
    results = []

    start = time.time()
    for doc in documents:
        result_str = eval_chain.invoke({
            "title": doc["title"],
            "content": doc["content"]
        })
        result = json.loads(result_str)
        results.append({
            "id": doc["id"],
            "title": doc["title"],
            "score": result["score"],
            "reason": result["reason"]
        })

    duration = time.time() - start
    return results, duration

print("执行串行评估...")
serial_results, serial_time = evaluate_serial(test_documents)

print(f"完成！耗时: {serial_time:.2f}秒")
print(f"平均每个文档: {serial_time / len(test_documents):.2f}秒")
print()

print("评估结果（前3个）:")
for result in serial_results[:3]:
    print(f"  {result['id']}. {result['title']}: {result['score']}/10")
print()

# ===== 4. 方法2：批处理（并行）=====
print("=== 步骤4: 方法2 - 批处理（并行）===\n")

def evaluate_batch(documents: List[Dict]) -> List[Dict]:
    """批处理评估"""
    start = time.time()

    # 准备批量输入
    inputs = [
        {
            "title": doc["title"],
            "content": doc["content"]
        }
        for doc in documents
    ]

    # 批量执行
    results_str = eval_chain.batch(inputs)

    # 解析结果
    results = []
    for doc, result_str in zip(documents, results_str):
        result = json.loads(result_str)
        results.append({
            "id": doc["id"],
            "title": doc["title"],
            "score": result["score"],
            "reason": result["reason"]
        })

    duration = time.time() - start
    return results, duration

print("执行批处理评估...")
batch_results, batch_time = evaluate_batch(test_documents)

print(f"完成！耗时: {batch_time:.2f}秒")
print(f"平均每个文档: {batch_time / len(test_documents):.2f}秒")
print()

print("评估结果（前3个）:")
for result in batch_results[:3]:
    print(f"  {result['id']}. {result['title']}: {result['score']}/10")
print()

# ===== 5. 性能对比 =====
print("=== 步骤5: 性能对比 ===\n")

print("性能对比:")
print(f"  串行执行: {serial_time:.2f}秒")
print(f"  批处理: {batch_time:.2f}秒")
print(f"  加速比: {serial_time / batch_time:.2f}x")
print(f"  时间节省: {(1 - batch_time / serial_time) * 100:.1f}%")
print()

# ===== 6. 控制并发数 =====
print("=== 步骤6: 控制并发数 ===\n")

def evaluate_batch_with_concurrency(
    documents: List[Dict],
    max_concurrency: int = 5
) -> List[Dict]:
    """批处理评估（控制并发数）"""
    start = time.time()

    inputs = [
        {
            "title": doc["title"],
            "content": doc["content"]
        }
        for doc in documents
    ]

    # 批量执行，控制并发数
    results_str = eval_chain.batch(
        inputs,
        config={"max_concurrency": max_concurrency}
    )

    results = []
    for doc, result_str in zip(documents, results_str):
        result = json.loads(result_str)
        results.append({
            "id": doc["id"],
            "title": doc["title"],
            "score": result["score"],
            "reason": result["reason"]
        })

    duration = time.time() - start
    return results, duration

# 测试不同并发数
concurrency_levels = [3, 5, 10]

print("测试不同并发数:")
for max_concurrency in concurrency_levels:
    results, duration = evaluate_batch_with_concurrency(
        test_documents,
        max_concurrency=max_concurrency
    )
    print(f"  并发数 {max_concurrency}: {duration:.2f}秒")

print()

# ===== 7. 分批处理大量文档 =====
print("=== 步骤7: 分批处理大量文档 ===\n")

def evaluate_in_chunks(
    documents: List[Dict],
    chunk_size: int = 5
) -> List[Dict]:
    """分批处理大量文档"""
    all_results = []

    total_chunks = (len(documents) + chunk_size - 1) // chunk_size

    for i in range(0, len(documents), chunk_size):
        chunk = documents[i:i + chunk_size]
        chunk_num = i // chunk_size + 1

        print(f"  处理批次 {chunk_num}/{total_chunks} ({len(chunk)} 个文档)...")

        inputs = [
            {
                "title": doc["title"],
                "content": doc["content"]
            }
            for doc in chunk
        ]

        results_str = eval_chain.batch(inputs)

        for doc, result_str in zip(chunk, results_str):
            result = json.loads(result_str)
            all_results.append({
                "id": doc["id"],
                "title": doc["title"],
                "score": result["score"],
                "reason": result["reason"]
            })

    return all_results

print("分批处理（每批5个）:")
start = time.time()
chunked_results = evaluate_in_chunks(test_documents, chunk_size=5)
chunked_time = time.time() - start

print(f"完成！总耗时: {chunked_time:.2f}秒")
print()

# ===== 8. 错误处理的批处理 =====
print("=== 步骤8: 错误处理的批处理 ===\n")

def safe_evaluate_batch(documents: List[Dict]) -> tuple:
    """安全的批处理评估"""
    results = []
    errors = []

    for doc in documents:
        try:
            result_str = eval_chain.invoke({
                "title": doc["title"],
                "content": doc["content"]
            })
            result = json.loads(result_str)
            results.append({
                "id": doc["id"],
                "title": doc["title"],
                "score": result["score"],
                "reason": result["reason"],
                "success": True
            })
        except Exception as e:
            results.append({
                "id": doc["id"],
                "title": doc["title"],
                "success": False,
                "error": str(e)
            })
            errors.append({
                "id": doc["id"],
                "error": str(e)
            })

    return results, errors

print("执行安全批处理...")
safe_results, safe_errors = safe_evaluate_batch(test_documents)

print(f"成功: {sum(1 for r in safe_results if r.get('success'))}/{len(test_documents)}")
print(f"失败: {len(safe_errors)}")
print()

# ===== 9. 结果汇总和分析 =====
print("=== 步骤9: 结果汇总和分析 ===\n")

def analyze_results(results: List[Dict]):
    """分析评估结果"""
    scores = [r["score"] for r in results if "score" in r]

    print("评估结果统计:")
    print(f"  总文档数: {len(results)}")
    print(f"  平均分数: {sum(scores) / len(scores):.2f}")
    print(f"  最高分: {max(scores)}")
    print(f"  最低分: {min(scores)}")
    print()

    print("分数分布:")
    score_ranges = {
        "9-10分": sum(1 for s in scores if s >= 9),
        "7-8分": sum(1 for s in scores if 7 <= s < 9),
        "5-6分": sum(1 for s in scores if 5 <= s < 7),
        "1-4分": sum(1 for s in scores if s < 5)
    }

    for range_name, count in score_ranges.items():
        percentage = (count / len(scores)) * 100
        bar = "█" * int(percentage / 5)
        print(f"  {range_name}: {count} ({percentage:.1f}%) {bar}")

    print()

    print("高分文档（≥8分）:")
    high_score_docs = [r for r in results if r.get("score", 0) >= 8]
    for doc in high_score_docs[:5]:
        print(f"  {doc['id']}. {doc['title']}: {doc['score']}/10")

analyze_results(batch_results)

# ===== 10. 保存结果 =====
print("=== 步骤10: 保存结果 ===\n")

output_file = "evaluation_results.json"
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump({
        "total_documents": len(test_documents),
        "evaluation_time": batch_time,
        "results": batch_results
    }, f, ensure_ascii=False, indent=2)

print(f"结果已保存到: {output_file}")
print()

# ===== 11. 2026 成本优化：langasync =====
print("=== 步骤11: 2026 成本优化 - langasync ===\n")

print("langasync 批处理成本优化（概念演示）:")
print()

print("传统批处理:")
print("  100个文档 × $0.01/个 = $1.00")
print()

print("langasync 批处理:")
print("  100个文档 × $0.005/个 = $0.50（节省50%）")
print()

print("使用示例:")
print("""
from langasync import wrap_chain

# 包装链为批处理模式
async_chain = wrap_chain(eval_chain, batch_size=10)

# 批量执行（成本降低50%）
results = await async_chain.abatch(inputs)
""")
print()

print("适用场景:")
print("  ✅ 批量评估和测试")
print("  ✅ 数据标注任务")
print("  ✅ 离线分析和报告")
print("  ❌ 实时对话应用")
print()

# ===== 12. 性能优化建议 =====
print("=== 步骤12: 性能优化建议 ===\n")

print("批处理优化建议:")
print()

print("1. 选择合适的批次大小:")
print("   - 小批次（5-10）: 更快失败，更好的错误隔离")
print("   - 大批次（50-100）: 更高吞吐量，但失败影响大")
print()

print("2. 控制并发数:")
print("   - OpenAI: 10-20")
print("   - Anthropic: 5-10")
print("   - 本地模型: 根据资源调整")
print()

print("3. 添加错误处理:")
print("   - 单个失败不影响其他")
print("   - 记录失败的文档")
print("   - 支持重试失败的文档")
print()

print("4. 监控性能:")
print("   - 记录每批次的耗时")
print("   - 监控成功率")
print("   - 分析性能瓶颈")
print()

# ===== 13. 完整性能报告 =====
print("=== 步骤13: 完整性能报告 ===\n")

print("=" * 60)
print("批处理性能报告")
print("=" * 60)
print()

print("测试配置:")
print(f"  文档数量: {len(test_documents)}")
print(f"  模型: gpt-4o-mini")
print(f"  温度: 0")
print()

print("性能对比:")
print(f"  串行执行: {serial_time:.2f}秒")
print(f"  批处理: {batch_time:.2f}秒")
print(f"  加速比: {serial_time / batch_time:.2f}x")
print()

print("成本估算（假设）:")
serial_cost = len(test_documents) * 0.01
batch_cost = len(test_documents) * 0.01
langasync_cost = len(test_documents) * 0.005

print(f"  串行执行: ${serial_cost:.2f}")
print(f"  批处理: ${batch_cost:.2f}")
print(f"  langasync: ${langasync_cost:.2f} (节省50%)")
print()

print("推荐方案:")
print("  实时任务: 串行执行")
print("  批量评估: 批处理")
print("  成本敏感: langasync批处理")
print()

print("演示完成！")
```

---

## 运行输出示例

```
=== 步骤1: 准备测试文档 ===

准备了 10 个测试文档
  1. 人工智能的未来
  2. 气候变化挑战
  3. 量子计算突破
  ...

=== 步骤2: 构建评估链 ===

评估链构建完成

=== 步骤3: 方法1 - 循环执行（串行）===

执行串行评估...
完成！耗时: 18.45秒
平均每个文档: 1.85秒

评估结果（前3个）:
  1. 人工智能的未来: 7/10
  2. 气候变化挑战: 8/10
  3. 量子计算突破: 7/10

=== 步骤4: 方法2 - 批处理（并行）===

执行批处理评估...
完成！耗时: 3.21秒
平均每个文档: 0.32秒

评估结果（前3个）:
  1. 人工智能的未来: 7/10
  2. 气候变化挑战: 8/10
  3. 量子计算突破: 7/10

=== 步骤5: 性能对比 ===

性能对比:
  串行执行: 18.45秒
  批处理: 3.21秒
  加速比: 5.75x
  时间节省: 82.6%

=== 步骤6: 控制并发数 ===

测试不同并发数:
  并发数 3: 4.12秒
  并发数 5: 3.18秒
  并发数 10: 3.25秒

=== 步骤7: 分批处理大量文档 ===

分批处理（每批5个）:
  处理批次 1/2 (5 个文档)...
  处理批次 2/2 (5 个文档)...
完成！总耗时: 6.34秒

=== 步骤8: 错误处理的批处理 ===

执行安全批处理...
成功: 10/10
失败: 0

=== 步骤9: 结果汇总和分析 ===

评估结果统计:
  总文档数: 10
  平均分数: 7.50
  最高分: 9
  最低分: 6

分数分布:
  9-10分: 1 (10.0%) ██
  7-8分: 6 (60.0%) ████████████
  5-6分: 3 (30.0%) ██████
  1-4分: 0 (0.0%)

高分文档（≥8分）:
  2. 气候变化挑战: 8/10
  5. 生物技术创新: 8/10
  9. 教育技术革新: 9/10

=== 步骤10: 保存结果 ===

结果已保存到: evaluation_results.json

=== 步骤11: 2026 成本优化 - langasync ===

langasync 批处理成本优化（概念演示）:

传统批处理:
  100个文档 × $0.01/个 = $1.00

langasync 批处理:
  100个文档 × $0.005/个 = $0.50（节省50%）

使用示例:

from langasync import wrap_chain

# 包装链为批处理模式
async_chain = wrap_chain(eval_chain, batch_size=10)

# 批量执行（成本降低50%）
results = await async_chain.abatch(inputs)

适用场景:
  ✅ 批量评估和测试
  ✅ 数据标注任务
  ✅ 离线分析和报告
  ❌ 实时对话应用

=== 步骤12: 性能优化建议 ===

批处理优化建议:

1. 选择合适的批次大小:
   - 小批次（5-10）: 更快失败，更好的错误隔离
   - 大批次（50-100）: 更高吞吐量，但失败影响大

2. 控制并发数:
   - OpenAI: 10-20
   - Anthropic: 5-10
   - 本地模型: 根据资源调整

3. 添加错误处理:
   - 单个失败不影响其他
   - 记录失败的文档
   - 支持重试失败的文档

4. 监控性能:
   - 记录每批次的耗时
   - 监控成功率
   - 分析性能瓶颈

=== 步骤13: 完整性能报告 ===

============================================================
批处理性能报告
============================================================

测试配置:
  文档数量: 10
  模型: gpt-4o-mini
  温度: 0

性能对比:
  串行执行: 18.45秒
  批处理: 3.21秒
  加速比: 5.75x

成本估算（假设）:
  串行执行: $0.10
  批处理: $0.10
  langasync: $0.05 (节省50%)

推荐方案:
  实时任务: 串行执行
  批量评估: 批处理
  成本敏感: langasync批处理

演示完成！
```

---

## 代码详解

### 1. 串行 vs 批处理

```python
# 串行：一个接一个
for doc in documents:
    result = chain.invoke(doc)

# 批处理：并行执行
results = chain.batch(documents)
```

**性能对比**：
- 串行：18.45秒
- 批处理：3.21秒
- 加速：5.75x

### 2. 控制并发数

```python
results = chain.batch(
    inputs,
    config={"max_concurrency": 5}
)
```

**关键点**：
- 避免 API 限流
- 平衡性能和稳定性
- 根据 API 限制调整

### 3. 分批处理

```python
for i in range(0, len(documents), chunk_size):
    chunk = documents[i:i + chunk_size]
    results = chain.batch(chunk)
```

**关键点**：
- 处理大量文档
- 更好的错误隔离
- 进度反馈

---

## 2025-2026 最新实践

### 1. langasync 成本优化

**来源**：社区工具 - langasync

```python
from langasync import wrap_chain

async_chain = wrap_chain(chain, batch_size=10)
results = await async_chain.abatch(inputs)
# 成本降低 50%
```

### 2. 性能监控

```python
import time

start = time.time()
results = chain.batch(inputs)
duration = time.time() - start

print(f"耗时: {duration:.2f}秒")
print(f"吞吐量: {len(inputs) / duration:.2f} 个/秒")
```

### 3. 错误处理

```python
def safe_batch(chain, inputs):
    results = []
    for input in inputs:
        try:
            result = chain.invoke(input)
            results.append({"success": True, "result": result})
        except Exception as e:
            results.append({"success": False, "error": str(e)})
    return results
```

---

## 学习检查清单

- [ ] 理解批处理的性能优势
- [ ] 理解并发控制的重要性
- [ ] 掌握 batch 的使用
- [ ] 能运行完整代码
- [ ] 理解成本优化策略
- [ ] 了解 2025-2026 最新实践

---

**版本**: v1.0
**最后更新**: 2026-02-18
**参考来源**:
- LangChain 官方文档
- Analytics Vidhya - LCEL Guide
- langasync 社区工具
