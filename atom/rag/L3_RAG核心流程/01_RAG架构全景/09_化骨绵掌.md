# 化骨绵掌 - 10个2分钟知识卡片

## 卡片1：RAG架构的本质

**一句话：** RAG架构是将外部知识与LLM生成能力结合的组件化系统。

**核心公式：**
```
RAG = 检索系统 + 上下文注入 + LLM生成
```

**关键洞察：** 不是简单的"检索+生成"，而是14个组件协同工作的完整系统。

**应用：** 企业知识库、客服机器人、研究助手

---

## 卡片2：四层架构模型

**一句话：** RAG架构分为基础层、检索优化层、生成层、高级模式层。

**层级职责：**
- 基础层（6组件）：数据流转
- 检索优化层（3组件）：提升检索质量
- 生成层（2组件）：生成答案
- 高级模式层（3组件）：复杂场景

**应用：** 根据场景选择合适的层级组合

---

## 卡片3：最小可用架构（MVP）

**一句话：** 5个组件就能构建基础RAG系统。

**MVP组件：**
1. 文档加载
2. 文本分块（500字符）
3. 嵌入模型（OpenAI）
4. 向量存储（ChromaDB）
5. LLM生成（GPT-4）

**应用：** 快速验证想法，测量基线效果

---

## 卡片4：混合检索策略

**一句话：** 结合Dense（语义）和Sparse（关键词）检索，提升召回率20-30%。

**工作原理：**
```python
dense_results = vectorstore.search(query)  # 语义理解
sparse_results = bm25.search(query)        # 关键词匹配
final = RRF_fusion([dense, sparse])        # 融合
```

**应用：** 处理专有名词+概念性查询的混合场景

---

## 卡片5：重排序技术

**一句话：** 使用Cross-Encoder精确打分，提升精确度15-30%。

**Bi-Encoder vs Cross-Encoder：**
- Bi-Encoder：快但粗糙（初筛）
- Cross-Encoder：慢但精确（精排）

**最佳实践：** 先检索10-20个候选，再重排序取Top-3

**应用：** 提升Top-K结果的准确性

---

## 卡片6：Lost in the Middle问题

**一句话：** LLM对上下文中间部分的信息利用率低。

**解决方案：**
```
开头：最相关文档（高利用率）
中间：次相关文档（低利用率）
结尾：第二相关文档（高利用率）
```

**应用：** 优化多文档上下文的排序

---

## 卡片7：Prompt工程核心

**一句话：** Prompt质量决定生成质量，包括上下文注入、指令设计、Few-shot示例。

**基础模板：**
```
系统角色 + 上下文信息 + 用户问题 + 回答要求
```

**关键要求：**
- 明确要求基于上下文
- 说明如何处理无关信息
- 指定输出格式

**应用：** 所有RAG系统的必需组件

---

## 卡片8：Agentic RAG

**一句话：** 赋予RAG自主决策能力，支持多跳推理、工具使用、反思机制。

**核心能力：**
1. 自主规划检索步骤
2. 多跳推理（逐步深入）
3. 工具调用（计算器、API）
4. 反思与调整

**适用场景：** 复杂推理、多步骤问题

**成本：** LLM调用次数增加3-5倍

---

## 卡片9：GraphRAG

**一句话：** 通过知识图谱增强RAG，支持结构化知识检索和全局理解。

**核心技术：**
- 实体关系提取
- 社区检测
- 层次化摘要
- 图谱检索

**vs 传统RAG：**
- 传统：向量相似度检索
- GraphRAG：图谱遍历+向量检索

**应用：** 需要理解文档间关系、全局分析

---

## 卡片10：评估与优化

**一句话：** 持续评估检索和生成质量，指导系统优化。

**关键指标：**
- 检索：Recall@K、Precision@K、MRR
- 生成：Faithfulness、Answer Relevancy
- 端到端：RAGAS框架

**优化循环：**
```
测量基线 → 单独测试优化 → A/B对比 → 选择最优组合
```

**应用：** 生产环境的质量保证

---

## 总结

**10个卡片覆盖：**
1. 架构本质
2. 四层模型
3. MVP实现
4. 混合检索
5. 重排序
6. 上下文优化
7. Prompt工程
8. Agentic RAG
9. GraphRAG
10. 评估优化

**学习路径：** 按顺序学习，从简单到复杂，从基础到高级。
