# 化骨绵掌

> **核心理念**：将 Compaction 拆分成 10 个 2 分钟知识卡片，快速掌握核心要点

---

## 使用说明

**化骨绵掌**是一种学习方法：
- 每个卡片独立完整，可单独理解
- 2 分钟内可看完（~200 字）
- 10 个卡片形成递进关系
- 适合快速复习和碎片化学习

**学习建议：**
- 第一遍：按顺序完整阅读
- 复习时：随机抽取卡片
- 面试前：快速过一遍所有卡片

---

## 卡片 1：直觉理解 - Compaction 是什么？

**一句话：** Compaction 是 AI Agent 的"笔记本整理术"，把旧笔记总结成摘要，腾出空间记录新内容。

**举例：**
```
你的笔记本有 200 页（上下文窗口）
已经写满 180 页（对话历史）
只剩 20 页了（快满了）

Compaction 做什么？
1. 把前 160 页总结成 5 页摘要
2. 保留最近 20 页的原始内容
3. 现在有 25 页内容，还剩 175 页空间
4. 可以继续记录新内容
```

**应用：** 在 Pi Coding Agent 中，一个复杂项目的对话可能持续几小时，产生几十万 tokens。没有 Compaction，对话会因为超过上下文窗口而中断；有了 Compaction，可以无限长对话。

**记住：** Compaction = 自动整理 + 智能总结 + 无限对话

---

## 卡片 2：形式化定义 - 精确表述

**一句话：** Compaction 是在有限上下文窗口内管理无限增长对话历史的语义压缩机制。

**数学表达：**
```
触发条件：contextTokens > contextWindow - reserveTokens
压缩操作：messages[0:cutPoint] → summary
保留内容：[summary, messages[cutPoint:]]
压缩比：originalTokens / summaryTokens (通常 10-25x)
```

**关键属性：**
- **自动性**：无需人工干预，自动触发
- **语义性**：保留意义，丢弃细节
- **结构化**：摘要包含 Summary、Key Points、Files
- **累积性**：多次压缩时包含之前的摘要

**应用：** 在设计 AI Agent 时，必须考虑 Compaction 机制，否则无法支持长期对话。

**记住：** 形式化定义帮助理解本质，而非死记硬背。

---

## 卡片 3：关键概念 - 自动触发机制

**一句话：** 当对话使用超过 92% 的上下文窗口时，自动触发压缩。

**触发公式：**
```typescript
if (contextTokens > contextWindow - reserveTokens) {
  await compactSession();
}

// 默认值
contextWindow = 200000      // Claude Opus 4
reserveTokens = 16384       // 预留 16K
threshold = 183616          // 触发阈值（92%）
```

**为什么预留空间？**
- 压缩本身需要调用 LLM（需要空间）
- 用户的下一条消息需要空间
- Agent 的响应需要空间
- 避免在压缩前就超限

**应用：** 在配置 Compaction 时，可以调整 `reserveTokens` 来控制压缩频率。预留空间越大，压缩越早触发；预留空间越小，压缩越晚触发。

**记住：** 92% 是经过优化的默认值，适合大多数场景。

---

## 卡片 4：关键概念 - 切点算法

**一句话：** 从后往前找，保留最近 20K tokens 的消息，确保切点是有效的（user/assistant）。

**算法流程：**
```typescript
1. 从最后一条消息往前遍历
2. 累积 token 数
3. 达到 keepRecentTokens (20K) 时停止
4. 向前查找有效切点（user/assistant）
5. 切点前的消息 → 压缩
6. 切点后的消息 → 保留
```

**为什么 tool 不能作为切点？**
```
错误：在 tool 消息处切断
[assistant: 调用工具]
[tool: 结果] ← 切点（错误！）
[assistant: 基于结果的响应]

问题：工具调用和结果被分离，Agent 无法理解上下文
```

**应用：** 在实现自定义压缩时，必须遵守切点规则，否则会破坏消息完整性。

**记住：** 切点算法确保压缩不会破坏对话的逻辑完整性。

---

## 卡片 5：编程实现 - 最小可用代码

**一句话：** 用 50 行代码实现基础的 Compaction 逻辑。

**核心代码：**
```typescript
async function compactSession(session: Session) {
  // 1. 检查是否需要压缩
  const contextTokens = estimateContextTokens(session.messages);
  if (contextTokens <= session.config.contextWindow - session.config.reserveTokens) {
    return; // 不需要压缩
  }

  // 2. 查找切点
  const cutPoint = findCutPoint(session.messages, session.config.keepRecentTokens);

  // 3. 分割消息
  const toCompress = session.messages.slice(0, cutPoint);
  const toKeep = session.messages.slice(cutPoint);

  // 4. 生成摘要
  const summary = await session.llm.summarize(toCompress);

  // 5. 重组消息
  session.messages = [
    { role: 'summary', content: summary },
    ...toKeep,
  ];
}
```

**应用：** 这个最小实现展示了 Compaction 的核心逻辑，可以作为自定义实现的起点。

**记住：** 理解核心逻辑比记住所有细节更重要。

---

## 卡片 6：对比区分 - Compaction vs Chunking

**一句话：** Compaction 是语义压缩（有损），Chunking 是物理分割（无损）。

**核心区别：**
```
Compaction（压缩对话）
- 输入：对话消息（动态）
- 输出：结构化摘要（语义）
- 信息：有损（保留关键）
- 依赖：需要 LLM

Chunking（分割文档）
- 输入：静态文档（固定）
- 输出：文本片段（物理）
- 信息：无损（保留全部）
- 依赖：不需要 LLM
```

**类比：**
- Compaction = 会议纪要（总结关键决策）
- Chunking = 书籍分章（保留全部内容）

**应用：** 在 RAG Agent 中，Chunking 用于文档检索，Compaction 用于对话管理，两者解决不同层面的问题。

**记住：** 不要混淆两者，它们的目的和实现完全不同。

---

## 卡片 7：进阶理解 - 迭代摘要更新

**一句话：** 多次压缩时，新摘要包含旧摘要，确保信息累积而非丢失。

**迭代过程：**
```typescript
// 第一次压缩
messages1 = [msg1, msg2, ..., msg100]
summary1 = summarize(messages1)
// "实现了用户登录功能"

// 第二次压缩（包含第一次的摘要）
messages2 = [summary1, msg101, ..., msg200]
summary2 = summarize(messages2)
// "实现了用户登录和注册功能"（包含了之前的内容）

// 第三次压缩
messages3 = [summary2, msg201, ..., msg300]
summary3 = summarize(messages3)
// "实现了完整的用户认证系统"（累积了所有信息）
```

**为什么重要？**
- 避免信息丢失：每次压缩都基于之前的摘要
- 保持连贯性：Agent 能理解整个对话的历史
- 支持长期对话：可以进行几天、几周的对话

**应用：** 在生成摘要时，必须检查是否有之前的摘要，并将其包含在新摘要中。

**记住：** 迭代更新是 Compaction 支持无限长对话的关键。

---

## 卡片 8：高级应用 - 成本优化策略

**一句话：** 使用 Gemini Flash 代替 Claude Opus 进行压缩，成本降低 99%。

**成本对比：**
```
Claude Opus 4: $0.90 / 50K tokens 压缩
Gemini Flash:  $0.005 / 50K tokens 压缩
节省：99.4%
```

**优化策略：**
```typescript
// 策略 1：固定使用便宜模型
event.customModel = 'gemini-flash-2.0';

// 策略 2：根据复杂度动态选择
if (complexity > 0.7) {
  event.customModel = 'claude-opus-4';  // 高质量
} else if (complexity > 0.4) {
  event.customModel = 'claude-sonnet-4'; // 平衡
} else {
  event.customModel = 'gemini-flash-2.0'; // 成本优化
}

// 策略 3：调整压缩频率
reserveTokens = 20000; // 增大预留空间，减少压缩次数
```

**应用：** 在生产环境中，成本优化是必须考虑的因素。通过选择合适的模型和调整配置，可以大幅降低成本。

**记住：** 成本优化不是牺牲质量，而是在质量和成本之间找到平衡。

---

## 卡片 9：实际应用 - Pi Coding Agent 中的使用

**一句话：** Pi Coding Agent 使用 Compaction 支持长时间编码会话，自动管理上下文。

**实际场景：**
```
场景：开发一个复杂的 Web 应用
时间：持续 3 小时
消息：约 500 条
Token：约 250K tokens

Compaction 的作用：
1. 第 1 小时：正常对话，未触发压缩
2. 第 2 小时：达到 92% 阈值，触发第一次压缩
   - 压缩前 150 条消息 → 1 条摘要
   - 保留最近 50 条消息
3. 第 3 小时：再次达到阈值，触发第二次压缩
   - 压缩前 100 条消息（包含第一次摘要）→ 1 条新摘要
   - 保留最近 50 条消息

结果：
- 用户无感知：对话流畅，无中断
- Agent 有记忆：知道之前做了什么
- 成本可控：只为实际使用的 token 付费
```

**应用：** 这就是 Compaction 的实际价值：让 AI Agent 能够像人类一样进行长时间、复杂的工作。

**记住：** Compaction 是长期运行 AI Agent 的基础设施，不是可选功能。

---

## 卡片 10：总结与延伸 - 掌握 Compaction 的路径

**一句话：** Compaction 是 AI Agent 开发的核心技术，掌握它需要理解原理、实践应用、优化策略。

**学习路径：**
```
1. 理解原理（为什么需要）
   ↓
2. 掌握机制（如何工作）
   - 自动触发
   - 切点算法
   - 摘要生成
   ↓
3. 实践应用（如何使用）
   - 配置参数
   - 监控 token
   - 手动压缩
   ↓
4. 优化策略（如何优化）
   - 成本优化
   - 质量优化
   - 性能优化
   ↓
5. 深入源码（如何实现）
   - 阅读 pi-mono 源码
   - 实现自定义扩展
   - 贡献代码
```

**延伸学习：**
- **2025-2026 前沿**：SimpleMem、Agent Cognitive Compressor、RL-based Compression
- **相关技术**：Memory Management、Context Engineering、RAG
- **实战项目**：构建自己的长期运行 AI Agent

**应用：** Compaction 不是孤立的技术，而是 AI Agent 开发体系的一部分。掌握 Compaction 后，可以更好地理解 Agent 的内存管理、上下文工程等高级话题。

**记住：** 学习是一个持续的过程，从理解原理到实践应用，再到优化创新。

---

## 快速复习检查清单

完成 10 个卡片后，检查你是否掌握：

### 基础理解
- [ ] 能用一句话解释 Compaction 是什么
- [ ] 理解为什么需要 Compaction
- [ ] 知道 Compaction 的触发条件

### 技术细节
- [ ] 理解切点查找算法
- [ ] 知道为什么 tool 不能作为切点
- [ ] 理解迭代摘要更新机制

### 实践应用
- [ ] 能够配置 Compaction 参数
- [ ] 知道如何监控 token 使用
- [ ] 能够实现自定义压缩扩展

### 优化策略
- [ ] 知道如何降低压缩成本
- [ ] 理解质量和成本的权衡
- [ ] 能够根据场景选择策略

### 深度理解
- [ ] 能够对比 Compaction 和 Chunking
- [ ] 理解 Compaction 在 AI Agent 中的作用
- [ ] 知道 2025-2026 的前沿技术

---

## 使用建议

### 第一次学习
1. 按顺序阅读所有卡片（20 分钟）
2. 理解每个卡片的核心要点
3. 完成检查清单

### 日常复习
1. 随机抽取 3-5 个卡片（5 分钟）
2. 快速回顾核心要点
3. 检查是否还记得

### 面试准备
1. 快速过一遍所有卡片（10 分钟）
2. 重点复习卡片 1、2、6、9
3. 准备 2-3 个实际案例

### 实战应用
1. 参考卡片 5 的代码实现
2. 参考卡片 8 的优化策略
3. 参考卡片 9 的实际场景

---

## 下一步学习

完成 Compaction 的学习后，可以：

1. **深入源码**：阅读 `packages/coding-agent/src/core/compaction/compaction.ts`
2. **实战项目**：构建一个需要长期对话的 AI Agent
3. **相关知识**：学习 Session 管理、Memory 架构、Context Engineering
4. **前沿研究**：关注 SimpleMem、ACC 等最新研究

---

**恭喜！** 你已经完成了 Compaction 压缩机制的完整学习。

**记住：** 知识的价值在于应用。把学到的 Compaction 知识应用到实际项目中，才能真正掌握它。

---

**版本：** v1.0
**最后更新：** 2026-02-20
**维护者：** Claude Code
