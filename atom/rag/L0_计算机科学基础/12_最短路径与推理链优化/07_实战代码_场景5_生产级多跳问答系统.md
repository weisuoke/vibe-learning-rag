# 实战代码_场景5：生产级多跳问答系统

> 构建完整的LangGraph + RAG + 路径规划生产系统

---

## 场景描述

构建一个生产级的多跳问答系统，集成：
- LangGraph状态管理
- GraphRAG混合检索
- 最短路径算法
- 可观测性和监控
- 错误处理和降级

**技术栈：**
- LangGraph：工作流管理
- Neo4j：图数据库
- ChromaDB：向量存储
- LangSmith：可观测性
- FastAPI：API服务

---

## 完整代码实现

```python
"""
生产级多跳问答系统
演示：LangGraph + GraphRAG + 最短路径算法的完整集成
"""

from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Optional, Annotated
import operator
from neo4j import GraphDatabase
import chromadb
import openai
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import logging
from datetime import datetime
import time
from functools import wraps


# ===== 1. 配置和日志 =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ===== 2. 状态定义 =====
class MultiHopQAState(TypedDict):
    """多跳问答状态"""
    # 输入
    question: str
    session_id: str

    # 中间状态
    question_entities: List[str]
    reasoning_plan: List[str]
    current_step: int
    reasoning_paths: Annotated[List[Dict], operator.add]
    vector_context: Annotated[List[str], operator.add]
    graph_context: Annotated[List[Dict], operator.add]

    # 输出
    answer: str
    confidence: float
    metadata: Dict

    # 错误处理
    error: Optional[str]
    retry_count: int


# ===== 3. 知识图谱管理器 =====
class KnowledgeGraphManager:
    """知识图谱管理器（带连接池）"""

    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(
            uri,
            auth=(user, password),
            max_connection_pool_size=50
        )

    def close(self):
        self.driver.close()

    def find_shortest_path(
        self,
        start: str,
        end: str,
        max_hops: int = 5
    ) -> Optional[Dict]:
        """查找最短路径"""
        with self.driver.session() as session:
            try:
                result = session.run("""
                    MATCH (start:Entity {name: $start})
                    MATCH (end:Entity {name: $end})
                    MATCH path = shortestPath((start)-[*..{max_hops}]-(end))
                    RETURN
                        [n in nodes(path) | n.name] AS entities,
                        [r in relationships(path) | type(r)] AS relations,
                        reduce(cost = 0, r in relationships(path) | cost + r.weight) AS totalCost
                """.format(max_hops=max_hops), start=start, end=end)

                record = result.single()
                if record:
                    return {
                        "entities": record["entities"],
                        "relations": record["relations"],
                        "cost": record["totalCost"]
                    }
            except Exception as e:
                logger.error(f"Graph query error: {e}")
                return None

        return None

    def find_k_paths(
        self,
        start: str,
        end: str,
        k: int = 3
    ) -> List[Dict]:
        """查找K条最短路径"""
        with self.driver.session() as session:
            try:
                result = session.run("""
                    MATCH (start:Entity {name: $start})
                    MATCH (end:Entity {name: $end})
                    MATCH path = (start)-[*..5]-(end)
                    WITH path,
                         reduce(cost = 0, r in relationships(path) | cost + r.weight) AS totalCost,
                         [n in nodes(path) | n.name] AS entities,
                         [r in relationships(path) | type(r)] AS relations
                    ORDER BY totalCost
                    LIMIT $k
                    RETURN entities, relations, totalCost
                """, start=start, end=end, k=k)

                paths = []
                for record in result:
                    paths.append({
                        "entities": record["entities"],
                        "relations": record["relations"],
                        "cost": record["totalCost"]
                    })
                return paths
            except Exception as e:
                logger.error(f"K-paths query error: {e}")
                return []


# ===== 4. 向量存储管理器 =====
class VectorStoreManager:
    """向量存储管理器"""

    def __init__(self, collection_name: str = "knowledge_base"):
        self.client = chromadb.Client()
        self.collection = self.client.get_or_create_collection(collection_name)
        self.openai_client = openai.OpenAI()

    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """向量检索"""
        try:
            query_embedding = self._get_embedding(query)

            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k
            )

            documents = []
            for i in range(len(results['ids'][0])):
                documents.append({
                    "text": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i],
                    "distance": results['distances'][0][i]
                })

            return documents
        except Exception as e:
            logger.error(f"Vector search error: {e}")
            return []

    def _get_embedding(self, text: str) -> List[float]:
        response = self.openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding


# ===== 5. LangGraph工作流 =====
class MultiHopQAWorkflow:
    """多跳问答工作流"""

    def __init__(
        self,
        kg_manager: KnowledgeGraphManager,
        vector_manager: VectorStoreManager
    ):
        self.kg = kg_manager
        self.vector = vector_manager
        self.openai_client = openai.OpenAI()
        self.workflow = self._create_workflow()

    def _create_workflow(self) -> StateGraph:
        """创建LangGraph工作流"""
        workflow = StateGraph(MultiHopQAState)

        # 添加节点
        workflow.add_node("extract_entities", self._extract_entities)
        workflow.add_node("create_plan", self._create_plan)
        workflow.add_node("execute_step", self._execute_step)
        workflow.add_node("verify_quality", self._verify_quality)
        workflow.add_node("synthesize_answer", self._synthesize_answer)
        workflow.add_node("handle_error", self._handle_error)

        # 设置入口
        workflow.set_entry_point("extract_entities")

        # 添加边
        workflow.add_edge("extract_entities", "create_plan")
        workflow.add_edge("create_plan", "execute_step")

        # 条件边：是否继续执行
        workflow.add_conditional_edges(
            "execute_step",
            self._should_continue_execution,
            {
                "continue": "execute_step",
                "verify": "verify_quality",
                "error": "handle_error"
            }
        )

        # 条件边：质量验证
        workflow.add_conditional_edges(
            "verify_quality",
            self._is_quality_sufficient,
            {
                "sufficient": "synthesize_answer",
                "insufficient": "execute_step",
                "error": "handle_error"
            }
        )

        workflow.add_edge("synthesize_answer", END)
        workflow.add_edge("handle_error", END)

        return workflow.compile()

    def _extract_entities(self, state: MultiHopQAState) -> Dict:
        """提取实体"""
        logger.info(f"Extracting entities from: {state['question']}")

        try:
            prompt = f"""
            从以下问题中提取关键实体：

            问题：{state['question']}

            返回JSON格式：
            {{"entities": ["实体1", "实体2"]}}
            """

            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )

            import json
            result = json.loads(response.choices[0].message.content)

            return {
                "question_entities": result.get("entities", []),
                "current_step": 0,
                "retry_count": 0
            }
        except Exception as e:
            logger.error(f"Entity extraction error: {e}")
            return {"error": str(e)}

    def _create_plan(self, state: MultiHopQAState) -> Dict:
        """创建推理计划"""
        logger.info("Creating reasoning plan")

        try:
            prompt = f"""
            为以下问题创建推理计划：

            问题：{state['question']}
            实体：{state['question_entities']}

            将问题分解为2-3个推理步骤。

            返回JSON格式：
            {{"steps": ["步骤1", "步骤2"]}}
            """

            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )

            import json
            result = json.loads(response.choices[0].message.content)

            return {"reasoning_plan": result.get("steps", [])}
        except Exception as e:
            logger.error(f"Planning error: {e}")
            return {"error": str(e)}

    def _execute_step(self, state: MultiHopQAState) -> Dict:
        """执行推理步骤"""
        current_step = state["current_step"]
        plan = state["reasoning_plan"]

        if current_step >= len(plan):
            return {"current_step": current_step}

        step = plan[current_step]
        logger.info(f"Executing step {current_step + 1}: {step}")

        try:
            # 向量检索
            vector_results = self.vector.search(step, top_k=3)

            # 图检索
            entities = state["question_entities"]
            graph_paths = []

            if len(entities) >= 2:
                paths = self.kg.find_k_paths(entities[0], entities[-1], k=2)
                graph_paths = paths

            return {
                "vector_context": [doc["text"] for doc in vector_results],
                "graph_context": graph_paths,
                "reasoning_paths": graph_paths,
                "current_step": current_step + 1
            }
        except Exception as e:
            logger.error(f"Step execution error: {e}")
            return {"error": str(e)}

    def _verify_quality(self, state: MultiHopQAState) -> Dict:
        """验证推理质量"""
        logger.info("Verifying reasoning quality")

        paths = state.get("reasoning_paths", [])

        if not paths:
            return {"confidence": 0.0}

        # 计算平均路径代价
        avg_cost = sum(p.get("cost", 1.0) for p in paths) / len(paths)

        # 质量得分（代价越小越好）
        quality_score = 1.0 / (1.0 + avg_cost)

        return {
            "confidence": quality_score,
            "metadata": {
                "avg_path_cost": avg_cost,
                "num_paths": len(paths)
            }
        }

    def _synthesize_answer(self, state: MultiHopQAState) -> Dict:
        """综合答案"""
        logger.info("Synthesizing answer")

        try:
            # 构建上下文
            context_parts = []

            if state.get("vector_context"):
                context_parts.append("相关文档：")
                context_parts.extend(state["vector_context"][:2])

            if state.get("reasoning_paths"):
                context_parts.append("\n推理路径：")
                for i, path in enumerate(state["reasoning_paths"][:2], 1):
                    path_str = " → ".join(path["entities"])
                    context_parts.append(f"{i}. {path_str}")

            context = "\n".join(context_parts)

            # 生成答案
            prompt = f"""
            问题：{state['question']}

            上下文：
            {context}

            请基于上下文回答问题。
            """

            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )

            return {
                "answer": response.choices[0].message.content,
                "metadata": {
                    **state.get("metadata", {}),
                    "timestamp": datetime.now().isoformat()
                }
            }
        except Exception as e:
            logger.error(f"Answer synthesis error: {e}")
            return {"error": str(e)}

    def _handle_error(self, state: MultiHopQAState) -> Dict:
        """错误处理"""
        logger.error(f"Handling error: {state.get('error')}")

        return {
            "answer": "抱歉，处理您的问题时遇到错误。",
            "confidence": 0.0,
            "metadata": {
                "error": state.get("error"),
                "timestamp": datetime.now().isoformat()
            }
        }

    def _should_continue_execution(self, state: MultiHopQAState) -> str:
        """判断是否继续执行"""
        if state.get("error"):
            return "error"

        if state["current_step"] >= len(state["reasoning_plan"]):
            return "verify"

        return "continue"

    def _is_quality_sufficient(self, state: MultiHopQAState) -> str:
        """判断质量是否足够"""
        if state.get("error"):
            return "error"

        confidence = state.get("confidence", 0.0)

        if confidence > 0.7:
            return "sufficient"

        # 如果质量不够且还有重试次数
        if state.get("retry_count", 0) < 2:
            return "insufficient"

        # 超过重试次数，接受当前结果
        return "sufficient"

    def query(self, question: str, session_id: str = "default") -> Dict:
        """查询接口"""
        initial_state = {
            "question": question,
            "session_id": session_id,
            "question_entities": [],
            "reasoning_plan": [],
            "current_step": 0,
            "reasoning_paths": [],
            "vector_context": [],
            "graph_context": [],
            "answer": "",
            "confidence": 0.0,
            "metadata": {},
            "error": None,
            "retry_count": 0
        }

        result = self.workflow.invoke(initial_state)

        return {
            "question": question,
            "answer": result["answer"],
            "confidence": result["confidence"],
            "reasoning_paths": result.get("reasoning_paths", []),
            "metadata": result.get("metadata", {})
        }


# ===== 6. FastAPI服务 =====
app = FastAPI(title="Multi-Hop QA API")

# 请求/响应模型
class QuestionRequest(BaseModel):
    question: str
    session_id: Optional[str] = "default"

class QuestionResponse(BaseModel):
    question: str
    answer: str
    confidence: float
    reasoning_paths: List[Dict]
    metadata: Dict


# 全局实例
kg_manager = None
vector_manager = None
qa_workflow = None


@app.on_event("startup")
async def startup_event():
    """启动时初始化"""
    global kg_manager, vector_manager, qa_workflow

    logger.info("Initializing services...")

    kg_manager = KnowledgeGraphManager(
        uri="bolt://localhost:7687",
        user="neo4j",
        password="password"
    )

    vector_manager = VectorStoreManager()

    qa_workflow = MultiHopQAWorkflow(kg_manager, vector_manager)

    logger.info("Services initialized")


@app.on_event("shutdown")
async def shutdown_event():
    """关闭时清理"""
    global kg_manager

    if kg_manager:
        kg_manager.close()

    logger.info("Services closed")


@app.post("/query", response_model=QuestionResponse)
async def query_endpoint(request: QuestionRequest):
    """问答接口"""
    try:
        start_time = time.time()

        result = qa_workflow.query(
            question=request.question,
            session_id=request.session_id
        )

        elapsed = time.time() - start_time

        logger.info(f"Query completed in {elapsed:.2f}s")

        return QuestionResponse(**result)

    except Exception as e:
        logger.error(f"Query error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """健康检查"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }


# ===== 7. 主程序 =====
if __name__ == "__main__":
    import uvicorn

    # 开发模式：直接测试
    print("生产级多跳问答系统\n")
    print("=" * 60)

    # 初始化
    kg = KnowledgeGraphManager(
        uri="bolt://localhost:7687",
        user="neo4j",
        password="password"
    )

    vector = VectorStoreManager()

    workflow = MultiHopQAWorkflow(kg, vector)

    # 测试问题
    questions = [
        "谁是《哈利·波特》作者的丈夫？",
        "《哈利·波特》的作者是谁？"
    ]

    for question in questions:
        print(f"\n问题: {question}")
        print("-" * 60)

        result = workflow.query(question)

        print(f"答案: {result['answer']}")
        print(f"置信度: {result['confidence']:.2f}")

        if result['reasoning_paths']:
            print("\n推理路径:")
            for i, path in enumerate(result['reasoning_paths'], 1):
                path_str = " → ".join(path['entities'])
                print(f"  {i}. {path_str} (代价: {path['cost']:.2f})")

    kg.close()

    # 生产模式：启动API服务
    # uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## Docker Compose配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Neo4j图数据库
  neo4j:
    image: neo4j:5.15
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc"]
    volumes:
      - neo4j_data:/data
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "password", "RETURN 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # API服务
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      neo4j:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000

volumes:
  neo4j_data:
```

---

## Dockerfile

```dockerfile
FROM python:3.13-slim

WORKDIR /app

# 安装依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制代码
COPY . .

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s \
  CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# 启动服务
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## requirements.txt

```
fastapi==0.109.0
uvicorn[standard]==0.27.0
langgraph==0.0.20
langchain==0.1.0
neo4j==5.15.0
chromadb==0.4.22
openai==1.10.0
pydantic==2.5.3
python-dotenv==1.0.0
```

---

## 使用示例

### 1. 启动服务

```bash
# 启动所有服务
docker-compose up -d

# 查看日志
docker-compose logs -f api
```

### 2. API调用

```bash
# 健康检查
curl http://localhost:8000/health

# 问答请求
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "谁是《哈利·波特》作者的丈夫？",
    "session_id": "user123"
  }'
```

### 3. Python客户端

```python
import requests

def ask_question(question: str):
    response = requests.post(
        "http://localhost:8000/query",
        json={"question": question}
    )

    result = response.json()

    print(f"问题: {result['question']}")
    print(f"答案: {result['answer']}")
    print(f"置信度: {result['confidence']:.2f}")

    if result['reasoning_paths']:
        print("\n推理路径:")
        for i, path in enumerate(result['reasoning_paths'], 1):
            entities = " → ".join(path['entities'])
            print(f"  {i}. {entities}")

# 使用
ask_question("谁是《哈利·波特》作者的丈夫？")
```

---

## 监控和可观测性

### Prometheus指标

```python
from prometheus_client import Counter, Histogram, generate_latest

# 定义指标
query_counter = Counter(
    'qa_queries_total',
    'Total number of queries',
    ['status']
)

query_duration = Histogram(
    'qa_query_duration_seconds',
    'Query duration in seconds'
)

@app.post("/query")
async def query_endpoint(request: QuestionRequest):
    start_time = time.time()

    try:
        result = qa_workflow.query(request.question)

        query_counter.labels(status='success').inc()

        return result

    except Exception as e:
        query_counter.labels(status='error').inc()
        raise

    finally:
        duration = time.time() - start_time
        query_duration.observe(duration)


@app.get("/metrics")
async def metrics():
    return Response(
        generate_latest(),
        media_type="text/plain"
    )
```

---

## 性能优化

### 1. 连接池配置

```python
# Neo4j连接池
driver = GraphDatabase.driver(
    uri,
    auth=(user, password),
    max_connection_pool_size=50,
    connection_acquisition_timeout=30
)
```

### 2. 缓存策略

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_shortest_path(start: str, end: str):
    return kg.find_shortest_path(start, end)
```

### 3. 异步处理

```python
import asyncio

async def parallel_retrieve(question: str):
    """并行检索"""
    vector_task = asyncio.create_task(
        vector_manager.search(question)
    )

    graph_task = asyncio.create_task(
        kg_manager.find_paths(entities)
    )

    vector_results, graph_results = await asyncio.gather(
        vector_task,
        graph_task
    )

    return vector_results, graph_results
```

---

## 关键要点

### 1. 生产级特性

**可观测性：**
- 结构化日志
- Prometheus指标
- 健康检查端点

**可靠性：**
- 错误处理和重试
- 降级策略
- 连接池管理

**性能：**
- 缓存优化
- 并行处理
- 连接复用

### 2. LangGraph优势

**状态管理：**
- 清晰的状态定义
- 自动状态传递
- 条件分支控制

**可维护性：**
- 模块化节点设计
- 易于测试和调试
- 可视化工作流

### 3. 部署架构

**容器化：**
- Docker镜像
- Docker Compose编排
- 健康检查

**扩展性：**
- 水平扩展API服务
- 图数据库集群
- 负载均衡

---

## 总结

这个生产级系统展示了：

1. **完整集成**：LangGraph + GraphRAG + 最短路径
2. **生产就绪**：监控、日志、错误处理
3. **可扩展**：容器化、连接池、缓存
4. **可维护**：模块化设计、清晰架构

**适用场景：**
- 企业知识库问答
- 智能客服系统
- 研究助手
- 教育平台

---

**恭喜！** 你已经完成了最短路径算法在AI Agent中的完整学习，从基础理论到生产实践。
