# RunnableParallel并行执行 - 核心概念3：错误处理与容错

> 深入理解并行执行中的错误处理机制和容错策略

---

## 概述

本文档深入讲解 RunnableParallel 的错误处理和容错机制：
1. **部分失败处理**：一个任务失败不影响其他任务
2. **重试机制**：自动重试失败的任务
3. **降级策略**：提供备用方案
4. **超时控制**：避免任务无限等待

**学习目标**：
- 理解默认的错误传播机制
- 掌握 with_fallback 的使用
- 实现重试和超时控制
- 能够手写容错包装器

---

## 第一部分：默认错误传播

### 1.1 默认行为：一个失败全部失败

**RunnableParallel 默认会传播任何任务的异常**

```python
from langchain_core.runnables import RunnableParallel, RunnableLambda

def task1(x):
    return x + 1

def task2(x):
    raise ValueError("Task 2 failed!")

def task3(x):
    return x * 2

# 并行执行
parallel = RunnableParallel(
    t1=RunnableLambda(task1),
    t2=RunnableLambda(task2),  # 会失败
    t3=RunnableLambda(task3)
)

try:
    result = parallel.invoke(5)
except ValueError as e:
    print(f"错误: {e}")
    # 输出: 错误: Task 2 failed!
    # 整个并行执行失败，t1 和 t3 的结果丢失
```

**问题**：
- task2 失败导致整体失败
- task1 和 task3 的结果无法获取
- 用户体验差

---

### 1.2 错误传播的原理

**asyncio.gather 的默认行为**

```python
import asyncio

async def task1():
    await asyncio.sleep(1)
    return "success"

async def task2():
    await asyncio.sleep(1)
    raise ValueError("failed")

async def task3():
    await asyncio.sleep(1)
    return "success"

# 默认行为：一个失败全部失败
try:
    results = await asyncio.gather(task1(), task2(), task3())
except ValueError as e:
    print(f"错误: {e}")
    # task1 和 task3 的结果丢失
```

**关键机制**：
- `asyncio.gather` 默认在第一个异常时停止
- 已完成的任务结果被丢弃
- 未完成的任务被取消

---

## 第二部分：with_fallback 容错机制

### 2.1 基础 fallback

**使用 with_fallback 提供备用方案**

```python
from langchain_core.runnables import RunnableParallel, RunnableLambda

def primary_task(x):
    raise ValueError("Primary failed")

def backup_task(x):
    return x * 2  # 备用方案

# 添加 fallback
task_with_fallback = RunnableLambda(primary_task).with_fallback([
    RunnableLambda(backup_task)
])

# 并行执行
parallel = RunnableParallel(
    task1=RunnableLambda(lambda x: x + 1),
    task2=task_with_fallback,  # 有 fallback
    task3=RunnableLambda(lambda x: x ** 2)
)

result = parallel.invoke(5)
print(result)
# 输出: {"task1": 6, "task2": 10, "task3": 25}
# task2 使用了 backup_task
```

**执行流程**：
```
1. task2 执行 primary_task → 失败
2. 自动切换到 backup_task → 成功
3. 返回 backup_task 的结果
4. 整体执行成功
```

---

### 2.2 多级 fallback

**提供多个备用方案**

```python
# 多级 fallback
task_with_multi_fallback = (
    RunnableLambda(primary_task)
    .with_fallback([
        RunnableLambda(backup1),
        RunnableLambda(backup2),
        RunnableLambda(backup3)
    ])
)

# 执行流程
# primary_task → 失败
# backup1 → 失败
# backup2 → 失败
# backup3 → 成功
```

**2025-2026 生产实践**：

```python
from langchain_openai import ChatOpenAI

# 多模型 fallback
gpt4_with_fallback = (
    ChatOpenAI(model="gpt-4o")
    .with_fallback([
        ChatOpenAI(model="gpt-4o-mini"),  # 备用1
        ChatOpenAI(model="gpt-3.5-turbo")  # 备用2
    ])
)

# 并行调用
parallel = RunnableParallel(
    primary=gpt4_with_fallback,
    secondary=claude_with_fallback
)
```

---

### 2.3 fallback 的配置选项

**控制 fallback 行为**

```python
# 配置 fallback
task_with_config = (
    RunnableLambda(primary_task)
    .with_fallback(
        fallbacks=[RunnableLambda(backup_task)],
        exceptions_to_handle=(ValueError, TimeoutError),  # 只处理特定异常
    )
)
```

**异常过滤**：
```python
# 只对特定异常使用 fallback
task = (
    RunnableLambda(risky_task)
    .with_fallback(
        [RunnableLambda(safe_task)],
        exceptions_to_handle=(ConnectionError, TimeoutError)
    )
)

# ValueError 不会触发 fallback，直接抛出
```

---

## 第三部分：重试机制

### 3.1 基础重试

**使用 with_retry 自动重试**

```python
from langchain_core.runnables import RunnableLambda

# 模拟不稳定的任务
import random

def unstable_task(x):
    if random.random() < 0.7:  # 70% 失败率
        raise ConnectionError("Network error")
    return x * 2

# 添加重试
task_with_retry = (
    RunnableLambda(unstable_task)
    .with_retry(
        stop_after_attempt=3,  # 最多重试3次
        wait_exponential_multiplier=1,  # 指数退避
        wait_exponential_max=10  # 最大等待10秒
    )
)

# 使用
result = task_with_retry.invoke(5)
# 如果失败，会自动重试最多3次
```

**重试策略**：
```
第1次失败 → 等待 1秒 → 重试
第2次失败 → 等待 2秒 → 重试
第3次失败 → 等待 4秒 → 重试
第4次失败 → 抛出异常
```

---

### 3.2 指数退避（Exponential Backoff）

**2025-2026 推荐的重试策略**

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=1, min=1, max=60),
    retry=retry_if_exception_type((ConnectionError, TimeoutError))
)
def api_call_with_retry(input):
    # 调用外部 API
    return external_api.call(input)

# 使用
task = RunnableLambda(api_call_with_retry)
```

**退避时间表**：
```
尝试1: 立即
尝试2: 等待 1秒
尝试3: 等待 2秒
尝试4: 等待 4秒
尝试5: 等待 8秒
尝试6: 等待 16秒
...
最大等待: 60秒
```

---

### 3.3 重试 + fallback 组合

**最佳实践：先重试，再 fallback**

```python
# 组合策略
task = (
    RunnableLambda(primary_api)
    .with_retry(stop_after_attempt=3)  # 先重试3次
    .with_fallback([
        RunnableLambda(backup_api)  # 重试失败后使用备用
    ])
)

# 执行流程
# primary_api → 失败 → 重试1 → 失败 → 重试2 → 失败 → 重试3 → 失败
# 切换到 backup_api → 成功
```

---

## 第四部分：超时控制

### 4.1 基础超时

**使用 with_config 设置超时**

```python
from langchain_core.runnables import RunnableLambda
import time

def slow_task(x):
    time.sleep(10)  # 模拟慢速任务
    return x * 2

# 设置超时
task_with_timeout = RunnableLambda(slow_task).with_config(
    {"timeout": 5}  # 5秒超时
)

# 并行执行
parallel = RunnableParallel(
    fast=RunnableLambda(lambda x: x + 1),
    slow=task_with_timeout  # 会超时
)

try:
    result = parallel.invoke(5)
except TimeoutError:
    print("任务超时")
```

---

### 4.2 超时 + fallback

**超时后使用备用方案**

```python
# 超时后使用缓存值
task = (
    RunnableLambda(slow_api_call)
    .with_config({"timeout": 5})
    .with_fallback([
        RunnableLambda(lambda x: get_cached_value(x))
    ])
)

# 执行流程
# slow_api_call → 超时（5秒）
# 切换到 get_cached_value → 返回缓存
```

---

### 4.3 异步超时控制

**使用 asyncio.wait_for**

```python
import asyncio

async def slow_async_task(x):
    await asyncio.sleep(10)
    return x * 2

async def task_with_timeout(x):
    try:
        result = await asyncio.wait_for(
            slow_async_task(x),
            timeout=5.0
        )
        return result
    except asyncio.TimeoutError:
        return "timeout"

# 使用
parallel = RunnableParallel(
    task1=RunnableLambda(task_with_timeout),
    task2=RunnableLambda(fast_task)
)
```

---

## 第五部分：手写容错包装器

### 5.1 基础容错包装器

```python
from typing import Callable, Any, List
import logging

logger = logging.getLogger(__name__)

class FallbackWrapper:
    """容错包装器"""

    def __init__(
        self,
        primary: Callable,
        fallbacks: List[Callable],
        exceptions: tuple = (Exception,)
    ):
        self.primary = primary
        self.fallbacks = fallbacks
        self.exceptions = exceptions

    def __call__(self, input: Any) -> Any:
        """执行主任务，失败时使用 fallback"""
        # 1. 尝试主任务
        try:
            return self.primary(input)
        except self.exceptions as e:
            logger.warning(f"Primary failed: {e}")

            # 2. 尝试 fallback
            for i, fallback in enumerate(self.fallbacks):
                try:
                    logger.info(f"Trying fallback {i+1}")
                    return fallback(input)
                except self.exceptions as e:
                    logger.warning(f"Fallback {i+1} failed: {e}")
                    continue

            # 3. 所有 fallback 都失败
            raise RuntimeError("All fallbacks failed")

# 使用示例
def primary(x):
    raise ValueError("Primary failed")

def backup1(x):
    raise ValueError("Backup1 failed")

def backup2(x):
    return x * 2

wrapper = FallbackWrapper(
    primary=primary,
    fallbacks=[backup1, backup2],
    exceptions=(ValueError,)
)

result = wrapper(5)
print(result)  # 10（使用了 backup2）
```

---

### 5.2 重试包装器

```python
import time
from typing import Callable, Any

class RetryWrapper:
    """重试包装器"""

    def __init__(
        self,
        func: Callable,
        max_attempts: int = 3,
        backoff_factor: float = 1.0,
        exceptions: tuple = (Exception,)
    ):
        self.func = func
        self.max_attempts = max_attempts
        self.backoff_factor = backoff_factor
        self.exceptions = exceptions

    def __call__(self, input: Any) -> Any:
        """执行任务，失败时重试"""
        for attempt in range(self.max_attempts):
            try:
                return self.func(input)
            except self.exceptions as e:
                if attempt == self.max_attempts - 1:
                    # 最后一次尝试，抛出异常
                    raise

                # 计算等待时间（指数退避）
                wait_time = self.backoff_factor * (2 ** attempt)
                logger.warning(
                    f"Attempt {attempt + 1} failed: {e}. "
                    f"Retrying in {wait_time}s..."
                )
                time.sleep(wait_time)

# 使用示例
import random

def unstable_func(x):
    if random.random() < 0.7:
        raise ConnectionError("Network error")
    return x * 2

wrapper = RetryWrapper(
    func=unstable_func,
    max_attempts=5,
    backoff_factor=1.0,
    exceptions=(ConnectionError,)
)

result = wrapper(5)
```

---

### 5.3 超时包装器

```python
import signal
from typing import Callable, Any

class TimeoutWrapper:
    """超时包装器（仅限 Unix）"""

    def __init__(self, func: Callable, timeout: int):
        self.func = func
        self.timeout = timeout

    def _timeout_handler(self, signum, frame):
        raise TimeoutError(f"Function timed out after {self.timeout}s")

    def __call__(self, input: Any) -> Any:
        """执行任务，超时则抛出异常"""
        # 设置信号处理器
        signal.signal(signal.SIGALRM, self._timeout_handler)
        signal.alarm(self.timeout)

        try:
            result = self.func(input)
        finally:
            # 取消定时器
            signal.alarm(0)

        return result

# 使用示例
def slow_func(x):
    time.sleep(10)
    return x * 2

wrapper = TimeoutWrapper(func=slow_func, timeout=5)

try:
    result = wrapper(5)
except TimeoutError as e:
    print(f"超时: {e}")
```

---

### 5.4 综合容错包装器

**组合重试、fallback、超时**

```python
class RobustWrapper:
    """综合容错包装器"""

    def __init__(
        self,
        primary: Callable,
        fallbacks: List[Callable] = None,
        max_attempts: int = 3,
        timeout: int = None,
        backoff_factor: float = 1.0
    ):
        self.primary = primary
        self.fallbacks = fallbacks or []
        self.max_attempts = max_attempts
        self.timeout = timeout
        self.backoff_factor = backoff_factor

    def __call__(self, input: Any) -> Any:
        """执行任务（重试 + 超时 + fallback）"""
        # 1. 尝试主任务（带重试）
        for attempt in range(self.max_attempts):
            try:
                if self.timeout:
                    # 带超时执行
                    result = self._execute_with_timeout(
                        self.primary, input
                    )
                else:
                    result = self.primary(input)
                return result

            except Exception as e:
                if attempt < self.max_attempts - 1:
                    # 重试
                    wait_time = self.backoff_factor * (2 ** attempt)
                    logger.warning(f"Retry after {wait_time}s")
                    time.sleep(wait_time)
                else:
                    # 最后一次尝试失败
                    logger.error(f"Primary failed after {self.max_attempts} attempts")

        # 2. 尝试 fallback
        for fallback in self.fallbacks:
            try:
                logger.info("Trying fallback")
                return fallback(input)
            except Exception as e:
                logger.warning(f"Fallback failed: {e}")
                continue

        # 3. 所有尝试都失败
        raise RuntimeError("All attempts failed")

    def _execute_with_timeout(self, func, input):
        """带超时执行"""
        # 实现超时逻辑
        pass

# 使用示例
wrapper = RobustWrapper(
    primary=unstable_api_call,
    fallbacks=[backup_api_call, cached_value],
    max_attempts=3,
    timeout=5,
    backoff_factor=1.0
)

result = wrapper(input)
```

---

## 第六部分：生产环境最佳实践

### 6.1 多模型容错（2025案例）

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.runnables import RunnableParallel

# 定义多个模型（带 fallback）
gpt4 = (
    ChatOpenAI(model="gpt-4o")
    .with_retry(stop_after_attempt=3)
    .with_fallback([ChatOpenAI(model="gpt-4o-mini")])
)

claude = (
    ChatAnthropic(model="claude-3-5-sonnet-20241022")
    .with_retry(stop_after_attempt=3)
    .with_fallback([ChatAnthropic(model="claude-3-haiku-20240307")])
)

# 并行调用
parallel = RunnableParallel(
    gpt4=gpt4,
    claude=claude
)

# 即使某个模型失败，也能返回结果
result = await parallel.ainvoke("解释量子计算")
```

---

### 6.2 RAG 检索容错

```python
# 多数据源检索（部分失败容错）
retrieval = RunnableParallel(
    vector=vector_retriever.with_fallback([
        RunnableLambda(lambda _: [])  # 失败返回空列表
    ]),
    kg=kg_retriever.with_fallback([
        RunnableLambda(lambda _: [])
    ]),
    search=search_retriever.with_fallback([
        RunnableLambda(lambda _: [])
    ])
)

# 即使某个数据源失败，也能返回其他结果
context = await retrieval.ainvoke({"query": user_question})
```

---

### 6.3 监控与告警

```python
from langsmith import trace
import logging

logger = logging.getLogger(__name__)

@trace
def monitored_parallel(input):
    """带监控的并行执行"""
    try:
        result = parallel.invoke(input)
        logger.info("Parallel execution succeeded")
        return result
    except Exception as e:
        logger.error(f"Parallel execution failed: {e}")
        # 发送告警
        send_alert(f"Parallel execution failed: {e}")
        raise

# 使用 LangSmith 追踪
# - 记录每个任务的成功/失败
# - 记录 fallback 使用情况
# - 记录重试次数
```

---

## 学习检查清单

- [ ] 理解默认的错误传播机制
- [ ] 掌握 with_fallback 的使用
- [ ] 理解重试机制和指数退避
- [ ] 掌握超时控制方法
- [ ] 能够组合多种容错策略
- [ ] 能够手写容错包装器
- [ ] 理解生产环境最佳实践

---

## 参考资料

[来源: LangChain Best Practices - https://www.swarnendu.de/blog/langchain-best-practices, 访问日期: 2026-02-18]

[来源: 7 LangChain Retry & Timeout Patterns for Flaky Tools - https://medium.com/@connect.hashblock/7-langchain-retry-timeout-patterns-for-flaky-tools-a371c3edc1d3, 访问日期: 2026-02-18]

[来源: Retries, Fallbacks, and Circuit Breakers in LLM Apps - https://www.getmaxim.ai/articles/retries-fallbacks-and-circuit-breakers-in-llm-apps-a-production-guide, 访问日期: 2026-02-18]

---

**版本**: v1.0
**最后更新**: 2026-02-18
**行数**: 约490行
