# 第一性原理

## 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题，而不是基于类比或经验。

## pgvector 的第一性原理

### 1. 最基础的定义

**pgvector = PostgreSQL 的向量数据类型扩展**

仅此而已！没有更基础的了。

它做了三件事：
1. 让 PostgreSQL 能存储向量（数字数组）
2. 提供向量距离计算函数（余弦、欧氏、内积）
3. 提供向量索引（HNSW、IVFFlat）加速检索

### 2. 为什么需要 pgvector？

**核心问题：如何让计算机理解"相似"？**

传统数据库的"相似"：
```sql
-- 字符串匹配（精确）
SELECT * FROM documents WHERE content = '向量数据库';

-- 模糊匹配（字面相似）
SELECT * FROM documents WHERE content LIKE '%向量%';

-- 全文检索（关键词匹配）
SELECT * FROM documents WHERE to_tsvector(content) @@ to_tsquery('向量 & 数据库');
```

**问题：这些方法都无法理解"语义相似"**
- "向量数据库" 和 "vector database" 是同一个意思，但字符串不匹配
- "苹果手机" 和 "iPhone" 是同一个东西，但关键词不同
- "机器学习" 和 "人工智能" 有很强的语义关联，但传统检索找不到

**解决方案：向量表示 + 向量检索**
1. 把文本转换为向量（Embedding）：捕捉语义信息
2. 计算向量之间的距离：距离越近，语义越相似
3. 找到距离最近的 Top-K 向量：返回最相似的文档

**这就是 pgvector 存在的根本原因：让数据库能够理解和检索"语义相似"。**

### 3. pgvector 的三层价值

#### 价值1：统一的数据存储

**问题：**
- 传统方案：业务数据在 PostgreSQL，向量数据在专用向量库（Milvus、Pinecone）
- 结果：两个数据源，数据一致性难以保证

**pgvector 的解决：**
```python
# 在同一个事务中操作业务数据和向量数据
with conn.cursor() as cursor:
    # 插入文档
    cursor.execute(
        "INSERT INTO documents (id, content, user_id) VALUES (%s, %s, %s)",
        (1, "什么是向量数据库？", 123)
    )

    # 插入向量
    cursor.execute(
        "UPDATE documents SET embedding = %s WHERE id = %s",
        (embedding, 1)
    )

    conn.commit()  # 要么全成功，要么全失败

# 删除文档时，向量自动删除（外键约束）
cursor.execute("DELETE FROM documents WHERE id = %s", (1,))
```

**价值：**
- 数据一致性：事务保证
- 运维简化：只需维护一个数据库
- 成本降低：无需额外的向量库基础设施

#### 价值2：SQL 的表达能力

**问题：**
- 专用向量库通常只支持简单的向量检索
- 复杂查询（过滤、聚合、JOIN）需要在应用层实现

**pgvector 的解决：**
```sql
-- 复杂查询：向量检索 + 过滤 + JOIN
SELECT
    d.content,
    d.embedding <=> :query_embedding AS distance,
    u.username,
    c.name AS category
FROM documents d
JOIN users u ON d.user_id = u.id
JOIN categories c ON d.category_id = c.id
WHERE
    d.created_at > '2024-01-01'  -- 时间过滤
    AND u.is_active = true        -- 用户过滤
    AND c.name IN ('tech', 'ai')  -- 分类过滤
ORDER BY distance
LIMIT 10;
```

**价值：**
- 表达能力强：SQL 的全部能力（JOIN、聚合、窗口函数）
- 开发效率高：无需在应用层拼接数据
- 性能优化：数据库优化器自动选择最优执行计划

#### 价值3：渐进式采用

**问题：**
- 引入专用向量库需要大规模架构改造
- 对于中小规模应用，成本过高

**pgvector 的解决：**
```sql
-- 第一步：在现有表上添加向量列
ALTER TABLE documents ADD COLUMN embedding vector(1536);

-- 第二步：生成并更新向量
UPDATE documents SET embedding = generate_embedding(content);

-- 第三步：创建索引
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);

-- 第四步：开始使用向量检索
SELECT * FROM documents ORDER BY embedding <=> :query_embedding LIMIT 10;
```

**价值：**
- 零架构改造：在现有 PostgreSQL 上直接启用
- 渐进式迁移：逐步从关键词检索过渡到语义检索
- 低风险：可以随时回退到传统检索

### 4. 从第一性原理推导 RAG 系统

**推理链：**

```
1. 问题：用户提问"什么是向量数据库？"
   ↓
2. 传统方案：关键词匹配，只能找到包含"向量数据库"的文档
   ↓
3. 局限：无法找到语义相关但用词不同的文档（如"vector store"、"embedding database"）
   ↓
4. 解决：将文本转换为向量（Embedding），捕捉语义信息
   ↓
5. 存储：需要一个数据库存储向量，并支持相似度检索
   ↓
6. 选择：pgvector（在现有 PostgreSQL 上扩展）vs 专用向量库（Milvus、Pinecone）
   ↓
7. 权衡：
   - 数据量 < 500 万：pgvector（简单、一致性好）
   - 数据量 > 500 万：专用向量库（性能更好、分布式）
   ↓
8. RAG 流程：
   a. 文档入库：文本 → Embedding → pgvector
   b. 用户提问：问题 → Embedding → pgvector 检索 Top-K
   c. 上下文注入：Top-K 文档 + 问题 → LLM
   d. 生成回答：LLM → 回答
   ↓
9. 结论：pgvector 是 RAG 系统的数据层基础
```

**实际应用：**

```python
# RAG 系统的完整流程
from openai import OpenAI
import psycopg2

client = OpenAI()
conn = psycopg2.connect("postgresql://localhost/mydb")

# 1. 文档入库
def ingest_document(content: str):
    # 生成 Embedding
    embedding = client.embeddings.create(
        input=content,
        model="text-embedding-3-small"
    ).data[0].embedding

    # 存入 pgvector
    with conn.cursor() as cursor:
        cursor.execute(
            "INSERT INTO documents (content, embedding) VALUES (%s, %s)",
            (content, embedding)
        )
        conn.commit()

# 2. 检索相关文档
def retrieve_documents(query: str, top_k: int = 5):
    # 生成查询向量
    query_embedding = client.embeddings.create(
        input=query,
        model="text-embedding-3-small"
    ).data[0].embedding

    # 向量检索
    with conn.cursor() as cursor:
        cursor.execute(
            """
            SELECT content
            FROM documents
            ORDER BY embedding <=> %s
            LIMIT %s
            """,
            (query_embedding, top_k)
        )
        return [row[0] for row in cursor.fetchall()]

# 3. RAG 问答
def rag_qa(question: str):
    # 检索相关文档
    docs = retrieve_documents(question, top_k=3)

    # 构建上下文
    context = "\n\n".join(docs)

    # LLM 生成回答
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "根据以下文档回答问题"},
            {"role": "user", "content": f"文档：\n{context}\n\n问题：{question}"}
        ]
    )

    return response.choices[0].message.content

# 使用
answer = rag_qa("什么是向量数据库？")
print(answer)
```

### 5. 一句话总结第一性原理

**pgvector 是让 PostgreSQL 理解"语义相似"的扩展，通过向量存储和距离计算，使数据库能够检索语义相关的内容，而不仅仅是字面匹配，这是构建 RAG 系统的数据层基础。**

---

## 从第一性原理理解关键设计

### 为什么向量是固定维度的？

**第一性原理：**
- 向量距离计算要求两个向量维度相同
- 例如：`[1, 2, 3]` 和 `[4, 5]` 无法计算距离（维度不匹配）

**实现：**
```sql
-- 创建表时指定维度
CREATE TABLE documents (
    embedding vector(1536)  -- 固定 1536 维
);

-- 插入时必须匹配维度
INSERT INTO documents (embedding) VALUES ('[0.1, 0.2, ...]');  -- 必须是 1536 维
```

### 为什么需要索引？

**第一性原理：**
- 暴力计算所有向量的距离是 O(N) 复杂度
- 50 万向量 × 1536 维 × 浮点运算 = 数秒延迟
- 用户无法接受秒级延迟

**解决：**
- HNSW 索引：多层图结构，O(log N) 复杂度
- IVFFlat 索引：聚类 + 倒排索引，减少搜索空间

**权衡：**
- 索引构建时间：HNSW > IVFFlat
- 查询速度：HNSW > IVFFlat
- 召回率：HNSW > IVFFlat

### 为什么使用余弦距离而非欧氏距离？

**第一性原理：**
- 文本 Embedding 通常已归一化（向量长度为 1）
- 归一化后，余弦距离和欧氏距离等价
- 但余弦距离的语义更清晰：只关心方向，不关心长度

**数学证明：**
```
对于归一化向量（||v|| = 1）：
余弦相似度 = v1 · v2 / (||v1|| × ||v2||) = v1 · v2
欧氏距离² = ||v1 - v2||² = 2 - 2(v1 · v2)

因此：欧氏距离² = 2 - 2×余弦相似度
```

**实际应用：**
- OpenAI Embedding：已归一化，使用余弦距离
- 图像 Embedding：可能未归一化，使用欧氏距离

---

## 第一性原理的应用

### 1. 选型决策

**问题：pgvector vs 专用向量库？**

**第一性原理分析：**
- **数据一致性需求**：高 → pgvector（事务保证）
- **查询复杂度**：高（JOIN、聚合）→ pgvector（SQL 表达能力）
- **数据规模**：< 500 万 → pgvector（性能足够）
- **数据规模**：> 500 万 → 专用向量库（分布式）

### 2. 性能优化

**问题：查询很慢怎么办？**

**第一性原理分析：**
1. **是否有索引？** 无 → 创建 HNSW 索引
2. **索引是否生效？** 否 → 检查查询语句（必须有 LIMIT）
3. **数据量是否足够？** < 1 万 → 索引无优势，全表扫描更快
4. **召回率是否足够？** 否 → 增加 `ef_search` 参数

### 3. 架构设计

**问题：如何设计 RAG 系统的数据层？**

**第一性原理分析：**
1. **文档和向量的关系**：1:1 → 同一张表
2. **元数据的存储**：JSONB 列（灵活）vs 关系表（结构化）
3. **索引策略**：HNSW（查询优先）vs IVFFlat（插入优先）
4. **分区策略**：按时间分区（历史数据归档）vs 按类别分区（减少搜索空间）

---

## 总结

**pgvector 的第一性原理：**
1. **本质**：让 PostgreSQL 理解"语义相似"
2. **方法**：向量存储 + 距离计算 + 索引加速
3. **价值**：统一存储、SQL 表达能力、渐进式采用
4. **应用**：RAG 系统的数据层基础

**记住：**
- 不要盲目追求高维度（维度灾难）
- 不要忽视索引（性能差距 100 倍）
- 不要混淆余弦距离和欧氏距离（语义不同）
- 不要期望 100% 召回率（近似搜索的权衡）
