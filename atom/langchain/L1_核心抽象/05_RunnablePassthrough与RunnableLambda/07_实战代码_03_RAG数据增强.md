# 07_实战代码_03_RAG数据增强

> **学习目标**：通过完整的 RAG 应用掌握 RunnablePassthrough 与 RunnableLambda 的实战应用

---

## 环境准备

```bash
# 安装 RAG 相关依赖
uv add langchain-openai langchain-chroma chromadb

# 确保 .env 文件配置了 OPENAI_API_KEY
```

---

## 示例 1：标准 RAG 管道

### 代码

```python
"""
示例 1：标准 RAG 管道
演示：使用 RunnablePassthrough.assign() 构建基础 RAG
"""

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_chroma import Chroma
from dotenv import load_dotenv

load_dotenv()


def example_basic_rag():
    """基础 RAG 示例"""
    print("=" * 50)
    print("示例 1：标准 RAG 管道")
    print("=" * 50)

    # 1. 初始化组件
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    embeddings = OpenAIEmbeddings()

    # 2. 创建向量存储（示例数据）
    texts = [
        "LangChain 是一个用于构建 LLM 应用的框架",
        "LCEL 是 LangChain Expression Language 的缩写",
        "RunnablePassthrough 用于在链中保留原始数据"
    ]
    vectorstore = Chroma.from_texts(
        texts=texts,
        embedding=embeddings,
        collection_name="demo"
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

    # 3. 创建 Prompt
    prompt = ChatPromptTemplate.from_template("""
根据以下上下文回答问题：

上下文：
{context}

问题：{query}

答案：
""")

    # 4. 构建 RAG 链
    rag_chain = (
        RunnablePassthrough.assign(
            context=lambda x: retriever.invoke(x["query"])
        )
        | prompt
        | llm
        | StrOutputParser()
    )

    # 5. 使用
    query = "什么是 LangChain?"
    print(f"\n查询: {query}")
    answer = rag_chain.invoke({"query": query})
    print(f"答案: {answer}")


if __name__ == "__main__":
    example_basic_rag()
```

---

## 示例 2：查询改写 + RAG

### 代码

```python
"""
示例 2：查询改写 + RAG
演示：使用 RunnableLambda 实现查询改写
"""

from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()


def rewrite_query(input_dict):
    """查询改写函数"""
    query = input_dict["query"]

    # 简单的改写逻辑
    if len(query) < 10:
        rewritten = f"请详细解释：{query}，包括定义和用途"
    else:
        rewritten = query

    return {
        "query": rewritten,
        "original_query": query
    }


def example_query_rewrite():
    """查询改写示例"""
    print("=" * 50)
    print("示例 2：查询改写 + RAG")
    print("=" * 50)

    # 构建链（假设已有 retriever、prompt、llm）
    chain = (
        RunnableLambda(rewrite_query)  # 改写查询
        | RunnablePassthrough.assign(
            context=lambda x: f"检索结果 for: {x['query']}"
        )
    )

    # 测试
    input_data = {"query": "RAG"}
    result = chain.invoke(input_data)

    print(f"\n输入: {input_data}")
    print(f"\n输出:")
    for key, value in result.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    example_query_rewrite()
```

---

## 示例 3：多级数据增强

### 代码

```python
"""
示例 3：多级数据增强
演示：逐步添加多个字段
"""

from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()


def get_metadata(x):
    """获取元数据"""
    return {
        "timestamp": datetime.now().isoformat(),
        "user": x.get("user", "anonymous")
    }


def get_stats(x):
    """获取统计信息"""
    query = x["query"]
    return {
        "query_length": len(query),
        "word_count": len(query.split())
    }


def example_multi_level_enrichment():
    """多级数据增强示例"""
    print("=" * 50)
    print("示例 3：多级数据增强")
    print("=" * 50)

    # 构建多级增强链
    chain = (
        RunnablePassthrough.assign(
            rewritten=lambda x: x["query"].lower()
        )
        | RunnablePassthrough.assign(
            context=lambda x: f"检索结果 for: {x['rewritten']}"
        )
        | RunnablePassthrough.assign(
            metadata=get_metadata,
            stats=get_stats
        )
    )

    # 测试
    input_data = {"query": "什么是 LangChain?", "user": "alice"}
    result = chain.invoke(input_data)

    print(f"\n输入: {input_data}")
    print(f"\n输出:")
    for key, value in result.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    example_multi_level_enrichment()
```

---

## 示例 4：并行数据增强

### 代码

```python
"""
示例 4：并行数据增强
演示：使用 RunnableParallel 并行获取多个数据源
"""

from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()


def get_metadata(x):
    """获取元数据"""
    return {
        "timestamp": datetime.now().isoformat(),
        "user": x.get("user", "anonymous")
    }


def get_stats(x):
    """获取统计信息"""
    return {
        "length": len(x["query"]),
        "word_count": len(x["query"].split())
    }


def example_parallel_enrichment():
    """并行数据增强示例"""
    print("=" * 50)
    print("示例 4：并行数据增强")
    print("=" * 50)

    # 构建并行增强链
    parallel = RunnableParallel({
        "original": RunnablePassthrough(),
        "context": RunnableLambda(lambda x: f"检索结果 for: {x['query']}"),
        "metadata": RunnableLambda(get_metadata),
        "stats": RunnableLambda(get_stats)
    })

    # 测试
    input_data = {"query": "什么是 LangChain?", "user": "alice"}
    result = parallel.invoke(input_data)

    print(f"\n输入: {input_data}")
    print(f"\n输出:")
    for key, value in result.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    example_parallel_enrichment()
```

---

## 示例 5：完整 RAG 应用

### 代码

```python
"""
示例 5：完整 RAG 应用
演示：综合应用所有技术
"""

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_chroma import Chroma
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()


def validate_input(x):
    """验证输入"""
    if "query" not in x:
        raise ValueError("Missing 'query' field")
    if len(x["query"]) < 3:
        raise ValueError("Query too short")
    return x


def preprocess_query(x):
    """预处理查询"""
    return {
        **x,
        "query": x["query"].strip().lower(),
        "original_query": x["query"]
    }


def add_metadata(x):
    """添加元数据"""
    return {
        **x,
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "query_length": len(x["query"]),
            "word_count": len(x["query"].split())
        }
    }


def example_complete_rag():
    """完整 RAG 应用"""
    print("=" * 50)
    print("示例 5：完整 RAG 应用")
    print("=" * 50)

    # 1. 初始化组件
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    embeddings = OpenAIEmbeddings()

    # 2. 创建向量存储
    texts = [
        "LangChain 是一个用于构建 LLM 应用的框架",
        "LCEL 是 LangChain Expression Language 的缩写",
        "RunnablePassthrough 用于在链中保留原始数据",
        "RunnableLambda 用于包装自定义函数"
    ]
    vectorstore = Chroma.from_texts(
        texts=texts,
        embedding=embeddings,
        collection_name="complete_demo"
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

    # 3. 创建 Prompt
    prompt = ChatPromptTemplate.from_template("""
根据以下上下文回答问题：

上下文：
{context}

原始问题：{original_query}
处理后的问题：{query}

答案：
""")

    # 4. 构建完整的 RAG 链
    rag_chain = (
        RunnableLambda(validate_input)  # 验证
        | RunnableLambda(preprocess_query)  # 预处理
        | RunnablePassthrough.assign(
            context=lambda x: retriever.invoke(x["query"])
        )  # 检索
        | RunnableLambda(add_metadata)  # 添加元数据
        | prompt
        | llm
        | StrOutputParser()
    )

    # 5. 测试
    print("\n测试 1：成功案例")
    try:
        query = "  什么是 LangChain?  "
        print(f"查询: '{query}'")
        answer = rag_chain.invoke({"query": query, "user": "alice"})
        print(f"答案: {answer}")
    except Exception as e:
        print(f"错误: {e}")

    print("\n测试 2：失败案例（查询太短）")
    try:
        query = "hi"
        print(f"查询: '{query}'")
        answer = rag_chain.invoke({"query": query})
        print(f"答案: {answer}")
    except Exception as e:
        print(f"错误: {e}")


if __name__ == "__main__":
    example_complete_rag()
```

---

## 学习检查

### 基础检查

- [ ] 理解 RAG 管道的基本结构
- [ ] 能使用 RunnablePassthrough.assign() 保留查询
- [ ] 能使用 RunnableLambda 实现查询改写
- [ ] 理解数据流动过程

### 进阶检查

- [ ] 能实现多级数据增强
- [ ] 能使用 RunnableParallel 并行处理
- [ ] 能添加验证和错误处理
- [ ] 能构建完整的 RAG 应用

### 实战检查

- [ ] 能集成真实的向量存储
- [ ] 能处理各种边界情况
- [ ] 能优化性能
- [ ] 能应用到生产环境

---

## 总结

### 核心模式

1. **标准 RAG**：`RunnablePassthrough.assign(context=retriever)`
2. **查询改写**：`RunnableLambda(rewrite) | assign(context=retriever)`
3. **多级增强**：多个 `assign()` 串联
4. **并行增强**：`RunnableParallel` 并行获取数据

### 最佳实践

1. **验证输入**：使用 RunnableLambda 验证
2. **预处理**：清理和标准化查询
3. **数据保留**：使用 assign() 保留原始数据
4. **元数据**：添加时间戳、统计信息等
5. **错误处理**：添加 try-except 和重试机制

---

**下一步**：
- 复习 `06_反直觉点.md` 避免常见陷阱
- 查看 `10_一句话总结.md` 验证学习效果

---

**参考资料**：
- [LangChain RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/) (2025)
- [Building Production-Ready AI Pipelines](https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557) (2026)

---

**版本**：v1.0
**最后更新**：2026-02-18
