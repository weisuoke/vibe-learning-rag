# 实战代码 05：分支摘要生成

> 完整的 TypeScript 分支摘要生成实现，使用 LLM 自动生成分支上下文摘要

---

## 代码概览

本文实现完整的分支摘要生成系统，包括：

1. **上下文收集**：收集需要摘要的条目
2. **LLM 调用**：使用 LLM 生成摘要
3. **文件跟踪**：跟踪读取和修改的文件
4. **摘要存储**：将摘要作为特殊条目存储
5. **摘要优化**：优化摘要质量和长度

---

## 完整实现

### 类型定义

```typescript
// types.ts
export interface BranchSummaryOptions {
  maxLength?: number;
  includeFiles?: boolean;
  includeStats?: boolean;
  model?: string;
}

export interface BranchSummaryResult {
  summary: string;
  readFiles: string[];
  modifiedFiles: string[];
  messageCount: number;
  tokenCount: number;
}

export interface LLMClient {
  complete(params: {
    messages: Array<{ role: string; content: string }>;
    max_tokens?: number;
    temperature?: number;
  }): Promise<{ content: string }>;
}
```

### 分支摘要生成器

```typescript
// branch-summarizer.ts
import { randomBytes } from 'crypto';
import { SessionEntry, BranchSummaryOptions, BranchSummaryResult, LLMClient } from './types';
import { BranchManager } from './branch-manager';

export class BranchSummarizer {
  constructor(
    private manager: BranchManager,
    private llmClient: LLMClient
  ) {}

  /**
   * 生成分支摘要
   */
  async generateSummary(
    branchFromId: string,
    options: BranchSummaryOptions = {}
  ): Promise<BranchSummaryResult> {
    const {
      maxLength = 200,
      includeFiles = true,
      includeStats = true,
      model = 'claude-3-opus-20240229'
    } = options;

    // 1. 收集上下文
    const context = this.collectContext(branchFromId);

    // 2. 跟踪文件
    const { readFiles, modifiedFiles } = includeFiles
      ? this.trackFiles(context.entries)
      : { readFiles: [], modifiedFiles: [] };

    // 3. 生成摘要
    const summary = await this.generateSummaryText(
      context.entries,
      maxLength,
      model
    );

    // 4. 返回结果
    return {
      summary,
      readFiles,
      modifiedFiles,
      messageCount: context.messageCount,
      tokenCount: context.tokenCount
    };
  }

  /**
   * 收集需要摘要的上下文
   */
  private collectContext(branchFromId: string): {
    entries: SessionEntry[];
    messageCount: number;
    tokenCount: number;
  } {
    const branch = this.manager.getBranch(branchFromId);

    // 过滤出需要摘要的条目
    const entries = branch.filter(entry =>
      entry.type === 'user' ||
      entry.type === 'assistant' ||
      entry.type === 'tool_use' ||
      entry.type === 'tool_result'
    );

    // 统计消息数量
    const messageCount = entries.filter(e =>
      e.type === 'user' || e.type === 'assistant'
    ).length;

    // 估算 Token 数量
    const tokenCount = entries.reduce((sum, entry) => {
      const content = entry.content || JSON.stringify(entry);
      return sum + Math.ceil(content.length / 4);
    }, 0);

    return { entries, messageCount, tokenCount };
  }

  /**
   * 跟踪文件操作
   */
  private trackFiles(entries: SessionEntry[]): {
    readFiles: string[];
    modifiedFiles: string[];
  } {
    const readFiles = new Set<string>();
    const modifiedFiles = new Set<string>();

    for (const entry of entries) {
      if (entry.type === 'tool_use') {
        const toolName = entry.name;
        const input = entry.input || {};

        // 读取文件
        if (toolName === 'read_file' || toolName === 'Read') {
          if (input.file_path || input.path) {
            readFiles.add(input.file_path || input.path);
          }
        }

        // 修改文件
        if (toolName === 'write_file' || toolName === 'Write' ||
            toolName === 'edit_file' || toolName === 'Edit') {
          if (input.file_path || input.path) {
            modifiedFiles.add(input.file_path || input.path);
          }
        }
      }
    }

    return {
      readFiles: Array.from(readFiles),
      modifiedFiles: Array.from(modifiedFiles)
    };
  }

  /**
   * 生成摘要文本
   */
  private async generateSummaryText(
    entries: SessionEntry[],
    maxLength: number,
    model: string
  ): Promise<string> {
    // 构建 prompt
    const prompt = this.buildSummaryPrompt(entries, maxLength);

    // 调用 LLM
    const response = await this.llmClient.complete({
      messages: [{ role: 'user', content: prompt }],
      max_tokens: maxLength,
      temperature: 0.3
    });

    return response.content.trim();
  }

  /**
   * 构建摘要 prompt
   */
  private buildSummaryPrompt(entries: SessionEntry[], maxLength: number): string {
    // 提取对话内容
    const conversation = entries
      .filter(e => e.type === 'user' || e.type === 'assistant')
      .map(e => `${e.type}: ${e.content}`)
      .join('\n\n');

    // 提取工具调用
    const toolUses = entries
      .filter(e => e.type === 'tool_use')
      .map(e => `- ${e.name}(${JSON.stringify(e.input)})`)
      .join('\n');

    return `
请为以下对话生成一个简洁的摘要（最多 ${maxLength} 字符）。

对话内容：
${conversation}

${toolUses ? `工具调用：\n${toolUses}\n` : ''}

要求：
1. 用 1-2 句话总结对话的主要内容
2. 突出关键信息和决策
3. 如果有文件操作，简要提及
4. 保持客观和准确

摘要：
    `.trim();
  }

  /**
   * 创建并保存分支摘要
   */
  async createBranchSummary(
    branchFromId: string,
    options: BranchSummaryOptions = {}
  ): Promise<string> {
    // 生成摘要
    const result = await this.generateSummary(branchFromId, options);

    // 创建摘要条目
    const summaryId = this.generateId();
    const summaryEntry: SessionEntry = {
      type: 'branch_summary',
      id: summaryId,
      parentId: branchFromId,
      timestamp: new Date().toISOString(),
      summary: result.summary,
      branchFromId,
      readFiles: result.readFiles,
      modifiedFiles: result.modifiedFiles
    };

    // 保存到 JSONL
    this.manager.appendEntry(summaryEntry);

    console.log(`✓ Branch summary created: ${summaryId}`);
    console.log(`  Summary: ${result.summary}`);
    if (result.readFiles.length > 0) {
      console.log(`  Read files: ${result.readFiles.join(', ')}`);
    }
    if (result.modifiedFiles.length > 0) {
      console.log(`  Modified files: ${result.modifiedFiles.join(', ')}`);
    }

    return summaryId;
  }

  private generateId(): string {
    return randomBytes(4).toString('hex');
  }
}
```

### LLM 客户端实现

```typescript
// llm-client.ts
export class OpenAIClient implements LLMClient {
  constructor(
    private apiKey: string,
    private baseURL: string = 'https://api.openai.com/v1'
  ) {}

  async complete(params: {
    messages: Array<{ role: string; content: string }>;
    max_tokens?: number;
    temperature?: number;
  }): Promise<{ content: string }> {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages: params.messages,
        max_tokens: params.max_tokens || 500,
        temperature: params.temperature || 0.7
      })
    });

    if (!response.ok) {
      throw new Error(`LLM API error: ${response.statusText}`);
    }

    const data = await response.json();
    return {
      content: data.choices[0].message.content
    };
  }
}

export class AnthropicClient implements LLMClient {
  constructor(
    private apiKey: string,
    private baseURL: string = 'https://api.anthropic.com/v1'
  ) {}

  async complete(params: {
    messages: Array<{ role: string; content: string }>;
    max_tokens?: number;
    temperature?: number;
  }): Promise<{ content: string }> {
    const response = await fetch(`${this.baseURL}/messages`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': this.apiKey,
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify({
        model: 'claude-3-opus-20240229',
        messages: params.messages,
        max_tokens: params.max_tokens || 500,
        temperature: params.temperature || 0.7
      })
    });

    if (!response.ok) {
      throw new Error(`LLM API error: ${response.statusText}`);
    }

    const data = await response.json();
    return {
      content: data.content[0].text
    };
  }
}
```

### 摘要优化器

```typescript
// summary-optimizer.ts
export class SummaryOptimizer {
  /**
   * 优化摘要长度
   */
  optimizeLength(summary: string, maxLength: number): string {
    if (summary.length <= maxLength) {
      return summary;
    }

    // 截断到最后一个完整句子
    const sentences = summary.match(/[^.!?]+[.!?]+/g) || [];
    let result = '';

    for (const sentence of sentences) {
      if (result.length + sentence.length <= maxLength) {
        result += sentence;
      } else {
        break;
      }
    }

    return result || summary.substring(0, maxLength) + '...';
  }

  /**
   * 提取关键信息
   */
  extractKeyInfo(entries: SessionEntry[]): {
    mainTopic: string;
    keyDecisions: string[];
    filesInvolved: string[];
  } {
    const messages = entries.filter(e => e.type === 'user' || e.type === 'assistant');
    const toolUses = entries.filter(e => e.type === 'tool_use');

    // 提取主题（第一条用户消息）
    const mainTopic = messages.find(e => e.type === 'user')?.content || 'Unknown';

    // 提取关键决策（包含"决定"、"选择"等关键词的消息）
    const keyDecisions = messages
      .filter(e => {
        const content = e.content?.toLowerCase() || '';
        return content.includes('决定') ||
               content.includes('选择') ||
               content.includes('采用') ||
               content.includes('使用');
      })
      .map(e => e.content || '')
      .slice(0, 3);

    // 提取涉及的文件
    const filesInvolved = toolUses
      .map(e => e.input?.file_path || e.input?.path)
      .filter(Boolean)
      .slice(0, 5);

    return { mainTopic, keyDecisions, filesInvolved };
  }

  /**
   * 生成结构化摘要
   */
  generateStructuredSummary(keyInfo: {
    mainTopic: string;
    keyDecisions: string[];
    filesInvolved: string[];
  }): string {
    const parts: string[] = [];

    // 主题
    parts.push(`主题: ${keyInfo.mainTopic.substring(0, 50)}`);

    // 关键决策
    if (keyInfo.keyDecisions.length > 0) {
      parts.push(`决策: ${keyInfo.keyDecisions[0].substring(0, 50)}`);
    }

    // 涉及文件
    if (keyInfo.filesInvolved.length > 0) {
      parts.push(`文件: ${keyInfo.filesInvolved.slice(0, 2).join(', ')}`);
    }

    return parts.join(' | ');
  }
}
```

---

## 使用示例

### 示例 1：基础摘要生成

```typescript
import { BranchManager } from './branch-manager';
import { BranchSummarizer } from './branch-summarizer';
import { AnthropicClient } from './llm-client';

async function basicSummaryExample() {
  const manager = new BranchManager('session.jsonl');
  const llmClient = new AnthropicClient(process.env.ANTHROPIC_API_KEY!);
  const summarizer = new BranchSummarizer(manager, llmClient);

  // 获取当前分支的父节点
  const currentLeaf = manager.getLeafId();
  const parent = manager.getParent(currentLeaf);

  if (parent) {
    // 生成摘要
    const result = await summarizer.generateSummary(parent.id);

    console.log('=== Branch Summary ===');
    console.log(`Summary: ${result.summary}`);
    console.log(`Messages: ${result.messageCount}`);
    console.log(`Tokens: ${result.tokenCount}`);
    console.log(`Read files: ${result.readFiles.join(', ')}`);
    console.log(`Modified files: ${result.modifiedFiles.join(', ')}`);
  }

  manager.close();
}

basicSummaryExample();
```

### 示例 2：创建分支并生成摘要

```typescript
async function branchWithSummaryExample() {
  const manager = new BranchManager('session.jsonl');
  const llmClient = new AnthropicClient(process.env.ANTHROPIC_API_KEY!);
  const summarizer = new BranchSummarizer(manager, llmClient);

  // 添加一些对话
  manager.addMessage('帮我实现一个排序函数', 'user');
  manager.addMessage('好的，我来实现快速排序', 'assistant');
  const branchPoint = manager.getLeafId();

  manager.addMessage('继续', 'user');
  manager.addMessage('这是快速排序的实现...', 'assistant');

  // 回到分支点
  manager.branch(branchPoint);

  // 生成摘要并创建新分支
  const summaryId = await summarizer.createBranchSummary(branchPoint, {
    maxLength: 150,
    includeFiles: true
  });

  // 从新分支继续
  manager.addMessage('用归并排序实现', 'user');
  manager.addMessage('好的，这是归并排序...', 'assistant');

  // 可视化树
  manager.visualizeFullTree();

  manager.close();
}

branchWithSummaryExample();
```

### 示例 3：批量生成摘要

```typescript
async function batchSummaryExample() {
  const manager = new BranchManager('session.jsonl');
  const llmClient = new AnthropicClient(process.env.ANTHROPIC_API_KEY!);
  const summarizer = new BranchSummarizer(manager, llmClient);

  // 获取所有分支
  const branches = manager.getAllBranches();

  console.log(`Found ${branches.length} branches`);

  // 为每个分支生成摘要
  for (const branch of branches) {
    const parent = manager.getParent(branch.leafId);

    if (parent) {
      console.log(`\nGenerating summary for branch ${branch.id}...`);

      const result = await summarizer.generateSummary(parent.id, {
        maxLength: 100
      });

      console.log(`  Summary: ${result.summary}`);
    }
  }

  manager.close();
}

batchSummaryExample();
```

### 示例 4：优化摘要质量

```typescript
import { SummaryOptimizer } from './summary-optimizer';

async function optimizedSummaryExample() {
  const manager = new BranchManager('session.jsonl');
  const llmClient = new AnthropicClient(process.env.ANTHROPIC_API_KEY!);
  const summarizer = new BranchSummarizer(manager, llmClient);
  const optimizer = new SummaryOptimizer();

  const branchFromId = manager.getLeafId();
  const branch = manager.getBranch(branchFromId);

  // 提取关键信息
  const keyInfo = optimizer.extractKeyInfo(branch);

  console.log('=== Key Information ===');
  console.log(`Main topic: ${keyInfo.mainTopic}`);
  console.log(`Key decisions: ${keyInfo.keyDecisions.length}`);
  console.log(`Files involved: ${keyInfo.filesInvolved.length}`);

  // 生成结构化摘要
  const structuredSummary = optimizer.generateStructuredSummary(keyInfo);
  console.log(`\nStructured summary: ${structuredSummary}`);

  // 生成 LLM 摘要
  const result = await summarizer.generateSummary(branchFromId);

  // 优化长度
  const optimizedSummary = optimizer.optimizeLength(result.summary, 100);
  console.log(`\nOptimized summary: ${optimizedSummary}`);

  manager.close();
}

optimizedSummaryExample();
```

### 示例 5：自定义摘要模板

```typescript
class CustomBranchSummarizer extends BranchSummarizer {
  protected buildSummaryPrompt(entries: SessionEntry[], maxLength: number): string {
    const conversation = entries
      .filter(e => e.type === 'user' || e.type === 'assistant')
      .map(e => `${e.type}: ${e.content}`)
      .join('\n\n');

    return `
请用以下格式生成摘要：

[主题] 简要描述对话主题
[行动] 描述采取的主要行动
[结果] 描述最终结果

对话内容：
${conversation}

摘要（最多 ${maxLength} 字符）：
    `.trim();
  }
}

async function customTemplateExample() {
  const manager = new BranchManager('session.jsonl');
  const llmClient = new AnthropicClient(process.env.ANTHROPIC_API_KEY!);
  const summarizer = new CustomBranchSummarizer(manager, llmClient);

  const branchFromId = manager.getLeafId();
  const result = await summarizer.generateSummary(branchFromId);

  console.log('Custom summary:', result.summary);

  manager.close();
}

customTemplateExample();
```

---

## 高级功能

### 功能 1：摘要缓存

```typescript
class CachedBranchSummarizer extends BranchSummarizer {
  private cache = new Map<string, BranchSummaryResult>();

  async generateSummary(
    branchFromId: string,
    options: BranchSummaryOptions = {}
  ): Promise<BranchSummaryResult> {
    const cacheKey = `${branchFromId}:${JSON.stringify(options)}`;

    if (this.cache.has(cacheKey)) {
      console.log('Using cached summary');
      return this.cache.get(cacheKey)!;
    }

    const result = await super.generateSummary(branchFromId, options);
    this.cache.set(cacheKey, result);

    return result;
  }

  clearCache(): void {
    this.cache.clear();
  }
}
```

### 功能 2：多语言摘要

```typescript
class MultilingualSummarizer extends BranchSummarizer {
  async generateMultilingualSummary(
    branchFromId: string,
    languages: string[]
  ): Promise<Map<string, string>> {
    const summaries = new Map<string, string>();

    for (const lang of languages) {
      const result = await this.generateSummaryInLanguage(branchFromId, lang);
      summaries.set(lang, result.summary);
    }

    return summaries;
  }

  private async generateSummaryInLanguage(
    branchFromId: string,
    language: string
  ): Promise<BranchSummaryResult> {
    // 修改 prompt 以指定语言
    const context = this.collectContext(branchFromId);
    const prompt = `Generate a summary in ${language}:\n\n${context.entries.map(e => e.content).join('\n')}`;

    // ... 调用 LLM
    return await this.generateSummary(branchFromId);
  }
}
```

### 功能 3：摘要评分

```typescript
class SummaryEvaluator {
  /**
   * 评估摘要质量
   */
  evaluateSummary(summary: string, originalEntries: SessionEntry[]): {
    score: number;
    feedback: string[];
  } {
    const feedback: string[] = [];
    let score = 100;

    // 检查长度
    if (summary.length < 20) {
      score -= 20;
      feedback.push('摘要过短');
    }

    if (summary.length > 300) {
      score -= 10;
      feedback.push('摘要过长');
    }

    // 检查关键词覆盖
    const keywords = this.extractKeywords(originalEntries);
    const coveredKeywords = keywords.filter(kw =>
      summary.toLowerCase().includes(kw.toLowerCase())
    );

    const coverage = coveredKeywords.length / keywords.length;
    if (coverage < 0.5) {
      score -= 30;
      feedback.push('关键信息覆盖不足');
    }

    // 检查结构
    if (!summary.includes('。') && !summary.includes('.')) {
      score -= 10;
      feedback.push('缺少句子结构');
    }

    return { score: Math.max(0, score), feedback };
  }

  private extractKeywords(entries: SessionEntry[]): string[] {
    // 简化实现：提取常见名词
    const text = entries
      .map(e => e.content || '')
      .join(' ')
      .toLowerCase();

    const words = text.split(/\W+/);
    const wordCounts = new Map<string, number>();

    for (const word of words) {
      if (word.length > 3) {
        wordCounts.set(word, (wordCounts.get(word) || 0) + 1);
      }
    }

    return Array.from(wordCounts.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10)
      .map(([word]) => word);
  }
}
```

---

## 与 Pi-mono 的对比

### Pi-mono 的实现

```typescript
// Pi-mono branch-summarization.ts
export async function generateBranchSummary(
  entries: SessionEntry[],
  llmClient: LLMClient
): Promise<string> {
  const messages = entries.filter(e =>
    e.type === 'user' || e.type === 'assistant'
  );

  const prompt = buildSummaryPrompt(messages);

  const response = await llmClient.complete({
    messages: [{ role: 'user', content: prompt }],
    max_tokens: 200
  });

  return response.content;
}
```

### 我们的实现

```typescript
// 更完整、更灵活的实现
class BranchSummarizer {
  // 支持文件跟踪
  trackFiles(entries): { readFiles, modifiedFiles } { ... }

  // 支持摘要优化
  optimizeLength(summary, maxLength): string { ... }

  // 支持批量生成
  async batchGenerate(branches): Promise<Map<string, string>> { ... }

  // 支持自定义模板
  protected buildSummaryPrompt(entries, maxLength): string { ... }
}

// 摘要质量评估
class SummaryEvaluator {
  evaluateSummary(summary, entries): { score, feedback } { ... }
}
```

---

## 关键要点总结

1. **上下文收集**：收集需要摘要的条目和文件操作
2. **LLM 调用**：使用 LLM 生成高质量摘要
3. **文件跟踪**：自动跟踪读取和修改的文件
4. **摘要优化**：控制长度、提取关键信息
5. **质量评估**：评估摘要质量并提供反馈

---

**下一步**：实现完整 SessionManager → `07_实战代码_06_完整SessionManager实现.md`
