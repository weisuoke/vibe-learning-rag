# 07_实战代码_03_条件路由与分支

> **本文档提供 RunnableLambda 在条件路由与分支场景中的完整实战代码。**

---

## 场景 1：基于输入类型的动态路由

### 需求

根据输入的类型（文本、JSON、URL等）选择不同的处理路径。

### 完整实现

```python
from langchain_core.runnables import RunnableLambda, RunnableBranch
import json
import re

def detect_input_type(input: str) -> str:
    """检测输入类型"""
    # 检测 JSON
    try:
        json.loads(input)
        return "json"
    except:
        pass

    # 检测 URL
    if re.match(r'https?://', input):
        return "url"

    # 检测代码
    if any(keyword in input for keyword in ['def ', 'class ', 'import ', 'function']):
        return "code"

    # 默认为文本
    return "text"

def process_json(input: str) -> dict:
    """处理 JSON 输入"""
    data = json.loads(input)
    return {"type": "json", "data": data, "keys": list(data.keys())}

def process_url(input: str) -> dict:
    """处理 URL 输入"""
    import requests
    response = requests.get(input)
    return {"type": "url", "status": response.status_code, "content_length": len(response.text)}

def process_code(input: str) -> dict:
    """处理代码输入"""
    lines = input.split('\n')
    return {"type": "code", "lines": len(lines), "language": "python"}

def process_text(input: str) -> dict:
    """处理文本输入"""
    return {"type": "text", "length": len(input), "words": len(input.split())}

# 方式1: 使用 RunnableBranch
type_router = RunnableBranch(
    (lambda x: detect_input_type(x) == "json", RunnableLambda(process_json)),
    (lambda x: detect_input_type(x) == "url", RunnableLambda(process_url)),
    (lambda x: detect_input_type(x) == "code", RunnableLambda(process_code)),
    RunnableLambda(process_text)  # 默认分支
)

# 测试
result1 = type_router.invoke('{"name": "Alice"}')  # JSON
result2 = type_router.invoke('https://example.com')  # URL
result3 = type_router.invoke('def hello(): pass')  # Code
result4 = type_router.invoke('Hello world')  # Text

# 方式2: 使用 RunnableLambda 实现路由
def smart_router(input: str) -> dict:
    """智能路由"""
    input_type = detect_input_type(input)

    if input_type == "json":
        return process_json(input)
    elif input_type == "url":
        return process_url(input)
    elif input_type == "code":
        return process_code(input)
    else:
        return process_text(input)

router = RunnableLambda(smart_router)
```

---

## 场景 2：基于内容复杂度的路由

### 需求

根据查询的复杂度选择不同的处理策略（简单查询用快速模型，复杂查询用强大模型）。

### 完整实现

```python
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI

def assess_complexity(query: str) -> str:
    """评估查询复杂度"""
    # 简单规则
    word_count = len(query.split())
    has_technical_terms = any(term in query.lower() for term in [
        'algorithm', 'implement', 'optimize', 'architecture', 'design pattern'
    ])
    has_multiple_questions = query.count('?') > 1

    if word_count < 10 and not has_technical_terms:
        return "simple"
    elif has_multiple_questions or has_technical_terms:
        return "complex"
    else:
        return "medium"

def route_by_complexity(query: str) -> str:
    """根据复杂度路由"""
    complexity = assess_complexity(query)

    if complexity == "simple":
        # 使用快速模型
        model = ChatOpenAI(model="gpt-3.5-turbo")
        return model.invoke(query).content
    elif complexity == "complex":
        # 使用强大模型
        model = ChatOpenAI(model="gpt-4")
        return model.invoke(query).content
    else:
        # 使用中等模型
        model = ChatOpenAI(model="gpt-4-turbo")
        return model.invoke(query).content

complexity_router = RunnableLambda(route_by_complexity)

# 测试
result1 = complexity_router.invoke("What is Python?")  # 简单 -> GPT-3.5
result2 = complexity_router.invoke("Explain the algorithm for optimizing database queries")  # 复杂 -> GPT-4
```

---

## 场景 3：多路径并行执行与结果合并

### 需求

同时执行多个处理路径，然后合并结果。

### 完整实现

```python
from langchain_core.runnables import RunnableLambda, RunnableParallel

def extract_keywords(text: str) -> list[str]:
    """提取关键词"""
    # 简化实现
    words = text.lower().split()
    return [w for w in words if len(w) > 4][:5]

def count_stats(text: str) -> dict:
    """统计信息"""
    return {
        "chars": len(text),
        "words": len(text.split()),
        "sentences": text.count('.') + text.count('!') + text.count('?')
    }

def detect_language(text: str) -> str:
    """检测语言"""
    # 简化实现
    if any(ord(c) > 127 for c in text):
        return "non-english"
    return "english"

def analyze_sentiment(text: str) -> str:
    """情感分析"""
    # 简化实现
    positive_words = ['good', 'great', 'excellent', 'amazing']
    negative_words = ['bad', 'terrible', 'awful', 'poor']

    text_lower = text.lower()
    pos_count = sum(1 for w in positive_words if w in text_lower)
    neg_count = sum(1 for w in negative_words if w in text_lower)

    if pos_count > neg_count:
        return "positive"
    elif neg_count > pos_count:
        return "negative"
    else:
        return "neutral"

# 并行执行多个分析
parallel_analysis = RunnableParallel(
    keywords=RunnableLambda(extract_keywords),
    stats=RunnableLambda(count_stats),
    language=RunnableLambda(detect_language),
    sentiment=RunnableLambda(analyze_sentiment)
)

# 合并结果
def merge_analysis(results: dict) -> dict:
    """合并分析结果"""
    return {
        "summary": {
            "language": results["language"],
            "sentiment": results["sentiment"],
            "word_count": results["stats"]["words"]
        },
        "keywords": results["keywords"],
        "details": results["stats"]
    }

# 完整管道
analysis_pipeline = (
    parallel_analysis
    | RunnableLambda(merge_analysis)
)

# 测试
text = "This is a great example of parallel processing in LangChain."
result = analysis_pipeline.invoke(text)
```

---

## 场景 4：条件链式路由

### 需求

根据前一步的结果决定下一步的处理路径。

### 完整实现

```python
from langchain_core.runnables import RunnableLambda

def step1_classify(input: str) -> dict:
    """第一步：分类"""
    if "question" in input.lower() or "?" in input:
        return {"type": "question", "content": input}
    elif "translate" in input.lower():
        return {"type": "translation", "content": input}
    else:
        return {"type": "statement", "content": input}

def step2_route(data: dict) -> dict:
    """第二步：根据类型路由"""
    if data["type"] == "question":
        # 问答处理
        return {"result": f"Answer: {data['content']}", "processed_by": "qa_handler"}
    elif data["type"] == "translation":
        # 翻译处理
        return {"result": f"Translated: {data['content']}", "processed_by": "translator"}
    else:
        # 陈述处理
        return {"result": f"Acknowledged: {data['content']}", "processed_by": "statement_handler"}

def step3_format(data: dict) -> str:
    """第三步：格式化输出"""
    return f"[{data['processed_by']}] {data['result']}"

# 条件链式路由
conditional_chain = (
    RunnableLambda(step1_classify)
    | RunnableLambda(step2_route)
    | RunnableLambda(step3_format)
)

# 测试
result1 = conditional_chain.invoke("What is Python?")
result2 = conditional_chain.invoke("Please translate this text")
result3 = conditional_chain.invoke("Python is great")
```

---

## 场景 5：动态工具选择

### 需求

根据用户意图动态选择使用哪个工具或 API。

### 完整实现

```python
from langchain_core.runnables import RunnableLambda

def detect_intent(query: str) -> str:
    """检测用户意图"""
    query_lower = query.lower()

    if any(word in query_lower for word in ['weather', 'temperature', 'forecast']):
        return "weather"
    elif any(word in query_lower for word in ['news', 'headline', 'article']):
        return "news"
    elif any(word in query_lower for word in ['calculate', 'compute', 'math']):
        return "calculator"
    elif any(word in query_lower for word in ['search', 'find', 'look up']):
        return "search"
    else:
        return "general"

def call_weather_api(query: str) -> dict:
    """调用天气 API"""
    return {"tool": "weather", "result": "Sunny, 25°C"}

def call_news_api(query: str) -> dict:
    """调用新闻 API"""
    return {"tool": "news", "result": "Latest headlines..."}

def call_calculator(query: str) -> dict:
    """调用计算器"""
    # 简化实现
    return {"tool": "calculator", "result": "42"}

def call_search_api(query: str) -> dict:
    """调用搜索 API"""
    return {"tool": "search", "result": "Search results..."}

def call_general_llm(query: str) -> dict:
    """调用通用 LLM"""
    return {"tool": "llm", "result": "General response..."}

def dynamic_tool_selector(query: str) -> dict:
    """动态工具选择器"""
    intent = detect_intent(query)

    if intent == "weather":
        return call_weather_api(query)
    elif intent == "news":
        return call_news_api(query)
    elif intent == "calculator":
        return call_calculator(query)
    elif intent == "search":
        return call_search_api(query)
    else:
        return call_general_llm(query)

tool_router = RunnableLambda(dynamic_tool_selector)

# 测试
result1 = tool_router.invoke("What's the weather today?")
result2 = tool_router.invoke("Show me the latest news")
result3 = tool_router.invoke("Calculate 2 + 2")
```

---

## 实战技巧

### 技巧 1：缓存路由决策

```python
route_cache = {}

def cached_route(input: str) -> str:
    """缓存路由决策"""
    if input in route_cache:
        return route_cache[input]

    route = detect_input_type(input)
    route_cache[input] = route
    return route
```

### 技巧 2：路由日志记录

```python
def logged_route(input: str) -> dict:
    """记录路由决策"""
    route = detect_input_type(input)
    print(f"Routing {input[:50]}... to {route}")

    result = smart_router(input)
    result["_route"] = route
    return result
```

### 技巧 3：降级路由

```python
def safe_route(input: str) -> dict:
    """带降级的路由"""
    try:
        return smart_router(input)
    except Exception as e:
        print(f"Routing failed: {e}, using default")
        return process_text(input)
```

---

## 完整示例：智能客服路由

```python
from langchain_core.runnables import RunnableLambda, RunnableParallel
from langchain_openai import ChatOpenAI

# 意图分类
def classify_intent(message: str) -> str:
    """分类用户意图"""
    message_lower = message.lower()

    intents = {
        "order_status": ["order", "status", "tracking", "delivery"],
        "refund": ["refund", "return", "money back"],
        "product_info": ["product", "price", "feature", "specification"],
        "complaint": ["complaint", "problem", "issue", "not working"],
        "general": []
    }

    for intent, keywords in intents.items():
        if any(kw in message_lower for kw in keywords):
            return intent

    return "general"

# 不同意图的处理器
def handle_order_status(message: str) -> str:
    """处理订单状态查询"""
    return "Let me check your order status..."

def handle_refund(message: str) -> str:
    """处理退款请求"""
    return "I'll help you with the refund process..."

def handle_product_info(message: str) -> str:
    """处理产品信息查询"""
    return "Here's the product information..."

def handle_complaint(message: str) -> str:
    """处理投诉"""
    return "I'm sorry to hear that. Let me escalate this..."

def handle_general(message: str) -> str:
    """处理一般查询"""
    model = ChatOpenAI(model="gpt-4")
    return model.invoke(message).content

# 路由器
def customer_service_router(message: str) -> str:
    """客服路由器"""
    intent = classify_intent(message)

    handlers = {
        "order_status": handle_order_status,
        "refund": handle_refund,
        "product_info": handle_product_info,
        "complaint": handle_complaint,
        "general": handle_general
    }

    handler = handlers.get(intent, handle_general)
    return handler(message)

# 添加日志和监控
def monitored_router(message: str) -> dict:
    """带监控的路由器"""
    import time

    start = time.time()
    intent = classify_intent(message)
    response = customer_service_router(message)
    duration = time.time() - start

    return {
        "intent": intent,
        "response": response,
        "duration": duration,
        "timestamp": time.time()
    }

cs_router = RunnableLambda(monitored_router)

# 测试
result = cs_router.invoke("Where is my order?")
print(result)
# {
#     "intent": "order_status",
#     "response": "Let me check your order status...",
#     "duration": 0.001,
#     "timestamp": 1708387200.0
# }
```

---

## 总结

### 核心模式

1. **类型路由**: 根据输入类型选择处理路径
2. **复杂度路由**: 根据任务复杂度选择模型
3. **并行执行**: 同时执行多个路径并合并
4. **条件链式**: 根据前一步结果决定下一步
5. **动态工具**: 根据意图选择工具

### 最佳实践

- 清晰的路由逻辑
- 添加日志记录
- 实现降级策略
- 缓存路由决策

---

## 引用来源

- [LangChain Branching Guide](https://python.langchain.com/docs/expression_language/how_to/routing)
- [RunnableBranch Documentation](https://python.langchain.com/docs/expression_language/primitives/branch)

---

**版本**: v1.0
**最后更新**: 2026-02-20
