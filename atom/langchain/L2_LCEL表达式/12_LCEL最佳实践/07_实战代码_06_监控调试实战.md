# 实战代码：监控调试实战

> **本节目标**：通过生产级API项目，掌握Callbacks、LangSmith追踪、结构化日志和指标收集的实战应用。

---

## 一、项目场景

**生产级RAG API**：
- Callbacks生命周期监控
- LangSmith可视化追踪
- 结构化日志（JSON格式）
- Prometheus指标收集
- 成本追踪与告警

**可观测性目标**：
- 完整调用链追踪
- 实时性能监控
- 成本透明化
- 问题快速定位

---

## 二、环境准备

```bash
# 安装依赖
uv add langchain langchain-openai structlog prometheus-client

# 配置环境
cat > .env << EOF
OPENAI_API_KEY=your_api_key_here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_key
LANGCHAIN_PROJECT=production_rag
EOF
```

---

## 三、Callbacks监控

### 3.1 基础回调

```python
# monitoring/callbacks.py
from langchain_core.callbacks import BaseCallbackHandler
import time
import logging

logger = logging.getLogger(__name__)

class MonitoringCallback(BaseCallbackHandler):
    """监控回调"""

    def __init__(self):
        self.start_time = None
        self.token_count = 0
        self.cost = 0.0

    def on_chain_start(self, serialized, inputs, **kwargs):
        """链开始"""
        self.start_time = time.time()
        logger.info(f"Chain started: {serialized.get('name')}")

    def on_chain_end(self, outputs, **kwargs):
        """链结束"""
        elapsed = time.time() - self.start_time
        logger.info(f"Chain completed in {elapsed:.3f}s")

    def on_llm_start(self, serialized, prompts, **kwargs):
        """LLM开始"""
        logger.info(f"LLM call started: {len(prompts)} prompts")

    def on_llm_end(self, response, **kwargs):
        """LLM结束"""
        # 提取token使用量
        usage = response.llm_output.get("token_usage", {})
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)
        total_tokens = prompt_tokens + completion_tokens

        # 计算成本（GPT-4o定价）
        cost = (prompt_tokens * 0.005 + completion_tokens * 0.015) / 1000

        self.token_count += total_tokens
        self.cost += cost

        logger.info(f"LLM completed: {total_tokens} tokens, ${cost:.4f}")

    def on_chain_error(self, error, **kwargs):
        """链错误"""
        logger.error(f"Chain error: {error}")

    def get_metrics(self):
        """获取指标"""
        return {
            "total_tokens": self.token_count,
            "total_cost": self.cost,
            "elapsed_time": time.time() - self.start_time if self.start_time else 0
        }


# 使用示例
if __name__ == "__main__":
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate

    logging.basicConfig(level=logging.INFO)

    # 创建回调
    callback = MonitoringCallback()

    # 创建链
    prompt = ChatPromptTemplate.from_template("回答: {question}")
    llm = ChatOpenAI(model="gpt-4o-mini")
    chain = prompt | llm

    # 执行（带监控）
    result = chain.invoke(
        {"question": "什么是LCEL?"},
        config={"callbacks": [callback]}
    )

    # 查看指标
    metrics = callback.get_metrics()
    print(f"\n指标:")
    print(f"- Token数: {metrics['total_tokens']}")
    print(f"- 成本: ${metrics['total_cost']:.4f}")
    print(f"- 耗时: {metrics['elapsed_time']:.3f}秒")
```

### 3.2 成本追踪器

```python
# 成本追踪
class CostTracker(BaseCallbackHandler):
    """成本追踪器"""

    def __init__(self, budget: float = 100.0):
        self.budget = budget
        self.spent = 0.0
        self.calls = []

    def on_llm_end(self, response, **kwargs):
        """记录每次LLM调用的成本"""
        usage = response.llm_output.get("token_usage", {})
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)

        # 计算成本
        cost = (prompt_tokens * 0.005 + completion_tokens * 0.015) / 1000
        self.spent += cost

        # 记录调用
        self.calls.append({
            "timestamp": time.time(),
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "cost": cost
        })

        # 预算告警
        if self.spent > self.budget * 0.8:
            logger.warning(f"⚠️ 预算告警: ${self.spent:.2f} / ${self.budget:.2f}")

        if self.spent > self.budget:
            raise RuntimeError(f"预算超支: ${self.spent:.2f} > ${self.budget:.2f}")

    def get_report(self):
        """生成报告"""
        return {
            "total_calls": len(self.calls),
            "total_spent": self.spent,
            "budget": self.budget,
            "budget_used_pct": self.spent / self.budget * 100,
            "avg_cost_per_call": self.spent / len(self.calls) if self.calls else 0
        }
```

---

## 四、结构化日志

### 4.1 structlog配置

```python
# monitoring/logging_config.py
import structlog
import logging

def configure_logging():
    """配置结构化日志"""
    structlog.configure(
        processors=[
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.add_log_level,
            structlog.processors.JSONRenderer()
        ],
        logger_factory=structlog.PrintLoggerFactory(),
    )

    # 配置标准logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(message)s"
    )


# 使用
configure_logging()
logger = structlog.get_logger()

# 记录日志
logger.info(
    "chain_execution",
    chain_name="rag_chain",
    input_length=100,
    output_length=200,
    latency=1.5
)
# 输出: {"event": "chain_execution", "chain_name": "rag_chain", ...}
```

### 4.2 关联ID追踪

```python
# 关联ID追踪
import uuid

class CorrelationIDCallback(BaseCallbackHandler):
    """关联ID回调"""

    def __init__(self, correlation_id: str = None):
        self.correlation_id = correlation_id or str(uuid.uuid4())
        self.logger = structlog.get_logger().bind(
            correlation_id=self.correlation_id
        )

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.logger.info(
            "chain_start",
            chain_name=serialized.get("name"),
            input=inputs
        )

    def on_chain_end(self, outputs, **kwargs):
        self.logger.info(
            "chain_end",
            output=outputs
        )

    def on_chain_error(self, error, **kwargs):
        self.logger.error(
            "chain_error",
            error=str(error)
        )


# 使用
correlation_id = str(uuid.uuid4())
callback = CorrelationIDCallback(correlation_id)

result = chain.invoke(
    input,
    config={"callbacks": [callback]}
)
```

---

## 五、Prometheus指标

### 5.1 指标定义

```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# 定义指标
chain_calls_total = Counter(
    'chain_calls_total',
    'Total chain calls',
    ['chain_name', 'status']
)

chain_latency_seconds = Histogram(
    'chain_latency_seconds',
    'Chain latency in seconds',
    ['chain_name']
)

chain_tokens_total = Counter(
    'chain_tokens_total',
    'Total tokens used',
    ['chain_name']
)

chain_cost_dollars = Counter(
    'chain_cost_dollars',
    'Total cost in dollars',
    ['chain_name']
)

active_chains = Gauge(
    'active_chains',
    'Number of active chains'
)


class MetricsCallback(BaseCallbackHandler):
    """Prometheus指标回调"""

    def __init__(self, chain_name: str = "default"):
        self.chain_name = chain_name
        self.start_time = None

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.start_time = time.time()
        active_chains.inc()

    def on_chain_end(self, outputs, **kwargs):
        # 记录延迟
        latency = time.time() - self.start_time
        chain_latency_seconds.labels(chain_name=self.chain_name).observe(latency)

        # 记录成功调用
        chain_calls_total.labels(
            chain_name=self.chain_name,
            status="success"
        ).inc()

        active_chains.dec()

    def on_llm_end(self, response, **kwargs):
        # 记录token和成本
        usage = response.llm_output.get("token_usage", {})
        tokens = usage.get("total_tokens", 0)
        cost = tokens * 0.01 / 1000

        chain_tokens_total.labels(chain_name=self.chain_name).inc(tokens)
        chain_cost_dollars.labels(chain_name=self.chain_name).inc(cost)

    def on_chain_error(self, error, **kwargs):
        chain_calls_total.labels(
            chain_name=self.chain_name,
            status="error"
        ).inc()
        active_chains.dec()
```

### 5.2 指标导出

```python
# 导出Prometheus指标
from prometheus_client import start_http_server

# 启动指标服务器
start_http_server(8000)
print("Prometheus metrics available at http://localhost:8000/metrics")

# 使用
callback = MetricsCallback(chain_name="rag_chain")
result = chain.invoke(input, config={"callbacks": [callback]})
```

---

## 六、LangSmith集成

### 6.1 基础配置

```python
# LangSmith追踪
import os

# 配置环境变量
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your_langsmith_key"
os.environ["LANGCHAIN_PROJECT"] = "production_rag"

# 自动追踪所有链
chain = prompt | llm | parser
result = chain.invoke(input)
# 自动上传到LangSmith
```

### 6.2 自定义追踪

```python
# 自定义追踪标签
result = chain.invoke(
    input,
    config={
        "run_name": "rag_query",
        "tags": ["production", "v1.0"],
        "metadata": {
            "user_id": "user_123",
            "session_id": "session_456"
        }
    }
)
```

---

## 七、完整监控系统

### 7.1 生产级API

```python
# main.py
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from monitoring.callbacks import MonitoringCallback, CostTracker
from monitoring.metrics import MetricsCallback
from monitoring.logging_config import configure_logging
import structlog
import uuid

# 加载环境变量
load_dotenv()

# 配置日志
configure_logging()
logger = structlog.get_logger()

# 创建FastAPI应用
app = FastAPI(title="Monitored RAG API")

# 创建链
prompt = ChatPromptTemplate.from_template("回答: {question}")
llm = ChatOpenAI(model="gpt-4o-mini")
chain = prompt | llm | StrOutputParser()


class QueryRequest(BaseModel):
    """查询请求"""
    question: str
    user_id: str = "anonymous"


class QueryResponse(BaseModel):
    """查询响应"""
    answer: str
    correlation_id: str
    metrics: dict


@app.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """问答接口（带完整监控）"""
    # 生成关联ID
    correlation_id = str(uuid.uuid4())

    # 绑定关联ID到logger
    log = logger.bind(
        correlation_id=correlation_id,
        user_id=request.user_id
    )

    log.info("query_received", question=request.question)

    try:
        # 创建回调
        monitoring_cb = MonitoringCallback()
        cost_tracker = CostTracker(budget=10.0)
        metrics_cb = MetricsCallback(chain_name="rag_chain")

        # 执行链
        answer = chain.invoke(
            {"question": request.question},
            config={
                "callbacks": [monitoring_cb, cost_tracker, metrics_cb],
                "run_name": "rag_query",
                "tags": ["production", request.user_id],
                "metadata": {
                    "correlation_id": correlation_id,
                    "user_id": request.user_id
                }
            }
        )

        # 获取指标
        metrics = monitoring_cb.get_metrics()

        log.info(
            "query_completed",
            answer_length=len(answer),
            tokens=metrics["total_tokens"],
            cost=metrics["total_cost"],
            latency=metrics["elapsed_time"]
        )

        return QueryResponse(
            answer=answer,
            correlation_id=correlation_id,
            metrics=metrics
        )

    except Exception as e:
        log.error("query_failed", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health():
    """健康检查"""
    return {"status": "healthy"}


@app.get("/metrics")
async def metrics():
    """指标端点"""
    from prometheus_client import generate_latest
    return generate_latest()


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### 7.2 运行与测试

```bash
# 运行API
python main.py

# 测试查询
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "什么是LCEL?", "user_id": "user_123"}'

# 查看指标
curl http://localhost:8000/metrics
```

---

## 八、调试工具

### 8.1 全局调试模式

```python
# 启用调试模式
from langchain.globals import set_debug

set_debug(True)

# 执行链（输出详细日志）
result = chain.invoke(input)

# 输出示例:
# [chain/start] [1:chain:RunnableSequence] Entering Chain run...
# [llm/start] [1:llm:ChatOpenAI] Entering LLM run...
# [llm/end] [1:llm:ChatOpenAI] [2s] Exiting LLM run...
# [chain/end] [1:chain:RunnableSequence] [2.1s] Exiting Chain run...
```

### 8.2 astream_events调试

```python
# 流式事件调试
async def debug_chain():
    async for event in chain.astream_events(input, version="v2"):
        kind = event["event"]
        if kind == "on_chain_start":
            print(f"开始: {event['name']}")
        elif kind == "on_chain_stream":
            print(f"流式: {event['data']['chunk']}")
        elif kind == "on_chain_end":
            print(f"结束: {event['name']}")


# 运行
import asyncio
asyncio.run(debug_chain())
```

---

## 九、告警系统

### 9.1 成本告警

```python
# 成本告警
class CostAlerter(BaseCallbackHandler):
    """成本告警器"""

    def __init__(self, threshold: float = 1.0):
        self.threshold = threshold
        self.spent = 0.0

    def on_llm_end(self, response, **kwargs):
        usage = response.llm_output.get("token_usage", {})
        cost = usage.get("total_tokens", 0) * 0.01 / 1000
        self.spent += cost

        if self.spent > self.threshold:
            logger.warning(
                "cost_alert",
                spent=self.spent,
                threshold=self.threshold
            )
```

### 9.2 延迟告警

```python
# 延迟告警
class LatencyAlerter(BaseCallbackHandler):
    """延迟告警器"""

    def __init__(self, threshold: float = 3.0):
        self.threshold = threshold
        self.start_time = None

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.start_time = time.time()

    def on_chain_end(self, outputs, **kwargs):
        latency = time.time() - self.start_time
        if latency > self.threshold:
            logger.warning(
                "latency_alert",
                latency=latency,
                threshold=self.threshold
            )
```

---

## 十、总结

### 核心要点

1. **Callbacks**: 生命周期监控，灵活插入逻辑
2. **结构化日志**: JSON格式，易于分析
3. **Prometheus指标**: 量化监控，可视化展示
4. **LangSmith**: 可视化追踪，89%生产采用
5. **关联ID**: 请求追踪，问题定位

### 监控层次

```
告警（异常检测）
  ↓
指标（Metrics）
  ↓
追踪（Tracing）
  ↓
日志（Logging）
```

### 实战收获

- ✅ 完整调用链追踪
- ✅ 实时性能监控
- ✅ 成本透明化
- ✅ 问题快速定位
- ✅ 生产级可观测性

---

**下一步**: 学习【生产环境部署实战】，构建完整部署方案。
