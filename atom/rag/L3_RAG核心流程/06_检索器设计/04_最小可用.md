# æœ€å°å¯ç”¨çŸ¥è¯†

> æŒæ¡ä»¥ä¸‹20%çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œå°±èƒ½è§£å†³80%çš„RAGæ£€ç´¢é—®é¢˜

---

## 4.1 æ··åˆæ£€ç´¢æ˜¯2025-2026æ ‡å‡†æ–¹æ¡ˆ

**æ ¸å¿ƒè§‚ç‚¹**: ä¸è¦åªç”¨Denseæˆ–Sparseï¼Œæ··åˆæ£€ç´¢æ‰æ˜¯ç‹é“

### ä¸ºä»€ä¹ˆï¼Ÿ

- **Denseæ£€ç´¢**: ç†è§£è¯­ä¹‰ï¼Œä½†å¯èƒ½æ¼æ‰å…³é”®æœ¯è¯­
- **Sparseæ£€ç´¢**: ç²¾å‡†åŒ¹é…ï¼Œä½†ä¸ç†è§£åŒä¹‰è¯
- **Hybridæ£€ç´¢**: ä¸¤è€…ç»“åˆï¼Œä¼˜åŠ¿äº’è¡¥

### æœ€ç®€å®ç°

```python
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import Chroma

# Denseæ£€ç´¢å™¨
dense_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# Sparseæ£€ç´¢å™¨
sparse_retriever = BM25Retriever.from_documents(documents)
sparse_retriever.k = 10

# æ··åˆæ£€ç´¢å™¨ (Denseæƒé‡0.6, Sparseæƒé‡0.4)
hybrid_retriever = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.6, 0.4]
)

# ä½¿ç”¨
results = hybrid_retriever.get_relevant_documents("æŸ¥è¯¢æ–‡æœ¬")
```

### æƒé‡é€‰æ‹©ç»éªŒ

| åœºæ™¯ | Denseæƒé‡ | Sparseæƒé‡ | è¯´æ˜ |
|------|-----------|------------|------|
| é€šç”¨é—®ç­” | 0.6 | 0.4 | å¹³è¡¡è¯­ä¹‰å’Œç²¾å‡† |
| æ³•å¾‹/åŒ»ç–— | 0.4 | 0.6 | æœ¯è¯­ç²¾å‡†æ›´é‡è¦ |
| åˆ›æ„å†…å®¹ | 0.7 | 0.3 | è¯­ä¹‰ç†è§£æ›´é‡è¦ |

**å‚è€ƒ**: [DAT: Dynamic Alpha Tuning 2025](https://arxiv.org/abs/2503.23013) - åŠ¨æ€æƒé‡è°ƒæ•´æ¡†æ¶

---

## 4.2 HNSWæ˜¯100Må‘é‡ä»¥å†…çš„é¦–é€‰ç´¢å¼•

**æ ¸å¿ƒè§‚ç‚¹**: ä¸è¦çº ç»“ç´¢å¼•ç®—æ³•ï¼Œ100Må‘é‡ä»¥å†…ç›´æ¥ç”¨HNSW

### æ¨èå‚æ•°

```python
import chromadb

# ç”Ÿäº§çº§HNSWé…ç½®
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.create_collection(
    name="my_collection",
    metadata={
        "hnsw:space": "cosine",           # ç›¸ä¼¼åº¦åº¦é‡
        "hnsw:construction_ef": 200,      # æ„å»ºæ—¶æœç´¢èŒƒå›´
        "hnsw:M": 16,                     # æ¯å±‚è¿æ¥æ•°
        "hnsw:search_ef": 100             # æŸ¥è¯¢æ—¶æœç´¢èŒƒå›´
    }
)
```

### å‚æ•°è°ƒä¼˜ç»éªŒ

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ | æƒè¡¡ |
|------|--------|------|------|
| **M** | 16-32 | æ¯å±‚è¿æ¥æ•° | è¶Šå¤§è¶Šå‡†ï¼Œä½†å†…å­˜å ç”¨é«˜ |
| **efConstruction** | 200-400 | æ„å»ºæ—¶æœç´¢èŒƒå›´ | è¶Šå¤§è¶Šå‡†ï¼Œä½†æ„å»ºæ…¢ |
| **efSearch** | 100-200 | æŸ¥è¯¢æ—¶æœç´¢èŒƒå›´ | è¶Šå¤§è¶Šå‡†ï¼Œä½†æŸ¥è¯¢æ…¢ |

**å¿«é€Ÿå†³ç­–**:
- å°æ•°æ®é›†ï¼ˆ<1Mï¼‰: M=16, efConstruction=200, efSearch=100
- ä¸­æ•°æ®é›†ï¼ˆ1M-10Mï¼‰: M=32, efConstruction=400, efSearch=200
- å¤§æ•°æ®é›†ï¼ˆ>10Mï¼‰: è€ƒè™‘IVFæˆ–åˆ†ç‰‡

**å‚è€ƒ**: [Vector Similarity Search 2025: RAG Engineer's Guide](https://www.linkedin.com/pulse/vector-similarity-search-2025-rag-engineers-field-guide-gadiraju-gqucc)

---

## 4.3 Top-K + MMRé¿å…é‡å¤ç»“æœ

**æ ¸å¿ƒè§‚ç‚¹**: ä¸è¦åªç”¨Top-Kï¼ŒåŠ ä¸ŠMMRæå‡å¤šæ ·æ€§

### é—®é¢˜åœºæ™¯

```python
# âŒ åªç”¨Top-Kï¼Œå¯èƒ½è¿”å›10ä¸ªå‡ ä¹ç›¸åŒçš„ç»“æœ
results = retriever.get_relevant_documents("Pythonæ•™ç¨‹", k=10)
# ç»“æœ: 10ç¯‡éƒ½æ˜¯"Pythonå…¥é—¨æ•™ç¨‹"ï¼Œå†…å®¹é«˜åº¦é‡å¤
```

### è§£å†³æ–¹æ¡ˆ: MMR

```python
# âœ… ä½¿ç”¨MMRï¼Œå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
results = vectorstore.max_marginal_relevance_search(
    query="Pythonæ•™ç¨‹",
    k=10,              # æœ€ç»ˆè¿”å›10ä¸ªç»“æœ
    fetch_k=50,        # å…ˆæ£€ç´¢50ä¸ªå€™é€‰
    lambda_mult=0.7    # 0.7ç›¸å…³æ€§ + 0.3å¤šæ ·æ€§
)
# ç»“æœ: åŒ…å«å…¥é—¨ã€è¿›é˜¶ã€å®æˆ˜ç­‰ä¸åŒç±»å‹çš„æ•™ç¨‹
```

### Lambdaå‚æ•°é€‰æ‹©

| lambdaå€¼ | ç›¸å…³æ€§ | å¤šæ ·æ€§ | é€‚ç”¨åœºæ™¯ |
|----------|--------|--------|----------|
| 1.0 | 100% | 0% | ç²¾å‡†é—®ç­”ï¼ˆåªè¦æœ€ç›¸å…³çš„ï¼‰ |
| 0.7 | 70% | 30% | é€šç”¨åœºæ™¯ï¼ˆæ¨èï¼‰ |
| 0.5 | 50% | 50% | æ¢ç´¢æ€§æœç´¢ |
| 0.3 | 30% | 70% | å‘ç°æ–°å†…å®¹ |

**å‚è€ƒ**: [Diversifying search results with MMR - Elastic 2025](https://www.elastic.co/search-labs/blog/maximum-marginal-relevance-diversify-results)

---

## 4.4 Cosineç›¸ä¼¼åº¦æ˜¯é»˜è®¤é¦–é€‰

**æ ¸å¿ƒè§‚ç‚¹**: ä¸è¦çº ç»“åº¦é‡é€‰æ‹©ï¼Œå¤§éƒ¨åˆ†åœºæ™¯ç”¨Cosineå°±å¯¹äº†

### ä¸‰ç§ä¸»è¦åº¦é‡

```python
import numpy as np

def cosine_similarity(a, b):
    """ä½™å¼¦ç›¸ä¼¼åº¦ - æ¨è"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def euclidean_distance(a, b):
    """æ¬§æ°è·ç¦» - ç‰¹å®šåœºæ™¯"""
    return np.linalg.norm(a - b)

def dot_product(a, b):
    """å†…ç§¯ - å½’ä¸€åŒ–å‘é‡å¯ç”¨"""
    return np.dot(a, b)
```

### å¿«é€Ÿå†³ç­–è¡¨

| åº¦é‡ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|----------|------|------|
| **Cosine** | é€šç”¨åœºæ™¯ï¼ˆæ¨èï¼‰ | ä¸å—å‘é‡é•¿åº¦å½±å“ | è®¡ç®—ç¨æ…¢ |
| **Dot Product** | å½’ä¸€åŒ–å‘é‡ | è®¡ç®—æœ€å¿« | éœ€è¦å‘é‡å½’ä¸€åŒ– |
| **Euclidean** | èšç±»ã€å¼‚å¸¸æ£€æµ‹ | ç›´è§‚ | å—å‘é‡é•¿åº¦å½±å“ |

**ç»éªŒæ³•åˆ™**:
- âœ… 90%åœºæ™¯ç”¨Cosine
- âœ… å‘é‡å·²å½’ä¸€åŒ–å¯ç”¨Dot Productï¼ˆæ›´å¿«ï¼‰
- âœ… éœ€è¦è€ƒè™‘å‘é‡é•¿åº¦æ—¶ç”¨Euclidean

**å‚è€ƒ**: [Embeddings in Practice 2026](https://medium.com/@adnanmasood/embeddings-in-practice-a-research-implementation-guide-9dbf20961590)

---

## 4.5 Recall@kæ˜¯æœ€é‡è¦çš„è¯„ä¼°æŒ‡æ ‡

**æ ¸å¿ƒè§‚ç‚¹**: ä¸è¦åªçœ‹"æ„Ÿè§‰"ï¼Œç”¨Recall@ké‡åŒ–æ£€ç´¢è´¨é‡

### ä»€ä¹ˆæ˜¯Recall@kï¼Ÿ

**å®šä¹‰**: åœ¨è¿”å›çš„Top-Kç»“æœä¸­ï¼Œæ‰¾åˆ°äº†å¤šå°‘ä¸ªçœŸæ­£ç›¸å…³çš„æ–‡æ¡£

```python
def recall_at_k(retrieved_docs, relevant_docs, k):
    """
    è®¡ç®—Recall@k

    Args:
        retrieved_docs: æ£€ç´¢è¿”å›çš„æ–‡æ¡£IDåˆ—è¡¨
        relevant_docs: çœŸæ­£ç›¸å…³çš„æ–‡æ¡£IDé›†åˆ
        k: è€ƒå¯Ÿå‰kä¸ªç»“æœ
    """
    top_k = set(retrieved_docs[:k])
    relevant_set = set(relevant_docs)

    # æ‰¾åˆ°äº†å¤šå°‘ä¸ªç›¸å…³æ–‡æ¡£
    hits = len(top_k & relevant_set)

    # Recall = æ‰¾åˆ°çš„ç›¸å…³æ–‡æ¡£æ•° / æ€»ç›¸å…³æ–‡æ¡£æ•°
    return hits / len(relevant_set) if relevant_set else 0

# ç¤ºä¾‹
retrieved = ["doc1", "doc5", "doc3", "doc8", "doc2"]
relevant = ["doc1", "doc3", "doc7"]

print(f"Recall@3: {recall_at_k(retrieved, relevant, 3)}")
# è¾“å‡º: 0.667 (æ‰¾åˆ°äº†doc1å’Œdoc3ï¼Œæ¼äº†doc7)
```

### ç›®æ ‡å€¼å‚è€ƒ

| åœºæ™¯ | Recall@5 | Recall@10 | è¯´æ˜ |
|------|----------|-----------|------|
| ç²¾å‡†é—®ç­” | >0.8 | >0.9 | å¿…é¡»æ‰¾åˆ°å…³é”®ä¿¡æ¯ |
| é€šç”¨æ£€ç´¢ | >0.6 | >0.8 | å¹³è¡¡ç²¾å‡†å’Œå¬å› |
| æ¢ç´¢æ€§æœç´¢ | >0.4 | >0.7 | å¤šæ ·æ€§æ›´é‡è¦ |

**å®æˆ˜å»ºè®®**:
1. å…ˆå»ºç«‹æµ‹è¯•é›†ï¼ˆ100-500ä¸ªæŸ¥è¯¢+æ ‡æ³¨ï¼‰
2. è®¡ç®—Recall@5å’ŒRecall@10
3. ä½äºç›®æ ‡å€¼æ—¶è°ƒæ•´æ£€ç´¢ç­–ç•¥
4. æŒç»­ç›‘æ§ç”Ÿäº§ç¯å¢ƒæŒ‡æ ‡

**å‚è€ƒ**: [RAG Evaluation Guide 2025 - Maxim AI](https://www.getmaxim.ai/articles/rag-evaluation-a-complete-guide-for-2025)

---

## æœ€å°å¯ç”¨æ€»ç»“

æŒæ¡ä»¥ä¸Š5ä¸ªæ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼Œä½ å°±èƒ½ï¼š

### âœ… èƒ½åšä»€ä¹ˆ

1. **æ„å»ºç”Ÿäº§çº§æ··åˆæ£€ç´¢ç³»ç»Ÿ**
   - Dense + Sparseèåˆ
   - RRFæƒé‡è°ƒæ•´

2. **é…ç½®HNSWç´¢å¼•**
   - æ ¹æ®æ•°æ®è§„æ¨¡é€‰æ‹©å‚æ•°
   - å¹³è¡¡ç²¾åº¦å’Œæ€§èƒ½

3. **ä¼˜åŒ–æ£€ç´¢ç»“æœ**
   - ä½¿ç”¨MMRæå‡å¤šæ ·æ€§
   - é¿å…é‡å¤ç»“æœ

4. **é€‰æ‹©ç›¸ä¼¼åº¦åº¦é‡**
   - 90%åœºæ™¯ç”¨Cosine
   - ç‰¹æ®Šåœºæ™¯çµæ´»è°ƒæ•´

5. **è¯„ä¼°æ£€ç´¢è´¨é‡**
   - è®¡ç®—Recall@k
   - é‡åŒ–ä¼˜åŒ–æ•ˆæœ

### âœ… ä¸ºåç»­å­¦ä¹ æ‰“åŸºç¡€

- æ·±å…¥ç†è§£Dense/SparseåŸç† â†’ æ ¸å¿ƒæ¦‚å¿µ1-2
- å­¦ä¹ IVFç´¢å¼• â†’ æ ¸å¿ƒæ¦‚å¿µ7
- æŒæ¡æ›´å¤šè¯„ä¼°æŒ‡æ ‡ â†’ æ ¸å¿ƒæ¦‚å¿µ8
- å®æˆ˜è°ƒä¼˜ â†’ å®æˆ˜ä»£ç 1-7

---

## å¿«é€Ÿä¸Šæ‰‹ä»£ç 

```python
"""
æœ€å°å¯ç”¨RAGæ£€ç´¢å™¨ - 5åˆ†é’Ÿä¸Šæ‰‹
"""
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# 1. å‡†å¤‡æ–‡æ¡£
documents = [...]  # ä½ çš„æ–‡æ¡£åˆ—è¡¨

# 2. åˆ›å»ºDenseæ£€ç´¢å™¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=documents,
    embedding=embeddings,
    collection_metadata={
        "hnsw:space": "cosine",
        "hnsw:M": 16,
        "hnsw:construction_ef": 200
    }
)
dense_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# 3. åˆ›å»ºSparseæ£€ç´¢å™¨
sparse_retriever = BM25Retriever.from_documents(documents)
sparse_retriever.k = 10

# 4. æ··åˆæ£€ç´¢å™¨
hybrid_retriever = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.6, 0.4]
)

# 5. ä½¿ç”¨MMRæ£€ç´¢
results = vectorstore.max_marginal_relevance_search(
    query="ä½ çš„æŸ¥è¯¢",
    k=5,
    fetch_k=20,
    lambda_mult=0.7
)

# 6. è¯„ä¼°
def evaluate_retriever(retriever, test_queries):
    recalls = []
    for query, relevant_docs in test_queries:
        retrieved = retriever.get_relevant_documents(query)
        retrieved_ids = [doc.metadata['id'] for doc in retrieved]
        recall = recall_at_k(retrieved_ids, relevant_docs, k=5)
        recalls.append(recall)
    return sum(recalls) / len(recalls)

print(f"Average Recall@5: {evaluate_retriever(hybrid_retriever, test_set)}")
```

---

**è¿™äº›çŸ¥è¯†è¶³ä»¥è®©ä½ æ„å»ºä¸€ä¸ªç”Ÿäº§çº§çš„RAGæ£€ç´¢å™¨ï¼** ğŸ¯

æƒ³æ·±å…¥ç†è§£åŸç†ï¼Ÿç»§ç»­å­¦ä¹ ã€æ ¸å¿ƒæ¦‚å¿µã€‘å’Œã€å®æˆ˜ä»£ç ã€‘ç« èŠ‚ã€‚
