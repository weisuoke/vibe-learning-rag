# 核心概念：监控与调试体系

> **本节目标**：掌握LCEL的可观测性体系，实现生产级监控与调试能力。

---

## 一、为什么需要监控与调试？

### 1.1 生产环境的挑战

**黑盒问题**：
- LLM调用不透明
- 错误难以定位
- 性能瓶颈不明
- 成本失控

**可观测性收益**：
- **89%生产部署**使用可观测性工具
- **62%应用**有详细的步骤追踪
- 问题定位时间：从小时降至分钟
- 成本优化：识别浪费点

### 1.2 可观测性三支柱

| 支柱 | 作用 | 工具 |
|------|------|------|
| **Logging** | 记录事件 | structlog, Python logging |
| **Tracing** | 追踪请求 | LangSmith, OpenTelemetry |
| **Metrics** | 量化指标 | Prometheus, CloudWatch |

---

## 二、Callbacks：生命周期钩子

### 2.1 核心原理

**Callbacks**：在链执行的关键节点插入自定义逻辑。

**生命周期事件**：
```
on_chain_start → on_llm_start → on_llm_end → on_chain_end
                      ↓ 错误
                  on_chain_error
```

### 2.2 基础用法

```python
from langchain_core.callbacks import BaseCallbackHandler

class MonitoringCallback(BaseCallbackHandler):
    """监控回调"""

    def on_chain_start(self, serialized, inputs, **kwargs):
        """链开始时"""
        print(f"[START] Chain: {serialized.get('name')}")
        print(f"[INPUT] {inputs}")

    def on_chain_end(self, outputs, **kwargs):
        """链结束时"""
        print(f"[OUTPUT] {outputs}")

    def on_chain_error(self, error, **kwargs):
        """链错误时"""
        print(f"[ERROR] {error}")

# 使用
chain = prompt | llm | parser
result = chain.invoke(
    input,
    config={"callbacks": [MonitoringCallback()]}
)
```

### 2.3 with_listeners：简化语法

```python
# 定义监听器
def on_start(run):
    print(f"开始: {run.name}")

def on_end(run):
    print(f"结束: {run.name}, 耗时: {run.end_time - run.start_time}")

def on_error(run):
    print(f"错误: {run.error}")

# 添加监听器
chain = (
    prompt | llm | parser
).with_listeners(
    on_start=on_start,
    on_end=on_end,
    on_error=on_error
)

# 异步版本
chain = chain.with_alisteners(
    on_start=async_on_start,
    on_end=async_on_end
)
```

### 2.4 实战场景：成本追踪

```python
class CostTracker(BaseCallbackHandler):
    """成本追踪器"""

    def __init__(self):
        self.total_tokens = 0
        self.total_cost = 0.0

    def on_llm_end(self, response, **kwargs):
        """LLM调用结束时"""
        # 提取token使用量
        usage = response.llm_output.get("token_usage", {})
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)

        # 计算成本（GPT-4o定价）
        cost = (prompt_tokens * 0.005 + completion_tokens * 0.015) / 1000

        self.total_tokens += prompt_tokens + completion_tokens
        self.total_cost += cost

        print(f"本次调用: {prompt_tokens + completion_tokens} tokens, ${cost:.4f}")

    def report(self):
        print(f"总Token: {self.total_tokens}")
        print(f"总成本: ${self.total_cost:.2f}")

# 使用
tracker = CostTracker()
chain = chain.with_config({"callbacks": [tracker]})

# 执行多次调用
for query in queries:
    chain.invoke(query)

# 查看报告
tracker.report()
```

---

## 三、LangSmith：可视化追踪

### 3.1 核心原理

**LangSmith**：LangChain官方的可观测性平台。

**功能**：
- 完整的调用链追踪
- Token使用量统计
- 成本分析
- 延迟监控
- 错误率追踪

### 3.2 基础配置

```python
import os

# 配置LangSmith
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your_api_key"
os.environ["LANGCHAIN_PROJECT"] = "my_project"

# 自动追踪所有链
chain = prompt | llm | parser
result = chain.invoke(input)
# 自动上传到LangSmith
```

### 3.3 自定义追踪

```python
from langchain.callbacks.tracers import LangChainTracer

# 自定义追踪器
tracer = LangChainTracer(
    project_name="production",
    tags=["v1.0", "rag"]
)

# 使用
result = chain.invoke(
    input,
    config={
        "callbacks": [tracer],
        "metadata": {
            "user_id": "123",
            "session_id": "abc"
        }
    }
)
```

### 3.4 实战场景：RAG调试

```python
# RAG链追踪
rag_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | parser
).with_config(
    run_name="rag_pipeline",
    tags=["rag", "production"]
)

# 执行
result = rag_chain.invoke("什么是LCEL？")

# LangSmith UI显示：
# 1. 检索步骤：耗时、检索到的文档
# 2. Prompt构建：最终prompt内容
# 3. LLM调用：token使用、成本、延迟
# 4. 解析步骤：输出结果
```

---

## 四、Structured Logging：结构化日志

### 4.1 核心原理

**结构化日志**：机器可读的JSON格式日志。

**优势**：
- 易于查询和分析
- 支持日志聚合
- 包含上下文信息

### 4.2 基础实现

```python
import structlog
import logging

# 配置structlog
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
    logger_factory=structlog.PrintLoggerFactory(),
)

logger = structlog.get_logger()

# 使用
class LoggingCallback(BaseCallbackHandler):
    """结构化日志回调"""

    def on_chain_start(self, serialized, inputs, **kwargs):
        logger.info(
            "chain_start",
            chain_name=serialized.get("name"),
            input=inputs,
            run_id=kwargs.get("run_id")
        )

    def on_chain_end(self, outputs, **kwargs):
        logger.info(
            "chain_end",
            output=outputs,
            run_id=kwargs.get("run_id")
        )

    def on_chain_error(self, error, **kwargs):
        logger.error(
            "chain_error",
            error=str(error),
            run_id=kwargs.get("run_id")
        )
```

### 4.3 关联ID追踪

```python
import uuid

def process_request(user_query: str):
    """处理请求（带关联ID）"""
    # 生成关联ID
    correlation_id = str(uuid.uuid4())

    # 绑定到logger
    log = logger.bind(correlation_id=correlation_id)

    log.info("request_received", query=user_query)

    try:
        # 执行链
        result = chain.invoke(
            user_query,
            config={
                "metadata": {"correlation_id": correlation_id}
            }
        )
        log.info("request_completed", result=result)
        return result

    except Exception as e:
        log.error("request_failed", error=str(e))
        raise
```

### 4.4 安全性：过滤敏感信息

```python
class SafeLoggingCallback(BaseCallbackHandler):
    """安全日志回调（过滤PII）"""

    def _sanitize(self, data):
        """移除敏感信息"""
        if isinstance(data, dict):
            return {
                k: "[REDACTED]" if k in ["password", "api_key", "token"] else v
                for k, v in data.items()
            }
        return data

    def on_chain_start(self, serialized, inputs, **kwargs):
        safe_inputs = self._sanitize(inputs)
        logger.info("chain_start", input=safe_inputs)
```

---

## 五、Metrics：量化指标

### 5.1 核心指标

| 指标 | 说明 | 目标 |
|------|------|------|
| **Total Calls** | 总调用次数 | 监控流量 |
| **Total Tokens** | 总Token数 | 成本控制 |
| **Average Latency** | 平均延迟 | <2秒 |
| **Error Rate** | 错误率 | <1% |
| **Cost per Request** | 单次成本 | 优化目标 |
| **Cache Hit Rate** | 缓存命中率 | >60% |

### 5.2 Prometheus集成

```python
from prometheus_client import Counter, Histogram, Gauge

# 定义指标
chain_calls = Counter('chain_calls_total', 'Total chain calls')
chain_tokens = Counter('chain_tokens_total', 'Total tokens used')
chain_latency = Histogram('chain_latency_seconds', 'Chain latency')
chain_errors = Counter('chain_errors_total', 'Total errors')
chain_cost = Counter('chain_cost_dollars', 'Total cost')

class MetricsCallback(BaseCallbackHandler):
    """指标收集回调"""

    def on_chain_start(self, serialized, inputs, **kwargs):
        chain_calls.inc()
        self.start_time = time.time()

    def on_chain_end(self, outputs, **kwargs):
        # 记录延迟
        latency = time.time() - self.start_time
        chain_latency.observe(latency)

    def on_llm_end(self, response, **kwargs):
        # 记录token和成本
        usage = response.llm_output.get("token_usage", {})
        tokens = usage.get("total_tokens", 0)
        cost = tokens * 0.01 / 1000

        chain_tokens.inc(tokens)
        chain_cost.inc(cost)

    def on_chain_error(self, error, **kwargs):
        chain_errors.inc()
```

---

## 六、调试工具

### 6.1 全局调试模式

```python
from langchain.globals import set_debug

# 启用调试模式
set_debug(True)

# 执行链
chain = prompt | llm | parser
result = chain.invoke(input)

# 输出详细日志：
# [chain/start] [1:chain:RunnableSequence] Entering Chain run...
# [llm/start] [1:llm:ChatOpenAI] Entering LLM run...
# [llm/end] [1:llm:ChatOpenAI] [2s] Exiting LLM run...
# [chain/end] [1:chain:RunnableSequence] [2.1s] Exiting Chain run...
```

### 6.2 astream_events：事件流

```python
# 流式获取事件
async for event in chain.astream_events(input, version="v2"):
    kind = event["event"]
    if kind == "on_chain_start":
        print(f"开始: {event['name']}")
    elif kind == "on_chain_stream":
        print(f"流式输出: {event['data']['chunk']}")
    elif kind == "on_chain_end":
        print(f"结束: {event['name']}")
```

### 6.3 自定义事件

```python
from langchain_core.runnables import RunnableLambda

async def custom_step(input):
    # 发送自定义事件
    await adispatch_custom_event(
        "custom_event",
        {"message": "处理中...", "progress": 0.5}
    )
    return process(input)

chain = RunnableLambda(custom_step) | llm
```

---

## 七、告警与异常检测

### 7.1 成本告警

```python
class CostAlerter(BaseCallbackHandler):
    """成本告警"""

    def __init__(self, budget: float):
        self.budget = budget
        self.spent = 0.0

    def on_llm_end(self, response, **kwargs):
        usage = response.llm_output.get("token_usage", {})
        cost = usage.get("total_tokens", 0) * 0.01 / 1000
        self.spent += cost

        # 检查预算
        if self.spent > self.budget * 0.8:
            logger.warning(
                "budget_alert",
                spent=self.spent,
                budget=self.budget,
                percentage=self.spent / self.budget * 100
            )

        if self.spent > self.budget:
            raise RuntimeError(f"预算超支: ${self.spent:.2f} > ${self.budget:.2f}")
```

### 7.2 延迟告警

```python
class LatencyAlerter(BaseCallbackHandler):
    """延迟告警"""

    def __init__(self, threshold: float = 3.0):
        self.threshold = threshold

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.start_time = time.time()

    def on_chain_end(self, outputs, **kwargs):
        latency = time.time() - self.start_time
        if latency > self.threshold:
            logger.warning(
                "latency_alert",
                latency=latency,
                threshold=self.threshold
            )
```

---

## 八、最佳实践

### 8.1 监控层次

```
L1: 基础监控（必需）
  - 调用次数、错误率、延迟
  - 成本追踪

L2: 详细追踪（推荐）
  - LangSmith追踪
  - 结构化日志
  - 关联ID

L3: 高级分析（可选）
  - 自定义指标
  - 异常检测
  - 性能分析
```

### 8.2 生产环境配置

```python
# 生产环境监控配置
production_config = {
    "callbacks": [
        CostTracker(),
        MetricsCallback(),
        SafeLoggingCallback(),
        CostAlerter(budget=100.0),
        LatencyAlerter(threshold=2.0)
    ],
    "metadata": {
        "environment": "production",
        "version": "1.0.0"
    },
    "tags": ["prod"]
}

# 使用
chain = chain.with_config(production_config)
```

---

## 九、总结

### 核心要点

1. **Callbacks**：生命周期钩子，灵活插入监控逻辑
2. **LangSmith**：可视化追踪，89%生产部署使用
3. **Structured Logging**：机器可读日志，易于分析
4. **Metrics**：量化指标，Prometheus集成

### 监控金字塔

```
告警（异常检测）
  ↓
指标（Metrics）
  ↓
追踪（Tracing）
  ↓
日志（Logging）
```

### 实施建议

- ✅ 从基础监控开始（调用、错误、延迟）
- ✅ 使用LangSmith可视化追踪
- ✅ 结构化日志 + 关联ID
- ✅ 设置成本和延迟告警
- ✅ 定期审查监控数据

---

**下一步**：学习【安全与权限控制】，掌握生产环境安全实践。
