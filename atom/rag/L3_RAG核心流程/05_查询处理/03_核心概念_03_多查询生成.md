# 核心概念 03：多查询生成 (Multi-Query Generation)

## 概述

多查询生成是查询改写的扩展技术，通过生成多个不同角度的查询变体来提升检索的召回率和多样性。根据 StackAI 2026 年的报告,多查询生成可以提升 20-40% 的召回率。

**定义：** 多查询生成是将单一用户查询扩展为多个不同表达方式的查询变体，并行检索后合并结果的技术。

---

## 为什么需要多查询生成？

### 问题：单一查询的局限性

**核心问题：** 用户的单一查询无法覆盖意图的多样性和文档表达的多样性。

**示例：**

```
用户查询："RAG 系统如何提升准确性？"

这个查询实际包含多个子意图：
1. 检索准确性优化
2. 生成质量提升
3. 幻觉检测与缓解
4. 评估指标与调优
5. Prompt 工程优化
```

如果只用原始查询检索，可能只召回其中一部分相关文档。

---

## 多查询生成的核心原理

### 原理 1：意图覆盖

**目标：** 通过多个查询变体覆盖用户意图的不同方面

**示例：**

```
原始查询："Python 性能优化"

生成的查询变体：
1. "Python 代码执行速度提升方法"（关注速度）
2. "Python 内存使用优化技术"（关注内存）
3. "Python 并发编程性能改进"（关注并发）
```

**效果：** 每个变体关注不同方面，综合起来覆盖更全面。

---

### 原理 2：表达多样性

**目标：** 使用不同的表达方式匹配不同风格的文档

**示例：**

```
原始查询："什么是 RAG？"

生成的查询变体：
1. "RAG 技术原理和架构"（技术角度）
2. "Retrieval-Augmented Generation 概念解释"（学术角度）
3. "RAG 系统实战应用案例"（实践角度）
```

---

### 原理 3：并行检索与结果融合

**流程：**

```
原始查询
    ↓
生成 N 个查询变体
    ↓
并行检索（每个变体独立检索）
    ↓
结果合并与去重
    ↓
最终文档集合
```

---

## 多查询生成的实现方法

### 方法 1：基于 LLM 的多查询生成（推荐）

```python
from openai import OpenAI

client = OpenAI()

MULTI_QUERY_PROMPT = """你是一个查询扩展专家。请为以下查询生成 {num_queries} 个不同角度的变体查询。

要求：
1. 每个变体从不同角度理解原始查询
2. 保持查询的核心意图
3. 使用专业术语
4. 确保变体之间有足够差异
5. 每行一个查询，不要编号或解释

原始查询：{query}

变体查询："""

def generate_multi_queries(query: str, num_queries: int = 3) -> list[str]:
    """生成多个查询变体"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": MULTI_QUERY_PROMPT.format(
                query=query,
                num_queries=num_queries
            )}
        ],
        temperature=0.7  # 稍高温度增加多样性
    )

    # 解析多行输出
    queries = response.choices[0].message.content.strip().split('\n')
    queries = [q.strip() for q in queries if q.strip()]

    return queries[:num_queries]
```

**测试：**

```python
query = "RAG 系统如何提升准确性？"
variants = generate_multi_queries(query, num_queries=3)

print(f"原始查询: {query}\n")
print("生成的查询变体:")
for i, v in enumerate(variants, 1):
    print(f"{i}. {v}")
```

**预期输出：**

```
原始查询: RAG 系统如何提升准确性？

生成的查询变体:
1. RAG 检索准确性优化方法和技术
2. 减少 RAG 系统幻觉的策略
3. RAG 评估指标和性能调优实践
```

---

### 方法 2：角度引导的多查询生成

**策略：** 明确指定每个查询变体的角度

```python
ANGLE_GUIDED_PROMPT = """你是一个查询扩展专家。请从以下不同角度为原始查询生成变体：

角度 1：技术实现角度
角度 2：问题诊断角度
角度 3：最佳实践角度

要求：
1. 每个角度生成一个查询
2. 保持原始查询的核心意图
3. 使用专业术语
4. 每行一个查询，格式：角度X: 查询内容

原始查询：{query}

变体查询："""

def generate_angle_guided_queries(query: str) -> list[str]:
    """生成角度引导的查询变体"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": ANGLE_GUIDED_PROMPT.format(query=query)}
        ],
        temperature=0.7
    )

    # 解析输出，提取查询内容
    lines = response.choices[0].message.content.strip().split('\n')
    queries = []

    for line in lines:
        if ':' in line:
            # 提取冒号后的内容
            query_text = line.split(':', 1)[1].strip()
            queries.append(query_text)

    return queries
```

---

### 方法 3：Few-shot 引导的多查询生成

```python
FEW_SHOT_MULTI_QUERY_PROMPT = """你是一个查询扩展专家。请参考以下示例，为原始查询生成 3 个不同角度的变体。

示例 1:
原始查询：Python 性能优化
变体 1：Python 代码执行速度提升方法
变体 2：Python 内存使用优化技术
变体 3：Python 并发编程性能改进

示例 2:
原始查询：什么是 RAG？
变体 1：RAG 技术原理和架构
变体 2：Retrieval-Augmented Generation 概念解释
变体 3：RAG 系统实战应用案例

现在请为以下查询生成变体：
原始查询：{query}

变体查询（每行一个，不要编号）："""
```

---

## 并行检索与结果融合

### 步骤 1：并行检索

```python
import chromadb

# 初始化向量数据库
chroma_client = chromadb.Client()
collection = chroma_client.create_collection("docs")

def parallel_retrieve(queries: list[str], k: int = 3) -> list[dict]:
    """并行检索多个查询"""
    all_results = []

    for query in queries:
        results = collection.query(
            query_texts=[query],
            n_results=k
        )

        # 提取文档和分数
        for i, doc in enumerate(results['documents'][0]):
            all_results.append({
                'content': doc,
                'query': query,
                'rank': i + 1,
                'distance': results['distances'][0][i] if 'distances' in results else None
            })

    return all_results
```

---

### 步骤 2：去重

```python
def deduplicate_results(results: list[dict]) -> list[dict]:
    """去重检索结果"""
    seen_content = set()
    unique_results = []

    for result in results:
        content = result['content']

        # 如果内容未见过，添加到结果
        if content not in seen_content:
            unique_results.append(result)
            seen_content.add(content)

    return unique_results
```

---

### 步骤 3：重排序（可选）

```python
def rerank_results(results: list[dict], original_query: str) -> list[dict]:
    """使用原始查询重新排序结果"""
    # 简单策略：按距离排序
    if results and results[0].get('distance') is not None:
        return sorted(results, key=lambda x: x['distance'])

    # 如果没有距离信息，保持原顺序
    return results
```

---

### 完整流程

```python
def multi_query_rag(query: str, num_queries: int = 3, k: int = 3) -> str:
    """带多查询生成的 RAG"""
    # 1. 生成多个查询变体
    queries = generate_multi_queries(query, num_queries=num_queries)
    print(f"原始查询: {query}\n")
    print("生成的查询变体:")
    for i, q in enumerate(queries, 1):
        print(f"  {i}. {q}")

    # 2. 并行检索
    all_results = parallel_retrieve(queries, k=k)
    print(f"\n检索到 {len(all_results)} 个结果")

    # 3. 去重
    unique_results = deduplicate_results(all_results)
    print(f"去重后剩余 {len(unique_results)} 个结果")

    # 4. 重排序
    ranked_results = rerank_results(unique_results, query)

    # 5. 提取前 K 个文档
    top_docs = ranked_results[:5]

    # 6. 生成答案
    context = "\n\n".join([doc['content'] for doc in top_docs])

    answer_prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{query}

答案："""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": answer_prompt}],
        temperature=0.7
    )

    return response.choices[0].message.content.strip()
```

---

## 2025-2026 最佳实践

### 1. 最佳查询数量：3-5 个

根据 StackAI 2026 和 arXiv 2025 的研究：

| 查询数量 | 召回率 | 精确率 | 计算成本 | 推荐度 |
|----------|--------|--------|----------|--------|
| 1 个 | 65% | 75% | 1x | ⭐⭐ |
| 3 个 | 82% | 68% | 3x | ⭐⭐⭐⭐⭐ |
| 5 个 | 88% | 58% | 5x | ⭐⭐⭐⭐ |
| 10 个 | 92% | 42% | 10x | ⭐⭐ |

**结论：** 3 个查询是最佳平衡点。

**引用来源：**
- [Advanced RAG Techniques (Updated 2026)](https://www.stack-ai.com/blog/advanced-rag-techniques) - StackAI
- [Query Decomposition for RAG](https://arxiv.org/abs/2510.18633) - arXiv 2025

---

### 2. RAG-Fusion 技术

**RAG-Fusion** 是 2024-2025 年流行的多查询融合技术。

**核心思想：** 使用倒数排名融合（Reciprocal Rank Fusion, RRF）合并多个查询的结果。

**RRF 公式：**

```
RRF_score(doc) = Σ 1 / (k + rank_i(doc))
```

其中：
- `k` 是常数（通常为 60）
- `rank_i(doc)` 是文档在第 i 个查询结果中的排名

**实现：**

```python
def rag_fusion(results: list[dict], k: int = 60) -> list[dict]:
    """RAG-Fusion 算法"""
    # 计算每个文档的 RRF 分数
    doc_scores = {}

    for result in results:
        content = result['content']
        rank = result['rank']

        if content not in doc_scores:
            doc_scores[content] = 0

        # RRF 公式
        doc_scores[content] += 1 / (k + rank)

    # 按分数排序
    sorted_docs = sorted(
        doc_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )

    # 构建结果
    fusion_results = []
    for content, score in sorted_docs:
        fusion_results.append({
            'content': content,
            'fusion_score': score
        })

    return fusion_results
```

---

### 3. 自适应查询数量

**策略：** 根据查询复杂度动态调整查询数量

```python
def adaptive_num_queries(query: str) -> int:
    """根据查询复杂度确定查询数量"""
    # 简单规则
    query_length = len(query.split())

    if query_length < 5:
        return 2  # 简单查询
    elif query_length < 10:
        return 3  # 中等查询
    else:
        return 5  # 复杂查询
```

---

## 多查询生成的优化技巧

### 技巧 1：确保多样性

```python
DIVERSITY_PROMPT = """你是一个查询扩展专家。请为以下查询生成 3 个不同角度的变体查询。

重要要求：
1. 每个变体必须从完全不同的角度理解原始查询
2. 变体之间的相似度应尽可能低
3. 第一个变体：关注技术实现
4. 第二个变体：关注问题诊断
5. 第三个变体：关注最佳实践

原始查询：{query}

变体查询（每行一个）："""
```

---

### 技巧 2：控制温度参数

```python
# 低温度（0.3）：变体相似，稳定性高
variants_low = generate_multi_queries(query, temperature=0.3)

# 中温度（0.7）：平衡多样性和相关性（推荐）
variants_mid = generate_multi_queries(query, temperature=0.7)

# 高温度（1.0）：变体多样，但可能偏离原意
variants_high = generate_multi_queries(query, temperature=1.0)
```

---

### 技巧 3：过滤低质量变体

```python
def filter_low_quality_variants(
    original_query: str,
    variants: list[str]
) -> list[str]:
    """过滤低质量变体"""
    filtered = []

    for variant in variants:
        # 1. 过滤过短的变体
        if len(variant.split()) < 3:
            continue

        # 2. 过滤与原查询完全相同的变体
        if variant.lower() == original_query.lower():
            continue

        # 3. 过滤包含"变体"、"查询"等元信息的变体
        if any(word in variant for word in ["变体", "查询", "原始"]):
            continue

        filtered.append(variant)

    return filtered
```

---

## 评估多查询生成的效果

### 评估指标

#### 1. 召回率提升

```python
def evaluate_recall_improvement(
    original_query: str,
    multi_queries: list[str],
    ground_truth_docs: list[str]
) -> dict:
    """评估召回率提升"""
    # 原始查询检索
    original_results = retrieve(original_query, k=5)
    original_recall = calculate_recall(original_results, ground_truth_docs)

    # 多查询检索
    multi_results = []
    for query in multi_queries:
        results = retrieve(query, k=3)
        multi_results.extend(results)

    multi_results = deduplicate(multi_results)
    multi_recall = calculate_recall(multi_results, ground_truth_docs)

    return {
        'original_recall': original_recall,
        'multi_recall': multi_recall,
        'improvement': multi_recall - original_recall
    }
```

#### 2. 多样性评估

```python
def evaluate_diversity(variants: list[str]) -> float:
    """评估查询变体的多样性"""
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity

    # 计算变体之间的相似度
    vectorizer = TfidfVectorizer()
    vectors = vectorizer.fit_transform(variants)

    # 计算平均相似度
    similarities = cosine_similarity(vectors)
    avg_similarity = (similarities.sum() - len(variants)) / (len(variants) * (len(variants) - 1))

    # 多样性 = 1 - 平均相似度
    diversity = 1 - avg_similarity

    return diversity
```

---

## 常见问题与解决方案

### 问题 1：变体过于相似

**原因：** Temperature 过低或 Prompt 不够引导多样性

**解决方案：**

```python
# 提高 temperature
variants = generate_multi_queries(query, temperature=0.8)

# 使用角度引导
variants = generate_angle_guided_queries(query)
```

---

### 问题 2：变体偏离原意

**原因：** Temperature 过高或 Prompt 缺乏约束

**解决方案：**

```python
CONSTRAINED_PROMPT = """生成查询变体时，必须保持原始查询的核心意图不变。

原始查询：{query}

请生成 3 个变体，每个变体必须：
1. 保持与原始查询相同的核心意图
2. 只改变表达方式和角度
3. 不添加新的意图或主题

变体查询："""
```

---

### 问题 3：检索结果过多

**原因：** 查询数量过多或每个查询返回的文档数过多

**解决方案：**

```python
# 减少查询数量
variants = generate_multi_queries(query, num_queries=3)

# 减少每个查询的返回数量
results = parallel_retrieve(variants, k=2)

# 限制最终文档数量
final_docs = ranked_results[:5]
```

---

## 总结

### 关键要点

1. **扩展单一查询**：多查询生成是查询改写的扩展，提升召回率
2. **最佳数量：3-5 个**：平衡召回率、精确率和成本
3. **并行检索**：每个变体独立检索，提升效率
4. **结果融合**：去重、重排序、RAG-Fusion
5. **2025-2026 技术**：RAG-Fusion、自适应查询数量
6. **多样性关键**：确保变体之间有足够差异

### 实战建议

1. **从 3 个查询开始**：最佳性价比
2. **使用角度引导**：确保多样性
3. **控制温度参数**：0.7 是最佳平衡点
4. **添加去重**：避免重复文档
5. **考虑 RAG-Fusion**：提升结果质量
6. **持续评估**：对比单查询和多查询的效果

### 避免的误区

1. **不要生成过多查询**：超过 5 个效果递减
2. **不要忽略多样性**：相似的变体无意义
3. **不要忽略去重**：重复文档浪费 Token
4. **不要忽略成本**：多查询增加 30% 成本

---

**记住：** 多查询生成是提升召回率的有效方法，但要平衡召回率、精确率和成本。3 个精心设计的查询变体胜过 10 个随意生成的变体。

---

**引用来源汇总：**
- [Advanced RAG Techniques (Updated 2026)](https://www.stack-ai.com/blog/advanced-rag-techniques) - StackAI
- [Query Decomposition for RAG](https://arxiv.org/abs/2510.18633) - arXiv 2025
