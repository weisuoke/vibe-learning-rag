# 实战代码1：基础条件路由

完整可运行的 RunnableBranch 基础示例。

---

## 环境准备

```bash
# 确保已安装依赖
uv sync

# 配置 API 密钥
cp .env.example .env
# 编辑 .env 文件，添加 OPENAI_API_KEY
```

---

## 示例1：类型检查路由

```python
"""
示例1：根据输入类型路由到不同处理器
"""
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 定义处理器
dict_handler = RunnableLambda(lambda x: f"Dict handler: {list(x.keys())}")
str_handler = RunnableLambda(lambda x: f"String handler: {x[:20]}...")
list_handler = RunnableLambda(lambda x: f"List handler: {len(x)} items")
default_handler = RunnableLambda(lambda x: f"Unknown type: {type(x)}")

# 创建类型路由
type_router = RunnableBranch(
    (lambda x: isinstance(x, dict), dict_handler),
    (lambda x: isinstance(x, str), str_handler),
    (lambda x: isinstance(x, list), list_handler),
    default_handler
)

# 测试
print("=== 示例1：类型检查路由 ===")
print(type_router.invoke({"name": "Alice", "age": 30}))
print(type_router.invoke("Hello, this is a long string"))
print(type_router.invoke([1, 2, 3, 4, 5]))
print(type_router.invoke(123))
```

**输出**：
```
=== 示例1：类型检查路由 ===
Dict handler: ['name', 'age']
String handler: Hello, this is a lo...
List handler: 5 items
Unknown type: <class 'int'>
```

---

## 示例2：情感分析路由

```python
"""
示例2：根据情感分析结果路由
"""
from langchain_core.runnables import RunnableBranch, RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import os
from dotenv import load_dotenv

load_dotenv()

# 情感分类器
sentiment_prompt = ChatPromptTemplate.from_template(
    "Classify sentiment as 'positive', 'negative', or 'neutral': {text}\nSentiment:"
)
sentiment_classifier = (
    sentiment_prompt
    | ChatOpenAI(model="gpt-4o-mini", temperature=0)
    | RunnableLambda(lambda x: x.content.strip().lower())
)

# 不同情感的处理器
positive_handler = ChatPromptTemplate.from_template(
    "Thank you for the positive feedback: {text}"
) | ChatOpenAI(model="gpt-4o-mini")

negative_handler = ChatPromptTemplate.from_template(
    "We apologize for the issue: {text}. How can we help?"
) | ChatOpenAI(model="gpt-4o-mini")

neutral_handler = ChatPromptTemplate.from_template(
    "Thank you for your message: {text}"
) | ChatOpenAI(model="gpt-4o-mini")

# 情感路由
sentiment_router = RunnableBranch(
    (lambda x: "positive" in x, positive_handler),
    (lambda x: "negative" in x, negative_handler),
    neutral_handler
)

# 完整链
chain = sentiment_classifier | sentiment_router

# 测试
print("\n=== 示例2：情感分析路由 ===")
result = chain.invoke({"text": "I love this product!"})
print(f"Positive: {result.content}")

result = chain.invoke({"text": "This is terrible and broken"})
print(f"Negative: {result.content}")
```

---

## 示例3：查询分类路由

```python
"""
示例3：根据查询类型路由到专门的处理器
"""
from langchain_core.runnables import RunnableBranch
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 代码问题处理器
code_handler = ChatPromptTemplate.from_template(
    "As a coding expert, answer: {query}"
) | ChatOpenAI(model="gpt-4o")

# 数学问题处理器
math_handler = ChatPromptTemplate.from_template(
    "As a math expert, solve: {query}"
) | ChatOpenAI(model="gpt-4o")

# 通用处理器
general_handler = ChatPromptTemplate.from_template(
    "Answer: {query}"
) | ChatOpenAI(model="gpt-4o-mini")

# 查询路由
query_router = RunnableBranch(
    (lambda x: any(kw in x["query"].lower() for kw in ["code", "python", "function"]),
     code_handler),
    (lambda x: any(kw in x["query"].lower() for kw in ["math", "calculate", "solve"]),
     math_handler),
    general_handler
)

# 测试
print("\n=== 示例3：查询分类路由 ===")
result = query_router.invoke({"query": "Write a Python function to sort a list"})
print(f"Code: {result.content[:100]}...")

result = query_router.invoke({"query": "Calculate the area of a circle with radius 5"})
print(f"Math: {result.content[:100]}...")
```

---

## 示例4：简单 if-else 逻辑

```python
"""
示例4：将 if-else 逻辑转换为 RunnableBranch
"""
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 传统 if-else
def traditional_logic(x):
    if x > 100:
        return "Large"
    elif x > 50:
        return "Medium"
    elif x > 0:
        return "Small"
    else:
        return "Invalid"

# RunnableBranch 版本
branch_logic = RunnableBranch(
    (lambda x: x > 100, RunnableLambda(lambda x: "Large")),
    (lambda x: x > 50, RunnableLambda(lambda x: "Medium")),
    (lambda x: x > 0, RunnableLambda(lambda x: "Small")),
    RunnableLambda(lambda x: "Invalid")
)

# 对比测试
print("\n=== 示例4：if-else vs RunnableBranch ===")
test_values = [150, 75, 25, -10]
for val in test_values:
    trad = traditional_logic(val)
    branch = branch_logic.invoke(val)
    print(f"{val}: traditional={trad}, branch={branch}")
```

---

## 示例5：多条件路由

```python
"""
示例5：组合多个条件
"""
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 复杂条件处理器
vip_urgent_handler = RunnableLambda(
    lambda x: f"VIP URGENT: {x['user']} - {x['message']}"
)
urgent_handler = RunnableLambda(
    lambda x: f"URGENT: {x['user']} - {x['message']}"
)
vip_handler = RunnableLambda(
    lambda x: f"VIP: {x['user']} - {x['message']}"
)
normal_handler = RunnableLambda(
    lambda x: f"Normal: {x['user']} - {x['message']}"
)

# 多条件路由
priority_router = RunnableBranch(
    (lambda x: x.get("is_vip") and x.get("is_urgent"), vip_urgent_handler),
    (lambda x: x.get("is_urgent"), urgent_handler),
    (lambda x: x.get("is_vip"), vip_handler),
    normal_handler
)

# 测试
print("\n=== 示例5：多条件路由 ===")
cases = [
    {"user": "Alice", "message": "Help!", "is_vip": True, "is_urgent": True},
    {"user": "Bob", "message": "Issue", "is_vip": False, "is_urgent": True},
    {"user": "Carol", "message": "Question", "is_vip": True, "is_urgent": False},
    {"user": "Dave", "message": "Info", "is_vip": False, "is_urgent": False},
]
for case in cases:
    print(priority_router.invoke(case))
```

---

## 示例6：默认分支处理

```python
"""
示例6：默认分支的不同策略
"""
from langchain_core.runnables import RunnableBranch, RunnableLambda
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 策略1：通用处理
default_general = RunnableLambda(lambda x: f"General: {x}")

# 策略2：错误处理
def error_handler(x):
    return {"error": "No matching condition", "input": x}
default_error = RunnableLambda(error_handler)

# 策略3：日志 + 兜底
def logged_default(x):
    logger.warning(f"No condition matched for: {x}")
    return f"Fallback: {x}"
default_logged = RunnableLambda(logged_default)

# 测试不同策略
print("\n=== 示例6：默认分支策略 ===")

# 使用通用处理
branch1 = RunnableBranch(
    (lambda x: x > 100, RunnableLambda(lambda x: "Large")),
    default_general
)
print(f"General: {branch1.invoke(50)}")

# 使用错误处理
branch2 = RunnableBranch(
    (lambda x: x > 100, RunnableLambda(lambda x: "Large")),
    default_error
)
print(f"Error: {branch2.invoke(50)}")

# 使用日志处理
branch3 = RunnableBranch(
    (lambda x: x > 100, RunnableLambda(lambda x: "Large")),
    default_logged
)
print(f"Logged: {branch3.invoke(50)}")
```

---

## 示例7：与 LCEL 组合

```python
"""
示例7：RunnableBranch 与 LCEL 链式组合
"""
from langchain_core.runnables import RunnableBranch, RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 预处理
preprocessor = RunnableLambda(lambda x: {
    "text": x["text"].strip().lower(),
    "length": len(x["text"])
})

# 条件路由
router = RunnableBranch(
    (lambda x: x["length"] > 100,
     ChatPromptTemplate.from_template("Summarize: {text}") | ChatOpenAI(model="gpt-4o-mini")),
    (lambda x: x["length"] > 20,
     ChatPromptTemplate.from_template("Respond to: {text}") | ChatOpenAI(model="gpt-4o-mini")),
    RunnableLambda(lambda x: f"Too short: {x['text']}")
)

# 后处理
postprocessor = RunnableLambda(lambda x:
    x.content if hasattr(x, 'content') else str(x)
)

# 完整链
chain = preprocessor | router | postprocessor

# 测试
print("\n=== 示例7：LCEL 组合 ===")
result = chain.invoke({"text": "Hi"})
print(f"Short: {result}")

result = chain.invoke({"text": "Can you help me with this problem?"})
print(f"Medium: {result[:50]}...")
```

---

## 运行说明

1. **安装依赖**：
```bash
uv sync
```

2. **配置环境**：
```bash
cp .env.example .env
# 编辑 .env，添加 OPENAI_API_KEY
```

3. **运行示例**：
```bash
# 复制代码到文件
python examples/langchain/branch_basic.py
```

---

## 学习要点

1. **类型检查**：使用 `isinstance()` 判断输入类型
2. **关键词匹配**：使用 `in` 和 `any()` 检查关键词
3. **多条件组合**：使用 `and`/`or` 组合条件
4. **默认分支**：必须提供，用于兜底处理
5. **LCEL 组合**：使用 `|` 连接预处理、路由、后处理
6. **条件顺序**：从具体到通用，影响优先级

---

## 常见问题

**Q: 为什么我的条件总是匹配第一个？**
A: 检查条件顺序，把更具体的条件放在前面。

**Q: 如何处理条件评估错误？**
A: 在条件函数中添加 try-except，或使用默认分支兜底。

**Q: 可以嵌套 RunnableBranch 吗？**
A: 可以，但不推荐深度嵌套，建议用 RunnableLambda。
