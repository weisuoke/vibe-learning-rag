# 最小可用知识

> 掌握以下内容，就能在 RAG 系统中应用高级索引类型

---

## 核心理念

**20% 的核心知识解决 80% 的问题**

高级索引类型看似复杂，但实际应用中，你只需要掌握：
1. **何时使用**哪种索引（决策树）
2. **如何创建**索引（基本代码）
3. **如何调优**关键参数（性能优化）

---

## 4.1 三种索引的快速决策

### 决策树

```
你的数据规模是多少？
├─ < 1000万：使用基础索引（HNSW）即可，不需要高级索引
└─ > 1000万：继续
    ↓
你的主要痛点是什么？
├─ 查询延迟太高（> 100ms）
│   ↓
│   你有 GPU 资源吗？
│   ├─ 有：使用 GPU_IVF_FLAT 或 GPU_IVF_PQ
│   └─ 无：优化基础索引参数，或考虑量化索引
│
├─ 存储成本太高
│   ↓
│   你能接受多少精度损失？
│   ├─ < 2%：使用 IVF_SQ8（标量量化）
│   └─ < 5%：使用 IVF_PQ（乘积量化）
│
└─ 数据是稀疏向量（如 BM25、SPLADE）
    ↓
    使用 SPARSE_INVERTED_INDEX 或 SPARSE_WAND
```

### 快速选择表

| 场景 | 推荐索引 | 理由 |
|------|---------|------|
| 实时搜索（< 50ms） | GPU_IVF_FLAT | GPU 并行计算，最快 |
| 大规模存储（> 1亿） | IVF_PQ | 压缩 8-32 倍，成本低 |
| 混合检索（关键词+语义） | SPARSE_INVERTED_INDEX + HNSW | 稀疏+稠密双索引 |
| 平衡性能与成本 | GPU_IVF_PQ | GPU 加速 + 量化压缩 |
| 无 GPU 资源 | IVF_SQ8 | CPU 友好，压缩 4 倍 |

---

## 4.2 GPU 索引：最小可用代码

### 基本使用

```python
from pymilvus import Collection, connections, FieldSchema, CollectionSchema, DataType

# 连接 Milvus
connections.connect("default", host="localhost", port="19530")

# 定义 Schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)
]
schema = CollectionSchema(fields, description="GPU index demo")

# 创建 Collection
collection = Collection("gpu_demo", schema)

# 创建 GPU 索引
index_params = {
    "index_type": "GPU_IVF_FLAT",  # GPU 索引类型
    "metric_type": "L2",            # 距离度量
    "params": {
        "nlist": 1024               # 聚类中心数量
    }
}
collection.create_index("embedding", index_params)

# 加载到 GPU 内存
collection.load()

# 搜索
search_params = {"metric_type": "L2", "params": {"nprobe": 16}}
results = collection.search(
    data=[[0.1] * 768],  # 查询向量
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

### 关键参数

| 参数 | 作用 | 推荐值 | 影响 |
|------|------|--------|------|
| `nlist` | 聚类中心数量 | `sqrt(N)` 到 `4*sqrt(N)` | 越大索引越慢，查询越快 |
| `nprobe` | 搜索的聚类数 | `nlist` 的 1-10% | 越大召回越高，速度越慢 |

**经验公式**：
- `nlist = 4 * sqrt(N)`（N 是向量数量）
- `nprobe = nlist * 0.05`（搜索 5% 的聚类）

---

## 4.3 量化索引：最小可用代码

### PQ 量化（推荐）

```python
# 创建 PQ 量化索引
index_params = {
    "index_type": "IVF_PQ",
    "metric_type": "L2",
    "params": {
        "nlist": 1024,    # 聚类中心数量
        "m": 96,          # 子向量数量（必须能整除向量维度）
        "nbits": 8        # 每个子向量的编码位数
    }
}
collection.create_index("embedding", index_params)

# 搜索参数
search_params = {"metric_type": "L2", "params": {"nprobe": 16}}
```

### SQ8 量化（更简单）

```python
# 创建 SQ8 量化索引
index_params = {
    "index_type": "IVF_SQ8",
    "metric_type": "L2",
    "params": {
        "nlist": 1024
    }
}
collection.create_index("embedding", index_params)
```

### 关键参数

| 参数 | 作用 | 推荐值 | 影响 |
|------|------|--------|------|
| `m` | 子向量数量 | `dim / 8` 到 `dim / 4` | 越小压缩越多，精度越低 |
| `nbits` | 编码位数 | 8（常用） | 8 位足够，16 位精度更高但压缩少 |

**经验公式**：
- 768 维向量：`m = 96`（768 / 8），压缩 8 倍
- 1024 维向量：`m = 128`（1024 / 8），压缩 8 倍

---

## 4.4 稀疏向量索引：最小可用代码

### 基本使用

```python
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 定义稀疏向量 Schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="sparse_embedding", dtype=DataType.SPARSE_FLOAT_VECTOR)
]
schema = CollectionSchema(fields, description="Sparse vector demo")

# 创建 Collection
collection = Collection("sparse_demo", schema)

# 创建稀疏向量索引
index_params = {
    "index_type": "SPARSE_INVERTED_INDEX",
    "metric_type": "IP",  # 稀疏向量通常使用内积
    "params": {
        "drop_ratio_build": 0.2  # 构建时丢弃最小的 20% 值
    }
}
collection.create_index("sparse_embedding", index_params)

# 插入稀疏向量数据
# 格式：{index: value} 字典
sparse_data = [
    {0: 0.5, 10: 0.3, 100: 0.8},  # 只有 3 个非零值
    {5: 0.6, 20: 0.4, 150: 0.9}
]
collection.insert([sparse_data])

# 搜索
search_params = {"metric_type": "IP", "params": {"drop_ratio_search": 0.2}}
results = collection.search(
    data=[{0: 0.5, 10: 0.3}],  # 查询稀疏向量
    anns_field="sparse_embedding",
    param=search_params,
    limit=10
)
```

### 关键参数

| 参数 | 作用 | 推荐值 | 影响 |
|------|------|--------|------|
| `drop_ratio_build` | 构建时丢弃小值的比例 | 0.1 - 0.3 | 越大索引越小，召回越低 |
| `drop_ratio_search` | 搜索时丢弃小值的比例 | 0.1 - 0.3 | 越大搜索越快，召回越低 |

---

## 4.5 混合检索：稀疏 + 稠密

### 实际应用场景

在 RAG 系统中，通常需要同时使用：
- **稠密向量**（BERT、OpenAI Embedding）：语义相似度
- **稀疏向量**（BM25、SPLADE）：关键词匹配

```python
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 定义混合 Schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="dense_embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
    FieldSchema(name="sparse_embedding", dtype=DataType.SPARSE_FLOAT_VECTOR),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000)
]
schema = CollectionSchema(fields, description="Hybrid search")

collection = Collection("hybrid_demo", schema)

# 为稠密向量创建索引
collection.create_index("dense_embedding", {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {"M": 16, "efConstruction": 200}
})

# 为稀疏向量创建索引
collection.create_index("sparse_embedding", {
    "index_type": "SPARSE_INVERTED_INDEX",
    "metric_type": "IP",
    "params": {"drop_ratio_build": 0.2}
})

collection.load()

# 混合检索（需要 Milvus 2.4+）
from pymilvus import AnnSearchRequest, RRFRanker

# 稠密向量搜索请求
dense_req = AnnSearchRequest(
    data=[[0.1] * 768],
    anns_field="dense_embedding",
    param={"metric_type": "L2", "params": {"ef": 100}},
    limit=20
)

# 稀疏向量搜索请求
sparse_req = AnnSearchRequest(
    data=[{0: 0.5, 10: 0.3}],
    anns_field="sparse_embedding",
    param={"metric_type": "IP", "params": {"drop_ratio_search": 0.2}},
    limit=20
)

# 使用 RRF（Reciprocal Rank Fusion）融合结果
results = collection.hybrid_search(
    reqs=[dense_req, sparse_req],
    rerank=RRFRanker(),
    limit=10
)
```

---

## 4.6 性能调优速查表

### GPU 索引调优

| 目标 | 调整参数 | 方向 |
|------|---------|------|
| 提高召回率 | `nprobe` | 增大（如 16 → 32） |
| 降低延迟 | `nprobe` | 减小（如 32 → 16） |
| 减少索引时间 | `nlist` | 减小（如 2048 → 1024） |
| 提高查询精度 | `nlist` | 增大（如 1024 → 2048） |

### 量化索引调优

| 目标 | 调整参数 | 方向 |
|------|---------|------|
| 提高精度 | `m` | 增大（如 64 → 96） |
| 减少存储 | `m` | 减小（如 96 → 64） |
| 平衡精度与存储 | `nbits` | 使用 8（推荐） |

### 稀疏索引调优

| 目标 | 调整参数 | 方向 |
|------|---------|------|
| 提高召回率 | `drop_ratio_search` | 减小（如 0.3 → 0.1） |
| 降低延迟 | `drop_ratio_search` | 增大（如 0.1 → 0.3） |
| 减少索引大小 | `drop_ratio_build` | 增大（如 0.1 → 0.3） |

---

## 4.7 常见问题快速解答

### Q1: 我的数据有 5000 万个向量，应该用什么索引？

**A**:
- 有 GPU：`GPU_IVF_PQ`（平衡性能与成本）
- 无 GPU：`IVF_PQ`（节省存储）或 `HNSW`（更高精度）

### Q2: GPU 索引比 CPU 索引快多少？

**A**:
- 通常快 10-50 倍
- 具体取决于：GPU 型号、向量维度、batch size

### Q3: 量化索引会损失多少精度？

**A**:
- SQ8：召回率下降 1-2%
- PQ（m=96）：召回率下降 2-5%
- 实际影响很小，因为 RAG 通常只需要 Top-10

### Q4: 稀疏向量索引适合什么场景？

**A**:
- BM25 关键词检索
- SPLADE 稀疏 Embedding
- 混合检索（稀疏 + 稠密）

### Q5: 如何选择 `nlist` 和 `nprobe`？

**A**:
```python
import math

N = 50_000_000  # 向量数量

# nlist：聚类中心数量
nlist = int(4 * math.sqrt(N))
print(f"nlist = {nlist}")  # 输出: nlist = 28284

# nprobe：搜索的聚类数（5% 的 nlist）
nprobe = max(16, int(nlist * 0.05))
print(f"nprobe = {nprobe}")  # 输出: nprobe = 1414
```

---

## 4.8 实战检查清单

在应用高级索引前，确保：

- [ ] 数据规模 > 1000 万（否则用基础索引即可）
- [ ] 明确主要瓶颈（延迟、存储、还是稀疏性）
- [ ] 了解硬件资源（有无 GPU、内存大小）
- [ ] 测试过基础索引的性能（作为 baseline）
- [ ] 准备好评估指标（召回率、延迟、存储成本）

在创建索引后，验证：

- [ ] 索引创建成功（无报错）
- [ ] 召回率在可接受范围（> 95%）
- [ ] 查询延迟满足需求（< 100ms）
- [ ] 存储成本在预算内
- [ ] 在实际数据上测试过（不只是 demo 数据）

---

## 总结：最小可用知识的力量

掌握以上内容，你就能：

✅ **快速决策**：根据场景选择合适的索引类型
✅ **快速上手**：用 10 行代码创建高级索引
✅ **快速调优**：知道调整哪些参数来优化性能
✅ **快速排查**：遇到问题知道从哪里入手

**这些知识足以**：
- 在 RAG 系统中应用高级索引
- 优化向量检索性能
- 降低存储成本
- 为后续深入学习打下基础

**下一步**：
- 深入学习：阅读 [03_核心概念_GPU索引](./03_核心概念_GPU索引.md)
- 动手实践：运行 [09_实战代码_场景1_GPU索引实战](./09_实战代码_场景1_GPU索引实战.md)
- 理解原理：阅读 [02_第一性原理](./02_第一性原理.md)
