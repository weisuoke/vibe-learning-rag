# 实战代码2：分布式部署

> 完整的 Milvus 分布式部署示例，适合大规模生产环境

---

## 概述

分布式部署将 Milvus 的各个组件独立部署，适合：
- 大规模生产环境（> 1000万向量）
- 高并发场景（QPS > 1000）
- 需要高可用和水平扩展的场景

---

## 1. 完整的分布式配置

```yaml
version: '3.8'

services:
  # ===== 存储层 =====
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: milvus-etcd
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
    volumes:
      - etcd_data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - milvus

  pulsar:
    image: apachepulsar/pulsar:2.10.0
    container_name: milvus-pulsar
    command: bin/pulsar standalone
    volumes:
      - pulsar_data:/pulsar/data
    healthcheck:
      test: ["CMD", "bin/pulsar-admin", "brokers", "healthcheck"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - milvus

  minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    container_name: milvus-minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - milvus

  # ===== 协调层 =====
  rootcoord:
    image: milvusdb/milvus:v2.4.0
    container_name: milvus-rootcoord
    command: ["milvus", "run", "rootcoord"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      etcd:
        condition: service_healthy
      pulsar:
        condition: service_healthy
      minio:
        condition: service_healthy
    networks:
      - milvus
    restart: unless-stopped

  datacoord:
    image: milvusdb/milvus:v2.4.0
    container_name: milvus-datacoord
    command: ["milvus", "run", "datacoord"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - rootcoord
    networks:
      - milvus
    restart: unless-stopped

  querycoord:
    image: milvusdb/milvus:v2.4.0
    container_name: milvus-querycoord
    command: ["milvus", "run", "querycoord"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - rootcoord
    networks:
      - milvus
    restart: unless-stopped

  indexcoord:
    image: milvusdb/milvus:v2.4.0
    container_name: milvus-indexcoord
    command: ["milvus", "run", "indexcoord"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - rootcoord
    networks:
      - milvus
    restart: unless-stopped

  # ===== 工作层 =====
  datanode:
    image: milvusdb/milvus:v2.4.0
    command: ["milvus", "run", "datanode"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - datacoord
    networks:
      - milvus
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G

  querynode:
    image: milvusdb/milvus:v2.4.0
    command: ["milvus", "run", "querynode"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - querycoord
    networks:
      - milvus
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '4'
          memory: 8G

  indexnode:
    image: milvusdb/milvus:v2.4.0
    command: ["milvus", "run", "indexnode"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - indexcoord
    networks:
      - milvus
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '4'
          memory: 8G

  # ===== 接入层 =====
  proxy:
    image: milvusdb/milvus:v2.4.0
    command: ["milvus", "run", "proxy"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      PULSAR_ADDRESS: pulsar://pulsar:6650
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - rootcoord
      - datacoord
      - querycoord
      - indexcoord
    networks:
      - milvus
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G

networks:
  milvus:
    driver: bridge

volumes:
  etcd_data:
  pulsar_data:
  minio_data:
```

---

## 2. 部署步骤

### 2.1 准备工作

```bash
# 1. 创建项目目录
mkdir -p ~/milvus-distributed
cd ~/milvus-distributed

# 2. 保存配置文件
# 将上面的配置保存为 docker-compose.yml

# 3. 验证配置
docker-compose config

# 4. 检查系统资源
# 分布式部署需要更多资源
free -h  # 至少 16GB 内存
df -h    # 至少 100GB 磁盘空间
```

### 2.2 启动服务

```bash
# 启动所有服务
docker-compose up -d

# 查看启动进度
docker-compose logs -f

# 等待所有服务就绪（约 2-3 分钟）
```

### 2.3 验证部署

```bash
# 查看所有容器状态
docker-compose ps

# 预期输出：所有服务都是 Up 状态
# NAME                  STATUS
# milvus-etcd           Up (healthy)
# milvus-pulsar         Up (healthy)
# milvus-minio          Up (healthy)
# milvus-rootcoord      Up
# milvus-datacoord      Up
# milvus-querycoord     Up
# milvus-indexcoord     Up
# milvus-datanode-1     Up
# milvus-datanode-2     Up
# milvus-querynode-1    Up
# milvus-querynode-2    Up
# milvus-indexnode-1    Up
# milvus-indexnode-2    Up
# milvus-proxy-1        Up
# milvus-proxy-2        Up
```

---

## 3. 扩展 Worker 节点

### 3.1 扩展 QueryNode

```bash
# 扩展到 4 个 QueryNode
docker-compose up -d --scale querynode=4

# 验证
docker-compose ps | grep querynode
```

### 3.2 扩展 DataNode

```bash
# 扩展到 3 个 DataNode
docker-compose up -d --scale datanode=3
```

### 3.3 扩展 Proxy

```bash
# 扩展到 3 个 Proxy（需要负载均衡器）
docker-compose up -d --scale proxy=3
```

---

## 4. 负载均衡配置

### 4.1 使用 Nginx 负载均衡

```yaml
# 添加到 docker-compose.yml
services:
  nginx:
    image: nginx:latest
    container_name: milvus-nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "19530:19530"
    depends_on:
      - proxy
    networks:
      - milvus
```

### 4.2 Nginx 配置文件

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

stream {
    upstream milvus_backend {
        least_conn;
        server proxy-1:19530;
        server proxy-2:19530;
    }

    server {
        listen 19530;
        proxy_pass milvus_backend;
        proxy_connect_timeout 10s;
        proxy_timeout 300s;
    }
}
```

---

## 5. 监控配置

### 5.1 添加 Prometheus

```yaml
# 添加到 docker-compose.yml
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: milvus-prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - milvus

volumes:
  prometheus_data:
```

### 5.2 Prometheus 配置

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'milvus'
    static_configs:
      - targets:
          - 'proxy-1:9091'
          - 'proxy-2:9091'
          - 'rootcoord:9091'
          - 'datacoord:9091'
          - 'querycoord:9091'
          - 'indexcoord:9091'
```

### 5.3 添加 Grafana

```yaml
# 添加到 docker-compose.yml
services:
  grafana:
    image: grafana/grafana:latest
    container_name: milvus-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - milvus

volumes:
  grafana_data:
```

---

## 6. 高可用配置

### 6.1 etcd 集群

```yaml
services:
  etcd-1:
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_NAME=etcd-1
      - ETCD_INITIAL_CLUSTER=etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380
      - ETCD_INITIAL_CLUSTER_STATE=new
      - ETCD_INITIAL_CLUSTER_TOKEN=milvus-etcd-cluster
    # ... 其他配置

  etcd-2:
    image: quay.io/coreos/etcd:v3.5.5
    # ... 类似配置

  etcd-3:
    image: quay.io/coreos/etcd:v3.5.5
    # ... 类似配置
```

### 6.2 MinIO 集群

```yaml
services:
  minio-1:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    command: minio server http://minio-{1...4}/data --console-address ":9001"
    # ... 其他配置

  minio-2:
    # ... 类似配置

  minio-3:
    # ... 类似配置

  minio-4:
    # ... 类似配置
```

---

## 7. 性能测试

### 7.1 大规模数据插入

```python
"""
大规模数据插入测试
"""
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import time
import numpy as np

def benchmark_distributed_insert(num_vectors=1000000):
    """测试分布式插入性能"""

    connections.connect(host="localhost", port="19530")
    collection = Collection("benchmark_collection")

    model = SentenceTransformer('all-MiniLM-L6-v2')

    batch_size = 10000
    total_time = 0

    print(f"开始插入 {num_vectors} 个向量...")

    for i in range(0, num_vectors, batch_size):
        texts = [f"Document {j}" for j in range(i, min(i + batch_size, num_vectors))]
        embeddings = model.encode(texts)

        start = time.time()

        data = [
            texts,
            embeddings.tolist(),
            [f"source_{j}" for j in range(len(texts))]
        ]

        collection.insert(data)

        elapsed = time.time() - start
        total_time += elapsed

        if (i + batch_size) % 100000 == 0:
            print(f"已插入 {i + batch_size} 个向量，吞吐量: {batch_size / elapsed:.2f} vectors/s")

    collection.flush()

    print(f"\n✅ 插入完成")
    print(f"总时间: {total_time:.2f}s")
    print(f"平均吞吐量: {num_vectors / total_time:.2f} vectors/s")

if __name__ == "__main__":
    benchmark_distributed_insert(num_vectors=1000000)
```

### 7.2 并发检索测试

```python
"""
并发检索测试
"""
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import time
import threading
import numpy as np

def search_worker(collection, model, num_queries, results):
    """检索工作线程"""
    latencies = []

    for i in range(num_queries):
        query_text = f"Query {i}"
        query_embedding = model.encode([query_text])

        start = time.time()

        collection.search(
            data=query_embedding.tolist(),
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=10
        )

        latency = (time.time() - start) * 1000
        latencies.append(latency)

    results.append(latencies)

def benchmark_concurrent_search(num_threads=10, queries_per_thread=100):
    """测试并发检索性能"""

    connections.connect(host="localhost", port="19530")
    collection = Collection("benchmark_collection")
    model = SentenceTransformer('all-MiniLM-L6-v2')

    print(f"启动 {num_threads} 个并发线程，每个线程执行 {queries_per_thread} 次查询...")

    threads = []
    results = []

    start = time.time()

    for i in range(num_threads):
        thread = threading.Thread(
            target=search_worker,
            args=(collection, model, queries_per_thread, results)
        )
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    total_time = time.time() - start

    # 合并所有结果
    all_latencies = []
    for result in results:
        all_latencies.extend(result)

    all_latencies = np.array(all_latencies)

    print(f"\n✅ 测试完成")
    print(f"总查询数: {num_threads * queries_per_thread}")
    print(f"总时间: {total_time:.2f}s")
    print(f"QPS: {num_threads * queries_per_thread / total_time:.2f}")
    print(f"平均延迟: {all_latencies.mean():.2f}ms")
    print(f"P50 延迟: {np.percentile(all_latencies, 50):.2f}ms")
    print(f"P95 延迟: {np.percentile(all_latencies, 95):.2f}ms")
    print(f"P99 延迟: {np.percentile(all_latencies, 99):.2f}ms")

if __name__ == "__main__":
    benchmark_concurrent_search(num_threads=10, queries_per_thread=100)
```

---

## 8. 故障恢复测试

### 8.1 模拟 QueryNode 故障

```bash
# 停止一个 QueryNode
docker stop milvus-querynode-1

# 观察系统行为
docker-compose logs -f querycoord

# 系统应该自动将查询路由到其他 QueryNode

# 重启 QueryNode
docker start milvus-querynode-1
```

### 8.2 模拟 DataNode 故障

```bash
# 停止一个 DataNode
docker stop milvus-datanode-1

# 观察系统行为
docker-compose logs -f datacoord

# 重启 DataNode
docker start milvus-datanode-1
```

---

## 9. 管理脚本

### 9.1 启动脚本

```bash
#!/bin/bash
# start_distributed.sh

echo "启动 Milvus 分布式集群..."

# 检查资源
TOTAL_MEM=$(free -g | awk '/^Mem:/{print $2}')
if [ $TOTAL_MEM -lt 16 ]; then
    echo "⚠️  警告：系统内存不足 16GB，可能影响性能"
fi

# 启动服务
docker-compose up -d

# 等待服务就绪
echo "等待服务启动..."
sleep 60

# 检查服务状态
docker-compose ps

echo ""
echo "✅ Milvus 分布式集群启动完成！"
echo "Proxy 端口: 19530"
echo "Prometheus: http://localhost:9090"
echo "Grafana: http://localhost:3000"
```

### 9.2 扩展脚本

```bash
#!/bin/bash
# scale_workers.sh

COMPONENT=$1
REPLICAS=$2

if [ -z "$COMPONENT" ] || [ -z "$REPLICAS" ]; then
    echo "用法: $0 <component> <replicas>"
    echo "示例: $0 querynode 4"
    exit 1
fi

echo "扩展 $COMPONENT 到 $REPLICAS 个副本..."

docker-compose up -d --scale $COMPONENT=$REPLICAS

echo "✅ 扩展完成"
docker-compose ps | grep $COMPONENT
```

### 9.3 监控脚本

```bash
#!/bin/bash
# monitor_distributed.sh

echo "Milvus 分布式集群监控"
echo "====================="
echo ""

# 服务状态
echo "1. 服务状态:"
docker-compose ps
echo ""

# 资源使用
echo "2. 资源使用:"
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" | grep milvus
echo ""

# 组件数量
echo "3. 组件数量:"
echo "Proxy: $(docker-compose ps | grep proxy | wc -l)"
echo "QueryNode: $(docker-compose ps | grep querynode | wc -l)"
echo "DataNode: $(docker-compose ps | grep datanode | wc -l)"
echo "IndexNode: $(docker-compose ps | grep indexnode | wc -l)"
echo ""

# Metrics
echo "4. 关键指标:"
curl -s http://localhost:9091/metrics | grep -E "milvus_proxy_req_count|milvus_query_node_search_latency" | head -5
```

---

## 10. 从单机迁移到分布式

### 10.1 数据导出

```python
"""
从单机 Milvus 导出数据
"""
from pymilvus import connections, Collection, utility

def export_data(collection_name, output_file):
    """导出 Collection 数据"""

    # 连接到单机 Milvus
    connections.connect("source", host="old-server", port="19530")

    # 获取 Collection
    collection = Collection(collection_name)

    # 导出所有数据
    print(f"导出 Collection: {collection_name}")

    results = collection.query(
        expr="",
        output_fields=["*"],
        limit=16384  # 最大限制
    )

    # 保存到文件
    import json
    with open(output_file, 'w') as f:
        json.dump(results, f)

    print(f"✅ 导出完成: {len(results)} 条记录")

if __name__ == "__main__":
    export_data("rag_documents", "rag_documents_export.json")
```

### 10.2 数据导入

```python
"""
导入数据到分布式 Milvus
"""
from pymilvus import connections, Collection
import json

def import_data(collection_name, input_file):
    """导入数据到 Collection"""

    # 连接到分布式 Milvus
    connections.connect("target", host="new-server", port="19530")

    # 获取 Collection
    collection = Collection(collection_name)

    # 读取数据
    with open(input_file, 'r') as f:
        data = json.load(f)

    print(f"导入 {len(data)} 条记录到 {collection_name}")

    # 批量插入
    batch_size = 1000
    for i in range(0, len(data), batch_size):
        batch = data[i:i+batch_size]

        # 准备插入数据
        texts = [item['text'] for item in batch]
        embeddings = [item['embedding'] for item in batch]
        sources = [item['source'] for item in batch]

        collection.insert([texts, embeddings, sources])

        if (i + batch_size) % 10000 == 0:
            print(f"已导入 {i + batch_size} 条记录")

    collection.flush()

    print(f"✅ 导入完成")

if __name__ == "__main__":
    import_data("rag_documents", "rag_documents_export.json")
```

---

## 关键要点

1. **分布式架构**
   - 每个组件独立容器
   - 可以独立扩展
   - 高可用和容错

2. **水平扩展**
   - Worker 节点可以动态扩展
   - 使用 `--scale` 命令
   - 需要负载均衡器

3. **监控和告警**
   - Prometheus 收集指标
   - Grafana 可视化
   - 关键指标监控

4. **高可用配置**
   - etcd 集群（3节点）
   - MinIO 集群（4节点）
   - 多副本 Worker

5. **性能测试**
   - 大规模数据插入
   - 并发检索测试
   - 故障恢复测试

---

## 下一步

完成分布式部署后，可以学习：
- **实战代码3**：生产环境配置
- **化骨绵掌**：10个2分钟知识卡片
