# åŒé‡ç±»æ¯”

> **é€šè¿‡å‰ç«¯å¼€å‘å’Œæ—¥å¸¸ç”Ÿæ´»çš„åŒé‡ç±»æ¯”ï¼Œå¿«é€Ÿç†è§£ RunnableConfig å’Œå›è°ƒç³»ç»Ÿ**

---

## ç±»æ¯” 1ï¼šRunnableConfig = Express ä¸­é—´ä»¶é…ç½®

### å‰ç«¯å¼€å‘ç±»æ¯”

```javascript
// Express åº”ç”¨é…ç½®
const app = express();

// 1. å…¨å±€ä¸­é—´ä»¶ï¼ˆç±»ä¼¼æ„é€ æ—¶é…ç½®ï¼‰
app.use(logger);           // â† ç±»ä¼¼ callbacks
app.use(metrics);          // â† ç±»ä¼¼æˆæœ¬è¿½è¸ª
app.use(errorHandler);     // â† ç±»ä¼¼é”™è¯¯å›è°ƒ

// 2. è·¯ç”±çº§é…ç½®ï¼ˆç±»ä¼¼è°ƒç”¨æ—¶é…ç½®ï¼‰
app.get('/api/users',
  authenticate,            // â† ç±»ä¼¼ tags è¿‡æ»¤
  rateLimit,              // â† ç±»ä¼¼ max_concurrency
  (req, res) => {
    // ä¸šåŠ¡é€»è¾‘
    res.json({ users: [] });
  }
);

// 3. è¯·æ±‚å…ƒæ•°æ®ï¼ˆç±»ä¼¼ metadataï¼‰
app.locals.env = 'production';
app.locals.version = '1.0.0';
```

**å¯¹åº” LangChain**ï¼š

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableConfig

# 1. å…¨å±€é…ç½®ï¼ˆæ„é€ æ—¶ï¼‰
llm = ChatOpenAI().with_config(
    callbacks=[logger, metrics, error_handler],
    tags=["production"]
)

# 2. è°ƒç”¨æ—¶é…ç½®ï¼ˆåŠ¨æ€ï¼‰
llm.invoke(
    "ä½ å¥½",
    config=RunnableConfig(
        tags=["authenticated", "rate-limited"],
        max_concurrency=10,
        metadata={"env": "production", "version": "1.0.0"}
    )
)
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **ä¸­é—´ä»¶ = å›è°ƒ**ï¼šåœ¨è¯·æ±‚/è°ƒç”¨çš„ä¸åŒé˜¶æ®µæ‰§è¡Œ
- **app.locals = metadata**ï¼šå­˜å‚¨è¯·æ±‚çº§åˆ«çš„å…ƒæ•°æ®
- **è·¯ç”±é…ç½® = RunnableConfig**ï¼šæ§åˆ¶å•æ¬¡è¯·æ±‚çš„è¡Œä¸º

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šå¤–å–è®¢å•ç³»ç»Ÿ

```
è®¢å•é…ç½®ï¼ˆRunnableConfigï¼‰ï¼š
â”œâ”€â”€ é…é€è¦æ±‚ï¼ˆcallbacksï¼‰
â”‚   â”œâ”€â”€ åˆ°è¾¾æ—¶å‘çŸ­ä¿¡é€šçŸ¥
â”‚   â”œâ”€â”€ å»¶è¿Ÿæ—¶è‡ªåŠ¨é€€æ¬¾
â”‚   â””â”€â”€ å®Œæˆåè¯·æ±‚è¯„ä»·
â”œâ”€â”€ è®¢å•æ ‡ç­¾ï¼ˆtagsï¼‰
â”‚   â”œâ”€â”€ "æ€¥å•"ï¼ˆä¼˜å…ˆé…é€ï¼‰
â”‚   â”œâ”€â”€ "VIP"ï¼ˆä¸“å±å®¢æœï¼‰
â”‚   â””â”€â”€ "é¦–å•"ï¼ˆèµ é€ä¼˜æƒ åˆ¸ï¼‰
â””â”€â”€ è®¢å•è¯¦æƒ…ï¼ˆmetadataï¼‰
    â”œâ”€â”€ ç”¨æˆ·ID: user_123
    â”œâ”€â”€ åœ°å€: åŒ—äº¬å¸‚æœé˜³åŒº
    â””â”€â”€ æ”¯ä»˜æ–¹å¼: å¾®ä¿¡æ”¯ä»˜
```

**å¯¹åº”ä»£ç **ï¼š

```python
config = RunnableConfig(
    callbacks=[
        SMSNotifier(),      # åˆ°è¾¾æ—¶å‘çŸ­ä¿¡
        AutoRefunder(),     # å»¶è¿Ÿæ—¶é€€æ¬¾
        ReviewRequester()   # å®Œæˆåè¯·æ±‚è¯„ä»·
    ],
    tags=["urgent", "vip", "first-order"],
    metadata={
        "user_id": "user_123",
        "address": "åŒ—äº¬å¸‚æœé˜³åŒº",
        "payment": "wechat"
    }
)
```

---

## ç±»æ¯” 2ï¼šCallbacks = React ç”Ÿå‘½å‘¨æœŸé’©å­

### å‰ç«¯å¼€å‘ç±»æ¯”

```javascript
// React ç»„ä»¶ç”Ÿå‘½å‘¨æœŸ
function MyComponent() {
  useEffect(() => {
    console.log('ç»„ä»¶æŒ‚è½½');  // â† ç±»ä¼¼ on_llm_start

    return () => {
      console.log('ç»„ä»¶å¸è½½');  // â† ç±»ä¼¼ on_llm_end
    };
  }, []);

  useEffect(() => {
    if (error) {
      console.error('å‘ç”Ÿé”™è¯¯');  // â† ç±»ä¼¼ on_llm_error
    }
  }, [error]);

  return <div>Hello</div>;
}
```

**å¯¹åº” LangChain**ï¼š

```python
from langchain_core.callbacks import BaseCallbackHandler

class LifecycleLogger(BaseCallbackHandler):
    def on_llm_start(self, serialized, prompts, **kwargs):
        print('LLM å¼€å§‹è°ƒç”¨')  # â† ç»„ä»¶æŒ‚è½½

    def on_llm_end(self, response, **kwargs):
        print('LLM è°ƒç”¨ç»“æŸ')  # â† ç»„ä»¶å¸è½½

    def on_llm_error(self, error, **kwargs):
        print(f'LLM è°ƒç”¨å¤±è´¥: {error}')  # â† é”™è¯¯å¤„ç†
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **ç”Ÿå‘½å‘¨æœŸé’©å­ = å›è°ƒæ–¹æ³•**ï¼šåœ¨ç‰¹å®šæ—¶æœºè‡ªåŠ¨æ‰§è¡Œ
- **useEffect æ¸…ç†å‡½æ•° = on_*_end**ï¼šèµ„æºæ¸…ç†å’ŒçŠ¶æ€æ›´æ–°
- **é”™è¯¯è¾¹ç•Œ = on_*_error**ï¼šæ•è·å’Œå¤„ç†é”™è¯¯

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šå¿«é€’è¿½è¸ªç³»ç»Ÿ

```
å¿«é€’çŠ¶æ€å˜åŒ–ï¼ˆå›è°ƒäº‹ä»¶ï¼‰ï¼š
â”œâ”€â”€ æ½ä»¶æˆåŠŸ â†’ on_chain_start
â”œâ”€â”€ è¿è¾“ä¸­   â†’ on_chain_streamï¼ˆæµå¼æ›´æ–°ï¼‰
â”œâ”€â”€ æ´¾é€ä¸­   â†’ on_tool_startï¼ˆè°ƒç”¨é…é€å·¥å…·ï¼‰
â”œâ”€â”€ å·²ç­¾æ”¶   â†’ on_chain_end
â””â”€â”€ é…é€å¤±è´¥ â†’ on_chain_error
```

**å¯¹åº”ä»£ç **ï¼š

```python
class DeliveryTracker(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        print('ğŸ“¦ æ½ä»¶æˆåŠŸ')

    def on_chain_stream(self, token, **kwargs):
        print(f'ğŸšš è¿è¾“ä¸­: {token}')

    def on_tool_start(self, tool, input_str, **kwargs):
        print('ğŸƒ æ´¾é€ä¸­')

    def on_chain_end(self, outputs, **kwargs):
        print('âœ… å·²ç­¾æ”¶')

    def on_chain_error(self, error, **kwargs):
        print('âŒ é…é€å¤±è´¥')
```

---

## ç±»æ¯” 3ï¼šTags = CSS ç±»é€‰æ‹©å™¨

### å‰ç«¯å¼€å‘ç±»æ¯”

```html
<!-- HTML å…ƒç´ çš„ class å±æ€§ -->
<button class="btn primary large">æäº¤</button>
<button class="btn secondary small">å–æ¶ˆ</button>
```

```css
/* CSS é€‰æ‹©å™¨ï¼ˆç±»ä¼¼ tags è¿‡æ»¤ï¼‰ */
.btn { padding: 10px; }           /* æ‰€æœ‰æŒ‰é’® */
.primary { background: blue; }    /* ä¸»è¦æŒ‰é’® */
.large { font-size: 18px; }       /* å¤§æŒ‰é’® */
```

**å¯¹åº” LangChain**ï¼š

```python
# 1. ç»™è°ƒç”¨æ‰“æ ‡ç­¾
config = RunnableConfig(tags=["production", "critical", "high-priority"])

# 2. å›è°ƒæ ¹æ®æ ‡ç­¾è¿‡æ»¤
class ProductionOnlyCallback(BaseCallbackHandler):
    def on_llm_start(self, serialized, prompts, **kwargs):
        tags = kwargs.get("tags", [])
        if "production" in tags:
            print('ç”Ÿäº§ç¯å¢ƒè°ƒç”¨')  # åªåœ¨ç”Ÿäº§ç¯å¢ƒæ‰§è¡Œ
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **CSS class = tags**ï¼šç”¨äºåˆ†ç±»å’Œè¿‡æ»¤
- **CSS é€‰æ‹©å™¨ = å›è°ƒè¿‡æ»¤é€»è¾‘**ï¼šæ ¹æ®æ ‡ç­¾å†³å®šæ˜¯å¦æ‰§è¡Œ
- **å¤šä¸ª class = å¤šä¸ª tags**ï¼šå¯ä»¥åŒæ—¶åº”ç”¨å¤šä¸ªæ ‡ç­¾

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šé¤å…è®¢å•æ ‡ç­¾ç³»ç»Ÿ

```
è®¢å•æ ‡ç­¾ï¼ˆtagsï¼‰ï¼š
â”œâ”€â”€ "å ‚é£Ÿ" vs "å¤–å–"     â†’ å†³å®šé…é€æ–¹å¼
â”œâ”€â”€ "è¾£" vs "ä¸è¾£"       â†’ å†³å®šè°ƒæ–™é…ç½®
â”œâ”€â”€ "æ€¥å•" vs "æ™®é€š"     â†’ å†³å®šä¼˜å…ˆçº§
â””â”€â”€ "ä¼šå‘˜" vs "æ™®é€šå®¢æˆ·" â†’ å†³å®šæŠ˜æ‰£ç­–ç•¥
```

**å¯¹åº”ä»£ç **ï¼š

```python
# 1. è®¢å•é…ç½®
order_config = RunnableConfig(
    tags=["dine-in", "spicy", "urgent", "member"]
)

# 2. å¨æˆ¿ç³»ç»Ÿæ ¹æ®æ ‡ç­¾å¤„ç†
class KitchenCallback(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        tags = kwargs.get("tags", [])

        if "urgent" in tags:
            print('ğŸ”¥ æ€¥å•ï¼ä¼˜å…ˆå¤„ç†')

        if "spicy" in tags:
            print('ğŸŒ¶ï¸ åŠ è¾£')

        if "member" in tags:
            print('ğŸ’ ä¼šå‘˜æŠ˜æ‰£')
```

---

## ç±»æ¯” 4ï¼šMetadata = HTTP è¯·æ±‚å¤´

### å‰ç«¯å¼€å‘ç±»æ¯”

```javascript
// HTTP è¯·æ±‚å¤´ï¼ˆç±»ä¼¼ metadataï¼‰
fetch('/api/users', {
  headers: {
    'Authorization': 'Bearer token123',  // â† è®¤è¯ä¿¡æ¯
    'X-User-ID': 'user_123',            // â† ç”¨æˆ·æ ‡è¯†
    'X-Request-ID': 'req_abc',          // â† è¯·æ±‚è¿½è¸ª
    'X-Client-Version': '1.0.0'         // â† å®¢æˆ·ç«¯ç‰ˆæœ¬
  }
});
```

**å¯¹åº” LangChain**ï¼š

```python
config = RunnableConfig(
    metadata={
        "user_id": "user_123",        # ç”¨æˆ·æ ‡è¯†
        "request_id": "req_abc",      # è¯·æ±‚è¿½è¸ª
        "client_version": "1.0.0",    # å®¢æˆ·ç«¯ç‰ˆæœ¬
        "session": "session_xyz"      # ä¼šè¯æ ‡è¯†
    }
)

# å›è°ƒä¸­è¯»å– metadata
class MetadataLogger(BaseCallbackHandler):
    def on_llm_end(self, response, **kwargs):
        metadata = kwargs.get("metadata", {})
        user_id = metadata.get("user_id")
        print(f'ç”¨æˆ· {user_id} çš„è°ƒç”¨å®Œæˆ')
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **HTTP å¤´ = metadata**ï¼šä¼ é€’è¯·æ±‚çº§åˆ«çš„å…ƒæ•°æ®
- **X-Request-ID = request_id**ï¼šç”¨äºåˆ†å¸ƒå¼è¿½è¸ª
- **Authorization = user_id**ï¼šç”¨äºè®¤è¯å’Œæˆæƒ

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šå¿«é€’åŒ…è£¹çš„è¯¦æƒ…å•

```
åŒ…è£¹è¯¦æƒ…ï¼ˆmetadataï¼‰ï¼š
â”œâ”€â”€ å¯„ä»¶äºº: å¼ ä¸‰
â”œâ”€â”€ æ”¶ä»¶äºº: æå››
â”œâ”€â”€ é‡é‡: 2.5kg
â”œâ”€â”€ ä¿ä»·é‡‘é¢: 1000å…ƒ
â”œâ”€â”€ å¿«é€’å•å·: SF1234567890
â””â”€â”€ å¤‡æ³¨: æ˜“ç¢å“ï¼Œè½»æ‹¿è½»æ”¾
```

**å¯¹åº”ä»£ç **ï¼š

```python
config = RunnableConfig(
    metadata={
        "sender": "å¼ ä¸‰",
        "receiver": "æå››",
        "weight": 2.5,
        "insurance": 1000,
        "tracking_number": "SF1234567890",
        "note": "æ˜“ç¢å“ï¼Œè½»æ‹¿è½»æ”¾"
    }
)

# å¿«é€’ç³»ç»Ÿæ ¹æ® metadata å¤„ç†
class DeliverySystem(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        metadata = kwargs.get("metadata", {})

        if metadata.get("insurance", 0) > 500:
            print('ğŸ’° é«˜ä»·å€¼åŒ…è£¹ï¼ŒåŠ å¼ºä¿æŠ¤')

        if "æ˜“ç¢" in metadata.get("note", ""):
            print('âš ï¸ æ˜“ç¢å“ï¼Œè½»æ‹¿è½»æ”¾')
```

---

## ç±»æ¯” 5ï¼šConfigurable Fields = ç¯å¢ƒå˜é‡

### å‰ç«¯å¼€å‘ç±»æ¯”

```javascript
// ç¯å¢ƒå˜é‡é…ç½®
const config = {
  apiUrl: process.env.API_URL || 'http://localhost:3000',
  timeout: process.env.TIMEOUT || 5000,
  debug: process.env.DEBUG === 'true'
};

// è¿è¡Œæ—¶åˆ‡æ¢
// å¼€å‘ç¯å¢ƒ: API_URL=http://localhost:3000
// ç”Ÿäº§ç¯å¢ƒ: API_URL=https://api.example.com
```

**å¯¹åº” LangChain**ï¼š

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import ConfigurableField

# 1. å£°æ˜å¯é…ç½®å­—æ®µ
llm = ChatOpenAI(temperature=0.7).configurable_fields(
    temperature=ConfigurableField(
        id="temp",
        name="Temperature",
        description="æ§åˆ¶è¾“å‡ºéšæœºæ€§"
    )
)

# 2. è¿è¡Œæ—¶åˆ‡æ¢
# å¼€å‘ç¯å¢ƒï¼šé«˜ temperatureï¼ˆæ›´æœ‰åˆ›æ„ï¼‰
llm.invoke("å†™ä¸€é¦–è¯—", config={"configurable": {"temp": 0.9}})

# ç”Ÿäº§ç¯å¢ƒï¼šä½ temperatureï¼ˆæ›´ç¨³å®šï¼‰
llm.invoke("å†™ä¸€é¦–è¯—", config={"configurable": {"temp": 0.3}})
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **ç¯å¢ƒå˜é‡ = configurable fields**ï¼šè¿è¡Œæ—¶åŠ¨æ€é…ç½®
- **process.env = config["configurable"]**ï¼šè¯»å–é…ç½®çš„æ–¹å¼
- **å¼€å‘/ç”Ÿäº§åˆ‡æ¢ = åŠ¨æ€å‚æ•°è°ƒæ•´**ï¼šæ— éœ€é‡å¯æœåŠ¡

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šç©ºè°ƒçš„å¯è°ƒå‚æ•°

```
ç©ºè°ƒé…ç½®ï¼ˆconfigurable fieldsï¼‰ï¼š
â”œâ”€â”€ æ¸©åº¦: 16Â°C - 30Â°C
â”œâ”€â”€ é£é€Ÿ: ä½/ä¸­/é«˜
â”œâ”€â”€ æ¨¡å¼: åˆ¶å†·/åˆ¶çƒ­/é™¤æ¹¿
â””â”€â”€ å®šæ—¶: 0 - 24å°æ—¶
```

**å¯¹åº”ä»£ç **ï¼š

```python
# 1. å£°æ˜å¯é…ç½®å­—æ®µ
air_conditioner = AirConditioner(
    temperature=26,
    fan_speed="medium",
    mode="cooling"
).configurable_fields(
    temperature=ConfigurableField(id="temp"),
    fan_speed=ConfigurableField(id="fan"),
    mode=ConfigurableField(id="mode")
)

# 2. è¿è¡Œæ—¶è°ƒæ•´
# ç™½å¤©ï¼šåˆ¶å†·æ¨¡å¼ï¼Œ26åº¦
air_conditioner.run(config={"configurable": {
    "temp": 26,
    "fan": "high",
    "mode": "cooling"
}})

# æ™šä¸Šï¼šåˆ¶çƒ­æ¨¡å¼ï¼Œ20åº¦
air_conditioner.run(config={"configurable": {
    "temp": 20,
    "fan": "low",
    "mode": "heating"
}})
```

---

## ç±»æ¯” 6ï¼šLangSmith = Google Analytics

### å‰ç«¯å¼€å‘ç±»æ¯”

```javascript
// Google Analytics è‡ªåŠ¨è¿½è¸ª
// 1. åªéœ€æ·»åŠ ä¸€è¡Œä»£ç 
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_ID"></script>

// 2. è‡ªåŠ¨è®°å½•æ‰€æœ‰é¡µé¢è®¿é—®
gtag('config', 'GA_ID');

// 3. åœ¨ä»ªè¡¨ç›˜æŸ¥çœ‹æ•°æ®
// - é¡µé¢æµè§ˆé‡
// - ç”¨æˆ·åœç•™æ—¶é—´
// - è½¬åŒ–ç‡
```

**å¯¹åº” LangChain**ï¼š

```bash
# 1. åªéœ€è®¾ç½®ç¯å¢ƒå˜é‡
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY=your_key
export LANGCHAIN_PROJECT=my_project
```

```python
# 2. ä»£ç æ— éœ€æ”¹åŠ¨ï¼Œè‡ªåŠ¨è¿½è¸ª
llm = ChatOpenAI()
llm.invoke("ä½ å¥½")  # â† è‡ªåŠ¨å‘é€åˆ° LangSmith

# 3. åœ¨ LangSmith ä»ªè¡¨ç›˜æŸ¥çœ‹
# - Token æ¶ˆè€—
# - è°ƒç”¨å»¶è¿Ÿ
# - æˆæœ¬ç»Ÿè®¡
# - é”™è¯¯ç‡
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **GA è¿½è¸ª = LangSmith è¿½è¸ª**ï¼šè‡ªåŠ¨è®°å½•æ‰€æœ‰äº‹ä»¶
- **GA ä»ªè¡¨ç›˜ = LangSmith ä»ªè¡¨ç›˜**ï¼šå¯è§†åŒ–æ•°æ®åˆ†æ
- **é›¶ä»£ç ä¾µå…¥ = ç¯å¢ƒå˜é‡é…ç½®**ï¼šæ— éœ€ä¿®æ”¹ä¸šåŠ¡ä»£ç 

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šæ±½è½¦çš„è¡Œè½¦è®°å½•ä»ª

```
è¡Œè½¦è®°å½•ä»ªï¼ˆLangSmithï¼‰ï¼š
â”œâ”€â”€ è‡ªåŠ¨è®°å½•ï¼ˆæ— éœ€æ‰‹åŠ¨æ“ä½œï¼‰
â”‚   â”œâ”€â”€ è¡Œé©¶è½¨è¿¹
â”‚   â”œâ”€â”€ é€Ÿåº¦å˜åŒ–
â”‚   â”œâ”€â”€ æ²¹è€—ç»Ÿè®¡
â”‚   â””â”€â”€ å¼‚å¸¸äº‹ä»¶
â”œâ”€â”€ å›æ”¾åŠŸèƒ½ï¼ˆè¿½è¸ªæŸ¥çœ‹ï¼‰
â”‚   â”œâ”€â”€ æŸ¥çœ‹å†å²è½¨è¿¹
â”‚   â”œâ”€â”€ åˆ†æé©¾é©¶ä¹ æƒ¯
â”‚   â””â”€â”€ å®šä½é—®é¢˜æ—¶åˆ»
â””â”€â”€ å‘Šè­¦åŠŸèƒ½ï¼ˆå®æ—¶ç›‘æ§ï¼‰
    â”œâ”€â”€ è¶…é€Ÿæé†’
    â”œâ”€â”€ ç¢°æ’æ£€æµ‹
    â””â”€â”€ ç–²åŠ³é©¾é©¶è­¦å‘Š
```

**å¯¹åº”ä»£ç **ï¼š

```python
# 1. å¯ç”¨ LangSmithï¼ˆå®‰è£…è¡Œè½¦è®°å½•ä»ªï¼‰
export LANGCHAIN_TRACING_V2=true

# 2. æ­£å¸¸ä½¿ç”¨ï¼ˆè‡ªåŠ¨è®°å½•ï¼‰
chain = llm | parser
chain.invoke("ä½ å¥½")  # â† è‡ªåŠ¨è®°å½•åˆ° LangSmith

# 3. æŸ¥çœ‹è¿½è¸ªï¼ˆå›æ”¾åŠŸèƒ½ï¼‰
# è®¿é—® https://smith.langchain.com
# - æŸ¥çœ‹è°ƒç”¨é“¾è·¯
# - åˆ†ææ€§èƒ½ç“¶é¢ˆ
# - å®šä½é”™è¯¯åŸå› 
```

---

## ç±»æ¯” 7ï¼šMax Concurrency = çº¿ç¨‹æ± å¤§å°

### å‰ç«¯å¼€å‘ç±»æ¯”

```javascript
// Promise.all å¹¶å‘æ§åˆ¶
async function fetchWithLimit(urls, limit) {
  const results = [];

  for (let i = 0; i < urls.length; i += limit) {
    const batch = urls.slice(i, i + limit);
    const batchResults = await Promise.all(
      batch.map(url => fetch(url))
    );
    results.push(...batchResults);
  }

  return results;
}

// é™åˆ¶å¹¶å‘æ•°ä¸º 5
fetchWithLimit(urls, 5);
```

**å¯¹åº” LangChain**ï¼š

```python
from langchain_core.runnables import RunnableConfig

# é™åˆ¶å¹¶å‘æ•°ä¸º 10
config = RunnableConfig(max_concurrency=10)

# æ‰¹é‡è°ƒç”¨æ—¶è‡ªåŠ¨é™æµ
chain.batch(
    [{"input": f"é—®é¢˜{i}"} for i in range(100)],
    config=config
)
```

**æ ¸å¿ƒç›¸ä¼¼ç‚¹**ï¼š
- **Promise.all é™æµ = max_concurrency**ï¼šæ§åˆ¶å¹¶å‘æ•°
- **æ‰¹é‡è¯·æ±‚ = batch()**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡
- **é¿å…è¿‡è½½ = é™åˆ¶å¹¶å‘**ï¼šä¿æŠ¤ API ä¸è¢«æ‰“çˆ†

---

### æ—¥å¸¸ç”Ÿæ´»ç±»æ¯”

**åœºæ™¯**ï¼šé¤å…çš„åº§ä½æ•°é™åˆ¶

```
é¤å…å¹¶å‘æ§åˆ¶ï¼ˆmax_concurrencyï¼‰ï¼š
â”œâ”€â”€ æ€»åº§ä½æ•°: 50ï¼ˆæœ€å¤§å¹¶å‘ï¼‰
â”œâ”€â”€ å½“å‰å°±é¤: 45
â”œâ”€â”€ ç­‰å¾…é˜Ÿåˆ—: 10
â””â”€â”€ ç­–ç•¥:
    â”œâ”€â”€ åº§ä½æ»¡æ—¶æ’é˜Ÿç­‰å¾…
    â”œâ”€â”€ æœ‰ç©ºä½æ—¶æŒ‰é¡ºåºå…¥åº§
    â””â”€â”€ é¿å…è¶…è½½ï¼ˆä¿è¯æœåŠ¡è´¨é‡ï¼‰
```

**å¯¹åº”ä»£ç **ï¼š

```python
# é¤å…é…ç½®
restaurant_config = RunnableConfig(
    max_concurrency=50  # æœ€å¤šåŒæ—¶æœåŠ¡ 50 æ¡Œ
)

# æ‰¹é‡å¤„ç†è®¢å•
restaurant.batch(
    orders,  # 100 ä¸ªè®¢å•
    config=restaurant_config  # è‡ªåŠ¨æ’é˜Ÿï¼Œæ¯æ¬¡æœ€å¤šå¤„ç† 50 ä¸ª
)
```

---

## ç±»æ¯”æ€»ç»“è¡¨

| LangChain æ¦‚å¿µ | å‰ç«¯å¼€å‘ç±»æ¯” | æ—¥å¸¸ç”Ÿæ´»ç±»æ¯” |
|---------------|-------------|-------------|
| **RunnableConfig** | Express ä¸­é—´ä»¶é…ç½® | å¤–å–è®¢å•é…ç½® |
| **Callbacks** | React ç”Ÿå‘½å‘¨æœŸé’©å­ | å¿«é€’è¿½è¸ªç³»ç»Ÿ |
| **Tags** | CSS ç±»é€‰æ‹©å™¨ | é¤å…è®¢å•æ ‡ç­¾ |
| **Metadata** | HTTP è¯·æ±‚å¤´ | å¿«é€’åŒ…è£¹è¯¦æƒ…å• |
| **Configurable Fields** | ç¯å¢ƒå˜é‡ | ç©ºè°ƒå¯è°ƒå‚æ•° |
| **LangSmith** | Google Analytics | æ±½è½¦è¡Œè½¦è®°å½•ä»ª |
| **Max Concurrency** | Promise.all é™æµ | é¤å…åº§ä½æ•°é™åˆ¶ |
| **Recursion Limit** | é€’å½’æ·±åº¦é™åˆ¶ | ç”µæ¢¯æœ€å¤§æ¥¼å±‚ |

---

## ç»¼åˆç¤ºä¾‹ï¼šå®Œæ•´ç±»æ¯”

### å‰ç«¯å¼€å‘åœºæ™¯

```javascript
// Express åº”ç”¨ï¼šç”¨æˆ·æŸ¥è¯¢ API
app.post('/api/query',
  authenticate,           // â† tags: ["authenticated"]
  rateLimit,             // â† max_concurrency
  logger,                // â† callbacks: [logger]
  metrics,               // â† callbacks: [metrics]
  async (req, res) => {
    const { query, userId } = req.body;

    // è°ƒç”¨ AI æœåŠ¡
    const result = await aiService.query(query, {
      headers: {
        'X-User-ID': userId,      // â† metadata
        'X-Request-ID': req.id    // â† metadata
      }
    });

    res.json(result);
  }
);
```

### LangChain å¯¹åº”å®ç°

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableConfig
from langchain_core.callbacks import BaseCallbackHandler

# 1. å®šä¹‰å›è°ƒï¼ˆä¸­é—´ä»¶ï¼‰
class Logger(BaseCallbackHandler):
    def on_llm_end(self, response, **kwargs):
        print('æ—¥å¿—è®°å½•')

class Metrics(BaseCallbackHandler):
    def on_llm_end(self, response, **kwargs):
        print('æŒ‡æ ‡æ”¶é›†')

# 2. åˆ›å»ºé“¾
llm = ChatOpenAI()

# 3. è°ƒç”¨ï¼ˆç±»ä¼¼ Express è¯·æ±‚ï¼‰
def query_api(query: str, user_id: str, request_id: str):
    config = RunnableConfig(
        callbacks=[Logger(), Metrics()],      # ä¸­é—´ä»¶
        tags=["authenticated"],               # è®¤è¯æ ‡ç­¾
        max_concurrency=10,                   # é™æµ
        metadata={                            # è¯·æ±‚å¤´
            "user_id": user_id,
            "request_id": request_id
        }
    )

    return llm.invoke(query, config=config)
```

---

### æ—¥å¸¸ç”Ÿæ´»åœºæ™¯

**åœºæ™¯**ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

```
å®¢æˆ·å’¨è¯¢æµç¨‹ï¼š
1. å®¢æˆ·æé—®ï¼ˆinvokeï¼‰
2. ç³»ç»Ÿé…ç½®ï¼ˆRunnableConfigï¼‰
   â”œâ”€â”€ é€šçŸ¥è®¾ç½®ï¼ˆcallbacksï¼‰
   â”‚   â”œâ”€â”€ å¼€å§‹å’¨è¯¢æ—¶é€šçŸ¥å®¢æœ
   â”‚   â”œâ”€â”€ ç»“æŸæ—¶å‘é€æ»¡æ„åº¦è°ƒæŸ¥
   â”‚   â””â”€â”€ å¼‚å¸¸æ—¶è½¬äººå·¥å®¢æœ
   â”œâ”€â”€ å®¢æˆ·æ ‡ç­¾ï¼ˆtagsï¼‰
   â”‚   â”œâ”€â”€ "VIP"ï¼ˆä¼˜å…ˆå“åº”ï¼‰
   â”‚   â”œâ”€â”€ "æ–°å®¢æˆ·"ï¼ˆè¯¦ç»†å¼•å¯¼ï¼‰
   â”‚   â””â”€â”€ "æŠ•è¯‰"ï¼ˆå‡çº§å¤„ç†ï¼‰
   â””â”€â”€ å®¢æˆ·ä¿¡æ¯ï¼ˆmetadataï¼‰
       â”œâ”€â”€ å®¢æˆ·ID
       â”œâ”€â”€ å†å²è®¢å•æ•°
       â””â”€â”€ ä¼šå‘˜ç­‰çº§
3. æ™ºèƒ½å›å¤ï¼ˆLLMï¼‰
4. è´¨é‡ç›‘æ§ï¼ˆLangSmithï¼‰
```

**å¯¹åº”ä»£ç **ï¼š

```python
# æ™ºèƒ½å®¢æœç³»ç»Ÿ
class CustomerServiceCallback(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        print('ğŸ“ å®¢æˆ·å’¨è¯¢å¼€å§‹ï¼Œé€šçŸ¥å®¢æœ')

    def on_chain_end(self, outputs, **kwargs):
        print('ğŸ“‹ å‘é€æ»¡æ„åº¦è°ƒæŸ¥')

    def on_chain_error(self, error, **kwargs):
        print('ğŸš¨ å¼‚å¸¸ï¼è½¬äººå·¥å®¢æœ')

# å¤„ç†å®¢æˆ·å’¨è¯¢
def handle_customer_query(query: str, customer_id: str, is_vip: bool):
    tags = ["customer-service"]
    if is_vip:
        tags.append("vip")

    config = RunnableConfig(
        callbacks=[CustomerServiceCallback()],
        tags=tags,
        metadata={
            "customer_id": customer_id,
            "is_vip": is_vip,
            "timestamp": "2025-01-15 10:30:00"
        }
    )

    return customer_service_chain.invoke(query, config=config)
```

---

## è®°å¿†å£è¯€

**RunnableConfig ä¸ƒè¦ç´ **ï¼š

```
é…ç½®å­—å…¸ä¼ å‚æ•°ï¼ˆRunnableConfigï¼‰
å›è°ƒç›‘å¬å…¨æµç¨‹ï¼ˆcallbacksï¼‰
æ ‡ç­¾è¿‡æ»¤é€‰æ‰§è¡Œï¼ˆtagsï¼‰
å…ƒæ•°æ®è¿½è¸ªå½’å› ï¼ˆmetadataï¼‰
å¯é…å­—æ®µåŠ¨æ€è°ƒï¼ˆconfigurableï¼‰
å¹¶å‘é™åˆ¶é˜²è¿‡è½½ï¼ˆmax_concurrencyï¼‰
é€’å½’æ·±åº¦ä¿å®‰å…¨ï¼ˆrecursion_limitï¼‰
```

---

## å‚è€ƒèµ„æ–™

- [RunnableConfig API Reference](https://reference.langchain.com/v0.3/python/core/runnables/langchain_core.runnables.config.RunnableConfig.html)
- [BaseCallbackHandler API Reference](https://reference.langchain.com/v0.3/python/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html)
- [LangSmith Observability Platform](https://www.langchain.com/langsmith/observability)
