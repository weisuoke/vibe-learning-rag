# 长任务处理 - 化骨绵掌

> 10个2分钟知识卡片，快速掌握长任务处理的核心知识

---

## 卡片1：为什么需要长任务处理？

**一句话**：HTTP请求有超时限制（30-60秒），长时间任务会导致超时、资源浪费、用户体验差。

**举例**：
```python
# ❌ 问题：处理100个PDF文档（50分钟）
@app.post("/process")
async def process(files: List[UploadFile]):
    for file in files:  # 100个文件
        parse_and_embed(file)  # 每个30秒
    return {"status": "done"}  # 50分钟后才返回

# 结果：30秒后浏览器超时，用户看到错误页面
```

**应用**：在AI Agent开发中的典型场景
- 批量文档处理（100个PDF，50分钟）
- 复杂Agent推理（10步推理链，2分钟）
- 大规模向量检索（百万级向量库，1分钟）

---

## 卡片2：长任务处理的核心思想

**一句话**：将任务提交和任务执行解耦，任务提交立即返回，任务执行在后台进行。

**举例**：
```python
# ✅ 解决方案：解耦
@app.post("/process")
async def process(files: List[UploadFile]):
    # 1. 创建任务记录
    task = create_task()

    # 2. 异步执行任务（后台）
    process_files.delay(task.id, files)

    # 3. 立即返回任务ID（<1秒）
    return {"task_id": task.id, "status": "processing"}

# 结果：立即返回，任务在后台执行
```

**应用**：类比快递系统
- 寄快递（提交任务）→ 拿到快递单号（任务ID）→ 离开（立即返回）
- 快递在后台配送（任务执行）→ 查询物流（查询任务状态）

---

## 卡片3：任务队列的本质

**一句话**：任务队列 = 持久化队列（Redis）+ Worker进程（消费任务）+ 消息代理（分发任务）。

**举例**：
```python
# Celery任务队列
from celery import Celery

# 创建Celery应用（配置消息代理）
app = Celery('tasks', broker='redis://localhost:6379/0')

# 定义任务
@app.task
def process_document(file_path: str):
    # 处理文档
    return {"status": "done"}

# 调用任务
result = process_document.delay('/path/to/file.pdf')
print(f"任务ID: {result.id}")
```

**应用**：三个关键组件
- **Redis**：存储任务队列（持久化）
- **Worker**：执行任务（独立进程）
- **Broker**：分发任务（消息代理）

---

## 卡片4：BackgroundTasks vs Celery

**一句话**：BackgroundTasks适合<30秒的任务，Celery适合>30秒的任务。

**举例**：
```python
# BackgroundTasks：发送邮件（5秒）✅
@app.post("/register")
async def register(user: User, background_tasks: BackgroundTasks):
    save_user(user)
    background_tasks.add_task(send_email, user.email)
    return {"status": "registered"}

# Celery：处理100个文档（50分钟）✅
@app.post("/process")
async def process(files: List[UploadFile]):
    task = create_task()
    process_files.delay(task.id, files)
    return {"task_id": task.id}
```

**应用**：决策标准
- 任务耗时 < 30秒 → BackgroundTasks
- 任务耗时 > 30秒 → Celery

---

## 卡片5：任务状态管理

**一句话**：任务状态机：pending（待处理）→ running（执行中）→ completed/failed（完成/失败）。

**举例**：
```python
# 数据库模型
class Task(Base):
    __tablename__ = "tasks"

    id = Column(Integer, primary_key=True)
    task_id = Column(String, unique=True)  # Celery任务ID
    status = Column(String)  # pending/running/completed/failed
    progress = Column(Float)  # 0.0-100.0
    result = Column(Text)  # JSON格式的结果

# 更新状态
task.status = "running"
task.progress = 50.0
db.commit()
```

**应用**：状态转换规则
- pending → running：任务开始执行
- running → completed：任务成功完成
- running → failed：任务执行失败
- 状态不可逆（不能从completed回到pending）

---

## 卡片6：SSE vs WebSocket

**一句话**：进度推送用SSE（单向、自动重连、简单），聊天应用用WebSocket（双向、需要连接管理、复杂）。

**举例**：
```python
# SSE实现（简单）
@app.get("/tasks/{task_id}/stream")
async def stream_progress(task_id: str):
    async def generate():
        while True:
            task = get_task(task_id)
            yield f"data: {json.dumps({'progress': task.progress})}\n\n"
            if task.status in ["completed", "failed"]:
                break
            await asyncio.sleep(1)

    return StreamingResponse(generate(), media_type="text/event-stream")

# 前端连接
const eventSource = new EventSource(`/tasks/${taskId}/stream`);
eventSource.onmessage = (event) => {
    const data = JSON.parse(event.data);
    console.log(`进度: ${data.progress}%`);
};
```

**应用**：选择标准
- 需要双向通信 → WebSocket
- 只需要单向推送 → SSE

---

## 卡片7：进度追踪实现

**一句话**：Worker分步更新进度，SSE实时推送给客户端。

**举例**：
```python
# Worker更新进度
@app.task(bind=True)
def process_documents(self, task_id: int, files: List[str]):
    total = len(files)
    for i, file in enumerate(files):
        # 处理文件
        process_file(file)

        # 更新进度
        progress = (i + 1) / total * 100
        update_task_progress(task_id, progress)

# SSE推送进度
@app.get("/tasks/{task_id}/stream")
async def stream_progress(task_id: str):
    async def generate():
        while True:
            task = get_task(task_id)
            yield f"data: {json.dumps({'progress': task.progress})}\n\n"
            if task.status in ["completed", "failed"]:
                break
            await asyncio.sleep(1)

    return StreamingResponse(generate(), media_type="text/event-stream")
```

**应用**：进度计算公式
- 进度 = (已完成数量 / 总数量) × 100

---

## 卡片8：任务重试机制

**一句话**：任务失败后自动重试，使用指数退避策略（60秒、120秒、240秒）。

**举例**：
```python
@app.task(
    bind=True,
    max_retries=3,           # 最多重试3次
    default_retry_delay=60   # 重试间隔60秒
)
def process_document(self, file_path: str):
    try:
        result = parse_and_embed(file_path)
        return result
    except Exception as e:
        # 指数退避：60秒、120秒、240秒
        raise self.retry(exc=e, countdown=60 * (2 ** self.request.retries))
```

**应用**：重试策略
- 第1次失败：等待60秒后重试
- 第2次失败：等待120秒后重试
- 第3次失败：等待240秒后重试
- 第4次失败：放弃，标记为失败

---

## 卡片9：任务超时控制

**一句话**：设置任务超时时间，防止任务无限执行。

**举例**：
```python
@app.task(
    time_limit=300,      # 硬超时：5分钟（强制终止）
    soft_time_limit=270  # 软超时：4.5分钟（抛出异常）
)
def process_document(file_path: str):
    try:
        # 任务逻辑
        result = parse_and_embed(file_path)
        return result
    except SoftTimeLimitExceeded:
        # 软超时，清理资源
        cleanup()
        raise
```

**应用**：两种超时
- **软超时**：抛出异常，可以捕获并清理资源
- **硬超时**：强制终止，无法捕获

---

## 卡片10：Celery vs ARQ vs Redis Queue

**一句话**：根据任务量选择：小项目用Redis Queue，中项目用ARQ，大项目用Celery。

**举例**：
```python
# Redis Queue（极简，30行代码）
from rq import Queue
from redis import Redis

redis_conn = Redis()
q = Queue(connection=redis_conn)
job = q.enqueue(process_document, '/path/to/file.pdf')

# ARQ（轻量级，50行代码）
from arq import create_pool

async def process_document(ctx, file_path: str):
    return {"status": "done"}

redis = await create_pool(RedisSettings())
job = await redis.enqueue_job('process_document', '/path/to/file.pdf')

# Celery（功能全面，100+行代码）
from celery import Celery

app = Celery('tasks', broker='redis://localhost:6379/0')

@app.task(max_retries=3)
def process_document(file_path: str):
    return {"status": "done"}
```

**应用**：选择标准
- 任务量 < 100/天 → Redis Queue
- 任务量 100-10000/天 → ARQ
- 任务量 > 10000/天 → Celery

---

## 知识卡片总结

### 核心概念（卡片1-3）
1. **为什么需要**：HTTP超时问题
2. **核心思想**：解耦（提交 vs 执行）
3. **任务队列**：持久化队列 + Worker进程

### 技术选型（卡片4、10）
4. **BackgroundTasks vs Celery**：<30秒 vs >30秒
10. **Celery vs ARQ vs Redis Queue**：根据任务量选择

### 状态管理（卡片5、7）
5. **任务状态机**：pending → running → completed/failed
7. **进度追踪**：Worker更新 + SSE推送

### 实时通信（卡片6）
6. **SSE vs WebSocket**：单向 vs 双向

### 错误处理（卡片8-9）
8. **重试机制**：指数退避
9. **超时控制**：软超时 + 硬超时

---

## 快速参考表

| 概念 | 核心要点 | 代码示例 |
|------|---------|---------|
| **长任务处理** | 解耦提交和执行 | `process_files.delay(task_id, files)` |
| **任务队列** | Redis + Worker + Broker | `app = Celery('tasks', broker='redis://...')` |
| **BackgroundTasks** | <30秒的任务 | `background_tasks.add_task(send_email)` |
| **Celery** | >30秒的任务 | `@app.task` + `.delay()` |
| **任务状态** | pending → running → completed | `task.status = "running"` |
| **SSE** | 单向推送，自动重连 | `StreamingResponse(generate(), media_type="text/event-stream")` |
| **WebSocket** | 双向通信，需要连接管理 | `@app.websocket("/ws/{task_id}")` |
| **进度追踪** | (已完成 / 总数) × 100 | `progress = (i + 1) / total * 100` |
| **重试机制** | 指数退避 | `max_retries=3, countdown=60 * (2 ** retries)` |
| **超时控制** | 软超时 + 硬超时 | `time_limit=300, soft_time_limit=270` |

---

## 学习检查清单

完成10个知识卡片后，你应该能够：

- [ ] 理解为什么需要长任务处理（HTTP超时问题）
- [ ] 掌握长任务处理的核心思想（解耦）
- [ ] 理解任务队列的本质（持久化队列 + Worker）
- [ ] 区分BackgroundTasks和Celery的适用场景
- [ ] 设计任务状态机（pending → running → completed/failed）
- [ ] 选择合适的实时通信技术（SSE vs WebSocket）
- [ ] 实现进度追踪（Worker更新 + SSE推送）
- [ ] 配置任务重试机制（指数退避）
- [ ] 设置任务超时控制（软超时 + 硬超时）
- [ ] 根据项目规模选择任务队列（Redis Queue vs ARQ vs Celery）

---

## 实战练习

### 练习1：识别长任务场景

判断以下场景是否需要长任务处理：

1. 单次LLM调用（10秒）→ ❌ 不需要
2. 3步Agent推理（30秒）→ ⚠️ 临界点，建议用
3. 10步Agent推理（100秒）→ ✅ 需要
4. 处理10个PDF（5分钟）→ ✅ 需要
5. 发送欢迎邮件（5秒）→ ❌ 不需要（用BackgroundTasks）

### 练习2：设计任务状态机

为"批量文档处理"任务设计状态机：

```
pending（待处理）
   ↓
running（执行中）
   ↓ 进度：0% → 50% → 100%
   ↓
completed（成功）或 failed（失败）
```

### 练习3：选择技术方案

为以下场景选择合适的技术方案：

| 场景 | 任务量 | 推荐方案 |
|------|-------|---------|
| 个人博客 | 10个任务/天 | Redis Queue |
| 中型SaaS | 1000个任务/天 | ARQ |
| 大型平台 | 100000个任务/天 | Celery |

### 练习4：实现进度追踪

计算进度百分比：

```python
# 场景：处理100个文档，已完成30个
total = 100
completed = 30
progress = (completed / total) * 100  # 30.0%
```

### 练习5：配置重试策略

为"LLM调用"任务配置重试策略：

```python
@app.task(
    bind=True,
    max_retries=3,           # 最多重试3次
    default_retry_delay=60   # 重试间隔60秒
)
def call_llm(self, prompt: str):
    try:
        response = llm.invoke(prompt)
        return response
    except NetworkError as e:
        # 网络错误，重试
        raise self.retry(exc=e, countdown=60 * (2 ** self.request.retries))
    except InvalidPromptError:
        # 提示词错误，不重试
        raise
```

---

## 记忆口诀

**长任务解耦是关键，提交执行要分开**
- 提交任务立即返回
- 执行任务后台进行

**三十秒内用BG，超过三十用Celery**
- BackgroundTasks：<30秒
- Celery：>30秒

**任务状态有三态，pending到completed**
- pending → running → completed/failed

**进度推送用SSE，双向通信才WebSocket**
- SSE：单向推送
- WebSocket：双向通信

**重试机制指数退，六十一二零二四零**
- 第1次：60秒
- 第2次：120秒
- 第3次：240秒

**任务队列看规模，小RQ中ARQ大Celery**
- 小项目：Redis Queue
- 中项目：ARQ
- 大项目：Celery

---

## 下一步学习

掌握10个知识卡片后，建议：

1. **实战练习**：实现一个完整的文档处理系统
2. **深入学习**：阅读核心概念文档（03_核心概念_*.md）
3. **代码实践**：运行实战代码示例（07_实战代码_*.md）
4. **生产部署**：学习监控、告警、性能优化

---

**记住**：长任务处理的核心是**解耦**，就像快递系统一样，寄件人不需要等待快递送达，可以通过快递单号随时查询物流状态。
