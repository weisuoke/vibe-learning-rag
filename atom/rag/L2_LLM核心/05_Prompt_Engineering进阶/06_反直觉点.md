# 反直觉点

进阶 Prompt 技巧中最常见的 3 个误区。

---

## 误区1：Few-shot 示例越多越好 ❌

### 错误观点

"给 LLM 10 个、20 个示例，效果肯定比 3 个好"

### 为什么错？

1. **Token 限制**：示例占用 Context Window，留给实际内容的空间变少
2. **边际效益递减**：2-5 个示例通常就够了，更多示例提升有限
3. **可能引入噪声**：示例太多，LLM 可能学到不一致的模式

```python
# ❌ 错误：塞满示例
prompt_too_many = """
示例1：...（200 tokens）
示例2：...（200 tokens）
示例3：...（200 tokens）
...
示例10：...（200 tokens）

# 示例占了 2000 tokens，留给文档的空间不够了
文档：{context}  # 被截断
问题：{query}
"""

# ✅ 正确：精选 2-3 个高质量示例
prompt_optimal = """
示例1：...（200 tokens）  # 展示基本格式
示例2：...（200 tokens）  # 展示边界情况

文档：{context}  # 有足够空间
问题：{query}
"""
```

### 为什么人们容易这样错？

- **直觉迁移**：在机器学习中，更多训练数据通常更好
- **安全感**：觉得示例多一点"保险"
- **忽视成本**：没有意识到 Token 是有限资源

### 正确理解

```
Few-shot 示例数量的最佳实践：
- 简单任务：1-2 个示例
- 中等任务：2-3 个示例
- 复杂任务：3-5 个示例
- 超过 5 个：通常没有必要，考虑优化示例质量
```

---

## 误区2：CoT 对所有问题都有效 ❌

### 错误观点

"Chain-of-Thought 是万能的，所有问题都应该用 CoT"

### 为什么错？

1. **简单问题不需要**：直接回答更高效
2. **增加 Token 消耗**：推理过程会增加输出长度
3. **可能引入错误**：推理步骤本身也可能出错

```python
# ❌ 错误：简单问题也用 CoT
prompt_overkill = """
问题：1 + 1 等于多少？

让我们一步步思考：
1. 首先，我们有数字 1
2. 然后，我们要加上另一个 1
3. 1 + 1 的结果是 2
答案：2

# 这完全是浪费 Token
"""

# ✅ 正确：简单问题直接回答
prompt_simple = """
问题：1 + 1 等于多少？
答案：2
"""

# ✅ 正确：复杂问题才用 CoT
prompt_complex = """
问题：公司有 3 个部门，每个部门有 5 个团队，每个团队有 8 人，
      其中 20% 是管理层，管理层平均工资 15000，普通员工平均工资 8000，
      公司每月工资支出是多少？

让我们一步步思考：
1. 总人数：3 × 5 × 8 = 120 人
2. 管理层人数：120 × 20% = 24 人
3. 普通员工人数：120 - 24 = 96 人
4. 管理层工资：24 × 15000 = 360000 元
5. 普通员工工资：96 × 8000 = 768000 元
6. 总工资：360000 + 768000 = 1128000 元

答案：每月工资支出 1,128,000 元
"""
```

### 为什么人们容易这样错？

- **论文效应**：CoT 论文展示了惊人效果，容易过度推广
- **一刀切思维**：找到一个好方法就想到处用
- **忽视成本**：没有考虑 Token 消耗和延迟

### 正确理解

```
CoT 适用场景判断：
✅ 需要多步推理的数学问题
✅ 需要综合多个信息源的问题
✅ 需要逻辑推导的问题
✅ 容易出错的复杂问题

❌ 简单的事实查询
❌ 直接从文档中提取信息
❌ 格式转换类任务
```

---

## 误区3：结构化输出 100% 可靠 ❌

### 错误观点

"用了 JSON Mode，LLM 输出的 JSON 一定是正确的、可解析的"

### 为什么错？

1. **格式正确 ≠ 内容正确**：JSON 格式对了，但字段值可能是错的
2. **Schema 可能不符**：JSON 能解析，但字段可能缺失或类型错误
3. **边界情况**：特殊字符、超长内容可能导致问题

```python
# ❌ 错误：盲目信任 JSON 输出
def process_response(response: str):
    result = json.loads(response)  # 假设一定成功
    return result["answer"]        # 假设字段一定存在

# ✅ 正确：添加验证和容错
def process_response_safe(response: str) -> dict:
    """安全处理 LLM 的 JSON 输出"""

    # 1. 尝试解析 JSON
    try:
        result = json.loads(response)
    except json.JSONDecodeError:
        # 尝试提取 JSON 部分
        import re
        match = re.search(r'\{.*\}', response, re.DOTALL)
        if match:
            result = json.loads(match.group())
        else:
            return {"answer": response, "confidence": "low", "error": "JSON解析失败"}

    # 2. 验证必需字段
    required_fields = ["answer", "confidence"]
    for field in required_fields:
        if field not in result:
            result[field] = "unknown"

    # 3. 验证字段类型
    if result.get("confidence") not in ["high", "medium", "low"]:
        result["confidence"] = "medium"

    return result
```

### 为什么人们容易这样错？

- **API 承诺**：JSON Mode 听起来像是"保证输出 JSON"
- **测试偏差**：测试时正常，生产环境遇到边界情况
- **过度信任**：觉得 LLM 很智能，不会犯低级错误

### 正确理解

```
结构化输出的防御性编程：
1. 始终用 try-catch 包裹 JSON 解析
2. 验证必需字段是否存在
3. 验证字段类型是否正确
4. 提供默认值和降级策略
5. 记录解析失败的情况，用于改进 Prompt
```

---

## 三个误区总结

| 误区 | 正确理解 | 实践建议 |
|------|---------|---------|
| Few-shot 越多越好 | 2-5 个高质量示例最优 | 精选示例，注意 Token 预算 |
| CoT 万能 | 只对复杂推理问题有效 | 简单问题直接回答 |
| JSON 输出 100% 可靠 | 格式可能对，内容可能错 | 添加验证和容错逻辑 |

---

## 避坑检查清单

在使用进阶技巧前，问自己：

- [ ] Few-shot：示例数量是否合理？是否占用太多 Token？
- [ ] CoT：这个问题真的需要分步推理吗？
- [ ] 结构化输出：是否添加了解析容错？是否验证了字段？
- [ ] 组合使用：是否考虑了总 Token 消耗？

---

**下一步：** [07_实战代码](./07_实战代码.md) - 完整的可运行代码示例
