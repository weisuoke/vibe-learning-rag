# 核心概念：跨会话记忆

> **理解 AI Agent 的长期记忆管理**

---

## 概念定义

**跨会话记忆（Cross-Session Memory）= 在不同会话之间持久化和恢复用户状态、对话历史和偏好的能力**

### 核心特征

1. **持久化**：数据在会话结束后不丢失
2. **可恢复**：新会话可以加载历史数据
3. **用户隔离**：不同用户的数据互不干扰
4. **增量更新**：支持追加和更新历史记录

---

## 为什么需要跨会话记忆？

### 问题场景

```python
# 没有跨会话记忆的 AI Agent
用户（第一次对话）: "我喜欢 Python"
AI: "好的，我记住了"

# 用户关闭浏览器，第二天再来
用户（第二次对话）: "你还记得我喜欢什么吗？"
AI: "抱歉，我不记得之前的对话"  # 用户体验差！
```

### 解决方案

```python
# 有跨会话记忆的 AI Agent
用户（第一次对话）: "我喜欢 Python"
AI: "好的，我记住了"
# 系统自动保存到数据库

# 用户关闭浏览器，第二天再来
用户（第二次对话）: "你还记得我喜欢什么吗？"
AI: "是的，你喜欢 Python"  # 从数据库加载历史
```

---

## 实现方式

### 1. PostgreSQL + pgvector

**LangGraph 官方推荐方案**

```python
from langgraph.checkpoint.postgres import PostgresSaver
from psycopg import Connection
import asyncio

class CrossSessionMemory:
    """跨会话记忆（PostgreSQL + pgvector）"""
    def __init__(self, db_url: str):
        self.conn = Connection.connect(db_url)
        self.checkpointer = PostgresSaver(self.conn)

    async def save_conversation(self, user_id: str, messages: list):
        """保存对话历史"""
        await self.checkpointer.aput(
            config={"configurable": {"thread_id": user_id}},
            checkpoint={"messages": messages}
        )
        print(f"✅ 保存对话: {user_id} ({len(messages)} 条消息)")

    async def load_conversation(self, user_id: str) -> list:
        """加载对话历史"""
        checkpoint = await self.checkpointer.aget(
            config={"configurable": {"thread_id": user_id}}
        )

        if checkpoint:
            messages = checkpoint.get("messages", [])
            print(f"✅ 加载对话: {user_id} ({len(messages)} 条消息)")
            return messages

        return []

    async def save_preference(self, user_id: str, key: str, value: any):
        """保存用户偏好"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO user_preferences (user_id, key, value)
            VALUES (%s, %s, %s)
            ON CONFLICT (user_id, key)
            DO UPDATE SET value = EXCLUDED.value
        """, (user_id, key, value))
        self.conn.commit()

    async def load_preference(self, user_id: str, key: str) -> any:
        """加载用户偏好"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT value FROM user_preferences
            WHERE user_id = %s AND key = %s
        """, (user_id, key))
        result = cursor.fetchone()
        return result[0] if result else None

# 使用示例
async def main():
    memory = CrossSessionMemory("postgresql://localhost/agent_memory")

    # 第一次会话
    await memory.save_conversation("user_123", [
        {"role": "user", "content": "我喜欢 Python"},
        {"role": "assistant", "content": "好的，我记住了"}
    ])
    await memory.save_preference("user_123", "language", "zh-CN")

    # 第二次会话（新会话）
    history = await memory.load_conversation("user_123")
    lang = await memory.load_preference("user_123", "language")

    print(f"历史对话: {history}")
    print(f"用户语言: {lang}")

asyncio.run(main())
```

**数据库表结构**：

```sql
-- LangGraph checkpoints 表
CREATE TABLE checkpoints (
    thread_id TEXT NOT NULL,
    checkpoint_id TEXT NOT NULL,
    parent_checkpoint_id TEXT,
    checkpoint JSONB NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (thread_id, checkpoint_id)
);

-- 用户偏好表
CREATE TABLE user_preferences (
    user_id TEXT NOT NULL,
    key TEXT NOT NULL,
    value JSONB NOT NULL,
    updated_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (user_id, key)
);

-- 向量检索表（pgvector）
CREATE TABLE conversation_embeddings (
    id SERIAL PRIMARY KEY,
    user_id TEXT NOT NULL,
    message TEXT NOT NULL,
    embedding vector(1536),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX ON conversation_embeddings USING ivfflat (embedding vector_cosine_ops);
```

---

### 2. Redis + PostgreSQL 混合方案

**短期记忆用 Redis，长期记忆用 PostgreSQL**

```python
import redis
import psycopg2
from psycopg2.extras import Json
import json

class HybridCrossSessionMemory:
    """混合跨会话记忆（Redis + PostgreSQL）"""
    def __init__(self, redis_client: redis.Redis, db_conn):
        self.redis = redis_client
        self.db = db_conn

    def add_message(self, user_id: str, role: str, content: str):
        """添加消息（先写 Redis）"""
        # L2: Redis 会话缓存（快速访问）
        key = f"conv:{user_id}"
        message = json.dumps({"role": role, "content": content})
        self.redis.lpush(key, message)
        self.redis.ltrim(key, 0, 99)  # 保留最近 100 条
        self.redis.expire(key, 3600)  # 1 小时过期

        # L4: PostgreSQL 持久化（长期保存）
        cursor = self.db.cursor()
        cursor.execute("""
            INSERT INTO conversations (user_id, role, content, created_at)
            VALUES (%s, %s, %s, NOW())
        """, (user_id, role, content))
        self.db.commit()

    def get_recent_messages(self, user_id: str, n: int = 10) -> list:
        """获取最近消息（优先从 Redis）"""
        key = f"conv:{user_id}"

        # 先查 Redis
        messages = self.redis.lrange(key, 0, n - 1)
        if messages:
            return [json.loads(msg.decode()) for msg in messages]

        # Redis 未命中，从 PostgreSQL 加载
        cursor = self.db.cursor()
        cursor.execute("""
            SELECT role, content FROM conversations
            WHERE user_id = %s
            ORDER BY created_at DESC
            LIMIT %s
        """, (user_id, n))

        messages = [
            {"role": row[0], "content": row[1]}
            for row in cursor.fetchall()
        ]

        # 回填到 Redis
        if messages:
            key = f"conv:{user_id}"
            for msg in reversed(messages):
                self.redis.lpush(key, json.dumps(msg))
            self.redis.expire(key, 3600)

        return messages

    def get_all_history(self, user_id: str) -> list:
        """获取完整历史（从 PostgreSQL）"""
        cursor = self.db.cursor()
        cursor.execute("""
            SELECT role, content, created_at FROM conversations
            WHERE user_id = %s
            ORDER BY created_at ASC
        """, (user_id,))

        return [
            {
                "role": row[0],
                "content": row[1],
                "timestamp": row[2].isoformat()
            }
            for row in cursor.fetchall()
        ]

# 使用示例
redis_client = redis.Redis(host='localhost', port=6379)
db_conn = psycopg2.connect("dbname=agent_memory")

memory = HybridCrossSessionMemory(redis_client, db_conn)

# 添加消息
memory.add_message("user_123", "user", "你好")
memory.add_message("user_123", "assistant", "你好！")

# 获取最近消息（从 Redis，快速）
recent = memory.get_recent_messages("user_123", n=10)

# 获取完整历史（从 PostgreSQL，完整）
history = memory.get_all_history("user_123")
```

---

### 3. 向量检索增强

**结合语义检索，找到相关历史**

```python
from openai import OpenAI
import numpy as np

client = OpenAI()

class VectorEnhancedMemory:
    """向量检索增强的跨会话记忆"""
    def __init__(self, db_conn):
        self.db = db_conn

    def _get_embedding(self, text: str) -> list:
        """获取文本向量"""
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding

    def add_message(self, user_id: str, role: str, content: str):
        """添加消息（带向量）"""
        embedding = self._get_embedding(content)

        cursor = self.db.cursor()
        cursor.execute("""
            INSERT INTO conversation_embeddings (user_id, role, content, embedding)
            VALUES (%s, %s, %s, %s)
        """, (user_id, role, content, embedding))
        self.db.commit()

    def search_similar_messages(
        self,
        user_id: str,
        query: str,
        top_k: int = 5
    ) -> list:
        """搜索相似的历史消息"""
        query_embedding = self._get_embedding(query)

        cursor = self.db.cursor()
        cursor.execute("""
            SELECT role, content, embedding <=> %s::vector AS distance
            FROM conversation_embeddings
            WHERE user_id = %s
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """, (query_embedding, user_id, query_embedding, top_k))

        return [
            {
                "role": row[0],
                "content": row[1],
                "similarity": 1 - row[2]  # 距离转相似度
            }
            for row in cursor.fetchall()
        ]

# 使用示例
memory = VectorEnhancedMemory(db_conn)

# 添加历史消息
memory.add_message("user_123", "user", "我喜欢 Python")
memory.add_message("user_123", "assistant", "好的，我记住了")
memory.add_message("user_123", "user", "推荐一些 Python 书籍")

# 搜索相关历史
similar = memory.search_similar_messages("user_123", "Python 学习资源")
# 返回: [{"role": "user", "content": "推荐一些 Python 书籍", "similarity": 0.92}, ...]
```

---

## LangGraph 完整示例

### 带记忆的 Agent

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.postgres import PostgresSaver
from langchain_openai import ChatOpenAI
from typing import TypedDict, Annotated
import operator

# 定义状态
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    user_id: str

# 创建 Agent
def create_agent_with_memory(db_url: str):
    """创建带记忆的 Agent"""
    # 初始化 LLM
    llm = ChatOpenAI(model="gpt-4")

    # 初始化 Checkpointer
    conn = Connection.connect(db_url)
    checkpointer = PostgresSaver(conn)

    # 定义节点
    def chat_node(state: AgentState):
        """对话节点"""
        messages = state["messages"]
        response = llm.invoke(messages)
        return {"messages": [response]}

    # 构建图
    workflow = StateGraph(AgentState)
    workflow.add_node("chat", chat_node)
    workflow.set_entry_point("chat")
    workflow.add_edge("chat", END)

    # 编译（带 Checkpointer）
    app = workflow.compile(checkpointer=checkpointer)

    return app

# 使用示例
async def main():
    app = create_agent_with_memory("postgresql://localhost/agent_memory")

    # 第一次会话
    config = {"configurable": {"thread_id": "user_123"}}

    result1 = await app.ainvoke(
        {"messages": [{"role": "user", "content": "我喜欢 Python"}]},
        config=config
    )
    print(result1["messages"][-1].content)

    # 第二次会话（自动加载历史）
    result2 = await app.ainvoke(
        {"messages": [{"role": "user", "content": "你还记得我喜欢什么吗？"}]},
        config=config
    )
    print(result2["messages"][-1].content)
    # 输出: "是的，你喜欢 Python"

asyncio.run(main())
```

---

## AI Agent 应用

### 1. 个性化推荐

```python
class PersonalizedAgent:
    """个性化 AI Agent"""
    def __init__(self, memory: CrossSessionMemory):
        self.memory = memory

    async def get_recommendations(self, user_id: str, category: str) -> list:
        """基于历史偏好推荐"""
        # 加载用户偏好
        preferences = await self.memory.load_preference(user_id, "preferences")

        # 加载历史对话
        history = await self.memory.load_conversation(user_id)

        # 分析用户兴趣
        interests = self._analyze_interests(history, preferences)

        # 生成推荐
        recommendations = self._generate_recommendations(category, interests)

        return recommendations

    def _analyze_interests(self, history: list, preferences: dict) -> list:
        """分析用户兴趣"""
        # 从历史对话中提取关键词
        keywords = []
        for msg in history:
            if msg["role"] == "user":
                # 简化版：提取名词
                keywords.extend(msg["content"].split())

        return list(set(keywords))

# 使用示例
agent = PersonalizedAgent(memory)

# 第一次会话
await memory.save_conversation("user_123", [
    {"role": "user", "content": "我喜欢 Python 和机器学习"},
    {"role": "assistant", "content": "好的"}
])

# 第二次会话：个性化推荐
recommendations = await agent.get_recommendations("user_123", "books")
# 返回: ["Python 机器学习实战", "深度学习入门", ...]
```

### 2. 上下文延续

```python
class ContextualAgent:
    """上下文延续 Agent"""
    def __init__(self, memory: CrossSessionMemory):
        self.memory = memory
        self.llm = ChatOpenAI(model="gpt-4")

    async def chat(self, user_id: str, message: str) -> str:
        """带上下文的对话"""
        # 加载历史对话
        history = await self.memory.load_conversation(user_id)

        # 构建上下文
        messages = history + [{"role": "user", "content": message}]

        # 调用 LLM
        response = self.llm.invoke(messages)

        # 保存新消息
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": response.content})
        await self.memory.save_conversation(user_id, history)

        return response.content

# 使用示例
agent = ContextualAgent(memory)

# 第一次会话
response1 = await agent.chat("user_123", "我在学习 RAG")
# AI: "RAG 是检索增强生成..."

# 第二次会话（新会话，但有上下文）
response2 = await agent.chat("user_123", "能举个例子吗？")
# AI: "当然，RAG 的例子有..." （知道是在讨论 RAG）
```

### 3. 长期知识积累

```python
class KnowledgeAccumulationAgent:
    """知识积累 Agent"""
    def __init__(self, memory: VectorEnhancedMemory):
        self.memory = memory

    async def learn(self, user_id: str, knowledge: str):
        """学习新知识"""
        await self.memory.add_message(user_id, "knowledge", knowledge)
        print(f"✅ 学习了新知识: {knowledge}")

    async def recall(self, user_id: str, query: str) -> list:
        """回忆相关知识"""
        similar = await self.memory.search_similar_messages(user_id, query)
        return [msg["content"] for msg in similar if msg["role"] == "knowledge"]

# 使用示例
agent = KnowledgeAccumulationAgent(memory)

# 学习阶段
await agent.learn("user_123", "RAG 是检索增强生成")
await agent.learn("user_123", "向量数据库用于存储 Embedding")
await agent.learn("user_123", "LangChain 是 AI Agent 框架")

# 回忆阶段
knowledge = await agent.recall("user_123", "什么是 RAG？")
# 返回: ["RAG 是检索增强生成"]
```

---

## 性能优化

### 1. 分页加载

```python
def load_conversation_paginated(
    user_id: str,
    page: int = 1,
    page_size: int = 20
) -> dict:
    """分页加载对话历史"""
    offset = (page - 1) * page_size

    cursor = db.cursor()

    # 获取总数
    cursor.execute("""
        SELECT COUNT(*) FROM conversations WHERE user_id = %s
    """, (user_id,))
    total = cursor.fetchone()[0]

    # 分页查询
    cursor.execute("""
        SELECT role, content, created_at FROM conversations
        WHERE user_id = %s
        ORDER BY created_at DESC
        LIMIT %s OFFSET %s
    """, (user_id, page_size, offset))

    messages = [
        {"role": row[0], "content": row[1], "timestamp": row[2].isoformat()}
        for row in cursor.fetchall()
    ]

    return {
        "messages": messages,
        "page": page,
        "page_size": page_size,
        "total": total,
        "total_pages": (total + page_size - 1) // page_size
    }
```

### 2. 增量同步

```python
class IncrementalSyncMemory:
    """增量同步记忆"""
    def __init__(self, redis_client, db_conn):
        self.redis = redis_client
        self.db = db_conn

    def sync_to_db(self, user_id: str):
        """将 Redis 中的新消息同步到数据库"""
        key = f"conv:{user_id}"
        new_key = f"conv:{user_id}:new"

        # 获取新消息
        new_messages = self.redis.lrange(new_key, 0, -1)
        if not new_messages:
            return

        # 批量插入数据库
        cursor = self.db.cursor()
        for msg in new_messages:
            data = json.loads(msg.decode())
            cursor.execute("""
                INSERT INTO conversations (user_id, role, content, created_at)
                VALUES (%s, %s, %s, NOW())
            """, (user_id, data["role"], data["content"]))

        self.db.commit()

        # 清空新消息队列
        self.redis.delete(new_key)

        print(f"✅ 同步了 {len(new_messages)} 条新消息")
```

### 3. 缓存预热

```python
def warm_up_user_memory(user_id: str, redis_client, db_conn):
    """预热用户记忆"""
    # 从数据库加载最近消息
    cursor = db_conn.cursor()
    cursor.execute("""
        SELECT role, content FROM conversations
        WHERE user_id = %s
        ORDER BY created_at DESC
        LIMIT 100
    """, (user_id,))

    messages = cursor.fetchall()

    # 写入 Redis
    key = f"conv:{user_id}"
    for role, content in reversed(messages):
        redis_client.lpush(key, json.dumps({"role": role, "content": content}))

    redis_client.expire(key, 3600)

    print(f"✅ 预热了 {len(messages)} 条消息")
```

---

## 最佳实践

### 1. 数据隔离

```python
# 使用 user_id 作为分区键
CREATE TABLE conversations (
    user_id TEXT NOT NULL,
    message_id SERIAL,
    role TEXT NOT NULL,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (user_id, message_id)
) PARTITION BY HASH (user_id);

# 创建分区
CREATE TABLE conversations_p0 PARTITION OF conversations
    FOR VALUES WITH (MODULUS 4, REMAINDER 0);
CREATE TABLE conversations_p1 PARTITION OF conversations
    FOR VALUES WITH (MODULUS 4, REMAINDER 1);
CREATE TABLE conversations_p2 PARTITION OF conversations
    FOR VALUES WITH (MODULUS 4, REMAINDER 2);
CREATE TABLE conversations_p3 PARTITION OF conversations
    FOR VALUES WITH (MODULUS 4, REMAINDER 3);
```

### 2. 数据归档

```python
def archive_old_conversations(days: int = 90):
    """归档旧对话"""
    cursor = db.cursor()

    # 移动到归档表
    cursor.execute("""
        INSERT INTO conversations_archive
        SELECT * FROM conversations
        WHERE created_at < NOW() - INTERVAL '%s days'
    """, (days,))

    # 删除原表数据
    cursor.execute("""
        DELETE FROM conversations
        WHERE created_at < NOW() - INTERVAL '%s days'
    """, (days,))

    db.commit()
    print(f"✅ 归档了 {days} 天前的对话")
```

### 3. 隐私保护

```python
def anonymize_user_data(user_id: str):
    """匿名化用户数据"""
    cursor = db.cursor()

    # 删除个人信息
    cursor.execute("""
        UPDATE user_preferences
        SET value = '***'
        WHERE user_id = %s AND key IN ('email', 'phone', 'address')
    """, (user_id,))

    # 删除敏感对话
    cursor.execute("""
        DELETE FROM conversations
        WHERE user_id = %s AND content LIKE '%密码%'
    """, (user_id,))

    db.commit()
    print(f"✅ 匿名化了用户数据: {user_id}")
```

---

## 参考资源

### 2025-2026 最新研究
- [LangGraph Memory Documentation](https://docs.langchain.com/oss/python/langgraph/add-memory) - PostgreSQL + pgvector 实现
- [LangGraph Long Memory Example](https://github.com/FareedKhan-dev/langgraph-long-memory) - 完整示例
- [AI Agents 2026 Architecture](https://andriifurmanets.com/blogs/ai-agents-2026-practical-architecture-tools-memory-evals-guardrails) - 4层记忆架构

### 实现参考
- [PostgreSQL pgvector](https://github.com/pgvector/pgvector) - 向量扩展
- [Redis Documentation](https://redis.io/docs/) - Redis 缓存
- [LangChain Memory](https://python.langchain.com/docs/modules/memory/) - 记忆管理
