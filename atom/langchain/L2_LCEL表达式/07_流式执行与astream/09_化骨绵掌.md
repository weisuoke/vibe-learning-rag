# 化骨绵掌

## 概述

化骨绵掌式知识卡片，将流式执行的核心知识浓缩为易记忆、易应用的卡片形式。

---

## 卡片 1：流式执行本质

### 核心定义
**流式执行 = 边计算边返回 = 优化感知等待时间**

### 关键公式
```
用户体验 = f(感知等待时间, 实际等待时间)
流式：感知等待时间 << 实际等待时间
批量：感知等待时间 = 实际等待时间
```

### 记忆口诀
**"不是更快，是感觉快"**

### 实战应用
```python
# 批量：等 5 秒后看到结果
result = chain.invoke(input)

# 流式：0.1 秒后开始看到结果
async for chunk in chain.astream(input):
    print(chunk.content, end="", flush=True)
```

---

## 卡片 2：三种流式模式

### 模式速记表

| 模式 | 用途 | 返回数据 | 典型场景 |
|------|------|----------|----------|
| **updates** | 看步骤 | `{node: state}` | Agent 监控 |
| **messages** | 看输出 | `(token, metadata)` | ChatGPT 式对话 |
| **custom** | 看进度 | 任意数据 | 业务进度 |

### 记忆口诀
**"updates 看步骤，messages 看输出，custom 看进度"**

### 选择决策树
```
需要什么？
├─ Agent 执行步骤 → updates
├─ LLM 实时输出 → messages
└─ 自定义进度 → custom
```

---

## 卡片 3：API 速查

### 基础 API
```python
# 同步流式（不推荐）
for chunk in chain.stream(input):
    process(chunk)

# 异步流式（推荐）
async for chunk in chain.astream(input):
    process(chunk)

# 多模式流式
for mode, data in agent.stream(
    input,
    stream_mode=["updates", "messages", "custom"]
):
    handle(mode, data)
```

### 自定义流式
```python
from langgraph.config import get_stream_writer

def my_tool(query: str) -> str:
    writer = get_stream_writer()
    writer("步骤 1...")
    writer("步骤 2...")
    return "Done"
```

### 禁用流式
```python
# 方法 1
model = ChatOpenAI(streaming=False)

# 方法 2（兼容所有模型）
model = ChatOpenAI(disable_streaming=True)
```

---

## 卡片 4：性能权衡

### 性能数据
```
流式开销：<10%（2025-2026）
用户体验提升：50 倍（首字节时间）
ROI：500+
```

### 开销构成
- 网络往返：~3%
- 序列化：~2%
- 队列管理：~1%
- 连接维护：~1%

### 决策矩阵
```
使用流式：
✅ 用户交互场景
✅ 长文本生成
✅ 多步 Agent

不使用流式：
❌ 后台批处理
❌ 性能极度敏感
❌ 不需要实时反馈
```

---

## 卡片 5：实现原理三要素

### 1. AsyncIterator
```python
async def astream(input) -> AsyncIterator[Output]:
    async for chunk in generate():
        yield chunk  # 逐步返回
```

### 2. 回调系统
```python
class _StreamingCallbackHandler:
    async def on_llm_new_token(self, token):
        await self.queue.put(token)
```

### 3. Transform 方法
```python
class StreamableComponent:
    async def transform(self, input_stream):
        async for chunk in input_stream:
            yield self.process(chunk)
```

### 记忆口诀
**"迭代器 + 回调 + Transform"**

---

## 卡片 6：常见错误与解决

### 错误 1：忘记 flush
```python
# ❌ 错误
print(chunk.content, end="")

# ✅ 正确
print(chunk.content, end="", flush=True)
```

### 错误 2：混淆 messages 返回值
```python
# ❌ 错误
for chunk in agent.stream(input, stream_mode="messages"):
    print(chunk.content)  # chunk 是元组

# ✅ 正确
for token, metadata in agent.stream(input, stream_mode="messages"):
    print(token.content, end="")
```

### 错误 3：工具外部使用 get_stream_writer
```python
# ❌ 错误
def main():
    writer = get_stream_writer()  # 抛出异常

# ✅ 正确
def my_tool(query: str) -> str:
    writer = get_stream_writer()  # 正常工作
    return "Done"
```

---

## 卡片 7：反直觉点速记

### 反直觉点 Top 5

1. **流式不会让总时间变短**
   - 实际：总时间增加 <10%
   - 但：首字节时间缩短 50 倍

2. **messages 不只返回文本**
   - 实际：返回 `(token, metadata)` 元组
   - 包含：文本、工具调用、元数据

3. **get_stream_writer 只能在工具内部**
   - 原因：依赖 LangGraph 执行上下文
   - Python < 3.11：需要手动传递 config

4. **多模式流式顺序不保证**
   - 实际：不同模式数据可能交错
   - 解决：使用缓冲区收集

5. **streaming=False 不禁用所有流式**
   - 实际：只禁用 LLM token 流式
   - updates 和 custom 仍然工作

---

## 卡片 8：2025-2026 新特性

### 新特性速览

#### 1. 性能优化
```
2024: ~20% 开销
2025: ~10% 开销
2026: <10% 开销
```

#### 2. Subgraph 流式
```python
for namespace, mode, data in agent.stream(
    input,
    stream_mode="updates",
    subgraphs=True  # 新参数
):
    print(f"Level {len(namespace)}: {data}")
```

#### 3. Human-in-the-loop 流式
```python
for mode, data in agent.stream(input, stream_mode=["updates"]):
    if mode == "__interrupt__":
        decision = get_user_decision()
        agent.stream(Command(resume=decision), ...)
```

#### 4. 更好的元数据
```python
for token, metadata in agent.stream(input, stream_mode="messages"):
    agent_name = metadata.get("lc_agent_name")  # 新字段
    print(f"[{agent_name}] {token.content}")
```

---

## 卡片 9：类比记忆法

### 前端开发者记忆

| LangChain | 前端类比 |
|-----------|----------|
| 流式执行 | Server-Sent Events |
| updates | React DevTools 组件树 |
| messages | 打字机效果 |
| custom | 文件上传进度条 |
| 异步流式 | async/await |

### 非技术背景记忆

| LangChain | 日常类比 |
|-----------|----------|
| 流式执行 | 看直播 vs 看录播 |
| updates | 外卖配送进度 |
| messages | 语音转文字实时显示 |
| custom | 洗衣机状态显示 |
| 异步流式 | 多窗口银行 |

---

## 卡片 10：调试技巧

### 技巧 1：打印元数据
```python
for token, metadata in agent.stream(input, stream_mode="messages"):
    print(f"\n[DEBUG] {metadata}")
    print(token.content, end="")
```

### 技巧 2：监控性能
```python
import time

start = time.time()
first_chunk = True

async for chunk in chain.astream(input):
    if first_chunk:
        print(f"TTFB: {time.time() - start:.2f}s")
        first_chunk = False
    print(chunk.content, end="")

print(f"\nTotal: {time.time() - start:.2f}s")
```

### 技巧 3：错误处理
```python
try:
    async for chunk in chain.astream(input):
        print(chunk.content, end="", flush=True)
except Exception as e:
    print(f"\n[ERROR] {e}")
    # 降级到批量模式
    result = chain.invoke(input)
    print(result.content)
```

---

## 卡片 11：生产环境检查清单

### 部署前检查

- [ ] 使用 `astream()` 而非 `stream()`
- [ ] 所有 `print()` 都有 `flush=True`
- [ ] 正确解构 `messages` 模式返回值
- [ ] 错误处理和降级方案
- [ ] 性能监控和日志
- [ ] 超时处理
- [ ] 连接重试机制

### 性能优化检查

- [ ] 禁用不需要的流式模式
- [ ] 使用连接池（2025+ 自动）
- [ ] 合理使用批量 + 流式组合
- [ ] 监控 TTFB 和总时间

---

## 卡片 12：快速决策表

### 场景 → 方案

| 场景 | 推荐方案 |
|------|----------|
| ChatGPT 式对话 | `stream_mode="messages"` |
| 多步 Agent 监控 | `stream_mode="updates"` |
| 数据处理进度 | `stream_mode="custom"` |
| 全面监控 | `stream_mode=["updates", "messages", "custom"]` |
| 后台批处理 | `invoke()` 不流式 |
| 高并发场景 | `astream()` 异步流式 |
| 嵌套 Agent | `subgraphs=True` |
| 人工审核 | Human-in-the-loop 流式 |

---

## 卡片 13：源码位置速查

### 核心源码

```
langchain_core/runnables/base.py:132
└─ astream() 方法定义

langchain_core/tracers/event_stream.py
└─ 事件流实现

langchain_core/tracers/_streaming.py
└─ 流式回调处理器

langgraph/config.py
└─ get_stream_writer() 实现
```

### 关键类

```
Runnable
├─ invoke() - 批量执行
├─ stream() - 同步流式
├─ astream() - 异步流式
└─ transform() - 流式转换

RunnableSequence
└─ 链式组合的流式支持

_StreamingCallbackHandler
└─ LLM token 流式回调
```

---

## 卡片 14：面试高频问题

### Q1: 流式执行解决什么问题？
**A**: 优化用户感知等待时间，从 5 秒降至 0.1 秒

### Q2: 三种流式模式的区别？
**A**: updates（步骤）、messages（tokens）、custom（自定义）

### Q3: 为什么流式总时间会略长？
**A**: 网络往返、序列化等开销，但 <10%，ROI 极高

### Q4: get_stream_writer 为什么只能在工具内部？
**A**: 依赖 LangGraph 执行上下文，需要知道数据发送到哪个流

### Q5: 如何优化流式性能？
**A**: 使用 astream()、禁用不需要的模式、连接池复用

---

## 卡片 15：一行代码速查

### 基础流式
```python
async for chunk in chain.astream(input): print(chunk.content, end="", flush=True)
```

### Agent 进度
```python
for chunk in agent.stream(input, stream_mode="updates"): print(list(chunk.keys()))
```

### LLM Tokens
```python
for token, _ in agent.stream(input, stream_mode="messages"): print(token.content, end="")
```

### 自定义流式
```python
writer = get_stream_writer(); writer("Processing...")
```

### 多模式
```python
for mode, data in agent.stream(input, stream_mode=["updates", "messages"]): print(mode, data)
```

---

## 卡片 16：性能基准

### 基准数据（2026）

```
单次调用：
- invoke(): 5.23 秒
- astream(): 5.45 秒
- 开销: 4.2%

10 次并发：
- stream(): 52.3 秒（串行）
- astream(): 5.5 秒（并发）
- 提升: 9.5 倍

首字节时间：
- invoke(): 5.23 秒
- astream(): 0.1 秒
- 提升: 52 倍
```

### 性能目标

- TTFB < 200ms
- 总时间开销 < 10%
- 并发吞吐量 > 100 QPS

---

## 卡片 17：错误码速查

### 常见错误

| 错误 | 原因 | 解决方案 |
|------|------|----------|
| `RuntimeError: No stream writer` | 工具外部使用 | 只在工具内部使用 |
| `AttributeError: 'tuple' has no 'content'` | messages 模式解构错误 | 使用 `token, metadata = data` |
| 输出不显示 | 缺少 flush | 添加 `flush=True` |
| `ConnectionError` | 网络中断 | 添加重试机制 |
| `TimeoutError` | 执行超时 | 设置超时并降级 |

---

## 卡片 18：最佳实践清单

### 代码规范

✅ 使用 `astream()` 而非 `stream()`
✅ 所有 `print()` 添加 `flush=True`
✅ 正确解构 `messages` 模式
✅ 只在工具内部使用 `get_stream_writer()`
✅ 不假设多模式流式的顺序

### 架构设计

✅ 根据场景选择合适的流式模式
✅ 添加错误处理和降级方案
✅ 监控 TTFB 和总时间
✅ 合理使用批量 + 流式组合
✅ 生产环境使用异步流式

### 性能优化

✅ 禁用不需要的流式模式
✅ 使用连接池（2025+ 自动）
✅ 监控性能指标
✅ 设置合理的超时
✅ 实现重试机制

---

## 卡片 19：学习路径

### 第 1 周：基础掌握
- [ ] 理解流式执行的本质
- [ ] 掌握三种流式模式
- [ ] 实现简单的 ChatGPT 式对话

### 第 2 周：深入理解
- [ ] 学习实现原理（AsyncIterator + 回调 + Transform）
- [ ] 理解性能权衡
- [ ] 掌握错误处理

### 第 3 周：高级应用
- [ ] 多模式流式组合
- [ ] Subgraph 流式
- [ ] Human-in-the-loop 流式

### 第 4 周：生产部署
- [ ] 性能优化
- [ ] 监控和日志
- [ ] 错误处理和降级

---

## 卡片 20：资源导航

### 官方文档
- **Streaming Overview**: https://docs.langchain.com/oss/python/langchain/streaming/overview
- **LangGraph Streaming**: https://docs.langchain.com/oss/python/langgraph/streaming

### 源码阅读
- `langchain_core/runnables/base.py:132` - astream 方法
- `langchain_core/tracers/event_stream.py` - 事件流实现
- `langgraph/config.py` - get_stream_writer 实现

### 相关知识点
- 01_30字核心 - 核心定义
- 02_第一性原理 - 深入理解设计原理
- 04_最小可用 - 最小 API 集
- 07_实战代码 - 完整代码示例

---

## 使用说明

### 如何使用这些卡片

1. **快速查阅**：需要某个知识点时，直接查找对应卡片
2. **记忆巩固**：定期复习卡片，强化记忆
3. **实战应用**：遇到问题时，参考卡片中的代码示例
4. **面试准备**：重点复习卡片 14（面试高频问题）

### 记忆技巧

1. **口诀记忆**：使用卡片中的记忆口诀
2. **类比记忆**：使用卡片 9 的类比方法
3. **实践记忆**：动手实现卡片中的代码示例
4. **关联记忆**：将多个卡片的知识点关联起来

---

**版本**：LangChain 0.3.x (2025-2026)
**最后更新**：2026-02-21
**核心理念**：将复杂知识浓缩为易记忆、易应用的卡片形式。
