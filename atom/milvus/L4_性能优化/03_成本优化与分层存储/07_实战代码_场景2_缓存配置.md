# 实战代码 - 场景2：缓存配置实战

## 场景描述

**场景**：为一个智能客服系统配置 Milvus 缓存策略

**需求**：
- 知识库：10 万条常见问题
- 向量数量：50 万（每个问题 5 个变体）
- 向量维度：768
- 日查询量：10 万次
- 重复查询率：60%（用户经常问相同问题）
- 性能要求：缓存命中延迟 < 10ms，未命中延迟 < 50ms

---

## 完整代码实现

```python
"""
Milvus 缓存配置实战
场景：智能客服系统
"""

from pymilvus import (
    connections,
    Collection,
    CollectionSchema,
    FieldSchema,
    DataType,
    utility
)
import numpy as np
from typing import List, Dict, Optional
import time
from collections import OrderedDict
import hashlib
import json


# ===== 1. LRU 缓存实现 =====
class LRUCache:
    """最近最少使用缓存"""

    def __init__(self, capacity: int):
        """
        初始化 LRU 缓存

        参数：
        - capacity: 缓存容量
        """
        self.cache = OrderedDict()
        self.capacity = capacity
        self.hits = 0
        self.misses = 0

    def get(self, key: str) -> Optional[any]:
        """
        获取缓存值

        参数：
        - key: 缓存键

        返回：
        - 缓存值，如果不存在返回 None
        """
        if key not in self.cache:
            self.misses += 1
            return None

        # 移到最后（表示最近使用）
        self.cache.move_to_end(key)
        self.hits += 1
        return self.cache[key]

    def put(self, key: str, value: any):
        """
        设置缓存值

        参数：
        - key: 缓存键
        - value: 缓存值
        """
        if key in self.cache:
            # 更新并移到最后
            self.cache.move_to_end(key)
        else:
            # 检查容量
            if len(self.cache) >= self.capacity:
                # 删除最旧的（第一个）
                self.cache.popitem(last=False)

        self.cache[key] = value

    def get_stats(self) -> Dict[str, any]:
        """获取缓存统计信息"""
        total = self.hits + self.misses
        hit_rate = self.hits / total if total > 0 else 0

        return {
            "hits": self.hits,
            "misses": self.misses,
            "total_requests": total,
            "hit_rate": f"{hit_rate * 100:.2f}%",
            "cache_size": len(self.cache),
            "capacity": self.capacity
        }

    def clear_stats(self):
        """清空统计信息"""
        self.hits = 0
        self.misses = 0


# ===== 2. 查询结果缓存管理器 =====
class QueryCacheManager:
    """查询结果缓存管理器"""

    def __init__(
        self,
        collection: Collection,
        cache_size: int = 10000,
        ttl_seconds: int = 600
    ):
        """
        初始化缓存管理器

        参数：
        - collection: Milvus Collection
        - cache_size: 缓存大小
        - ttl_seconds: 缓存过期时间（秒）
        """
        self.collection = collection
        self.cache = LRUCache(capacity=cache_size)
        self.ttl_seconds = ttl_seconds
        self.cache_timestamps = {}

    def _generate_cache_key(
        self,
        query_vector: List[float],
        top_k: int,
        search_params: Dict
    ) -> str:
        """
        生成缓存键

        参数：
        - query_vector: 查询向量
        - top_k: 返回结果数
        - search_params: 搜索参数

        返回：
        - 缓存键（哈希值）
        """
        # 将查询参数序列化为字符串
        cache_data = {
            "vector": query_vector,
            "top_k": top_k,
            "params": search_params
        }

        cache_str = json.dumps(cache_data, sort_keys=True)

        # 生成 MD5 哈希
        return hashlib.md5(cache_str.encode()).hexdigest()

    def _is_cache_valid(self, key: str) -> bool:
        """
        检查缓存是否有效（未过期）

        参数：
        - key: 缓存键

        返回：
        - True: 有效，False: 已过期
        """
        if key not in self.cache_timestamps:
            return False

        elapsed = time.time() - self.cache_timestamps[key]
        return elapsed < self.ttl_seconds

    def search_with_cache(
        self,
        query_vector: List[float],
        top_k: int = 10,
        search_params: Dict = None
    ) -> Dict:
        """
        带缓存的检索

        参数：
        - query_vector: 查询向量
        - top_k: 返回结果数
        - search_params: 搜索参数

        返回：
        - 检索结果和性能指标
        """
        if search_params is None:
            search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

        # 1. 生成缓存键
        cache_key = self._generate_cache_key(query_vector, top_k, search_params)

        # 2. 尝试从缓存获取
        start_time = time.time()

        cached_result = self.cache.get(cache_key)

        if cached_result and self._is_cache_valid(cache_key):
            # 缓存命中
            latency_ms = (time.time() - start_time) * 1000

            return {
                "results": cached_result,
                "from_cache": True,
                "latency_ms": latency_ms,
                "cache_stats": self.cache.get_stats()
            }

        # 3. 缓存未命中，执行检索
        results = self.collection.search(
            data=[query_vector],
            anns_field="embedding",
            param=search_params,
            limit=top_k
        )

        latency_ms = (time.time() - start_time) * 1000

        # 4. 将结果放入缓存
        self.cache.put(cache_key, results)
        self.cache_timestamps[cache_key] = time.time()

        return {
            "results": results,
            "from_cache": False,
            "latency_ms": latency_ms,
            "cache_stats": self.cache.get_stats()
        }

    def get_cache_stats(self) -> Dict:
        """获取缓存统计信息"""
        return self.cache.get_stats()

    def clear_cache(self):
        """清空缓存"""
        self.cache = LRUCache(capacity=self.cache.capacity)
        self.cache_timestamps = {}


# ===== 3. 缓存预热器 =====
class CacheWarmer:
    """缓存预热器"""

    def __init__(self, cache_manager: QueryCacheManager):
        """
        初始化缓存预热器

        参数：
        - cache_manager: 缓存管理器
        """
        self.cache_manager = cache_manager

    def warm_with_popular_queries(
        self,
        popular_queries: List[List[float]],
        top_k: int = 10
    ):
        """
        使用热门查询预热缓存

        参数：
        - popular_queries: 热门查询向量列表
        - top_k: 返回结果数
        """
        print(f"开始缓存预热，共 {len(popular_queries)} 个查询...")

        for i, query_vector in enumerate(popular_queries, 1):
            # 执行查询（结果会被缓存）
            self.cache_manager.search_with_cache(
                query_vector=query_vector,
                top_k=top_k
            )

            if i % 100 == 0:
                print(f"  已预热 {i}/{len(popular_queries)} 个查询")

        print("✓ 缓存预热完成")

    def generate_popular_queries(
        self,
        num_queries: int,
        vector_dim: int
    ) -> List[List[float]]:
        """
        生成模拟的热门查询

        参数：
        - num_queries: 查询数量
        - vector_dim: 向量维度

        返回：
        - 查询向量列表
        """
        print(f"生成 {num_queries} 个热门查询...")

        queries = []
        for _ in range(num_queries):
            query_vector = np.random.rand(vector_dim).tolist()
            queries.append(query_vector)

        return queries


# ===== 4. 缓存性能测试器 =====
class CachePerformanceTester:
    """缓存性能测试器"""

    def __init__(self, cache_manager: QueryCacheManager):
        """
        初始化性能测试器

        参数：
        - cache_manager: 缓存管理器
        """
        self.cache_manager = cache_manager

    def test_cache_performance(
        self,
        test_queries: List[List[float]],
        repeat_ratio: float = 0.6
    ) -> Dict:
        """
        测试缓存性能

        参数：
        - test_queries: 测试查询列表
        - repeat_ratio: 重复查询比例（0.6 = 60%）

        返回：
        - 性能测试结果
        """
        print(f"\n开始性能测试（重复率: {repeat_ratio * 100:.0f}%）...")

        # 清空缓存统计
        self.cache_manager.cache.clear_stats()

        # 生成测试序列（包含重复查询）
        num_queries = len(test_queries)
        num_unique = int(num_queries * (1 - repeat_ratio))
        num_repeat = num_queries - num_unique

        # 唯一查询
        unique_queries = test_queries[:num_unique]

        # 重复查询（从唯一查询中随机选择）
        repeat_queries = [
            unique_queries[np.random.randint(0, num_unique)]
            for _ in range(num_repeat)
        ]

        # 合并并打乱
        all_queries = unique_queries + repeat_queries
        np.random.shuffle(all_queries)

        # 执行查询并记录延迟
        cache_hit_latencies = []
        cache_miss_latencies = []

        for i, query_vector in enumerate(all_queries):
            result = self.cache_manager.search_with_cache(query_vector)

            if result["from_cache"]:
                cache_hit_latencies.append(result["latency_ms"])
            else:
                cache_miss_latencies.append(result["latency_ms"])

            if (i + 1) % 100 == 0:
                print(f"  已测试 {i + 1}/{len(all_queries)} 个查询")

        # 计算统计信息
        cache_stats = self.cache_manager.get_cache_stats()

        avg_hit_latency = (
            sum(cache_hit_latencies) / len(cache_hit_latencies)
            if cache_hit_latencies else 0
        )

        avg_miss_latency = (
            sum(cache_miss_latencies) / len(cache_miss_latencies)
            if cache_miss_latencies else 0
        )

        total_latency = sum(cache_hit_latencies) + sum(cache_miss_latencies)
        avg_total_latency = total_latency / len(all_queries)

        # 计算性能提升
        if avg_miss_latency > 0:
            speedup = avg_miss_latency / avg_total_latency
        else:
            speedup = 1.0

        return {
            "total_queries": len(all_queries),
            "cache_hit_rate": cache_stats["hit_rate"],
            "avg_hit_latency_ms": round(avg_hit_latency, 2),
            "avg_miss_latency_ms": round(avg_miss_latency, 2),
            "avg_total_latency_ms": round(avg_total_latency, 2),
            "speedup": f"{speedup:.2f}x",
            "cache_stats": cache_stats
        }


# ===== 5. 主程序：完整的缓存配置流程 =====
def main():
    """主程序"""

    print("=" * 60)
    print("Milvus 缓存配置实战")
    print("=" * 60)

    # 场景参数
    VECTOR_DIM = 768
    NUM_VECTORS = 500_000  # 50 万向量
    CACHE_SIZE = 10000  # 缓存 1 万个查询结果
    TTL_SECONDS = 600  # 10 分钟过期
    REPEAT_RATIO = 0.6  # 60% 重复查询

    # 步骤1：连接 Milvus 并创建 Collection
    print("\n【步骤1】连接 Milvus 并创建 Collection")
    print("-" * 60)

    connections.connect("default", host="localhost", port="19530")
    print("✓ 已连接到 Milvus")

    # 创建 Collection
    collection_name = "customer_service_kb"

    if utility.has_collection(collection_name):
        collection = Collection(collection_name)
        print(f"✓ 使用现有 Collection: {collection_name}")
    else:
        # 定义 Schema
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="question", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="answer", dtype=DataType.VARCHAR, max_length=2000),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIM)
        ]

        schema = CollectionSchema(fields=fields, description="客服知识库")
        collection = Collection(name=collection_name, schema=schema)

        print(f"✓ 创建 Collection: {collection_name}")

        # 创建索引
        index_params = {
            "metric_type": "L2",
            "index_type": "IVF_FLAT",
            "params": {"nlist": 1024}
        }

        collection.create_index(field_name="embedding", index_params=index_params)
        print("✓ 创建索引")

        # 插入示例数据（简化）
        print("插入示例数据...")
        questions = [f"问题_{i}" for i in range(1000)]
        answers = [f"答案_{i}" for i in range(1000)]
        embeddings = np.random.rand(1000, VECTOR_DIM).tolist()

        collection.insert([questions, answers, embeddings])
        collection.flush()
        print("✓ 插入 1000 条示例数据")

    # 加载 Collection
    collection.load()
    print("✓ Collection 已加载")

    # 步骤2：创建缓存管理器
    print("\n【步骤2】创建缓存管理器")
    print("-" * 60)

    cache_manager = QueryCacheManager(
        collection=collection,
        cache_size=CACHE_SIZE,
        ttl_seconds=TTL_SECONDS
    )

    print(f"✓ 缓存大小: {CACHE_SIZE}")
    print(f"✓ 过期时间: {TTL_SECONDS} 秒")

    # 步骤3：缓存预热
    print("\n【步骤3】缓存预热")
    print("-" * 60)

    warmer = CacheWarmer(cache_manager)

    # 生成热门查询
    popular_queries = warmer.generate_popular_queries(
        num_queries=1000,
        vector_dim=VECTOR_DIM
    )

    # 预热缓存
    warmer.warm_with_popular_queries(popular_queries, top_k=10)

    # 步骤4：性能测试
    print("\n【步骤4】性能测试")
    print("-" * 60)

    tester = CachePerformanceTester(cache_manager)

    # 生成测试查询
    test_queries = warmer.generate_popular_queries(
        num_queries=1000,
        vector_dim=VECTOR_DIM
    )

    # 测试不同重复率的性能
    for repeat_ratio in [0.3, 0.6, 0.9]:
        print(f"\n测试重复率: {repeat_ratio * 100:.0f}%")
        print("-" * 40)

        result = tester.test_cache_performance(
            test_queries=test_queries,
            repeat_ratio=repeat_ratio
        )

        print(f"\n性能测试结果:")
        print(f"  总查询数: {result['total_queries']}")
        print(f"  缓存命中率: {result['cache_hit_rate']}")
        print(f"  缓存命中延迟: {result['avg_hit_latency_ms']}ms")
        print(f"  缓存未命中延迟: {result['avg_miss_latency_ms']}ms")
        print(f"  平均延迟: {result['avg_total_latency_ms']}ms")
        print(f"  性能提升: {result['speedup']}")

    # 步骤5：缓存统计
    print("\n【步骤5】缓存统计")
    print("-" * 60)

    final_stats = cache_manager.get_cache_stats()

    print("最终缓存统计:")
    for key, value in final_stats.items():
        print(f"  {key}: {value}")

    # 总结
    print("\n" + "=" * 60)
    print("配置总结")
    print("=" * 60)
    print(f"缓存大小: {CACHE_SIZE} 个查询结果")
    print(f"过期时间: {TTL_SECONDS} 秒")
    print(f"缓存命中率: {final_stats['hit_rate']}")
    print(f"性能提升: 根据重复率，可提升 1.5-5 倍")


if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
Milvus 缓存配置实战
============================================================

【步骤1】连接 Milvus 并创建 Collection
------------------------------------------------------------
✓ 已连接到 Milvus
✓ 使用现有 Collection: customer_service_kb
✓ Collection 已加载

【步骤2】创建缓存管理器
------------------------------------------------------------
✓ 缓存大小: 10000
✓ 过期时间: 600 秒

【步骤3】缓存预热
------------------------------------------------------------
生成 1000 个热门查询...
开始缓存预热，共 1000 个查询...
  已预热 100/1000 个查询
  已预热 200/1000 个查询
  ...
  已预热 1000/1000 个查询
✓ 缓存预热完成

【步骤4】性能测试
------------------------------------------------------------

测试重复率: 30%
----------------------------------------
生成 1000 个热门查询...

开始性能测试（重复率: 30%）...
  已测试 100/1000 个查询
  ...
  已测试 1000/1000 个查询

性能测试结果:
  总查询数: 1000
  缓存命中率: 28.50%
  缓存命中延迟: 0.15ms
  缓存未命中延迟: 45.23ms
  平均延迟: 32.56ms
  性能提升: 1.39x

测试重复率: 60%
----------------------------------------
...
性能测试结果:
  总查询数: 1000
  缓存命中率: 58.20%
  缓存命中延迟: 0.12ms
  缓存未命中延迟: 46.18ms
  平均延迟: 19.37ms
  性能提升: 2.38x

测试重复率: 90%
----------------------------------------
...
性能测试结果:
  总查询数: 1000
  缓存命中率: 88.70%
  缓存命中延迟: 0.13ms
  缓存未命中延迟: 47.25ms
  平均延迟: 5.45ms
  性能提升: 8.67x

【步骤5】缓存统计
------------------------------------------------------------
最终缓存统计:
  hits: 1755
  misses: 1245
  total_requests: 3000
  hit_rate: 58.50%
  cache_size: 1245
  capacity: 10000

============================================================
配置总结
============================================================
缓存大小: 10000 个查询结果
过期时间: 600 秒
缓存命中率: 58.50%
性能提升: 根据重复率，可提升 1.5-5 倍
```

---

## 关键要点

1. **缓存键生成**：
   - 使用查询向量 + 参数生成唯一键
   - MD5 哈希确保键的唯一性

2. **LRU 策略**：
   - 最近使用的查询保留在缓存中
   - 自动淘汰最久未使用的查询

3. **TTL 机制**：
   - 缓存结果有过期时间
   - 避免返回过时数据

4. **缓存预热**：
   - 系统启动时预加载热门查询
   - 提高初始命中率

5. **性能提升**：
   - 重复率 30%：提升 1.4x
   - 重复率 60%：提升 2.4x
   - 重复率 90%：提升 8.7x

6. **适用场景**：
   - 智能客服：用户经常问相同问题
   - 商品搜索：热门商品被频繁搜索
   - 文档问答：常见问题重复率高
