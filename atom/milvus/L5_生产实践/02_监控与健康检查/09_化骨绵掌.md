# 化骨绵掌

> 10个2分钟知识卡片，系统掌握监控与健康检查

---

## 卡片1：监控的本质是什么？

**一句话：** 监控是通过持续观察系统状态，及时发现异常，快速定位问题的过程。

**核心观点：**
- 监控不是目的，而是手段
- 目的是保障系统稳定运行
- 三个关键环节：观察 → 发现 → 定位

**举例：**
```python
# 监控就像汽车仪表盘
仪表盘（监控系统）
├── 速度表（QPS）
├── 转速表（CPU）
├── 油量表（内存）
└── 故障灯（告警）
```

**应用：** 在 RAG 系统中，监控向量检索的延迟、准确率、资源使用，确保用户体验。

---

## 卡片2：Prometheus 的 Pull 模型

**一句话：** Prometheus 主动拉取指标，而不是应用推送，实现故障隔离和灵活服务发现。

**核心观点：**
- Pull 模型：Prometheus → 应用（拉取）
- Push 模型：应用 → 监控系统（推送）
- Pull 的优势：监控系统故障不影响应用

**举例：**
```python
# Milvus 暴露 Metrics 端点
http://localhost:9091/metrics

# Prometheus 每 15 秒拉取一次
scrape_configs:
  - job_name: 'milvus'
    scrape_interval: 15s
    static_configs:
      - targets: ['milvus:9091']
```

**应用：** Milvus 只需暴露端点，无需关心监控系统地址，降低耦合。

---

## 卡片3：三种指标类型

**一句话：** Counter（只增不减）、Gauge（可增可减）、Histogram（分布统计）是 Prometheus 的三种基础指标类型。

**核心观点：**
- **Counter**：累计值，如总请求数（只增不减）
- **Gauge**：瞬时值，如当前内存使用（可增可减）
- **Histogram**：分布统计，如延迟分布（分桶计数）

**举例：**
```python
# Counter：查询总次数
milvus_proxy_search_vectors_count

# Gauge：当前内存使用
process_resident_memory_bytes

# Histogram：查询延迟分布
milvus_proxy_search_latency_milliseconds_bucket
```

**应用：** 选择正确的指标类型：累计用 Counter，当前状态用 Gauge，分布用 Histogram。

---

## 卡片4：Liveness vs Readiness

**一句话：** Liveness 检查进程是否存活（失败→重启），Readiness 检查服务是否就绪（失败→停止流量）。

**核心观点：**
- **Liveness**：回答"需要重启吗？"
- **Readiness**：回答"能接收流量吗？"
- 决策树：重启能解决问题吗？能→Liveness，不能→Readiness

**举例：**
```python
# Liveness：只检查进程本身
@app.route('/healthz')
def liveness():
    return "OK", 200

# Readiness：检查依赖服务
@app.route('/readyz')
def readiness():
    if not check_etcd():
        return "not ready", 503
    return "OK", 200
```

**应用：** Liveness 检查 Milvus 进程，Readiness 检查 etcd、MinIO、Pulsar 连接。

---

## 卡片5：四个黄金信号

**一句话：** Google SRE 提出的四个核心监控指标：延迟、流量、错误、饱和度。

**核心观点：**
- **延迟（Latency）**：P50、P95、P99 延迟
- **流量（Traffic）**：QPS、吞吐量
- **错误（Errors）**：错误率、失败次数
- **饱和度（Saturation）**：CPU、内存、磁盘使用率

**举例：**
```promql
# 延迟：P95 查询延迟
histogram_quantile(0.95, rate(milvus_proxy_search_latency_milliseconds_bucket[5m]))

# 流量：QPS
rate(milvus_proxy_search_vectors_count[5m])

# 错误：错误率
rate(milvus_proxy_search_failed_count[5m]) / rate(milvus_proxy_search_vectors_count[5m])

# 饱和度：内存使用率
process_resident_memory_bytes / (16 * 1024^3) * 100
```

**应用：** 任何系统都应该监控这四个指标，覆盖最关键的健康状况。

---

## 卡片6：PromQL 查询语言

**一句话：** PromQL 是 Prometheus 的查询语言，用于从时间序列数据中提取和计算指标。

**核心观点：**
- **即时查询**：查询当前值
- **范围查询**：查询一段时间的数据
- **聚合函数**：sum、avg、max、min
- **速率函数**：rate（计算速率）、increase（计算增量）

**举例：**
```promql
# 计算 QPS（过去 5 分钟的平均速率）
rate(milvus_proxy_search_vectors_count[5m])

# 计算总 QPS（所有实例）
sum(rate(milvus_proxy_search_vectors_count[5m]))

# 按 Collection 分组
sum by (collection) (rate(milvus_proxy_search_vectors_count[5m]))
```

**应用：** 使用 PromQL 在 Grafana 中创建复杂的监控图表。

---

## 卡片7：告警规则设计

**一句话：** 告警规则定义何时触发告警，包括条件、持续时间、严重程度和通知方式。

**核心观点：**
- **条件**：指标超过阈值
- **持续时间**：连续 N 分钟才触发（避免抖动）
- **严重程度**：Critical、Warning、Info
- **可操作性**：每个告警都应该有明确的处理步骤

**举例：**
```yaml
- alert: HighSearchLatency
  expr: histogram_quantile(0.95, rate(milvus_proxy_search_latency_milliseconds_bucket[5m])) > 500
  for: 5m  # 持续 5 分钟才触发
  labels:
    severity: warning
  annotations:
    summary: "Milvus search latency is high"
    description: "P95 latency is {{ $value }}ms"
```

**应用：** 设置合理的阈值和持续时间，避免告警风暴和误报。

---

## 卡片8：Grafana 仪表盘设计

**一句话：** Grafana 将 Prometheus 指标转换为可视化图表，通过仪表盘实时监控系统状态。

**核心观点：**
- **面板类型**：Time series（折线图）、Gauge（仪表盘）、Stat（数值）
- **变量**：动态过滤数据（如选择实例、Collection）
- **阈值**：颜色编码（绿色正常、黄色警告、红色危险）
- **分层设计**：概览 → 详细 → 诊断

**举例：**
```python
# 创建 QPS 面板
{
  "title": "QPS",
  "type": "timeseries",
  "targets": [{
    "expr": "rate(milvus_proxy_search_vectors_count[5m])"
  }],
  "fieldConfig": {
    "defaults": {"unit": "reqps"}
  }
}
```

**应用：** 设计清晰的仪表盘，让运维人员一眼看出系统状态。

---

## 卡片9：健康检查最佳实践

**一句话：** 健康检查要平衡及时性和稳定性，避免误判导致不必要的重启。

**核心观点：**
- **初始延迟**：给足够的启动时间（Liveness 90秒，Readiness 30秒）
- **检查间隔**：Liveness 30秒，Readiness 10秒
- **失败阈值**：连续失败 N 次才判定（Liveness 3次，Readiness 2次）
- **超时时间**：避免网络抖动误判（Liveness 10秒，Readiness 5秒）

**举例：**
```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 9091
  initialDelaySeconds: 90
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3
```

**应用：** 合理配置健康检查参数，避免因偶发故障导致服务不稳定。

---

## 卡片10：监控的常见误区

**一句话：** 避免三大误区：指标越多越好、Liveness 检查依赖服务、检查频率越高越好。

**核心观点：**
- **误区1**：采集大量无用指标 → 存储爆炸、查询变慢
- **误区2**：Liveness 检查依赖服务 → 不断重启无法解决问题
- **误区3**：检查频率过高 → 增加系统负担、容易误判

**正确做法：**
```python
# ✅ 只采集可操作的指标
milvus_proxy_search_vectors_count{collection="kb"}

# ❌ 避免高基数标签
milvus_proxy_search_vectors_count{user_id="12345"}

# ✅ Liveness 只检查进程
@app.route('/healthz')
def liveness():
    return "OK", 200

# ✅ 合理的检查频率
periodSeconds: 30  # 不是 1 秒
```

**应用：** 遵循最佳实践，构建高效稳定的监控系统。

---

## 知识卡片总结

**10个卡片的学习路径：**

```
1. 监控本质 → 理解监控的目的和价值
2. Pull 模型 → 理解 Prometheus 的工作原理
3. 指标类型 → 掌握三种基础指标类型
4. 健康探针 → 区分 Liveness 和 Readiness
5. 黄金信号 → 掌握核心监控指标
6. PromQL → 学会查询和计算指标
7. 告警规则 → 设计有效的告警
8. Grafana → 创建可视化仪表盘
9. 最佳实践 → 优化健康检查配置
10. 常见误区 → 避免典型错误
```

**学习检查清单：**

- [ ] 理解监控的三个关键环节（观察、发现、定位）
- [ ] 能解释 Pull 模型和 Push 模型的区别
- [ ] 能区分 Counter、Gauge、Histogram 的使用场景
- [ ] 能正确配置 Liveness 和 Readiness 探针
- [ ] 能监控四个黄金信号（延迟、流量、错误、饱和度）
- [ ] 能编写基础的 PromQL 查询
- [ ] 能设计合理的告警规则（条件、持续时间、严重程度）
- [ ] 能创建 Grafana 监控仪表盘
- [ ] 能优化健康检查配置（频率、阈值、超时）
- [ ] 能识别和避免常见监控误区

**下一步学习建议：**

1. **实践部署**：按照实战代码部署完整的监控栈
2. **模拟故障**：手动触发故障，观察监控和告警的反应
3. **优化调整**：根据实际情况调整告警阈值和检查频率
4. **扩展应用**：为 RAG 系统添加自定义监控指标

---

**完成标志：**

当你能够：
- ✅ 独立部署 Prometheus + Grafana 监控栈
- ✅ 为 Milvus 配置完整的健康检查
- ✅ 创建自定义的监控仪表盘
- ✅ 设计合理的告警规则
- ✅ 快速定位和解决监控问题

你就已经掌握了 Milvus 监控与健康检查的核心知识！

---

**参考资源：**

- Prometheus 官方文档：https://prometheus.io/docs/
- Grafana 官方文档：https://grafana.com/docs/
- Google SRE Book：https://sre.google/books/
- Kubernetes 健康检查：https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
