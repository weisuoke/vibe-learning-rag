# 核心概念3：声明分解与原子验证

> **将复杂句子拆分为原子声明，逐一验证每个最小事实单元**

---

## 概念定义

**声明分解（Claim Decomposition）**：将生成的复杂句子拆分为多个独立的原子声明，每个声明只包含一个可验证的事实。

**原子声明（Atomic Claim）**：不可再分的最小语义单元，包含完整的主谓宾结构，可以独立验证真伪。

**原子验证（Atomic Verification）**：对每个原子声明逐一验证是否被检索上下文支持。

---

## 为什么需要声明分解？

### 问题：整体验证的局限性

```
生成内容："Python是一种由Guido van Rossum于1991年创建的高级编程语言，广泛用于数据科学和Web开发。"

整体验证：
- Faithfulness分数：0.6（部分支持）
- 问题：无法知道哪个部分有问题

声明分解后：
1. "Python是一种编程语言" ✅
2. "Python是高级编程语言" ✅
3. "Python由Guido van Rossum创建" ✅
4. "Python于1991年创建" ✅
5. "Python广泛用于数据科学" ❌（上下文未提及）
6. "Python广泛用于Web开发" ❌（上下文未提及）

结论：精确定位幻觉位置（第5、6个声明）
```

---

## 原子声明的判断标准

### 三个必要条件

1. **包含完整的主谓宾结构**
   ```
   ✅ "Python是编程语言"（主谓宾完整）
   ❌ "Python"（只有主语）
   ❌ "编程语言"（只有宾语）
   ```

2. **可以独立验证真伪**
   ```
   ✅ "Python由Guido创建"（可以验证）
   ❌ "Python很好用"（主观判断，无法验证）
   ```

3. **不能再拆分而不丢失语义**
   ```
   ✅ "Python是高级语言"（已经是原子）
   ❌ "Python是一种由Guido创建的高级语言"（可以继续拆分）
   ```

---

## 声明分解方法

### 方法1：使用LLM分解（推荐）

```python
from openai import OpenAI

client = OpenAI()

def decompose_claims_with_llm(response: str) -> list[str]:
    """使用LLM分解声明"""

    prompt = f"""
将以下回答拆分为独立的原子声明。

回答：
{response}

要求：
1. 每个声明只包含一个可验证的事实
2. 每个声明独立完整，包含主谓宾结构
3. 不包含推理或解释
4. 不能再拆分而不丢失语义

输出格式：每行一个声明，不要编号
"""

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0  # 确保输出稳定
    )

    claims_text = completion.choices[0].message.content.strip()
    claims = [c.strip("- ").strip() for c in claims_text.split("\n") if c.strip()]

    return claims

# 使用示例
response = "Python是一种由Guido van Rossum于1991年创建的高级编程语言，广泛用于数据科学和Web开发。"
claims = decompose_claims_with_llm(response)

for i, claim in enumerate(claims, 1):
    print(f"{i}. {claim}")
```

**输出示例：**
```
1. Python是一种编程语言
2. Python是高级编程语言
3. Python由Guido van Rossum创建
4. Python于1991年创建
5. Python广泛用于数据科学
6. Python广泛用于Web开发
```

### 方法2：基于规则分解

```python
import re
from typing import List

def rule_based_decompose(response: str) -> List[str]:
    """基于规则的声明分解"""

    claims = []

    # 步骤1：按句子分割
    sentences = re.split(r'[。！？]', response)

    for sent in sentences:
        if not sent.strip():
            continue

        # 步骤2：按连词拆分
        # 中文连词：和、以及、并且、同时、而且
        sub_claims = re.split(r'[，,](?=.*(?:和|以及|并且|同时|而且))', sent)

        for sub in sub_claims:
            sub = sub.strip()
            if sub and len(sub) > 3:  # 过滤太短的片段
                claims.append(sub)

    return claims

# 使用示例
response = "Python是一种高级编程语言，由Guido van Rossum创建，广泛用于数据科学和Web开发。"
claims = rule_based_decompose(response)

for i, claim in enumerate(claims, 1):
    print(f"{i}. {claim}")
```

### 方法3：混合方法（最佳实践）

```python
def hybrid_decompose(response: str) -> List[str]:
    """混合方法：规则预处理 + LLM精细化"""

    # 步骤1：规则预处理（快速拆分）
    rough_claims = rule_based_decompose(response)

    # 步骤2：LLM精细化（确保原子性）
    refined_claims = []
    for claim in rough_claims:
        # 对每个粗粒度声明进一步分解
        sub_claims = decompose_claims_with_llm(claim)
        refined_claims.extend(sub_claims)

    # 步骤3：去重
    unique_claims = list(dict.fromkeys(refined_claims))

    return unique_claims
```

---

## 原子验证流程

### 完整验证流程

```python
def atomic_verification(response: str, contexts: List[str]) -> dict:
    """原子级验证流程"""

    # 步骤1：声明分解
    claims = decompose_claims_with_llm(response)

    # 步骤2：逐一验证
    verified_claims = []
    for claim in claims:
        # 方法1：NLI验证
        nli_supported = verify_with_nli(claim, contexts)

        # 方法2：语义相似度
        similarity_supported = verify_with_similarity(claim, contexts)

        # 方法3：LLM-as-judge
        llm_supported = verify_with_llm(claim, contexts)

        # 投票机制
        votes = [nli_supported, similarity_supported, llm_supported]
        is_supported = sum(votes) >= 2

        verified_claims.append({
            "claim": claim,
            "supported": is_supported,
            "nli": nli_supported,
            "similarity": similarity_supported,
            "llm": llm_supported
        })

    # 步骤3：计算支持率
    support_ratio = sum(1 for c in verified_claims if c["supported"]) / len(verified_claims)

    return {
        "claims": verified_claims,
        "support_ratio": support_ratio,
        "total_claims": len(verified_claims),
        "supported_claims": sum(1 for c in verified_claims if c["supported"]),
        "unsupported_claims": [c["claim"] for c in verified_claims if not c["supported"]]
    }
```

### NLI验证实现

```python
from transformers import pipeline

nli_model = pipeline("text-classification", model="microsoft/deberta-v3-base-mnli-fever-anli")

def verify_with_nli(claim: str, contexts: List[str], threshold: float = 0.8) -> bool:
    """使用NLI验证声明"""

    for context in contexts:
        input_text = f"{context} [SEP] {claim}"
        result = nli_model(input_text)[0]

        if result["label"] == "entailment" and result["score"] > threshold:
            return True

    return False
```

### 语义相似度验证

```python
from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')

def verify_with_similarity(claim: str, contexts: List[str], threshold: float = 0.75) -> bool:
    """使用语义相似度验证声明"""

    claim_emb = model.encode(claim, convert_to_tensor=True)
    context_embs = model.encode(contexts, convert_to_tensor=True)

    similarities = util.cos_sim(claim_emb, context_embs)[0]
    max_similarity = similarities.max().item()

    return max_similarity > threshold
```

### LLM-as-judge验证

```python
def verify_with_llm(claim: str, contexts: List[str]) -> bool:
    """使用LLM验证声明"""

    context_text = "\n".join(contexts)

    prompt = f"""
判断以下声明是否被上下文支持。

上下文：
{context_text}

声明：
{claim}

要求：
- 如果上下文明确支持该声明，回答"是"
- 如果上下文与该声明矛盾或未提及，回答"否"

回答（只回答"是"或"否"）：
"""

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    answer = completion.choices[0].message.content.strip()
    return answer == "是"
```

---

## 在RAG中的集成

### 完整RAG流程

```python
def rag_with_atomic_verification(question: str, threshold: float = 0.8):
    """集成原子验证的RAG系统"""

    # 1. 检索
    contexts = retrieve_contexts(question)

    # 2. 生成
    answer = generate_answer(question, contexts)

    # 3. 原子验证
    verification_result = atomic_verification(answer, contexts)

    # 4. 根据支持率决定是否返回
    if verification_result["support_ratio"] >= threshold:
        # 只保留被支持的声明
        supported_claims = [
            c["claim"] for c in verification_result["claims"]
            if c["supported"]
        ]
        filtered_answer = " ".join(supported_claims)

        return {
            "answer": filtered_answer,
            "original_answer": answer,
            "support_ratio": verification_result["support_ratio"],
            "status": "passed",
            "removed_claims": verification_result["unsupported_claims"]
        }
    else:
        return {
            "answer": "抱歉，我无法基于提供的信息回答这个问题。",
            "original_answer": answer,
            "support_ratio": verification_result["support_ratio"],
            "status": "rejected",
            "unsupported_claims": verification_result["unsupported_claims"]
        }
```

---

## 粒度对比

### 不同粒度的效果

| 粒度 | 示例 | 验证次数 | 准确率 | 计算成本 | 推荐 |
|------|------|----------|--------|----------|------|
| **词级** | "Python", "编程语言" | 100+ | 60% | 极高 | ❌ |
| **短语级** | "高级编程语言" | 50+ | 70% | 高 | ❌ |
| **声明级** | "Python是高级编程语言" | 10-20 | 90% | 中 | ✅ |
| **句子级** | 整个句子 | 5-10 | 75% | 低 | ⚠️ |
| **段落级** | 整个段落 | 1-3 | 65% | 极低 | ❌ |

### 粒度选择策略

```python
def adaptive_granularity(response: str, scenario: str) -> List[str]:
    """根据场景自适应选择粒度"""

    if scenario in ["medical", "legal"]:
        # 高风险场景：最细粒度（声明级）
        return decompose_claims_with_llm(response)

    elif scenario in ["enterprise_kb"]:
        # 中风险场景：标准粒度（句子级）
        return response.split("。")

    else:
        # 低风险场景：粗粒度（段落级）
        return [response]
```

---

## 2026年最新技术

### 1. 自动化声明分解框架

**RefChecker（2025）**

```python
from refchecker import RefChecker

checker = RefChecker()

def verify_with_refchecker(response: str, contexts: List[str]) -> dict:
    """使用RefChecker进行声明级验证"""

    result = checker.check(
        claim=response,
        reference=contexts
    )

    return {
        "claims": result["atomic_claims"],
        "support_ratio": result["support_ratio"],
        "unsupported_claims": result["unsupported"]
    }
```

### 2. HalluSearch Pipeline（ACL 2025）

```python
from hallusearch import HalluSearchPipeline

pipeline = HalluSearchPipeline()

def verify_with_hallusearch(response: str, contexts: List[str]) -> dict:
    """使用HalluSearch进行细粒度验证"""

    result = pipeline.verify(
        generated_text=response,
        source_documents=contexts,
        granularity="atomic"  # 原子级验证
    )

    return result
```

### 3. 声明级引用溯源

```python
def claim_level_attribution(claims: List[str], contexts: List[str]) -> List[dict]:
    """为每个声明添加引用"""

    attributed_claims = []

    for claim in claims:
        # 找到最相似的上下文
        best_context = find_best_context(claim, contexts)

        attributed_claims.append({
            "claim": claim,
            "source": best_context["text"],
            "source_index": best_context["index"],
            "similarity": best_context["similarity"]
        })

    return attributed_claims
```

---

## 常见问题

### Q1: 声明分解的粒度如何确定？

**A:** 遵循"原子声明"原则：
- 包含完整的主谓宾结构
- 可以独立验证真伪
- 不能再拆分而不丢失语义

**示例：**
```
❌ 太粗："Python是一种由Guido创建的高级语言"
✅ 合适："Python是高级语言" + "Python由Guido创建"
❌ 太细："Python" + "高级" + "语言"
```

### Q2: 如何处理复杂的逻辑关系？

**A:** 拆分为独立的原子声明

```
原句："如果Python是高级语言，那么它易于学习"

拆分：
1. "Python是高级语言"
2. "高级语言易于学习"

注意：不要拆分为"Python易于学习"（这是推理结果，不是原子声明）
```

### Q3: 声明分解的成本如何优化？

**A:** 3种优化策略：

1. **缓存分解结果**
   ```python
   @lru_cache(maxsize=1000)
   def decompose_claims_cached(response: str) -> tuple:
       claims = decompose_claims_with_llm(response)
       return tuple(claims)  # tuple可以被缓存
   ```

2. **批量分解**
   ```python
   def batch_decompose(responses: List[str]) -> List[List[str]]:
       # 一次LLM调用处理多个回答
       prompt = "\n\n".join([f"回答{i+1}：{r}" for i, r in enumerate(responses)])
       # ...
   ```

3. **规则预处理**
   ```python
   # 先用规则快速拆分，只对复杂句子用LLM
   if len(response) < 50:
       return rule_based_decompose(response)
   else:
       return decompose_claims_with_llm(response)
   ```

### Q4: 如何评估声明分解的质量？

**A:** 3个评估维度：

1. **完整性**：是否覆盖原回答的所有信息
2. **原子性**：每个声明是否不可再分
3. **独立性**：每个声明是否可以独立验证

```python
def evaluate_decomposition(original: str, claims: List[str]) -> dict:
    """评估声明分解质量"""

    # 1. 完整性：重组后的文本与原文的相似度
    reconstructed = " ".join(claims)
    completeness = compute_similarity(original, reconstructed)

    # 2. 原子性：每个声明的平均长度（越短越原子）
    avg_length = sum(len(c) for c in claims) / len(claims)
    atomicity = 1.0 / (1.0 + avg_length / 20)  # 归一化

    # 3. 独立性：每个声明是否包含完整主谓宾
    independence = sum(1 for c in claims if has_complete_structure(c)) / len(claims)

    return {
        "completeness": completeness,
        "atomicity": atomicity,
        "independence": independence,
        "overall_score": (completeness + atomicity + independence) / 3
    }
```

---

## 实际案例

### 案例1：医疗咨询

```python
response = """
感冒的症状包括流鼻涕、咳嗽和发热。
患者应该多喝水、休息，并在必要时服用退烧药。
"""

claims = decompose_claims_with_llm(response)
# 输出：
# 1. 感冒的症状包括流鼻涕
# 2. 感冒的症状包括咳嗽
# 3. 感冒的症状包括发热
# 4. 患者应该多喝水
# 5. 患者应该休息
# 6. 患者在必要时应该服用退烧药

# 逐一验证
context = "感冒的常见症状包括流鼻涕、咳嗽、发热和喉咙痛。"
for claim in claims:
    supported = verify_with_nli(claim, [context])
    print(f"{'✅' if supported else '❌'} {claim}")
```

### 案例2：企业知识库

```python
response = """
公司年假政策规定，入职满1年可享受5天年假，
入职满3年可享受10天年假，入职满5年可享受15天年假。
"""

claims = decompose_claims_with_llm(response)
# 输出：
# 1. 入职满1年可享受5天年假
# 2. 入职满3年可享受10天年假
# 3. 入职满5年可享受15天年假

# 验证
context = """
公司年假政策：
- 入职满1年：5天年假
- 入职满3年：10天年假
- 入职满5年：15天年假
"""

verification_result = atomic_verification(response, [context])
print(f"支持率: {verification_result['support_ratio']}")
# 输出: 支持率: 1.0（所有声明都被支持）
```

---

## 学习资源

### 论文

- **RefChecker: Fine-grained Hallucination Detection** (2025)
- **HalluSearch: Claim-level Hallucination Detection** (ACL 2025)
- **Atomic Claim Decomposition for Fact Verification** (2024)

### 工具

- **RefChecker**: https://github.com/refchecker/refchecker
- **HalluSearch**: https://github.com/hallusearch/hallusearch

### 数据集

- **FEVER**: Fact Extraction and VERification
- **ClaimDecomp**: Claim Decomposition Dataset

---

**记住：声明分解是幻觉检测的核心技术，通过细粒度验证可以精确定位幻觉位置，显著提升检测准确率。**
