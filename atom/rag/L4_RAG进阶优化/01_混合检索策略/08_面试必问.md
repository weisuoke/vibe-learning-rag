# 面试必问

混合检索相关的高频面试问题及出彩回答。

---

## 问题1："为什么 RAG 系统需要混合检索？纯向量检索不够吗？"

### 普通回答（❌ 不出彩）

> "混合检索可以提高召回率，因为它结合了两种方法的优点。"

### 出彩回答（✅ 推荐）

> **混合检索解决的是"检索盲区"问题，我从三个层面来解释：**
>
> **1. 两种检索的本质差异**
>
> - **BM25（关键词检索）**：基于词频统计，核心假设是"查询词出现在文档中 = 相关"。擅长精确匹配专有名词、代码、版本号。
> - **向量检索**：基于语义相似度，核心假设是"语义相近的文本在向量空间中距离近"。擅长理解同义词、意图。
>
> **2. 单一方法的盲区**
>
> - 向量检索搜索 "Python 3.12.1" 可能返回 "Python 3.11" 的文档（版本号语义相似）
> - BM25 搜索 "如何让代码跑得更快" 可能漏掉 "性能优化指南"（没有"快"这个词）
>
> **3. 实际效果对比**
>
> 在我们的项目中，纯 BM25 召回率约 65%，纯向量约 75%，混合检索达到 88%。特别是对于技术文档问答，混合检索能同时处理精确术语查询和自然语言问题。
>
> **所以混合检索不是"锦上添花"，而是生产环境的必需品。**

### 为什么这个回答出彩？

1. ✅ 从原理层面解释了两种方法的本质差异
2. ✅ 用具体例子说明了各自的盲区
3. ✅ 给出了实际项目中的数据对比
4. ✅ 最后总结了实践意义

---

## 问题2："混合检索中，BM25 和向量检索的结果如何融合？"

### 普通回答（❌ 不出彩）

> "可以用 RRF 算法把两个结果合并起来。"

### 出彩回答（✅ 推荐）

> **融合策略是混合检索的核心难点，主要有三种方法：**
>
> **1. 为什么不能直接合并？**
>
> BM25 分数范围是 [0, +∞)，通常在 0-30 之间；向量相似度范围是 [-1, 1]。直接相加会导致 BM25 主导结果，向量检索几乎没有影响。
>
> **2. 三种主流融合策略**
>
> | 策略 | 原理 | 优缺点 |
> |------|------|--------|
> | **RRF（倒数排名融合）** | score = Σ 1/(k+rank) | 简单有效，不需要归一化，业界首选 |
> | **归一化加权** | 先 Min-Max 归一化，再加权求和 | 可调权重，但需要额外计算 |
> | **学习排序** | 用模型学习最优融合权重 | 效果最好，但需要标注数据 |
>
> **3. 我的实践选择**
>
> 生产环境我推荐 RRF，原因是：
> - 不需要归一化，避免了分数尺度问题
> - k=60 是论文验证的鲁棒参数
> - 实现简单，只需要排名信息
>
> ```python
> def rrf(results_list, k=60):
>     scores = {}
>     for results in results_list:
>         for rank, doc_id in enumerate(results, 1):
>             scores[doc_id] = scores.get(doc_id, 0) + 1/(k+rank)
>     return sorted(scores.items(), key=lambda x: x[1], reverse=True)
> ```

### 为什么这个回答出彩？

1. ✅ 先解释了为什么这是个难点（分数不可比）
2. ✅ 系统对比了多种方法
3. ✅ 给出了明确的实践建议和理由
4. ✅ 附带了简洁的代码示例

---

## 问题3："混合检索的权重应该怎么设置？"

### 普通回答（❌ 不出彩）

> "一般设置成 50:50 就可以了。"

### 出彩回答（✅ 推荐）

> **最优权重取决于业务场景，没有万能的答案。我的方法论是：**
>
> **1. 场景分析**
>
> | 场景 | 推荐权重 | 原因 |
> |------|----------|------|
> | 技术文档（代码、API） | BM25:60% 向量:40% | 精确术语多 |
> | 客服对话 | BM25:30% 向量:70% | 自然语言多 |
> | 通用知识库 | BM25:45% 向量:55% | 两者兼顾 |
>
> **2. 数据驱动调优**
>
> 我的做法是：
> 1. 准备一个评估数据集（100+ 条 query + 标注的相关文档）
> 2. 网格搜索不同权重组合（0.1 到 0.9，步长 0.1）
> 3. 用召回率@K 作为评估指标
> 4. 选择最优权重
>
> **3. 动态权重（进阶）**
>
> 更高级的做法是根据查询类型动态调整：
> - 检测到代码/版本号 → 提高 BM25 权重
> - 检测到疑问句 → 提高向量权重
>
> **总结：50:50 是起点，不是终点。生产环境一定要基于数据调优。**

### 为什么这个回答出彩？

1. ✅ 明确指出"没有万能答案"，展示了工程思维
2. ✅ 给出了不同场景的具体建议
3. ✅ 提供了数据驱动的调优方法论
4. ✅ 提到了进阶的动态权重方案

---

## 问题4："BM25 和 TF-IDF 有什么区别？"

### 普通回答（❌ 不出彩）

> "BM25 是 TF-IDF 的改进版本。"

### 出彩回答（✅ 推荐）

> **BM25 是 TF-IDF 的概率改进版，主要有三个关键改进：**
>
> **1. 词频饱和（TF Saturation）**
>
> - TF-IDF：词频越高，分数线性增长
> - BM25：词频增长到一定程度后趋于饱和
>
> ```
> TF-IDF: score ∝ tf（线性）
> BM25:   score ∝ tf / (tf + k1)（饱和曲线）
> ```
>
> 这解决了"一个词出现 100 次不应该比出现 10 次重要 10 倍"的问题。
>
> **2. 文档长度归一化**
>
> - TF-IDF：长文档天然词多，容易得高分
> - BM25：通过 `|D|/avgdl` 归一化，消除长度偏差
>
> **3. 参数可调**
>
> - k1（默认 1.2）：控制词频饱和速度
> - b（默认 0.75）：控制文档长度归一化强度
>
> **实际效果**：在信息检索评测中，BM25 通常比 TF-IDF 高 5-10% 的准确率，是目前关键词检索的事实标准。

### 为什么这个回答出彩？

1. ✅ 指出了具体的改进点，而不是笼统地说"改进"
2. ✅ 用公式和直觉解释了词频饱和
3. ✅ 提到了参数的含义
4. ✅ 给出了实际效果的量化对比

---

## 面试技巧总结

| 问题类型 | 回答策略 |
|----------|----------|
| "为什么需要 X" | 从问题出发，说明 X 解决了什么问题 |
| "X 和 Y 的区别" | 列出 2-3 个关键差异，最好有对比表格 |
| "怎么实现 X" | 先说原理，再说实践选择，最好附代码 |
| "X 的参数怎么设置" | 强调"取决于场景"，给出方法论而非固定值 |

---

**下一步：** [09_化骨绵掌](./09_化骨绵掌.md) - 10个2分钟知识卡片
