# 核心概念05：错误处理与重试机制

> 深入理解任务失败类型、重试策略、死信队列和优雅降级

---

## 任务失败的类型

### 1. 临时性失败（可重试）

**特征**：重试后可能成功

```python
# 网络超时
requests.exceptions.Timeout

# 数据库连接失败
sqlalchemy.exc.OperationalError

# LLM API限流
openai.error.RateLimitError

# 资源暂时不可用
ResourceUnavailableError
```

**处理策略**：自动重试

---

### 2. 永久性失败（不可重试）

**特征**：重试也不会成功

```python
# 文件不存在
FileNotFoundError

# 数据格式错误
json.JSONDecodeError

# 参数错误
ValueError

# 权限不足
PermissionError
```

**处理策略**：立即失败，记录错误

---

### 3. 业务逻辑失败

**特征**：业务规则不满足

```python
# 用户余额不足
InsufficientBalanceError

# 文件格式不支持
UnsupportedFormatError

# 数据验证失败
ValidationError
```

**处理策略**：返回错误信息，不重试

---

## Celery重试机制

### 1. 基础重试配置

```python
from celery import Celery

app = Celery('tasks', broker='redis://localhost:6379/0')

@app.task(
    bind=True,
    max_retries=3,           # 最多重试3次
    default_retry_delay=60   # 重试间隔60秒
)
def process_document(self, file_path: str):
    try:
        # 处理文档
        result = parse_and_embed(file_path)
        return result

    except Exception as e:
        # 重试
        raise self.retry(exc=e)
```

**关键参数**：
- `bind=True`：绑定任务实例（访问self）
- `max_retries`：最大重试次数
- `default_retry_delay`：重试间隔（秒）

---

### 2. 指数退避策略

```python
@app.task(bind=True, max_retries=5)
def process_document(self, file_path: str):
    try:
        result = parse_and_embed(file_path)
        return result

    except Exception as e:
        # 指数退避：60秒、120秒、240秒、480秒、960秒
        countdown = 60 * (2 ** self.request.retries)
        raise self.retry(exc=e, countdown=countdown)
```

**退避时间表**：

| 重试次数 | 等待时间 | 计算公式 |
|---------|---------|---------|
| 第1次 | 60秒 | 60 * 2^0 |
| 第2次 | 120秒 | 60 * 2^1 |
| 第3次 | 240秒 | 60 * 2^2 |
| 第4次 | 480秒 | 60 * 2^3 |
| 第5次 | 960秒 | 60 * 2^4 |

---

### 3. 错误分类重试

```python
@app.task(bind=True, max_retries=3)
def process_document(self, file_path: str):
    try:
        result = parse_and_embed(file_path)
        return result

    except FileNotFoundError:
        # 文件不存在，不重试
        raise

    except requests.exceptions.Timeout as e:
        # 网络超时，重试
        raise self.retry(exc=e, countdown=60)

    except openai.error.RateLimitError as e:
        # API限流，等待更长时间后重试
        raise self.retry(exc=e, countdown=300)

    except Exception as e:
        # 其他错误，记录日志后重试
        logger.error(f"Unexpected error: {e}")
        raise self.retry(exc=e)
```

---

### 4. 自定义重试条件

```python
@app.task(bind=True, max_retries=3)
def call_llm(self, prompt: str):
    try:
        response = llm.invoke(prompt)
        return response

    except Exception as e:
        # 只在特定条件下重试
        if should_retry(e):
            raise self.retry(exc=e, countdown=60)
        else:
            # 不重试，直接失败
            raise

def should_retry(error: Exception) -> bool:
    """判断是否应该重试"""
    # 网络错误：重试
    if isinstance(error, (requests.exceptions.Timeout, requests.exceptions.ConnectionError)):
        return True

    # API限流：重试
    if isinstance(error, openai.error.RateLimitError):
        return True

    # 其他错误：不重试
    return False
```

---

## 任务超时控制

### 1. 软超时和硬超时

```python
@app.task(
    time_limit=300,      # 硬超时：5分钟（强制终止）
    soft_time_limit=270  # 软超时：4.5分钟（抛出异常）
)
def process_document(file_path: str):
    try:
        # 任务逻辑
        result = parse_and_embed(file_path)
        return result

    except SoftTimeLimitExceeded:
        # 软超时，清理资源
        cleanup_resources()
        raise
```

**超时类型对比**：

| 超时类型 | 触发时间 | 行为 | 可捕获 |
|---------|---------|------|--------|
| **软超时** | 4.5分钟 | 抛出异常 | ✅ 可以捕获并清理资源 |
| **硬超时** | 5分钟 | 强制终止 | ❌ 无法捕获 |

---

### 2. 超时后重试

```python
@app.task(
    bind=True,
    max_retries=3,
    time_limit=300,
    soft_time_limit=270
)
def process_document(self, file_path: str):
    try:
        result = parse_and_embed(file_path)
        return result

    except SoftTimeLimitExceeded:
        # 软超时，重试
        logger.warning(f"Task timeout, retrying...")
        raise self.retry(countdown=60)
```

---

## 死信队列（DLQ）

### 1. 什么是死信队列？

**定义**：存储最终失败任务的队列

```
任务执行
   ↓
失败 → 重试1次
   ↓
失败 → 重试2次
   ↓
失败 → 重试3次
   ↓
最终失败 → 进入死信队列（DLQ）
```

---

### 2. 实现死信队列

```python
# app/tasks.py
from app.models.task import Task, TaskStatus
from app.core.database import SessionLocal

@app.task(bind=True, max_retries=3)
def process_document(self, file_path: str, db_task_id: int):
    try:
        result = parse_and_embed(file_path)
        return result

    except Exception as e:
        # 检查是否是最后一次重试
        if self.request.retries >= self.max_retries:
            # 最后一次重试失败，进入死信队列
            send_to_dlq(self.request.id, file_path, str(e))

        # 重试
        raise self.retry(exc=e)

def send_to_dlq(task_id: str, file_path: str, error: str):
    """发送到死信队列"""
    db = SessionLocal()

    # 更新任务状态
    task = db.query(Task).filter(Task.task_id == task_id).first()
    if task:
        task.status = TaskStatus.FAILED
        task.error = error
        db.commit()

    # 记录到死信队列表
    dlq_entry = DeadLetterQueue(
        task_id=task_id,
        task_type="document_process",
        params={"file_path": file_path},
        error=error,
        retry_count=3
    )
    db.add(dlq_entry)
    db.commit()
    db.close()

    # 发送告警
    send_alert(f"Task {task_id} failed after 3 retries")
```

---

### 3. 处理死信队列

```python
@app.task
def process_dlq():
    """定期处理死信队列"""
    db = SessionLocal()

    # 查询死信队列
    dlq_entries = db.query(DeadLetterQueue).filter(
        DeadLetterQueue.processed == False
    ).limit(100).all()

    for entry in dlq_entries:
        # 人工审核或自动处理
        if can_retry(entry):
            # 重新提交任务
            process_document.delay(entry.params['file_path'])

        # 标记为已处理
        entry.processed = True

    db.commit()
    db.close()
```

---

## 错误日志与告警

### 1. 结构化错误日志

```python
import structlog

logger = structlog.get_logger()

@app.task(bind=True, max_retries=3)
def process_document(self, file_path: str):
    try:
        result = parse_and_embed(file_path)
        return result

    except Exception as e:
        # 记录结构化日志
        logger.error(
            "task_failed",
            task_id=self.request.id,
            file_path=file_path,
            error_type=type(e).__name__,
            error_message=str(e),
            retry_count=self.request.retries,
            max_retries=self.max_retries
        )

        # 重试
        raise self.retry(exc=e)
```

---

### 2. 错误告警

```python
def send_alert(message: str, level: str = "error"):
    """发送告警"""
    # 发送到Slack
    slack_webhook = os.getenv("SLACK_WEBHOOK_URL")
    if slack_webhook:
        requests.post(slack_webhook, json={
            "text": f"[{level.upper()}] {message}"
        })

    # 发送邮件
    send_email(
        to="admin@example.com",
        subject=f"Task Alert: {level}",
        body=message
    )

@app.task(bind=True, max_retries=3)
def process_document(self, file_path: str):
    try:
        result = parse_and_embed(file_path)
        return result

    except Exception as e:
        # 最后一次重试失败，发送告警
        if self.request.retries >= self.max_retries:
            send_alert(
                f"Task {self.request.id} failed after {self.max_retries} retries: {e}",
                level="critical"
            )

        raise self.retry(exc=e)
```

---

## 优雅降级

### 1. 降级策略

```python
@app.task(bind=True, max_retries=3)
def generate_summary(self, text: str):
    try:
        # 尝试使用GPT-4
        summary = llm_gpt4.invoke(text)
        return summary

    except Exception as e:
        # 降级到GPT-3.5
        try:
            logger.warning("GPT-4 failed, falling back to GPT-3.5")
            summary = llm_gpt35.invoke(text)
            return summary

        except Exception as e2:
            # 降级到简单摘要
            logger.warning("GPT-3.5 failed, using simple summary")
            summary = simple_summary(text)
            return summary
```

---

### 2. 部分成功处理

```python
@app.task(bind=True)
def process_documents(self, files: List[str]):
    """批量处理文档（部分成功）"""
    results = {
        "success": [],
        "failed": []
    }

    for file in files:
        try:
            result = process_file(file)
            results["success"].append({
                "file": file,
                "result": result
            })

        except Exception as e:
            # 记录失败，继续处理其他文件
            logger.error(f"Failed to process {file}: {e}")
            results["failed"].append({
                "file": file,
                "error": str(e)
            })

    return results
```

---

## 最佳实践

### 1. 幂等性设计

```python
@app.task
def update_user_status(user_id: int, status: str):
    """幂等任务：多次执行结果相同"""
    user = get_user(user_id)

    # 检查状态是否已经是目标状态
    if user.status == status:
        return {"status": "already_updated"}

    # 更新状态
    user.status = status
    save_user(user)

    return {"status": "updated"}
```

---

### 2. 事务性操作

```python
@app.task
def transfer_money(from_user_id: int, to_user_id: int, amount: float):
    """事务性任务"""
    db = SessionLocal()

    try:
        # 开始事务
        from_user = db.query(User).filter(User.id == from_user_id).with_for_update().first()
        to_user = db.query(User).filter(User.id == to_user_id).with_for_update().first()

        # 检查余额
        if from_user.balance < amount:
            raise InsufficientBalanceError()

        # 转账
        from_user.balance -= amount
        to_user.balance += amount

        # 提交事务
        db.commit()

        return {"status": "success"}

    except Exception as e:
        # 回滚事务
        db.rollback()
        raise

    finally:
        db.close()
```

---

### 3. 监控指标

```python
from prometheus_client import Counter, Histogram

# 定义指标
task_total = Counter('task_total', 'Total tasks', ['task_type', 'status'])
task_duration = Histogram('task_duration_seconds', 'Task duration', ['task_type'])

@app.task(bind=True)
def process_document(self, file_path: str):
    start_time = time.time()

    try:
        result = parse_and_embed(file_path)

        # 记录成功指标
        task_total.labels(task_type='document_process', status='success').inc()

        return result

    except Exception as e:
        # 记录失败指标
        task_total.labels(task_type='document_process', status='failed').inc()
        raise

    finally:
        # 记录执行时间
        duration = time.time() - start_time
        task_duration.labels(task_type='document_process').observe(duration)
```

---

## 总结

### 错误处理核心要点

1. **错误分类**：临时性失败（重试）vs 永久性失败（不重试）
2. **重试策略**：指数退避（60秒、120秒、240秒...）
3. **超时控制**：软超时（可捕获）+ 硬超时（强制终止）
4. **死信队列**：存储最终失败的任务
5. **优雅降级**：降级到备用方案

### 实现检查清单

- [ ] 实现错误分类（临时性 vs 永久性）
- [ ] 配置重试策略（指数退避）
- [ ] 设置任务超时（软超时 + 硬超时）
- [ ] 实现死信队列（存储失败任务）
- [ ] 实现错误日志（结构化日志）
- [ ] 实现告警机制（Slack/邮件）
- [ ] 实现优雅降级（备用方案）
- [ ] 确保幂等性（多次执行结果相同）

---

**记住**：错误处理不是为了避免失败，而是为了在失败时能够优雅地恢复或降级。
