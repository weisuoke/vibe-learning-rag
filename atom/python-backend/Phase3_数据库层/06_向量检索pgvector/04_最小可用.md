# 最小可用

掌握以下内容，就能开始使用 pgvector 构建基础的向量检索系统：

## 4.1 安装和启用 pgvector 扩展

**核心知识：**
pgvector 是 PostgreSQL 的扩展，需要先安装再启用。

```bash
# 1. 安装 pgvector（macOS）
brew install pgvector

# 2. 安装 pgvector（Ubuntu/Debian）
sudo apt install postgresql-15-pgvector

# 3. 安装 pgvector（Docker）
docker run -d \
  --name postgres-pgvector \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 \
  pgvector/pgvector:pg16
```

```sql
-- 4. 在数据库中启用扩展
CREATE EXTENSION IF NOT EXISTS vector;

-- 5. 验证安装
SELECT * FROM pg_extension WHERE extname = 'vector';
```

**在 AI Agent 开发中：**
- 使用 Docker 镜像最简单，开发环境快速启动
- 生产环境建议使用包管理器安装，便于版本管理

---

## 4.2 创建向量表和插入数据

**核心知识：**
使用 `vector(N)` 类型存储 N 维向量，N 必须与 Embedding 模型的维度一致。

```python
import psycopg2
from openai import OpenAI

# 连接数据库
conn = psycopg2.connect(
    host="localhost",
    database="mydb",
    user="postgres",
    password="password"
)
cursor = conn.cursor()

# 1. 创建向量表
cursor.execute("""
    CREATE TABLE IF NOT EXISTS documents (
        id SERIAL PRIMARY KEY,
        content TEXT NOT NULL,
        embedding vector(1536),  -- OpenAI text-embedding-3-small 的维度
        metadata JSONB,
        created_at TIMESTAMP DEFAULT NOW()
    )
""")
conn.commit()

# 2. 生成 Embedding
client = OpenAI()
text = "什么是向量数据库？"
embedding = client.embeddings.create(
    input=text,
    model="text-embedding-3-small"
).data[0].embedding

# 3. 插入向量数据
cursor.execute(
    """
    INSERT INTO documents (content, embedding, metadata)
    VALUES (%s, %s, %s)
    """,
    (text, embedding, {"category": "tech"})
)
conn.commit()

print(f"✅ 插入成功，向量维度: {len(embedding)}")
```

**关键点：**
- `vector(1536)` 的维度必须与 Embedding 模型一致
- 使用 `%s` 占位符，psycopg2 会自动处理向量格式转换
- `metadata JSONB` 用于存储文档的元数据（分类、标签等）

---

## 4.3 执行相似度检索

**核心知识：**
使用 `<=>` 操作符进行余弦距离检索，返回最相似的 Top-K 结果。

```python
# 1. 生成查询向量
query_text = "向量数据库的应用场景"
query_embedding = client.embeddings.create(
    input=query_text,
    model="text-embedding-3-small"
).data[0].embedding

# 2. 执行相似度检索（Top-5）
cursor.execute(
    """
    SELECT
        id,
        content,
        embedding <=> %s AS distance,
        metadata
    FROM documents
    ORDER BY distance
    LIMIT 5
    """,
    (query_embedding,)
)

# 3. 获取结果
results = cursor.fetchall()
for row in results:
    doc_id, content, distance, metadata = row
    similarity = 1 - distance  # 转换为相似度（0-1）
    print(f"ID: {doc_id}")
    print(f"内容: {content}")
    print(f"相似度: {similarity:.4f}")
    print(f"元数据: {metadata}")
    print("-" * 50)
```

**距离操作符：**
- `<=>` : 余弦距离（推荐用于文本）
- `<->` : 欧氏距离（L2 距离）
- `<#>` : 内积距离（负内积）

**输出示例：**
```
ID: 1
内容: 什么是向量数据库？
相似度: 0.9234
元数据: {'category': 'tech'}
--------------------------------------------------
```

---

## 4.4 创建 HNSW 索引加速检索

**核心知识：**
无索引时，查询是 O(N) 复杂度；创建 HNSW 索引后，降到 O(log N)。

```python
# 1. 创建 HNSW 索引（推荐）
cursor.execute("""
    CREATE INDEX ON documents
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64)
""")
conn.commit()

print("✅ HNSW 索引创建成功")

# 2. 验证索引是否生效
cursor.execute("""
    EXPLAIN ANALYZE
    SELECT content, embedding <=> %s AS distance
    FROM documents
    ORDER BY distance
    LIMIT 10
""", (query_embedding,))

plan = cursor.fetchall()
for line in plan:
    print(line[0])
```

**索引参数说明：**
- `m = 16` : 每个节点的邻居数（默认 16，范围 2-100）
  - 越大：召回率越高，但内存占用越大
- `ef_construction = 64` : 构建时的搜索范围（默认 64）
  - 越大：索引质量越高，但构建时间越长

**查询时调整搜索范围：**
```python
# 增加搜索范围，提高召回率（但会增加延迟）
cursor.execute("SET hnsw.ef_search = 100")
```

**性能对比：**
```
无索引：50 万向量，查询延迟 5000ms
HNSW 索引：50 万向量，查询延迟 30ms（提升 166 倍）
```

---

## 4.5 在 FastAPI 中集成 pgvector

**核心知识：**
使用 SQLAlchemy 和依赖注入，在 FastAPI 中实现向量检索 API。

```python
from fastapi import FastAPI, Depends
from sqlalchemy import create_engine, Column, Integer, String, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import Session, sessionmaker
from pgvector.sqlalchemy import Vector
from pydantic import BaseModel
from openai import OpenAI

# 1. 数据库配置
DATABASE_URL = "postgresql://postgres:password@localhost/mydb"
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(bind=engine)
Base = declarative_base()

# 2. 定义模型
class Document(Base):
    __tablename__ = "documents"

    id = Column(Integer, primary_key=True)
    content = Column(Text, nullable=False)
    embedding = Column(Vector(1536))  # pgvector 类型

Base.metadata.create_all(engine)

# 3. FastAPI 应用
app = FastAPI()
client = OpenAI()

# 依赖注入：数据库会话
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# 4. 请求/响应模型
class SearchRequest(BaseModel):
    query: str
    top_k: int = 5

class SearchResult(BaseModel):
    id: int
    content: str
    similarity: float

# 5. 检索 API
@app.post("/search", response_model=list[SearchResult])
async def search_documents(
    request: SearchRequest,
    db: Session = Depends(get_db)
):
    # 生成查询向量
    query_embedding = client.embeddings.create(
        input=request.query,
        model="text-embedding-3-small"
    ).data[0].embedding

    # 执行向量检索
    results = db.execute(
        """
        SELECT id, content, 1 - (embedding <=> :embedding) AS similarity
        FROM documents
        ORDER BY embedding <=> :embedding
        LIMIT :limit
        """,
        {"embedding": query_embedding, "limit": request.top_k}
    ).fetchall()

    return [
        SearchResult(id=r[0], content=r[1], similarity=r[2])
        for r in results
    ]

# 运行：uvicorn main:app --reload
```

**测试 API：**
```bash
curl -X POST "http://localhost:8000/search" \
  -H "Content-Type: application/json" \
  -d '{"query": "向量数据库的应用", "top_k": 5}'
```

---

## 这些知识足以：

### ✅ 能做什么

1. **搭建基础 RAG 系统**
   - 存储文档 Embedding
   - 实现语义检索
   - 返回最相关的文档

2. **构建向量检索 API**
   - FastAPI + pgvector 集成
   - 支持 Top-K 检索
   - 返回相似度分数

3. **优化查询性能**
   - 创建 HNSW 索引
   - 查询延迟从秒级降到毫秒级

### ✅ 为后续学习打基础

- **进阶索引优化**：IVFFlat 索引、索引参数调优
- **混合检索**：向量检索 + 全文检索
- **生产级优化**：连接池、缓存、监控
- **复杂 RAG 场景**：多模态检索、ReRank、Query 改写

---

## 快速检查清单

完成以下任务，确认你已掌握最小可用知识：

- [ ] 在本地启动 PostgreSQL + pgvector
- [ ] 创建一个向量表（包含 content 和 embedding 字段）
- [ ] 使用 OpenAI API 生成 Embedding 并插入数据库
- [ ] 执行一次相似度检索，返回 Top-5 结果
- [ ] 创建 HNSW 索引，验证查询性能提升
- [ ] 在 FastAPI 中实现一个简单的检索 API

---

## 常见问题

### Q1: 向量维度不匹配怎么办？
```python
# 错误示例
embedding = [0.1, 0.2, 0.3]  # 3 维
cursor.execute("INSERT INTO documents (embedding) VALUES (%s)", (embedding,))
# 报错：expected 1536 dimensions, not 3

# 解决方案：确保维度一致
# 1. 检查 Embedding 模型的维度
# 2. 创建表时使用正确的维度：vector(1536)
```

### Q2: 查询很慢怎么办？
```python
# 1. 检查是否创建了索引
cursor.execute("SELECT * FROM pg_indexes WHERE tablename = 'documents'")

# 2. 使用 EXPLAIN ANALYZE 查看查询计划
cursor.execute("EXPLAIN ANALYZE SELECT ...")

# 3. 如果没有索引，创建 HNSW 索引
cursor.execute("CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops)")
```

### Q3: 如何批量插入向量？
```python
# 使用 executemany 批量插入
data = [
    (text1, embedding1, metadata1),
    (text2, embedding2, metadata2),
    # ...
]
cursor.executemany(
    "INSERT INTO documents (content, embedding, metadata) VALUES (%s, %s, %s)",
    data
)
conn.commit()
```

---

## 下一步学习

掌握最小可用知识后，可以深入学习：

1. **索引优化**：HNSW vs IVFFlat，参数调优
2. **混合检索**：向量检索 + 全文检索（ts_vector）
3. **生产级实践**：连接池、缓存、监控、备份
4. **复杂 RAG 场景**：多模态检索、ReRank、对话式 RAG
