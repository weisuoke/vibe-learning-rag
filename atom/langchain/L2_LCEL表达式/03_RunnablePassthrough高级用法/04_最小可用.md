# 最小可用知识

> **20%核心知识解决80%问题**

---

## 学习目标

掌握本文档后，你将能够：
- ✅ 使用 RunnablePassthrough 保持上下文
- ✅ 使用 assign 方法添加新字段
- ✅ 构建完整的 RAG 检索链
- ✅ 实现多步骤数据累积
- ✅ 处理常见的错误场景
- ✅ 理解性能特性和优化策略

**学习时长**: 45-60 分钟
**前置知识**: Runnable 接口、管道操作符 `|`、RunnableParallel

---

## 核心知识点

### 1. 直接透传（Identity 函数）

**这是最基础的用法，理解它是理解 assign 的前提！**

```python
from langchain_core.runnables import RunnablePassthrough

# 最简单的透传：原样返回输入
passthrough = RunnablePassthrough()

# 任何类型都可以透传
result1 = passthrough.invoke("hello")
print(result1)  # "hello"

result2 = passthrough.invoke({"key": "value"})
print(result2)  # {"key": "value"}

result3 = passthrough.invoke([1, 2, 3])
print(result3)  # [1, 2, 3]
```

**关键点**：
- RunnablePassthrough 就是一个 identity 函数的 Runnable 包装
- 输入什么，输出什么，不做任何转换
- 主要用于在并行链中保持原始输入

**使用场景**：
```python
# 在并行链中保持原始输入
chain = {
    "original": RunnablePassthrough(),  # 保持原始输入
    "processed": some_runnable,         # 处理后的结果
}

result = chain.invoke("input data")
# {
#     "original": "input data",  # 原始输入
#     "processed": ...           # 处理结果
# }
```

---

### 2. assign 方法（数据增强）

**这是 RunnablePassthrough 最强大的功能，必须掌握！**

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4")

# 在原有字典基础上添加新字段
chain = RunnablePassthrough.assign(
    summary=ChatPromptTemplate.from_template("总结: {text}") | model
)

# 原始输入
input_data = {
    "text": "LangChain 是一个强大的 AI 框架",
    "user": "Alice"
}

# 执行后保留所有原始字段 + 新增字段
result = chain.invoke(input_data)
print(result)
# {
#     "text": "LangChain 是一个强大的 AI 框架",  # 保留
#     "user": "Alice",                          # 保留
#     "summary": AIMessage(content="...")       # 新增
# }
```

**关键点**：
- assign 只能用于字典输入（不能用于字符串、列表等）
- 保留原有字典的所有字段
- 添加新字段（键名由你指定）
- 不会覆盖已有字段（如果键名冲突会报错）

---

### 3. 链式 assign（多步骤累积）

**逐步构建复杂的数据字典**

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4")

# 链式 assign：每一步都保留之前的所有数据
chain = (
    # 步骤1: 添加摘要
    RunnablePassthrough.assign(
        summary=ChatPromptTemplate.from_template("总结: {text}") | model
    )
    # 步骤2: 添加关键词（可以访问 text 和 summary）
    | RunnablePassthrough.assign(
        keywords=ChatPromptTemplate.from_template(
            "从以下文本提取关键词:\n{text}\n\n摘要: {summary}"
        ) | model
    )
    # 步骤3: 添加情感分析（可以访问所有之前的字段）
    | RunnablePassthrough.assign(
        sentiment=ChatPromptTemplate.from_template(
            "分析情感: {text}"
        ) | model
    )
)

result = chain.invoke({"text": "LangChain 让 AI 开发变得简单高效"})
# {
#     "text": "...",      # 原始输入
#     "summary": "...",   # 步骤1添加
#     "keywords": "...",  # 步骤2添加
#     "sentiment": "..."  # 步骤3添加
# }
```

**关键点**：
- 每一步都可以访问之前所有步骤的结果
- 数据逐步累积，不会丢失
- 便于调试和追踪数据流

---

### 4. 与 itemgetter 结合使用

**当 runnable 需要特定字段而非整个字典时**

```python
from operator import itemgetter
from langchain_core.runnables import RunnablePassthrough

# 假设 retriever 期望字符串输入，但我们的输入是字典
chain = RunnablePassthrough.assign(
    context=itemgetter("question") | retriever  # 提取 question 字段
)

result = chain.invoke({
    "question": "LangChain 是什么？",
    "user": "Alice"
})
# {
#     "question": "LangChain 是什么？",
#     "user": "Alice",
#     "context": [...]  # retriever 只接收 question 字符串
# }
```

**关键点**：
- `itemgetter("key")` 从字典中提取指定字段
- 解决类型不匹配问题（字典 vs 字符串）
- 常用于 retriever、model 等期望特定输入类型的组件

---

## 必会的4个模式

### 模式1: RAG 基础链（最常用）

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document
from operator import itemgetter
from dotenv import load_dotenv

load_dotenv()

# 1. 准备知识库
docs = [
    Document(page_content="LangChain 是一个用于构建 AI 应用的框架"),
    Document(page_content="RunnablePassthrough 用于保持上下文"),
    Document(page_content="assign 方法可以添加新字段而不丢失原始数据"),
]

vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=OpenAIEmbeddings()
)
retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# 2. 构建 RAG 链
model = ChatOpenAI(model="gpt-4")

rag_chain = (
    # 步骤1: 添加检索结果
    RunnablePassthrough.assign(
        context=itemgetter("question") | retriever
    )
    # 步骤2: 生成答案
    | RunnablePassthrough.assign(
        answer=ChatPromptTemplate.from_template(
            "根据以下上下文回答问题。如果上下文中没有相关信息，请说不知道。\n\n"
            "上下文:\n{context}\n\n"
            "问题: {question}\n\n"
            "答案:"
        ) | model
    )
)

# 3. 测试
result = rag_chain.invoke({"question": "RunnablePassthrough 的作用是什么？"})
print("问题:", result["question"])
print("上下文:", result["context"])
print("答案:", result["answer"].content)
```

**关键点**：
- 使用 `itemgetter("question")` 提取问题字符串传给 retriever
- 第一个 assign 添加 context
- 第二个 assign 添加 answer（可以访问 question 和 context）
- 最终输出包含所有中间结果，便于调试

---

### 模式2: 多步骤数据累积

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 模拟评估函数
def evaluate_answer(data: dict) -> float:
    """简单的评估函数：根据答案长度评分"""
    answer_length = len(data["answer"].content)
    if answer_length > 100:
        return 0.9
    elif answer_length > 50:
        return 0.7
    else:
        return 0.5

# 完整的处理链：问题 → 上下文 → 答案 → 评分
chain = (
    # 步骤1: 添加模拟上下文
    RunnablePassthrough.assign(
        context=RunnableLambda(lambda x: [
            "LangChain 是一个 AI 应用开发框架",
            "它提供了 LCEL 表达式语言"
        ])
    )
    # 步骤2: 生成答案
    | RunnablePassthrough.assign(
        answer=ChatPromptTemplate.from_template(
            "根据上下文回答问题\n\n上下文: {context}\n\n问题: {question}"
        ) | model
    )
    # 步骤3: 评估答案质量
    | RunnablePassthrough.assign(
        score=RunnableLambda(evaluate_answer)
    )
    # 步骤4: 格式化输出
    | RunnableLambda(lambda x: {
        "question": x["question"],
        "answer": x["answer"].content,
        "score": x["score"],
        "metadata": {
            "context_count": len(x["context"]),
            "answer_length": len(x["answer"].content)
        }
    })
)

# 测试
result = chain.invoke({"question": "LangChain 是什么？"})
print("问题:", result["question"])
print("答案:", result["answer"])
print("评分:", result["score"])
print("元数据:", result["metadata"])
```

**关键点**：
- 每一步都保留之前的所有数据
- 后续步骤可以访问所有历史数据
- 最后可以选择性地格式化输出

---

### 模式3: 并行处理 + 上下文保持

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 并行执行多个分析任务，同时保持原始输入
analysis_chain = {
    "original": RunnablePassthrough(),  # 保持原始输入
    "summary": ChatPromptTemplate.from_template(
        "用一句话总结:\n\n{text}"
    ) | model,
    "keywords": ChatPromptTemplate.from_template(
        "提取3-5个关键词:\n\n{text}"
    ) | model,
    "sentiment": ChatPromptTemplate.from_template(
        "分析情感倾向（积极/中性/消极）:\n\n{text}"
    ) | model,
}

# 测试
text = """
LangChain 是一个强大的框架，让开发者能够轻松构建 AI 应用。
它提供了丰富的组件和工具，大大简化了开发流程。
"""

result = analysis_chain.invoke({"text": text})
print("原始输入:", result["original"])
print("摘要:", result["summary"].content)
print("关键词:", result["keywords"].content)
print("情感:", result["sentiment"].content)
```

**关键点**：
- 使用字典语法创建 RunnableParallel
- `RunnablePassthrough()` 保持原始输入
- 其他分支并行执行分析任务
- 所有结果合并为一个字典

---

### 模式4: 条件处理 + 上下文保持

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 根据问题类型选择不同的处理方式
def classify_question(data: dict) -> str:
    """简单的问题分类"""
    question = data["question"].lower()
    if "是什么" in question or "what" in question:
        return "definition"
    elif "怎么" in question or "how" in question:
        return "howto"
    else:
        return "general"

# 不同类型的 prompt
prompts = {
    "definition": ChatPromptTemplate.from_template(
        "请给出 {question} 的定义"
    ),
    "howto": ChatPromptTemplate.from_template(
        "请解释如何 {question}"
    ),
    "general": ChatPromptTemplate.from_template(
        "请回答: {question}"
    ),
}

# 完整链：分类 → 选择 prompt → 生成答案
chain = (
    # 步骤1: 添加问题类型
    RunnablePassthrough.assign(
        question_type=RunnableLambda(classify_question)
    )
    # 步骤2: 根据类型生成答案
    | RunnablePassthrough.assign(
        answer=RunnableLambda(lambda x: (
            prompts[x["question_type"]] | model
        ).invoke(x))
    )
)

# 测试不同类型的问题
questions = [
    "LangChain 是什么？",
    "怎么使用 RunnablePassthrough？",
    "LCEL 的优势有哪些？"
]

for q in questions:
    result = chain.invoke({"question": q})
    print(f"问题: {result['question']}")
    print(f"类型: {result['question_type']}")
    print(f"答案: {result['answer'].content}\n")
```

**关键点**：
- 先分类问题类型
- 根据类型选择不同的处理方式
- 保留所有中间结果（问题、类型、答案）

---

## 常见错误与解决

### 错误1: assign 用于非字典输入

```python
# ❌ 错误：assign 期望字典，但收到字符串
chain = RunnablePassthrough.assign(
    new_field=some_runnable
)
chain.invoke("string input")  # 报错！

# ✅ 正确：确保输入是字典
chain = RunnablePassthrough.assign(
    new_field=some_runnable
)
chain.invoke({"key": "value"})  # ✅
```

**解决方案**：
- 如果输入不是字典，先转换为字典
- 或者使用 RunnableParallel 创建字典

```python
# 方案1: 先转换为字典
chain = (
    RunnableLambda(lambda x: {"input": x})
    | RunnablePassthrough.assign(new_field=some_runnable)
)

# 方案2: 使用 RunnableParallel
chain = {
    "input": RunnablePassthrough(),
    "new_field": some_runnable,
}
```

---

### 错误2: retriever 类型不匹配

```python
# ❌ 错误：retriever 期望字符串，但收到字典
chain = RunnablePassthrough.assign(
    context=retriever  # retriever 期望字符串
)
chain.invoke({"question": "..."})  # 报错！

# ✅ 正确：使用 itemgetter 提取字段
from operator import itemgetter

chain = RunnablePassthrough.assign(
    context=itemgetter("question") | retriever
)
chain.invoke({"question": "..."})  # ✅
```

---

### 错误3: 键名冲突

```python
# ❌ 错误：尝试覆盖已有字段
chain = RunnablePassthrough.assign(
    text="new value"  # 如果输入已有 text 字段会冲突
)
chain.invoke({"text": "old value"})  # 可能报错或产生意外行为

# ✅ 正确：使用不同的键名
chain = RunnablePassthrough.assign(
    processed_text="new value"
)
chain.invoke({"text": "old value"})  # ✅
```

---

### 错误4: 忘记保持上下文

```python
# ❌ 错误：后续步骤无法访问原始问题
chain = (
    retriever  # 只返回文档列表
    | prompt   # 无法访问原始问题
    | model
)

# ✅ 正确：使用 RunnablePassthrough 保持问题
from operator import itemgetter

chain = (
    RunnablePassthrough.assign(
        context=itemgetter("question") | retriever
    )
    | prompt  # 可以访问 question 和 context
    | model
)
```

---

## 性能特性

### 1. 直接透传：零开销

```python
import time

# 测试透传性能
passthrough = RunnablePassthrough()
large_data = {"data": "x" * 1000000}  # 1MB 数据

start = time.time()
for _ in range(1000):
    result = passthrough.invoke(large_data)
elapsed = time.time() - start

print(f"1000次透传耗时: {elapsed:.3f}秒")
# 预期: < 0.01秒（几乎零开销）
```

---

### 2. assign 的性能考虑

```python
# assign 中的 runnable 会实际执行
chain = RunnablePassthrough.assign(
    field1=expensive_operation1,  # 假设耗时 2秒
    field2=expensive_operation2,  # 假设耗时 2秒
)

# 串行执行：总时间 = 2 + 2 = 4秒
```

**优化建议**：
```python
# 如果 field1 和 field2 可以并行计算
# 使用 RunnableParallel 而非 assign

chain = (
    # 先并行计算
    RunnableParallel(
        field1=expensive_operation1,
        field2=expensive_operation2,
    )
    # 再合并到原始输入
    | RunnableLambda(lambda x: {**original_input, **x})
)

# 并行执行：总时间 = max(2, 2) = 2秒
```

---

## 快速参考

### 基础语法

```python
from langchain_core.runnables import RunnablePassthrough

# 直接透传
passthrough = RunnablePassthrough()
result = passthrough.invoke(anything)  # 返回 anything

# assign 方法
chain = RunnablePassthrough.assign(
    new_field=some_runnable
)
result = chain.invoke({"existing": "value"})
# {"existing": "value", "new_field": ...}

# 链式 assign
chain = (
    RunnablePassthrough.assign(field1=runnable1)
    | RunnablePassthrough.assign(field2=runnable2)
)

# 与 itemgetter 结合
from operator import itemgetter
chain = RunnablePassthrough.assign(
    new_field=itemgetter("key") | runnable
)
```

---

### 常用组合

```python
# RAG 模式
from operator import itemgetter

rag_chain = RunnablePassthrough.assign(
    context=itemgetter("question") | retriever
)

# 多步骤累积
chain = (
    RunnablePassthrough.assign(step1=runnable1)
    | RunnablePassthrough.assign(step2=runnable2)
    | RunnablePassthrough.assign(step3=runnable3)
)

# 并行 + 保持上下文
chain = {
    "original": RunnablePassthrough(),
    "processed": some_runnable,
}
```

---

## 学习检查清单

完成以下任务，确保你已掌握最小可用知识：

- [ ] 理解 RunnablePassthrough 的 identity 函数本质
- [ ] 使用 assign 方法添加新字段
- [ ] 实现链式 assign 逐步累积数据
- [ ] 使用 itemgetter 解决类型不匹配问题
- [ ] 构建完整的 RAG 检索链
- [ ] 实现多步骤数据累积模式
- [ ] 实现并行处理 + 上下文保持模式
- [ ] 处理常见的错误场景
- [ ] 理解性能特性和优化策略

---

## 下一步学习

掌握最小可用知识后，你可以：

1. **深入核心概念** → 学习 assign 方法原理、数据透传与增强、上下文保持机制
2. **实战代码** → 学习更复杂的 RAG 场景、复杂链构建、生产环境最佳实践
3. **第一性原理** → 理解为什么需要数据透传和上下文保持
4. **面试准备** → 学习常见面试问题和出彩回答

---

## 参考资源

**官方文档（2025-2026）**：
- [RunnablePassthrough API Reference](https://reference.langchain.com/v0.3/python/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html) - LangChain 0.3+ 官方文档
- [LCEL Primitives](https://reference.langchain.com/python/langchain_core/runnables) - LCEL 核心原语

**2025-2026 最佳实践**：
- [Building Production-Ready AI Pipelines with LangChain Runnables](https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557) - 生产级 AI 管道构建
- [LangChain Best Practices](https://www.swarnendu.de/blog/langchain-best-practices) - 2025 最佳实践指南
- [Master LangChain in 2025: From RAG to Tools](https://towardsai.net/p/machine-learning/master-langchain-in-2025-from-rag-to-tools-complete-guide) - 2025 完整指南

**实战教程（2025-2026）**：
- [LangChain vs LangGraph 2026 — Technical Decision Guide](https://myengineeringpath.dev/tools/langchain-vs-langgraph) - 2026 技术决策指南
- [RunnablePassthrough.assign() for Data Enrichment](https://www.linkedin.com/posts/abhishek-rath-48498942_langchain-llm-ai-activity-7404830349609992192-U4uu) - assign 方法深度解析

---

**版本**: v1.0
**最后更新**: 2026-02-19
**适用**: LangChain 0.3+, Python 3.13+
