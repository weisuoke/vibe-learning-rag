# 化骨绵掌：链式调试与日志

## 什么是化骨绵掌？

**化骨绵掌**是指将复杂的知识点拆解成独立的、可快速掌握的知识卡片。

每个卡片包含：
- 一句话总结
- 代码示例
- 关键点
- 应用场景

**目标**：2分钟掌握一个知识点。

---

## 卡片1：astream_events基础使用

### 一句话总结

使用 `astream_events(version="v2")` 实时查看链的执行过程。

### 代码示例

```python
async for event in chain.astream_events(input, version="v2"):
    print(f"{event['event']}: {event['name']}")
```

### 关键点

- 必须指定 `version="v2"`
- 返回异步迭代器
- 每个事件包含 `event`, `name`, `data`
- 有10-20%性能开销

### 应用场景

- 开发阶段调试
- 理解链的执行流程
- 查看中间结果
- 定位问题

---

## 卡片2：实时查看LLM输出

### 一句话总结

监听 `on_chat_model_stream` 事件实时查看LLM生成的内容。

### 代码示例

```python
async for event in chain.astream_events(input, version="v2"):
    if event["event"] == "on_chat_model_stream":
        chunk = event["data"]["chunk"]
        print(chunk.content, end="", flush=True)
```

### 关键点

- 流式输出，逐token显示
- 使用 `end=""` 避免换行
- 使用 `flush=True` 立即显示
- 适合长文本生成

### 应用场景

- 实时显示生成进度
- 提升用户体验
- 调试生成内容
- 流式API

---

## 卡片3：事件过滤

### 一句话总结

使用 `include_types` 只查看特定类型的事件，减少噪音。

### 代码示例

```python
async for event in chain.astream_events(
    input,
    version="v2",
    include_types=["chat_model"]  # 只看LLM事件
):
    print(event)
```

### 关键点

- `include_types`: 包含特定类型
- `exclude_types`: 排除特定类型
- `include_names`: 包含特定名称
- 可以组合使用

### 应用场景

- 聚焦关键事件
- 减少日志噪音
- 提高调试效率
- 性能优化

---

## 卡片4：自定义回调处理器

### 一句话总结

继承 `BaseCallbackHandler` 实现自定义日志记录。

### 代码示例

```python
from langchain_core.callbacks import BaseCallbackHandler

class MyLogHandler(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        logger.info(f"Started: {inputs}")
    
    def on_chain_end(self, outputs, **kwargs):
        logger.info(f"Completed: {outputs}")

chain.invoke(input, config={"callbacks": [MyLogHandler()]})
```

### 关键点

- 继承 `BaseCallbackHandler`
- 实现需要的回调方法
- 通过 `config` 传入
- 可以组合多个处理器

### 应用场景

- 记录到文件
- 记录到数据库
- 性能追踪
- 错误处理

---

## 卡片5：异步回调处理器

### 一句话总结

使用 `AsyncCallbackHandler` 避免阻塞链执行。

### 代码示例

```python
from langchain_core.callbacks import AsyncCallbackHandler

class AsyncLogHandler(AsyncCallbackHandler):
    async def on_chain_start(self, serialized, inputs, **kwargs):
        await self._write_to_database(inputs)

result = await chain.ainvoke(
    input,
    config={"callbacks": [AsyncLogHandler()]}
)
```

### 关键点

- 继承 `AsyncCallbackHandler`
- 方法使用 `async`
- 使用 `ainvoke()` 而不是 `invoke()`
- 不会阻塞链执行

### 应用场景

- 慢速IO操作
- 数据库写入
- 网络请求
- 生产环境

---

## 卡片6：LangSmith零代码集成

### 一句话总结

通过环境变量配置LangSmith，自动追踪所有链执行。

### 代码示例

```python
# .env 文件
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_key
LANGCHAIN_PROJECT=my_project

# 代码无需修改
from dotenv import load_dotenv
load_dotenv()

result = chain.invoke(input)  # 自动追踪
```

### 关键点

- 零代码集成
- 自动追踪所有链
- 可视化仪表板
- 成本追踪

### 应用场景

- 快速上手
- 生产监控
- 成本分析
- 性能优化

---

## 卡片7：OpenTelemetry基础追踪

### 一句话总结

使用OpenTelemetry Span追踪链执行，导出到监控系统。

### 代码示例

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

with tracer.start_as_current_span("my_chain") as span:
    span.set_attribute("question", question)
    result = chain.invoke({"question": question})
    span.set_attribute("response_length", len(result.content))
```

### 关键点

- 创建span追踪
- 设置属性记录信息
- 支持多层级span
- 导出到监控系统

### 应用场景

- 分布式追踪
- 自建监控系统
- 数据自主控制
- 多语言集成

---

## 卡片8：采样策略

### 一句话总结

只追踪部分请求，平衡成本和可观测性。

### 代码示例

```python
import random

def should_trace(error=None, duration=None):
    # 总是追踪错误
    if error:
        return True
    # 总是追踪慢请求
    if duration and duration > 5.0:
        return True
    # 随机采样10%
    return random.random() < 0.1

if should_trace(error, duration):
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
```

### 关键点

- 错误请求100%追踪
- 慢请求100%追踪
- 正常请求1-10%采样
- 动态调整采样率

### 应用场景

- 生产环境
- 成本控制
- 高流量系统
- 性能优化

---

## 卡片9：性能追踪

### 一句话总结

使用回调处理器追踪延迟和Token使用。

### 代码示例

```python
class PerformanceHandler(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        self.start_time = time.time()
    
    def on_chain_end(self, outputs, **kwargs):
        duration = time.time() - self.start_time
        logger.info(f"Duration: {duration:.2f}s")
    
    def on_llm_end(self, response, **kwargs):
        tokens = response.llm_output.get("token_usage", {})
        logger.info(f"Tokens: {tokens}")
```

### 关键点

- 记录开始时间
- 计算执行时长
- 统计Token使用
- 计算成本

### 应用场景

- 性能监控
- 成本追踪
- 瓶颈分析
- 优化决策

---

## 卡片10：错误处理和分类

### 一句话总结

捕获和分类错误，方便后续分析和告警。

### 代码示例

```python
class ErrorHandler(BaseCallbackHandler):
    def on_chain_error(self, error, **kwargs):
        error_str = str(error).lower()
        
        if "rate limit" in error_str:
            category = "rate_limit"
            logger.warning("⚠️ Rate limit reached!")
        elif "timeout" in error_str:
            category = "timeout"
        elif "authentication" in error_str:
            category = "auth"
        else:
            category = "unknown"
        
        self.errors.append({
            "category": category,
            "error": str(error)
        })
```

### 关键点

- 分类错误类型
- 记录错误信息
- 触发告警
- 统计错误率

### 应用场景

- 错误监控
- 告警通知
- 问题排查
- 系统优化

---

## 卡片11：RAG链调试

### 一句话总结

监听 `on_retriever_end` 查看检索结果。

### 代码示例

```python
async for event in rag_chain.astream_events(query, version="v2"):
    if event["event"] == "on_retriever_end":
        docs = event["data"]["output"]
        print(f"Retrieved {len(docs)} documents:")
        for doc in docs:
            print(f"- {doc.page_content[:80]}")
```

### 关键点

- 查看检索查询
- 查看检索结果
- 检查文档相关性
- 验证检索质量

### 应用场景

- RAG调试
- 检索优化
- 质量评估
- 问题定位

---

## 卡片12：告警规则

### 一句话总结

设置关键指标的阈值，自动触发告警。

### 代码示例

```python
@dataclass
class AlertRule:
    name: str
    condition: Callable
    message: str
    severity: str

# 高延迟告警
AlertRule(
    name="high_latency",
    condition=lambda m: m["p95_latency"] > 5.0,
    message="P95 latency > 5s",
    severity="warning"
)

# 错误率告警
AlertRule(
    name="high_error_rate",
    condition=lambda m: m["error_rate"] > 0.01,
    message="Error rate > 1%",
    severity="error"
)
```

### 关键点

- 定义告警规则
- 设置阈值
- 告警分级
- 冷却时间

### 应用场景

- 生产监控
- 及时发现问题
- 自动通知
- 系统稳定性

---

## 卡片13：数据脱敏

### 一句话总结

在日志中过滤敏感信息，保护用户隐私。

### 代码示例

```python
import re

def sanitize_data(data):
    if isinstance(data, str):
        # 脱敏邮箱
        data = re.sub(r'\b[\w.-]+@[\w.-]+\.\w+\b', '***@***.***', data)
        # 脱敏手机号
        data = re.sub(r'\b\d{11}\b', '***********', data)
    elif isinstance(data, dict):
        # 脱敏敏感字段
        for key in ['password', 'token', 'api_key']:
            if key in data:
                data[key] = '***'
    return data
```

### 关键点

- 识别敏感信息
- 正则表达式匹配
- 替换为占位符
- 保护用户隐私

### 应用场景

- 生产日志
- 合规要求
- 隐私保护
- 安全审计

---

## 卡片14：分层监控

### 一句话总结

不同环境使用不同的监控策略。

### 代码示例

```python
# 开发环境：详细调试
if env == "development":
    async for event in chain.astream_events(input, version="v2"):
        print(event)

# 集成环境：自定义日志
elif env == "staging":
    chain.invoke(input, config={"callbacks": [LogHandler()]})

# 生产环境：采样监控
elif env == "production":
    if random.random() < 0.01:  # 1%采样
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
```

### 关键点

- 开发：100%详细
- 集成：10-50%采样
- 生产：1-10%采样
- 动态调整

### 应用场景

- 环境隔离
- 成本控制
- 性能优化
- 灵活监控

---

## 卡片15：Metrics收集

### 一句话总结

使用OpenTelemetry收集量化的性能指标。

### 代码示例

```python
from opentelemetry import metrics

meter = metrics.get_meter(__name__)

# 计数器
request_counter = meter.create_counter("requests_total")

# 直方图
latency_histogram = meter.create_histogram("latency_ms")

# 使用
request_counter.add(1, {"status": "success"})
latency_histogram.record(duration_ms)
```

### 关键点

- Counter：累计计数
- Histogram：分布统计
- Gauge：瞬时值
- 导出到监控系统

### 应用场景

- 性能监控
- 趋势分析
- 容量规划
- SLA监控

---

## 快速查询表

### 调试工具选择

| 阶段 | 工具 | 命令 |
|------|------|------|
| 开发 | astream_events | `astream_events(input, version="v2")` |
| 集成 | BaseCallbackHandler | `config={"callbacks": [handler]}` |
| 生产 | LangSmith | `LANGCHAIN_TRACING_V2=true` |

---

### 事件类型速查

| 事件 | 触发时机 | 数据 |
|------|----------|------|
| `on_chain_start` | 链开始 | `input` |
| `on_chat_model_stream` | LLM流式输出 | `chunk` |
| `on_retriever_end` | 检索完成 | `documents` |
| `on_chain_error` | 链出错 | `error` |

---

### 回调方法速查

| 方法 | 触发时机 | 参数 |
|------|----------|------|
| `on_chain_start` | 链开始 | `inputs` |
| `on_chain_end` | 链结束 | `outputs` |
| `on_llm_end` | LLM结束 | `response` |
| `on_chain_error` | 链出错 | `error` |

---

### 采样率建议

| 环境 | 正常请求 | 错误请求 | 慢请求 |
|------|----------|----------|--------|
| 开发 | 100% | 100% | 100% |
| 预发布 | 10-20% | 100% | 100% |
| 生产 | 1-5% | 100% | 100% |

---

### 告警阈值建议

| 指标 | 阈值 | 级别 |
|------|------|------|
| P95延迟 | >5s | Warning |
| P99延迟 | >10s | Error |
| 错误率 | >1% | Error |
| 成本 | 超预算20% | Warning |

---

## 学习路径

### 第一天：基础调试

1. 学习 `astream_events()` 基础使用
2. 实践事件过滤
3. 调试简单链

---

### 第二天：自定义日志

1. 学习 `BaseCallbackHandler`
2. 实现文件日志处理器
3. 实现性能追踪处理器

---

### 第三天：生产监控

1. 配置LangSmith
2. 学习OpenTelemetry
3. 实施采样策略

---

### 第四天：高级技巧

1. 错误处理和分类
2. 数据脱敏
3. 告警规则

---

## 最后的话

**化骨绵掌的精髓**：

1. 每个知识点独立完整
2. 2分钟快速掌握
3. 代码示例可运行
4. 立即应用到实践

**记住**：不要试图一次学完所有内容，每天掌握2-3个卡片，持续积累。

---

**版本信息**
- LangChain: v0.3+ (2025-2026)
- Python: 3.13+
- 最后更新: 2026-02-20
