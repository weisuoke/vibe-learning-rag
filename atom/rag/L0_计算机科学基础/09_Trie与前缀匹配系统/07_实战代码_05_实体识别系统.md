# 实体识别系统

## 完整可运行代码

```python
"""
基于 Trie 的实体识别系统（NER）
演示：最长匹配、实体类型识别、RAG 应用
"""

from typing import List, Dict, Tuple, Optional


class TrieNode:
    """Trie 节点"""
    def __init__(self):
        self.children = {}
        self.is_end = False
        self.entity_type = None  # 实体类型
        self.metadata = None     # 实体元数据


class EntityRecognizer:
    """实体识别器"""

    def __init__(self):
        self.trie = TrieNode()
        self.entities = {}  # entity -> metadata

    def add_entity(self, entity: str, entity_type: str, metadata: Dict = None):
        """
        添加实体到词典

        Args:
            entity: 实体文本
            entity_type: 实体类型（PER/LOC/ORG等）
            metadata: 实体元数据
        """
        self.entities[entity] = {
            "type": entity_type,
            "metadata": metadata or {}
        }

        # 插入到 Trie
        node = self.trie
        for char in entity:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end = True
        node.entity_type = entity_type
        node.metadata = metadata

    def recognize(self, text: str) -> List[Dict]:
        """
        识别文本中的实体（最长匹配）

        Returns:
            List of entities: [{"text": str, "type": str, "start": int, "end": int}, ...]
        """
        entities = []
        i = 0

        while i < len(text):
            # 尝试最长匹配
            max_len = 0
            max_entity = None
            max_type = None
            max_metadata = None

            for j in range(i + 1, len(text) + 1):
                substring = text[i:j]
                node = self._get_node(substring)
                if node and node.is_end:
                    max_len = j - i
                    max_entity = substring
                    max_type = node.entity_type
                    max_metadata = node.metadata

            if max_entity:
                entities.append({
                    "text": max_entity,
                    "type": max_type,
                    "start": i,
                    "end": i + max_len,
                    "metadata": max_metadata
                })
                i += max_len
            else:
                i += 1

        return entities

    def recognize_all_matches(self, text: str) -> List[Dict]:
        """
        识别所有可能的匹配（包括重叠）

        Returns:
            List of all possible entities
        """
        entities = []

        for i in range(len(text)):
            for j in range(i + 1, len(text) + 1):
                substring = text[i:j]
                node = self._get_node(substring)
                if node and node.is_end:
                    entities.append({
                        "text": substring,
                        "type": node.entity_type,
                        "start": i,
                        "end": j,
                        "metadata": node.metadata
                    })

        return entities

    def _get_node(self, text: str) -> Optional[TrieNode]:
        """获取文本对应的节点"""
        node = self.trie
        for char in text:
            if char not in node.children:
                return None
            node = node.children[char]
        return node

    def get_entity_info(self, entity: str) -> Optional[Dict]:
        """获取实体信息"""
        return self.entities.get(entity)


class RAGEntityRecognizer:
    """RAG 实体识别器"""

    def __init__(self):
        self.recognizer = EntityRecognizer()

    def add_entities_from_documents(self, documents: List[Dict]):
        """从文档中提取实体"""
        for doc in documents:
            # 简化：假设文档包含实体列表
            if "entities" in doc:
                for entity_info in doc["entities"]:
                    self.recognizer.add_entity(
                        entity_info["text"],
                        entity_info["type"],
                        {"doc_id": doc.get("id"), **entity_info.get("metadata", {})}
                    )

    def enhance_query(self, query: str) -> Dict:
        """
        增强查询（识别实体）

        Returns:
            Enhanced query with entities
        """
        entities = self.recognizer.recognize(query)

        # 按类型分组
        entity_types = {}
        for entity in entities:
            entity_type = entity["type"]
            if entity_type not in entity_types:
                entity_types[entity_type] = []
            entity_types[entity_type].append(entity["text"])

        return {
            "original_query": query,
            "entities": entities,
            "entity_types": entity_types,
            "entity_count": len(entities)
        }

    def filter_documents_by_entities(self, query: str, documents: List[Dict]) -> List[Dict]:
        """根据实体过滤文档"""
        # 识别查询中的实体
        query_entities = self.recognizer.recognize(query)
        query_entity_texts = {e["text"] for e in query_entities}

        # 过滤文档
        filtered_docs = []
        for doc in documents:
            doc_entities = doc.get("entities", [])
            doc_entity_texts = {e["text"] for e in doc_entities}

            # 计算实体重叠度
            overlap = len(query_entity_texts & doc_entity_texts)
            if overlap > 0:
                filtered_docs.append({
                    **doc,
                    "entity_overlap": overlap
                })

        # 按重叠度排序
        filtered_docs.sort(key=lambda x: x["entity_overlap"], reverse=True)
        return filtered_docs


# ===== 测试代码 =====
if __name__ == "__main__":
    print("=" * 60)
    print("实体识别系统测试")
    print("=" * 60)

    # ===== 1. 基础实体识别 =====
    print("\n【1. 基础实体识别】")
    recognizer = EntityRecognizer()

    # 添加实体
    entities = [
        ("北京大学", "ORG", {"full_name": "北京大学", "type": "university"}),
        ("北京", "LOC", {"province": "北京市"}),
        ("清华大学", "ORG", {"full_name": "清华大学", "type": "university"}),
        ("张三", "PER", {"role": "student"}),
        ("李四", "PER", {"role": "teacher"}),
        ("Python", "TECH", {"category": "programming_language"}),
        ("机器学习", "TECH", {"category": "ai"}),
    ]

    for entity, entity_type, metadata in entities:
        recognizer.add_entity(entity, entity_type, metadata)

    print(f"添加 {len(entities)} 个实体")

    # 测试识别
    test_texts = [
        "张三在北京大学学习机器学习",
        "李四在清华大学教Python",
        "北京有很多大学",
    ]

    for text in test_texts:
        print(f"\n文本: {text}")
        entities = recognizer.recognize(text)
        for entity in entities:
            print(f"  - {entity['text']} ({entity['type']}): {entity['start']}-{entity['end']}")

    # ===== 2. 最长匹配测试 =====
    print("\n【2. 最长匹配测试】")
    recognizer2 = EntityRecognizer()
    recognizer2.add_entity("北京", "LOC")
    recognizer2.add_entity("北京大学", "ORG")
    recognizer2.add_entity("北京师范大学", "ORG")

    text = "我在北京大学读书"
    print(f"\n文本: {text}")
    print("实体词典: 北京, 北京大学, 北京师范大学")

    entities = recognizer2.recognize(text)
    print("\n最长匹配结果:")
    for entity in entities:
        print(f"  - {entity['text']} ({entity['type']})")

    # ===== 3. 所有匹配测试 =====
    print("\n【3. 所有匹配测试（包括重叠）】")
    all_entities = recognizer2.recognize_all_matches(text)
    print("\n所有可能的匹配:")
    for entity in all_entities:
        print(f"  - {entity['text']} ({entity['type']}): {entity['start']}-{entity['end']}")

    # ===== 4. RAG 应用场景 =====
    print("\n【4. RAG 应用场景】")
    rag_recognizer = RAGEntityRecognizer()

    # 模拟文档库
    documents = [
        {
            "id": 1,
            "content": "Python 是一种编程语言",
            "entities": [
                {"text": "Python", "type": "TECH"}
            ]
        },
        {
            "id": 2,
            "content": "机器学习是人工智能的一个分支",
            "entities": [
                {"text": "机器学习", "type": "TECH"},
                {"text": "人工智能", "type": "TECH"}
            ]
        },
        {
            "id": 3,
            "content": "北京大学是中国的顶尖大学",
            "entities": [
                {"text": "北京大学", "type": "ORG"},
                {"text": "中国", "type": "LOC"}
            ]
        }
    ]

    # 从文档中提取实体
    rag_recognizer.add_entities_from_documents(documents)

    # 增强查询
    query = "如何在Python中实现机器学习？"
    print(f"\n查询: {query}")

    enhanced = rag_recognizer.enhance_query(query)
    print("\n增强后的查询:")
    print(f"  原始查询: {enhanced['original_query']}")
    print(f"  识别实体: {enhanced['entities']}")
    print(f"  实体类型: {enhanced['entity_types']}")

    # 根据实体过滤文档
    print("\n根据实体过滤文档:")
    filtered = rag_recognizer.filter_documents_by_entities(query, documents)
    for doc in filtered:
        print(f"  文档 {doc['id']}: 实体重叠度 {doc['entity_overlap']}")

    # ===== 5. 实体元数据测试 =====
    print("\n【5. 实体元数据测试】")
    text = "张三在北京大学学习Python"
    entities = recognizer.recognize(text)

    print(f"\n文本: {text}")
    print("\n识别的实体及元数据:")
    for entity in entities:
        print(f"\n  实体: {entity['text']}")
        print(f"  类型: {entity['type']}")
        if entity['metadata']:
            print(f"  元数据: {entity['metadata']}")

    # ===== 6. 实体类型统计 =====
    print("\n【6. 实体类型统计】")
    text = "张三和李四在北京大学和清华大学学习Python和机器学习"
    entities = recognizer.recognize(text)

    print(f"\n文本: {text}")

    # 统计实体类型
    from collections import Counter
    entity_types = Counter([e['type'] for e in entities])

    print("\n实体类型统计:")
    for entity_type, count in entity_types.items():
        print(f"  {entity_type}: {count}")

    # ===== 7. 性能测试 =====
    print("\n【7. 性能测试】")
    import time

    # 大规模实体词典
    large_recognizer = EntityRecognizer()
    print("构建大规模实体词典（10,000 个实体）...")
    start = time.time()
    for i in range(10000):
        large_recognizer.add_entity(f"实体{i}", "TEST")
    build_time = time.time() - start
    print(f"构建时间: {build_time:.3f}s")

    # 识别性能
    test_text = "这是一段包含实体1000和实体2000的测试文本"
    print(f"\n测试文本: {test_text}")

    start = time.time()
    for _ in range(1000):
        large_recognizer.recognize(test_text)
    recognize_time = time.time() - start
    print(f"1,000 次识别: {recognize_time:.3f}s")
    print(f"平均每次识别: {recognize_time / 1000 * 1000:.3f}ms")

    # ===== 8. 实际应用：知识图谱实体链接 =====
    print("\n【8. 实际应用：知识图谱实体链接】")

    # 构建知识图谱实体
    kg_recognizer = EntityRecognizer()
    kg_entities = [
        ("北京大学", "ORG", {
            "id": "Q1",
            "relations": [("位于", "北京"), ("类型", "大学")]
        }),
        ("清华大学", "ORG", {
            "id": "Q2",
            "relations": [("位于", "北京"), ("类型", "大学")]
        }),
        ("北京", "LOC", {
            "id": "Q3",
            "relations": [("国家", "中国")]
        }),
    ]

    for entity, entity_type, metadata in kg_entities:
        kg_recognizer.add_entity(entity, entity_type, metadata)

    # 实体链接
    text = "北京大学和清华大学都位于北京"
    print(f"\n文本: {text}")

    entities = kg_recognizer.recognize(text)
    print("\n实体链接结果:")
    for entity in entities:
        print(f"\n  实体: {entity['text']}")
        print(f"  类型: {entity['type']}")
        print(f"  知识图谱ID: {entity['metadata']['id']}")
        print(f"  关系: {entity['metadata']['relations']}")

    # ===== 9. 边界情况测试 =====
    print("\n【9. 边界情况测试】")

    # 空文本
    print("\n空文本:")
    print(f"  recognize(''): {recognizer.recognize('')}")

    # 无匹配实体
    print("\n无匹配实体:")
    print(f"  recognize('这是一段没有实体的文本'): {recognizer.recognize('这是一段没有实体的文本')}")

    # 连续实体
    text = "张三李四"
    print(f"\n连续实体: {text}")
    entities = recognizer.recognize(text)
    print(f"  识别结果: {[e['text'] for e in entities]}")

    # 重叠实体
    recognizer3 = EntityRecognizer()
    recognizer3.add_entity("机器", "TECH")
    recognizer3.add_entity("机器学习", "TECH")
    recognizer3.add_entity("学习", "TECH")

    text = "机器学习"
    print(f"\n重叠实体: {text}")
    print(f"  实体词典: 机器, 机器学习, 学习")
    entities = recognizer3.recognize(text)
    print(f"  最长匹配: {[e['text'] for e in entities]}")
    all_entities = recognizer3.recognize_all_matches(text)
    print(f"  所有匹配: {[e['text'] for e in all_entities]}")

    # ===== 10. 与 RAG 检索集成 =====
    print("\n【10. 与 RAG 检索集成】")

    # 模拟 RAG 检索流程
    print("\n场景：用户查询 → 实体识别 → 增强检索")

    query = "北京大学的机器学习课程"
    print(f"\n1. 用户查询: {query}")

    # 识别实体
    entities = recognizer.recognize(query)
    print(f"\n2. 识别实体: {[e['text'] for e in entities]}")

    # 构建增强查询
    entity_texts = [e['text'] for e in entities]
    enhanced_query = f"{query} (实体: {', '.join(entity_texts)})"
    print(f"\n3. 增强查询: {enhanced_query}")

    # 模拟检索
    print("\n4. 检索结果（根据实体过滤）:")
    print("  - 文档1: 北京大学机器学习课程介绍 (匹配实体: 北京大学, 机器学习)")
    print("  - 文档2: 机器学习基础教程 (匹配实体: 机器学习)")

    print("\n" + "=" * 60)
    print("测试完成")
    print("=" * 60)
```

## 预期输出

```
============================================================
实体识别系统测试
============================================================

【1. 基础实体识别】
添加 7 个实体

文本: 张三在北京大学学习机器学习
  - 张三 (PER): 0-2
  - 北京大学 (ORG): 3-7
  - 机器学习 (TECH): 9-13

文本: 李四在清华大学教Python
  - 李四 (PER): 0-2
  - 清华大学 (ORG): 3-7
  - Python (TECH): 8-14

文本: 北京有很多大学
  - 北京 (LOC): 0-2

【2. 最长匹配测试】

文本: 我在北京大学读书
实体词典: 北京, 北京大学, 北京师范大学

最长匹配结果:
  - 北京大学 (ORG)

【3. 所有匹配测试（包括重叠）】

所有可能的匹配:
  - 北京 (LOC): 2-4
  - 北京大学 (ORG): 2-6

【4. RAG 应用场景】

查询: 如何在Python中实现机器学习？

增强后的查询:
  原始查询: 如何在Python中实现机器学习？
  识别实体: [{'text': 'Python', 'type': 'TECH', ...}, {'text': '机器学习', 'type': 'TECH', ...}]
  实体类型: {'TECH': ['Python', '机器学习']}

根据实体过滤文档:
  文档 1: 实体重叠度 1
  文档 2: 实体重叠度 1

【5. 实体元数据测试】

文本: 张三在北京大学学习Python

识别的实体及元数据:

  实体: 张三
  类型: PER
  元数据: {'role': 'student'}

  实体: 北京大学
  类型: ORG
  元数据: {'full_name': '北京大学', 'type': 'university'}

  实体: Python
  类型: TECH
  元数据: {'category': 'programming_language'}

【6. 实体类型统计】

文本: 张三和李四在北京大学和清华大学学习Python和机器学习

实体类型统计:
  PER: 2
  ORG: 2
  TECH: 2

【7. 性能测试】
构建大规模实体词典（10,000 个实体）...
构建时间: 0.030s

测试文本: 这是一段包含实体1000和实体2000的测试文本
1,000 次识别: 0.250s
平均每次识别: 0.250ms

【8. 实际应用：知识图谱实体链接】

文本: 北京大学和清华大学都位于北京

实体链接结果:

  实体: 北京大学
  类型: ORG
  知识图谱ID: Q1
  关系: [('位于', '北京'), ('类型', '大学')]

  实体: 清华大学
  类型: ORG
  知识图谱ID: Q2
  关系: [('位于', '北京'), ('类型', '大学')]

  实体: 北京
  类型: LOC
  知识图谱ID: Q3
  关系: [('国家', '中国')]

【9. 边界情况测试】

空文本:
  recognize(''): []

无匹配实体:
  recognize('这是一段没有实体的文本'): []

连续实体: 张三李四
  识别结果: ['张三', '李四']

重叠实体: 机器学习
  实体词典: 机器, 机器学习, 学习
  最长匹配: ['机器学习']
  所有匹配: ['机器', '机器学习', '学习']

【10. 与 RAG 检索集成】

场景：用户查询 → 实体识别 → 增强检索

1. 用户查询: 北京大学的机器学习课程

2. 识别实体: ['北京大学', '机器学习']

3. 增强查询: 北京大学的机器学习课程 (实体: 北京大学, 机器学习)

4. 检索结果（根据实体过滤）:
  - 文档1: 北京大学机器学习课程介绍 (匹配实体: 北京大学, 机器学习)
  - 文档2: 机器学习基础教程 (匹配实体: 机器学习)

============================================================
测试完成
============================================================
```

## 代码说明

### 核心功能

1. **实体添加（add_entity）**
   - 支持实体类型（PER/LOC/ORG/TECH）
   - 支持元数据存储

2. **实体识别（recognize）**
   - 最长匹配算法
   - 避免重叠
   - 返回位置信息

3. **所有匹配（recognize_all_matches）**
   - 返回所有可能的匹配
   - 包括重叠实体

4. **RAG 集成（RAGEntityRecognizer）**
   - 查询增强
   - 文档过滤
   - 实体链接

### 最长匹配算法

```python
# 示例：识别 "北京大学"
# 实体词典：["北京", "北京大学"]

# 文本："我在北京大学读书"
# 位置 i=2:
#   尝试匹配 "北" → 无匹配
#   尝试匹配 "北京" → 匹配（长度 2）
#   尝试匹配 "北京大" → 无匹配
#   尝试匹配 "北京大学" → 匹配（长度 4）
#   尝试匹配 "北京大学读" → 无匹配
# 结果：选择最长匹配 "北京大学"（长度 4）
```

### 应用场景

#### 场景 1：RAG 查询增强

```python
# 用户查询："北京大学的机器学习课程"
# 识别实体：["北京大学", "机器学习"]
# 增强查询：添加实体类型信息
# 检索：优先返回包含这些实体的文档
```

#### 场景 2：知识图谱实体链接

```python
# 文本："张三在北京大学工作"
# 识别实体：["张三", "北京大学"]
# 链接到知识图谱：
#   张三 → Q1 (人物)
#   北京大学 → Q2 (机构)
# 查询关系：张三 -[工作于]-> 北京大学
```

#### 场景 3：文档标注

```python
# 文档："Python 是一种编程语言"
# 识别实体：["Python"]
# 标注类型：TECH
# 用于：文档分类、检索优化
```

### 优化策略

#### 1. AC 自动机优化

```python
# 传统 Trie：每个位置都要尝试匹配
# 时间复杂度：O(n × m)

# AC 自动机：构建失败指针
# 时间复杂度：O(n + m)
```

#### 2. 双数组 Trie

```python
# 传统 Trie：使用字典存储子节点
# 空间复杂度：O(n × m)

# 双数组 Trie：使用数组存储
# 空间复杂度：O(n)
```

#### 3. 缓存优化

```python
from functools import lru_cache

class CachedEntityRecognizer(EntityRecognizer):
    @lru_cache(maxsize=1000)
    def recognize(self, text: str) -> tuple:
        results = super().recognize(text)
        return tuple(results)  # 转为 tuple 以支持缓存
```

### 实际应用

#### 1. RAG 系统

```python
# 查询增强
query = "北京大学的AI课程"
entities = recognizer.recognize(query)
# 使用实体过滤文档
filtered_docs = filter_by_entities(entities, documents)
```

#### 2. 智能问答

```python
# 问题："张三在哪里工作？"
# 识别实体：["张三"]
# 查询知识图谱：张三 -[工作于]-> ?
# 返回答案："北京大学"
```

#### 3. 文档分类

```python
# 文档："Python 机器学习教程"
# 识别实体：["Python", "机器学习"]
# 分类：技术文档 > 编程 > Python
```

### 扩展功能

#### 1. 模糊匹配

```python
def recognize_fuzzy(self, text: str, max_distance: int = 1):
    """支持拼写错误的实体识别"""
    # 使用编辑距离算法
    pass
```

#### 2. 上下文消歧

```python
def recognize_with_context(self, text: str, context: str):
    """根据上下文消除歧义"""
    # 例如："苹果" 可能是水果或公司
    # 根据上下文判断
    pass
```

#### 3. 嵌套实体

```python
def recognize_nested(self, text: str):
    """识别嵌套实体"""
    # 例如："北京大学计算机系"
    # 识别：["北京大学", "计算机系"]
    # 关系：计算机系 属于 北京大学
    pass
```

---

**版本**: v1.0
**最后更新**: 2026-02-14
**运行环境**: Python 3.9+
**依赖**: 无（标准库）

**应用场景**:
- RAG 查询增强
- 知识图谱实体链接
- 文档自动标注
- 智能问答系统
