# 实战代码：多级缓存系统

> **构建生产级的4层缓存架构**

---

## 学习目标

- 掌握多级缓存的设计原理
- 实现 L1-L4 完整的缓存层级
- 理解缓存提升和降级策略
- 能够集成 Redis 和 PostgreSQL

---

## 完整实现

### 基础多级缓存

```python
from typing import Any, Optional
from collections import OrderedDict
import json
from pathlib import Path

class MultiLevelCache:
    """4层缓存系统"""

    def __init__(
        self,
        l1_capacity: int = 100,
        l2_capacity: int = 1000,
        l3_capacity: int = 10000,
        storage_path: str = "cache_storage"
    ):
        """
        初始化多级缓存

        Args:
            l1_capacity: L1 缓存容量
            l2_capacity: L2 缓存容量
            l3_capacity: L3 缓存容量
            storage_path: L4 持久化存储路径
        """
        # L1: 工作内存（最快，最小）
        self.l1_cache: dict[str, Any] = {}
        self.l1_capacity = l1_capacity

        # L2: 会话缓存（快，中等）
        self.l2_cache = OrderedDict()
        self.l2_capacity = l2_capacity

        # L3: 语义缓存（中等，大）
        self.l3_cache = OrderedDict()
        self.l3_capacity = l3_capacity

        # L4: 持久化存储（慢，最大）
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(exist_ok=True)

        # 统计信息
        self.stats = {
            "l1_hits": 0,
            "l2_hits": 0,
            "l3_hits": 0,
            "l4_hits": 0,
            "misses": 0
        }

    def get(self, key: str) -> Optional[Any]:
        """
        从缓存获取数据（L1 → L2 → L3 → L4）

        Args:
            key: 缓存键

        Returns:
            缓存值，如果不存在返回 None
        """
        # L1: 工作内存
        if key in self.l1_cache:
            self.stats["l1_hits"] += 1
            print(f"✅ L1 命中: {key}")
            return self.l1_cache[key]

        # L2: 会话缓存
        if key in self.l2_cache:
            self.stats["l2_hits"] += 1
            print(f"✅ L2 命中: {key}")
            value = self.l2_cache[key]
            # 提升到 L1
            self._promote_to_l1(key, value)
            return value

        # L3: 语义缓存
        if key in self.l3_cache:
            self.stats["l3_hits"] += 1
            print(f"✅ L3 命中: {key}")
            value = self.l3_cache[key]
            # 提升到 L2 和 L1
            self._promote_to_l2(key, value)
            self._promote_to_l1(key, value)
            return value

        # L4: 持久化存储
        value = self._load_from_l4(key)
        if value is not None:
            self.stats["l4_hits"] += 1
            print(f"✅ L4 命中: {key}")
            # 提升到 L3, L2, L1
            self._promote_to_l3(key, value)
            self._promote_to_l2(key, value)
            self._promote_to_l1(key, value)
            return value

        self.stats["misses"] += 1
        print(f"❌ 缓存未命中: {key}")
        return None

    def put(self, key: str, value: Any, critical: bool = False) -> None:
        """
        写入缓存

        Args:
            key: 缓存键
            value: 缓存值
            critical: 是否关键数据（立即持久化）
        """
        # L1: 总是写入工作内存
        self._promote_to_l1(key, value)

        # L2: 写入会话缓存
        self._promote_to_l2(key, value)

        # L3: 写入语义缓存
        self._promote_to_l3(key, value)

        # L4: 关键数据立即持久化
        if critical:
            self._save_to_l4(key, value)
            print(f"✅ 关键数据立即持久化: {key}")

    def _promote_to_l1(self, key: str, value: Any) -> None:
        """提升到 L1"""
        if len(self.l1_cache) >= self.l1_capacity:
            # L1 满了，删除一个（简单 FIFO）
            first_key = next(iter(self.l1_cache))
            del self.l1_cache[first_key]

        self.l1_cache[key] = value

    def _promote_to_l2(self, key: str, value: Any) -> None:
        """提升到 L2（LRU）"""
        if key in self.l2_cache:
            self.l2_cache.move_to_end(key)
        else:
            if len(self.l2_cache) >= self.l2_capacity:
                self.l2_cache.popitem(last=False)
            self.l2_cache[key] = value

    def _promote_to_l3(self, key: str, value: Any) -> None:
        """提升到 L3（LRU）"""
        if key in self.l3_cache:
            self.l3_cache.move_to_end(key)
        else:
            if len(self.l3_cache) >= self.l3_capacity:
                self.l3_cache.popitem(last=False)
            self.l3_cache[key] = value

    def _save_to_l4(self, key: str, value: Any) -> None:
        """保存到 L4（持久化）"""
        file_path = self.storage_path / f"{key}.json"
        file_path.write_text(json.dumps(value))

    def _load_from_l4(self, key: str) -> Optional[Any]:
        """从 L4 加载"""
        file_path = self.storage_path / f"{key}.json"
        if file_path.exists():
            return json.loads(file_path.read_text())
        return None

    def flush_to_l4(self) -> int:
        """批量持久化 L3 到 L4"""
        count = 0
        for key, value in self.l3_cache.items():
            self._save_to_l4(key, value)
            count += 1
        print(f"✅ 批量持久化: {count} 个键")
        return count

    def get_stats(self) -> dict:
        """获取统计信息"""
        total = sum(self.stats.values())
        return {
            **self.stats,
            "total": total,
            "l1_hit_rate": self.stats["l1_hits"] / total if total > 0 else 0,
            "l2_hit_rate": self.stats["l2_hits"] / total if total > 0 else 0,
            "l3_hit_rate": self.stats["l3_hits"] / total if total > 0 else 0,
            "l4_hit_rate": self.stats["l4_hits"] / total if total > 0 else 0,
            "overall_hit_rate": (total - self.stats["misses"]) / total if total > 0 else 0
        }

# 测试
if __name__ == "__main__":
    cache = MultiLevelCache(
        l1_capacity=3,
        l2_capacity=5,
        l3_capacity=10
    )

    # 写入数据
    cache.put("key1", "value1")
    cache.put("key2", "value2", critical=True)

    # 第一次读取：从 L1
    cache.get("key1")

    # 清空 L1，模拟缓存失效
    cache.l1_cache.clear()

    # 第二次读取：从 L2，提升到 L1
    cache.get("key1")

    # 第三次读取：从 L1
    cache.get("key1")

    # 统计
    stats = cache.get_stats()
    print(f"\n统计信息:")
    print(f"L1 命中: {stats['l1_hits']}")
    print(f"L2 命中: {stats['l2_hits']}")
    print(f"总命中率: {stats['overall_hit_rate']:.2%}")
```

---

## Redis 集成版本

```python
import redis
import json
from typing import Any, Optional
from collections import OrderedDict

class RedisMultiLevelCache:
    """集成 Redis 的多级缓存"""

    def __init__(
        self,
        redis_client: redis.Redis,
        l1_capacity: int = 100,
        l2_ttl: int = 3600
    ):
        """
        初始化

        Args:
            redis_client: Redis 客户端
            l1_capacity: L1 缓存容量
            l2_ttl: L2 缓存过期时间（秒）
        """
        # L1: 进程内缓存
        self.l1_cache: dict[str, Any] = {}
        self.l1_capacity = l1_capacity

        # L2: Redis 缓存
        self.redis = redis_client
        self.l2_ttl = l2_ttl

        # 统计
        self.stats = {"l1_hits": 0, "l2_hits": 0, "misses": 0}

    def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        # L1: 进程内缓存
        if key in self.l1_cache:
            self.stats["l1_hits"] += 1
            return self.l1_cache[key]

        # L2: Redis 缓存
        redis_value = self.redis.get(key)
        if redis_value:
            self.stats["l2_hits"] += 1
            value = json.loads(redis_value.decode())
            # 提升到 L1
            self._promote_to_l1(key, value)
            return value

        self.stats["misses"] += 1
        return None

    def put(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """写入缓存"""
        # L1: 进程内缓存
        self._promote_to_l1(key, value)

        # L2: Redis 缓存
        ttl = ttl or self.l2_ttl
        self.redis.setex(key, ttl, json.dumps(value))

    def _promote_to_l1(self, key: str, value: Any) -> None:
        """提升到 L1"""
        if len(self.l1_cache) >= self.l1_capacity:
            first_key = next(iter(self.l1_cache))
            del self.l1_cache[first_key]
        self.l1_cache[key] = value

    def delete(self, key: str) -> None:
        """删除缓存"""
        if key in self.l1_cache:
            del self.l1_cache[key]
        self.redis.delete(key)

    def clear_l1(self) -> None:
        """清空 L1 缓存"""
        self.l1_cache.clear()

# 使用示例
if __name__ == "__main__":
    redis_client = redis.Redis(host='localhost', port=6379)
    cache = RedisMultiLevelCache(redis_client, l1_capacity=100)

    # 写入
    cache.put("user_123", {"name": "Alice", "age": 25})

    # 读取（L1 命中）
    user = cache.get("user_123")
    print(user)

    # 清空 L1
    cache.clear_l1()

    # 读取（L2 命中，提升到 L1）
    user = cache.get("user_123")
    print(user)
```

---

## PostgreSQL 集成版本

```python
import psycopg2
from psycopg2.extras import Json
from typing import Any, Optional

class PostgresMultiLevelCache:
    """集成 PostgreSQL 的多级缓存"""

    def __init__(
        self,
        redis_client: redis.Redis,
        db_conn: psycopg2.extensions.connection,
        l1_capacity: int = 100
    ):
        """
        初始化

        Args:
            redis_client: Redis 客户端
            db_conn: PostgreSQL 连接
            l1_capacity: L1 缓存容量
        """
        # L1: 进程内缓存
        self.l1_cache: dict[str, Any] = {}
        self.l1_capacity = l1_capacity

        # L2: Redis 缓存
        self.redis = redis_client

        # L3: PostgreSQL 持久化
        self.db = db_conn

        # 统计
        self.stats = {"l1_hits": 0, "l2_hits": 0, "l3_hits": 0, "misses": 0}

    def get(self, key: str) -> Optional[Any]:
        """获取缓存（L1 → L2 → L3）"""
        # L1: 进程内缓存
        if key in self.l1_cache:
            self.stats["l1_hits"] += 1
            return self.l1_cache[key]

        # L2: Redis 缓存
        redis_value = self.redis.get(key)
        if redis_value:
            self.stats["l2_hits"] += 1
            value = json.loads(redis_value.decode())
            self._promote_to_l1(key, value)
            return value

        # L3: PostgreSQL
        cursor = self.db.cursor()
        cursor.execute("""
            SELECT value FROM cache_data WHERE key = %s
        """, (key,))
        result = cursor.fetchone()

        if result:
            self.stats["l3_hits"] += 1
            value = result[0]
            # 提升到 L2 和 L1
            self.redis.setex(key, 3600, json.dumps(value))
            self._promote_to_l1(key, value)
            return value

        self.stats["misses"] += 1
        return None

    def put(self, key: str, value: Any, critical: bool = False) -> None:
        """写入缓存"""
        # L1: 进程内缓存
        self._promote_to_l1(key, value)

        # L2: Redis 缓存
        self.redis.setex(key, 3600, json.dumps(value))

        # L3: 关键数据立即持久化
        if critical:
            cursor = self.db.cursor()
            cursor.execute("""
                INSERT INTO cache_data (key, value)
                VALUES (%s, %s)
                ON CONFLICT (key)
                DO UPDATE SET value = EXCLUDED.value
            """, (key, Json(value)))
            self.db.commit()

    def _promote_to_l1(self, key: str, value: Any) -> None:
        """提升到 L1"""
        if len(self.l1_cache) >= self.l1_capacity:
            first_key = next(iter(self.l1_cache))
            del self.l1_cache[first_key]
        self.l1_cache[key] = value

# 数据库表结构
"""
CREATE TABLE cache_data (
    key TEXT PRIMARY KEY,
    value JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_cache_updated ON cache_data(updated_at);
"""
```

---

## AI Agent 应用

### 对话记忆管理

```python
class ConversationMemoryCache:
    """对话记忆的多级缓存"""

    def __init__(self, cache: MultiLevelCache):
        self.cache = cache

    def add_message(self, user_id: str, role: str, content: str) -> None:
        """添加对话消息"""
        key = f"conv:{user_id}"

        # 获取现有对话
        messages = self.cache.get(key) or []

        # 添加新消息
        messages.append({"role": role, "content": content})

        # 只保留最近 100 条
        messages = messages[-100:]

        # 写入缓存
        self.cache.put(key, messages)

    def get_recent_messages(self, user_id: str, n: int = 10) -> list:
        """获取最近消息"""
        key = f"conv:{user_id}"
        messages = self.cache.get(key) or []
        return messages[-n:]

    def save_to_db(self, user_id: str) -> None:
        """保存到数据库（L4）"""
        key = f"conv:{user_id}"
        messages = self.cache.get(key) or []
        self.cache.put(key, messages, critical=True)

# 使用示例
cache = MultiLevelCache()
memory = ConversationMemoryCache(cache)

# 添加对话
memory.add_message("user_123", "user", "你好")
memory.add_message("user_123", "assistant", "你好！")

# 获取最近消息
recent = memory.get_recent_messages("user_123", n=10)
print(recent)

# 保存到数据库
memory.save_to_db("user_123")
```

---

## 性能监控

```python
import time
from dataclasses import dataclass
from typing import Dict

@dataclass
class CacheMetrics:
    """缓存指标"""
    l1_hits: int = 0
    l2_hits: int = 0
    l3_hits: int = 0
    l4_hits: int = 0
    misses: int = 0
    l1_latency: float = 0.0
    l2_latency: float = 0.0
    l3_latency: float = 0.0
    l4_latency: float = 0.0

    @property
    def total_requests(self) -> int:
        return self.l1_hits + self.l2_hits + self.l3_hits + self.l4_hits + self.misses

    @property
    def hit_rate(self) -> float:
        total = self.total_requests
        return (total - self.misses) / total if total > 0 else 0.0

    @property
    def avg_latency(self) -> float:
        """平均延迟"""
        total_latency = (
            self.l1_latency * self.l1_hits +
            self.l2_latency * self.l2_hits +
            self.l3_latency * self.l3_hits +
            self.l4_latency * self.l4_hits
        )
        total_hits = self.l1_hits + self.l2_hits + self.l3_hits + self.l4_hits
        return total_latency / total_hits if total_hits > 0 else 0.0

class MonitoredMultiLevelCache(MultiLevelCache):
    """带监控的多级缓存"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.metrics = CacheMetrics()

    def get(self, key: str) -> Optional[Any]:
        """获取缓存（记录延迟）"""
        start = time.time()

        # L1
        if key in self.l1_cache:
            self.metrics.l1_hits += 1
            self.metrics.l1_latency += time.time() - start
            return self.l1_cache[key]

        # L2
        if key in self.l2_cache:
            self.metrics.l2_hits += 1
            self.metrics.l2_latency += time.time() - start
            value = self.l2_cache[key]
            self._promote_to_l1(key, value)
            return value

        # L3
        if key in self.l3_cache:
            self.metrics.l3_hits += 1
            self.metrics.l3_latency += time.time() - start
            value = self.l3_cache[key]
            self._promote_to_l2(key, value)
            self._promote_to_l1(key, value)
            return value

        # L4
        value = self._load_from_l4(key)
        if value is not None:
            self.metrics.l4_hits += 1
            self.metrics.l4_latency += time.time() - start
            self._promote_to_l3(key, value)
            self._promote_to_l2(key, value)
            self._promote_to_l1(key, value)
            return value

        self.metrics.misses += 1
        return None

    def get_metrics(self) -> CacheMetrics:
        """获取指标"""
        return self.metrics

    def print_report(self) -> None:
        """打印报告"""
        m = self.metrics
        print(f"\n=== 缓存性能报告 ===")
        print(f"总请求: {m.total_requests}")
        print(f"命中率: {m.hit_rate:.2%}")
        print(f"平均延迟: {m.avg_latency*1000:.2f}ms")
        print(f"\n分层统计:")
        print(f"L1 命中: {m.l1_hits} ({m.l1_hits/m.total_requests:.2%})")
        print(f"L2 命中: {m.l2_hits} ({m.l2_hits/m.total_requests:.2%})")
        print(f"L3 命中: {m.l3_hits} ({m.l3_hits/m.total_requests:.2%})")
        print(f"L4 命中: {m.l4_hits} ({m.l4_hits/m.total_requests:.2%})")
        print(f"未命中: {m.misses} ({m.misses/m.total_requests:.2%})")

# 测试
cache = MonitoredMultiLevelCache(l1_capacity=10, l2_capacity=50)

# 模拟访问
for i in range(100):
    key = f"key_{i % 20}"  # 20个不同的键
    value = cache.get(key)
    if value is None:
        cache.put(key, f"value_{i}")

cache.print_report()
```

---

## 总结

### 关键要点

1. **分层设计**：L1-L4 各有特点
2. **缓存提升**：热数据向上提升
3. **智能淘汰**：每层使用合适的策略
4. **性能监控**：跟踪命中率和延迟
5. **灵活集成**：支持 Redis、PostgreSQL

### 最佳实践

- L1 用于当前请求的临时数据
- L2 用于会话级数据（Redis）
- L3 用于跨会话的热数据
- L4 用于永久存储（PostgreSQL）

---

## 参考资源

- [Redis Documentation](https://redis.io/docs/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [AI Agents 2026 Architecture](https://andriifurmanets.com/blogs/ai-agents-2026-practical-architecture-tools-memory-evals-guardrails)
