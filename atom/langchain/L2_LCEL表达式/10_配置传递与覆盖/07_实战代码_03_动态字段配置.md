# 实战代码03：动态字段配置

> **场景**: 演示configurable_fields()的使用，实现运行时动态配置LLM参数（temperature、max_tokens等）

---

## 一、完整可运行代码

```python
"""
动态字段配置示例
演示：configurable_fields()、运行时参数配置、类型安全
"""

import os
from typing import Dict, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import ConfigurableField

# 加载环境变量
load_dotenv()

# ============================================================================
# 第一部分：基础动态字段配置
# ============================================================================

def example_1_basic_configurable_field():
    """示例1：配置单个字段（temperature）"""
    print("\n" + "="*80)
    print("示例1：配置单个字段（temperature）")
    print("="*80)

    # 创建可配置的LLM
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7  # 默认值
    ).configurable_fields(
        temperature=ConfigurableField(
            id="llm_temperature",
            name="LLM Temperature",
            description="控制输出的随机性，0=确定性，1=创造性"
        )
    )

    # 创建链
    prompt = ChatPromptTemplate.from_template("Write a {style} story about {topic}")
    chain = prompt | llm | StrOutputParser()

    # 测试1：使用默认temperature（0.7）
    print("\n测试1：使用默认temperature（0.7）")
    result1 = chain.invoke({"style": "short", "topic": "AI"})
    print(f"结果: {result1[:150]}...")

    # 测试2：运行时设置temperature=0（确定性）
    print("\n测试2：运行时设置temperature=0（确定性）")
    result2 = chain.invoke(
        {"style": "short", "topic": "AI"},
        config={"configurable": {"llm_temperature": 0}}
    )
    print(f"结果: {result2[:150]}...")

    # 测试3：运行时设置temperature=1（创造性）
    print("\n测试3：运行时设置temperature=1（创造性）")
    result3 = chain.invoke(
        {"style": "short", "topic": "AI"},
        config={"configurable": {"llm_temperature": 1}}
    )
    print(f"结果: {result3[:150]}...")

    print("\n观察：不同temperature产生不同风格的输出")


# ============================================================================
# 第二部分：多个可配置字段
# ============================================================================

def example_2_multiple_configurable_fields():
    """示例2：配置多个字段"""
    print("\n" + "="*80)
    print("示例2：配置多个字段")
    print("="*80)

    # 创建可配置多个字段的LLM
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7,
        max_tokens=100
    ).configurable_fields(
        temperature=ConfigurableField(
            id="llm_temperature",
            name="Temperature",
            description="输出随机性"
        ),
        max_tokens=ConfigurableField(
            id="llm_max_tokens",
            name="Max Tokens",
            description="最大输出长度"
        )
    )

    # 创建链
    prompt = ChatPromptTemplate.from_template("Explain {concept}")
    chain = prompt | llm | StrOutputParser()

    # 测试1：默认配置
    print("\n测试1：默认配置（temperature=0.7, max_tokens=100）")
    result1 = chain.invoke({"concept": "machine learning"})
    print(f"结果长度: {len(result1)} 字符")
    print(f"结果: {result1}")

    # 测试2：低temperature + 短输出
    print("\n测试2：低temperature + 短输出（temperature=0, max_tokens=50）")
    result2 = chain.invoke(
        {"concept": "machine learning"},
        config={"configurable": {
            "llm_temperature": 0,
            "llm_max_tokens": 50
        }}
    )
    print(f"结果长度: {len(result2)} 字符")
    print(f"结果: {result2}")

    # 测试3：高temperature + 长输出
    print("\n测试3：高temperature + 长输出（temperature=1, max_tokens=200）")
    result3 = chain.invoke(
        {"concept": "machine learning"},
        config={"configurable": {
            "llm_temperature": 1,
            "llm_max_tokens": 200
        }}
    )
    print(f"结果长度: {len(result3)} 字符")
    print(f"结果: {result3[:150]}...")


# ============================================================================
# 第三部分：配置字段ID的重要性
# ============================================================================

def example_3_field_id_uniqueness():
    """示例3：字段ID必须唯一"""
    print("\n" + "="*80)
    print("示例3：字段ID唯一性")
    print("="*80)

    # 创建两个可配置的LLM（不同ID）
    llm1 = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7
    ).configurable_fields(
        temperature=ConfigurableField(
            id="llm1_temperature",  # 唯一ID
            name="LLM1 Temperature"
        )
    )

    llm2 = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.3
    ).configurable_fields(
        temperature=ConfigurableField(
            id="llm2_temperature",  # 不同的唯一ID
            name="LLM2 Temperature"
        )
    )

    # 创建使用两个LLM的链
    prompt = ChatPromptTemplate.from_template("Topic: {topic}")

    # 链1：使用llm1生成初稿
    chain1 = prompt | llm1 | StrOutputParser()

    # 链2：使用llm2改进
    improve_prompt = ChatPromptTemplate.from_template("Improve this: {draft}")
    chain2 = improve_prompt | llm2 | StrOutputParser()

    print("\n执行两阶段生成：")
    print("- 阶段1：llm1生成初稿（默认temperature=0.7）")
    print("- 阶段2：llm2改进（默认temperature=0.3）")

    # 执行
    draft = chain1.invoke({"topic": "Python"})
    print(f"\n初稿: {draft[:100]}...")

    improved = chain2.invoke({"draft": draft})
    print(f"\n改进版: {improved[:100]}...")

    # 运行时配置两个LLM
    print("\n运行时配置：llm1_temperature=0, llm2_temperature=1")
    config = {
        "configurable": {
            "llm1_temperature": 0,
            "llm2_temperature": 1
        }
    }

    draft2 = chain1.invoke({"topic": "Python"}, config=config)
    print(f"\n初稿（temperature=0）: {draft2[:100]}...")

    improved2 = chain2.invoke({"draft": draft2}, config=config)
    print(f"\n改进版（temperature=1）: {improved2[:100]}...")


# ============================================================================
# 第四部分：动态配置的实际应用
# ============================================================================

def example_4_practical_use_case():
    """示例4：根据任务类型动态配置"""
    print("\n" + "="*80)
    print("示例4：根据任务类型动态配置")
    print("="*80)

    # 创建可配置的LLM
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7,
        max_tokens=150
    ).configurable_fields(
        temperature=ConfigurableField(
            id="temperature",
            name="Temperature"
        ),
        max_tokens=ConfigurableField(
            id="max_tokens",
            name="Max Tokens"
        )
    )

    # 创建链
    prompt = ChatPromptTemplate.from_template("{task}")
    chain = prompt | llm | StrOutputParser()

    # 定义不同任务类型的配置
    task_configs = {
        "factual": {
            "name": "事实性任务（如数据分析）",
            "config": {
                "configurable": {
                    "temperature": 0,  # 确定性
                    "max_tokens": 100  # 简洁
                }
            }
        },
        "creative": {
            "name": "创造性任务（如故事创作）",
            "config": {
                "configurable": {
                    "temperature": 0.9,  # 创造性
                    "max_tokens": 300  # 详细
                }
            }
        },
        "balanced": {
            "name": "平衡任务（如解释概念）",
            "config": {
                "configurable": {
                    "temperature": 0.5,  # 平衡
                    "max_tokens": 200  # 中等
                }
            }
        }
    }

    # 测试不同任务类型
    tasks = [
        ("factual", "What is 2+2?"),
        ("creative", "Write a poem about coding"),
        ("balanced", "Explain recursion")
    ]

    for task_type, task_text in tasks:
        config_info = task_configs[task_type]
        print(f"\n任务类型: {config_info['name']}")
        print(f"任务: {task_text}")
        print(f"配置: {config_info['config']['configurable']}")

        result = chain.invoke(
            {"task": task_text},
            config=config_info['config']
        )

        print(f"结果: {result[:150]}...")
        print(f"长度: {len(result)} 字符")


# ============================================================================
# 第五部分：配置字段的类型安全
# ============================================================================

def example_5_type_safety():
    """示例5：配置字段的类型验证"""
    print("\n" + "="*80)
    print("示例5：类型安全")
    print("="*80)

    # 创建可配置的LLM
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7
    ).configurable_fields(
        temperature=ConfigurableField(
            id="temperature",
            name="Temperature",
            description="Must be between 0 and 1"
        )
    )

    prompt = ChatPromptTemplate.from_template("Say hello")
    chain = prompt | llm | StrOutputParser()

    # 测试1：有效值
    print("\n测试1：有效值（temperature=0.5）")
    try:
        result = chain.invoke(
            {},
            config={"configurable": {"temperature": 0.5}}
        )
        print(f"✓ 成功: {result[:50]}...")
    except Exception as e:
        print(f"✗ 失败: {e}")

    # 测试2：边界值
    print("\n测试2：边界值（temperature=0）")
    try:
        result = chain.invoke(
            {},
            config={"configurable": {"temperature": 0}}
        )
        print(f"✓ 成功: {result[:50]}...")
    except Exception as e:
        print(f"✗ 失败: {e}")

    print("\n测试3：边界值（temperature=1）")
    try:
        result = chain.invoke(
            {},
            config={"configurable": {"temperature": 1}}
        )
        print(f"✓ 成功: {result[:50]}...")
    except Exception as e:
        print(f"✗ 失败: {e}")

    # 测试4：无效值（超出范围）
    print("\n测试4：无效值（temperature=2）")
    try:
        result = chain.invoke(
            {},
            config={"configurable": {"temperature": 2}}
        )
        print(f"✓ 成功: {result[:50]}...")
    except Exception as e:
        print(f"✗ 失败（预期）: {type(e).__name__}")

    print("\n注意：OpenAI API会验证参数范围")


# ============================================================================
# 第六部分：配置字段的默认值
# ============================================================================

def example_6_default_values():
    """示例6：默认值的使用"""
    print("\n" + "="*80)
    print("示例6：默认值")
    print("="*80)

    # 创建可配置的LLM with默认值
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7,  # 这是默认值
        max_tokens=100
    ).configurable_fields(
        temperature=ConfigurableField(
            id="temperature",
            name="Temperature"
        ),
        max_tokens=ConfigurableField(
            id="max_tokens",
            name="Max Tokens"
        )
    )

    prompt = ChatPromptTemplate.from_template("Explain {topic}")
    chain = prompt | llm | StrOutputParser()

    # 测试1：不提供配置（使用默认值）
    print("\n测试1：不提供配置（使用默认值）")
    result1 = chain.invoke({"topic": "Python"})
    print(f"结果: {result1[:100]}...")
    print("使用默认值：temperature=0.7, max_tokens=100")

    # 测试2：只覆盖部分字段
    print("\n测试2：只覆盖temperature")
    result2 = chain.invoke(
        {"topic": "Python"},
        config={"configurable": {"temperature": 0}}
    )
    print(f"结果: {result2[:100]}...")
    print("使用：temperature=0（覆盖）, max_tokens=100（默认）")

    # 测试3：覆盖所有字段
    print("\n测试3：覆盖所有字段")
    result3 = chain.invoke(
        {"topic": "Python"},
        config={"configurable": {
            "temperature": 1,
            "max_tokens": 50
        }}
    )
    print(f"结果: {result3[:100]}...")
    print("使用：temperature=1（覆盖）, max_tokens=50（覆盖）")


# ============================================================================
# 第七部分：配置字段的文档化
# ============================================================================

def example_7_field_documentation():
    """示例7：配置字段的文档"""
    print("\n" + "="*80)
    print("示例7：配置字段文档")
    print("="*80)

    # 创建详细文档的可配置LLM
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7,
        max_tokens=150
    ).configurable_fields(
        temperature=ConfigurableField(
            id="llm_temperature",
            name="LLM Temperature",
            description=(
                "控制输出的随机性和创造性。\n"
                "- 0.0: 完全确定性，适合事实性任务\n"
                "- 0.5: 平衡，适合一般任务\n"
                "- 1.0: 最大创造性，适合创意任务"
            )
        ),
        max_tokens=ConfigurableField(
            id="llm_max_tokens",
            name="Max Output Tokens",
            description=(
                "限制输出的最大token数量。\n"
                "- 50-100: 简短回答\n"
                "- 150-300: 中等长度\n"
                "- 500+: 详细回答"
            )
        )
    )

    # 获取配置字段信息
    print("\n可配置字段：")
    print("\n1. llm_temperature")
    print("   名称: LLM Temperature")
    print("   说明: 控制输出的随机性和创造性")
    print("   范围: 0.0 - 1.0")

    print("\n2. llm_max_tokens")
    print("   名称: Max Output Tokens")
    print("   说明: 限制输出的最大token数量")
    print("   范围: 1 - 模型最大值")

    print("\n这些文档帮助用户理解如何配置字段")


# ============================================================================
# 主函数
# ============================================================================

def main():
    """运行所有示例"""
    print("\n" + "="*80)
    print("动态字段配置 - 完整示例")
    print("="*80)

    try:
        # 运行所有示例
        example_1_basic_configurable_field()
        example_2_multiple_configurable_fields()
        example_3_field_id_uniqueness()
        example_4_practical_use_case()
        example_5_type_safety()
        example_6_default_values()
        example_7_field_documentation()

        print("\n" + "="*80)
        print("所有示例执行完成！")
        print("="*80)

        print("\n关键要点总结：")
        print("1. configurable_fields()使字段可运行时配置")
        print("2. 通过config.configurable字典传递配置")
        print("3. 字段ID必须在整个链中唯一")
        print("4. 支持配置多个字段")
        print("5. 未配置的字段使用默认值")
        print("6. ConfigurableField提供文档和元数据")

    except Exception as e:
        print(f"\n错误: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
```

---

## 二、代码说明

### 2.1 核心组件

**configurable_fields()方法**:
- 使Runnable的字段可运行时配置
- 返回新的Runnable实例
- 不修改原始Runnable

**ConfigurableField类**:
- `id`: 唯一标识符（必需）
- `name`: 显示名称
- `description`: 字段说明

**7个示例场景**:
1. 配置单个字段（temperature）
2. 配置多个字段
3. 字段ID唯一性
4. 根据任务类型动态配置
5. 类型安全验证
6. 默认值使用
7. 配置字段文档

### 2.2 配置语法

**定义可配置字段**:
```python
llm = ChatOpenAI(
    temperature=0.7  # 默认值
).configurable_fields(
    temperature=ConfigurableField(
        id="llm_temperature",
        name="Temperature",
        description="控制随机性"
    )
)
```

**运行时配置**:
```python
result = chain.invoke(
    input_data,
    config={
        "configurable": {
            "llm_temperature": 0.5
        }
    }
)
```

---

## 三、运行环境

### 3.1 依赖安装

```bash
uv sync
source .venv/bin/activate
```

### 3.2 环境变量

```bash
# .env文件
OPENAI_API_KEY=your_key_here
```

### 3.3 运行代码

```bash
python 07_实战代码_03_动态字段配置.py
```

---

## 四、预期输出

```
================================================================================
动态字段配置 - 完整示例
================================================================================

================================================================================
示例1：配置单个字段（temperature）
================================================================================

测试1：使用默认temperature（0.7）
结果: Once upon a time, in a world where artificial intelligence had become...

测试2：运行时设置temperature=0（确定性）
结果: In a world where artificial intelligence had advanced beyond human...

测试3：运行时设置temperature=1（创造性）
结果: In the neon-lit streets of Neo-Tokyo, a rogue AI named Zephyr...

观察：不同temperature产生不同风格的输出

[... 更多输出 ...]

================================================================================
所有示例执行完成！
================================================================================

关键要点总结：
1. configurable_fields()使字段可运行时配置
2. 通过config.configurable字典传递配置
3. 字段ID必须在整个链中唯一
4. 支持配置多个字段
5. 未配置的字段使用默认值
6. ConfigurableField提供文档和元数据
```

---

## 五、学习要点

### 5.1 可配置字段的优势

**灵活性**:
- 无需重新创建链
- 运行时动态调整参数
- 支持A/B测试

**可维护性**:
- 集中管理配置
- 清晰的配置接口
- 自文档化

**性能**:
- 避免重复创建对象
- 配置切换开销小

### 5.2 字段ID命名规范

**推荐命名**:
```python
# 好的命名
"llm_temperature"
"retriever_top_k"
"embeddings_model"

# 避免的命名
"temp"  # 太简短
"t"     # 不清晰
"temperature"  # 可能冲突
```

**命名原则**:
- 使用描述性名称
- 包含组件前缀
- 避免通用名称
- 保持一致性

### 5.3 配置字段的类型

**常见可配置字段**:
- `temperature`: 随机性控制
- `max_tokens`: 输出长度
- `top_p`: 核采样参数
- `frequency_penalty`: 频率惩罚
- `presence_penalty`: 存在惩罚

### 5.4 最佳实践

1. **提供有意义的默认值**
2. **使用清晰的字段ID**
3. **添加详细的description**
4. **验证配置值的有效性**
5. **文档化可配置字段**

---

## 六、常见问题

### Q1: 字段ID冲突会怎样？

**A**: 如果链中有多个相同ID的可配置字段，配置会应用到所有匹配的字段。这可能导致意外行为，因此ID必须唯一。

### Q2: 可以配置嵌套对象的字段吗？

**A**: 可以，但只能配置直接属性。对于深层嵌套，需要在每个层级使用configurable_fields()。

### Q3: 配置字段会影响性能吗？

**A**: 影响很小。configurable_fields()创建轻量级包装器，运行时配置查找非常快。

### Q4: 如何获取所有可配置字段？

**A**: 可以通过Runnable的config_schema()方法获取配置模式，包含所有可配置字段的信息。

---

## 七、下一步

- 学习多模型切换: [实战代码04 - 多模型切换](./07_实战代码_04_多模型切换.md)
- 理解可配置替代方案: [核心概念06 - 可配置替代方案](./03_核心概念_06_可配置替代方案.md)
- 深入可配置字段: [核心概念05 - 可配置字段系统](./03_核心概念_05_可配置字段系统.md)

---

**版本**: v1.0
**创建日期**: 2026-02-21
**代码行数**: 约500行
**Python版本**: 3.13+
**测试状态**: ✓ 所有代码可运行
