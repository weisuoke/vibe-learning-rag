# 核心概念2：重试机制与指数退避

**重试机制是在遇到临时性错误时自动重新执行失败的操作，指数退避是一种重试策略，每次重试的等待时间呈指数增长。**

---

## 为什么需要重试机制？

**问题：** 临时性错误（网络抖动、Rate Limit、服务过载）导致请求失败

```python
# ❌ 没有重试机制
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# 场景：OpenAI API 临时过载（1秒后恢复）
# 结果：请求失败，用户看到错误
```

**解决方案：** 重试机制

```python
# ✅ 有重试机制
async def call_llm(prompt: str):
    for attempt in range(3):
        try:
            response = await openai.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
        except Exception as e:
            if attempt < 2:
                await asyncio.sleep(2 ** attempt)  # 指数退避：1s, 2s
            else:
                raise

# 场景：OpenAI API 临时过载（1秒后恢复）
# 结果：第2次重试成功，用户无感知
```

---

## 指数退避算法

### 什么是指数退避？

**指数退避**：每次重试的等待时间呈指数增长（1s, 2s, 4s, 8s, ...）

**为什么不是线性退避？**

```python
# ❌ 线性退避：1s, 1s, 1s
# 问题：服务可能还没恢复，重试太快

# ✅ 指数退避：1s, 2s, 4s
# 优点：给服务更多恢复时间
```

**数学公式：**
```
delay = initial_delay * (2 ** attempt)
```

**示例：**
```python
initial_delay = 1.0  # 初始延迟 1 秒

# 第1次重试：1 * 2^0 = 1 秒
# 第2次重试：1 * 2^1 = 2 秒
# 第3次重试：1 * 2^2 = 4 秒
# 第4次重试：1 * 2^3 = 8 秒
```

---

### 指数退避的变体

#### 1. 带上限的指数退避

```python
delay = min(initial_delay * (2 ** attempt), max_delay)

# 示例：max_delay = 10
# 第1次：1 秒
# 第2次：2 秒
# 第3次：4 秒
# 第4次：8 秒
# 第5次：10 秒（达到上限）
# 第6次：10 秒（达到上限）
```

**为什么需要上限？**
- 防止等待时间过长（如 2^10 = 1024 秒 ≈ 17 分钟）
- 用户体验：等待时间不应该超过 10-30 秒

---

#### 2. 带随机抖动的指数退避

```python
import random

delay = initial_delay * (2 ** attempt) * (0.5 + random.random())

# 示例：
# 第1次：0.5-1.5 秒（随机）
# 第2次：1-3 秒（随机）
# 第3次：2-6 秒（随机）
```

**为什么需要随机抖动？**
- **防止惊群效应**：所有客户端同时重试，加剧服务负载
- **分散重试时间**：随机抖动让重试时间分散开

**惊群效应示例：**
```
场景：100 个客户端同时请求，服务过载

没有随机抖动：
- 0 秒：100 个请求 → 失败
- 1 秒：100 个请求同时重试 → 失败
- 3 秒：100 个请求同时重试 → 失败
- 7 秒：100 个请求同时重试 → 失败

有随机抖动：
- 0 秒：100 个请求 → 失败
- 0.5-1.5 秒：100 个请求分散重试 → 部分成功
- 1-3 秒：剩余请求分散重试 → 大部分成功
```

---

## 手写重试装饰器

### 基础版本：同步函数

```python
import time
from typing import TypeVar, Callable

T = TypeVar('T')

def retry(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 10.0
):
    """重试装饰器（同步版本）"""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        def wrapper(*args, **kwargs) -> T:
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise

                    # 指数退避（带上限）
                    delay = min(initial_delay * (2 ** attempt), max_delay)
                    print(f"重试 {attempt + 1}/{max_attempts}，等待 {delay}s")
                    time.sleep(delay)
        return wrapper
    return decorator

# 使用示例
@retry(max_attempts=3, initial_delay=1.0)
def call_api():
    response = requests.get("https://api.example.com")
    return response.json()
```

---

### 进阶版本：异步函数

```python
import asyncio
from typing import TypeVar, Callable, Awaitable

T = TypeVar('T')

def async_retry(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 10.0
):
    """重试装饰器（异步版本）"""
    def decorator(func: Callable[..., Awaitable[T]]) -> Callable[..., Awaitable[T]]:
        async def wrapper(*args, **kwargs) -> T:
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise

                    # 指数退避（带上限）
                    delay = min(initial_delay * (2 ** attempt), max_delay)
                    print(f"重试 {attempt + 1}/{max_attempts}，等待 {delay}s")
                    await asyncio.sleep(delay)
        return wrapper
    return decorator

# 使用示例
@async_retry(max_attempts=3, initial_delay=1.0)
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

### 完整版本：条件重试 + 随机抖动

```python
"""
完整的重试装饰器
支持：条件重试、指数退避、随机抖动、最大延迟
"""

import asyncio
import random
from typing import TypeVar, Callable, Awaitable, Type

T = TypeVar('T')

def async_retry(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 10.0,
    jitter: bool = True,
    retry_on: tuple[Type[Exception], ...] = (Exception,)
):
    """
    重试装饰器（完整版）

    参数：
        max_attempts: 最大重试次数
        initial_delay: 初始延迟（秒）
        max_delay: 最大延迟（秒）
        jitter: 是否添加随机抖动
        retry_on: 可重试的异常类型
    """
    def decorator(func: Callable[..., Awaitable[T]]) -> Callable[..., Awaitable[T]]:
        async def wrapper(*args, **kwargs) -> T:
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except retry_on as e:
                    if attempt == max_attempts - 1:
                        raise

                    # 指数退避
                    delay = initial_delay * (2 ** attempt)

                    # 添加随机抖动（0.5-1.5倍）
                    if jitter:
                        delay *= (0.5 + random.random())

                    # 限制最大延迟
                    delay = min(delay, max_delay)

                    print(f"重试 {attempt + 1}/{max_attempts}，等待 {delay:.2f}s，错误: {type(e).__name__}")
                    await asyncio.sleep(delay)
                except Exception as e:
                    # 不可重试的异常，直接抛出
                    raise
        return wrapper
    return decorator

# 使用示例：只重试特定异常
from openai import Timeout, RateLimitError

@async_retry(
    max_attempts=3,
    initial_delay=1.0,
    max_delay=10.0,
    jitter=True,
    retry_on=(Timeout, RateLimitError)  # 只重试超时和 Rate Limit
)
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

## 使用 tenacity 库

**tenacity** 是一个功能强大的重试库，提供了丰富的重试策略。

### 安装

```bash
uv add tenacity
```

### 基础用法

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10)
)
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# 重试策略：
# - 最多重试 3 次
# - 指数退避：1s, 2s, 4s（最大 10s）
```

---

### 条件重试

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import Timeout, RateLimitError

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((Timeout, RateLimitError))  # 只重试特定异常
)
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

### 自定义重试条件

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception

def should_retry(exception: Exception) -> bool:
    """判断是否应该重试"""
    # 可重试的异常
    if isinstance(exception, (Timeout, RateLimitError)):
        return True

    # 根据 HTTP 状态码判断
    if hasattr(exception, 'status_code'):
        return exception.status_code in [429, 500, 502, 503, 504]

    return False

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception(should_retry)
)
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

### 重试回调

```python
from tenacity import retry, stop_after_attempt, wait_exponential, before_sleep_log
import structlog

logger = structlog.get_logger()

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    before_sleep=before_sleep_log(logger, "warning")  # 重试前记录日志
)
async def call_llm(prompt: str):
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

## 在 AI Agent API 中的应用

### 场景1：LLM 调用重试

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import AsyncOpenAI, Timeout, RateLimitError, APIError
import structlog

logger = structlog.get_logger()
client = AsyncOpenAI()

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((Timeout, RateLimitError, APIError))
)
async def call_llm(prompt: str) -> str:
    """调用 LLM（自动重试）"""
    try:
        response = await client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            timeout=30.0
        )
        return response.choices[0].message.content
    except Timeout:
        logger.warning("llm_timeout", provider="OpenAI")
        raise
    except RateLimitError as e:
        retry_after = int(e.response.headers.get("Retry-After", 60))
        logger.warning("llm_rate_limit", provider="OpenAI", retry_after=retry_after)
        raise
    except APIError as e:
        logger.error("llm_api_error", provider="OpenAI", error=str(e))
        raise

# 使用示例
@app.post("/chat")
async def chat(message: str):
    response = await call_llm(message)
    return {"response": response}
```

---

### 场景2：数据库操作重试

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from sqlalchemy.exc import OperationalError, DBAPIError

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=0.5, min=0.5, max=5),
    retry=retry_if_exception_type((OperationalError, DBAPIError))
)
async def save_conversation(conversation: dict):
    """保存对话（自动重试）"""
    async with db.session() as session:
        session.add(Conversation(**conversation))
        await session.commit()
```

---

### 场景3：向量检索重试

```python
from tenacity import retry, stop_after_attempt, wait_exponential
import chromadb

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10)
)
async def vector_search(query: str, top_k: int = 5):
    """向量检索（自动重试）"""
    client = chromadb.Client()
    collection = client.get_collection("documents")

    results = collection.query(
        query_texts=[query],
        n_results=top_k
    )
    return results
```

---

## 重试策略的最佳实践

### 1. 重试次数：3 次

**推荐：** 3 次重试（总共 4 次尝试）

**理由：**
- 恢复概率：87.5%（假设每次成功率 50%）
- 等待时间：7 秒（1s + 2s + 4s）
- 用户体验：可接受的等待时间

```python
@retry(stop=stop_after_attempt(3))
async def call_api():
    ...
```

---

### 2. 初始延迟：1 秒

**推荐：** 1 秒初始延迟

**理由：**
- 太短（0.1s）：服务可能还没恢复
- 太长（5s）：用户等待时间过长

```python
@retry(wait=wait_exponential(multiplier=1, min=1, max=10))
async def call_api():
    ...
```

---

### 3. 最大延迟：10 秒

**推荐：** 10 秒最大延迟

**理由：**
- 防止等待时间过长（2^10 = 1024 秒）
- 用户体验：单次重试不应该超过 10 秒

```python
@retry(wait=wait_exponential(multiplier=1, min=1, max=10))
async def call_api():
    ...
```

---

### 4. 添加随机抖动

**推荐：** 添加随机抖动（0.5-1.5倍）

**理由：**
- 防止惊群效应
- 分散重试时间

```python
from tenacity import wait_random_exponential

@retry(wait=wait_random_exponential(multiplier=1, min=1, max=10))
async def call_api():
    ...
```

---

### 5. 只重试临时性错误

**推荐：** 只重试临时性错误（网络、Rate Limit、服务过载）

**理由：**
- 永久性错误（参数错误、认证失败）重试无意义
- 浪费资源

```python
@retry(
    retry=retry_if_exception_type((Timeout, RateLimitError, APIError))
)
async def call_api():
    ...
```

---

## 重试机制的权衡

### 权衡1：可靠性 vs 延迟

**可靠性：** 重试次数越多，成功率越高
**延迟：** 重试次数越多，等待时间越长

**平衡：**
- 3 次重试：87.5% 成功率，7 秒等待时间 ✅
- 10 次重试：99.95% 成功率，1023 秒等待时间 ❌

---

### 权衡2：自动恢复 vs 资源消耗

**自动恢复：** 重试可以自动恢复临时故障
**资源消耗：** 重试会占用连接、内存、CPU

**平衡：**
- 关键路径（用户对话）：允许重试
- 非关键路径（后台任务）：快速失败

---

### 权衡3：指数退避 vs 线性退避

**指数退避：** 给服务更多恢复时间
**线性退避：** 重试更快

**平衡：**
- 临时故障（网络抖动）：指数退避 ✅
- 快速恢复（缓存失效）：线性退避

---

## 总结

**重试机制的核心价值：**
1. **自动恢复**：临时故障不会导致永久失败
2. **用户体验**：用户无感知，服务更可靠
3. **资源优化**：指数退避减少服务负载

**指数退避的优势：**
1. **给服务恢复时间**：每次重试间隔更长
2. **防止惊群效应**：随机抖动分散重试时间
3. **限制最大延迟**：防止等待时间过长

**最佳实践：**
- 重试次数：3 次
- 初始延迟：1 秒
- 最大延迟：10 秒
- 添加随机抖动
- 只重试临时性错误

**在 AI Agent API 中的应用：**
- LLM 调用重试（Timeout、RateLimitError）
- 数据库操作重试（OperationalError）
- 向量检索重试（网络错误）
