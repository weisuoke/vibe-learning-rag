# 最小可用

> 掌握20%的核心知识，解决80%的幻觉问题

---

## 核心理念

在 RAG 开发中，幻觉检测与缓解可以很复杂，但掌握以下核心知识，就能开始构建可信赖的 RAG 系统。

---

## 必须掌握的5个核心知识点

### 1. 理解幻觉的两种类型

**矛盾型幻觉 vs 编造型幻觉**

```python
# 矛盾型：与检索内容直接冲突
retrieved = "Python 3.9 发布于 2020 年 10 月"
generated = "Python 3.9 发布于 2021 年"  # ❌ 矛盾

# 编造型：检索内容中不存在的信息
retrieved = "Python 3.9 新增了字典合并运算符"
generated = "Python 3.9 新增了字典合并运算符和模式匹配"  # ❌ 模式匹配是编造的
```

**为什么重要？**
- 矛盾型更容易检测（使用 NLI 模型）
- 编造型更难检测（需要验证每个事实是否有来源支持）

**最小可用方案：**
```python
def detect_hallucination(answer, retrieved_docs):
    # 简单方法：检查答案中的关键信息是否在检索文档中
    answer_facts = extract_facts(answer)
    for fact in answer_facts:
        if not any(fact in doc for doc in retrieved_docs):
            return "可能存在编造"
    return "通过检测"
```

---

### 2. 使用预训练 NLI 模型做一致性检测

**核心概念：** 自然语言推理（NLI）模型可以判断两段文本的关系

```python
from sentence_transformers import CrossEncoder

# 加载预训练 NLI 模型
nli_model = CrossEncoder('cross-encoder/nli-deberta-v3-base')

def check_consistency(answer, retrieved_doc):
    """
    检查答案与检索文档的一致性
    返回：0-1 的分数，越高越一致
    """
    # NLI 模型输出三个分数：[矛盾, 中立, 蕴含]
    scores = nli_model.predict([(retrieved_doc, answer)])

    # 提取蕴含分数（第3个）
    entailment_score = scores[0][2]

    return entailment_score

# 使用示例
doc = "Python 3.9 于 2020 年 10 月 5 日发布"
answer1 = "Python 3.9 在 2020 年发布"
answer2 = "Python 3.9 在 2021 年发布"

print(f"一致性分数1: {check_consistency(answer1, doc)}")  # 高分
print(f"一致性分数2: {check_consistency(answer2, doc)}")  # 低分
```

**为什么这是最小可用？**
- 只需要一个预训练模型，无需训练
- 几行代码就能实现
- 覆盖大部分矛盾型幻觉检测场景

---

### 3. 在 Prompt 中要求 LLM 添加引用

**核心技巧：** 通过 Prompt 工程让 LLM 标注来源

```python
def generate_with_citations(query, docs):
    """
    生成带引用的答案
    """
    # 构建带编号的文档
    numbered_docs = "\n\n".join([
        f"文档{i+1}：{doc}"
        for i, doc in enumerate(docs)
    ])

    prompt = f"""
基于以下文档回答问题，并用 [1], [2] 等标注引用来源。

{numbered_docs}

问题：{query}

要求：
1. 每个事实性陈述都要标注来源
2. 不要添加文档中没有的信息
3. 如果文档中没有答案，明确说明

答案：
"""

    answer = llm.generate(prompt)
    return answer

# 使用示例
docs = [
    "Python 3.9 于 2020 年 10 月 5 日发布",
    "Python 3.9 新增了字典合并运算符 |"
]
query = "Python 3.9 有什么新特性？"
answer = generate_with_citations(query, docs)

# 预期输出：
# "Python 3.9 于 2020 年 10 月 5 日发布 [1]，新增了字典合并运算符 | [2]"
```

**为什么这是最小可用？**
- 不需要额外模型或工具
- 只需要改进 Prompt
- 立即提升可追溯性

---

### 4. 设置置信度阈值，低置信度时拒绝回答

**核心原则：** 不确定时，诚实地说"不知道"比给出错误答案更好

```python
def generate_with_confidence(query, docs, threshold=0.7):
    """
    带置信度评估的生成
    """
    # 1. 检查检索质量
    if len(docs) == 0:
        return "抱歉，我没有找到相关信息"

    # 2. 生成答案
    answer = generate_with_citations(query, docs)

    # 3. 一致性检测
    consistency_scores = [
        check_consistency(answer, doc)
        for doc in docs
    ]
    avg_consistency = sum(consistency_scores) / len(consistency_scores)

    # 4. 置信度判断
    if avg_consistency < threshold:
        return "抱歉，我对这个答案不够确定，建议查阅原始文档"

    return answer

# 使用示例
docs = ["相关度较低的文档..."]
answer = generate_with_confidence("复杂问题", docs, threshold=0.7)
# 可能返回："抱歉，我对这个答案不够确定..."
```

**为什么这是最小可用？**
- 简单的阈值判断
- 避免了大部分高风险幻觉
- 提升用户信任

---

### 5. 过滤低质量检索结果

**核心原则：** 垃圾输入 → 垃圾输出，在检索阶段就要把关

```python
def filter_low_quality_docs(docs, min_score=0.7):
    """
    过滤低质量检索结果
    """
    filtered = []

    for doc in docs:
        # 检查1：相似度分数
        if doc.score < min_score:
            continue

        # 检查2：文档长度（太短可能不完整）
        if len(doc.content) < 50:
            continue

        # 检查3：文档质量（可选）
        # 例如：检查是否包含关键词、是否是完整句子等

        filtered.append(doc)

    return filtered

# 使用示例
retrieved_docs = retriever.search(query, top_k=10)
quality_docs = filter_low_quality_docs(retrieved_docs, min_score=0.7)

if len(quality_docs) == 0:
    return "抱歉，没有找到高质量的相关文档"

answer = generate_with_citations(query, quality_docs)
```

**为什么这是最小可用？**
- 预防胜于治疗
- 简单的过滤规则
- 显著降低幻觉风险

---

## 最小可用的完整流程

将以上5个知识点组合成一个完整的防护流程：

```python
from sentence_transformers import CrossEncoder
from openai import OpenAI

# 初始化
nli_model = CrossEncoder('cross-encoder/nli-deberta-v3-base')
client = OpenAI()

def minimal_hallucination_protection(query, retriever, threshold=0.7):
    """
    最小可用的幻觉防护流程
    """
    # 步骤1：检索
    retrieved_docs = retriever.search(query, top_k=5)

    # 步骤2：过滤低质量文档
    quality_docs = [
        doc for doc in retrieved_docs
        if doc.score > 0.7 and len(doc.content) > 50
    ]

    if len(quality_docs) == 0:
        return {
            "answer": "抱歉，没有找到相关信息",
            "confidence": 0.0,
            "sources": []
        }

    # 步骤3：生成带引用的答案
    numbered_docs = "\n\n".join([
        f"文档{i+1}：{doc.content}"
        for i, doc in enumerate(quality_docs)
    ])

    prompt = f"""
基于以下文档回答问题，并用 [1], [2] 标注引用来源：

{numbered_docs}

问题：{query}

要求：严格基于文档内容，不要添加文档中没有的信息。

答案：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    answer = response.choices[0].message.content

    # 步骤4：一致性检测
    consistency_scores = []
    for doc in quality_docs:
        scores = nli_model.predict([(doc.content, answer)])
        entailment_score = scores[0][2]  # 蕴含分数
        consistency_scores.append(entailment_score)

    avg_consistency = sum(consistency_scores) / len(consistency_scores)

    # 步骤5：置信度判断
    if avg_consistency < threshold:
        return {
            "answer": "抱歉，我对这个答案不够确定",
            "confidence": avg_consistency,
            "sources": []
        }

    return {
        "answer": answer,
        "confidence": avg_consistency,
        "sources": [doc.metadata for doc in quality_docs]
    }

# 使用示例
result = minimal_hallucination_protection(
    query="Python 3.9 有什么新特性？",
    retriever=my_retriever,
    threshold=0.7
)

print(f"答案：{result['answer']}")
print(f"置信度：{result['confidence']:.2f}")
print(f"来源：{result['sources']}")
```

---

## 这些知识足以做什么？

掌握以上5个核心知识点，你可以：

### ✅ 构建基础的幻觉防护系统
- 检测明显的矛盾型幻觉
- 为答案添加引用来源
- 在不确定时拒绝回答

### ✅ 应用于实际项目
- 文档问答系统
- 知识库检索
- 客服聊天机器人

### ✅ 为后续学习打基础
- 理解幻觉问题的本质
- 掌握基本的检测和缓解方法
- 为学习更高级技术做准备

---

## 快速上手指南

### 第1步：安装依赖

```bash
pip install sentence-transformers openai chromadb
```

### 第2步：准备 NLI 模型

```python
from sentence_transformers import CrossEncoder

# 首次运行会自动下载模型
nli_model = CrossEncoder('cross-encoder/nli-deberta-v3-base')
```

### 第3步：集成到 RAG 流程

```python
# 在生成答案后添加一致性检测
answer = llm.generate(query, docs)
consistency = check_consistency(answer, docs[0])

if consistency < 0.7:
    answer = "抱歉，我对这个答案不够确定"
```

---

## 常见问题

### Q1：NLI 模型会不会很慢？

**A**：预训练的 NLI 模型推理速度很快（毫秒级），对用户体验影响很小。

### Q2：置信度阈值应该设置多少？

**A**：
- **高风险场景**（医疗、法律）：0.8-0.9
- **一般场景**（客服、问答）：0.6-0.7
- **低风险场景**（娱乐、推荐）：0.5-0.6

### Q3：引用标记 [1][2] 会不会不准确？

**A**：LLM 可能会错误标注引用，需要后处理验证：

```python
def verify_citations(answer, docs):
    """验证引用是否有效"""
    citations = re.findall(r'\[(\d+)\]', answer)
    for cite in citations:
        cite_num = int(cite)
        if cite_num > len(docs):
            return False  # 引用了不存在的文档
    return True
```

---

## 进阶方向

掌握最小可用知识后，可以学习：

1. **更精细的一致性检测**：使用多个 NLI 模型集成
2. **自动引用提取**：从答案中自动提取并验证引用
3. **多策略缓解**：结合检索优化、约束生成、后处理过滤
4. **评估指标**：使用 RAGAS 等框架量化评估效果

---

## 总结

**最小可用的5个核心知识：**

1. ✅ 理解幻觉的两种类型（矛盾型 vs 编造型）
2. ✅ 使用 NLI 模型做一致性检测
3. ✅ 在 Prompt 中要求添加引用
4. ✅ 设置置信度阈值
5. ✅ 过滤低质量检索结果

**记住：**

> **20%的核心知识（这5个要点）可以解决80%的幻觉问题。**
>
> **先掌握这些，再逐步深入学习更高级的技术。**
