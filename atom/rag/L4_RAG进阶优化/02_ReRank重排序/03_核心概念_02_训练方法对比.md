# 03_核心概念_02_训练方法对比

## ReRank模型的三种训练方法

ReRank模型的训练目标是学习query-document的相关性排序。根据训练数据的组织方式和损失函数设计，主要有三种训练方法：

1. **Pointwise**：独立评分每个query-doc对
2. **Pairwise**：学习相对排序关系
3. **Listwise**：整体优化排序质量

---

## 方法1：Pointwise训练

### 核心思想

**将排序问题转化为分类/回归问题**：独立预测每个query-doc对的相关性分数。

### 训练数据格式

```python
# Pointwise训练数据
training_data = [
    {
        "query": "什么是RAG？",
        "document": "RAG是检索增强生成技术",
        "label": 1  # 相关
    },
    {
        "query": "什么是RAG？",
        "document": "今天天气很好",
        "label": 0  # 不相关
    },
    {
        "query": "如何使用向量数据库？",
        "document": "ChromaDB是轻量级向量数据库",
        "label": 1  # 相关
    }
]
```

**标注方式：**
- 二分类：0（不相关）/ 1（相关）
- 多分类：0（不相关）/ 1（部分相关）/ 2（相关）/ 3（非常相关）
- 回归：0.0-1.0的连续分数

### 损失函数

**二分类（Binary Cross-Entropy）：**

```python
import torch
import torch.nn as nn

# 模型输出
logits = model(query, doc)  # [batch_size, 1]
predictions = torch.sigmoid(logits)  # [batch_size, 1]

# 损失函数
loss_fn = nn.BCELoss()
loss = loss_fn(predictions, labels)

# 示例
# predictions = [0.95, 0.12, 0.88]
# labels = [1, 0, 1]
# loss = -[1*log(0.95) + 0*log(1-0.12) + 1*log(0.88)] / 3 = 0.08
```

**多分类（Cross-Entropy）：**

```python
# 模型输出
logits = model(query, doc)  # [batch_size, num_classes]
predictions = torch.softmax(logits, dim=-1)  # [batch_size, num_classes]

# 损失函数
loss_fn = nn.CrossEntropyLoss()
loss = loss_fn(logits, labels)
```

**回归（MSE）：**

```python
# 模型输出
predictions = model(query, doc)  # [batch_size, 1]

# 损失函数
loss_fn = nn.MSELoss()
loss = loss_fn(predictions, labels)
```

### 优点

1. **简单易实现**：标准的分类/回归任务
2. **标注成本低**：只需独立标注每个query-doc对
3. **训练稳定**：损失函数简单，收敛快
4. **可解释性强**：输出分数有明确含义

### 缺点

1. **忽略相对关系**：不考虑同一query下不同doc的相对排序
2. **位置偏差**：模型不知道排序位置的重要性
3. **精度有限**：NDCG@10通常比Pairwise/Listwise低5-10%

### 实际应用

**BGE reranker-base使用Pointwise训练：**

```python
from sentence_transformers import CrossEncoder

# 加载Pointwise训练的模型
reranker = CrossEncoder('BAAI/bge-reranker-base')

# 预测相关性分数
query = "什么是RAG？"
docs = ["RAG是检索增强生成", "今天天气很好"]
scores = reranker.predict([(query, doc) for doc in docs])
# 输出：[0.9876, 0.1234]

# 排序
ranked_indices = np.argsort(scores)[::-1]
```

---

## 方法2：Pairwise训练

### 核心思想

**学习相对排序关系**：给定query和两个doc（一个相关，一个不相关），模型学习相关doc的分数应该高于不相关doc。

### 训练数据格式

```python
# Pairwise训练数据
training_data = [
    {
        "query": "什么是RAG？",
        "doc_pos": "RAG是检索增强生成技术",  # 正样本（相关）
        "doc_neg": "今天天气很好"  # 负样本（不相关）
    },
    {
        "query": "如何使用向量数据库？",
        "doc_pos": "ChromaDB是轻量级向量数据库",
        "doc_neg": "Python是编程语言"
    }
]
```

**标注方式：**
- 成对标注：标注哪个doc更相关
- 可以从Pointwise标注自动生成：label=1的doc作为正样本，label=0的doc作为负样本

### 损失函数

**Margin Ranking Loss：**

```python
import torch
import torch.nn as nn

# 模型输出
score_pos = model(query, doc_pos)  # [batch_size, 1]
score_neg = model(query, doc_neg)  # [batch_size, 1]

# 损失函数
loss_fn = nn.MarginRankingLoss(margin=1.0)
target = torch.ones(batch_size)  # 表示score_pos应该大于score_neg
loss = loss_fn(score_pos, score_neg, target)

# 等价于：
# loss = max(0, margin - (score_pos - score_neg))
# 示例：
# score_pos = 0.9, score_neg = 0.8, margin = 1.0
# loss = max(0, 1.0 - (0.9 - 0.8)) = max(0, 0.9) = 0.9
```

**Hinge Loss：**

```python
# 损失函数
margin = 1.0
loss = torch.clamp(margin - (score_pos - score_neg), min=0).mean()
```

**Logistic Loss（RankNet）：**

```python
# 损失函数
loss = torch.log(1 + torch.exp(-(score_pos - score_neg))).mean()
```

### ELO-based训练（ZeroEntropy zerank-1）

**核心思想：** 借鉴国际象棋ELO评分系统，动态更新doc的"实力"评分。

```python
# ELO更新公式
def update_elo(elo_winner, elo_loser, K=32):
    # 期望胜率
    expected_winner = 1 / (1 + 10 ** ((elo_loser - elo_winner) / 400))
    expected_loser = 1 / (1 + 10 ** ((elo_winner - elo_loser) / 400))

    # 更新ELO
    new_elo_winner = elo_winner + K * (1 - expected_winner)
    new_elo_loser = elo_loser + K * (0 - expected_loser)

    return new_elo_winner, new_elo_loser

# 训练过程
for query, doc_pos, doc_neg in training_data:
    score_pos = model(query, doc_pos)
    score_neg = model(query, doc_neg)

    # 根据ELO计算损失权重
    elo_pos = doc_elo_scores[doc_pos]
    elo_neg = doc_elo_scores[doc_neg]
    weight = abs(elo_pos - elo_neg) / 400  # 归一化

    # 加权损失
    loss = weight * torch.log(1 + torch.exp(-(score_pos - score_neg)))

    # 更新ELO
    if score_pos > score_neg:
        doc_elo_scores[doc_pos], doc_elo_scores[doc_neg] = update_elo(elo_pos, elo_neg)
    else:
        doc_elo_scores[doc_neg], doc_elo_scores[doc_pos] = update_elo(elo_neg, elo_pos)
```

**优势：**
- 动态调整难样本权重
- 更好地处理不平衡数据
- ZeroEntropy zerank-1使用此方法，NDCG@10达到0.87

### 优点

1. **学习相对排序**：直接优化排序目标
2. **精度更高**：NDCG@10比Pointwise高5-10%
3. **鲁棒性强**：对标注噪声不敏感
4. **适合排序任务**：符合reranking的本质

### 缺点

1. **标注成本高**：需要成对标注
2. **训练复杂度高**：需要采样正负样本对
3. **收敛慢**：比Pointwise训练慢2-3倍

### 实际应用

**Cohere Rerank 4使用Pairwise训练：**

```python
import cohere

client = cohere.Client(api_key="your_key")

# Pairwise训练的模型
results = client.rerank(
    query="什么是RAG？",
    documents=["RAG是检索增强生成", "今天天气很好"],
    model="rerank-4"
)

# 输出相对排序
for result in results.results:
    print(f"Rank {result.index}: {result.document.text}")
```

---

## 方法3：Listwise训练

### 核心思想

**整体优化排序质量**：给定query和一组doc，模型学习整体排序，直接优化NDCG等排序指标。

### 训练数据格式

```python
# Listwise训练数据
training_data = [
    {
        "query": "什么是RAG？",
        "documents": [
            "RAG是检索增强生成技术",
            "向量数据库用于存储embedding",
            "今天天气很好",
            "Python是编程语言"
        ],
        "relevance_scores": [3, 1, 0, 0]  # 相关性分数
    }
]
```

**标注方式：**
- 分级标注：0（不相关）/ 1（部分相关）/ 2（相关）/ 3（非常相关）
- 理想排序：[doc1, doc2, doc3, doc4]

### 损失函数

**ListNet（基于概率分布）：**

```python
import torch
import torch.nn as nn

# 模型输出
scores = model(query, documents)  # [num_docs]

# 真实排序的概率分布
true_probs = torch.softmax(relevance_scores, dim=0)

# 预测排序的概率分布
pred_probs = torch.softmax(scores, dim=0)

# 交叉熵损失
loss = -torch.sum(true_probs * torch.log(pred_probs))

# 示例：
# relevance_scores = [3, 1, 0, 0]
# true_probs = [0.88, 0.12, 0.00, 0.00]
# scores = [0.9, 0.7, 0.2, 0.1]
# pred_probs = [0.50, 0.35, 0.10, 0.05]
# loss = -[0.88*log(0.50) + 0.12*log(0.35) + ...] = 0.65
```

**ListMLE（最大似然估计）：**

```python
# 模型输出
scores = model(query, documents)  # [num_docs]

# 按相关性排序的索引
sorted_indices = torch.argsort(relevance_scores, descending=True)

# 计算似然
log_likelihood = 0
for i, idx in enumerate(sorted_indices):
    # 当前doc的分数
    score_i = scores[idx]
    # 剩余doc的分数
    remaining_scores = scores[sorted_indices[i:]]
    # log(exp(score_i) / sum(exp(remaining_scores)))
    log_likelihood += score_i - torch.logsumexp(remaining_scores, dim=0)

loss = -log_likelihood
```

**ApproxNDCG（直接优化NDCG）：**

```python
# 模型输出
scores = model(query, documents)  # [num_docs]

# 计算NDCG
def compute_ndcg(scores, relevance_scores, k=10):
    # 按预测分数排序
    sorted_indices = torch.argsort(scores, descending=True)[:k]
    sorted_relevance = relevance_scores[sorted_indices]

    # DCG
    dcg = torch.sum(sorted_relevance / torch.log2(torch.arange(2, k+2, dtype=torch.float32)))

    # IDCG（理想排序的DCG）
    ideal_sorted = torch.sort(relevance_scores, descending=True)[0][:k]
    idcg = torch.sum(ideal_sorted / torch.log2(torch.arange(2, k+2, dtype=torch.float32)))

    # NDCG
    ndcg = dcg / idcg
    return ndcg

# 损失函数（最大化NDCG = 最小化-NDCG）
ndcg = compute_ndcg(scores, relevance_scores, k=10)
loss = -ndcg
```

### 优点

1. **直接优化排序指标**：NDCG、MRR等
2. **最高精度**：NDCG@10比Pairwise高2-5%
3. **考虑位置信息**：Top位置的doc权重更高
4. **整体优化**：考虑所有doc的相对关系

### 缺点

1. **标注成本极高**：需要分级标注所有doc
2. **计算复杂度高**：需要计算所有doc的排列组合
3. **训练不稳定**：梯度计算复杂，容易过拟合
4. **收敛极慢**：比Pairwise训练慢5-10倍

### 实际应用

**研究实验中使用Listwise训练：**

```python
# Listwise训练的模型（研究阶段）
# 生产环境较少使用，因为训练成本太高
```

---

## 三种方法对比

### 性能对比表

| 维度 | Pointwise | Pairwise | Listwise |
|------|-----------|----------|----------|
| **NDCG@10** | 0.82 | 0.87 | 0.89 |
| **训练速度** | 快（1x） | 中（0.3-0.5x） | 慢（0.1-0.2x） |
| **标注成本** | 低 | 中 | 高 |
| **实现复杂度** | 简单 | 中等 | 复杂 |
| **收敛稳定性** | 稳定 | 较稳定 | 不稳定 |
| **生产应用** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐ |

### 精度提升对比

**2026年实测数据（MS MARCO数据集）：**

```
Baseline（BM25）: NDCG@10 = 0.65

Pointwise训练：
- BGE reranker-base: 0.82 (+26%)
- 训练时间：2天（8×V100）

Pairwise训练：
- BGE reranker-v2-m3: 0.87 (+34%)
- 训练时间：5天（8×V100）

Listwise训练：
- 研究模型: 0.89 (+37%)
- 训练时间：15天（8×V100）
```

**ROI分析：**
- Pointwise → Pairwise：精度提升6%，训练时间增加2.5倍，ROI = 2.4
- Pairwise → Listwise：精度提升2%，训练时间增加3倍，ROI = 0.67

**结论：** Pairwise是最佳平衡点

### 适用场景

**Pointwise：**
- ✅ 快速原型验证
- ✅ 标注预算有限
- ✅ 对精度要求不高（NDCG@10 > 0.80即可）
- ❌ 高精度排序任务

**Pairwise：**
- ✅ 生产环境推荐
- ✅ 平衡精度和成本
- ✅ 标注资源充足
- ✅ 对精度有较高要求（NDCG@10 > 0.85）

**Listwise：**
- ✅ 研究实验
- ✅ 追求极致精度
- ✅ 标注和计算资源充足
- ❌ 生产环境（成本太高）

---

## 混合训练策略

### 两阶段训练

**阶段1：Pointwise预训练**
```python
# 使用大规模弱标注数据快速预训练
model = CrossEncoder('bert-base-uncased')
model.train(pointwise_data, epochs=3)
# NDCG@10: 0.80
```

**阶段2：Pairwise微调**
```python
# 使用小规模强标注数据精细微调
model.train(pairwise_data, epochs=2)
# NDCG@10: 0.87
```

**优势：**
- 结合两种方法的优点
- 训练时间：3天（vs Pairwise 5天）
- 精度：0.87（vs Pointwise 0.82）

### 多任务学习

```python
# 同时优化Pointwise和Pairwise损失
loss_pointwise = bce_loss(score, label)
loss_pairwise = margin_loss(score_pos, score_neg)
loss_total = 0.3 * loss_pointwise + 0.7 * loss_pairwise
```

**优势：**
- 更稳定的训练
- 更好的泛化能力
- BGE reranker-v2-m3使用此策略

---

## 实战建议

### 选择训练方法的决策树

```
1. 是否有充足的标注预算？
   └─ 否 → Pointwise
   └─ 是 → 继续

2. 是否需要极致精度（NDCG@10 > 0.88）？
   └─ 是 → Listwise（研究实验）
   └─ 否 → 继续

3. 是否有充足的计算资源（>5天训练时间）？
   └─ 否 → Pointwise + Pairwise微调
   └─ 是 → Pairwise

4. 推荐：Pairwise（生产环境最佳选择）
```

### 标注数据准备

**Pointwise标注：**
```python
# 每个query标注10-20个doc
# 标注时间：10秒/doc
# 总标注时间：1000 queries × 15 docs × 10秒 = 42小时
```

**Pairwise标注：**
```python
# 每个query标注5-10对doc
# 标注时间：15秒/对
# 总标注时间：1000 queries × 7对 × 15秒 = 29小时
```

**Listwise标注：**
```python
# 每个query标注所有doc的相关性分数
# 标注时间：30秒/query
# 总标注时间：1000 queries × 30秒 = 8.3小时
# 但需要更专业的标注员，成本更高
```

### 训练超参数

**Pointwise：**
```python
learning_rate = 2e-5
batch_size = 32
epochs = 3
warmup_steps = 500
```

**Pairwise：**
```python
learning_rate = 1e-5
batch_size = 16  # 更小的batch size
epochs = 5
margin = 1.0
warmup_steps = 1000
```

**Listwise：**
```python
learning_rate = 5e-6  # 更小的学习率
batch_size = 8  # 更小的batch size
epochs = 10
warmup_steps = 2000
```

---

## 关键要点速记

### 核心概念
1. Pointwise：独立评分，简单但精度有限
2. Pairwise：相对排序，生产环境推荐
3. Listwise：整体优化，研究实验使用

### 性能对比
4. NDCG@10：Pointwise 0.82 < Pairwise 0.87 < Listwise 0.89
5. 训练速度：Pointwise 1x > Pairwise 0.3-0.5x > Listwise 0.1-0.2x
6. ROI：Pairwise最高（精度提升6%，时间增加2.5倍）

### 实战建议
7. 生产环境：Pairwise（最佳平衡）
8. 快速原型：Pointwise
9. 研究实验：Listwise
10. 混合策略：Pointwise预训练 + Pairwise微调

### 主流模型
11. BGE reranker-base：Pointwise训练
12. BGE reranker-v2-m3：Pointwise + Pairwise多任务
13. Cohere Rerank 4：Pairwise训练
14. ZeroEntropy zerank-1：ELO-based Pairwise训练

---

## 参考资料

### 核心论文
- [Learning to Rank for Information Retrieval](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) - Microsoft Research, 2010
- [From RankNet to LambdaRank to LambdaMART](https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/) - Microsoft, 2010
- [ListNet: Learning to Rank with Listwise Loss](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf) - Microsoft Research, 2007

### 技术文档
- [BGE Reranker v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3) - Training details
- [Ultimate Guide to Choosing the Best Reranking Model in 2026](https://www.zeroentropy.dev/articles/ultimate-guide-to-choosing-the-best-reranking-model-in-2025)
- [Cohere Rerank Best Practices](https://docs.cohere.com/docs/reranking-best-practices)

### 实现参考
- [FlagEmbedding GitHub](https://github.com/FlagOpen/FlagEmbedding) - BGE训练代码
- [Sentence-Transformers](https://www.sbert.net/docs/pretrained_cross-encoders.html) - Cross-Encoder训练

---

**版本：** v1.0 (2026年标准)
**最后更新：** 2026-02-16
**适用场景：** RAG开发、信息检索、模型训练
