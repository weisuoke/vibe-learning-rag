# 实战代码05：日志过滤与路由

## 学习目标

掌握日志过滤和路由技术，实现灵活的日志分发策略。

---

## 第一步：基于日志级别过滤

### 示例1：只记录特定级别的日志

```python
# examples/logging/36_level_filtering.py
import structlog
import logging

# 配置：只记录WARNING及以上级别
structlog.configure(
    processors=[
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()
    ],
    wrapper_class=structlog.make_filtering_bound_logger(logging.WARNING)
)

logger = structlog.get_logger()

# 这些不会输出
logger.debug("debug_message")
logger.info("info_message")

# 这些会输出
logger.warning("warning_message")
logger.error("error_message")
logger.critical("critical_message")
```

---

## 第二步：基于路径过滤

### 示例2：跳过健康检查和静态资源

```python
# examples/logging/37_path_filtering.py
import uuid
from fastapi import FastAPI, Request
import structlog

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()
    ]
)

app = FastAPI()
logger = structlog.get_logger()

# 不需要记录日志的路径
SKIP_PATHS = {
    "/health",
    "/metrics",
    "/favicon.ico",
    "/robots.txt"
}

# 不需要记录日志的路径前缀
SKIP_PATH_PREFIXES = (
    "/static/",
    "/assets/",
    "/_next/"
)

@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    # 检查是否应该跳过
    if request.url.path in SKIP_PATHS:
        return await call_next(request)

    if request.url.path.startswith(SKIP_PATH_PREFIXES):
        return await call_next(request)

    # 正常记录日志
    request_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(request_id=request_id)

    logger.info("request_start", path=request.url.path)

    response = await call_next(request)

    logger.info("request_end", status_code=response.status_code)

    structlog.contextvars.clear_contextvars()

    return response

@app.get("/")
async def root():
    return {"message": "Hello"}

@app.get("/health")
async def health():
    return {"status": "ok"}

@app.get("/static/style.css")
async def static_file():
    return {"content": "css"}
```

---

## 第三步：基于采样过滤

### 示例3：高频日志采样

```python
# examples/logging/38_sampling.py
import uuid
import random
from fastapi import FastAPI, Request
import structlog

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()
    ]
)

app = FastAPI()
logger = structlog.get_logger()

# 采样配置
SAMPLING_RULES = {
    "/health": 0.01,      # 1%采样
    "/metrics": 0.01,     # 1%采样
    "/api/search": 0.1,   # 10%采样
    # 其他路径：100%记录
}

@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    # 获取采样率
    sampling_rate = SAMPLING_RULES.get(request.url.path, 1.0)

    # 决定是否记录日志
    should_log = random.random() < sampling_rate

    if not should_log:
        return await call_next(request)

    # 记录日志
    request_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(
        request_id=request_id,
        sampled=True,
        sampling_rate=sampling_rate
    )

    logger.info("request_start", path=request.url.path)

    response = await call_next(request)

    logger.info("request_end", status_code=response.status_code)

    structlog.contextvars.clear_contextvars()

    return response

@app.get("/")
async def root():
    return {"message": "Hello"}

@app.get("/health")
async def health():
    return {"status": "ok"}
```

---

## 第四步：基于条件过滤

### 示例4：只记录慢请求和错误

```python
# examples/logging/39_conditional_logging.py
import uuid
import time
from fastapi import FastAPI, Request
import structlog

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()
    ]
)

app = FastAPI()
logger = structlog.get_logger()

# 慢请求阈值（毫秒）
SLOW_REQUEST_THRESHOLD_MS = 1000

@app.middleware("http")
async def conditional_logging_middleware(request: Request, call_next):
    request_id = str(uuid.uuid4())
    start_time = time.time()

    # 绑定上下文（但不记录日志）
    structlog.contextvars.bind_contextvars(request_id=request_id)

    response = await call_next(request)

    duration_ms = (time.time() - start_time) * 1000

    # 只记录慢请求或错误
    if duration_ms > SLOW_REQUEST_THRESHOLD_MS or response.status_code >= 400:
        logger.warning("request_logged",
            path=request.url.path,
            status_code=response.status_code,
            duration_ms=duration_ms,
            reason="slow" if duration_ms > SLOW_REQUEST_THRESHOLD_MS else "error"
        )

    structlog.contextvars.clear_contextvars()

    return response

@app.get("/fast")
async def fast():
    return {"message": "Fast"}

@app.get("/slow")
async def slow():
    import asyncio
    await asyncio.sleep(2)
    return {"message": "Slow"}

@app.get("/error")
async def error():
    from fastapi import HTTPException
    raise HTTPException(status_code=500, detail="Error")
```

---

## 第五步：日志路由到不同目标

### 示例5：错误日志单独存储

```python
# examples/logging/40_log_routing.py
import structlog
import logging
from logging.handlers import RotatingFileHandler

# 创建多个handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

# 所有日志
all_logs_handler = RotatingFileHandler(
    "logs/all.log",
    maxBytes=10*1024*1024,
    backupCount=5
)
all_logs_handler.setLevel(logging.INFO)

# 只记录错误
error_handler = RotatingFileHandler(
    "logs/error.log",
    maxBytes=10*1024*1024,
    backupCount=5
)
error_handler.setLevel(logging.ERROR)

# 配置标准库logging
logging.basicConfig(
    handlers=[console_handler, all_logs_handler, error_handler],
    level=logging.INFO,
    format="%(message)s"
)

# 配置structlog
structlog.configure(
    processors=[
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
    logger_factory=structlog.stdlib.LoggerFactory()
)

logger = structlog.get_logger()

# 测试
logger.info("info_message")      # 输出到：控制台 + all.log
logger.warning("warning_message")  # 输出到：控制台 + all.log
logger.error("error_message")    # 输出到：控制台 + all.log + error.log
```

---

## 第六步：基于事件类型路由

### 示例6：不同事件类型路由到不同文件

```python
# examples/logging/41_event_routing.py
import structlog
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path

# 创建日志目录
Path("logs").mkdir(exist_ok=True)

# 自定义过滤器
class EventFilter(logging.Filter):
    """基于事件类型的过滤器"""

    def __init__(self, event_types):
        super().__init__()
        self.event_types = event_types

    def filter(self, record):
        # 从日志记录中提取event字段
        if hasattr(record, 'event'):
            return record.event in self.event_types
        return False

# 创建不同的handler
# LLM调用日志
llm_handler = RotatingFileHandler("logs/llm.log", maxBytes=10*1024*1024, backupCount=5)
llm_handler.addFilter(EventFilter({"llm_call_start", "llm_call_success", "llm_call_failed"}))

# RAG检索日志
rag_handler = RotatingFileHandler("logs/rag.log", maxBytes=10*1024*1024, backupCount=5)
rag_handler.addFilter(EventFilter({"rag_search_start", "rag_search_success"}))

# HTTP请求日志
http_handler = RotatingFileHandler("logs/http.log", maxBytes=10*1024*1024, backupCount=5)
http_handler.addFilter(EventFilter({"request_start", "request_end"}))

# 所有日志
all_handler = RotatingFileHandler("logs/all.log", maxBytes=10*1024*1024, backupCount=5)

# 配置logging
logging.basicConfig(
    handlers=[llm_handler, rag_handler, http_handler, all_handler],
    level=logging.INFO,
    format="%(message)s"
)

# 配置structlog
structlog.configure(
    processors=[
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
    logger_factory=structlog.stdlib.LoggerFactory()
)

logger = structlog.get_logger()

# 测试
logger.info("request_start", path="/api/chat")  # → http.log + all.log
logger.info("rag_search_start", query="Python")  # → rag.log + all.log
logger.info("llm_call_start", model="gpt-4")    # → llm.log + all.log
logger.info("request_end", status_code=200)     # → http.log + all.log
```

---

## 第七步：自定义过滤处理器

### 示例7：基于字段值过滤

```python
# examples/logging/42_custom_filter_processor.py
import structlog

def filter_sensitive_paths(logger, method_name, event_dict):
    """过滤敏感路径的日志"""
    sensitive_paths = ["/admin", "/internal", "/debug"]

    path = event_dict.get("path", "")

    # 如果是敏感路径，不记录详细信息
    if any(path.startswith(p) for p in sensitive_paths):
        # 只保留基本信息
        return {
            "event": event_dict.get("event"),
            "path": "[REDACTED]",
            "timestamp": event_dict.get("timestamp")
        }

    return event_dict

def filter_large_payloads(logger, method_name, event_dict):
    """过滤大payload"""
    max_size = 1000

    for key in ["body", "response", "data"]:
        if key in event_dict:
            value = event_dict[key]
            if isinstance(value, str) and len(value) > max_size:
                event_dict[key] = value[:max_size] + "...[truncated]"

    return event_dict

# 配置
structlog.configure(
    processors=[
        filter_sensitive_paths,      # 自定义过滤器1
        filter_large_payloads,        # 自定义过滤器2
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()

# 测试
logger.info("request", path="/api/users", body="normal data")
logger.info("request", path="/admin/users", body="sensitive data")
logger.info("request", path="/api/upload", body="x" * 2000)
```

---

## 第八步：动态日志级别调整

### 示例8：运行时调整日志级别

```python
# examples/logging/43_dynamic_log_level.py
import os
import structlog
import logging
from fastapi import FastAPI, HTTPException

app = FastAPI()

# 全局日志级别
current_log_level = logging.INFO

def setup_logging(log_level: int = logging.INFO):
    """配置日志系统"""
    global current_log_level
    current_log_level = log_level

    logging.basicConfig(
        level=log_level,
        format="%(message)s"
    )

    structlog.configure(
        processors=[
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.dev.ConsoleRenderer()
        ],
        wrapper_class=structlog.make_filtering_bound_logger(log_level),
        logger_factory=structlog.stdlib.LoggerFactory()
    )

# 初始化
setup_logging()

logger = structlog.get_logger()

@app.post("/admin/log-level")
async def set_log_level(level: str, admin_token: str):
    """动态调整日志级别"""
    # 验证管理员token
    if admin_token != os.getenv("ADMIN_TOKEN", "secret"):
        raise HTTPException(status_code=401, detail="Unauthorized")

    # 验证日志级别
    level_map = {
        "DEBUG": logging.DEBUG,
        "INFO": logging.INFO,
        "WARNING": logging.WARNING,
        "ERROR": logging.ERROR,
        "CRITICAL": logging.CRITICAL
    }

    if level not in level_map:
        raise HTTPException(status_code=400, detail="Invalid log level")

    # 调整日志级别
    new_level = level_map[level]
    setup_logging(new_level)

    logger.info("log_level_changed",
        old_level=logging.getLevelName(current_log_level),
        new_level=level
    )

    return {
        "message": f"Log level set to {level}",
        "old_level": logging.getLevelName(current_log_level),
        "new_level": level
    }

@app.get("/")
async def root():
    logger.debug("debug_message")
    logger.info("info_message")
    return {"message": "Hello"}
```

**使用：**
```bash
# 临时开启DEBUG级别（用于调试）
curl -X POST http://localhost:8000/admin/log-level \
  -H "Content-Type: application/json" \
  -d '{"level": "DEBUG", "admin_token": "secret"}'

# 恢复INFO级别
curl -X POST http://localhost:8000/admin/log-level \
  -H "Content-Type: application/json" \
  -d '{"level": "INFO", "admin_token": "secret"}'
```

---

## 第九步：完整的日志过滤和路由系统

### 示例9：生产级日志管理

```python
# config/log_routing.py
"""
日志过滤和路由配置

使用方法：
    from config.log_routing import setup_log_routing

    setup_log_routing()
"""

import structlog
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Set, Dict, Callable

class LogRoutingConfig:
    """日志路由配置"""

    def __init__(self):
        # 跳过的路径
        self.skip_paths: Set[str] = {"/health", "/metrics"}

        # 采样规则
        self.sampling_rules: Dict[str, float] = {
            "/health": 0.01,
            "/metrics": 0.01
        }

        # 慢请求阈值
        self.slow_request_threshold_ms: float = 1000

        # 日志目录
        self.log_dir: Path = Path("logs")

        # 日志文件配置
        self.log_files = {
            "all": "all.log",
            "error": "error.log",
            "slow": "slow.log",
            "llm": "llm.log",
            "rag": "rag.log"
        }

class EventFilter(logging.Filter):
    """基于事件类型的过滤器"""

    def __init__(self, event_types: Set[str]):
        super().__init__()
        self.event_types = event_types

    def filter(self, record):
        if hasattr(record, 'event'):
            return record.event in self.event_types
        return True

def create_handler(
    filename: str,
    level: int = logging.INFO,
    event_filter: Callable = None
) -> RotatingFileHandler:
    """创建日志handler"""
    handler = RotatingFileHandler(
        filename,
        maxBytes=10*1024*1024,
        backupCount=5
    )
    handler.setLevel(level)

    if event_filter:
        handler.addFilter(event_filter)

    return handler

def setup_log_routing(config: LogRoutingConfig = None):
    """配置日志路由"""
    if config is None:
        config = LogRoutingConfig()

    # 创建日志目录
    config.log_dir.mkdir(exist_ok=True)

    # 创建handlers
    handlers = []

    # 控制台handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    handlers.append(console_handler)

    # 所有日志
    all_handler = create_handler(
        config.log_dir / config.log_files["all"]
    )
    handlers.append(all_handler)

    # 错误日志
    error_handler = create_handler(
        config.log_dir / config.log_files["error"],
        level=logging.ERROR
    )
    handlers.append(error_handler)

    # LLM调用日志
    llm_handler = create_handler(
        config.log_dir / config.log_files["llm"],
        event_filter=EventFilter({
            "llm_call_start",
            "llm_call_success",
            "llm_call_failed"
        })
    )
    handlers.append(llm_handler)

    # RAG检索日志
    rag_handler = create_handler(
        config.log_dir / config.log_files["rag"],
        event_filter=EventFilter({
            "rag_search_start",
            "rag_search_success"
        })
    )
    handlers.append(rag_handler)

    # 配置标准库logging
    logging.basicConfig(
        handlers=handlers,
        level=logging.INFO,
        format="%(message)s"
    )

    # 配置structlog
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer()
        ],
        logger_factory=structlog.stdlib.LoggerFactory()
    )

    logger = structlog.get_logger()
    logger.info("log_routing_configured",
        log_dir=str(config.log_dir),
        handlers_count=len(handlers)
    )

# 使用示例
if __name__ == "__main__":
    setup_log_routing()

    logger = structlog.get_logger()

    # 测试不同类型的日志
    logger.info("request_start", path="/api/chat")
    logger.info("rag_search_start", query="Python")
    logger.info("llm_call_start", model="gpt-4")
    logger.error("api_failed", error="timeout")
```

---

## 总结

### 核心要点

1. **日志过滤**
   - 基于级别过滤
   - 基于路径过滤
   - 基于采样过滤
   - 基于条件过滤

2. **日志路由**
   - 错误日志单独存储
   - 基于事件类型路由
   - 多目标输出

3. **动态调整**
   - 运行时调整日志级别
   - 临时开启DEBUG模式

4. **自定义过滤器**
   - 敏感信息过滤
   - 大payload截断
   - 事件类型过滤

### 最佳实践

1. 跳过高频低价值日志（健康检查）
2. 采样高频日志减少存储
3. 错误日志单独存储便于排查
4. 支持运行时调整日志级别
5. 使用自定义过滤器保护敏感信息

### 下一步

- 【实战代码06】：手写结构化日志
- 【实战代码07】：生产级日志系统
