# 核心概念2：自定义日志策略

## 概述

`astream_events()` 适合开发调试，但生产环境需要更灵活的日志策略。`BaseCallbackHandler` 让你可以：

- 记录到文件或数据库
- 自定义日志格式
- 统计性能指标
- 错误分类和处理

---

## BaseCallbackHandler 架构

### 核心概念

`BaseCallbackHandler` 是一个基类，定义了链执行过程中的回调接口。

**工作原理**：
1. 继承 `BaseCallbackHandler`
2. 实现需要的回调方法
3. 在链执行时传入回调实例

```python
from langchain_core.callbacks import BaseCallbackHandler

class MyHandler(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        print(f"Chain started: {inputs}")

# 使用
chain.invoke(input, config={"callbacks": [MyHandler()]})
```

---

### 回调方法完整列表

#### 链回调 (Chain Callbacks)

```python
class ChainCallbacks(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        """链开始执行"""
        pass

    def on_chain_end(self, outputs, **kwargs):
        """链执行完成"""
        pass

    def on_chain_error(self, error, **kwargs):
        """链执行出错"""
        pass
```

**参数说明**：
- `serialized`: 链的序列化信息
- `inputs`: 输入数据
- `outputs`: 输出数据
- `error`: 错误对象
- `**kwargs`: 额外参数（run_id, parent_run_id, tags等）

---

#### LLM回调 (LLM Callbacks)

```python
class LLMCallbacks(BaseCallbackHandler):
    def on_llm_start(self, serialized, prompts, **kwargs):
        """LLM开始调用"""
        pass

    def on_llm_new_token(self, token, **kwargs):
        """LLM生成新token（流式）"""
        pass

    def on_llm_end(self, response, **kwargs):
        """LLM调用完成"""
        pass

    def on_llm_error(self, error, **kwargs):
        """LLM调用出错"""
        pass
```

**参数说明**：
- `prompts`: 发送给LLM的prompt列表
- `token`: 新生成的token
- `response`: LLMResult对象，包含完整响应

---

#### 聊天模型回调 (Chat Model Callbacks)

```python
class ChatModelCallbacks(BaseCallbackHandler):
    def on_chat_model_start(self, serialized, messages, **kwargs):
        """聊天模型开始"""
        pass

    def on_chat_model_end(self, response, **kwargs):
        """聊天模型完成"""
        pass
```

**注意**：聊天模型也会触发 `on_llm_*` 回调。

---

#### 工具回调 (Tool Callbacks)

```python
class ToolCallbacks(BaseCallbackHandler):
    def on_tool_start(self, serialized, input_str, **kwargs):
        """工具开始执行"""
        pass

    def on_tool_end(self, output, **kwargs):
        """工具执行完成"""
        pass

    def on_tool_error(self, error, **kwargs):
        """工具执行出错"""
        pass
```

---

#### 检索器回调 (Retriever Callbacks)

```python
class RetrieverCallbacks(BaseCallbackHandler):
    def on_retriever_start(self, serialized, query, **kwargs):
        """检索器开始"""
        pass

    def on_retriever_end(self, documents, **kwargs):
        """检索器完成"""
        pass

    def on_retriever_error(self, error, **kwargs):
        """检索器出错"""
        pass
```

---

## 同步 vs 异步回调

### 同步回调（默认）

```python
from langchain_core.callbacks import BaseCallbackHandler
import time

class SyncHandler(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        time.sleep(1)  # 会阻塞链执行
        print("Chain started")

# 使用同步调用
result = chain.invoke(input, config={"callbacks": [SyncHandler()]})
```

**问题**：同步回调会阻塞链执行！

---

### 异步回调（推荐）

```python
from langchain_core.callbacks import AsyncCallbackHandler
import asyncio

class AsyncHandler(AsyncCallbackHandler):
    async def on_chain_start(self, serialized, inputs, **kwargs):
        await asyncio.sleep(1)  # 不会阻塞
        print("Chain started")

# 使用异步调用
result = await chain.ainvoke(input, config={"callbacks": [AsyncHandler()]})
```

**优点**：异步回调不会阻塞链执行。

---

### 对比表

| 特性 | 同步回调 | 异步回调 |
|------|----------|----------|
| **基类** | `BaseCallbackHandler` | `AsyncCallbackHandler` |
| **方法** | 普通方法 | `async` 方法 |
| **阻塞** | 会阻塞链执行 | 不会阻塞 |
| **适用场景** | 快速操作 | 慢速操作（IO、网络） |
| **链调用** | `invoke()` | `ainvoke()` |

---

## 自定义回调处理器实现

### 示例1：文件日志处理器

```python
from langchain_core.callbacks import BaseCallbackHandler
from datetime import datetime
import json

class FileLogHandler(BaseCallbackHandler):
    """记录到JSON Lines文件"""

    def __init__(self, log_file="chain_logs.jsonl"):
        self.log_file = log_file

    def _write_log(self, event_type, data):
        """写入日志"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "event": event_type,
            "data": data
        }
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

    def on_chain_start(self, serialized, inputs, **kwargs):
        self._write_log("chain_start", {
            "inputs": inputs,
            "run_id": kwargs.get("run_id")
        })

    def on_chain_end(self, outputs, **kwargs):
        self._write_log("chain_end", {
            "outputs": str(outputs)[:200],  # 限制长度
            "run_id": kwargs.get("run_id")
        })

    def on_chain_error(self, error, **kwargs):
        self._write_log("chain_error", {
            "error": str(error),
            "run_id": kwargs.get("run_id")
        })

# 使用
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()

prompt = ChatPromptTemplate.from_template("回答问题: {question}")
model = ChatOpenAI(model="gpt-4o-mini")
chain = prompt | model

result = chain.invoke(
    {"question": "什么是LCEL?"},
    config={"callbacks": [FileLogHandler("my_logs.jsonl")]}
)

print(result.content)
```

**日志文件示例**：
```json
{"timestamp": "2026-02-20T14:30:00", "event": "chain_start", "data": {"inputs": {"question": "什么是LCEL?"}, "run_id": "..."}}
{"timestamp": "2026-02-20T14:30:02", "event": "chain_end", "data": {"outputs": "LCEL是...", "run_id": "..."}}
```

---

### 示例2：性能追踪处理器

```python
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerformanceHandler(BaseCallbackHandler):
    """追踪性能指标"""

    def __init__(self):
        self.start_times = {}
        self.metrics = {}

    def on_chain_start(self, serialized, inputs, **kwargs):
        run_id = kwargs.get("run_id")
        self.start_times[run_id] = time.time()
        logger.info(f"Chain {run_id} started")

    def on_chain_end(self, outputs, **kwargs):
        run_id = kwargs.get("run_id")
        if run_id in self.start_times:
            duration = time.time() - self.start_times[run_id]
            self.metrics[run_id] = {"duration": duration}
            logger.info(f"Chain {run_id} completed in {duration:.2f}s")

    def on_llm_start(self, serialized, prompts, **kwargs):
        run_id = kwargs.get("run_id")
        self.start_times[f"llm_{run_id}"] = time.time()

    def on_llm_end(self, response, **kwargs):
        run_id = kwargs.get("run_id")
        key = f"llm_{run_id}"
        if key in self.start_times:
            duration = time.time() - self.start_times[key]
            tokens = response.llm_output.get("token_usage", {})
            logger.info(f"LLM call: {duration:.2f}s, tokens: {tokens}")

    def get_metrics(self):
        """获取性能指标"""
        return self.metrics

# 使用
handler = PerformanceHandler()
result = chain.invoke(
    {"question": "什么是LCEL?"},
    config={"callbacks": [handler]}
)

print(f"Metrics: {handler.get_metrics()}")
```

---

### 示例3：异步数据库日志处理器

```python
from langchain_core.callbacks import AsyncCallbackHandler
import asyncio
import aiosqlite

class AsyncDBLogHandler(AsyncCallbackHandler):
    """异步记录到SQLite数据库"""

    def __init__(self, db_path="chain_logs.db"):
        self.db_path = db_path
        asyncio.create_task(self._init_db())

    async def _init_db(self):
        """初始化数据库"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute("""
                CREATE TABLE IF NOT EXISTS logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    event TEXT,
                    run_id TEXT,
                    data TEXT
                )
            """)
            await db.commit()

    async def _log(self, event, run_id, data):
        """写入日志"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute(
                "INSERT INTO logs (timestamp, event, run_id, data) VALUES (?, ?, ?, ?)",
                (datetime.now().isoformat(), event, run_id, str(data))
            )
            await db.commit()

    async def on_chain_start(self, serialized, inputs, **kwargs):
        await self._log("chain_start", kwargs.get("run_id"), inputs)

    async def on_chain_end(self, outputs, **kwargs):
        await self._log("chain_end", kwargs.get("run_id"), str(outputs)[:200])

# 使用
result = await chain.ainvoke(
    {"question": "什么是LCEL?"},
    config={"callbacks": [AsyncDBLogHandler()]}
)
```

---

### 示例4：错误处理和分类

```python
class ErrorHandler(BaseCallbackHandler):
    """错误处理和分类"""

    def __init__(self):
        self.errors = []

    def on_chain_error(self, error, **kwargs):
        """链错误"""
        self._handle_error("chain", error, kwargs)

    def on_llm_error(self, error, **kwargs):
        """LLM错误"""
        self._handle_error("llm", error, kwargs)

    def on_tool_error(self, error, **kwargs):
        """工具错误"""
        self._handle_error("tool", error, kwargs)

    def _handle_error(self, error_type, error, kwargs):
        """统一错误处理"""
        error_info = {
            "type": error_type,
            "error": str(error),
            "error_class": error.__class__.__name__,
            "run_id": kwargs.get("run_id"),
            "timestamp": datetime.now().isoformat()
        }

        # 分类错误
        if "rate limit" in str(error).lower():
            error_info["category"] = "rate_limit"
        elif "timeout" in str(error).lower():
            error_info["category"] = "timeout"
        elif "authentication" in str(error).lower():
            error_info["category"] = "auth"
        else:
            error_info["category"] = "unknown"

        self.errors.append(error_info)
        logger.error(f"Error: {error_info}")

    def get_errors(self):
        """获取错误列表"""
        return self.errors

# 使用
handler = ErrorHandler()
try:
    result = chain.invoke(
        {"question": "什么是LCEL?"},
        config={"callbacks": [handler]}
    )
except Exception as e:
    print(f"Errors: {handler.get_errors()}")
```

---

## 日志记录策略

### 策略1：结构化日志

使用结构化格式（JSON）记录日志，方便查询和分析。

```python
import json
import logging

class StructuredLogHandler(BaseCallbackHandler):
    """结构化日志"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.logger.info(json.dumps({
            "event": "chain_start",
            "inputs": inputs,
            "run_id": kwargs.get("run_id"),
            "tags": kwargs.get("tags", [])
        }))
```

---

### 策略2：日志级别

根据重要性设置不同的日志级别。

```python
class LeveledLogHandler(BaseCallbackHandler):
    """分级日志"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.logger.debug(f"Chain started: {inputs}")  # DEBUG

    def on_chain_end(self, outputs, **kwargs):
        self.logger.info(f"Chain completed")  # INFO

    def on_chain_error(self, error, **kwargs):
        self.logger.error(f"Chain error: {error}")  # ERROR
```

---

### 策略3：采样日志

只记录部分请求，减少日志量。

```python
import random

class SampledLogHandler(BaseCallbackHandler):
    """采样日志"""

    def __init__(self, sample_rate=0.1):
        self.sample_rate = sample_rate
        self.should_log = random.random() < sample_rate

    def on_chain_start(self, serialized, inputs, **kwargs):
        if self.should_log:
            logger.info(f"Chain started: {inputs}")

    def on_chain_end(self, outputs, **kwargs):
        if self.should_log:
            logger.info(f"Chain completed: {outputs}")
```

---

### 策略4：上下文传播

在分布式系统中传播上下文信息。

```python
class ContextPropagationHandler(BaseCallbackHandler):
    """上下文传播"""

    def __init__(self, trace_id=None, user_id=None):
        self.trace_id = trace_id or self._generate_trace_id()
        self.user_id = user_id

    def _generate_trace_id(self):
        import uuid
        return str(uuid.uuid4())

    def on_chain_start(self, serialized, inputs, **kwargs):
        logger.info(f"[trace_id={self.trace_id}] [user_id={self.user_id}] Chain started")

    def on_chain_end(self, outputs, **kwargs):
        logger.info(f"[trace_id={self.trace_id}] [user_id={self.user_id}] Chain completed")
```

---

## 多个回调处理器

可以同时使用多个回调处理器：

```python
# 组合多个处理器
handlers = [
    FileLogHandler("logs.jsonl"),
    PerformanceHandler(),
    ErrorHandler()
]

result = chain.invoke(
    {"question": "什么是LCEL?"},
    config={"callbacks": handlers}
)
```

**执行顺序**：按列表顺序依次执行。

---

## 最佳实践

### 1. 使用异步回调处理慢速操作

```python
# ✅ 正确：异步处理
class AsyncLogHandler(AsyncCallbackHandler):
    async def on_chain_start(self, serialized, inputs, **kwargs):
        await self._write_to_database(inputs)

# ❌ 错误：同步处理慢速操作
class SyncLogHandler(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        self._write_to_database(inputs)  # 会阻塞
```

---

### 2. 限制日志大小

```python
def on_chain_end(self, outputs, **kwargs):
    # 限制输出长度
    output_str = str(outputs)[:200]
    logger.info(f"Output: {output_str}")
```

---

### 3. 错误处理

```python
def on_chain_start(self, serialized, inputs, **kwargs):
    try:
        self._write_log(inputs)
    except Exception as e:
        logger.error(f"Failed to write log: {e}")
        # 不要让日志错误影响链执行
```

---

### 4. 使用上下文管理器

```python
class ResourceHandler(BaseCallbackHandler):
    def __init__(self):
        self.file = open("logs.txt", "a")

    def __del__(self):
        self.file.close()

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.file.write(f"Started: {inputs}\n")
        self.file.flush()
```

---

## 参考资源

### 官方文档
1. **LangChain Callbacks**: https://python.langchain.com/docs/modules/callbacks/
2. **BaseCallbackHandler API**: https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html

### 源码参考
1. **Callback Manager**: `langchain/libs/core/langchain_core/callbacks/manager.py`
2. **Base Callbacks**: `langchain/libs/core/langchain_core/callbacks/base.py`

---

## 总结

**核心要点**：

1. **BaseCallbackHandler**：自定义日志的基础
2. **异步优先**：慢速操作使用 `AsyncCallbackHandler`
3. **结构化日志**：使用JSON格式，方便查询
4. **错误处理**：不要让日志错误影响链执行
5. **多处理器**：可以组合多个处理器

**记住**：回调处理器是生产环境日志的核心工具，合理使用可以大大提高系统的可观测性。

---

**版本信息**
- LangChain: v0.3+ (2025-2026)
- Python: 3.13+
- 最后更新: 2026-02-20
