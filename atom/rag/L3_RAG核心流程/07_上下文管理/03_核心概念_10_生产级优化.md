# 核心概念10：生产级优化

> **监控、调优、部署的完整方案**

---

## 什么是生产级优化？

**生产级优化** 是指将上下文管理系统从开发环境部署到生产环境，并持续监控、调优的完整过程。

**核心目标**：
- 成本可控
- 性能稳定
- 质量保证
- 可观测性

---

## 成本优化

### 优化1：Token使用监控

```python
class TokenUsageMonitor:
    """Token使用监控"""
    def __init__(self):
        self.usage_log = []
        self.daily_budget = 100.0  # $100/天

    def log_usage(
        self,
        session_id: str,
        prompt_tokens: int,
        completion_tokens: int,
        model: str = "gpt-4-turbo"
    ):
        """记录Token使用"""
        # 计算成本
        prices = {
            "gpt-4-turbo": {"input": 10, "output": 30},
            "claude-3-sonnet": {"input": 15, "output": 75}
        }

        price = prices.get(model, prices["gpt-4-turbo"])
        cost = (prompt_tokens / 1_000_000) * price["input"] + \
               (completion_tokens / 1_000_000) * price["output"]

        self.usage_log.append({
            "timestamp": datetime.now(),
            "session_id": session_id,
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "model": model,
            "cost": cost
        })

        # 检查预算
        self._check_budget()

    def _check_budget(self):
        """检查预算"""
        today = datetime.now().date()
        today_usage = [
            log for log in self.usage_log
            if log["timestamp"].date() == today
        ]

        today_cost = sum(log["cost"] for log in today_usage)

        if today_cost > self.daily_budget:
            self._send_alert(f"⚠️ 今日成本超预算: ${today_cost:.2f} > ${self.daily_budget}")

        elif today_cost > self.daily_budget * 0.8:
            self._send_alert(f"⚠️ 今日成本接近预算: ${today_cost:.2f} (80%)")

    def get_daily_report(self) -> dict:
        """生成每日报告"""
        today = datetime.now().date()
        today_usage = [
            log for log in self.usage_log
            if log["timestamp"].date() == today
        ]

        if not today_usage:
            return {"total_cost": 0, "total_queries": 0}

        return {
            "total_cost": sum(log["cost"] for log in today_usage),
            "total_queries": len(today_usage),
            "avg_cost_per_query": sum(log["cost"] for log in today_usage) / len(today_usage),
            "total_prompt_tokens": sum(log["prompt_tokens"] for log in today_usage),
            "total_completion_tokens": sum(log["completion_tokens"] for log in today_usage)
        }
```

### 优化2：智能缓存策略

```python
from functools import lru_cache
import hashlib

class IntelligentCache:
    """智能缓存系统"""
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.cache = {}
        self.max_size = max_size
        self.ttl = ttl  # 秒
        self.hits = 0
        self.misses = 0

    def get(self, key: str) -> any:
        """获取缓存"""
        if key in self.cache:
            entry = self.cache[key]
            # 检查是否过期
            if datetime.now().timestamp() - entry["timestamp"] < self.ttl:
                self.hits += 1
                return entry["value"]
            else:
                # 过期，删除
                del self.cache[key]

        self.misses += 1
        return None

    def set(self, key: str, value: any):
        """设置缓存"""
        # 如果缓存满了，删除最旧的
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]["timestamp"])
            del self.cache[oldest_key]

        self.cache[key] = {
            "value": value,
            "timestamp": datetime.now().timestamp()
        }

    def get_hit_rate(self) -> float:
        """获取命中率"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0

    def generate_key(self, query: str, documents: list[str]) -> str:
        """生成缓存键"""
        content = query + "".join(documents)
        return hashlib.md5(content.encode()).hexdigest()
```

### 优化3：批量处理

```python
class BatchProcessor:
    """批量处理器"""
    def __init__(self, batch_size: int = 10, max_wait: float = 1.0):
        self.batch_size = batch_size
        self.max_wait = max_wait
        self.queue = []
        self.last_process_time = time.time()

    async def add_request(self, request: dict) -> any:
        """添加请求到批次"""
        self.queue.append(request)

        # 检查是否应该处理批次
        should_process = (
            len(self.queue) >= self.batch_size or
            time.time() - self.last_process_time >= self.max_wait
        )

        if should_process:
            return await self._process_batch()
        else:
            # 等待更多请求
            await asyncio.sleep(0.1)
            return await self.add_request(request)

    async def _process_batch(self) -> list:
        """处理批次"""
        if not self.queue:
            return []

        batch = self.queue[:self.batch_size]
        self.queue = self.queue[self.batch_size:]
        self.last_process_time = time.time()

        # 批量处理
        results = await self._batch_llm_call(batch)

        return results
```

---

## 性能优化

### 优化1：异步处理

```python
import asyncio

class AsyncContextManager:
    """异步上下文管理器"""
    def __init__(self):
        self.llm = AsyncOpenAI()
        self.vector_store = AsyncChromaDB()

    async def process_query(self, query: str) -> str:
        """异步处理查询"""
        # 并行执行检索和其他操作
        retrieval_task = self.vector_store.asimilarity_search(query, k=5)
        embedding_task = self.llm.aembed(query)

        # 等待所有任务完成
        documents, query_embedding = await asyncio.gather(
            retrieval_task,
            embedding_task
        )

        # 构建上下文
        context = "\n\n".join([doc.page_content for doc in documents])

        # 生成答案
        answer = await self.llm.agenerate(f"Context: {context}\n\nQuestion: {query}")

        return answer

    async def process_multiple_queries(self, queries: list[str]) -> list[str]:
        """并行处理多个查询"""
        tasks = [self.process_query(query) for query in queries]
        results = await asyncio.gather(*tasks)
        return results
```

### 优化2：连接池管理

```python
from contextlib import asynccontextmanager

class ConnectionPool:
    """连接池管理"""
    def __init__(self, max_connections: int = 10):
        self.max_connections = max_connections
        self.connections = []
        self.available = asyncio.Queue()

    async def initialize(self):
        """初始化连接池"""
        for _ in range(self.max_connections):
            conn = await self._create_connection()
            self.connections.append(conn)
            await self.available.put(conn)

    async def _create_connection(self):
        """创建连接"""
        # 实际实现中创建数据库或API连接
        return {"id": len(self.connections), "created_at": datetime.now()}

    @asynccontextmanager
    async def get_connection(self):
        """获取连接"""
        conn = await self.available.get()
        try:
            yield conn
        finally:
            await self.available.put(conn)

    async def close_all(self):
        """关闭所有连接"""
        for conn in self.connections:
            # 关闭连接
            pass
```

### 优化3：预加载和预热

```python
class Preloader:
    """预加载器"""
    def __init__(self):
        self.cache = IntelligentCache()
        self.common_queries = []

    async def preload_common_queries(self, queries: list[str]):
        """预加载常见查询"""
        self.common_queries = queries

        for query in queries:
            # 预先检索和缓存
            documents = await self.vector_store.asimilarity_search(query, k=5)
            context = self._build_context(documents)

            # 缓存结果
            cache_key = self.cache.generate_key(query, [doc.page_content for doc in documents])
            self.cache.set(cache_key, context)

    async def warmup(self):
        """预热系统"""
        # 预加载Embedding模型
        await self.embedding_model.load()

        # 预加载向量索引
        await self.vector_store.load_index()

        # 预加载常见查询
        await self.preload_common_queries(self.common_queries)
```

---

## 监控与告警

### 监控指标

```python
from prometheus_client import Counter, Histogram, Gauge

class MetricsCollector:
    """指标收集器"""
    def __init__(self):
        # 计数器
        self.query_counter = Counter(
            'rag_queries_total',
            'Total number of RAG queries'
        )

        self.error_counter = Counter(
            'rag_errors_total',
            'Total number of errors',
            ['error_type']
        )

        # 直方图
        self.latency_histogram = Histogram(
            'rag_latency_seconds',
            'RAG query latency in seconds',
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
        )

        self.token_histogram = Histogram(
            'rag_tokens_used',
            'Tokens used per query',
            buckets=[1000, 2000, 5000, 10000, 20000]
        )

        # 仪表
        self.active_sessions = Gauge(
            'rag_active_sessions',
            'Number of active sessions'
        )

        self.cache_hit_rate = Gauge(
            'rag_cache_hit_rate',
            'Cache hit rate'
        )

    def record_query(self, latency: float, tokens: int):
        """记录查询"""
        self.query_counter.inc()
        self.latency_histogram.observe(latency)
        self.token_histogram.observe(tokens)

    def record_error(self, error_type: str):
        """记录错误"""
        self.error_counter.labels(error_type=error_type).inc()

    def update_cache_hit_rate(self, hit_rate: float):
        """更新缓存命中率"""
        self.cache_hit_rate.set(hit_rate)
```

### 告警系统

```python
class AlertSystem:
    """告警系统"""
    def __init__(self):
        self.thresholds = {
            "latency_p95": 5.0,  # 秒
            "error_rate": 0.05,  # 5%
            "cost_per_day": 100.0,  # $100
            "cache_hit_rate": 0.5  # 50%
        }

        self.alert_channels = []

    def add_channel(self, channel):
        """添加告警渠道"""
        self.alert_channels.append(channel)

    def check_and_alert(self, metrics: dict):
        """检查指标并告警"""
        alerts = []

        # 检查延迟
        if metrics.get("latency_p95", 0) > self.thresholds["latency_p95"]:
            alerts.append({
                "level": "warning",
                "message": f"P95延迟过高: {metrics['latency_p95']:.2f}s"
            })

        # 检查错误率
        if metrics.get("error_rate", 0) > self.thresholds["error_rate"]:
            alerts.append({
                "level": "critical",
                "message": f"错误率过高: {metrics['error_rate']:.2%}"
            })

        # 检查成本
        if metrics.get("cost_per_day", 0) > self.thresholds["cost_per_day"]:
            alerts.append({
                "level": "warning",
                "message": f"每日成本超预算: ${metrics['cost_per_day']:.2f}"
            })

        # 检查缓存命中率
        if metrics.get("cache_hit_rate", 1.0) < self.thresholds["cache_hit_rate"]:
            alerts.append({
                "level": "info",
                "message": f"缓存命中率过低: {metrics['cache_hit_rate']:.2%}"
            })

        # 发送告警
        for alert in alerts:
            self._send_alert(alert)

    def _send_alert(self, alert: dict):
        """发送告警"""
        for channel in self.alert_channels:
            channel.send(alert)
```

---

## A/B测试

### A/B测试框架

```python
import random

class ABTestFramework:
    """A/B测试框架"""
    def __init__(self):
        self.experiments = {}
        self.results = {}

    def create_experiment(
        self,
        name: str,
        variants: dict,
        traffic_split: dict
    ):
        """创建实验"""
        self.experiments[name] = {
            "variants": variants,
            "traffic_split": traffic_split,
            "start_time": datetime.now()
        }

        self.results[name] = {
            variant: {"count": 0, "metrics": []}
            for variant in variants.keys()
        }

    def assign_variant(self, experiment_name: str, user_id: str) -> str:
        """分配变体"""
        experiment = self.experiments[experiment_name]
        traffic_split = experiment["traffic_split"]

        # 基于用户ID的一致性哈希
        hash_value = int(hashlib.md5(user_id.encode()).hexdigest(), 16)
        random.seed(hash_value)

        # 根据流量分配选择变体
        rand = random.random()
        cumulative = 0

        for variant, split in traffic_split.items():
            cumulative += split
            if rand < cumulative:
                return variant

        return list(traffic_split.keys())[0]

    def record_result(
        self,
        experiment_name: str,
        variant: str,
        metrics: dict
    ):
        """记录结果"""
        self.results[experiment_name][variant]["count"] += 1
        self.results[experiment_name][variant]["metrics"].append(metrics)

    def analyze_results(self, experiment_name: str) -> dict:
        """分析结果"""
        results = self.results[experiment_name]
        analysis = {}

        for variant, data in results.items():
            if data["count"] == 0:
                continue

            metrics_list = data["metrics"]

            analysis[variant] = {
                "count": data["count"],
                "avg_latency": sum(m["latency"] for m in metrics_list) / len(metrics_list),
                "avg_cost": sum(m["cost"] for m in metrics_list) / len(metrics_list),
                "avg_quality": sum(m["quality"] for m in metrics_list) / len(metrics_list)
            }

        return analysis

# 使用示例
ab_test = ABTestFramework()

# 创建实验：测试不同的压缩比
ab_test.create_experiment(
    name="compression_ratio_test",
    variants={
        "control": {"compression_ratio": 1.0},
        "variant_a": {"compression_ratio": 0.5},
        "variant_b": {"compression_ratio": 0.25}
    },
    traffic_split={
        "control": 0.34,
        "variant_a": 0.33,
        "variant_b": 0.33
    }
)

# 分配变体
user_id = "user_123"
variant = ab_test.assign_variant("compression_ratio_test", user_id)

# 记录结果
ab_test.record_result(
    "compression_ratio_test",
    variant,
    {"latency": 2.5, "cost": 0.05, "quality": 0.85}
)

# 分析结果
analysis = ab_test.analyze_results("compression_ratio_test")
```

---

## 部署策略

### 蓝绿部署

```python
class BlueGreenDeployment:
    """蓝绿部署"""
    def __init__(self):
        self.blue_version = None
        self.green_version = None
        self.active = "blue"

    def deploy_new_version(self, version: str):
        """部署新版本"""
        if self.active == "blue":
            # 部署到green
            self.green_version = version
            self._deploy_to_green(version)

            # 健康检查
            if self._health_check("green"):
                # 切换流量
                self.active = "green"
                print(f"切换到green版本: {version}")
            else:
                print("健康检查失败，回滚")
                self._rollback()

        else:
            # 部署到blue
            self.blue_version = version
            self._deploy_to_blue(version)

            if self._health_check("blue"):
                self.active = "blue"
                print(f"切换到blue版本: {version}")
            else:
                print("健康检查失败，回滚")
                self._rollback()

    def _health_check(self, environment: str) -> bool:
        """健康检查"""
        # 实际实现中进行健康检查
        return True

    def _rollback(self):
        """回滚"""
        self.active = "blue" if self.active == "green" else "green"
        print(f"回滚到{self.active}版本")
```

### 金丝雀发布

```python
class CanaryDeployment:
    """金丝雀发布"""
    def __init__(self):
        self.stable_version = "v1.0"
        self.canary_version = None
        self.canary_traffic = 0.0

    def start_canary(self, version: str, initial_traffic: float = 0.05):
        """开始金丝雀发布"""
        self.canary_version = version
        self.canary_traffic = initial_traffic
        print(f"开始金丝雀发布: {version}, 流量: {initial_traffic*100}%")

    def increase_traffic(self, increment: float = 0.1):
        """增加金丝雀流量"""
        self.canary_traffic = min(1.0, self.canary_traffic + increment)
        print(f"增加金丝雀流量到: {self.canary_traffic*100}%")

        # 监控指标
        metrics = self._monitor_canary()

        if metrics["error_rate"] > 0.05:
            print("错误率过高，回滚")
            self.rollback()
            return False

        return True

    def promote_canary(self):
        """提升金丝雀为稳定版本"""
        self.stable_version = self.canary_version
        self.canary_version = None
        self.canary_traffic = 0.0
        print(f"金丝雀提升为稳定版本: {self.stable_version}")

    def rollback(self):
        """回滚金丝雀"""
        self.canary_version = None
        self.canary_traffic = 0.0
        print("回滚金丝雀发布")

    def _monitor_canary(self) -> dict:
        """监控金丝雀指标"""
        # 实际实现中收集指标
        return {"error_rate": 0.01, "latency_p95": 2.5}
```

---

## 最佳实践

### 实践1：渐进式优化

```python
# 优化路线图
optimization_roadmap = {
    "phase1_baseline": {
        "features": ["基础RAG", "简单截断"],
        "expected_cost": "$3000/月",
        "expected_quality": "70%"
    },
    "phase2_compression": {
        "features": ["LLMLingua压缩", "缓存"],
        "expected_cost": "$750/月",  # -75%
        "expected_quality": "75%"  # +5%
    },
    "phase3_rerank": {
        "features": ["ReRank重排序", "首尾放置"],
        "expected_cost": "$900/月",  # +20%
        "expected_quality": "88%"  # +13%
    },
    "phase4_dynamic": {
        "features": ["动态窗口", "智能缓存"],
        "expected_cost": "$600/月",  # -33%
        "expected_quality": "90%"  # +2%
    }
}
```

### 实践2：监控仪表板

```python
class MonitoringDashboard:
    """监控仪表板"""
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.alert_system = AlertSystem()

    def get_dashboard_data(self) -> dict:
        """获取仪表板数据"""
        return {
            "overview": {
                "total_queries": self.metrics_collector.query_counter._value.get(),
                "total_errors": self.metrics_collector.error_counter._value.get(),
                "active_sessions": self.metrics_collector.active_sessions._value.get()
            },
            "performance": {
                "latency_p50": self._get_percentile("latency", 0.5),
                "latency_p95": self._get_percentile("latency", 0.95),
                "latency_p99": self._get_percentile("latency", 0.99)
            },
            "cost": {
                "today_cost": self._get_today_cost(),
                "monthly_projection": self._get_monthly_projection()
            },
            "quality": {
                "cache_hit_rate": self.metrics_collector.cache_hit_rate._value.get(),
                "avg_quality_score": self._get_avg_quality()
            }
        }
```

---

## 总结

### 核心要点

1. **成本优化**：监控、缓存、批量处理
2. **性能优化**：异步、连接池、预加载
3. **监控告警**：指标收集、告警系统
4. **A/B测试**：实验框架、数据分析
5. **部署策略**：蓝绿部署、金丝雀发布

### 记忆口诀

**"监控优化测试部署"**

### 下一步

理解了生产级优化后，接下来学习：
- **实战代码**：完整场景实现
- **化骨绵掌**：10张记忆卡片

---

**记住**：生产级优化是持续的过程，不是一次性的任务！
