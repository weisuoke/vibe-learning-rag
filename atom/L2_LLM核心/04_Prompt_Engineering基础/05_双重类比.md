# 双重类比

用熟悉的概念理解 RAG Prompt 设计。

---

## 类比1：RAG Prompt = API 请求

### 前端类比：发送 API 请求

```javascript
// 前端发送 API 请求
const response = await fetch('/api/search', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',  // ← 类似系统提示词：告诉服务器如何处理
  },
  body: JSON.stringify({
    context: searchResults,               // ← 类似上下文注入：提供数据
    query: userInput                      // ← 类似用户问题：具体请求
  })
});
```

```python
# RAG Prompt 结构
messages = [
    {"role": "system", "content": "..."},   # ← headers：配置信息
    {"role": "user", "content": f"""
        参考文档：{context}                   # ← body.context：数据
        问题：{query}                         # ← body.query：请求
    """}
]
```

### 日常生活类比：去餐厅点餐

| RAG Prompt | 餐厅点餐 |
|------------|---------|
| 系统提示词 | 告诉服务员"我要清淡口味、不要辣" |
| 上下文注入 | 服务员给你看的菜单 |
| 用户问题 | "推荐一道适合的菜" |
| LLM 回答 | 服务员的推荐 |

**关键洞察**：就像服务员只能推荐菜单上的菜，LLM 也应该只基于你给的文档回答。

---

## 类比2：系统提示词 = 组件 Props 配置

### 前端类比：React 组件配置

```jsx
// React 组件通过 props 配置行为
<ChatBot
  role="customer-service"           // 角色设定
  dataSource="knowledge-base"       // 信息来源
  fallbackMessage="请联系人工客服"   // 边界处理
  outputFormat="markdown"           // 输出格式
/>
```

```python
# 系统提示词配置 LLM 行为
system_prompt = """
角色：客服助手                      # role
信息来源：知识库文档                 # dataSource
无法回答时：请联系人工客服           # fallbackMessage
输出格式：Markdown                  # outputFormat
"""
```

### 日常生活类比：给新员工的工作手册

| 系统提示词要素 | 员工手册内容 |
|--------------|-------------|
| 角色设定 | "你是前台接待" |
| 能力边界 | "只回答公司业务相关问题" |
| 行为规则 | "保持微笑、使用敬语" |
| 边界处理 | "不清楚的问题转给主管" |

---

## 类比3：上下文注入 = 组件 State/Props 数据

### 前端类比：传递数据给组件

```jsx
// 前端：把数据传给组件渲染
function SearchResults({ documents, query }) {
  return (
    <div>
      {documents.map(doc => (
        <DocumentCard key={doc.id} content={doc.content} />
      ))}
      <QueryDisplay query={query} />
    </div>
  );
}
```

```python
# RAG：把检索结果注入 Prompt
def build_prompt(documents: list, query: str) -> str:
    context = "\n".join([doc["content"] for doc in documents])
    return f"""
参考文档：
{context}

问题：{query}
"""
```

### 日常生活类比：开卷考试

| 上下文注入 | 开卷考试 |
|-----------|---------|
| 检索到的文档 | 允许带进考场的参考资料 |
| 文档的相关性 | 资料是否包含答案 |
| 文档的数量 | 能带多少页资料（Token 限制） |
| LLM 的回答 | 基于资料写出的答案 |

**关键洞察**：开卷考试的成绩取决于：1）带对了资料 2）能找到相关内容 3）能正确理解和使用

---

## 类比4：用户问题模板 = 表单验证

### 前端类比：表单输入处理

```javascript
// 前端：格式化和验证用户输入
function formatUserInput(rawInput) {
  return {
    query: rawInput.trim(),
    type: detectQueryType(rawInput),
    constraints: {
      maxLength: 100,
      language: 'zh-CN'
    }
  };
}
```

```python
# RAG：格式化用户问题
def format_query(raw_query: str) -> str:
    return f"""
问题：{raw_query.strip()}
要求：
- 用中文回答
- 控制在100字以内
"""
```

### 日常生活类比：填写申请表

| 用户问题模板 | 申请表 |
|-------------|-------|
| 原始问题 | 你想申请什么 |
| 格式化后的问题 | 按表格格式填写的申请 |
| 约束条件 | 表格的字数限制、必填项 |
| 期望输出 | 表格要求的回复格式 |

---

## 类比5：RAG Pipeline = 前端数据流

### 前端类比：Redux 数据流

```
用户操作 → Action → Reducer → State → UI 更新
    ↓         ↓        ↓        ↓        ↓
用户问题 → 检索 → 排序 → 注入Prompt → LLM回答
```

```javascript
// 前端 Redux 流程
dispatch(searchAction(query))     // 1. 用户发起搜索
  → reducer处理                   // 2. 检索文档
  → 更新state                     // 3. 组装数据
  → 组件重新渲染                   // 4. 展示结果
```

```python
# RAG 流程
def rag_pipeline(query: str) -> str:
    docs = retrieve(query)        # 1. 检索
    docs = rerank(docs, query)    # 2. 排序
    prompt = build_prompt(docs)   # 3. 组装 Prompt
    return llm.generate(prompt)   # 4. 生成回答
```

### 日常生活类比：图书馆找资料写报告

```
1. 你有一个问题（用户问题）
2. 去图书馆找相关书籍（检索）
3. 挑选最相关的几本（排序）
4. 把书摊开在桌上（上下文注入）
5. 基于这些书写报告（LLM 生成）
```

---

## 类比总结表

| RAG 概念 | 前端类比 | 日常生活类比 |
|---------|---------|-------------|
| RAG Prompt | API 请求 | 餐厅点餐 |
| 系统提示词 | 组件 Props 配置 | 员工工作手册 |
| 上下文注入 | State/Props 数据传递 | 开卷考试的参考资料 |
| 用户问题模板 | 表单验证和格式化 | 填写申请表 |
| RAG Pipeline | Redux 数据流 | 图书馆找资料写报告 |
| Token 限制 | 请求体大小限制 | 考场能带的资料页数 |
| 幻觉 | 组件渲染了不存在的数据 | 考试时编造答案 |

---

## 代码对比示例

### 前端 vs RAG：处理用户输入

```javascript
// 前端：处理搜索请求
async function handleSearch(userInput) {
  // 1. 验证输入
  if (!userInput.trim()) return;

  // 2. 获取数据
  const results = await searchAPI(userInput);

  // 3. 格式化展示
  return formatResults(results);
}
```

```python
# RAG：处理用户问题
async def handle_query(user_input: str) -> str:
    # 1. 验证输入
    if not user_input.strip():
        return "请输入问题"

    # 2. 检索文档
    docs = await retrieve(user_input)

    # 3. 构建 Prompt 并生成
    prompt = build_rag_prompt(docs, user_input)
    return await llm.generate(prompt)
```

**相似之处**：
- 都需要验证用户输入
- 都需要获取/检索数据
- 都需要格式化输出

---

**下一步：** [06_反直觉点](./06_反直觉点.md) - 避免常见的 Prompt 设计误区
