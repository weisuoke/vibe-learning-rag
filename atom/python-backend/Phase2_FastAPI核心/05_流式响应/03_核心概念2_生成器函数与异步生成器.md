# 核心概念2：生成器函数与异步生成器

> 深入理解 Python 生成器原理、yield 关键字和异步生成器的实现机制

---

## 1. 生成器函数的本质

### 1.1 什么是生成器？

**生成器（Generator）** 是一种特殊的迭代器，使用 `yield` 关键字定义。

```python
# 普通函数：一次性返回所有结果
def normal_function():
    result = []
    for i in range(3):
        result.append(i)
    return result  # [0, 1, 2]

# 生成器函数：逐个返回结果
def generator_function():
    for i in range(3):
        yield i  # 0, 1, 2（逐个）

# 使用对比
normal_result = normal_function()
print(normal_result)  # [0, 1, 2]

generator_result = generator_function()
print(next(generator_result))  # 0
print(next(generator_result))  # 1
print(next(generator_result))  # 2
```

**核心区别：**
- 普通函数：`return` 一次性返回所有结果
- 生成器函数：`yield` 逐个返回结果

### 1.2 生成器的工作原理

```python
def simple_generator():
    print("开始执行")
    yield 1
    print("继续执行")
    yield 2
    print("再次执行")
    yield 3
    print("结束执行")

# 创建生成器对象（此时不执行任何代码）
gen = simple_generator()
print(type(gen))  # <class 'generator'>

# 第一次调用 next()
print(next(gen))
# 输出：
# 开始执行
# 1

# 第二次调用 next()
print(next(gen))
# 输出：
# 继续执行
# 2

# 第三次调用 next()
print(next(gen))
# 输出：
# 再次执行
# 3

# 第四次调用 next()（生成器已耗尽）
print(next(gen))
# 抛出 StopIteration 异常
```

**执行流程：**
```
1. 调用 simple_generator() → 创建生成器对象（不执行代码）
2. 第一次 next(gen) → 执行到第一个 yield，返回 1，暂停
3. 第二次 next(gen) → 从暂停处继续，执行到第二个 yield，返回 2，暂停
4. 第三次 next(gen) → 从暂停处继续，执行到第三个 yield，返回 3，暂停
5. 第四次 next(gen) → 从暂停处继续，函数结束，抛出 StopIteration
```

### 1.3 生成器的状态机

```python
import inspect

def stateful_generator():
    print("状态1：初始化")
    yield "数据1"

    print("状态2：处理中")
    yield "数据2"

    print("状态3：完成")
    yield "数据3"

gen = stateful_generator()

# 查看生成器状态
print(inspect.getgeneratorstate(gen))  # GEN_CREATED（已创建）

next(gen)
print(inspect.getgeneratorstate(gen))  # GEN_SUSPENDED（已暂停）

next(gen)
print(inspect.getgeneratorstate(gen))  # GEN_SUSPENDED

next(gen)
print(inspect.getgeneratorstate(gen))  # GEN_SUSPENDED

try:
    next(gen)
except StopIteration:
    print(inspect.getgeneratorstate(gen))  # GEN_CLOSED（已关闭）
```

**生成器的四种状态：**
1. **GEN_CREATED**：已创建，未开始执行
2. **GEN_RUNNING**：正在执行（很少见到，因为执行很快）
3. **GEN_SUSPENDED**：已暂停，等待下一次 next()
4. **GEN_CLOSED**：已关闭，无法再生成数据

---

## 2. yield 关键字的深入理解

### 2.1 yield 的三种用法

#### 用法1：yield 表达式（返回值）

```python
def yield_expression():
    result = yield 1  # yield 可以接收值
    print(f"接收到: {result}")
    yield 2

gen = yield_expression()
print(next(gen))  # 1

# 使用 send() 发送值给生成器
print(gen.send("Hello"))  # 接收到: Hello, 然后返回 2
```

#### 用法2：yield from（委托生成器）

```python
def sub_generator():
    yield 1
    yield 2

def main_generator():
    yield from sub_generator()  # 委托给子生成器
    yield 3

gen = main_generator()
print(list(gen))  # [1, 2, 3]
```

#### 用法3：yield（仅返回，不接收）

```python
def simple_yield():
    yield 1
    yield 2
    yield 3

gen = simple_yield()
print(list(gen))  # [1, 2, 3]
```

### 2.2 yield vs return

```python
# return：函数结束，返回值
def with_return():
    return 1
    return 2  # 永远不会执行
    return 3

print(with_return())  # 1

# yield：函数暂停，返回值，可以继续执行
def with_yield():
    yield 1
    yield 2
    yield 3

print(list(with_yield()))  # [1, 2, 3]

# 混合使用：return 结束生成器
def mixed():
    yield 1
    yield 2
    return "结束"  # 生成器结束，返回值作为 StopIteration 的 value

gen = mixed()
print(next(gen))  # 1
print(next(gen))  # 2
try:
    print(next(gen))
except StopIteration as e:
    print(f"生成器结束，返回值: {e.value}")  # 结束
```

### 2.3 生成器的内存优势

```python
import sys

# 普通列表：占用大量内存
def list_approach(n):
    return [i * i for i in range(n)]

# 生成器：占用极少内存
def generator_approach(n):
    for i in range(n):
        yield i * i

# 内存对比
n = 1000000
list_result = list_approach(n)
print(f"列表大小: {sys.getsizeof(list_result)} 字节")  # ~8MB

gen_result = generator_approach(n)
print(f"生成器大小: {sys.getsizeof(gen_result)} 字节")  # ~128 字节

# 生成器只在需要时才计算值
for i, value in enumerate(gen_result):
    if i >= 5:
        break
    print(value)  # 0, 1, 4, 9, 16
# 只计算了前5个值，其他99万多个值没有计算
```

---

## 3. 异步生成器（Async Generator）

### 3.1 什么是异步生成器？

**异步生成器** 是结合了 `async def` 和 `yield` 的生成器，支持异步操作。

```python
import asyncio

# 同步生成器：不能使用 await
def sync_generator():
    for i in range(3):
        # await asyncio.sleep(0.1)  # ❌ 语法错误
        yield i

# 异步生成器：可以使用 await
async def async_generator():
    for i in range(3):
        await asyncio.sleep(0.1)  # ✅ 可以使用 await
        yield i

# 使用异步生成器
async def main():
    async for value in async_generator():
        print(value)  # 0, 1, 2（每个间隔0.1秒）

asyncio.run(main())
```

**核心区别：**
- 同步生成器：`def` + `yield`，不能使用 `await`
- 异步生成器：`async def` + `yield`，可以使用 `await`

### 3.2 异步生成器的工作原理

```python
import asyncio

async def async_gen_with_state():
    print("状态1：开始")
    await asyncio.sleep(0.1)
    yield "数据1"

    print("状态2：处理中")
    await asyncio.sleep(0.1)
    yield "数据2"

    print("状态3：完成")
    await asyncio.sleep(0.1)
    yield "数据3"

async def main():
    gen = async_gen_with_state()

    # 使用 async for 遍历
    async for value in gen:
        print(f"接收到: {value}")

asyncio.run(main())

# 输出：
# 状态1：开始
# 接收到: 数据1
# 状态2：处理中
# 接收到: 数据2
# 状态3：完成
# 接收到: 数据3
```

### 3.3 异步生成器 vs 同步生成器

```python
import asyncio
import time

# 同步生成器：阻塞事件循环
def sync_gen():
    for i in range(3):
        time.sleep(1)  # 阻塞1秒
        yield i

# 异步生成器：不阻塞事件循环
async def async_gen():
    for i in range(3):
        await asyncio.sleep(1)  # 异步等待1秒
        yield i

# 测试并发性能
async def test_sync():
    """使用同步生成器（阻塞）"""
    start = time.time()

    # 启动3个并发任务
    async def task():
        for value in sync_gen():
            print(f"同步: {value}")

    await asyncio.gather(task(), task(), task())

    print(f"同步生成器总耗时: {time.time() - start:.2f}秒")
    # 输出：~9秒（3个任务串行执行，每个3秒）

async def test_async():
    """使用异步生成器（不阻塞）"""
    start = time.time()

    # 启动3个并发任务
    async def task():
        async for value in async_gen():
            print(f"异步: {value}")

    await asyncio.gather(task(), task(), task())

    print(f"异步生成器总耗时: {time.time() - start:.2f}秒")
    # 输出：~3秒（3个任务并行执行）

# 运行测试
asyncio.run(test_sync())
asyncio.run(test_async())
```

**性能对比：**
- 同步生成器：3个任务串行，总耗时 9秒
- 异步生成器：3个任务并行，总耗时 3秒

---

## 4. 手写实现：生成器的底层原理

### 4.1 手写生成器（使用类模拟）

```python
class ManualGenerator:
    """手写生成器：模拟 yield 的行为"""

    def __init__(self, n):
        self.n = n
        self.current = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.current < self.n:
            value = self.current
            self.current += 1
            return value
        else:
            raise StopIteration

# 使用手写生成器
gen = ManualGenerator(3)
print(next(gen))  # 0
print(next(gen))  # 1
print(next(gen))  # 2
# print(next(gen))  # StopIteration

# 等价的生成器函数
def simple_generator(n):
    for i in range(n):
        yield i

gen2 = simple_generator(3)
print(list(gen2))  # [0, 1, 2]
```

### 4.2 手写异步生成器（使用类模拟）

```python
import asyncio

class ManualAsyncGenerator:
    """手写异步生成器：模拟 async yield 的行为"""

    def __init__(self, n):
        self.n = n
        self.current = 0

    def __aiter__(self):
        return self

    async def __anext__(self):
        if self.current < self.n:
            await asyncio.sleep(0.1)  # 模拟异步操作
            value = self.current
            self.current += 1
            return value
        else:
            raise StopAsyncIteration

# 使用手写异步生成器
async def main():
    gen = ManualAsyncGenerator(3)
    async for value in gen:
        print(value)  # 0, 1, 2

asyncio.run(main())

# 等价的异步生成器函数
async def simple_async_generator(n):
    for i in range(n):
        await asyncio.sleep(0.1)
        yield i

async def main2():
    async for value in simple_async_generator(3):
        print(value)  # 0, 1, 2

asyncio.run(main2())
```

### 4.3 生成器的状态保存机制

```python
def stateful_generator():
    """生成器会保存局部变量的状态"""
    count = 0
    total = 0

    while True:
        value = yield total
        if value is None:
            break
        count += 1
        total += value
        print(f"第{count}次调用，当前总和: {total}")

# 使用
gen = stateful_generator()
next(gen)  # 启动生成器

print(gen.send(10))  # 第1次调用，当前总和: 10，返回 10
print(gen.send(20))  # 第2次调用，当前总和: 30，返回 30
print(gen.send(30))  # 第3次调用，当前总和: 60，返回 60

# 生成器保存了 count 和 total 的状态
```

---

## 5. 生成器在流式响应中的应用

### 5.1 基础流式响应

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio

app = FastAPI()

async def number_stream(count: int):
    """异步生成器：生成数字流"""
    for i in range(count):
        await asyncio.sleep(0.1)
        yield f"数字: {i}\n"

@app.get("/numbers/{count}")
async def stream_numbers(count: int):
    return StreamingResponse(
        number_stream(count),
        media_type="text/plain"
    )
```

### 5.2 数据库查询流式响应

```python
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

async def stream_database_results(db: AsyncSession, table):
    """流式查询数据库"""
    # 使用 stream() 方法流式查询
    result = await db.stream(select(table))

    async for row in result:
        # 逐行返回数据
        yield f"{row}\n"
        await asyncio.sleep(0.01)  # 避免过快

@app.get("/db-stream")
async def stream_db(db: AsyncSession = Depends(get_db)):
    return StreamingResponse(
        stream_database_results(db, User),
        media_type="text/plain"
    )
```

### 5.3 文件流式读取

```python
async def stream_large_file(file_path: str):
    """流式读取大文件"""
    with open(file_path, "rb") as f:
        while True:
            chunk = f.read(8192)  # 每次读取 8KB
            if not chunk:
                break
            yield chunk

@app.get("/download/{filename}")
async def download_file(filename: str):
    file_path = f"/path/to/{filename}"
    return StreamingResponse(
        stream_large_file(file_path),
        media_type="application/octet-stream",
        headers={
            "Content-Disposition": f"attachment; filename={filename}"
        }
    )
```

---

## 6. 生成器的高级用法

### 6.1 生成器表达式

```python
# 列表推导式：立即生成所有元素
list_comp = [i * i for i in range(1000000)]
print(sys.getsizeof(list_comp))  # ~8MB

# 生成器表达式：惰性生成
gen_exp = (i * i for i in range(1000000))
print(sys.getsizeof(gen_exp))  # ~128 字节

# 使用
for i, value in enumerate(gen_exp):
    if i >= 5:
        break
    print(value)  # 0, 1, 4, 9, 16
```

### 6.2 yield from 委托

```python
def sub_gen1():
    yield 1
    yield 2

def sub_gen2():
    yield 3
    yield 4

def main_gen():
    yield from sub_gen1()  # 委托给 sub_gen1
    yield from sub_gen2()  # 委托给 sub_gen2
    yield 5

print(list(main_gen()))  # [1, 2, 3, 4, 5]
```

### 6.3 生成器的异常处理

```python
def generator_with_exception():
    try:
        yield 1
        yield 2
        raise ValueError("模拟错误")
        yield 3  # 不会执行
    except ValueError as e:
        yield f"捕获异常: {e}"
    finally:
        yield "清理资源"

gen = generator_with_exception()
print(list(gen))
# [1, 2, '捕获异常: 模拟错误', '清理资源']
```

### 6.4 生成器的 close() 方法

```python
def closable_generator():
    try:
        for i in range(10):
            yield i
    except GeneratorExit:
        print("生成器被关闭")

gen = closable_generator()
print(next(gen))  # 0
print(next(gen))  # 1

gen.close()  # 关闭生成器
# 输出：生成器被关闭

try:
    print(next(gen))  # 抛出 StopIteration
except StopIteration:
    print("生成器已关闭，无法继续")
```

---

## 7. 实战示例：完整的流式响应系统

```python
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from typing import AsyncGenerator
import asyncio
import json

app = FastAPI()

class StreamProcessor:
    """流式数据处理器"""

    def __init__(self, data_source: str):
        self.data_source = data_source
        self.processed_count = 0

    async def process_stream(self) -> AsyncGenerator[str, None]:
        """异步生成器：处理数据流"""
        try:
            # 模拟数据源
            data_items = await self.fetch_data()

            for item in data_items:
                # 处理数据
                processed = await self.process_item(item)

                # 生成 JSON 格式的数据
                yield json.dumps(processed) + "\n"

                self.processed_count += 1

                # 避免过快
                await asyncio.sleep(0.01)

        except Exception as e:
            # 错误处理
            error_data = {"error": str(e)}
            yield json.dumps(error_data) + "\n"

        finally:
            # 清理资源
            await self.cleanup()
            summary = {
                "summary": f"处理完成，共 {self.processed_count} 条数据"
            }
            yield json.dumps(summary) + "\n"

    async def fetch_data(self):
        """获取数据"""
        await asyncio.sleep(0.1)
        return [f"数据{i}" for i in range(10)]

    async def process_item(self, item: str):
        """处理单个数据项"""
        await asyncio.sleep(0.05)
        return {"item": item, "processed": True}

    async def cleanup(self):
        """清理资源"""
        print(f"清理资源，共处理 {self.processed_count} 条数据")

@app.get("/stream/{source}")
async def stream_endpoint(source: str):
    """流式响应端点"""
    processor = StreamProcessor(source)

    return StreamingResponse(
        processor.process_stream(),
        media_type="application/x-ndjson",  # Newline Delimited JSON
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

# 测试
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 总结

**生成器与异步生成器的核心要点：**

1. **生成器原理**：使用 `yield` 暂停和恢复执行
2. **内存优势**：惰性求值，按需生成
3. **异步生成器**：结合 `async def` 和 `yield`，支持异步操作
4. **状态保存**：自动保存局部变量状态
5. **流式应用**：是流式响应的基础

**记住：** 生成器是 Python 实现流式处理的核心机制，理解生成器就理解了流式响应的本质！
