# 核心概念：L2距离（欧氏距离）

## 一句话定义

**L2距离是计算两个向量在空间中直线距离的度量方式，距离越小表示两个向量越相似。**

---

## 1. 数学原理

### 1.1 公式定义

对于两个n维向量 x = [x₁, x₂, ..., xₙ] 和 y = [y₁, y₂, ..., yₙ]：

```
L2(x, y) = √[(x₁-y₁)² + (x₂-y₂)² + ... + (xₙ-yₙ)²]
```

**简化表示：**
```
L2(x, y) = √[Σ(xᵢ - yᵢ)²]
```

**向量形式：**
```
L2(x, y) = ‖x - y‖₂
```

### 1.2 计算步骤

```python
# 手写实现L2距离
import numpy as np

def l2_distance(x, y):
    """
    计算L2距离（欧氏距离）

    参数:
        x: 向量1
        y: 向量2

    返回:
        L2距离值（标量）
    """
    # 步骤1：计算差值
    diff = x - y

    # 步骤2：平方
    squared = diff ** 2

    # 步骤3：求和
    sum_squared = np.sum(squared)

    # 步骤4：开方
    distance = np.sqrt(sum_squared)

    return distance

# 示例
x = np.array([1.0, 2.0, 3.0])
y = np.array([4.0, 5.0, 6.0])

distance = l2_distance(x, y)
print(f"L2距离: {distance:.4f}")  # 输出: 5.1962
```

---

## 2. 几何意义

### 2.1 二维空间直观理解

在2D平面上，L2距离就是两点之间的直线距离（勾股定理）：

```
点A = (1, 2)
点B = (4, 6)

L2距离 = √[(4-1)² + (6-2)²]
       = √[3² + 4²]
       = √[9 + 16]
       = √25
       = 5
```

**可视化：**
```
  y
  |
6 |       B(4,6)
  |      /|
5 |     / |
  |    /  |
4 |   /   | 4
  |  /    |
3 | /     |
  |/      |
2 A-------+
  |(1,2)  3
1 |
  +-----------> x
  0 1 2 3 4 5
```

### 2.2 高维空间推广

在高维空间（如768维的Embedding向量），L2距离仍然是"直线距离"，只是人类无法直观可视化。

**关键特性：**
- 距离永远非负：L2(x, y) ≥ 0
- 对称性：L2(x, y) = L2(y, x)
- 三角不等式：L2(x, z) ≤ L2(x, y) + L2(y, z)
- 自身距离为0：L2(x, x) = 0

---

## 3. 在Milvus中的使用

### 3.1 配置L2度量

```python
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 定义Schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)
]
schema = CollectionSchema(fields=fields, description="L2距离示例")

# 创建Collection
collection = Collection(name="l2_collection", schema=schema)

# 创建索引，指定L2度量
index_params = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",  # 使用L2距离
    "params": {"nlist": 128}
}
collection.create_index(field_name="embedding", index_params=index_params)
```

### 3.2 搜索时使用L2

```python
# 加载Collection
collection.load()

# 查询向量
query_vector = [[0.1, 0.2, 0.3, ...]]  # 768维

# 搜索参数
search_params = {
    "metric_type": "L2",
    "params": {"nprobe": 10}
}

# 执行搜索
results = collection.search(
    data=query_vector,
    anns_field="embedding",
    param=search_params,
    limit=10,
    output_fields=["id"]
)

# 结果按L2距离从小到大排序
for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, L2距离: {hit.distance:.4f}")
```

### 3.3 L2距离的排序规则

**重要：L2距离越小越相似**

```python
# 示例结果
# ID: 123, L2距离: 0.1234  ← 最相似（距离最小）
# ID: 456, L2距离: 0.2345
# ID: 789, L2距离: 0.3456
# ...
# ID: 999, L2距离: 1.2345  ← 最不相似（距离最大）
```

---

## 4. RAG应用场景

### 4.1 场景1：未归一化的Embedding检索

**适用情况：**
- Embedding模型输出未归一化
- 向量幅度携带信息（如重要性、置信度）

**示例：Word2Vec检索**

```python
import numpy as np
from pymilvus import connections, Collection

# 连接Milvus
connections.connect(host="localhost", port="19530")

# 假设使用Word2Vec（未归一化）
def word2vec_embedding(text):
    """模拟Word2Vec生成Embedding"""
    # 实际应用中使用gensim等库
    return np.random.randn(300)  # 300维，未归一化

# 插入文档
documents = [
    "机器学习是人工智能的核心",
    "深度学习是机器学习的子集",
    "神经网络是深度学习的基础"
]

collection = Collection("word2vec_docs")
embeddings = [word2vec_embedding(doc) for doc in documents]

# 使用L2距离检索
query = "什么是机器学习"
query_emb = word2vec_embedding(query)

results = collection.search(
    data=[query_emb],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=3
)

# L2距离能正确反映语义相似度
```

### 4.2 场景2：图像特征检索

**适用情况：**
- 图像特征向量（如CNN提取的特征）
- 特征幅度有意义（如激活强度）

**示例：相似图片搜索**

```python
# 图像特征提取（模拟）
def extract_image_features(image_path):
    """提取图像特征向量"""
    # 实际使用ResNet、VGG等模型
    features = np.random.randn(2048)  # 2048维特征
    return features

# 插入图片特征
image_paths = ["img1.jpg", "img2.jpg", "img3.jpg"]
features = [extract_image_features(path) for path in image_paths]

collection = Collection("image_features")
collection.insert([
    [i for i in range(len(features))],
    features
])

# 搜索相似图片
query_image = "query.jpg"
query_features = extract_image_features(query_image)

results = collection.search(
    data=[query_features],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=5
)

print("最相似的5张图片:")
for hit in results[0]:
    print(f"图片ID: {hit.id}, L2距离: {hit.distance:.4f}")
```

### 4.3 场景3：物理距离概念的应用

**适用情况：**
- 数据本身有物理距离含义
- 需要保持欧氏空间的几何性质

**示例：地理位置聚类**

```python
# 地理坐标（经度、纬度）
locations = np.array([
    [116.4074, 39.9042],  # 北京
    [121.4737, 31.2304],  # 上海
    [113.2644, 23.1291],  # 广州
])

# 使用L2距离计算城市间距离
def city_distance(city1, city2):
    """计算两个城市的L2距离"""
    return np.linalg.norm(city1 - city2)

beijing = locations[0]
shanghai = locations[1]

distance = city_distance(beijing, shanghai)
print(f"北京到上海的L2距离: {distance:.4f}")

# 在Milvus中存储和检索地理位置
collection = Collection("geo_locations")
collection.insert([
    [0, 1, 2],
    locations.tolist()
])

# 查找离北京最近的城市
results = collection.search(
    data=[beijing.tolist()],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=3
)
```

---

## 5. 完整实战代码

### 5.1 从零实现L2距离检索系统

```python
"""
L2距离检索系统完整示例
演示：文档检索中使用L2距离
"""

import numpy as np
from pymilvus import (
    connections,
    Collection,
    FieldSchema,
    CollectionSchema,
    DataType,
    utility
)

# ===== 1. 连接Milvus =====
print("=== 连接Milvus ===")
connections.connect(
    alias="default",
    host="localhost",
    port="19530"
)
print("✓ 连接成功")

# ===== 2. 创建Collection =====
print("\n=== 创建Collection ===")

# 删除已存在的Collection
collection_name = "l2_demo"
if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)
    print(f"✓ 删除旧Collection: {collection_name}")

# 定义Schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128)
]
schema = CollectionSchema(fields=fields, description="L2距离示例")

# 创建Collection
collection = Collection(name=collection_name, schema=schema)
print(f"✓ 创建Collection: {collection_name}")

# ===== 3. 插入数据 =====
print("\n=== 插入数据 ===")

# 模拟文档和Embedding
documents = [
    "机器学习是人工智能的核心技术",
    "深度学习是机器学习的重要分支",
    "神经网络是深度学习的基础",
    "自然语言处理研究计算机理解人类语言",
    "计算机视觉让机器能够理解图像",
]

# 生成模拟Embedding（实际应用中使用真实模型）
def generate_embedding(text, dim=128):
    """生成模拟Embedding（未归一化）"""
    np.random.seed(hash(text) % 2**32)
    return np.random.randn(dim).tolist()

embeddings = [generate_embedding(doc) for doc in documents]

# 插入数据
entities = [
    documents,
    embeddings
]

insert_result = collection.insert(entities)
print(f"✓ 插入 {len(documents)} 条数据")
print(f"  插入的ID: {insert_result.primary_keys}")

# ===== 4. 创建索引 =====
print("\n=== 创建索引 ===")

index_params = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",  # 使用L2距离
    "params": {"nlist": 16}
}

collection.create_index(
    field_name="embedding",
    index_params=index_params
)
print("✓ 创建L2索引")

# ===== 5. 加载Collection =====
print("\n=== 加载Collection ===")
collection.load()
print("✓ Collection已加载到内存")

# ===== 6. 执行搜索 =====
print("\n=== 执行搜索 ===")

# 查询文本
query_text = "什么是机器学习"
query_embedding = [generate_embedding(query_text)]

print(f"查询: {query_text}")

# 搜索参数
search_params = {
    "metric_type": "L2",
    "params": {"nprobe": 10}
}

# 执行搜索
results = collection.search(
    data=query_embedding,
    anns_field="embedding",
    param=search_params,
    limit=3,
    output_fields=["text"]
)

# ===== 7. 显示结果 =====
print("\n=== 搜索结果（按L2距离排序）===")
for i, hits in enumerate(results):
    print(f"\n查询 {i+1}:")
    for rank, hit in enumerate(hits, 1):
        print(f"  {rank}. [L2距离: {hit.distance:.4f}] {hit.entity.get('text')}")

# ===== 8. 手动验证L2距离 =====
print("\n=== 手动验证L2距离 ===")

# 获取查询向量
query_vec = np.array(query_embedding[0])

# 获取第一个结果的向量
first_hit_id = results[0][0].id
query_result = collection.query(
    expr=f"id == {first_hit_id}",
    output_fields=["embedding"]
)
first_hit_vec = np.array(query_result[0]["embedding"])

# 手动计算L2距离
manual_l2 = np.linalg.norm(query_vec - first_hit_vec)
milvus_l2 = results[0][0].distance

print(f"手动计算的L2距离: {manual_l2:.4f}")
print(f"Milvus返回的L2距离: {milvus_l2:.4f}")
print(f"差异: {abs(manual_l2 - milvus_l2):.6f}")

# ===== 9. 清理 =====
print("\n=== 清理资源 ===")
collection.release()
# utility.drop_collection(collection_name)  # 取消注释以删除Collection
print("✓ 完成")
```

### 5.2 运行输出示例

```
=== 连接Milvus ===
✓ 连接成功

=== 创建Collection ===
✓ 创建Collection: l2_demo

=== 插入数据 ===
✓ 插入 5 条数据
  插入的ID: [448979862796107776, 448979862796107777, ...]

=== 创建索引 ===
✓ 创建L2索引

=== 加载Collection ===
✓ Collection已加载到内存

=== 执行搜索 ===
查询: 什么是机器学习

=== 搜索结果（按L2距离排序）===

查询 1:
  1. [L2距离: 12.3456] 机器学习是人工智能的核心技术
  2. [L2距离: 13.7890] 深度学习是机器学习的重要分支
  3. [L2距离: 15.2345] 神经网络是深度学习的基础

=== 手动验证L2距离 ===
手动计算的L2距离: 12.3456
Milvus返回的L2距离: 12.3456
差异: 0.000000

=== 清理资源 ===
✓ 完成
```

---

## 6. L2距离的特点

### 6.1 优点

✅ **直观易懂**
- 对应物理空间的直线距离
- 符合人类对"距离"的直觉

✅ **数学性质好**
- 满足度量空间的所有公理
- 支持三角不等式

✅ **适用范围广**
- 适合未归一化的向量
- 适合物理距离概念的场景

### 6.2 缺点

❌ **受向量幅度影响**
- 向量长度不同会影响距离
- 可能不适合只关注方向的场景

❌ **计算成本较高**
- 需要平方、求和、开方
- 比内积IP慢

❌ **高维空间的"维度灾难"**
- 高维空间中，所有点的距离趋于相等
- 可能降低检索效果

---

## 7. 何时使用L2距离

### 7.1 推荐使用的场景

✅ **Embedding未归一化**
```python
# 检查向量是否归一化
embedding = model.encode("hello")
norm = np.linalg.norm(embedding)
if norm != 1.0:
    # 未归一化，可以使用L2
    metric_type = "L2"
```

✅ **向量幅度有意义**
- 幅度表示重要性、置信度等
- 需要考虑向量的"强度"

✅ **物理距离概念**
- 地理坐标
- 物理测量值

### 7.2 不推荐使用的场景

❌ **Embedding已归一化**
- 归一化后，L2和COSINE几乎等价
- 但COSINE更直观

❌ **只关注方向**
- 语义搜索通常只关注方向
- 应该使用COSINE

❌ **向量维度很高（>1000维）**
- 高维空间中L2距离区分度下降
- 考虑使用COSINE或降维

---

## 8. L2距离 vs 其他度量

### 8.1 L2 vs COSINE

| 维度 | L2距离 | 余弦相似度 |
|------|--------|-----------|
| 计算内容 | 空间距离 | 方向夹角 |
| 受幅度影响 | 是 | 否 |
| 归一化向量 | 与COSINE近似 | 标准选择 |
| 计算速度 | 较慢 | 较快 |
| 适用场景 | 未归一化向量 | 语义搜索 |

### 8.2 L2 vs IP

| 维度 | L2距离 | 内积IP |
|------|--------|--------|
| 计算内容 | 差值的范数 | 点积 |
| 值域 | [0, +∞) | (-∞, +∞) |
| 相似性 | 越小越相似 | 越大越相似 |
| 计算速度 | 慢 | 快 |
| 适用场景 | 物理距离 | 推荐系统 |

---

## 9. 性能优化技巧

### 9.1 避免重复计算范数

```python
# ❌ 低效：每次都计算范数
def l2_distance_slow(x, y):
    return np.linalg.norm(x - y)

# ✅ 高效：利用范数的性质
def l2_distance_fast(x, y, norm_x=None, norm_y=None):
    """
    利用公式：‖x-y‖² = ‖x‖² + ‖y‖² - 2(x·y)
    """
    if norm_x is None:
        norm_x = np.linalg.norm(x)
    if norm_y is None:
        norm_y = np.linalg.norm(y)

    dot_product = np.dot(x, y)
    distance_squared = norm_x**2 + norm_y**2 - 2*dot_product
    return np.sqrt(max(0, distance_squared))  # max避免负数（浮点误差）
```

### 9.2 批量计算

```python
# 批量计算L2距离
from scipy.spatial.distance import cdist

# 查询向量
queries = np.random.randn(10, 128)

# 候选向量
candidates = np.random.randn(1000, 128)

# 批量计算（高效）
distances = cdist(queries, candidates, metric='euclidean')
# distances.shape = (10, 1000)

# 找到每个查询的Top-K
k = 5
top_k_indices = np.argsort(distances, axis=1)[:, :k]
```

---

## 10. 总结

### 核心要点

1. **L2距离 = 空间直线距离**
2. **距离越小越相似**
3. **受向量幅度影响**
4. **适合未归一化向量**
5. **在Milvus中配置metric_type="L2"**

### 记忆口诀

**L2测距离，幅度有影响，未归一化用L2，归一化用COSINE。**

---

**下一步：** [04_核心概念_内积IP.md](./04_核心概念_内积IP.md) - 深入理解内积度量
