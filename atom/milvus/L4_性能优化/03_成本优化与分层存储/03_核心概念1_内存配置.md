# 核心概念1：内存配置

## 一句话定义

**内存配置是为 Milvus 各组件分配合适的内存资源，确保索引和数据能高效加载到内存中，避免频繁的磁盘 I/O。**

---

## 详细解释

### 为什么内存配置如此重要？

在向量检索系统中，**内存是性能的第一瓶颈**：

```
性能对比：
- 内存访问：100 ns
- SSD 访问：100,000 ns (慢 1000 倍)
- HDD 访问：10,000,000 ns (慢 100,000 倍)

结论：数据在内存 vs 在磁盘，性能差距可达 1000-100000 倍！
```

### Milvus 的内存使用模型

Milvus 的内存主要用于以下几个方面：

```
┌─────────────────────────────────────┐
│      Milvus 内存使用分布            │
├─────────────────────────────────────┤
│ 1. 索引数据 (40-60%)                │
│    - 向量索引结构                   │
│    - 量化后的向量数据               │
│                                     │
│ 2. 原始向量数据 (20-30%)            │
│    - 未压缩的向量                   │
│    - 标量字段数据                   │
│                                     │
│ 3. 查询缓冲区 (10-20%)              │
│    - 查询中间结果                   │
│    - 排序和过滤缓冲                 │
│                                     │
│ 4. 系统开销 (10-20%)                │
│    - 元数据                         │
│    - 连接池                         │
│    - 日志缓冲                       │
└─────────────────────────────────────┘
```

---

## 核心配置参数

### 1. QueryNode 内存配置

**QueryNode** 是 Milvus 中负责查询的组件，需要加载索引到内存。

```yaml
# milvus.yaml
queryNode:
  # 内存限制（单位：字节）
  # 建议：物理内存的 70-80%
  cache:
    memoryLimit: 17179869184  # 16GB

  # 是否启用内存保护
  # 当内存使用超过阈值时，自动释放部分数据
  enableMemoryProtection: true

  # 内存保护阈值（百分比）
  # 当内存使用超过此值时触发保护机制
  memoryProtectionThreshold: 0.9  # 90%
```

**计算公式**：

```python
# QueryNode 内存需求计算
def calculate_querynode_memory(
    num_vectors: int,
    vector_dim: int,
    index_type: str,
    num_partitions_loaded: int = 1
) -> int:
    """
    计算 QueryNode 所需内存

    参数：
    - num_vectors: 向量数量
    - vector_dim: 向量维度
    - index_type: 索引类型
    - num_partitions_loaded: 加载的分区数

    返回：
    - 所需内存（字节）
    """
    # 1. 原始向量大小
    raw_vector_size = num_vectors * vector_dim * 4  # float32 = 4 bytes

    # 2. 索引开销（根据索引类型）
    index_overhead = {
        "FLAT": 1.0,           # 无压缩
        "IVF_FLAT": 1.1,       # 10% 开销（聚类中心）
        "IVF_SQ8": 0.3,        # 压缩到 1/4（8bit 量化）
        "IVF_PQ": 0.15,        # 压缩到 1/8（PQ 编码）
        "HNSW": 1.5,           # 50% 开销（图结构）
    }

    index_size = raw_vector_size * index_overhead.get(index_type, 1.0)

    # 3. 查询缓冲区（20%）
    query_buffer = index_size * 0.2

    # 4. 系统开销（10%）
    system_overhead = index_size * 0.1

    # 5. 总内存需求
    total_memory = (index_size + query_buffer + system_overhead) * num_partitions_loaded

    # 6. 安全余量（20%）
    safe_memory = total_memory * 1.2

    return int(safe_memory)


# 示例：计算 1000 万向量的内存需求
memory_needed = calculate_querynode_memory(
    num_vectors=10_000_000,
    vector_dim=768,
    index_type="IVF_PQ",
    num_partitions_loaded=2
)

print(f"所需内存: {memory_needed / (1024**3):.2f} GB")
# 输出: 所需内存: 14.40 GB
```

### 2. DataNode 内存配置

**DataNode** 负责数据写入和持久化。

```yaml
# milvus.yaml
dataNode:
  # 内存限制
  memory:
    # 插入缓冲区大小（单位：MB）
    # 建议：1-4GB
    insertBufferSize: 2048  # 2GB

    # Flush 阈值（当缓冲区达到此大小时触发持久化）
    flushThreshold: 0.8  # 80%
```

**配置建议**：

```python
# DataNode 内存配置建议
def recommend_datanode_memory(write_qps: int, avg_vector_size: int) -> dict:
    """
    根据写入 QPS 推荐 DataNode 内存配置

    参数：
    - write_qps: 每秒写入向量数
    - avg_vector_size: 平均向量大小（字节）

    返回：
    - 推荐配置
    """
    # 1. 计算每秒写入数据量
    bytes_per_second = write_qps * avg_vector_size

    # 2. 缓冲区应该能容纳 10-30 秒的数据
    buffer_seconds = 20
    buffer_size = bytes_per_second * buffer_seconds

    # 3. 最小 1GB，最大 8GB
    buffer_size = max(1 * 1024**3, min(buffer_size, 8 * 1024**3))

    return {
        "insertBufferSize": buffer_size // (1024**2),  # 转换为 MB
        "flushThreshold": 0.8,
        "recommendedMemory": buffer_size * 1.5  # 总内存需求（含开销）
    }


# 示例：高写入场景
config = recommend_datanode_memory(
    write_qps=10000,  # 每秒 1 万条
    avg_vector_size=3072  # 768维 float32 = 3072 bytes
)

print(f"推荐配置:")
print(f"  insertBufferSize: {config['insertBufferSize']} MB")
print(f"  总内存需求: {config['recommendedMemory'] / (1024**3):.2f} GB")
# 输出:
#   insertBufferSize: 585 MB
#   总内存需求: 0.86 GB
```

### 3. IndexNode 内存配置

**IndexNode** 负责构建索引。

```yaml
# milvus.yaml
indexNode:
  # 内存限制
  memory:
    # 索引构建内存限制（单位：字节）
    # 建议：物理内存的 50-60%
    buildMemoryLimit: 10737418240  # 10GB
```

**索引构建内存需求**：

```python
# 索引构建内存计算
def calculate_index_build_memory(
    num_vectors: int,
    vector_dim: int,
    index_type: str
) -> int:
    """
    计算索引构建所需内存

    注意：索引构建时的内存需求通常是最终索引大小的 2-3 倍
    """
    raw_size = num_vectors * vector_dim * 4

    # 构建时的内存倍数
    build_multiplier = {
        "FLAT": 1.0,
        "IVF_FLAT": 2.0,   # 需要额外空间做聚类
        "IVF_SQ8": 2.5,    # 量化训练需要更多内存
        "IVF_PQ": 3.0,     # PQ 训练最耗内存
        "HNSW": 2.5,       # 图构建需要额外空间
    }

    multiplier = build_multiplier.get(index_type, 2.0)
    build_memory = raw_size * multiplier

    return int(build_memory)


# 示例
build_mem = calculate_index_build_memory(
    num_vectors=10_000_000,
    vector_dim=768,
    index_type="IVF_PQ"
)

print(f"索引构建内存: {build_mem / (1024**3):.2f} GB")
# 输出: 索引构建内存: 86.40 GB
```

---

## 内存配置最佳实践

### 1. 分层内存策略

```python
"""
分层内存策略：根据数据访问频率分配内存
"""

class TieredMemoryStrategy:
    def __init__(self, total_memory_gb: int):
        self.total_memory = total_memory_gb * (1024**3)

    def allocate(self, data_profile: dict) -> dict:
        """
        根据数据特征分配内存

        data_profile = {
            "hot_data_ratio": 0.2,    # 热数据占比（20%）
            "warm_data_ratio": 0.3,   # 温数据占比（30%）
            "cold_data_ratio": 0.5,   # 冷数据占比（50%）
        }
        """
        # 1. 热数据：全部加载到内存
        hot_memory = self.total_memory * 0.6  # 60% 内存给热数据

        # 2. 温数据：部分加载（使用压缩索引）
        warm_memory = self.total_memory * 0.3  # 30% 内存给温数据

        # 3. 冷数据：按需加载（使用缓存）
        cold_memory = self.total_memory * 0.1  # 10% 内存给冷数据缓存

        return {
            "hot_data": {
                "memory": hot_memory,
                "strategy": "全部加载，使用 HNSW 或 IVF_FLAT",
                "expected_latency": "< 10ms"
            },
            "warm_data": {
                "memory": warm_memory,
                "strategy": "压缩加载，使用 IVF_SQ8",
                "expected_latency": "10-50ms"
            },
            "cold_data": {
                "memory": cold_memory,
                "strategy": "按需加载，使用 IVF_PQ + 缓存",
                "expected_latency": "50-200ms"
            }
        }


# 示例
strategy = TieredMemoryStrategy(total_memory_gb=32)
allocation = strategy.allocate({
    "hot_data_ratio": 0.2,
    "warm_data_ratio": 0.3,
    "cold_data_ratio": 0.5,
})

for tier, config in allocation.items():
    print(f"{tier}:")
    print(f"  内存: {config['memory'] / (1024**3):.2f} GB")
    print(f"  策略: {config['strategy']}")
    print(f"  延迟: {config['expected_latency']}")
```

### 2. 动态内存调整

```python
"""
根据实际负载动态调整内存分配
"""

class DynamicMemoryManager:
    def __init__(self, total_memory_gb: int):
        self.total_memory = total_memory_gb * (1024**3)
        self.current_allocation = {}

    def adjust_based_on_metrics(self, metrics: dict) -> dict:
        """
        根据监控指标调整内存分配

        metrics = {
            "memory_usage": 0.85,      # 当前内存使用率
            "cache_hit_rate": 0.6,     # 缓存命中率
            "query_latency_p99": 150,  # P99 延迟（ms）
        }
        """
        adjustments = {}

        # 1. 内存使用率过高 → 释放部分数据或增加压缩
        if metrics["memory_usage"] > 0.9:
            adjustments["action"] = "释放冷数据或增加压缩"
            adjustments["target_usage"] = 0.8

        # 2. 缓存命中率低 → 增加缓存大小
        elif metrics["cache_hit_rate"] < 0.7:
            adjustments["action"] = "增加缓存 20%"
            adjustments["cache_increase"] = 0.2

        # 3. 延迟过高 → 增加内存分配
        elif metrics["query_latency_p99"] > 100:
            adjustments["action"] = "增加热数据内存 10%"
            adjustments["memory_increase"] = 0.1

        else:
            adjustments["action"] = "保持当前配置"

        return adjustments


# 示例
manager = DynamicMemoryManager(total_memory_gb=32)
adjustments = manager.adjust_based_on_metrics({
    "memory_usage": 0.85,
    "cache_hit_rate": 0.6,
    "query_latency_p99": 150,
})

print(f"调整建议: {adjustments['action']}")
```

---

## 在 RAG 系统中的应用

### 场景：多租户文档问答系统

```python
"""
场景：
- 100 个租户
- 每个租户 10 万篇文档
- 总向量数：5000 万（每篇文档 5 个 chunk）
- 向量维度：1536（OpenAI embedding）
"""

class RAGMemoryPlanner:
    def __init__(self, available_memory_gb: int):
        self.available_memory = available_memory_gb * (1024**3)

    def plan_for_multi_tenant(
        self,
        num_tenants: int,
        vectors_per_tenant: int,
        vector_dim: int
    ) -> dict:
        """
        为多租户 RAG 系统规划内存
        """
        # 1. 计算总数据量
        total_vectors = num_tenants * vectors_per_tenant
        raw_size = total_vectors * vector_dim * 4

        print(f"总数据量: {raw_size / (1024**3):.2f} GB")

        # 2. 使用压缩索引（IVF_PQ）
        compressed_size = raw_size * 0.15  # 压缩到 15%

        print(f"压缩后: {compressed_size / (1024**3):.2f} GB")

        # 3. 分区策略：每个租户一个分区
        # 只加载活跃租户的分区（假设 20% 活跃）
        active_ratio = 0.2
        loaded_size = compressed_size * active_ratio

        print(f"加载到内存: {loaded_size / (1024**3):.2f} GB")

        # 4. 查询缓冲区（20%）
        query_buffer = loaded_size * 0.2

        # 5. 总内存需求
        total_needed = loaded_size + query_buffer

        # 6. 检查是否满足
        if total_needed <= self.available_memory * 0.8:
            status = "✅ 内存充足"
        else:
            status = "❌ 内存不足，需要增加压缩或减少加载分区"

        return {
            "total_data_size_gb": raw_size / (1024**3),
            "compressed_size_gb": compressed_size / (1024**3),
            "loaded_size_gb": loaded_size / (1024**3),
            "query_buffer_gb": query_buffer / (1024**3),
            "total_needed_gb": total_needed / (1024**3),
            "available_gb": self.available_memory / (1024**3),
            "status": status
        }


# 示例
planner = RAGMemoryPlanner(available_memory_gb=32)
plan = planner.plan_for_multi_tenant(
    num_tenants=100,
    vectors_per_tenant=500_000,  # 10万文档 × 5 chunks
    vector_dim=1536
)

print("\n内存规划结果:")
for key, value in plan.items():
    print(f"  {key}: {value}")

# 输出:
# 总数据量: 286.10 GB
# 压缩后: 42.92 GB
# 加载到内存: 8.58 GB
#
# 内存规划结果:
#   total_data_size_gb: 286.1
#   compressed_size_gb: 42.92
#   loaded_size_gb: 8.58
#   query_buffer_gb: 1.72
#   total_needed_gb: 10.30
#   available_gb: 32.0
#   status: ✅ 内存充足
```

---

## 常见问题

### Q1: 如何知道当前内存使用情况？

```python
from pymilvus import utility

# 获取 Collection 的内存使用
stats = utility.get_query_segment_info("my_collection")

total_memory = 0
for segment in stats:
    total_memory += segment.mem_size

print(f"Collection 内存使用: {total_memory / (1024**3):.2f} GB")
```

### Q2: 内存不足时如何优化？

**优化策略**：
1. **使用压缩索引**：IVF_SQ8 或 IVF_PQ
2. **分区加载**：只加载活跃分区
3. **增加物理内存**：最直接的方案
4. **使用分布式部署**：多个 QueryNode 分担负载

### Q3: 如何预估生产环境的内存需求？

```python
def estimate_production_memory(
    num_vectors: int,
    vector_dim: int,
    index_type: str,
    num_replicas: int = 2,
    safety_margin: float = 1.5
) -> float:
    """
    预估生产环境内存需求

    参数：
    - num_vectors: 向量数量
    - vector_dim: 向量维度
    - index_type: 索引类型
    - num_replicas: 副本数（高可用）
    - safety_margin: 安全余量（1.5 = 50% 余量）

    返回：
    - 所需内存（GB）
    """
    # 基础内存计算
    base_memory = calculate_querynode_memory(
        num_vectors, vector_dim, index_type
    )

    # 考虑副本
    with_replicas = base_memory * num_replicas

    # 安全余量
    final_memory = with_replicas * safety_margin

    return final_memory / (1024**3)


# 示例
memory_gb = estimate_production_memory(
    num_vectors=50_000_000,
    vector_dim=768,
    index_type="IVF_PQ",
    num_replicas=2,
    safety_margin=1.5
)

print(f"生产环境推荐内存: {memory_gb:.2f} GB")
# 输出: 生产环境推荐内存: 43.20 GB
```

---

## 总结

**内存配置的核心原则**：
1. **优先保证热数据在内存**：80/20 原则
2. **使用压缩索引降低内存需求**：IVF_PQ 可压缩到 15%
3. **分区加载**：只加载活跃分区
4. **预留安全余量**：至少 20-30%
5. **持续监控和调优**：根据实际负载动态调整
