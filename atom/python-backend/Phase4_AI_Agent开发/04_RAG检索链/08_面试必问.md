# RAG检索链 - 面试必问

> 高频面试问题与出彩回答

---

## 问题1："什么是 RAG？它解决了什么问题？"

### 普通回答（❌ 不出彩）

"RAG 是检索增强生成，就是先检索文档，再让 LLM 生成答案。它可以让 LLM 回答更准确。"

**问题**：
- 太简单，没有深度
- 没有说明为什么需要 RAG
- 没有体现对技术的理解

---

### 出彩回答（✅ 推荐）

> **RAG 有三层含义：**
>
> **1. 技术层面**：RAG 是 Retrieval-Augmented Generation 的缩写，通过检索外部知识库、注入到 LLM 上下文、让 LLM 基于真实文档生成答案的技术。
>
> **2. 问题层面**：RAG 解决了 LLM 的两大核心问题：
> - **知识截止日期**：LLM 的知识是训练时固化的，无法回答最新信息
> - **幻觉问题**：LLM 不知道自己不知道什么，会编造看似合理的答案
>
> **3. 架构层面**：RAG 的本质是**上下文工程**和**知识外部化**：
> - 不改变 LLM 本身（不需要重新训练）
> - 通过动态注入上下文让 LLM 看到最新、最准确的信息
> - 知识存储在向量库中，可以随时更新、追溯来源
>
> **与微调的区别**：
> - **微调**：把知识固化到模型参数中，成本高、更新慢、不可追溯
> - **RAG**：把知识存储在外部，成本低、更新快、可追溯来源
>
> **在实际工作中的应用**：
> - 我在项目中用 RAG 构建了公司内部文档问答系统
> - 使用 LangChain + ChromaDB，支持 PDF/Markdown 文档
> - 实现了文档上传即可检索，解决了员工查找公司政策的痛点

---

### 为什么这个回答出彩？

1. ✅ **多层次解释**：从技术、问题、架构三个层面理解 RAG
2. ✅ **对比说明**：与微调对比，突出 RAG 的优势
3. ✅ **实际应用**：结合项目经验，展示实战能力
4. ✅ **技术深度**：提到上下文工程、知识外部化等核心概念

---

## 问题2："RAG 的核心流程是什么？每一步的作用是什么？"

### 普通回答（❌ 不出彩）

"RAG 的流程是：先把文档向量化存入数据库，然后检索相关文档，最后让 LLM 生成答案。"

**问题**：
- 流程描述不完整（缺少分块、Prompt 构造等）
- 没有说明每一步的作用
- 没有技术细节

---

### 出彩回答（✅ 推荐）

> **RAG 分为两个阶段：索引阶段和检索阶段**
>
> **索引阶段（离线）**：
> 1. **文档加载**：从 PDF/TXT/Markdown 等格式加载文档
>    - 作用：获取原始文本数据
> 2. **文本分块（Chunking）**：把长文档切成小块（通常 500-1000 字符）
>    - 作用：适配 LLM 上下文窗口限制，提升检索精度
> 3. **向量化（Embedding）**：把每个文本块转换为向量
>    - 作用：将文本转换为可计算相似度的数字表示
> 4. **存储**：把向量和原始文本存入向量数据库
>    - 作用：支持高效的相似度检索
>
> **检索阶段（在线）**：
> 1. **问题向量化**：把用户问题转换为向量
>    - 作用：与文档向量在同一空间中比较
> 2. **相似度检索**：在向量库中检索 Top-K 最相似的文档块
>    - 作用：找到最相关的知识
> 3. **上下文构造**：把检索到的文档注入到 Prompt 模板中
>    - 作用：为 LLM 提供回答问题所需的知识
> 4. **LLM 生成**：LLM 基于上下文生成答案
>    - 作用：理解文档并生成自然语言回答
>
> **关键技术点**：
> - **Chunking 策略**：需要保持语义完整性，通常按段落分割，设置重叠（overlap）
> - **Embedding 模型**：常用 OpenAI text-embedding-3-small 或 sentence-transformers
> - **相似度计算**：通常用余弦相似度（cosine similarity）
> - **Top-K 选择**：k 值通常 3-5，太多会引入噪音
>
> **在实际项目中的优化**：
> - 使用 RecursiveCharacterTextSplitter 保持语义完整
> - 添加元数据过滤（如文档类型、时间）提升检索精度
> - 使用 ReRank 模型二次排序，提升 Top-K 质量

---

### 为什么这个回答出彩？

1. ✅ **结构清晰**：分为索引和检索两个阶段
2. ✅ **每步都有作用说明**：不是简单列举，而是解释为什么需要这一步
3. ✅ **技术细节**：提到具体的工具、参数、算法
4. ✅ **实战经验**：结合项目中的优化策略

---

## 问题3："如何优化 RAG 的检索质量？"

### 普通回答（❌ 不出彩）

"可以调整 k 值，或者用更好的 Embedding 模型。"

**问题**：
- 方法太少，不全面
- 没有说明为什么这些方法有效
- 没有实战经验

---

### 出彩回答（✅ 推荐）

> **RAG 检索质量优化有三个层次：**
>
> **1. 检索策略优化**
>
> **混合检索（Hybrid Search）**：
> - 结合向量检索（语义相似）和关键词检索（精确匹配）
> - 适用场景：用户问题包含专有名词、代码、数字等
> - 实现：使用 BM25 + 向量检索，加权融合结果
>
> **ReRank 重排序**：
> - 先用向量检索快速筛选 Top-20 候选
> - 再用更精细的模型（如 Cross-Encoder）重新排序，选出 Top-3
> - 效果：准确率提升 10-20%，但延迟增加 100-200ms
>
> **元数据过滤**：
> - 在向量检索前先过滤元数据（如文档类型、时间、作者）
> - 适用场景：知识库很大，需要缩小检索范围
>
> **2. 文档处理优化**
>
> **Chunking 策略**：
> - 不要固定大小切割，按语义单元（段落、章节）分块
> - 设置 overlap（重叠）避免语义被截断
> - 我的经验：chunk_size=500, overlap=50 是一个好的起点
>
> **文档增强**：
> - 为每个 chunk 添加上下文信息（如章节标题、文档摘要）
> - 提升检索时的语义理解
>
> **3. Prompt 工程优化**
>
> **明确指令**：
> - 在 Prompt 中明确要求"基于文档回答"
> - 要求 LLM 引用来源（如"根据文档第3页..."）
>
> **Few-shot 示例**：
> - 在 Prompt 中提供好的回答示例
> - 引导 LLM 生成高质量答案
>
> **在实际项目中的效果**：
> - 使用混合检索 + ReRank，准确率从 65% 提升到 82%
> - 添加元数据过滤后，检索速度提升 3 倍
> - 优化 Chunking 策略后，用户满意度提升 25%

---

### 为什么这个回答出彩？

1. ✅ **系统性**：从检索、文档、Prompt 三个层次优化
2. ✅ **每个方法都有说明**：为什么有效、适用场景、权衡
3. ✅ **量化效果**：提供具体的提升数据
4. ✅ **实战经验**：结合项目中的实际效果

---

## 问题4："RAG 和微调（Fine-tuning）有什么区别？什么时候用 RAG，什么时候用微调？"

### 普通回答（❌ 不出彩）

"RAG 是检索文档，微调是训练模型。RAG 更简单，微调更准确。"

**问题**：
- 对比不全面
- 没有说明选择标准
- 没有深度理解

---

### 出彩回答（✅ 推荐）

> **RAG 和微调的本质区别：**
>
> | 维度 | RAG | 微调 |
> |------|-----|------|
> | **知识存储** | 外部向量库 | 模型参数 |
> | **更新成本** | 低（上传新文档即可） | 高（需要重新训练） |
> | **可追溯性** | 高（可以看到引用来源） | 低（黑盒） |
> | **适用场景** | 知识频繁更新、需要引用来源 | 特定领域、固定知识 |
> | **成本** | 低（只需要向量化） | 高（需要 GPU 训练） |
> | **延迟** | 较高（需要检索） | 低（直接生成） |
> | **准确性** | 依赖检索质量 | 依赖训练数据质量 |
>
> **选择标准：**
>
> **用 RAG 的场景**：
> 1. **知识频繁更新**：如公司文档、新闻、政策
> 2. **需要引用来源**：如法律咨询、医疗问答
> 3. **知识库很大**：如维基百科、技术文档
> 4. **成本敏感**：没有 GPU 资源或预算
>
> **用微调的场景**：
> 1. **特定领域语言**：如医疗术语、法律用语
> 2. **固定知识**：如数学公式、编程语法
> 3. **对延迟敏感**：如实时对话
> 4. **知识可以固化**：如历史事实、科学定律
>
> **组合使用**：
> - 微调 + RAG：先微调让 LLM 理解领域语言，再用 RAG 提供最新知识
> - 例如：微调医疗 LLM 理解医学术语，用 RAG 检索最新医学论文
>
> **在实际项目中的选择**：
> - 我们的客服系统用 RAG：因为产品文档每周更新
> - 我们的代码助手用微调：因为编程语法是固定的
> - 我们的法律咨询用 RAG：因为需要引用法条来源

---

### 为什么这个回答出彩？

1. ✅ **全面对比**：从多个维度对比 RAG 和微调
2. ✅ **明确选择标准**：什么场景用什么技术
3. ✅ **提到组合使用**：展示对技术的深度理解
4. ✅ **实际案例**：结合项目中的技术选型

---

## 问题5："RAG 的常见问题和解决方案是什么？"

### 普通回答（❌ 不出彩）

"RAG 可能检索不准确，可以用更好的模型。"

**问题**：
- 问题太少，不全面
- 解决方案太简单
- 没有实战经验

---

### 出彩回答（✅ 推荐）

> **RAG 的五大常见问题：**
>
> **1. 检索不准确**
> - **表现**：检索到的文档与问题不相关
> - **原因**：向量相似度≠语义相关，Embedding 模型理解有限
> - **解决方案**：
>   - 使用混合检索（向量 + 关键词）
>   - 添加 ReRank 重排序
>   - 优化 Chunking 策略（保持语义完整）
>
> **2. 上下文窗口溢出**
> - **表现**：检索到的文档太多，超出 LLM 上下文限制
> - **原因**：k 值设置过大，或 chunk_size 过大
> - **解决方案**：
>   - 减小 k 值（通常 3-5 即可）
>   - 使用 ReRank 精选最相关的文档
>   - 动态调整 k 值（根据问题复杂度）
>
> **3. 答案不完整**
> - **表现**：LLM 只基于部分文档回答，遗漏重要信息
> - **原因**：相关信息分散在多个 chunk 中
> - **解决方案**：
>   - 增加 chunk overlap（重叠）
>   - 使用 Parent Document Retriever（检索小块，返回大块）
>   - 多轮检索（根据初步答案再次检索）
>
> **4. 幻觉问题仍然存在**
> - **表现**：即使检索到文档，LLM 仍然编造答案
> - **原因**：Prompt 设计不当，LLM 没有严格遵循文档
> - **解决方案**：
>   - 在 Prompt 中明确要求"仅基于文档回答"
>   - 要求 LLM 引用来源（如"根据文档第3页..."）
>   - 使用 Few-shot 示例引导 LLM
>
> **5. 检索速度慢**
> - **表现**：用户提问后等待时间长（>3秒）
> - **原因**：向量库太大，检索算法不优化
> - **解决方案**：
>   - 使用 FAISS 等高性能向量库
>   - 添加元数据过滤缩小检索范围
>   - 使用缓存（相同问题直接返回缓存结果）
>
> **在实际项目中的经验**：
> - 遇到检索不准确，使用混合检索 + ReRank 后准确率提升 20%
> - 遇到上下文溢出，动态调整 k 值（简单问题 k=2，复杂问题 k=5）
> - 遇到幻觉问题，优化 Prompt 后幻觉率从 15% 降到 5%

---

### 为什么这个回答出彩？

1. ✅ **问题全面**：覆盖 RAG 的主要痛点
2. ✅ **每个问题都有原因和解决方案**：展示分析能力
3. ✅ **量化效果**：提供具体的改进数据
4. ✅ **实战经验**：结合项目中遇到的实际问题

---

## 面试准备建议

### 1. 准备项目案例

**推荐结构**：
```
项目背景 → 技术选型 → 实现细节 → 遇到的问题 → 解决方案 → 效果
```

**示例**：
- "我在项目中构建了公司内部文档问答系统"
- "选择 LangChain + ChromaDB，因为..."
- "实现了文档上传、分块、向量化、检索、生成的完整流程"
- "遇到检索不准确的问题，通过混合检索 + ReRank 解决"
- "准确率从 65% 提升到 82%，用户满意度提升 25%"

### 2. 掌握核心概念

**必须掌握**：
- [ ] RAG 的定义和价值
- [ ] RAG 的完整流程（索引 + 检索）
- [ ] Embedding 原理和常用模型
- [ ] 向量数据库的作用
- [ ] Chunking 策略
- [ ] Top-K 检索
- [ ] Prompt 工程

**加分项**：
- [ ] 混合检索
- [ ] ReRank 重排序
- [ ] RAG 与微调的对比
- [ ] RAG 的常见问题和解决方案

### 3. 准备代码示例

**推荐准备**：
- 一个最简单的 RAG 实现（20 行代码）
- 一个完整的 RAG 系统（包含文档处理、检索、生成）
- 一个优化案例（如混合检索、ReRank）

### 4. 了解最新技术

**2024-2025 年的 RAG 新趋势**：
- **多模态 RAG**：支持图片、表格、视频
- **Agent + RAG**：Agent 自主决定何时检索
- **GraphRAG**：基于知识图谱的检索
- **Self-RAG**：LLM 自我评估检索质量

---

**下一步**：学习 [09_化骨绵掌](./09_化骨绵掌.md)，通过 10 个知识卡片深入理解 RAG。
