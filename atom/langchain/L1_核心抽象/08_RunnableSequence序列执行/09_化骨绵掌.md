# 化骨绵掌

> 10个2分钟知识卡片，系统掌握 RunnableSequence

---

## 使用说明

**化骨绵掌**：武侠小说中的内功心法，看似柔和，实则深入骨髓。

**10个知识卡片**：
- 每个卡片独立完整，可单独理解
- 2分钟内可看完（~200字）
- 10个卡片形成递进关系，覆盖所有核心概念

**学习方式**：
- 快速浏览：10分钟通读全部卡片
- 深度学习：每天学习2个卡片，5天完成
- 复习巩固：随时查阅单个卡片

---

## 卡片1：直觉理解 - RunnableSequence 是什么

**一句话**：RunnableSequence 是用 `|` 操作符连接多个 Runnable 组件的执行链，数据从左到右依次流转。

**举例**：
```python
# 最简单的例子
chain = prompt | llm | parser

# 数据流转
input → prompt处理 → llm生成 → parser解析 → output
```

**类比**：
- 像工厂流水线：原材料 → 加工 → 组装 → 成品
- 像水管系统：水源 → 过滤 → 加热 → 水龙头
- 像接力赛：第1棒 → 第2棒 → 第3棒 → 终点

**应用**：90% 的 LangChain 应用都使用 RunnableSequence，是最常用的组合模式。

---

## 卡片2：形式化定义 - 精确表述

**一句话**：RunnableSequence 是实现了 Runnable 协议的序列组合器，通过 `__or__` 魔法方法重载 `|` 操作符。

**形式化定义**：
```python
class RunnableSequence(Runnable[Input, Output]):
    """序列组合器"""

    def __init__(self, *steps: Runnable):
        self.steps = list(steps)

    def invoke(self, input: Input) -> Output:
        result = input
        for step in self.steps:
            result = step.invoke(result)
        return result

    def batch(self, inputs: List[Input]) -> List[Output]:
        # 并行执行所有输入
        ...

    def stream(self, input: Input) -> Iterator[Output]:
        # 流式输出
        ...
```

**关键特性**：
- 实现 Runnable 协议（invoke/batch/stream）
- 维护组件列表（steps）
- 支持链式组合（`__or__`）

**应用**：理解形式化定义有助于手写简化版实现，深入理解原理。

---

## 卡片3：管道操作符 - `|` 的魔法

**一句话**：`|` 操作符通过 Python 的 `__or__` 魔法方法实现，自动创建 RunnableSequence。

**实现原理**：
```python
class Runnable:
    def __or__(self, other: Runnable) -> RunnableSequence:
        # 当使用 a | b 时，Python 调用 a.__or__(b)
        return RunnableSequence(self, other)

# 使用示例
a = PromptTemplate(...)
b = ChatOpenAI(...)
c = a | b  # 自动调用 a.__or__(b)，返回 RunnableSequence(a, b)
```

**扁平化优化**：
```python
# a | b | c 不会创建嵌套的 RunnableSequence
# 而是扁平化为 RunnableSequence(a, b, c)
```

**为什么选择 `|`**：
- Unix 管道使用 `|`，开发者熟悉
- 视觉上像管道，符合直觉
- 可以重载（Python 支持）

**应用**：理解 `|` 的实现有助于理解 LCEL 的设计哲学。

---

## 卡片4：三种执行方式 - invoke/batch/stream

**一句话**：RunnableSequence 提供三种执行方式，满足不同场景需求。

**invoke - 单次执行**：
```python
result = chain.invoke(input)  # 等待完整结果
```
- 适用：API 服务、命令行工具
- 特点：等待全部完成，返回完整结果

**batch - 批量执行**：
```python
results = chain.batch([input1, input2, input3])  # 并行处理
```
- 适用：批量评估、数据标注
- 特点：自动并行，性能提升 20-30x
- 优化：使用 `max_concurrency` 控制并发数

**stream - 流式输出**：
```python
for chunk in chain.stream(input):  # 实时输出
    print(chunk, end="", flush=True)
```
- 适用：对话应用、进度显示
- 特点：实时反馈，降低首字延迟
- 优化：使用 `astream` 异步流式

**应用**：根据场景选择合适的执行方式，提升用户体验和性能。

---

## 卡片5：数据流转 - 输入输出如何传递

**一句话**：数据从左到右依次流转，每个组件的输出自动成为下一个组件的输入。

**流转机制**：
```python
chain = step1 | step2 | step3

# 执行过程
input → step1.invoke(input) → output1
output1 → step2.invoke(output1) → output2
output2 → step3.invoke(output2) → final_output
```

**类型转换**：
```python
# 自动适配不同类型
chain = (
    prompt  # 输出: PromptValue
    | llm   # 输入: PromptValue, 输出: AIMessage
    | parser  # 输入: AIMessage, 输出: str
)
```

**字典输入**：
```python
# 支持字典输入（RunnableParallel）
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt  # 接收字典，展开为变量
    | llm
    | parser
)
```

**应用**：理解数据流转有助于调试链，快速定位问题。

---

## 卡片6：错误处理 - with_retry 和 with_fallbacks

**一句话**：使用 `with_retry` 重试临时性错误，使用 `with_fallbacks` 降级永久性错误。

**with_retry - 自动重试**：
```python
chain_with_retry = chain.with_retry(
    stop_after_attempt=3,           # 最多重试3次
    wait_exponential_jitter=True    # 指数退避 + 随机抖动
)
```
- 适用：网络抖动、API 限流
- 策略：指数退避（1s → 2s → 4s）
- 注意：设置最大重试次数，避免无限重试

**with_fallbacks - 降级方案**：
```python
main_chain = prompt | ChatOpenAI(model="gpt-4") | parser
fallback_chain = prompt | ChatOpenAI(model="gpt-3.5-turbo") | parser

chain_with_fallback = main_chain.with_fallbacks([fallback_chain])
```
- 适用：模型不可用、成本过高
- 策略：主链失败时自动切换
- 注意：可以有多个降级层级

**组合使用**（生产级）：
```python
production_chain = (
    chain
    .with_retry(stop_after_attempt=3)
    .with_fallbacks([fallback_chain])
)
```

**应用**：生产环境必须添加错误处理，提升稳定性到 99.9%。

---

## 卡片7：批处理优化 - 性能提升 20-30x

**一句话**：batch 模式通过并行执行和批量 API 调用，显著提升性能。

**并行执行**：
```python
# ❌ 串行执行（慢）
results = []
for input in inputs:
    results.append(chain.invoke(input))
# 100个输入需要 200秒

# ✅ 并行执行（快）
results = chain.batch(inputs)
# 100个输入只需要 7秒（加速 28x）
```

**控制并发数**：
```python
results = chain.batch(
    inputs,
    config={"max_concurrency": 10}  # 最多10个并发
)
```

**批量 API**：
```python
# 某些 API 支持批量请求（如 OpenAI Batch API）
# LangChain 自动使用批量 API
```

**成本优化**（2026 新特性）：
```python
from langasync import wrap_chain

async_chain = wrap_chain(chain, batch_size=10)
results = await async_chain.abatch(inputs)  # 成本降低 50%
```

**应用**：批量评估、数据标注、离线分析等场景，优先使用 batch。

---

## 卡片8：流式执行 - 实时反馈

**一句话**：stream 模式通过逐块输出，降低首字延迟，提升用户体验。

**基础流式**：
```python
for chunk in chain.stream(input):
    print(chunk, end="", flush=True)
```

**异步流式**：
```python
async for chunk in chain.astream(input):
    print(chunk, end="", flush=True)
```

**查看中间结果**（调试神器）：
```python
async for event in chain.astream_events(input, version="v2"):
    kind = event["event"]
    if kind == "on_chain_start":
        print(f"开始: {event['name']}")
    elif kind == "on_chain_end":
        print(f"结束: {event['name']}, 输出: {event['data']['output']}")
```

**性能对比**：
- invoke：等待全部完成（首字延迟高）
- stream：逐块输出（首字延迟低）
- 实测：对话场景，stream 首字延迟降低 80%

**应用**：对话机器人、实时翻译、进度显示等场景，优先使用 stream。

---

## 卡片9：可观测性 - 调试与监控

**一句话**：使用 LangSmith 和 astream_events 追踪执行过程，快速定位问题。

**LangSmith 集成**：
```python
import os
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = "your_key"

# 自动追踪所有链的执行
result = chain.invoke(input)
# 在 LangSmith 控制台查看详细追踪
```

**astream_events 调试**：
```python
async for event in chain.astream_events(input, version="v2"):
    print(f"{event['event']}: {event['name']}")
    if event['event'] == 'on_chain_end':
        print(f"输出: {event['data']['output']}")
```

**添加标记**：
```python
chain_with_name = chain.with_config({
    "run_name": "production_rag_chain",
    "tags": ["rag", "production"]
})
```

**回调系统**：
```python
from langchain.callbacks import StdOutCallbackHandler

class CustomHandler(StdOutCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        print(f"开始执行: {serialized['name']}")

chain.invoke(input, config={"callbacks": [CustomHandler()]})
```

**应用**：生产环境必须集成可观测性，快速定位和解决问题。

---

## 卡片10：最佳实践 - 生产级 RunnableSequence

**一句话**：生产级 RunnableSequence 需要错误处理、可观测性、性能优化三位一体。

**完整示例**：
```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ===== 1. 构建基础链 =====
prompt = ChatPromptTemplate.from_template("解释：{topic}")
llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()
base_chain = prompt | llm | parser

# ===== 2. 添加错误处理 =====
# 重试
chain_with_retry = base_chain.with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True
)

# 降级
fallback_llm = ChatOpenAI(model="gpt-3.5-turbo")
fallback_chain = prompt | fallback_llm | parser
chain_with_fallback = chain_with_retry.with_fallbacks([fallback_chain])

# ===== 3. 添加可观测性 =====
production_chain = chain_with_fallback.with_config({
    "run_name": "explain_chain",
    "tags": ["production", "explain"]
})

# ===== 4. 使用 =====
# 单次查询
result = production_chain.invoke({"topic": "量子计算"})

# 批量处理
results = production_chain.batch(
    [{"topic": "AI"}, {"topic": "ML"}, {"topic": "DL"}],
    config={"max_concurrency": 5}
)

# 流式输出
for chunk in production_chain.stream({"topic": "区块链"}):
    print(chunk, end="", flush=True)
```

**检查清单**：
- ✅ 添加 with_retry（重试3次）
- ✅ 添加 with_fallbacks（降级方案）
- ✅ 添加 run_name 和 tags（可观测性）
- ✅ 集成 LangSmith（追踪）
- ✅ 使用 batch（批量任务）
- ✅ 使用 stream（实时反馈）
- ✅ 控制 max_concurrency（避免限流）

**应用**：所有生产环境的链都应该遵循这个模式。

---

## 知识卡片总结

### 10个卡片的递进关系

```
卡片1: 直觉理解 → 建立基本概念
  ↓
卡片2: 形式化定义 → 精确理解
  ↓
卡片3: 管道操作符 → 理解语法
  ↓
卡片4: 三种执行方式 → 掌握用法
  ↓
卡片5: 数据流转 → 理解机制
  ↓
卡片6: 错误处理 → 生产必备
  ↓
卡片7: 批处理优化 → 性能提升
  ↓
卡片8: 流式执行 → 用户体验
  ↓
卡片9: 可观测性 → 调试监控
  ↓
卡片10: 最佳实践 → 综合应用
```

### 核心概念覆盖

| 核心概念 | 对应卡片 | 重要性 |
|---------|---------|--------|
| 基本定义 | 卡片1、2 | ⭐⭐⭐ |
| 管道操作符 | 卡片3 | ⭐⭐⭐ |
| 执行方式 | 卡片4 | ⭐⭐⭐ |
| 数据流转 | 卡片5 | ⭐⭐ |
| 错误处理 | 卡片6 | ⭐⭐⭐ |
| 批处理 | 卡片7 | ⭐⭐⭐ |
| 流式执行 | 卡片8 | ⭐⭐⭐ |
| 可观测性 | 卡片9 | ⭐⭐ |
| 最佳实践 | 卡片10 | ⭐⭐⭐ |

### 学习路径建议

**快速入门**（10分钟）：
- 卡片1: 直觉理解
- 卡片4: 三种执行方式
- 卡片10: 最佳实践

**深度学习**（30分钟）：
- 按顺序阅读所有10个卡片
- 运行每个卡片的代码示例
- 修改参数观察效果

**面试准备**（15分钟）：
- 卡片1: 直觉理解（快速定义）
- 卡片2: 形式化定义（精确表述）
- 卡片3: 管道操作符（实现原理）
- 卡片6: 错误处理（生产实践）
- 卡片10: 最佳实践（综合应用）

**生产实践**（20分钟）：
- 卡片6: 错误处理
- 卡片7: 批处理优化
- 卡片8: 流式执行
- 卡片9: 可观测性
- 卡片10: 最佳实践

---

## 快速参考表

### 核心 API

| API | 用途 | 示例 |
|-----|------|------|
| `a \| b` | 创建序列链 | `prompt \| llm \| parser` |
| `chain.invoke(input)` | 单次执行 | `chain.invoke({"q": "AI"})` |
| `chain.batch(inputs)` | 批量执行 | `chain.batch([input1, input2])` |
| `chain.stream(input)` | 流式输出 | `for chunk in chain.stream(input)` |
| `chain.with_retry(...)` | 添加重试 | `chain.with_retry(stop_after_attempt=3)` |
| `chain.with_fallbacks([...])` | 添加降级 | `chain.with_fallbacks([fallback])` |
| `chain.with_config({...})` | 添加配置 | `chain.with_config({"run_name": "..."})` |
| `chain.astream_events(...)` | 调试追踪 | `async for event in chain.astream_events(...)` |

### 常见模式

| 模式 | 代码 | 说明 |
|------|------|------|
| **基础链** | `prompt \| llm \| parser` | 最简单的序列链 |
| **RAG 链** | `{context: retriever, q: pass} \| prompt \| llm` | 检索增强生成 |
| **重试链** | `chain.with_retry(stop_after_attempt=3)` | 自动重试 |
| **降级链** | `main.with_fallbacks([fallback])` | 主链失败时降级 |
| **生产链** | `chain.with_retry(...).with_fallbacks([...])` | 重试 + 降级 |
| **批量处理** | `chain.batch(inputs, config={"max_concurrency": 10})` | 并行批处理 |
| **流式输出** | `for chunk in chain.stream(input)` | 实时流式 |
| **调试追踪** | `async for event in chain.astream_events(input)` | 查看中间结果 |

### 性能优化

| 场景 | 优化方法 | 提升 |
|------|----------|------|
| 批量任务 | 使用 `batch` 而非循环 `invoke` | 20-30x |
| 实时对话 | 使用 `stream` 降低首字延迟 | 80% |
| 成本优化 | 使用 `langasync` 批处理 | 50% |
| 并发控制 | 设置 `max_concurrency` | 避免限流 |
| 错误处理 | 添加 `with_retry` 和 `with_fallbacks` | 99.9% 稳定性 |

---

## 学习检查清单

完成10个知识卡片学习后，你应该能够：

### 理解层面
- [ ] 能用一句话解释 RunnableSequence
- [ ] 理解 `|` 操作符的实现原理
- [ ] 理解三种执行方式的区别
- [ ] 理解数据流转机制
- [ ] 理解错误处理策略

### 应用层面
- [ ] 能构建基础的 prompt | llm | parser 链
- [ ] 能使用 invoke/batch/stream 执行链
- [ ] 能添加 with_retry 和 with_fallbacks
- [ ] 能使用 astream_events 调试链
- [ ] 能构建生产级的完整链

### 实战层面
- [ ] 能构建 RAG 问答链
- [ ] 能实现批处理优化
- [ ] 能实现流式输出
- [ ] 能集成 LangSmith 可观测性
- [ ] 能应用所有最佳实践

---

## 下一步学习

### 如果你想深入理解原理

阅读核心概念文件：
- `03_核心概念_01_序列组合原理.md`
- `03_核心概念_02_管道操作符实现.md`
- `03_核心概念_03_数据流转机制.md`

### 如果你想看更多实战案例

阅读实战代码文件：
- `07_实战代码_01_基础序列链构建.md`
- `07_实战代码_02_复杂数据流转.md`
- `07_实战代码_03_错误处理与降级.md`

### 如果你想准备面试

阅读：
- `08_面试必问.md` - 高频面试问题
- `06_反直觉点.md` - 常见误区

---

**版本**: v1.0
**最后更新**: 2026-02-18
**参考来源**:
- LangChain 官方文档
- Pinecone - LCEL Tutorial
- Analytics Vidhya - LCEL Guide
- Medium - Production-Ready AI Pipelines
