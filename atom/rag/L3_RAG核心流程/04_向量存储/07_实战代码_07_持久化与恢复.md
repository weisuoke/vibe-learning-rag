# 实战代码07：持久化与恢复

## 代码说明

本示例展示向量索引的持久化存储、备份恢复和增量更新策略，确保数据安全和系统可靠性。

**环境要求**：
```bash
pip install hnswlib chromadb faiss-cpu numpy
```

---

## 完整代码

```python
"""
向量索引持久化与恢复示例
演示快照备份、增量备份和数据恢复策略
"""

import hnswlib
import chromadb
import faiss
import numpy as np
import os
import shutil
import time
import json
from pathlib import Path
from typing import Dict, List, Any

# ============================================
# 1. HNSW索引持久化
# ============================================

def hnsw_persistence_example():
    """HNSW索引持久化示例"""
    print("=" * 50)
    print("1. HNSW索引持久化")
    print("=" * 50)

    dimension = 128
    n_vectors = 10000

    # 生成测试数据
    vectors = np.random.randn(n_vectors, dimension).astype('float32')

    # 创建索引
    print("\n创建HNSW索引...")
    index = hnswlib.Index(space='cosine', dim=dimension)
    index.init_index(
        max_elements=n_vectors,
        ef_construction=200,
        M=16
    )
    index.add_items(vectors, list(range(n_vectors)))

    # 保存索引
    index_path = "/tmp/hnsw_index.bin"
    print(f"\n保存索引到: {index_path}")
    index.save_index(index_path)

    file_size = os.path.getsize(index_path) / (1024**2)
    print(f"✓ 索引已保存")
    print(f"  文件大小: {file_size:.2f}MB")

    # 加载索引
    print(f"\n加载索引...")
    loaded_index = hnswlib.Index(space='cosine', dim=dimension)
    loaded_index.load_index(index_path, max_elements=n_vectors)

    print(f"✓ 索引已加载")
    print(f"  向量数量: {loaded_index.get_current_count()}")

    # 验证加载的索引
    query = np.random.randn(dimension).astype('float32')
    loaded_index.set_ef(50)
    labels, distances = loaded_index.knn_query(query, k=5)

    print(f"\n验证查询:")
    print(f"  Top 5结果: {labels[0]}")
    print(f"  ✓ 索引功能正常")


# ============================================
# 2. ChromaDB持久化
# ============================================

def chromadb_persistence_example():
    """ChromaDB持久化示例"""
    print("\n" + "=" * 50)
    print("2. ChromaDB持久化")
    print("=" * 50)

    persist_directory = "/tmp/chroma_db"

    # 创建持久化客户端
    print(f"\n创建持久化客户端...")
    client = chromadb.PersistentClient(path=persist_directory)

    # 创建collection
    collection = client.get_or_create_collection(
        name="test_collection",
        metadata={"hnsw:space": "cosine"}
    )

    # 添加数据
    documents = [
        "RAG是检索增强生成技术",
        "向量数据库用于语义检索",
        "HNSW是高效索引算法"
    ]

    collection.add(
        documents=documents,
        ids=[f"doc_{i}" for i in range(len(documents))],
        metadatas=[{"source": "test"} for _ in documents]
    )

    print(f"✓ 数据已添加")
    print(f"  文档数量: {collection.count()}")

    # 数据自动持久化
    dir_size = sum(
        os.path.getsize(os.path.join(dirpath, filename))
        for dirpath, _, filenames in os.walk(persist_directory)
        for filename in filenames
    ) / (1024**2)

    print(f"\n持久化目录: {persist_directory}")
    print(f"  目录大小: {dir_size:.2f}MB")

    # 重新加载
    print(f"\n重新连接...")
    new_client = chromadb.PersistentClient(path=persist_directory)
    loaded_collection = new_client.get_collection("test_collection")

    print(f"✓ Collection已加载")
    print(f"  文档数量: {loaded_collection.count()}")


# ============================================
# 3. FAISS索引持久化
# ============================================

def faiss_persistence_example():
    """FAISS索引持久化示例"""
    print("\n" + "=" * 50)
    print("3. FAISS索引持久化")
    print("=" * 50)

    dimension = 128
    n_vectors = 10000

    # 生成测试数据
    vectors = np.random.randn(n_vectors, dimension).astype('float32')
    faiss.normalize_L2(vectors)

    # 创建索引
    print("\n创建FAISS索引...")
    index = faiss.IndexHNSWFlat(dimension, 32)
    index.add(vectors)

    # 保存索引
    index_path = "/tmp/faiss_index.bin"
    print(f"\n保存索引到: {index_path}")
    faiss.write_index(index, index_path)

    file_size = os.path.getsize(index_path) / (1024**2)
    print(f"✓ 索引已保存")
    print(f"  文件大小: {file_size:.2f}MB")

    # 加载索引
    print(f"\n加载索引...")
    loaded_index = faiss.read_index(index_path)

    print(f"✓ 索引已加载")
    print(f"  向量数量: {loaded_index.ntotal}")

    # 验证查询
    query = np.random.randn(1, dimension).astype('float32')
    faiss.normalize_L2(query)
    distances, indices = loaded_index.search(query, 5)

    print(f"\n验证查询:")
    print(f"  Top 5结果: {indices[0]}")
    print(f"  ✓ 索引功能正常")


# ============================================
# 4. 快照备份策略
# ============================================

def snapshot_backup_strategy():
    """快照备份策略"""
    print("\n" + "=" * 50)
    print("4. 快照备份策略")
    print("=" * 50)

    # 模拟索引文件
    index_path = "/tmp/hnsw_index.bin"
    backup_dir = "/tmp/backups"

    # 创建备份目录
    os.makedirs(backup_dir, exist_ok=True)

    # 生成时间戳
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    backup_path = os.path.join(backup_dir, f"index_snapshot_{timestamp}.bin")

    print(f"\n创建快照备份...")
    print(f"  源文件: {index_path}")
    print(f"  备份文件: {backup_path}")

    # 复制文件
    if os.path.exists(index_path):
        shutil.copy2(index_path, backup_path)
        print(f"✓ 快照备份完成")

        # 备份元数据
        metadata = {
            "timestamp": timestamp,
            "source": index_path,
            "backup": backup_path,
            "size_mb": os.path.getsize(backup_path) / (1024**2),
            "vector_count": 10000,
            "dimension": 128
        }

        metadata_path = backup_path.replace(".bin", ".json")
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        print(f"  元数据: {metadata_path}")
    else:
        print(f"✗ 源文件不存在")

    # 列出所有备份
    print(f"\n备份列表:")
    backups = sorted([f for f in os.listdir(backup_dir) if f.endswith('.bin')])
    for backup in backups:
        backup_file = os.path.join(backup_dir, backup)
        size_mb = os.path.getsize(backup_file) / (1024**2)
        mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(os.path.getmtime(backup_file)))
        print(f"  - {backup} ({size_mb:.2f}MB, {mtime})")


# ============================================
# 5. 增量备份策略
# ============================================

def incremental_backup_strategy():
    """增量备份策略"""
    print("\n" + "=" * 50)
    print("5. 增量备份策略")
    print("=" * 50)

    # 模拟增量数据
    base_index_path = "/tmp/hnsw_index.bin"
    incremental_dir = "/tmp/incremental"

    os.makedirs(incremental_dir, exist_ok=True)

    print("\n增量备份策略:")
    print("  1. 基础索引: 完整快照")
    print("  2. 增量数据: 只保存新增向量")
    print("  3. 恢复时: 基础索引 + 增量数据")

    # 模拟增量数据
    incremental_vectors = np.random.randn(1000, 128).astype('float32')
    incremental_ids = list(range(10000, 11000))

    # 保存增量数据
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    incremental_path = os.path.join(incremental_dir, f"incremental_{timestamp}.npz")

    np.savez(
        incremental_path,
        vectors=incremental_vectors,
        ids=incremental_ids
    )

    print(f"\n✓ 增量数据已保存")
    print(f"  文件: {incremental_path}")
    print(f"  新增向量: {len(incremental_ids)}")

    # 恢复示例
    print(f"\n恢复流程:")
    print(f"  1. 加载基础索引: {base_index_path}")
    print(f"  2. 加载增量数据: {incremental_path}")
    print(f"  3. 合并数据到索引")

    # 加载增量数据
    if os.path.exists(incremental_path):
        data = np.load(incremental_path)
        print(f"\n✓ 增量数据已加载")
        print(f"  向量数量: {len(data['vectors'])}")
        print(f"  ID范围: {data['ids'][0]} - {data['ids'][-1]}")


# ============================================
# 6. 数据恢复流程
# ============================================

def data_recovery_workflow():
    """数据恢复流程"""
    print("\n" + "=" * 50)
    print("6. 数据恢复流程")
    print("=" * 50)

    dimension = 128
    backup_path = "/tmp/backups/index_snapshot_20260215_120000.bin"

    print("\n恢复流程:")
    print("  步骤1: 验证备份文件完整性")
    print("  步骤2: 加载备份索引")
    print("  步骤3: 验证索引功能")
    print("  步骤4: 应用增量数据（如有）")
    print("  步骤5: 切换到恢复的索引")

    # 模拟恢复
    print(f"\n执行恢复...")

    # 步骤1: 验证文件
    if os.path.exists("/tmp/hnsw_index.bin"):
        print(f"  ✓ 步骤1: 备份文件存在")

        # 步骤2: 加载索引
        try:
            index = hnswlib.Index(space='cosine', dim=dimension)
            index.load_index("/tmp/hnsw_index.bin", max_elements=10000)
            print(f"  ✓ 步骤2: 索引加载成功")

            # 步骤3: 验证功能
            query = np.random.randn(dimension).astype('float32')
            index.set_ef(50)
            labels, distances = index.knn_query(query, k=5)
            print(f"  ✓ 步骤3: 索引功能正常")

            # 步骤4: 应用增量（模拟）
            print(f"  ✓ 步骤4: 增量数据已应用")

            # 步骤5: 切换索引
            print(f"  ✓ 步骤5: 索引切换完成")

            print(f"\n✓ 数据恢复成功")
            print(f"  向量数量: {index.get_current_count()}")

        except Exception as e:
            print(f"  ✗ 恢复失败: {e}")
    else:
        print(f"  ✗ 步骤1: 备份文件不存在")


# ============================================
# 7. 版本管理策略
# ============================================

def version_management_strategy():
    """版本管理策略"""
    print("\n" + "=" * 50)
    print("7. 版本管理策略")
    print("=" * 50)

    backup_dir = "/tmp/backups"

    print("\n版本管理策略:")
    print("  - 保留最近7天的每日备份")
    print("  - 保留最近4周的每周备份")
    print("  - 保留最近12个月的每月备份")

    # 模拟版本清理
    print(f"\n清理旧版本...")

    if os.path.exists(backup_dir):
        backups = sorted([f for f in os.listdir(backup_dir) if f.endswith('.bin')])

        # 按时间分类
        daily_backups = backups[-7:] if len(backups) > 7 else backups
        weekly_backups = backups[-28::7] if len(backups) > 28 else []
        monthly_backups = backups[-365::30] if len(backups) > 365 else []

        # 保留的备份
        keep_backups = set(daily_backups + weekly_backups + monthly_backups)

        print(f"  总备份数: {len(backups)}")
        print(f"  保留数量: {len(keep_backups)}")
        print(f"    - 每日备份: {len(daily_backups)}")
        print(f"    - 每周备份: {len(weekly_backups)}")
        print(f"    - 每月备份: {len(monthly_backups)}")

        # 删除旧备份（模拟）
        to_delete = [b for b in backups if b not in keep_backups]
        if to_delete:
            print(f"\n  将删除{len(to_delete)}个旧备份")
        else:
            print(f"\n  无需删除旧备份")


# ============================================
# 8. RAG应用场景
# ============================================

def rag_persistence_example():
    """RAG应用的持久化示例"""
    print("\n" + "=" * 50)
    print("8. RAG应用持久化示例")
    print("=" * 50)

    print("\nRAG系统持久化架构:")
    print("""
    ┌─────────────────────────────────────┐
    │         RAG应用层                    │
    └─────────────────────────────────────┘
                    ↓
    ┌─────────────────────────────────────┐
    │      向量索引（内存）                 │
    │  - HNSW索引                          │
    │  - 快速查询                          │
    └─────────────────────────────────────┘
                    ↓
    ┌─────────────────────────────────────┐
    │      持久化层                        │
    │  - 每日快照备份                      │
    │  - 增量数据备份                      │
    │  - 版本管理                          │
    └─────────────────────────────────────┘
                    ↓
    ┌─────────────────────────────────────┐
    │      存储层                          │
    │  - 本地磁盘                          │
    │  - 对象存储（S3/OSS）                │
    │  - 备份存储                          │
    └─────────────────────────────────────┘
    """)

    print("\n持久化最佳实践:")
    print("  1. 定期快照: 每日凌晨自动备份")
    print("  2. 增量备份: 每小时保存新增数据")
    print("  3. 异地备份: 同步到对象存储")
    print("  4. 版本管理: 保留多个历史版本")
    print("  5. 恢复演练: 定期测试恢复流程")


# ============================================
# 9. 持久化性能对比
# ============================================

def persistence_performance_comparison():
    """持久化性能对比"""
    print("\n" + "=" * 50)
    print("9. 持久化性能对比")
    print("=" * 50)

    dimension = 128
    n_vectors = 10000

    vectors = np.random.randn(n_vectors, dimension).astype('float32')

    # HNSW持久化
    print("\nHNSW持久化:")
    index = hnswlib.Index(space='cosine', dim=dimension)
    index.init_index(max_elements=n_vectors, ef_construction=200, M=16)
    index.add_items(vectors, list(range(n_vectors)))

    start = time.time()
    index.save_index("/tmp/hnsw_perf.bin")
    save_time = time.time() - start

    start = time.time()
    loaded = hnswlib.Index(space='cosine', dim=dimension)
    loaded.load_index("/tmp/hnsw_perf.bin", max_elements=n_vectors)
    load_time = time.time() - start

    file_size = os.path.getsize("/tmp/hnsw_perf.bin") / (1024**2)

    print(f"  保存时间: {save_time:.3f}秒")
    print(f"  加载时间: {load_time:.3f}秒")
    print(f"  文件大小: {file_size:.2f}MB")

    # FAISS持久化
    print("\nFAISS持久化:")
    faiss_index = faiss.IndexHNSWFlat(dimension, 32)
    faiss_index.add(vectors)

    start = time.time()
    faiss.write_index(faiss_index, "/tmp/faiss_perf.bin")
    faiss_save_time = time.time() - start

    start = time.time()
    faiss_loaded = faiss.read_index("/tmp/faiss_perf.bin")
    faiss_load_time = time.time() - start

    faiss_file_size = os.path.getsize("/tmp/faiss_perf.bin") / (1024**2)

    print(f"  保存时间: {faiss_save_time:.3f}秒")
    print(f"  加载时间: {faiss_load_time:.3f}秒")
    print(f"  文件大小: {faiss_file_size:.2f}MB")

    # 对比
    print("\n性能对比:")
    print(f"  HNSW vs FAISS (保存): {faiss_save_time/save_time:.2f}x")
    print(f"  HNSW vs FAISS (加载): {faiss_load_time/load_time:.2f}x")
    print(f"  HNSW vs FAISS (大小): {faiss_file_size/file_size:.2f}x")


# ============================================
# 主函数
# ============================================

def main():
    """主函数"""
    print("向量索引持久化与恢复示例")
    print("=" * 50)

    # 1. HNSW持久化
    hnsw_persistence_example()

    # 2. ChromaDB持久化
    chromadb_persistence_example()

    # 3. FAISS持久化
    faiss_persistence_example()

    # 4. 快照备份
    snapshot_backup_strategy()

    # 5. 增量备份
    incremental_backup_strategy()

    # 6. 数据恢复
    data_recovery_workflow()

    # 7. 版本管理
    version_management_strategy()

    # 8. RAG应用场景
    rag_persistence_example()

    # 9. 性能对比
    persistence_performance_comparison()

    print("\n" + "=" * 50)
    print("所有示例执行完成！")
    print("=" * 50)


if __name__ == "__main__":
    main()
```

---

## 关键要点

### 1. 持久化策略对比

| 策略 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| 快照备份 | 简单可靠 | 占用空间大 | 每日备份 |
| 增量备份 | 节省空间 | 恢复复杂 | 频繁更新 |
| 实时同步 | 数据最新 | 性能开销 | 关键数据 |

### 2. 备份频率建议

**开发环境**：
- 快照：每周一次
- 增量：不需要

**生产环境**：
- 快照：每日一次（凌晨）
- 增量：每小时一次
- 异地备份：每日同步

**关键业务**：
- 快照：每6小时
- 增量：每15分钟
- 实时同步：对象存储

### 3. 恢复时间目标（RTO）

```
数据量 < 1GB:   RTO < 5分钟
数据量 1-10GB:  RTO < 30分钟
数据量 > 10GB:  RTO < 2小时
```

### 4. 存储成本优化

**本地存储**：
- 快速访问
- 成本较高
- 适合热数据

**对象存储（S3/OSS）**：
- 成本低廉
- 访问较慢
- 适合冷备份

**存储分层**：
```
最近7天 → 本地SSD
7-30天 → 本地HDD
>30天 → 对象存储
```

### 5. RAG系统持久化检查清单

**每日任务**：
- [ ] 自动快照备份
- [ ] 验证备份完整性
- [ ] 同步到对象存储
- [ ] 清理过期备份

**每周任务**：
- [ ] 恢复演练
- [ ] 性能测试
- [ ] 容量规划

**每月任务**：
- [ ] 灾难恢复演练
- [ ] 备份策略评估
- [ ] 成本分析

---

## 引用来源

1. **备份策略**：
   - https://medium.com/@alexchen3292/safeguarding-data-integrity-best-practices-for-backup-and-recovery-in-vector-databases
   - https://zilliz.com/learn/vector-database-backup-and-recovery-safeguard-data-integrity

2. **持久化实践**：
   - https://www.meegle.com/en_us/topics/vector-databases/vector-database-backup-strategies
   - https://www.cncf.io/blog/2024/10/29/backup-and-recovery-for-vector-databases-on-kubernetes-using-kanister

3. **Milvus备份**：
   - https://medium.com/@CarlosMartes/backups-are-not-optional-how-i-design-vector-database-backup-recovery-for-milvus

---

**最后更新**：2026-02-15
**基于资料**：2025-2026最新持久化与恢复实践
