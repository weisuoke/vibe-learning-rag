# 核心概念：FIFO队列

## 概述

**FIFO队列（First In First Out Queue）是最基础的队列类型，遵循先进先出原则，保证任务按提交顺序执行。**

---

## 定义与特性

### 核心定义

FIFO队列是一种线性数据结构，具有以下特性：
1. **先进先出**：最先入队的元素最先出队
2. **单向流动**：元素从队尾入队，从队首出队
3. **顺序保证**：严格维护元素的时间顺序

### 基本操作

```python
# FIFO队列的基本操作
class Queue:
    def enqueue(self, item):
        """入队：将元素添加到队尾"""
        pass

    def dequeue(self):
        """出队：移除并返回队首元素"""
        pass

    def peek(self):
        """查看：返回队首元素但不移除"""
        pass

    def is_empty(self):
        """判空：检查队列是否为空"""
        pass

    def size(self):
        """大小：返回队列中元素数量"""
        pass
```

---

## 实现方式

### 方式1：基于列表（简单但低效）

```python
class ListQueue:
    """基于Python列表的队列实现"""

    def __init__(self):
        self.items = []

    def enqueue(self, item):
        """入队：O(1)"""
        self.items.append(item)

    def dequeue(self):
        """出队：O(n) - 需要移动所有元素"""
        if self.is_empty():
            raise IndexError("队列为空")
        return self.items.pop(0)

    def peek(self):
        """查看：O(1)"""
        if self.is_empty():
            raise IndexError("队列为空")
        return self.items[0]

    def is_empty(self):
        """判空：O(1)"""
        return len(self.items) == 0

    def size(self):
        """大小：O(1)"""
        return len(self.items)

# 测试
queue = ListQueue()
queue.enqueue(1)
queue.enqueue(2)
queue.enqueue(3)
print(queue.dequeue())  # 1
print(queue.peek())     # 2
print(queue.size())     # 2
```

**问题**：`pop(0)` 需要移动所有元素，时间复杂度O(n)

### 方式2：基于deque（推荐）

```python
from collections import deque

class DequeQueue:
    """基于deque的队列实现（推荐）"""

    def __init__(self):
        self.items = deque()

    def enqueue(self, item):
        """入队：O(1)"""
        self.items.append(item)

    def dequeue(self):
        """出队：O(1)"""
        if self.is_empty():
            raise IndexError("队列为空")
        return self.items.popleft()

    def peek(self):
        """查看：O(1)"""
        if self.is_empty():
            raise IndexError("队列为空")
        return self.items[0]

    def is_empty(self):
        """判空：O(1)"""
        return len(self.items) == 0

    def size(self):
        """大小：O(1)"""
        return len(self.items)

# 测试
queue = DequeQueue()
queue.enqueue(1)
queue.enqueue(2)
queue.enqueue(3)
print(queue.dequeue())  # 1
print(queue.peek())     # 2
print(queue.size())     # 2
```

**优点**：所有操作都是O(1)

### 方式3：基于链表

```python
class Node:
    """链表节点"""
    def __init__(self, data):
        self.data = data
        self.next = None

class LinkedQueue:
    """基于链表的队列实现"""

    def __init__(self):
        self.head = None  # 队首
        self.tail = None  # 队尾
        self._size = 0

    def enqueue(self, item):
        """入队：O(1)"""
        new_node = Node(item)

        if self.tail is None:
            # 队列为空
            self.head = new_node
            self.tail = new_node
        else:
            # 添加到队尾
            self.tail.next = new_node
            self.tail = new_node

        self._size += 1

    def dequeue(self):
        """出队：O(1)"""
        if self.is_empty():
            raise IndexError("队列为空")

        data = self.head.data
        self.head = self.head.next

        if self.head is None:
            # 队列变空
            self.tail = None

        self._size -= 1
        return data

    def peek(self):
        """查看：O(1)"""
        if self.is_empty():
            raise IndexError("队列为空")
        return self.head.data

    def is_empty(self):
        """判空：O(1)"""
        return self.head is None

    def size(self):
        """大小：O(1)"""
        return self._size

# 测试
queue = LinkedQueue()
queue.enqueue(1)
queue.enqueue(2)
queue.enqueue(3)
print(queue.dequeue())  # 1
print(queue.peek())     # 2
print(queue.size())     # 2
```

**优点**：
- 所有操作O(1)
- 动态大小，无需预分配空间

**缺点**：
- 每个元素需要额外的指针空间
- 缓存局部性差

---

## Python标准库队列

### queue.Queue（线程安全）

```python
from queue import Queue

# 创建队列
q = Queue(maxsize=10)  # 最大容量10

# 入队
q.put(1)
q.put(2)
q.put(3)

# 出队
item = q.get()
print(item)  # 1

# 非阻塞操作
try:
    item = q.get_nowait()  # 立即返回或抛出异常
except:
    print("队列为空")

# 阻塞操作
item = q.get(timeout=5)  # 最多等待5秒

# 队列大小
print(q.qsize())  # 2

# 判空
print(q.empty())  # False

# 判满
print(q.full())   # False
```

**特点**：
- 线程安全（使用锁）
- 支持阻塞和超时
- 适合多线程场景

### asyncio.Queue（异步）

```python
import asyncio

async def producer(queue):
    """生产者"""
    for i in range(5):
        await queue.put(f"任务{i}")
        print(f"生产: 任务{i}")
        await asyncio.sleep(0.1)

async def consumer(queue):
    """消费者"""
    while True:
        item = await queue.get()
        print(f"消费: {item}")
        await asyncio.sleep(0.2)
        queue.task_done()

async def main():
    queue = asyncio.Queue(maxsize=10)

    # 启动生产者和消费者
    producer_task = asyncio.create_task(producer(queue))
    consumer_task = asyncio.create_task(consumer(queue))

    # 等待生产者完成
    await producer_task

    # 等待队列清空
    await queue.join()

    # 取消消费者
    consumer_task.cancel()

asyncio.run(main())
```

**特点**：
- 异步非阻塞
- 适合I/O密集型任务
- 单线程高并发

---

## AI Agent应用场景

### 场景1：LLM API请求队列

```python
import asyncio
from typing import List, Dict

class LLMRequestQueue:
    """LLM API请求队列"""

    def __init__(self, rate_limit: int = 10):
        self.queue = asyncio.Queue()
        self.rate_limit = rate_limit
        self.interval = 1.0 / rate_limit

    async def add_request(self, request: Dict):
        """添加请求到队列"""
        await self.queue.put(request)

    async def process(self):
        """处理队列中的请求"""
        while True:
            request = await self.queue.get()

            try:
                # 调用LLM API
                response = await self._call_llm_api(request)
                print(f"请求成功: {request['prompt'][:30]}...")

            except Exception as e:
                print(f"请求失败: {e}")

            finally:
                # 限流
                await asyncio.sleep(self.interval)
                self.queue.task_done()

    async def _call_llm_api(self, request: Dict):
        """模拟LLM API调用"""
        await asyncio.sleep(0.1)
        return {"response": f"回复: {request['prompt']}"}

# 使用
async def main():
    queue = LLMRequestQueue(rate_limit=5)

    # 启动处理器
    asyncio.create_task(queue.process())

    # 添加请求
    for i in range(10):
        await queue.add_request({
            "prompt": f"请求{i}",
            "model": "gpt-4"
        })

    # 等待所有请求完成
    await queue.queue.join()

asyncio.run(main())
```

### 场景2：用户消息队列

```python
import asyncio
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Message:
    user_id: str
    content: str
    timestamp: datetime

class MessageQueue:
    """用户消息队列"""

    def __init__(self):
        self.queue = asyncio.Queue()

    async def send_message(self, user_id: str, content: str):
        """发送消息"""
        message = Message(
            user_id=user_id,
            content=content,
            timestamp=datetime.now()
        )
        await self.queue.put(message)

    async def process_messages(self):
        """处理消息"""
        while True:
            message = await self.queue.get()

            # 处理消息
            await self._handle_message(message)

            self.queue.task_done()

    async def _handle_message(self, message: Message):
        """处理单条消息"""
        print(f"[{message.timestamp}] {message.user_id}: {message.content}")
        await asyncio.sleep(0.1)

# 使用
async def main():
    queue = MessageQueue()

    # 启动处理器
    asyncio.create_task(queue.process_messages())

    # 发送消息
    await queue.send_message("user1", "你好")
    await queue.send_message("user2", "世界")
    await queue.send_message("user1", "再见")

    # 等待所有消息处理完成
    await queue.queue.join()

asyncio.run(main())
```

### 场景3：任务批处理队列

```python
import asyncio
from typing import List, Callable

class BatchQueue:
    """批处理队列"""

    def __init__(self, batch_size: int = 10, timeout: float = 1.0):
        self.queue = asyncio.Queue()
        self.batch_size = batch_size
        self.timeout = timeout

    async def add_task(self, task):
        """添加任务"""
        await self.queue.put(task)

    async def process_batches(self, processor: Callable):
        """批量处理任务"""
        while True:
            batch = []

            try:
                # 收集一批任务
                while len(batch) < self.batch_size:
                    task = await asyncio.wait_for(
                        self.queue.get(),
                        timeout=self.timeout
                    )
                    batch.append(task)

            except asyncio.TimeoutError:
                # 超时，处理当前批次
                pass

            if batch:
                # 批量处理
                await processor(batch)

                # 标记任务完成
                for _ in batch:
                    self.queue.task_done()

# 使用
async def batch_processor(batch: List):
    """批量处理器"""
    print(f"批量处理 {len(batch)} 个任务")
    await asyncio.sleep(0.5)

async def main():
    queue = BatchQueue(batch_size=5, timeout=1.0)

    # 启动处理器
    asyncio.create_task(queue.process_batches(batch_processor))

    # 添加任务
    for i in range(12):
        await queue.add_task(f"任务{i}")
        await asyncio.sleep(0.1)

    # 等待所有任务完成
    await queue.queue.join()

asyncio.run(main())
```

---

## 性能对比

### 基准测试

```python
import time
from collections import deque
from queue import Queue

def benchmark_list_queue(n=10000):
    """测试基于列表的队列"""
    queue = []
    start = time.time()

    for i in range(n):
        queue.append(i)

    for i in range(n):
        queue.pop(0)

    return time.time() - start

def benchmark_deque_queue(n=10000):
    """测试基于deque的队列"""
    queue = deque()
    start = time.time()

    for i in range(n):
        queue.append(i)

    for i in range(n):
        queue.popleft()

    return time.time() - start

def benchmark_thread_queue(n=10000):
    """测试线程安全队列"""
    queue = Queue()
    start = time.time()

    for i in range(n):
        queue.put(i)

    for i in range(n):
        queue.get()

    return time.time() - start

# 运行测试
print(f"列表队列: {benchmark_list_queue():.4f}秒")
print(f"deque队列: {benchmark_deque_queue():.4f}秒")
print(f"线程队列: {benchmark_thread_queue():.4f}秒")
```

**结果**（10000个元素）：
```
列表队列: 0.8234秒  # O(n²) 性能差
deque队列: 0.0012秒  # O(n) 性能好
线程队列: 0.0156秒  # O(n) 有锁开销
```

### 内存占用对比

```python
import sys

# 列表队列
list_queue = list(range(1000))
print(f"列表队列: {sys.getsizeof(list_queue)} 字节")

# deque队列
deque_queue = deque(range(1000))
print(f"deque队列: {sys.getsizeof(deque_queue)} 字节")

# 链表队列（估算）
# 每个节点: 对象头(16) + 数据(8) + 指针(8) = 32字节
linked_queue_size = 1000 * 32
print(f"链表队列: {linked_queue_size} 字节（估算）")
```

**结果**：
```
列表队列: 9016 字节
deque队列: 8856 字节
链表队列: 32000 字节（估算）
```

---

## 常见问题

### Q1：为什么不用list.pop(0)？

**A**：`pop(0)` 需要移动所有元素，时间复杂度O(n)

```python
# 错误：使用list.pop(0)
queue = [1, 2, 3, 4, 5]
queue.pop(0)  # 需要移动[2,3,4,5]到前面

# 正确：使用deque.popleft()
from collections import deque
queue = deque([1, 2, 3, 4, 5])
queue.popleft()  # O(1)操作
```

### Q2：何时使用queue.Queue vs asyncio.Queue？

**A**：
- **多线程** → `queue.Queue`
- **异步I/O** → `asyncio.Queue`

```python
# 多线程场景
import threading
from queue import Queue

def worker(queue):
    while True:
        item = queue.get()
        # 处理任务
        queue.task_done()

q = Queue()
for i in range(5):
    t = threading.Thread(target=worker, args=(q,))
    t.start()

# 异步场景
import asyncio

async def worker(queue):
    while True:
        item = await queue.get()
        # 处理任务
        queue.task_done()

async def main():
    q = asyncio.Queue()
    workers = [asyncio.create_task(worker(q)) for _ in range(5)]

asyncio.run(main())
```

### Q3：如何处理队列满的情况？

**A**：三种策略

```python
from queue import Queue, Full

q = Queue(maxsize=10)

# 策略1：阻塞等待
q.put(item)  # 队列满时阻塞

# 策略2：超时
try:
    q.put(item, timeout=5)  # 最多等待5秒
except Full:
    print("队列满，超时")

# 策略3：非阻塞
try:
    q.put_nowait(item)  # 立即返回或抛出异常
except Full:
    print("队列满，拒绝")
```

---

## 最佳实践

### 1. 选择合适的实现

```python
# 简单场景：使用deque
from collections import deque
queue = deque()

# 多线程：使用queue.Queue
from queue import Queue
queue = Queue()

# 异步I/O：使用asyncio.Queue
import asyncio
queue = asyncio.Queue()
```

### 2. 设置队列大小上限

```python
# 防止内存溢出
queue = asyncio.Queue(maxsize=1000)

# 监控队列长度
if queue.qsize() > 800:
    print("警告：队列接近满")
```

### 3. 优雅关闭

```python
async def graceful_shutdown(queue, workers):
    """优雅关闭队列"""
    # 等待队列清空
    await queue.join()

    # 取消所有worker
    for worker in workers:
        worker.cancel()

    # 等待worker退出
    await asyncio.gather(*workers, return_exceptions=True)
```

### 4. 错误处理

```python
async def safe_worker(queue):
    """带错误处理的worker"""
    while True:
        try:
            item = await queue.get()
            await process(item)
        except Exception as e:
            print(f"处理失败: {e}")
        finally:
            queue.task_done()
```

---

## 总结

### 核心要点

1. **FIFO原则**：先进先出，保证顺序
2. **实现选择**：deque > list，asyncio.Queue适合异步
3. **性能**：所有操作应该是O(1)
4. **应用**：API限流、消息队列、任务调度

### 选择指南

| 场景 | 推荐实现 | 原因 |
|------|----------|------|
| 简单队列 | `collections.deque` | 高性能，O(1)操作 |
| 多线程 | `queue.Queue` | 线程安全 |
| 异步I/O | `asyncio.Queue` | 非阻塞 |
| 自定义 | 链表实现 | 灵活性高 |

### 记忆口诀

**"先到先服务，deque最高效，多线程用Queue，异步用asyncio"**

---

**关键洞察**：FIFO队列是最基础但也是最重要的队列类型。在AI Agent开发中，90%的场景使用FIFO队列就足够了。掌握FIFO队列的实现和应用，是学习其他队列类型的基础。
