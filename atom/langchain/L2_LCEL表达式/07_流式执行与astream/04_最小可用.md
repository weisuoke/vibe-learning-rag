# æœ€å°å¯ç”¨çŸ¥è¯†

## å­¦ä¹ ç›®æ ‡

æŒæ¡æµå¼æ‰§è¡Œçš„æœ€å°å¿…è¦çŸ¥è¯†ï¼Œèƒ½å¤Ÿåœ¨å®é™…é¡¹ç›®ä¸­å¿«é€Ÿå®ç°åŸºæœ¬çš„æµå¼è¾“å‡ºåŠŸèƒ½ã€‚

---

## æ ¸å¿ƒæ¦‚å¿µé€Ÿè§ˆ

### ä»€ä¹ˆæ˜¯æµå¼æ‰§è¡Œï¼Ÿ

**æµå¼æ‰§è¡Œï¼ˆStreamingï¼‰** æ˜¯ä¸€ç§è®© AI åº”ç”¨é€æ­¥è¿”å›ç»“æœçš„æœºåˆ¶ï¼Œè€Œä¸æ˜¯ç­‰å¾…å…¨éƒ¨è®¡ç®—å®Œæˆåä¸€æ¬¡æ€§è¿”å›ã€‚

**ç±»æ¯”**ï¼š
- **å‰ç«¯å¼€å‘**ï¼šServer-Sent Events (SSE) - æœåŠ¡å™¨æŒç»­æ¨é€æ•°æ®åˆ°å®¢æˆ·ç«¯
- **æ—¥å¸¸ç”Ÿæ´»**ï¼šçœ‹ç›´æ’­ vs çœ‹å½•æ’­ - ç›´æ’­æ˜¯å®æ—¶çš„ï¼Œå½•æ’­éœ€è¦ç­‰å¾…å…¨éƒ¨ä¸‹è½½

### ä¸ºä»€ä¹ˆéœ€è¦æµå¼ï¼Ÿ

1. **ç”¨æˆ·ä½“éªŒ**ï¼šç«‹å³çœ‹åˆ°è¾“å‡ºå¼€å§‹ï¼Œæ„Ÿè§‰æ›´å¿«
2. **é•¿æ–‡æœ¬ç”Ÿæˆ**ï¼šæ–‡ç« ã€æŠ¥å‘Šç­‰é•¿å†…å®¹çš„å®æ—¶å±•ç¤º
3. **å¤šæ­¥ä»»åŠ¡**ï¼šAgent æ‰§è¡Œå¤šä¸ªæ­¥éª¤æ—¶ï¼Œå®æ—¶è¿½è¸ªè¿›åº¦
4. **è°ƒè¯•ç›‘æ§**ï¼šå¼€å‘é˜¶æ®µæŸ¥çœ‹æ‰§è¡Œæµç¨‹

---

## æœ€å° API é›†

### 1. åŸºç¡€æµå¼è¾“å‡º

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# åˆ›å»ºæ¨¡å‹å’Œæç¤º
model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template("è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯")

# åˆ›å»ºé“¾
chain = prompt | model

# åŒæ­¥æµå¼ï¼ˆä¸æ¨èï¼‰
for chunk in chain.stream({"topic": "ç¨‹åºå‘˜"}):
    print(chunk.content, end="", flush=True)

# å¼‚æ­¥æµå¼ï¼ˆæ¨èï¼‰
import asyncio

async def main():
    async for chunk in chain.astream({"topic": "ç¨‹åºå‘˜"}):
        print(chunk.content, end="", flush=True)

asyncio.run(main())
```

**è¾“å‡ºæ•ˆæœ**ï¼š
```
ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯åˆ†ä¸æ¸…ä¸‡åœ£èŠ‚å’Œåœ£è¯èŠ‚ï¼Ÿ

å› ä¸º Oct 31 == Dec 25
```

---

### 2. ä¸‰ç§æµå¼æ¨¡å¼

#### æ¨¡å¼ 1ï¼š`stream_mode="updates"` - Agent è¿›åº¦æµå¼

**ç”¨é€”**ï¼šè¿½è¸ª Agent æ‰§è¡Œçš„æ¯ä¸ªæ­¥éª¤

```python
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """è·å–åŸå¸‚å¤©æ°”"""
    return f"{city}çš„å¤©æ°”æ˜¯æ™´å¤©"

agent = create_agent(
    model="gpt-4o-mini",
    tools=[get_weather]
)

# æµå¼è¾“å‡ºæ¯ä¸ªæ­¥éª¤
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    stream_mode="updates"
):
    for node_name, data in chunk.items():
        print(f"[{node_name}] {data}")
```

**è¾“å‡º**ï¼š
```
[model] {'messages': [AIMessage(tool_calls=[...])]}
[tools] {'messages': [ToolMessage(content='åŒ—äº¬çš„å¤©æ°”æ˜¯æ™´å¤©')]}
[model] {'messages': [AIMessage(content='åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©')]}
```

---

#### æ¨¡å¼ 2ï¼š`stream_mode="messages"` - LLM ä»¤ç‰Œæµå¼

**ç”¨é€”**ï¼šå®æ—¶æ˜¾ç¤º LLM ç”Ÿæˆçš„æ¯ä¸ª token

```python
from langchain.agents import create_agent

agent = create_agent(model="gpt-4o-mini", tools=[get_weather])

# æµå¼è¾“å‡º LLM tokens
for token, metadata in agent.stream(
    {"messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    stream_mode="messages"
):
    # åªè¾“å‡ºæ–‡æœ¬å†…å®¹
    if hasattr(token, 'content'):
        print(token.content, end="", flush=True)
```

**è¾“å‡º**ï¼š
```
è®©æˆ‘æŸ¥è¯¢ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”...åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©
```

---

#### æ¨¡å¼ 3ï¼š`stream_mode="custom"` - è‡ªå®šä¹‰æ•°æ®æµå¼

**ç”¨é€”**ï¼šå‘é€è‡ªå®šä¹‰è¿›åº¦ä¿¡å·

```python
from langchain.agents import create_agent
from langgraph.config import get_stream_writer

def process_data(query: str) -> str:
    """å¤„ç†æ•°æ®å¹¶å‘é€è¿›åº¦"""
    writer = get_stream_writer()

    writer("æ­¥éª¤ 1: è¿æ¥æ•°æ®åº“...")
    # æ¨¡æ‹Ÿå¤„ç†
    import time
    time.sleep(0.5)

    writer("æ­¥éª¤ 2: æŸ¥è¯¢æ•°æ®...")
    time.sleep(0.5)

    writer("æ­¥éª¤ 3: å¤„ç†ç»“æœ...")
    time.sleep(0.5)

    return "å¤„ç†å®Œæˆ"

agent = create_agent(model="gpt-4o-mini", tools=[process_data])

# æµå¼è¾“å‡ºè‡ªå®šä¹‰æ•°æ®
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "å¤„ç†æ•°æ®"}]},
    stream_mode="custom"
):
    print(chunk)
```

**è¾“å‡º**ï¼š
```
æ­¥éª¤ 1: è¿æ¥æ•°æ®åº“...
æ­¥éª¤ 2: æŸ¥è¯¢æ•°æ®...
æ­¥éª¤ 3: å¤„ç†ç»“æœ...
```

---

### 3. å¤šæ¨¡å¼ç»„åˆ

```python
# åŒæ—¶ä½¿ç”¨å¤šç§æ¨¡å¼
for mode, data in agent.stream(
    {"messages": [{"role": "user", "content": "æŸ¥è¯¢å¤©æ°”"}]},
    stream_mode=["updates", "messages", "custom"]
):
    if mode == "updates":
        print(f"\n[æ­¥éª¤æ›´æ–°] {list(data.keys())}")
    elif mode == "messages":
        token, metadata = data
        if hasattr(token, 'content'):
            print(token.content, end="")
    elif mode == "custom":
        print(f"\n[è‡ªå®šä¹‰] {data}")
```

---

## å®æˆ˜åœºæ™¯

### åœºæ™¯ 1ï¼šChatGPT å¼å¯¹è¯åº”ç”¨

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# åˆ›å»ºå¯¹è¯é“¾
model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"),
    ("user", "{input}")
])
output_parser = StrOutputParser()

chain = prompt | model | output_parser

# æµå¼å¯¹è¯
async def chat_stream(user_input: str):
    async for chunk in chain.astream({"input": user_input}):
        print(chunk, end="", flush=True)
    print()  # æ¢è¡Œ

# ä½¿ç”¨
import asyncio
asyncio.run(chat_stream("ä»‹ç»ä¸€ä¸‹ Python"))
```

---

### åœºæ™¯ 2ï¼šå¤šæ­¥ Agent è¿›åº¦è¿½è¸ª

```python
from langchain.agents import create_agent

def search_web(query: str) -> str:
    """æœç´¢ç½‘ç»œ"""
    return f"æœç´¢ç»“æœ: {query}"

def analyze_data(data: str) -> str:
    """åˆ†ææ•°æ®"""
    return f"åˆ†æç»“æœ: {data}"

agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_web, analyze_data]
)

# è¿½è¸ª Agent æ‰§è¡Œæ­¥éª¤
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æœç´¢å¹¶åˆ†æ Python è¶‹åŠ¿"}]},
    stream_mode="updates"
):
    for node_name, data in chunk.items():
        if node_name == "model":
            # æ¨¡å‹èŠ‚ç‚¹
            msg = data["messages"][-1]
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                print(f"ğŸ¤– è°ƒç”¨å·¥å…·: {msg.tool_calls[0]['name']}")
        elif node_name == "tools":
            # å·¥å…·èŠ‚ç‚¹
            msg = data["messages"][-1]
            print(f"ğŸ”§ å·¥å…·ç»“æœ: {msg.content[:50]}...")
```

---

### åœºæ™¯ 3ï¼šé•¿æ–‡æœ¬ç”Ÿæˆè¿›åº¦æ˜¾ç¤º

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template(
    "å†™ä¸€ç¯‡å…³äº{topic}çš„ 1000 å­—æ–‡ç« "
)

chain = prompt | model

# æ˜¾ç¤ºç”Ÿæˆè¿›åº¦
async def generate_article(topic: str):
    word_count = 0
    async for chunk in chain.astream({"topic": topic}):
        content = chunk.content
        print(content, end="", flush=True)

        # ç»Ÿè®¡å­—æ•°
        word_count += len(content)
        if word_count % 100 == 0:
            print(f"\n[å·²ç”Ÿæˆ {word_count} å­—]", end="")

import asyncio
asyncio.run(generate_article("äººå·¥æ™ºèƒ½"))
```

---

## å¸¸è§é—®é¢˜ä¸è§£å†³

### é—®é¢˜ 1ï¼šæµå¼è¾“å‡ºä¸æ˜¾ç¤º

**åŸå› **ï¼šæ²¡æœ‰ä½¿ç”¨ `flush=True`

```python
# âŒ é”™è¯¯
for chunk in chain.stream(input):
    print(chunk.content, end="")  # å¯èƒ½è¢«ç¼“å†²

# âœ… æ­£ç¡®
for chunk in chain.stream(input):
    print(chunk.content, end="", flush=True)  # ç«‹å³è¾“å‡º
```

---

### é—®é¢˜ 2ï¼šå¼‚æ­¥æµå¼æŠ¥é”™

**åŸå› **ï¼šåœ¨åŒæ­¥ç¯å¢ƒä¸­ä½¿ç”¨ `astream()`

```python
# âŒ é”™è¯¯
async for chunk in chain.astream(input):  # åœ¨åŒæ­¥å‡½æ•°ä¸­
    print(chunk)

# âœ… æ­£ç¡®
import asyncio

async def main():
    async for chunk in chain.astream(input):
        print(chunk)

asyncio.run(main())
```

---

### é—®é¢˜ 3ï¼šè‡ªå®šä¹‰æµå¼ä¸å·¥ä½œ

**åŸå› **ï¼šå¿˜è®°ä½¿ç”¨ `get_stream_writer()`

```python
# âŒ é”™è¯¯
def my_tool(query: str) -> str:
    print("Processing...")  # ä¸ä¼šè¢«æµå¼è¾“å‡º
    return result

# âœ… æ­£ç¡®
from langgraph.config import get_stream_writer

def my_tool(query: str) -> str:
    writer = get_stream_writer()
    writer("Processing...")  # ä¼šè¢«æµå¼è¾“å‡º
    return result
```

---

### é—®é¢˜ 4ï¼šPython < 3.11 æµå¼å¤±è´¥

**åŸå› **ï¼šéœ€è¦æ‰‹åŠ¨ä¼ é€’ `RunnableConfig`

```python
# Python < 3.11
from langchain_core.runnables import RunnableConfig
from langgraph.config import get_stream_writer

def my_tool(query: str, config: RunnableConfig) -> str:
    writer = get_stream_writer(config)  # ä¼ é€’ config
    writer("Processing...")
    return result
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨å¼‚æ­¥æµå¼

```python
# âŒ åŒæ­¥ï¼ˆé˜»å¡ï¼‰
for chunk in chain.stream(input):
    process(chunk)

# âœ… å¼‚æ­¥ï¼ˆéé˜»å¡ï¼‰
async for chunk in chain.astream(input):
    await process(chunk)
```

---

### 2. ç¦ç”¨ä¸éœ€è¦çš„æµå¼

```python
# æŸäº›æ¨¡å‹ä¸éœ€è¦æµå¼
model = ChatOpenAI(
    model="gpt-4o-mini",
    streaming=False  # ç¦ç”¨æµå¼
)
```

---

### 3. æ‰¹é‡å¤„ç† + æµå¼

```python
# æ‰¹é‡è¾“å…¥ï¼Œæ¯ä¸ªè¾“å…¥æµå¼è¾“å‡º
inputs = [{"topic": "AI"}, {"topic": "ML"}, {"topic": "DL"}]

async def process_batch():
    for input_data in inputs:
        print(f"\nå¤„ç†: {input_data['topic']}")
        async for chunk in chain.astream(input_data):
            print(chunk.content, end="", flush=True)

import asyncio
asyncio.run(process_batch())
```

---

## å¿«é€Ÿå‚è€ƒå¡ç‰‡

### API é€ŸæŸ¥

| æ–¹æ³• | ç”¨é€” | è¿”å›ç±»å‹ |
|------|------|----------|
| `chain.stream(input)` | åŒæ­¥æµå¼ | `Iterator[Output]` |
| `chain.astream(input)` | å¼‚æ­¥æµå¼ | `AsyncIterator[Output]` |
| `agent.stream(input, stream_mode="updates")` | Agent è¿›åº¦ | `Iterator[dict]` |
| `agent.stream(input, stream_mode="messages")` | LLM tokens | `Iterator[tuple]` |
| `agent.stream(input, stream_mode="custom")` | è‡ªå®šä¹‰æ•°æ® | `Iterator[Any]` |

---

### æ¨¡å¼é€‰æ‹©

| éœ€æ±‚ | æ¨èæ¨¡å¼ |
|------|----------|
| ChatGPT å¼å¯¹è¯ | `stream_mode="messages"` |
| å¤šæ­¥ Agent è¿½è¸ª | `stream_mode="updates"` |
| è‡ªå®šä¹‰è¿›åº¦æ˜¾ç¤º | `stream_mode="custom"` |
| å…¨é¢ç›‘æ§ | `stream_mode=["updates", "messages", "custom"]` |

---

### å¸¸ç”¨ä»£ç ç‰‡æ®µ

#### 1. åŸºç¡€æµå¼
```python
async for chunk in chain.astream(input):
    print(chunk.content, end="", flush=True)
```

#### 2. Agent è¿›åº¦
```python
for chunk in agent.stream(input, stream_mode="updates"):
    for node, data in chunk.items():
        print(f"[{node}] æ‰§è¡Œå®Œæˆ")
```

#### 3. è‡ªå®šä¹‰æµå¼
```python
from langgraph.config import get_stream_writer

def my_tool(query: str) -> str:
    writer = get_stream_writer()
    writer("æ­¥éª¤ 1...")
    writer("æ­¥éª¤ 2...")
    return result
```

---

## å­¦ä¹ è·¯å¾„

### ç¬¬ 1 æ­¥ï¼šæŒæ¡åŸºç¡€æµå¼
- ç†è§£æµå¼ vs éæµå¼çš„åŒºåˆ«
- å®ç°ç®€å•çš„ ChatGPT å¼å¯¹è¯
- ç»ƒä¹  `stream()` å’Œ `astream()`

### ç¬¬ 2 æ­¥ï¼šç†è§£ä¸‰ç§æ¨¡å¼
- å­¦ä¹  `updates` æ¨¡å¼è¿½è¸ª Agent
- å­¦ä¹  `messages` æ¨¡å¼æ˜¾ç¤º tokens
- å­¦ä¹  `custom` æ¨¡å¼å‘é€è‡ªå®šä¹‰æ•°æ®

### ç¬¬ 3 æ­¥ï¼šå®æˆ˜åº”ç”¨
- æ„å»ºå®æ—¶å¯¹è¯åº”ç”¨
- å®ç°å¤šæ­¥ Agent è¿›åº¦è¿½è¸ª
- æ·»åŠ è‡ªå®šä¹‰è¿›åº¦æ˜¾ç¤º

### ç¬¬ 4 æ­¥ï¼šæ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨å¼‚æ­¥æµå¼
- åˆç†ç¦ç”¨æµå¼
- æ‰¹é‡å¤„ç†ä¼˜åŒ–

---

## é¿å‘æŒ‡å—

### âŒ å¸¸è§é”™è¯¯

1. **å¿˜è®° flush**
```python
print(chunk.content, end="")  # å¯èƒ½è¢«ç¼“å†²
```

2. **åŒæ­¥ç¯å¢ƒç”¨å¼‚æ­¥**
```python
async for chunk in chain.astream(input):  # åœ¨åŒæ­¥å‡½æ•°ä¸­
    pass
```

3. **ä¸ä¼ é€’ config (Python < 3.11)**
```python
writer = get_stream_writer()  # ç¼ºå°‘ config å‚æ•°
```

4. **æ··æ·†æ¨¡å¼è¿”å›å€¼**
```python
for chunk in agent.stream(input, stream_mode="messages"):
    print(chunk)  # åº”è¯¥æ˜¯ (token, metadata) å…ƒç»„
```

---

### âœ… æœ€ä½³å®è·µ

1. **ä¼˜å…ˆä½¿ç”¨å¼‚æ­¥**
```python
async for chunk in chain.astream(input):
    print(chunk.content, end="", flush=True)
```

2. **æ˜ç¡®æŒ‡å®šæ¨¡å¼**
```python
agent.stream(input, stream_mode="updates")  # æ˜ç¡®æŒ‡å®š
```

3. **å¤„ç†å…ƒç»„è¿”å›**
```python
for token, metadata in agent.stream(input, stream_mode="messages"):
    print(token.content, end="")
```

4. **åˆç†ä½¿ç”¨å¤šæ¨¡å¼**
```python
for mode, data in agent.stream(input, stream_mode=["updates", "messages"]):
    if mode == "updates":
        # å¤„ç†æ­¥éª¤æ›´æ–°
    elif mode == "messages":
        # å¤„ç† token
```

---

## ä¸‹ä¸€æ­¥å­¦ä¹ 

- **02_ç¬¬ä¸€æ€§åŸç†**ï¼šæ·±å…¥ç†è§£æµå¼æ‰§è¡Œçš„è®¾è®¡åŸç†
- **03_æ ¸å¿ƒæ¦‚å¿µ**ï¼šè¯¦ç»†å­¦ä¹ ä¸‰ç§æµå¼æ¨¡å¼
- **07_å®æˆ˜ä»£ç **ï¼šå®Œæ•´çš„ç”Ÿäº§çº§ä»£ç ç¤ºä¾‹

---

## å‚è€ƒèµ„æº

- **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.langchain.com/oss/python/langchain/streaming/overview
- **æºç ä½ç½®**ï¼š`langchain_core/runnables/base.py:132`
- **ç›¸å…³çŸ¥è¯†ç‚¹**ï¼š
  - L2_06 é“¾å¼è°ƒè¯•ä¸æ—¥å¿—
  - L2_08 æ‰¹å¤„ç†ä¸å¹¶å‘æ§åˆ¶

---

**ç‰ˆæœ¬**ï¼šLangChain 0.3.x (2025-2026)
**æœ€åæ›´æ–°**ï¼š2026-02-21
