# 核心概念03：路径权重与启发式函数

> 如何量化"代价"和"距离"：权重设计决定搜索质量

---

## 一句话定义

**路径权重是量化图中边的代价的数值，启发式函数是估计剩余距离的函数，两者的设计直接决定最短路径算法的搜索效率和结果质量。**

---

## 路径权重设计

### 什么是路径权重？

**定义：** 图中每条边的"代价"或"成本"。

```python
# 图的表示
graph = {
    'A': [('B', 5), ('C', 2)],  # A到B权重5，A到C权重2
    'B': [('D', 3)],
    'C': [('D', 8)]
}

# 路径权重 = 所有边权重之和
path_A_to_D_via_B = 5 + 3 = 8
path_A_to_D_via_C = 2 + 8 = 10
```

### 权重的物理意义

权重可以表示多种实际含义：

| 场景 | 权重含义 | 示例 |
|------|---------|------|
| **地图导航** | 距离/时间 | 5公里，10分钟 |
| **网络路由** | 延迟/带宽 | 50ms，100Mbps |
| **知识图谱** | 推理代价 | 关系可信度，推理步骤 |
| **任务规划** | 执行成本 | 时间，资源，风险 |
| **对话系统** | 对话代价 | 轮数，用户满意度 |

---

## 在AI Agent中设计权重

### 场景1：知识图谱推理

**目标：** 量化推理步骤的可靠性和代价。

```python
def knowledge_graph_weight(relation):
    """
    知识图谱中的边权重设计
    """
    # 因素1：关系类型的可靠性
    relation_reliability = {
        "直接关系": 0.1,    # 如"作者"、"配偶"
        "间接关系": 0.3,    # 如"同事"、"朋友"
        "推断关系": 0.5,    # 如"可能认识"
        "弱关系": 0.8       # 如"同城"
    }

    # 因素2：关系的置信度
    confidence = relation.confidence  # 0.0 - 1.0
    confidence_penalty = (1 - confidence) * 0.5

    # 因素3：时间衰减（关系越旧越不可靠）
    age_years = (current_date - relation.date).years
    time_decay = min(age_years * 0.05, 0.3)

    # 综合权重
    weight = (relation_reliability[relation.type]
              + confidence_penalty
              + time_decay)

    return weight


# 示例
relation1 = Relation(
    type="直接关系",
    confidence=0.95,
    date="2024-01-01"
)
weight1 = knowledge_graph_weight(relation1)
# = 0.1 + (1-0.95)*0.5 + 0.1 = 0.225

relation2 = Relation(
    type="推断关系",
    confidence=0.6,
    date="2020-01-01"
)
weight2 = knowledge_graph_weight(relation2)
# = 0.5 + (1-0.6)*0.5 + 0.3 = 1.0
```

### 场景2：多跳问答

**目标：** 平衡推理步骤数和可信度。

```python
def multi_hop_qa_weight(hop_info):
    """
    多跳问答中的权重设计
    """
    # 因素1：跳数惩罚（推理链越长越不可靠）
    hop_penalty = hop_info.hop_count * 0.2

    # 因素2：实体相关性
    relevance_score = hop_info.entity_relevance  # 0.0 - 1.0
    relevance_cost = (1 - relevance_score) * 0.5

    # 因素3：证据强度
    evidence_strength = hop_info.evidence_count / 10.0
    evidence_bonus = -min(evidence_strength, 0.3)  # 负权重=奖励

    weight = hop_penalty + relevance_cost + evidence_bonus
    return max(weight, 0.1)  # 最小权重0.1


# 示例：两条推理路径
path1 = [
    {"hop_count": 1, "entity_relevance": 0.9, "evidence_count": 5},
    {"hop_count": 2, "entity_relevance": 0.8, "evidence_count": 3}
]
cost1 = sum(multi_hop_qa_weight(hop) for hop in path1)
# ≈ 0.35 + 0.45 = 0.8

path2 = [
    {"hop_count": 1, "entity_relevance": 0.7, "evidence_count": 2},
    {"hop_count": 2, "entity_relevance": 0.6, "evidence_count": 1},
    {"hop_count": 3, "entity_relevance": 0.5, "evidence_count": 1}
]
cost2 = sum(multi_hop_qa_weight(hop) for hop in path2)
# ≈ 0.45 + 0.6 + 0.75 = 1.8

# path1更优（代价更小）
```

### 场景3：Agent任务规划

**目标：** 综合考虑时间、资源、风险。

```python
def task_planning_weight(task):
    """
    任务规划中的权重设计
    """
    # 因素1：执行时间（归一化到0-1）
    time_cost = task.estimated_time / max_time

    # 因素2：资源消耗
    resource_cost = (
        task.cpu_usage * 0.3 +
        task.memory_usage * 0.3 +
        task.api_calls * 0.4
    )

    # 因素3：失败风险
    failure_risk = task.failure_probability * 2.0

    # 因素4：依赖复杂度
    dependency_penalty = len(task.dependencies) * 0.1

    # 综合权重（可配置权重）
    weight = (
        time_cost * 0.4 +
        resource_cost * 0.3 +
        failure_risk * 0.2 +
        dependency_penalty * 0.1
    )

    return weight
```

---

## 启发式函数设计

### 什么是启发式函数？

**定义：** 估计从当前节点到目标节点的剩余代价。

```python
h(n) = 估计从n到goal的代价

# A*中的使用
f(n) = g(n) + h(n)
     = 实际已走代价 + 估计剩余代价
```

### 设计原则

#### 原则1：可采纳性（Admissibility）

**要求：** h(n) ≤ h*(n)（不高估实际代价）

```python
# ✅ 可采纳的启发式
def admissible_heuristic(node, goal):
    # 欧氏距离（直线距离 ≤ 实际路径）
    return euclidean_distance(node, goal)

# ❌ 不可采纳的启发式
def inadmissible_heuristic(node, goal):
    # 高估了实际距离
    return euclidean_distance(node, goal) * 2
```

**为什么重要？**
- 可采纳 → A*保证找到最优解
- 不可采纳 → A*可能找到次优解

#### 原则2：一致性（Consistency）

**要求：** h(n) ≤ cost(n, n') + h(n')（三角不等式）

```python
def check_consistency(h, graph):
    """检查启发式函数是否一致"""
    for node in graph:
        for neighbor, cost in graph[node]:
            if h(node, goal) > cost + h(neighbor, goal):
                return False  # 不一致
    return True
```

**意义：**
- 一致性 → 可采纳性（更强条件）
- 一致性 → 更高效（不需要重新打开节点）

#### 原则3：信息量

**目标：** h(n)越接近h*(n)越好

```python
# 信息量对比
h1(n) = 0                    # 无信息（退化为Dijkstra）
h2(n) = euclidean(n, goal)   # 中等信息
h3(n) = actual_distance(n, goal)  # 完美信息（理想情况）

# 搜索效率
efficiency(h1) < efficiency(h2) < efficiency(h3)
```

---

## 常见启发式函数

### 1. 欧氏距离（Euclidean Distance）

**适用：** 2D/3D空间，可以任意方向移动

```python
def euclidean_heuristic(node, goal):
    """欧氏距离：直线距离"""
    return math.sqrt(
        (node.x - goal.x)**2 +
        (node.y - goal.y)**2
    )

# 3D版本
def euclidean_3d(node, goal):
    return math.sqrt(
        (node.x - goal.x)**2 +
        (node.y - goal.y)**2 +
        (node.z - goal.z)**2
    )
```

**特点：**
- ✅ 可采纳
- ✅ 一致
- 适合：机器人导航、游戏AI

### 2. 曼哈顿距离（Manhattan Distance）

**适用：** 网格地图，只能横竖移动

```python
def manhattan_heuristic(node, goal):
    """曼哈顿距离：横竖距离之和"""
    return abs(node.x - goal.x) + abs(node.y - goal.y)
```

**特点：**
- ✅ 可采纳（网格图）
- ✅ 一致
- 适合：城市街道、网格游戏

### 3. 切比雪夫距离（Chebyshev Distance）

**适用：** 可以八方向移动

```python
def chebyshev_heuristic(node, goal):
    """切比雪夫距离：最大坐标差"""
    return max(
        abs(node.x - goal.x),
        abs(node.y - goal.y)
    )
```

**特点：**
- ✅ 可采纳（八方向移动）
- ✅ 一致
- 适合：国际象棋、策略游戏

### 4. 对角距离（Diagonal Distance）

**适用：** 斜向移动代价不同

```python
def diagonal_heuristic(node, goal):
    """对角距离：考虑斜向移动"""
    dx = abs(node.x - goal.x)
    dy = abs(node.y - goal.y)

    # 斜向移动代价 sqrt(2) ≈ 1.414
    # 直线移动代价 1.0
    diagonal_cost = 1.414
    straight_cost = 1.0

    return (diagonal_cost * min(dx, dy) +
            straight_cost * abs(dx - dy))
```

---

## AI Agent中的启发式函数

### 场景1：知识图谱语义距离

```python
def semantic_heuristic(node, goal, kg):
    """
    基于语义相似度的启发式函数
    """
    # 方法1：Embedding相似度
    node_emb = kg.get_embedding(node)
    goal_emb = kg.get_embedding(goal)
    similarity = cosine_similarity(node_emb, goal_emb)

    # 转换为距离（相似度越高，距离越小）
    # 需要校准以保证可采纳性
    max_possible_hops = kg.diameter  # 图的直径
    estimated_distance = (1 - similarity) * max_possible_hops * 0.1

    return estimated_distance


def hybrid_kg_heuristic(node, goal, kg):
    """
    混合启发式：结构 + 语义
    """
    # 结构距离：最短跳数（BFS预计算）
    structural_dist = bfs_distance(node, goal, kg) * 0.1

    # 语义距离
    semantic_dist = semantic_heuristic(node, goal, kg)

    # 加权组合
    return 0.6 * structural_dist + 0.4 * semantic_dist
```

### 场景2：任务规划状态距离

```python
def task_state_heuristic(current_state, goal_state):
    """
    任务规划中的启发式函数
    """
    # 计算未完成的子目标
    uncompleted = set(goal_state.goals) - set(current_state.achieved)

    # 估计每个子目标的平均代价
    avg_cost_per_goal = 2.0

    # 考虑依赖关系
    dependency_penalty = count_dependencies(uncompleted) * 0.5

    return len(uncompleted) * avg_cost_per_goal + dependency_penalty
```

### 场景3：对话状态距离

```python
def dialogue_heuristic(current_state, goal_state):
    """
    对话系统中的启发式函数
    """
    # 信息收集进度
    info_collected = len(current_state.collected_info)
    info_needed = len(goal_state.required_info)
    info_gap = info_needed - info_collected

    # 估计每个信息需要的对话轮数
    turns_per_info = 1.5

    # 用户满意度因素
    satisfaction_penalty = (1 - current_state.user_satisfaction) * 2.0

    return info_gap * turns_per_info + satisfaction_penalty
```

---

## LLM增强的启发式函数

### 2025年突破：iLLM-A*

**核心思想：** 用LLM生成高质量的启发式估计

```python
def llm_enhanced_heuristic(node, goal, llm, context):
    """
    LLM增强的启发式函数

    来源：arXiv 2510.02716v1 (2025)
    """
    prompt = f"""
    Given the current state and goal, estimate the remaining cost.

    Current: {node}
    Goal: {goal}
    Context: {context}

    Provide a numerical estimate (0.0 - 10.0) of the remaining cost.
    Consider: distance, obstacles, complexity.

    Estimate:
    """

    # LLM生成估计
    response = llm.generate(prompt)
    estimated_cost = parse_float(response)

    # 校准以保证可采纳性
    # 方法：乘以一个小于1的系数
    calibration_factor = 0.8
    return estimated_cost * calibration_factor


def llm_waypoint_heuristic(node, goal, llm):
    """
    LLM生成waypoints，然后计算启发式
    """
    # LLM生成关键路径点
    waypoints = llm.generate_waypoints(node, goal)

    # 估计到最近waypoint的距离
    nearest_waypoint = min(waypoints,
                          key=lambda w: distance(node, w))

    # h(n) = dist(n, nearest_waypoint) + dist(nearest_waypoint, goal)
    return (distance(node, nearest_waypoint) +
            distance(nearest_waypoint, goal))
```

---

## 权重与启发式的协同设计

### 原则：保持一致的度量单位

```python
# ❌ 错误：权重和启发式单位不一致
graph_weights = {
    ('A', 'B'): 5.0,  # 单位：公里
}

def bad_heuristic(node, goal):
    return time_estimate(node, goal)  # 单位：分钟（不一致！）


# ✅ 正确：统一单位
graph_weights = {
    ('A', 'B'): 5.0,  # 单位：公里
}

def good_heuristic(node, goal):
    return euclidean_distance(node, goal)  # 单位：公里
```

### 原则：权重和启发式的信息量匹配

```python
# 如果权重包含多个因素，启发式也应该考虑
def complex_weight(edge):
    return (
        edge.distance * 0.5 +
        edge.traffic * 0.3 +
        edge.toll * 0.2
    )

def matching_heuristic(node, goal):
    return (
        euclidean_distance(node, goal) * 0.5 +
        estimated_traffic(node, goal) * 0.3 +
        estimated_toll(node, goal) * 0.2
    )
```

---

## 实战示例：完整的权重和启发式设计

```python
class KnowledgeGraphPathFinder:
    """知识图谱路径查找器"""

    def __init__(self, kg):
        self.kg = kg

    def edge_weight(self, source, target, relation):
        """边权重设计"""
        # 1. 关系类型基础代价
        base_cost = {
            "直接关系": 0.1,
            "间接关系": 0.3,
            "推断关系": 0.5
        }[relation.type]

        # 2. 置信度惩罚
        confidence_penalty = (1 - relation.confidence) * 0.5

        # 3. 时间衰减
        age_penalty = min(relation.age_years * 0.05, 0.3)

        return base_cost + confidence_penalty + age_penalty

    def heuristic(self, node, goal):
        """启发式函数设计"""
        # 1. 结构距离（BFS预计算）
        structural_dist = self.kg.bfs_distance(node, goal)
        if structural_dist == float('inf'):
            return float('inf')  # 不可达

        # 2. 语义距离
        node_emb = self.kg.get_embedding(node)
        goal_emb = self.kg.get_embedding(goal)
        similarity = cosine_similarity(node_emb, goal_emb)
        semantic_dist = (1 - similarity) * structural_dist

        # 3. 混合启发式
        # 结构距离提供下界保证，语义距离提供方向引导
        return structural_dist * 0.1 + semantic_dist * 0.05

    def find_path(self, start, goal):
        """使用A*查找最优路径"""
        return a_star(
            self.kg.graph,
            start,
            goal,
            lambda n, g: self.heuristic(n, g)
        )


# 使用示例
kg = KnowledgeGraph()
finder = KnowledgeGraphPathFinder(kg)

path, cost = finder.find_path(
    "《哈利·波特》",
    "尼尔·默里"
)

print(f"最优推理路径: {' -> '.join(path)}")
print(f"总代价: {cost:.2f}")
```

---

## 常见错误

### 错误1：权重为负

```python
# ❌ 错误：负权重会破坏Dijkstra和A*
graph = {
    'A': [('B', -5)]  # 负权重！
}

# ✅ 解决方案1：使用Bellman-Ford算法
# ✅ 解决方案2：转换权重（如果可能）
graph = {
    'A': [('B', 10 - 5)]  # 加上偏移量
}
```

### 错误2：启发式不可采纳

```python
# ❌ 错误：高估了实际距离
def bad_heuristic(node, goal):
    return euclidean_distance(node, goal) * 1.5  # 高估！

# ✅ 正确：不高估
def good_heuristic(node, goal):
    return euclidean_distance(node, goal)  # 直线距离 ≤ 实际距离
```

### 错误3：单位不一致

```python
# ❌ 错误：权重是距离，启发式是时间
graph_weights_km = {...}
def heuristic_minutes(node, goal):
    return estimated_time(node, goal)

# ✅ 正确：统一单位
graph_weights_km = {...}
def heuristic_km(node, goal):
    return euclidean_distance_km(node, goal)
```

---

## 性能优化技巧

### 技巧1：预计算启发式

```python
# 对于固定目标，可以预计算所有节点的启发式
def precompute_heuristics(graph, goal):
    """预计算所有节点到目标的启发式"""
    heuristics = {}
    for node in graph:
        heuristics[node] = compute_heuristic(node, goal)
    return heuristics

# 使用时直接查表
h_values = precompute_heuristics(graph, goal)
def fast_heuristic(node, goal):
    return h_values[node]
```

### 技巧2：缓存启发式计算

```python
from functools import lru_cache

@lru_cache(maxsize=10000)
def cached_heuristic(node, goal):
    """缓存启发式计算结果"""
    return expensive_heuristic_computation(node, goal)
```

### 技巧3：自适应权重

```python
def adaptive_weight(edge, context):
    """根据上下文动态调整权重"""
    base_weight = edge.weight

    # 根据当前搜索状态调整
    if context.explored_nodes > 1000:
        # 搜索太慢，降低权重差异
        return base_weight * 0.8

    return base_weight
```

---

## 延伸思考

1. **如何设计权重来平衡多个目标（如速度和成本）？**
   - 提示：多目标优化，帕累托最优

2. **启发式函数可以是动态的吗？**
   - 提示：根据搜索进度调整

3. **如何验证启发式函数的可采纳性？**
   - 提示：理论证明 vs 实验验证

4. **LLM生成的启发式如何保证可采纳性？**
   - 提示：校准系数，后验验证

5. **权重设计如何影响推理链的可解释性？**
   - 提示：权重的语义含义

---

## 参考资源

- **论文**：Pearl, J. (1984). Heuristics: Intelligent Search Strategies
- **arXiv 2510.02716v1**：iLLM-A* for Large-Scale Path Planning
- **实践**：Red Blob Games - Heuristics in Pathfinding

---

**记住：权重设计决定"什么是最优"，启发式设计决定"如何高效找到最优"。**
