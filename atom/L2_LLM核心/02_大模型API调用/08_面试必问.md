# 大模型API调用 - 面试必问

高频面试问题及出彩回答。

---

## 问题1："如何设计一个健壮的 LLM API 调用模块？"

### 普通回答（❌ 不出彩）

> "就是用 try-catch 捕获异常，然后重试几次就行了。"

### 出彩回答（✅ 推荐）

> **设计健壮的 LLM API 调用模块需要考虑四个层面：**
>
> **1. 错误处理层**
> - 区分可重试错误（RateLimitError、网络超时）和不可重试错误（认证失败、参数错误）
> - 使用指数退避策略，避免雪崩效应
>
> **2. 可靠性层**
> - 设置合理的超时时间（通常 30-60 秒）
> - 实现熔断机制，当错误率过高时暂停调用
> - 考虑多模型 fallback（如 GPT-4 失败切换到 GPT-3.5）
>
> **3. 可观测性层**
> - 记录每次调用的延迟、token 使用量、错误类型
> - 监控 API 成本，设置预算告警
> - 追踪请求 ID，便于问题排查
>
> **4. 性能优化层**
> - 使用流式输出提升用户体验
> - 批量请求时考虑并发控制
> - 缓存相同问题的回答（注意 temperature 设置）
>
> **在实际 RAG 项目中**，我会封装一个统一的 LLM 调用类，包含重试、日志、成本统计功能，并支持多个模型提供商的切换。

### 为什么这个回答出彩？

1. ✅ 分层思考，展示系统设计能力
2. ✅ 提到具体技术点（指数退避、熔断、fallback）
3. ✅ 联系实际项目经验
4. ✅ 考虑了可观测性和成本控制

---

## 问题2："OpenAI 和 Anthropic 的 API 有什么区别？"

### 普通回答（❌ 不出彩）

> "就是调用方式不太一样，参数名有点区别。"

### 出彩回答（✅ 推荐）

> **两者的核心区别体现在三个方面：**
>
> **1. API 设计哲学**
>
> | 特性 | OpenAI | Anthropic |
> |------|--------|-----------|
> | System Prompt | messages 中的 role | 独立的 system 参数 |
> | max_tokens | 可选（有默认值） | 必填参数 |
> | 响应结构 | choices[0].message.content | content[0].text |
>
> **2. 模型特点**
> - OpenAI GPT-4o：速度快、成本低、多模态能力强
> - Claude：上下文窗口更大（200K）、长文本处理更好、更注重安全
>
> **3. 实际使用建议**
> - RAG 场景：两者都适合，Claude 在长上下文场景有优势
> - 代码生成：GPT-4 略强
> - 安全敏感场景：Claude 更保守
>
> **在项目中**，我通常会封装一个统一接口，支持两个提供商的切换，这样可以根据任务特点选择最合适的模型，也能在一个服务不可用时快速切换。

### 为什么这个回答出彩？

1. ✅ 用表格清晰对比
2. ✅ 不只是 API 差异，还包括模型特点
3. ✅ 给出实际使用建议
4. ✅ 展示了工程化思维（统一接口封装）

---

## 问题3："temperature 参数是什么？RAG 场景应该怎么设置？"

### 普通回答（❌ 不出彩）

> "temperature 控制随机性，RAG 用 0 就行。"

### 出彩回答（✅ 推荐）

> **temperature 控制模型输出的随机性，本质是调整 token 概率分布的"锐度"：**
>
> **原理解释：**
> - temperature=0：选择概率最高的 token，输出最确定
> - temperature=1：按原始概率采样，平衡创意和准确性
> - temperature>1：拉平概率分布，增加随机性
>
> **RAG 场景的设置建议：**
>
> | 场景 | 推荐值 | 原因 |
> |------|--------|------|
> | 事实性问答 | 0-0.1 | 需要忠于检索内容，减少幻觉 |
> | 摘要生成 | 0.1-0.3 | 允许适度的表达变化 |
> | 创意写作辅助 | 0.7-1.0 | 需要多样性 |
>
> **一个常见误区**：很多人以为 temperature=0 就能得到完全相同的输出，实际上由于模型更新、服务器差异等原因，即使 temperature=0 也可能有微小差异。如果需要更高的可复现性，应该同时使用 seed 参数。
>
> **在我的 RAG 项目中**，默认使用 temperature=0.1，既保证答案基于检索内容，又允许一定的表达灵活性。

### 为什么这个回答出彩？

1. ✅ 解释了底层原理（概率分布）
2. ✅ 针对不同场景给出具体建议
3. ✅ 主动提到常见误区
4. ✅ 结合实际项目经验

---

## 问题4："如何控制 LLM API 的调用成本？"

### 普通回答（❌ 不出彩）

> "少调用一点，用便宜的模型。"

### 出彩回答（✅ 推荐）

> **控制 LLM API 成本需要从四个维度入手：**
>
> **1. 输入优化**
> - 精简 System Prompt，去除冗余指令
> - RAG 场景控制检索结果数量（3-5 个 chunk 通常足够）
> - 使用更高效的 Prompt 模板
>
> **2. 输出控制**
> - 合理设置 max_tokens，避免过长回答
> - 使用 stop 参数在适当位置停止生成
> - 要求模型简洁回答
>
> **3. 模型选择**
> - 简单任务用小模型（GPT-3.5、Claude Haiku）
> - 复杂任务才用大模型（GPT-4、Claude Opus）
> - 可以用小模型做初筛，大模型做精处理
>
> **4. 架构优化**
> - 缓存相同问题的回答
> - 批量处理减少请求次数
> - 设置预算告警，监控异常消耗
>
> **成本公式**：`成本 = (输入 tokens + 输出 tokens) × 单价`
>
> **实际案例**：在一个文档问答项目中，通过优化 Prompt 模板和控制检索数量，将单次调用成本从 $0.05 降到 $0.01，节省了 80%。

### 为什么这个回答出彩？

1. ✅ 系统性地从多个维度分析
2. ✅ 给出具体可操作的建议
3. ✅ 提供成本计算公式
4. ✅ 用实际案例量化效果

---

## 面试技巧总结

| 问题类型 | 回答策略 |
|----------|----------|
| 概念解释 | 原理 + 类比 + 应用场景 |
| 对比问题 | 用表格 + 给出选择建议 |
| 设计问题 | 分层/分模块 + 具体技术点 |
| 优化问题 | 多维度分析 + 量化效果 |

**通用技巧：**
1. 先给结论/框架，再展开细节
2. 主动提到常见误区或陷阱
3. 结合实际项目经验
4. 展示系统性思维

---

**上一节：** [07_实战代码.md](./07_实战代码.md)
**下一节：** [09_化骨绵掌.md](./09_化骨绵掌.md) - 10 个 2 分钟知识卡片
