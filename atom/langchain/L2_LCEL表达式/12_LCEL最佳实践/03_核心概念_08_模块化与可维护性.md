# 核心概念：模块化与可维护性

> **本节目标**：掌握LCEL的模块化设计，构建可测试、可维护的生产级代码。

---

## 一、为什么需要模块化？

### 1.1 代码维护挑战

**单体链的问题**：
```python
# ❌ 难以维护的单体链
chain = (
    prompt1 | llm1 | parser1 | transform1 |
    prompt2 | llm2 | parser2 | transform2 |
    prompt3 | llm3 | parser3
)
# 难以测试、难以复用、难以调试
```

**模块化收益**：
- 可测试性：独立测试每个组件
- 可复用性：组件在多个链中复用
- 可维护性：修改局部不影响全局
- 可调试性：快速定位问题

### 1.2 单一职责原则

**每个组件只做一件事**：
```python
# ✅ 模块化设计
retrieval_chain = create_retrieval_chain()
generation_chain = create_generation_chain()
validation_chain = create_validation_chain()

# 组合
rag_chain = retrieval_chain | generation_chain | validation_chain
```

---

## 二、组件提取

### 2.1 核心原理

**组件提取**：将复杂链拆分为独立的、可复用的小组件。

**提取标准**：
- 功能独立（单一职责）
- 接口清晰（输入/输出明确）
- 可测试（无外部依赖）
- 可复用（多场景适用）

### 2.2 基础示例

```python
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 组件1：检索
def create_retrieval_chain(vectorstore):
    """创建检索链"""
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    return retriever | RunnableLambda(format_docs)

# 组件2：生成
def create_generation_chain(model: str = "gpt-4o"):
    """创建生成链"""
    prompt = ChatPromptTemplate.from_template(
        "基于以下上下文回答问题：\n\n{context}\n\n问题：{question}"
    )
    llm = ChatOpenAI(model=model)
    return prompt | llm | StrOutputParser()

# 组件3：验证
def create_validation_chain():
    """创建验证链"""
    def validate(response: str) -> str:
        if len(response) < 10:
            raise ValueError("响应过短")
        if "不知道" in response:
            raise ValueError("响应不确定")
        return response

    return RunnableLambda(validate)

# 组合使用
retrieval = create_retrieval_chain(vectorstore)
generation = create_generation_chain()
validation = create_validation_chain()

rag_chain = (
    {"context": retrieval, "question": RunnablePassthrough()}
    | generation
    | validation
)
```

### 2.3 工厂模式

```python
class ChainFactory:
    """链工厂"""

    def __init__(self, vectorstore, model: str = "gpt-4o"):
        self.vectorstore = vectorstore
        self.model = model

    def create_rag_chain(self):
        """创建RAG链"""
        retrieval = self._create_retrieval()
        generation = self._create_generation()
        return (
            {"context": retrieval, "question": RunnablePassthrough()}
            | generation
        )

    def create_summarization_chain(self):
        """创建摘要链"""
        prompt = ChatPromptTemplate.from_template("总结：{text}")
        llm = ChatOpenAI(model=self.model)
        return prompt | llm | StrOutputParser()

    def _create_retrieval(self):
        """内部：创建检索链"""
        retriever = self.vectorstore.as_retriever()
        return retriever | RunnableLambda(self._format_docs)

    def _create_generation(self):
        """内部：创建生成链"""
        prompt = ChatPromptTemplate.from_template(
            "上下文：{context}\n\n问题：{question}"
        )
        llm = ChatOpenAI(model=self.model)
        return prompt | llm | StrOutputParser()

    @staticmethod
    def _format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

# 使用
factory = ChainFactory(vectorstore, model="gpt-4o")
rag_chain = factory.create_rag_chain()
summary_chain = factory.create_summarization_chain()
```

---

## 三、Runnable协议优势

### 3.1 统一接口

**所有Runnable都有相同的接口**：
```python
# 统一接口
result = runnable.invoke(input)           # 同步调用
results = runnable.batch(inputs)          # 批处理
async_result = await runnable.ainvoke(input)  # 异步调用
for chunk in runnable.stream(input):      # 流式输出
    print(chunk)
```

### 3.2 自动功能

**Runnable自动支持**：
- 流式输出（stream）
- 批处理（batch）
- 异步执行（ainvoke）
- 重试（with_retry）
- 降级（with_fallbacks）

```python
# 任何Runnable都可以
chain = prompt | llm | parser

# 自动支持流式
for chunk in chain.stream(input):
    print(chunk)

# 自动支持批处理
results = chain.batch([input1, input2, input3])

# 自动支持重试
chain_with_retry = chain.with_retry(stop_after_attempt=3)
```

### 3.3 可组合性

```python
# 任意组合
chain1 = prompt1 | llm1
chain2 = prompt2 | llm2

# 顺序组合
sequential = chain1 | chain2

# 并行组合
parallel = RunnableParallel({
    "branch_a": chain1,
    "branch_b": chain2
})

# 条件组合
conditional = RunnableBranch(
    [(lambda x: x["score"] > 0.8, chain1)],
    chain2
)
```

---

## 四、测试策略

### 4.1 单元测试

**目标**：测试单个组件，无外部依赖。

```python
import pytest
from langchain_core.language_models.fake import FakeListLLM

def test_generation_chain():
    """测试生成链"""
    # 使用FakeLLM（无API调用）
    fake_llm = FakeListLLM(responses=["这是测试响应"])

    # 创建链
    prompt = ChatPromptTemplate.from_template("问题：{question}")
    chain = prompt | fake_llm | StrOutputParser()

    # 测试
    result = chain.invoke({"question": "什么是LCEL？"})
    assert result == "这是测试响应"

def test_validation_chain():
    """测试验证链"""
    validation = create_validation_chain()

    # 测试有效输入
    result = validation.invoke("这是一个有效的响应")
    assert result == "这是一个有效的响应"

    # 测试无效输入
    with pytest.raises(ValueError):
        validation.invoke("短")
```

### 4.2 集成测试

**目标**：测试完整链，使用真实LLM。

```python
def test_rag_chain_integration():
    """集成测试：完整RAG链"""
    # 使用真实组件
    vectorstore = Chroma.from_texts(
        ["LCEL是LangChain表达式语言"],
        embedding=OpenAIEmbeddings()
    )

    # 创建链
    rag_chain = create_rag_chain(vectorstore)

    # 测试
    result = rag_chain.invoke("什么是LCEL？")

    # 验证
    assert "LCEL" in result
    assert len(result) > 10
```

### 4.3 离线评估

**52%组织使用离线评估**。

```python
from langchain.evaluation import load_evaluator

# 准备测试数据集
test_dataset = [
    {"question": "什么是LCEL？", "expected": "LCEL是LangChain表达式语言"},
    {"question": "如何使用LCEL？", "expected": "使用管道操作符组合组件"},
]

# 评估器
evaluator = load_evaluator("qa")

# 运行评估
results = []
for item in test_dataset:
    prediction = rag_chain.invoke(item["question"])
    score = evaluator.evaluate_strings(
        prediction=prediction,
        reference=item["expected"]
    )
    results.append(score)

# 统计
accuracy = sum(r["score"] for r in results) / len(results)
print(f"准确率: {accuracy:.2%}")
```

### 4.4 在线评估

**37%组织使用在线评估，44.8%在生产环境**。

```python
class OnlineEvaluator:
    """在线评估器"""

    def __init__(self):
        self.metrics = {
            "total": 0,
            "success": 0,
            "latency": []
        }

    def evaluate(self, query: str, response: str, latency: float):
        """评估单次调用"""
        self.metrics["total"] += 1
        self.metrics["latency"].append(latency)

        # 简单质量检查
        if len(response) > 10 and "不知道" not in response:
            self.metrics["success"] += 1

    def report(self):
        """生成报告"""
        success_rate = self.metrics["success"] / self.metrics["total"]
        avg_latency = sum(self.metrics["latency"]) / len(self.metrics["latency"])

        return {
            "success_rate": success_rate,
            "avg_latency": avg_latency,
            "total_calls": self.metrics["total"]
        }

# 使用
evaluator = OnlineEvaluator()

def monitored_invoke(query: str):
    start = time.time()
    response = rag_chain.invoke(query)
    latency = time.time() - start

    # 在线评估
    evaluator.evaluate(query, response, latency)

    return response
```

---

## 五、评估方法

### 5.1 人工评审（59.8%采用）

```python
class HumanReview:
    """人工评审"""

    def __init__(self):
        self.pending_reviews = []

    def submit_for_review(self, query: str, response: str):
        """提交人工评审"""
        self.pending_reviews.append({
            "query": query,
            "response": response,
            "timestamp": datetime.now()
        })

    def get_pending(self):
        """获取待审核"""
        return self.pending_reviews

# 使用
reviewer = HumanReview()

def high_stakes_invoke(query: str):
    """高风险查询（需人工审核）"""
    response = rag_chain.invoke(query)

    # 提交审核
    reviewer.submit_for_review(query, response)

    return response
```

### 5.2 LLM-as-Judge（53.3%采用）

```python
from langchain.evaluation import load_evaluator

class LLMJudge:
    """LLM评判器"""

    def __init__(self):
        self.evaluator = load_evaluator(
            "labeled_criteria",
            criteria="correctness"
        )

    def judge(self, query: str, response: str, reference: str = None) -> float:
        """评判响应质量"""
        result = self.evaluator.evaluate_strings(
            input=query,
            prediction=response,
            reference=reference
        )
        return result["score"]

# 使用
judge = LLMJudge()

def evaluated_invoke(query: str, reference: str = None):
    """带评估的调用"""
    response = rag_chain.invoke(query)

    # LLM评判
    score = judge.judge(query, response, reference)

    if score < 0.7:
        logger.warning("低质量响应", score=score)

    return response
```

---

## 六、可复用模式

### 6.1 Prompt模板版本化

```python
# prompts/rag_v1.txt
PROMPT_V1 = """基于以下上下文回答问题：

上下文：{context}

问题：{question}
"""

# prompts/rag_v2.txt
PROMPT_V2 = """你是一个专业的助手。请基于以下上下文回答问题。

上下文：
{context}

问题：{question}

要求：
- 简洁明了
- 基于上下文
- 不确定时说"不知道"
"""

# 版本管理
class PromptVersionManager:
    """Prompt版本管理"""

    VERSIONS = {
        "v1": PROMPT_V1,
        "v2": PROMPT_V2
    }

    @classmethod
    def get_prompt(cls, version: str = "v2"):
        """获取指定版本的Prompt"""
        template = cls.VERSIONS.get(version, cls.VERSIONS["v2"])
        return ChatPromptTemplate.from_template(template)

# 使用
prompt = PromptVersionManager.get_prompt("v2")
chain = prompt | llm | parser
```

### 6.2 标准错误处理包装器

```python
def with_standard_error_handling(chain):
    """标准错误处理包装器"""
    return (
        chain
        .with_retry(stop_after_attempt=3)
        .with_fallbacks([fallback_chain])
    )

# 使用
safe_chain = with_standard_error_handling(base_chain)
```

### 6.3 通用验证函数

```python
def create_validator(min_length: int = 10, max_length: int = 1000):
    """创建验证器"""
    def validate(text: str) -> str:
        if len(text) < min_length:
            raise ValueError(f"响应过短（<{min_length}字符）")
        if len(text) > max_length:
            raise ValueError(f"响应过长（>{max_length}字符）")
        return text

    return RunnableLambda(validate)

# 复用
validator_short = create_validator(min_length=5)
validator_long = create_validator(min_length=50)
```

---

## 七、文档化

### 7.1 组件文档

```python
def create_rag_chain(
    vectorstore,
    model: str = "gpt-4o",
    k: int = 5
):
    """创建RAG问答链。

    Args:
        vectorstore: 向量存储实例
        model: LLM模型名称（默认：gpt-4o）
        k: 检索文档数量（默认：5）

    Returns:
        Runnable: RAG链，接受字符串问题，返回字符串答案

    Example:
        >>> vectorstore = Chroma.from_texts(texts, embeddings)
        >>> chain = create_rag_chain(vectorstore)
        >>> answer = chain.invoke("什么是LCEL？")

    Configuration:
        - 可通过with_config()修改运行时配置
        - 支持流式输出：chain.stream(question)
        - 支持批处理：chain.batch(questions)
    """
    retriever = vectorstore.as_retriever(search_kwargs={"k": k})
    # ... 实现
```

### 7.2 变更日志

```markdown
# CHANGELOG.md

## [2.0.0] - 2026-02-21
### Changed
- Prompt模板升级到v2（更详细的指令）
- 默认模型从gpt-3.5-turbo改为gpt-4o

### Added
- 新增验证链（最小长度检查）
- 支持自定义检索数量（k参数）

## [1.0.0] - 2026-01-15
### Added
- 初始版本
- 基础RAG链实现
```

---

## 八、最佳实践

### 8.1 设计原则

| 原则 | 说明 | 示例 |
|------|------|------|
| **单一职责** | 每个组件只做一件事 | 检索链只负责检索 |
| **依赖注入** | 通过参数传递依赖 | `create_chain(vectorstore)` |
| **接口清晰** | 明确输入输出类型 | `str -> str` |
| **可测试性** | 易于编写单元测试 | 使用FakeLLM |
| **可复用性** | 组件可在多处使用 | 工厂模式 |

### 8.2 测试金字塔

```
E2E测试（少量）
  ↓
集成测试（中等）
  ↓
单元测试（大量）
```

**比例建议**：
- 单元测试：70%
- 集成测试：20%
- E2E测试：10%

### 8.3 CI/CD集成

```yaml
# .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run unit tests
        run: pytest tests/unit/
      - name: Run integration tests
        run: pytest tests/integration/
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
```

---

## 九、总结

### 核心要点

1. **组件提取**：单一职责，接口清晰
2. **Runnable协议**：统一接口，自动功能
3. **测试策略**：单元测试（70%）+ 集成测试（20%）+ E2E（10%）
4. **评估方法**：人工评审（59.8%）+ LLM-as-Judge（53.3%）
5. **可复用模式**：Prompt版本化、错误处理包装器、验证函数

### 模块化路径

```
单体链（难维护）
  ↓ 组件提取
模块化链（可测试）
  ↓ 工厂模式
可复用组件（可扩展）
  ↓ 测试覆盖
生产级代码（可靠）
```

### 实施建议

- ✅ 从小组件开始（单一职责）
- ✅ 编写单元测试（FakeLLM）
- ✅ 使用工厂模式（可配置）
- ✅ Prompt版本化（可追溯）
- ✅ 集成CI/CD（自动化）
- ✅ 离线+在线评估（持续优化）

---

**Phase 3 完成！下一步**：进入 Phase 4，生成【实战代码】系列文件。
