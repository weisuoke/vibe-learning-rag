# GraphRAG知识图谱检索 - 核心概念2: 实体关系提取

> LLM驱动的结构化知识提取,GraphRAG的核心技术

---

## 概念定义

**实体关系提取 (Entity-Relation Extraction)** 是使用LLM从非结构化文本中识别实体并抽取实体间关系的过程,是构建知识图谱的关键步骤。

**一句话**: 把"Alice管理Marketing部门"转换成 `(Alice, manages, Marketing)` 三元组。

---

## 为什么需要实体关系提取?

### 传统方法的局限

```python
# 传统NER方法(基于规则或小模型)
text = "Alice是Marketing部门的经理,向Charlie汇报"

# 问题1: 实体识别不准确
# ❌ 可能识别: Alice(PERSON), Marketing(ORG)
# ❌ 遗漏: Charlie, 经理

# 问题2: 关系抽取困难
# ❌ 无法理解"是...的经理"表示管理关系
# ❌ 无法理解"向...汇报"表示汇报关系
```

### LLM方法的优势

```python
# LLM驱动的提取
prompt = f"""
从文本中提取实体和关系:
{text}

返回JSON格式:
{{
  "entities": [...],
  "relations": [
    {{"subject": "Alice", "predicate": "manages", "object": "Marketing"}},
    {{"subject": "Alice", "predicate": "reports_to", "object": "Charlie"}}
  ]
}}
"""

# ✅ 准确识别所有实体
# ✅ 理解复杂的关系表达
# ✅ 支持多语言和领域
```

---

## 核心技术详解

### 1. Prompt Engineering for Extraction

**基础Prompt模板**:

```python
from openai import OpenAI
import json
import os

def extract_entities_relations(text: str) -> dict:
    """使用LLM提取实体和关系"""
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    prompt = f"""
你是一个知识图谱构建专家。从以下文本中提取实体和关系。

文本: {text}

要求:
1. 识别所有重要实体(人名、组织、地点、概念等)
2. 提取实体间的关系
3. 关系类型使用标准动词(如: manages, works_in, reports_to, is, located_in)

返回JSON格式:
{{
  "entities": [
    {{"name": "实体名", "type": "PERSON|ORGANIZATION|LOCATION|CONCEPT"}}
  ],
  "relations": [
    {{"subject": "主体实体", "predicate": "关系类型", "object": "客体实体"}}
  ]
}}

只返回JSON,不要其他解释。
"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    
    return json.loads(response.choices[0].message.content)

# 示例
text = "Alice是Marketing部门的经理,Bob在Marketing部门工作,向Alice汇报"
result = extract_entities_relations(text)

print("实体:")
for entity in result["entities"]:
    print(f"  - {entity['name']} ({entity['type']})")

print("\n关系:")
for rel in result["relations"]:
    print(f"  ({rel['subject']}) --[{rel['predicate']}]--> ({rel['object']})")
```

**输出示例**:
```
实体:
  - Alice (PERSON)
  - Marketing (ORGANIZATION)
  - Bob (PERSON)

关系:
  (Alice) --[manages]--> (Marketing)
  (Bob) --[works_in]--> (Marketing)
  (Bob) --[reports_to]--> (Alice)
```

---

### 2. Few-shot Learning提升准确率

```python
def extract_with_examples(text: str) -> dict:
    """使用Few-shot提升提取准确率"""
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    prompt = f"""
从文本中提取实体和关系。

示例1:
文本: "张三是技术部门的总监"
输出:
{{
  "entities": [
    {{"name": "张三", "type": "PERSON"}},
    {{"name": "技术部门", "type": "ORGANIZATION"}},
    {{"name": "总监", "type": "CONCEPT"}}
  ],
  "relations": [
    {{"subject": "张三", "predicate": "is", "object": "总监"}},
    {{"subject": "张三", "predicate": "manages", "object": "技术部门"}}
  ]
}}

示例2:
文本: "北京是中国的首都"
输出:
{{
  "entities": [
    {{"name": "北京", "type": "LOCATION"}},
    {{"name": "中国", "type": "LOCATION"}}
  ],
  "relations": [
    {{"subject": "北京", "predicate": "capital_of", "object": "中国"}}
  ]
}}

现在处理:
文本: {text}
输出:
"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    
    return json.loads(response.choices[0].message.content)
```

---

### 3. 实体消歧 (Entity Disambiguation)

```python
class EntityDisambiguator:
    """实体消歧: 统一不同表述的同一实体"""
    
    def __init__(self):
        self.entity_map = {}  # {变体: 标准实体ID}
        self.entity_info = {}  # {实体ID: {name, type, aliases}}
        self.next_id = 0
    
    def add_entity(self, name: str, entity_type: str, aliases: list = None):
        """添加实体及其别名"""
        entity_id = f"E{self.next_id}"
        self.next_id += 1
        
        # 存储实体信息
        self.entity_info[entity_id] = {
            "name": name,
            "type": entity_type,
            "aliases": aliases or []
        }
        
        # 映射标准名
        self.entity_map[name.lower()] = entity_id
        
        # 映射别名
        if aliases:
            for alias in aliases:
                self.entity_map[alias.lower()] = entity_id
        
        return entity_id
    
    def resolve(self, entity_name: str) -> str:
        """解析实体到标准ID"""
        return self.entity_map.get(entity_name.lower(), entity_name)
    
    def get_canonical_name(self, entity_name: str) -> str:
        """获取标准名称"""
        entity_id = self.resolve(entity_name)
        if entity_id in self.entity_info:
            return self.entity_info[entity_id]["name"]
        return entity_name

# 示例
disambiguator = EntityDisambiguator()

# 添加实体及别名
disambiguator.add_entity("Alice Smith", "PERSON", ["Alice", "A. Smith", "Alice S."])
disambiguator.add_entity("Marketing Department", "ORGANIZATION", ["Marketing", "Marketing Dept", "市场部"])

# 消歧
print(disambiguator.resolve("Alice"))  # E0
print(disambiguator.resolve("A. Smith"))  # E0
print(disambiguator.resolve("市场部"))  # E1
print(disambiguator.get_canonical_name("Alice"))  # Alice Smith
```

---

### 4. 关系类型规范化

```python
class RelationNormalizer:
    """关系类型规范化"""
    
    def __init__(self):
        # 定义标准关系类型
        self.standard_relations = {
            "manages": ["管理", "负责", "领导", "is manager of"],
            "works_in": ["在...工作", "就职于", "works at"],
            "reports_to": ["向...汇报", "汇报给", "reports to"],
            "is": ["是", "担任", "serves as"],
            "located_in": ["位于", "在", "located at"],
            "part_of": ["属于", "是...的一部分", "part of"],
            "owns": ["拥有", "持有", "owns"],
            "founded_by": ["由...创立", "创始人是", "founded by"]
        }
        
        # 构建反向映射
        self.relation_map = {}
        for standard, variants in self.standard_relations.items():
            for variant in variants:
                self.relation_map[variant.lower()] = standard
    
    def normalize(self, relation: str) -> str:
        """规范化关系类型"""
        return self.relation_map.get(relation.lower(), relation)

# 示例
normalizer = RelationNormalizer()

print(normalizer.normalize("管理"))  # manages
print(normalizer.normalize("在...工作"))  # works_in
print(normalizer.normalize("向...汇报"))  # reports_to
```

---

### 5. 批量提取优化

```python
def extract_batch(texts: list, batch_size: int = 10) -> list:
    """批量提取,减少API调用"""
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    results = []
    
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        
        # 构建批量prompt
        prompt = "从以下文本中提取实体和关系,每个文本单独返回结果:\n\n"
        for j, text in enumerate(batch):
            prompt += f"文本{j+1}: {text}\n"
        
        prompt += "\n返回JSON数组格式: [{...}, {...}, ...]"
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        batch_results = json.loads(response.choices[0].message.content)
        results.extend(batch_results)
    
    return results
```

---

## 完整示例: 端到端提取流程

```python
"""
完整示例: 从文档到知识图谱
"""

import os
from openai import OpenAI
import json
from typing import List, Dict

class KnowledgeExtractor:
    """知识提取器"""
    
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.disambiguator = EntityDisambiguator()
        self.normalizer = RelationNormalizer()
    
    def extract(self, text: str) -> Dict:
        """提取实体和关系"""
        prompt = f"""
从文本中提取实体和关系:

文本: {text}

返回JSON格式:
{{
  "entities": [
    {{"name": "实体名", "type": "PERSON|ORGANIZATION|LOCATION|CONCEPT"}}
  ],
  "relations": [
    {{"subject": "主体", "predicate": "关系", "object": "客体"}}
  ]
}}

只返回JSON。
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return json.loads(response.choices[0].message.content)
    
    def process_documents(self, documents: List[str]) -> Dict:
        """处理多个文档"""
        all_entities = {}
        all_relations = []
        
        for doc in documents:
            result = self.extract(doc)
            
            # 处理实体
            for entity in result.get("entities", []):
                name = entity["name"]
                entity_type = entity["type"]
                
                if name not in all_entities:
                    all_entities[name] = {
                        "type": entity_type,
                        "mentions": 0
                    }
                all_entities[name]["mentions"] += 1
            
            # 处理关系
            for rel in result.get("relations", []):
                # 规范化关系类型
                rel["predicate"] = self.normalizer.normalize(rel["predicate"])
                all_relations.append(rel)
        
        return {
            "entities": all_entities,
            "relations": all_relations
        }

# 使用示例
if __name__ == "__main__":
    extractor = KnowledgeExtractor()
    
    documents = [
        "Alice是Marketing部门的经理",
        "Bob在Marketing部门工作,向Alice汇报",
        "Marketing部门向Charlie汇报",
        "Charlie是公司的CEO"
    ]
    
    print("=== 提取知识 ===")
    knowledge = extractor.process_documents(documents)
    
    print("\n实体:")
    for name, info in knowledge["entities"].items():
        print(f"  - {name} ({info['type']}) - 出现{info['mentions']}次")
    
    print("\n关系:")
    for rel in knowledge["relations"]:
        print(f"  ({rel['subject']}) --[{rel['predicate']}]--> ({rel['object']})")
```

---

## 在RAG开发中的应用

### 应用场景1: 企业知识库构建

```python
# 场景: 从企业文档构建组织架构图
documents = [
    "张三是技术部门的总监,负责整个技术团队",
    "李四在技术部门工作,主要负责后端开发",
    "王五是产品部门的经理",
    "技术部门和产品部门都向CEO汇报"
]

knowledge = extractor.process_documents(documents)
# 结果: 完整的组织架构关系图
```

### 应用场景2: 学术文献分析

```python
# 场景: 从论文中提取引用关系
documents = [
    "本文基于Transformer架构(Vaswani et al., 2017)",
    "BERT模型(Devlin et al., 2018)改进了Transformer",
    "GPT-3(Brown et al., 2020)进一步扩展了模型规模"
]

knowledge = extractor.process_documents(documents)
# 结果: 论文引用关系图
```

---

## 性能优化技巧

### 1. 缓存提取结果

```python
import hashlib
import json

class ExtractionCache:
    """缓存提取结果"""
    
    def __init__(self, cache_file: str = "extraction_cache.json"):
        self.cache_file = cache_file
        self.cache = self._load()
    
    def _load(self) -> dict:
        try:
            with open(self.cache_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def _save(self):
        with open(self.cache_file, 'w') as f:
            json.dump(self.cache, f)
    
    def get(self, text: str) -> dict:
        key = hashlib.md5(text.encode()).hexdigest()
        return self.cache.get(key)
    
    def set(self, text: str, result: dict):
        key = hashlib.md5(text.encode()).hexdigest()
        self.cache[key] = result
        self._save()
```

### 2. 并行处理

```python
from concurrent.futures import ThreadPoolExecutor

def extract_parallel(texts: List[str], max_workers: int = 5) -> List[Dict]:
    """并行提取"""
    extractor = KnowledgeExtractor()
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(extractor.extract, texts))
    
    return results
```

---

## 常见问题与解决方案

### 问题1: 实体识别遗漏

**解决方案**:
1. 使用更强的模型(GPT-4)
2. 提供领域特定的Few-shot示例
3. 多次提取+结果合并

### 问题2: 关系类型不一致

**解决方案**:
1. 使用RelationNormalizer规范化
2. 在Prompt中明确关系类型列表
3. 后处理统一关系类型

### 问题3: 成本过高

**解决方案**:
1. 批量处理减少API调用
2. 缓存提取结果
3. 使用更便宜的模型(gpt-4o-mini)

---

## 检查清单

掌握实体关系提取后,你应该能够:

- [ ] 使用LLM进行实体识别
- [ ] 使用LLM进行关系抽取
- [ ] 实现实体消歧
- [ ] 规范化关系类型
- [ ] 批量处理文档
- [ ] 优化提取性能
- [ ] 处理多语言文本

---

**版本**: v1.0 (基于2025-2026生产级实践)
**最后更新**: 2026-02-17
**维护者**: Claude Code
