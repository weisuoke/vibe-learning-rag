# 30字核心

**幻觉检测与缓解 = Faithfulness评估 + NLI验证 + 声明分解 + 引用溯源，确保RAG生成内容与检索上下文一致。**

---

## 核心公式

```
RAG可信度 = 检测准确率 × 缓解有效性

其中：
- 检测准确率 = Faithfulness分数 ∩ NLI验证 ∩ 声明级验证
- 缓解有效性 = 引用溯源 + Prompt优化 + 响应校正
```

---

## 一句话记忆

**RAG幻觉检测就像论文查重：先把回答拆成独立声明（声明分解），逐一检查是否能从检索文档中找到支持（Faithfulness + NLI），最后给每个声明标注出处（引用溯源）。**

---

## 为什么重要？

在RAG系统中，LLM可能：
- **忽略检索上下文**：直接使用参数化知识回答
- **混入错误推理**：基于上下文做出不合理的推断
- **生成无根据内容**：编造检索文档中不存在的信息

幻觉检测与缓解是确保RAG系统可信度的最后一道防线。

---

## 2026年核心技术

| 技术 | 作用 | 代表方案 |
|------|------|----------|
| **Faithfulness评估** | 整体一致性检查 | RAGAS, DeepEval |
| **NLI三分类验证** | 逻辑蕴含判断 | DeBERTa-NLI, LettuceDetect |
| **声明分解** | 细粒度验证 | RefChecker, HalluSearch |
| **引用溯源** | 可追溯性保证 | Attribution Pipeline |

---

## 快速判断标准

**好的幻觉检测系统应该：**
- ✅ 检测粒度细（声明级而非文档级）
- ✅ 验证方法多（Faithfulness + NLI + 语义相似度）
- ✅ 响应速度快（<500ms）
- ✅ 提供引用溯源（可点击的源文档链接）
- ✅ 支持自动修正（检测到幻觉后重新生成）

**避免的误区：**
- ❌ 只用单一检测方法（准确率不足）
- ❌ 检测粒度太粗（整段文本验证）
- ❌ 没有引用溯源（用户无法验证）
- ❌ 检测延迟高（影响用户体验）

---

## 实际应用场景

1. **企业知识库问答**：确保回答基于内部文档，不编造信息
2. **医疗健康咨询**：验证医疗建议有明确文献支持
3. **法律文档分析**：保证法律意见有条文依据
4. **金融报告生成**：确保数据和结论有源文档支撑

---

**记住：幻觉检测不是可选项，而是生产级RAG系统的必备组件。**
