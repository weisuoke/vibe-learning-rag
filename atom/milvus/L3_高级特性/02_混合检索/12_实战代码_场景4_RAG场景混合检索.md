# 实战代码 - 场景4：RAG 场景混合检索

完整的 RAG 文档问答系统，演示混合检索在实际应用中的使用。

---

## 场景描述

**目标**：构建一个企业知识库问答系统

**功能**：
- 文档向量化存储
- 语义搜索 + 时间/类别过滤
- 与 LLM 集成生成答案
- 支持多轮对话

---

## 完整代码

```python
"""
场景4：RAG 场景混合检索
演示：完整的 RAG 文档问答系统
"""

from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from openai import OpenAI
import numpy as np
from typing import List, Dict
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()

# ===== 1. 初始化 OpenAI 客户端 =====
print("=== 1. 初始化 OpenAI 客户端 ===")

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
)

print("✓ OpenAI 客户端初始化成功")

# ===== 2. Embedding 函数 =====
def get_embedding(text: str, model: str = "text-embedding-3-small") -> List[float]:
    """获取文本的 Embedding"""
    response = client.embeddings.create(
        input=text,
        model=model
    )
    return response.data[0].embedding

print("\n=== 2. 测试 Embedding ===")

test_text = "Python 编程教程"
test_embedding = get_embedding(test_text)

print(f"✓ Embedding 测试成功")
print(f"  - 文本: {test_text}")
print(f"  - 向量维度: {len(test_embedding)}")

# ===== 3. 连接 Milvus =====
print("\n=== 3. 连接 Milvus ===")

connections.connect("default", host="localhost", port="19530")

print("✓ Milvus 连接成功")

# ===== 4. 创建 Collection =====
print("\n=== 4. 创建 Collection ===")

collection_name = "rag_knowledge_base"

# 删除已存在的 Collection
if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)

# 定义 Schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),  # OpenAI embedding 维度
    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=500),
    FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=5000),
    FieldSchema(name="year", dtype=DataType.INT64),
    FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100),
    FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=200),
]

schema = CollectionSchema(fields=fields, description="RAG 知识库")
collection = Collection(name=collection_name, schema=schema)

print(f"✓ Collection 创建成功: {collection_name}")

# ===== 5. 创建索引 =====
print("\n=== 5. 创建索引 ===")

# 向量索引
index_params = {
    "index_type": "HNSW",
    "metric_type": "IP",  # OpenAI embedding 使用内积
    "params": {"M": 16, "efConstruction": 200}
}
collection.create_index(field_name="embedding", index_params=index_params)

# 标量索引
collection.create_index(field_name="year")
collection.create_index(field_name="category")

print("✓ 索引创建成功")

# ===== 6. 准备知识库数据 =====
print("\n=== 6. 准备知识库数据 ===")

# 模拟企业知识库文档
documents = [
    {
        "title": "Python 基础教程",
        "content": "Python 是一种高级编程语言，具有简洁的语法和强大的功能。适合初学者学习编程。",
        "year": 2024,
        "category": "tutorial",
        "source": "internal_docs"
    },
    {
        "title": "Python 数据分析",
        "content": "使用 Pandas 和 NumPy 进行数据分析。Pandas 提供了 DataFrame 数据结构，NumPy 提供了高效的数组操作。",
        "year": 2024,
        "category": "guide",
        "source": "internal_docs"
    },
    {
        "title": "机器学习入门",
        "content": "机器学习是人工智能的一个分支，通过算法让计算机从数据中学习。常见算法包括线性回归、决策树、神经网络等。",
        "year": 2024,
        "category": "tutorial",
        "source": "external_docs"
    },
    {
        "title": "深度学习框架 PyTorch",
        "content": "PyTorch 是一个开源的深度学习框架，提供了灵活的张量计算和自动微分功能。广泛应用于研究和生产环境。",
        "year": 2023,
        "category": "guide",
        "source": "external_docs"
    },
    {
        "title": "自然语言处理基础",
        "content": "自然语言处理（NLP）是让计算机理解和生成人类语言的技术。包括分词、词性标注、命名实体识别、情感分析等任务。",
        "year": 2024,
        "category": "tutorial",
        "source": "internal_docs"
    },
    {
        "title": "Transformer 模型详解",
        "content": "Transformer 是一种基于注意力机制的神经网络架构，彻底改变了 NLP 领域。BERT、GPT 等模型都基于 Transformer。",
        "year": 2023,
        "category": "paper",
        "source": "external_docs"
    },
    {
        "title": "向量数据库 Milvus",
        "content": "Milvus 是一个开源的向量数据库，专为 AI 应用设计。支持高效的向量检索和混合检索，广泛应用于 RAG 系统。",
        "year": 2024,
        "category": "documentation",
        "source": "external_docs"
    },
    {
        "title": "RAG 系统架构设计",
        "content": "RAG（检索增强生成）结合了检索和生成两种技术。通过检索相关文档，为 LLM 提供上下文，生成更准确的答案。",
        "year": 2024,
        "category": "guide",
        "source": "internal_docs"
    },
]

print(f"  准备 {len(documents)} 条文档...")

# 为每个文档生成 Embedding
for i, doc in enumerate(documents):
    print(f"  处理文档 {i+1}/{len(documents)}: {doc['title']}")
    # 使用标题 + 内容生成 Embedding
    text = f"{doc['title']}\n{doc['content']}"
    doc['embedding'] = get_embedding(text)

print(f"✓ 文档 Embedding 生成完成")

# ===== 7. 插入数据 =====
print("\n=== 7. 插入数据 ===")

collection.insert(documents)
collection.flush()

print(f"✓ 插入 {len(documents)} 条文档")

# ===== 8. 加载 Collection =====
print("\n=== 8. 加载 Collection ===")

collection.load()

print("✓ Collection 加载完成")

# ===== 9. RAG 检索函数 =====
def rag_search(
    query: str,
    year: int = None,
    category: str = None,
    top_k: int = 3
) -> List[Dict]:
    """
    RAG 检索函数

    Args:
        query: 用户查询
        year: 年份过滤（可选）
        category: 类别过滤（可选）
        top_k: 返回结果数量

    Returns:
        检索结果列表
    """
    # 1. 生成查询向量
    query_embedding = get_embedding(query)

    # 2. 构建过滤表达式
    expr_parts = []
    if year:
        expr_parts.append(f"year == {year}")
    if category:
        expr_parts.append(f"category == '{category}'")

    expr = " and ".join(expr_parts) if expr_parts else None

    # 3. 执行混合检索
    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"ef": 64}},
        limit=top_k,
        expr=expr,
        output_fields=["title", "content", "year", "category", "source"]
    )

    # 4. 格式化结果
    documents = []
    for hit in results[0]:
        documents.append({
            "id": hit.id,
            "title": hit.entity.get('title'),
            "content": hit.entity.get('content'),
            "year": hit.entity.get('year'),
            "category": hit.entity.get('category'),
            "source": hit.entity.get('source'),
            "score": hit.score
        })

    return documents

# ===== 10. RAG 问答函数 =====
def rag_qa(
    query: str,
    year: int = None,
    category: str = None,
    top_k: int = 3
) -> Dict:
    """
    RAG 问答函数

    Args:
        query: 用户问题
        year: 年份过滤（可选）
        category: 类别过滤（可选）
        top_k: 检索文档数量

    Returns:
        包含答案和来源的字典
    """
    # 1. 检索相关文档
    documents = rag_search(query, year, category, top_k)

    if not documents:
        return {
            "answer": "抱歉，没有找到相关文档。",
            "sources": []
        }

    # 2. 构建上下文
    context = "\n\n".join([
        f"文档 {i+1}:\n标题: {doc['title']}\n内容: {doc['content']}"
        for i, doc in enumerate(documents)
    ])

    # 3. 构建 Prompt
    system_prompt = "你是一个企业知识库助手。基于提供的文档回答用户问题。如果文档中没有相关信息，请明确说明。"

    user_prompt = f"""基于以下文档回答问题：

{context}

问题：{query}

请提供准确、简洁的答案。"""

    # 4. 调用 LLM 生成答案
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3
    )

    answer = response.choices[0].message.content

    # 5. 返回结果
    return {
        "answer": answer,
        "sources": documents
    }

# ===== 11. 测试场景 =====
print("\n=== 11. 测试场景 ===")

# 场景1：基础问答
print("\n场景1：基础问答")
print("-" * 50)

query1 = "什么是 Python？"
result1 = rag_qa(query1)

print(f"问题: {query1}")
print(f"\n答案:\n{result1['answer']}")
print(f"\n来源文档:")
for i, doc in enumerate(result1['sources']):
    print(f"  {i+1}. {doc['title']} (相似度: {doc['score']:.4f})")

# 场景2：带年份过滤
print("\n\n场景2：带年份过滤")
print("-" * 50)

query2 = "2024年有哪些关于机器学习的文档？"
result2 = rag_qa(query2, year=2024)

print(f"问题: {query2}")
print(f"\n答案:\n{result2['answer']}")
print(f"\n来源文档:")
for i, doc in enumerate(result2['sources']):
    print(f"  {i+1}. {doc['title']} ({doc['year']}, 相似度: {doc['score']:.4f})")

# 场景3：带类别过滤
print("\n\n场景3：带类别过滤")
print("-" * 50)

query3 = "有哪些教程类的文档？"
result3 = rag_qa(query3, category="tutorial")

print(f"问题: {query3}")
print(f"\n答案:\n{result3['answer']}")
print(f"\n来源文档:")
for i, doc in enumerate(result3['sources']):
    print(f"  {i+1}. {doc['title']} ({doc['category']}, 相似度: {doc['score']:.4f})")

# 场景4：复杂查询
print("\n\n场景4：复杂查询")
print("-" * 50)

query4 = "如何使用 Transformer 模型进行自然语言处理？"
result4 = rag_qa(query4, top_k=5)

print(f"问题: {query4}")
print(f"\n答案:\n{result4['answer']}")
print(f"\n来源文档:")
for i, doc in enumerate(result4['sources']):
    print(f"  {i+1}. {doc['title']} (相似度: {doc['score']:.4f})")

# 场景5：多轮对话
print("\n\n场景5：多轮对话")
print("-" * 50)

conversation = [
    "什么是 RAG？",
    "RAG 系统中使用什么数据库？",
    "Milvus 有什么特点？"
]

for i, query in enumerate(conversation):
    print(f"\n轮次 {i+1}:")
    print(f"问题: {query}")

    result = rag_qa(query, top_k=2)

    print(f"答案: {result['answer']}")
    print(f"来源: {', '.join([doc['title'] for doc in result['sources']])}")

# ===== 12. 性能统计 =====
print("\n\n=== 12. 性能统计 ===")

import time

# 测试检索性能
queries = [
    "Python 编程",
    "机器学习",
    "深度学习",
    "自然语言处理",
    "向量数据库"
]

times = []
for query in queries:
    start = time.time()
    rag_search(query, top_k=3)
    elapsed = time.time() - start
    times.append(elapsed)

avg_time = np.mean(times) * 1000
print(f"平均检索时间: {avg_time:.2f}ms")

# 测试端到端性能
times = []
for query in queries:
    start = time.time()
    rag_qa(query, top_k=3)
    elapsed = time.time() - start
    times.append(elapsed)

avg_time = np.mean(times) * 1000
print(f"平均端到端时间: {avg_time:.2f}ms")

# ===== 13. 清理 =====
print("\n=== 13. 清理 ===")

collection.release()
connections.disconnect("default")

print("✓ 资源已释放")
print("\n=== 场景4完成 ===")
```

---

## 运行输出示例

```
=== 1. 初始化 OpenAI 客户端 ===
✓ OpenAI 客户端初始化成功

=== 2. 测试 Embedding ===
✓ Embedding 测试成功
  - 文本: Python 编程教程
  - 向量维度: 1536

=== 3. 连接 Milvus ===
✓ Milvus 连接成功

=== 4. 创建 Collection ===
✓ Collection 创建成功: rag_knowledge_base

=== 5. 创建索引 ===
✓ 索引创建成功

=== 6. 准备知识库数据 ===
  准备 8 条文档...
  处理文档 1/8: Python 基础教程
  处理文档 2/8: Python 数据分析
  处理文档 3/8: 机器学习入门
  处理文档 4/8: 深度学习框架 PyTorch
  处理文档 5/8: 自然语言处理基础
  处理文档 6/8: Transformer 模型详解
  处理文档 7/8: 向量数据库 Milvus
  处理文档 8/8: RAG 系统架构设计
✓ 文档 Embedding 生成完成

=== 7. 插入数据 ===
✓ 插入 8 条文档

=== 8. 加载 Collection ===
✓ Collection 加载完成

=== 11. 测试场景 ===

场景1：基础问答
--------------------------------------------------
问题: 什么是 Python？

答案:
Python 是一种高级编程语言，具有简洁的语法和强大的功能，非常适合初学者学习编程。它广泛应用于数据分析、机器学习、Web开发等多个领域。

来源文档:
  1. Python 基础教程 (相似度: 0.8234)
  2. Python 数据分析 (相似度: 0.7456)
  3. 机器学习入门 (相似度: 0.6123)


场景2：带年份过滤
--------------------------------------------------
问题: 2024年有哪些关于机器学习的文档？

答案:
2024年关于机器学习的文档包括：
1. 机器学习入门 - 介绍了机器学习的基本概念和常见算法
2. RAG 系统架构设计 - 讲解了如何将机器学习应用于检索增强生成系统

来源文档:
  1. 机器学习入门 (2024, 相似度: 0.8567)
  2. RAG 系统架构设计 (2024, 相似度: 0.7234)
  3. Python 数据分析 (2024, 相似度: 0.6789)


场景3：带类别过滤
--------------------------------------------------
问题: 有哪些教程类的文档？

答案:
教程类的文档包括：
1. Python 基础教程 - 适合初学者学习 Python 编程
2. 机器学习入门 - 介绍机器学习的基本概念和算法
3. 自然语言处理基础 - 讲解 NLP 的基础知识和常见任务

来源文档:
  1. Python 基础教程 (tutorial, 相似度: 0.7890)
  2. 机器学习入门 (tutorial, 相似度: 0.7654)
  3. 自然语言处理基础 (tutorial, 相似度: 0.7123)


场景4：复杂查询
--------------------------------------------------
问题: 如何使用 Transformer 模型进行自然语言处理？

答案:
Transformer 是一种基于注意力机制的神经网络架构，在自然语言处理领域有广泛应用。使用 Transformer 进行 NLP 的步骤包括：

1. 理解 Transformer 架构：它彻底改变了 NLP 领域，BERT、GPT 等模型都基于 Transformer
2. 掌握 NLP 基础任务：包括分词、词性标注、命名实体识别、情感分析等
3. 选择合适的框架：如 PyTorch，它提供了灵活的张量计算和自动微分功能

来源文档:
  1. Transformer 模型详解 (相似度: 0.8901)
  2. 自然语言处理基础 (相似度: 0.8234)
  3. 深度学习框架 PyTorch (相似度: 0.7567)
  4. 机器学习入门 (相似度: 0.6890)
  5. RAG 系统架构设计 (相似度: 0.6234)


场景5：多轮对话
--------------------------------------------------

轮次 1:
问题: 什么是 RAG？
答案: RAG（检索增强生成）是一种结合了检索和生成两种技术的系统。它通过检索相关文档，为大语言模型（LLM）提供上下文，从而生成更准确的答案。
来源: RAG 系统架构设计, 向量数据库 Milvus

轮次 2:
问题: RAG 系统中使用什么数据库？
答案: RAG 系统中常用向量数据库，如 Milvus。Milvus 是一个开源的向量数据库，专为 AI 应用设计，支持高效的向量检索和混合检索。
来源: 向量数据库 Milvus, RAG 系统架构设计

轮次 3:
问题: Milvus 有什么特点？
答案: Milvus 的主要特点包括：1) 专为 AI 应用设计；2) 支持高效的向量检索；3) 支持混合检索（向量检索 + 标量过滤）；4) 广泛应用于 RAG 系统。
来源: 向量数据库 Milvus, RAG 系统架构设计

=== 12. 性能统计 ===
平均检索时间: 8.45ms
平均端到端时间: 1234.56ms

=== 13. 清理 ===
✓ 资源已释放

=== 场景4完成 ===
```

---

## 关键要点

### 1. RAG 系统架构

```
用户查询
   ↓
1. Embedding（向量化）
   ↓
2. 混合检索（Milvus）
   - 向量检索：语义相似
   - 标量过滤：精确条件
   ↓
3. 上下文构建
   ↓
4. LLM 生成答案
   ↓
5. 返回结果
```

### 2. 混合检索的作用

```python
# 纯向量检索：只考虑语义相似
documents = rag_search(query)

# 混合检索：语义相似 + 精确条件
documents = rag_search(query, year=2024, category="tutorial")

# 优势：
# - 更精准的召回
# - 更快的检索速度
# - 更好的用户体验
```

### 3. 性能优化

- **Embedding 缓存**：避免重复计算
- **批量检索**：减少网络开销
- **索引优化**：为常用过滤字段创建索引
- **Top-K 控制**：平衡召回率和性能

---

## 扩展功能

### 1. 添加文档元数据

```python
# 扩展 Schema
FieldSchema(name="author", dtype=DataType.VARCHAR, max_length=100)
FieldSchema(name="tags", dtype=DataType.VARCHAR, max_length=500)
FieldSchema(name="rating", dtype=DataType.FLOAT)

# 过滤条件
expr = "year == 2024 and rating >= 4.5 and author == 'Alice'"
```

### 2. 支持多语言

```python
# 添加语言字段
FieldSchema(name="language", dtype=DataType.VARCHAR, max_length=10)

# 过滤语言
documents = rag_search(query, language="zh")
```

### 3. 添加权重

```python
# 根据相似度和其他因素计算权重
for doc in documents:
    doc['weight'] = doc['score'] * 0.7 + doc['rating'] * 0.3
```

---

**下一步**：学习 [13_实战代码_场景5_生产级混合检索系统.md](./13_实战代码_场景5_生产级混合检索系统.md)
