# 第一性原理

> **从根本理解为什么需要 Provider 切换系统**

---

## 问题的本质

### 现实困境

**问题 1：LLM 服务商众多，API 各不相同**

```typescript
// Anthropic API
const anthropicRequest = {
  model: "claude-3-5-sonnet-20241022",
  messages: [{ role: "user", content: "Hello" }],
  max_tokens: 1024
};

// OpenAI API
const openaiRequest = {
  model: "gpt-4-turbo",
  messages: [{ role: "user", content: "Hello" }],
  max_completion_tokens: 1024
};

// Google API
const googleRequest = {
  model: "models/gemini-2.0-flash-exp",
  contents: [{ role: "user", parts: [{ text: "Hello" }] }],
  generationConfig: { maxOutputTokens: 1024 }
};
```

**问题 2：不同模型有不同的优势和成本**

| 模型 | 优势 | 成本 |
|------|------|------|
| Claude Opus | 最强推理 | $15/MTok |
| Claude Sonnet | 平衡性能 | $3/MTok |
| Claude Haiku | 快速响应 | $0.8/MTok |
| GPT-4o | 多模态 | $2.5/MTok |
| Llama 3.1 | 本地部署 | 免费 |

**问题 3：单一模型无法满足所有需求**

- 简单任务用 Opus 浪费成本
- 复杂任务用 Haiku 质量不足
- 本地开发需要离线能力
- 生产环境需要高可用性

---

## 第一性原理推导

### 原理 1：抽象统一接口

**核心思想**：通过抽象层屏蔽底层差异

```typescript
// 第一性原理：统一接口
interface LLMProvider {
  call(prompt: string, options: CallOptions): Promise<string>;
}

// 不同 Provider 实现相同接口
class AnthropicProvider implements LLMProvider {
  async call(prompt: string, options: CallOptions): Promise<string> {
    // 转换为 Anthropic API 格式
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      body: JSON.stringify({
        model: options.model,
        messages: [{ role: 'user', content: prompt }],
        max_tokens: options.maxTokens
      })
    });
    return response.content;
  }
}

class OpenAIProvider implements LLMProvider {
  async call(prompt: string, options: CallOptions): Promise<string> {
    // 转换为 OpenAI API 格式
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      body: JSON.stringify({
        model: options.model,
        messages: [{ role: 'user', content: prompt }],
        max_completion_tokens: options.maxTokens
      })
    });
    return response.choices[0].message.content;
  }
}
```

**推导链**：
```
API 差异 → 统一接口 → Provider 抽象 → 可互换性
```

### 原理 2：配置驱动行为

**核心思想**：通过配置文件而非代码控制行为

```typescript
// ❌ 硬编码：修改需要改代码
const provider = new AnthropicProvider();
const model = 'claude-3-5-sonnet-20241022';

// ✅ 配置驱动：修改只需改配置
const config = loadConfig('models.json');
const provider = createProvider(config.defaultProvider);
const model = config.defaultModel;
```

**推导链**：
```
硬编码 → 配置文件 → 运行时切换 → 灵活性
```

### 原理 3：分层优先级

**核心思想**：不同场景需要不同配置

```typescript
// 配置层级
const config = {
  global: loadConfig('~/.pi/agent/settings.json'),
  project: loadConfig('.pi/settings.json'),
  cli: parseArgs(process.argv),
  runtime: getCurrentSession()
};

// 优先级合并
const finalConfig = merge(
  config.global,
  config.project,
  config.cli,
  config.runtime
);
```

**推导链**：
```
单一配置 → 多层配置 → 优先级合并 → 场景适配
```

---

## 为什么需要 Provider 切换？

### 原因 1：成本优化

**场景**：不同任务需要不同成本的模型

```typescript
// 简单任务：代码格式化
const task1 = "Format this JSON";
// 最佳选择：Haiku ($0.8/MTok)
// 如果用 Opus：浪费 19 倍成本

// 复杂任务：架构设计
const task2 = "Design a scalable microservices architecture";
// 最佳选择：Opus ($15/MTok)
// 如果用 Haiku：质量不足，需要多次迭代
```

**成本对比**：

```typescript
// 每天 100 次交互，平均 5K input + 1K output

// 全部使用 Opus
const dailyCost = 100 * ((5000/1000000)*15 + (1000/1000000)*75);
// = 100 * (0.075 + 0.075) = $15/天
// 月度：$450

// 智能选择：80% Haiku + 15% Sonnet + 5% Opus
const optimizedCost =
  80 * ((5000/1000000)*0.8 + (1000/1000000)*4) +
  15 * ((5000/1000000)*3 + (1000/1000000)*15) +
  5 * ((5000/1000000)*15 + (1000/1000000)*75);
// = 80*0.008 + 15*0.03 + 5*0.15
// = 0.64 + 0.45 + 0.75 = $1.84/天
// 月度：$55.20
// 节省：$394.80 (88%)
```

### 原因 2：可靠性保障

**场景**：主模型失败时自动切换

```typescript
// Fallback 链
const fallbackChain = [
  'claude-3-5-sonnet-20241022',  // 主模型
  'gpt-4o',                       // 第一备选
  'claude-3-5-haiku-20241022',    // 第二备选
  'llama3.1:8b'                   // 本地备选
];

async function reliableCall(prompt: string): Promise<string> {
  for (const model of fallbackChain) {
    try {
      return await callModel(model, prompt);
    } catch (error) {
      console.log(`${model} failed, trying next...`);
    }
  }
  throw new Error('All models failed');
}
```

### 原因 3：专业分工

**场景**：不同模型擅长不同任务

```typescript
const taskRouter = {
  'code-generation': 'claude-3-5-sonnet-20241022',  // Claude 擅长代码
  'data-analysis': 'gpt-4o',                        // GPT 擅长分析
  'ui-design': 'gpt-4o',                            // GPT 支持多模态
  'local-testing': 'llama3.1:8b'                    // 本地模型免费
};

function selectModel(taskType: string): string {
  return taskRouter[taskType] || 'claude-3-5-haiku-20241022';
}
```

### 原因 4：环境适配

**场景**：开发、测试、生产使用不同模型

```typescript
const environmentConfig = {
  development: {
    provider: 'ollama',
    model: 'llama3.1:8b',
    reason: '本地开发，免费快速'
  },
  staging: {
    provider: 'anthropic',
    model: 'claude-3-5-haiku-20241022',
    reason: '测试环境，成本控制'
  },
  production: {
    provider: 'anthropic',
    model: 'claude-3-5-sonnet-20241022',
    reason: '生产环境，质量优先'
  }
};

const config = environmentConfig[process.env.NODE_ENV];
```

---

## 设计哲学

### 哲学 1：模型无关开发

**目标**：代码不依赖特定模型

```typescript
// ❌ 模型耦合
async function generateCode(prompt: string): Promise<string> {
  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    body: JSON.stringify({
      model: 'claude-3-5-sonnet-20241022',
      messages: [{ role: 'user', content: prompt }]
    })
  });
  return response.content;
}

// ✅ 模型无关
async function generateCode(prompt: string, provider: LLMProvider): Promise<string> {
  return await provider.call(prompt);
}
```

### 哲学 2：配置优于代码

**目标**：行为通过配置控制

```typescript
// ❌ 硬编码
const model = 'claude-3-5-sonnet-20241022';

// ✅ 配置驱动
const model = config.defaultModel;
```

### 哲学 3：用户友好

**目标**：简化切换操作

```typescript
// ❌ 复杂操作
// 1. 修改代码
// 2. 重新编译
// 3. 重启应用

// ✅ 简单操作
// 1. 按 Ctrl+P（快捷键）
// 或
// 1. 输入 /model（命令）
```

---

## 与 AI Agent 开发的联系

### 场景 1：多模型协作

```typescript
// 代码生成 + 代码审查 + 优化
async function developFeature(spec: string): Promise<string> {
  // 1. 用 Sonnet 生成代码
  const code = await callModel('claude-3-5-sonnet-20241022', `Generate code: ${spec}`);

  // 2. 用 GPT-4o 审查代码
  const review = await callModel('gpt-4o', `Review this code: ${code}`);

  // 3. 用 Opus 优化代码
  const optimized = await callModel('claude-opus-4-20250514', `Optimize based on review: ${code}\n\nReview: ${review}`);

  return optimized;
}
```

### 场景 2：渐进式深入

```typescript
// 从简单到复杂，逐步升级模型
async function solveProb(problem: string): Promise<string> {
  // 1. 先用 Haiku 尝试
  const simpleAttempt = await callModel('claude-3-5-haiku-20241022', problem);

  // 2. 如果不满意，用 Sonnet
  if (!isGoodEnough(simpleAttempt)) {
    const betterAttempt = await callModel('claude-3-5-sonnet-20241022', problem);

    // 3. 如果还不满意，用 Opus
    if (!isGoodEnough(betterAttempt)) {
      return await callModel('claude-opus-4-20250514', problem);
    }

    return betterAttempt;
  }

  return simpleAttempt;
}
```

---

## 反思与验证

### 验证 1：是否真的需要多 Provider？

**答案**：是的

**理由**：
- 单一 Provider 存在单点故障风险
- 不同 Provider 有不同优势（Claude 代码强，GPT 多模态强）
- 成本差异巨大（Haiku vs Opus = 1:19）

### 验证 2：配置复杂度是否值得？

**答案**：是的

**理由**：
- 一次配置，长期受益
- 配置复杂度 << 硬编码维护成本
- 灵活性带来的价值 >> 配置成本

### 验证 3：用户真的会切换模型吗？

**答案**：是的

**理由**：
- Ctrl+P 快捷键降低切换成本
- 成本节省是强激励
- 质量差异是强需求

---

## 下一步

- **核心概念**：阅读 [03_核心概念_01_Provider定义与配置.md](./03_核心概念_01_Provider定义与配置.md)
- **最小可用**：阅读 [04_最小可用.md](./04_最小可用.md)

---

**记住**：Provider 切换不是技术炫技，而是从第一性原理出发，解决成本、可靠性、专业分工的必然选择。
