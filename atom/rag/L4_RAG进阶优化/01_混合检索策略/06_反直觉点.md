# 反直觉点

混合检索最容易犯的3个错误，以及为什么人们容易这样错。

---

## 误区1：向量检索一定比 BM25 好 ❌

### 错误观点

> "都 2026 年了，还用 BM25？向量检索基于深度学习，肯定更先进更好用。"

### 为什么错？

**BM25 在很多场景下表现更好：**

```python
# 场景1：精确术语查询
query = "Python 3.12.1 release notes"

# BM25 结果（精确匹配版本号）
bm25_results = [
    "Python 3.12.1 Release Notes",      # ✅ 精确匹配
    "Python 3.12.0 Release Notes",      # 相关
]

# 向量检索结果（语义相似但版本可能不对）
vector_results = [
    "Python 3.11 New Features",         # ❌ 版本错误
    "Python Release History",           # 相关但不精确
    "Python 3.12.1 Release Notes",      # ✅ 但排名可能靠后
]
```

```python
# 场景2：代码片段搜索
query = "TypeError: 'NoneType' object is not subscriptable"

# BM25：精确匹配错误信息 ✅
# 向量检索：可能返回其他类型的错误 ❌
```

```python
# 场景3：专有名词搜索
query = "CUDA_OUT_OF_MEMORY"

# BM25：精确匹配 ✅
# 向量检索：可能返回"GPU 内存不足"等语义相似但不精确的结果
```

### 为什么人们容易这样错？

1. **新技术崇拜**：认为新技术一定比旧技术好
2. **忽视场景差异**：没有意识到不同查询类型需要不同方法
3. **过度泛化**：在某些场景向量检索确实更好，就认为所有场景都更好

### 正确理解

```python
# 不同查询类型的最佳检索方法

query_type_to_method = {
    "精确术语": "BM25",           # Python 3.12, API_KEY
    "错误信息": "BM25",           # TypeError, StackTrace
    "代码片段": "BM25",           # function_name, import xxx
    "自然语言问题": "向量检索",    # 如何优化性能？
    "模糊意图": "向量检索",        # 代码跑得慢怎么办
    "通用查询": "混合检索",        # 不确定用户会怎么问
}
```

**结论：没有绝对更好的方法，只有更适合场景的方法。混合检索是最稳健的选择。**

---

## 误区2：混合检索就是简单地把结果合并 ❌

### 错误观点

> "混合检索很简单，把 BM25 和向量检索的结果拼在一起就行了。"

### 为什么错？

**问题1：分数不可比**

```python
# BM25 分数和向量相似度不在同一尺度

bm25_results = [
    ("doc1", 15.2),   # BM25 分数范围：[0, +∞)
    ("doc2", 12.8),
    ("doc3", 8.5),
]

vector_results = [
    ("doc3", 0.92),   # 余弦相似度范围：[-1, 1]
    ("doc1", 0.85),
    ("doc4", 0.78),
]

# 错误做法：直接相加
wrong_fusion = {
    "doc1": 15.2 + 0.85,  # = 16.05
    "doc2": 12.8 + 0,     # = 12.8
    "doc3": 8.5 + 0.92,   # = 9.42
    "doc4": 0 + 0.78,     # = 0.78
}
# 结果：BM25 分数主导，向量检索几乎没有影响！
```

**问题2：简单合并会丢失排名信息**

```python
# 错误做法：简单去重合并
def wrong_merge(bm25_results, vector_results):
    seen = set()
    merged = []
    for doc in bm25_results + vector_results:
        if doc not in seen:
            merged.append(doc)
            seen.add(doc)
    return merged

# 问题：
# - 先出现的结果排在前面（BM25 优先）
# - 没有考虑两个检索器的排名信息
# - 向量检索的第1名可能排在 BM25 的第10名后面
```

### 为什么人们容易这样错？

1. **低估复杂性**：认为"合并"是简单操作
2. **忽视数学问题**：没有意识到分数尺度不同
3. **缺乏评估**：没有对比不同融合策略的效果

### 正确理解

```python
# 正确做法：使用 RRF 融合

def correct_rrf_fusion(results_list, k=60):
    """
    RRF 只使用排名，不使用原始分数
    这样就避免了分数尺度不同的问题
    """
    scores = {}
    for results in results_list:
        for rank, (doc_id, _) in enumerate(results, 1):
            scores[doc_id] = scores.get(doc_id, 0) + 1 / (k + rank)

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

# 或者：先归一化再加权
def correct_weighted_fusion(bm25_results, vector_results, alpha=0.5):
    """
    先将分数归一化到 [0, 1]，再加权融合
    """
    bm25_normalized = normalize_scores(bm25_results)
    vector_normalized = normalize_scores(vector_results)

    scores = {}
    for doc, score in bm25_normalized:
        scores[doc] = alpha * score
    for doc, score in vector_normalized:
        scores[doc] = scores.get(doc, 0) + (1 - alpha) * score

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

**结论：融合策略的选择直接影响检索效果，RRF 是最简单有效的方法。**

---

## 误区3：混合检索的权重应该是 50:50 ❌

### 错误观点

> "BM25 和向量检索各有优势，所以权重设成 50:50 最公平。"

### 为什么错？

**最优权重取决于：**

1. **数据特点**：技术文档 vs 日常对话
2. **查询类型**：精确查询 vs 模糊查询
3. **Embedding 模型质量**：通用模型 vs 领域微调模型

```python
# 不同场景的最优权重差异很大

# 场景1：技术文档问答（代码、API、错误信息多）
# BM25 更重要，因为需要精确匹配
optimal_weights_tech = {"bm25": 0.6, "vector": 0.4}

# 场景2：客服对话（自然语言、口语化表达多）
# 向量检索更重要，因为需要理解意图
optimal_weights_chat = {"bm25": 0.3, "vector": 0.7}

# 场景3：法律文档（专业术语 + 语义理解都重要）
# 相对均衡
optimal_weights_legal = {"bm25": 0.5, "vector": 0.5}
```

**实验数据（假设）：**

| 场景 | 50:50 召回率 | 最优权重 | 最优召回率 | 提升 |
|------|-------------|----------|-----------|------|
| 技术文档 | 78% | 60:40 | 85% | +7% |
| 客服对话 | 72% | 30:70 | 82% | +10% |
| 通用问答 | 80% | 45:55 | 83% | +3% |

### 为什么人们容易这样错？

1. **追求"公平"**：认为平均分配最合理
2. **懒得调参**：50:50 是最省事的默认值
3. **缺乏评估数据**：没有在真实数据上测试不同权重

### 正确理解

```python
# 正确做法：根据业务场景调整权重

class AdaptiveHybridSearch:
    def __init__(self, bm25_weight=0.5, vector_weight=0.5):
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight

    def search(self, query, query_type=None):
        # 根据查询类型动态调整权重
        if query_type == "code":
            weights = (0.7, 0.3)  # 代码查询，BM25 优先
        elif query_type == "natural_language":
            weights = (0.3, 0.7)  # 自然语言，向量优先
        else:
            weights = (self.bm25_weight, self.vector_weight)

        bm25_results = self.bm25_search(query)
        vector_results = self.vector_search(query)

        return self.weighted_fusion(bm25_results, vector_results, weights)

# 更好的做法：通过评估数据自动寻找最优权重
def find_optimal_weights(eval_dataset, bm25_index, vector_store):
    """
    在评估数据集上搜索最优权重
    """
    best_recall = 0
    best_weights = (0.5, 0.5)

    for bm25_w in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
        vector_w = 1 - bm25_w
        recall = evaluate_hybrid_search(
            eval_dataset, bm25_index, vector_store,
            bm25_weight=bm25_w, vector_weight=vector_w
        )
        if recall > best_recall:
            best_recall = recall
            best_weights = (bm25_w, vector_w)

    return best_weights
```

**结论：最优权重需要根据具体场景通过实验确定，50:50 只是起点，不是终点。**

---

## 误区总结

| 误区 | 正确理解 |
|------|----------|
| 向量检索一定比 BM25 好 | 各有擅长场景，混合最稳健 |
| 混合就是简单合并结果 | 需要合理的融合策略（如 RRF） |
| 权重应该是 50:50 | 最优权重取决于场景，需要实验确定 |

---

## 避免误区的检查清单

- [ ] 是否评估了纯 BM25、纯向量、混合检索的效果对比？
- [ ] 是否使用了合理的融合策略（RRF 或归一化加权）？
- [ ] 是否在真实数据上测试了不同权重的效果？
- [ ] 是否考虑了不同查询类型可能需要不同权重？

---

**下一步：** [07_实战代码](./07_实战代码.md) - 完整可运行的混合检索示例
