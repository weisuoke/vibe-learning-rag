# 错误处理策略 - 最小可用

掌握以下内容，就能为 AI Agent API 实现基本的错误处理：

---

## 4.1 异常分层：区分业务异常和系统异常

**核心思想：** 不同类型的错误需要不同的处理方式

```python
# 基础异常类
class AppError(Exception):
    """应用基础异常"""
    def __init__(self, message: str, error_code: str = None):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

# 业务异常（用户可以修正）
class BusinessError(AppError):
    """业务异常：用户输入错误、资源不存在等"""
    pass

# 系统异常（需要开发者修复）
class SystemError(AppError):
    """系统异常：数据库连接失败、LLM 超时等"""
    pass

# 具体异常
class TextTooLongError(BusinessError):
    """文本过长"""
    pass

class LLMTimeoutError(SystemError):
    """LLM 调用超时"""
    pass
```

**在 AI Agent API 中的应用：**
```python
@app.post("/chat")
async def chat(message: str):
    # 业务异常：返回 422，用户可以修正
    if len(message) > 2000:
        raise TextTooLongError("输入文本过长，请缩短至 2000 字以内")

    # 系统异常：返回 500，需要重试或人工干预
    try:
        response = await call_llm(message)
        return {"response": response}
    except Timeout:
        raise LLMTimeoutError("LLM 服务暂时不可用")
```

---

## 4.2 重试机制：自动恢复临时故障

**核心思想：** 临时性错误（网络抖动、Rate Limit）应该自动重试

```python
import asyncio
from typing import TypeVar, Callable

T = TypeVar('T')

async def retry_with_backoff(
    func: Callable[..., T],
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    *args,
    **kwargs
) -> T:
    """重试装饰器（指数退避）"""
    for attempt in range(max_attempts):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            if attempt == max_attempts - 1:
                raise

            # 指数退避：1s, 2s, 4s
            delay = initial_delay * (2 ** attempt)
            print(f"重试 {attempt + 1}/{max_attempts}，等待 {delay}s")
            await asyncio.sleep(delay)
```

**在 AI Agent API 中的应用：**
```python
async def call_llm(prompt: str):
    """调用 LLM（自动重试）"""
    return await retry_with_backoff(
        _call_llm_internal,
        max_attempts=3,
        initial_delay=1.0,
        prompt=prompt
    )

async def _call_llm_internal(prompt: str):
    """内部 LLM 调用"""
    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

## 4.3 超时控制：防止请求无限等待

**核心思想：** 所有外部调用都应该设置超时

```python
import asyncio

async def call_with_timeout(func, timeout: float, *args, **kwargs):
    """带超时的函数调用"""
    try:
        async with asyncio.timeout(timeout):
            return await func(*args, **kwargs)
    except asyncio.TimeoutError:
        raise TimeoutError(f"操作超时（{timeout}s）")
```

**在 AI Agent API 中的应用：**
```python
@app.post("/chat")
async def chat(message: str):
    try:
        # LLM 调用超时：30s
        response = await call_with_timeout(
            call_llm,
            timeout=30.0,
            prompt=message
        )
        return {"response": response}
    except TimeoutError:
        raise HTTPException(
            status_code=504,
            detail="LLM 服务响应超时，请稍后重试"
        )
```

---

## 4.4 统一异常处理：用户友好的错误响应

**核心思想：** 所有异常都应该转换为统一的错误响应格式

```python
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse

app = FastAPI()

@app.exception_handler(BusinessError)
async def business_error_handler(request: Request, exc: BusinessError):
    """业务异常处理器"""
    return JSONResponse(
        status_code=422,
        content={
            "error": exc.message,
            "error_code": exc.error_code or "BUSINESS_ERROR"
        }
    )

@app.exception_handler(SystemError)
async def system_error_handler(request: Request, exc: SystemError):
    """系统异常处理器"""
    return JSONResponse(
        status_code=500,
        content={
            "error": "服务暂时不可用，请稍后重试",
            "error_code": exc.error_code or "SYSTEM_ERROR"
        }
    )

@app.exception_handler(Exception)
async def global_error_handler(request: Request, exc: Exception):
    """全局异常处理器"""
    # 记录错误日志
    print(f"未处理的异常: {type(exc).__name__}: {str(exc)}")

    return JSONResponse(
        status_code=500,
        content={
            "error": "服务器内部错误",
            "error_code": "INTERNAL_ERROR"
        }
    )
```

**在 AI Agent API 中的应用：**
```python
@app.post("/chat")
async def chat(message: str):
    # 不需要手动 try-catch，异常会被全局处理器捕获
    if len(message) > 2000:
        raise TextTooLongError("输入文本过长")

    response = await call_llm(message)
    return {"response": response}

# 用户输入过长 → 返回 422
# {
#   "error": "输入文本过长",
#   "error_code": "TEXT_TOO_LONG"
# }

# LLM 超时 → 返回 500
# {
#   "error": "服务暂时不可用，请稍后重试",
#   "error_code": "LLM_TIMEOUT"
# }
```

---

## 4.5 错误日志：追踪问题根源

**核心思想：** 所有错误都应该记录详细的上下文信息

```python
import structlog
import traceback

logger = structlog.get_logger()

@app.exception_handler(Exception)
async def global_error_handler(request: Request, exc: Exception):
    """全局异常处理器（带日志）"""
    # 记录详细错误日志
    logger.error(
        "unhandled_exception",
        error_type=type(exc).__name__,
        error_message=str(exc),
        path=request.url.path,
        method=request.method,
        stack_trace=traceback.format_exc()
    )

    return JSONResponse(
        status_code=500,
        content={
            "error": "服务器内部错误",
            "error_code": "INTERNAL_ERROR"
        }
    )
```

**日志输出示例：**
```json
{
  "timestamp": "2026-02-12T08:00:00Z",
  "level": "error",
  "event": "unhandled_exception",
  "error_type": "TimeoutError",
  "error_message": "Request timeout after 30s",
  "path": "/api/chat",
  "method": "POST",
  "stack_trace": "Traceback (most recent call last):\n  ..."
}
```

---

## 这些知识足以：

**基础错误处理：**
- ✅ 区分业务异常和系统异常
- ✅ 自动重试临时故障（指数退避）
- ✅ 防止请求无限等待（超时控制）
- ✅ 返回用户友好的错误响应
- ✅ 记录详细的错误日志

**处理 AI Agent API 的常见错误：**
- ✅ 用户输入过长 → 返回 422
- ✅ LLM 调用超时 → 自动重试 3 次
- ✅ Rate Limit → 指数退避重试
- ✅ 数据库连接失败 → 记录日志，返回 500

**为后续学习打基础：**
- → 熔断器（防止雪崩）
- → 错误监控（Sentry 集成）
- → Request ID 追踪（分布式追踪）
- → 环境感知错误详情（开发 vs 生产）

---

## 完整示例：最小可用的 AI Agent API

```python
"""
最小可用的 AI Agent API 错误处理
包含：异常分层、重试、超时、统一异常处理、错误日志
"""

import asyncio
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI
import structlog

# ===== 1. 异常分层 =====
class AppError(Exception):
    """应用基础异常"""
    def __init__(self, message: str, error_code: str = None):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class BusinessError(AppError):
    """业务异常"""
    pass

class SystemError(AppError):
    """系统异常"""
    pass

class TextTooLongError(BusinessError):
    """文本过长"""
    pass

class LLMTimeoutError(SystemError):
    """LLM 超时"""
    pass

# ===== 2. 重试机制 =====
async def retry_with_backoff(func, max_attempts=3, initial_delay=1.0, *args, **kwargs):
    """重试装饰器（指数退避）"""
    for attempt in range(max_attempts):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            if attempt == max_attempts - 1:
                raise
            delay = initial_delay * (2 ** attempt)
            await asyncio.sleep(delay)

# ===== 3. 超时控制 =====
async def call_with_timeout(func, timeout, *args, **kwargs):
    """带超时的函数调用"""
    try:
        async with asyncio.timeout(timeout):
            return await func(*args, **kwargs)
    except asyncio.TimeoutError:
        raise LLMTimeoutError(f"操作超时（{timeout}s）")

# ===== 4. LLM 调用 =====
client = AsyncOpenAI()

async def call_llm(prompt: str) -> str:
    """调用 LLM（带重试和超时）"""
    async def _call():
        response = await client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    # 重试 + 超时
    return await call_with_timeout(
        retry_with_backoff,
        timeout=30.0,
        func=_call,
        max_attempts=3
    )

# ===== 5. FastAPI 应用 =====
app = FastAPI()
logger = structlog.get_logger()

# ===== 6. 统一异常处理 =====
@app.exception_handler(BusinessError)
async def business_error_handler(request: Request, exc: BusinessError):
    return JSONResponse(
        status_code=422,
        content={
            "error": exc.message,
            "error_code": exc.error_code or "BUSINESS_ERROR"
        }
    )

@app.exception_handler(SystemError)
async def system_error_handler(request: Request, exc: SystemError):
    logger.error(
        "system_error",
        error_type=type(exc).__name__,
        error_message=exc.message,
        path=request.url.path
    )
    return JSONResponse(
        status_code=500,
        content={
            "error": "服务暂时不可用，请稍后重试",
            "error_code": exc.error_code or "SYSTEM_ERROR"
        }
    )

@app.exception_handler(Exception)
async def global_error_handler(request: Request, exc: Exception):
    logger.error(
        "unhandled_exception",
        error_type=type(exc).__name__,
        error_message=str(exc),
        path=request.url.path
    )
    return JSONResponse(
        status_code=500,
        content={
            "error": "服务器内部错误",
            "error_code": "INTERNAL_ERROR"
        }
    )

# ===== 7. API 端点 =====
@app.post("/chat")
async def chat(message: str):
    """聊天端点"""
    # 业务校验
    if len(message) > 2000:
        raise TextTooLongError("输入文本过长，请缩短至 2000 字以内")

    # 调用 LLM（自动重试、超时、错误处理）
    response = await call_llm(message)
    return {"response": response}

# ===== 8. 运行 =====
# uvicorn main:app --reload
```

**测试：**
```bash
# 正常请求
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "你好"}'
# → {"response": "你好！有什么我可以帮助你的吗？"}

# 文本过长
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "很长的文本..."}'
# → {"error": "输入文本过长，请缩短至 2000 字以内", "error_code": "TEXT_TOO_LONG"}

# LLM 超时（自动重试 3 次）
# → {"error": "服务暂时不可用，请稍后重试", "error_code": "LLM_TIMEOUT"}
```

---

## 总结

**20% 的核心知识：**
1. **异常分层**：区分业务异常和系统异常
2. **重试机制**：自动恢复临时故障（指数退避）
3. **超时控制**：防止请求无限等待
4. **统一异常处理**：用户友好的错误响应
5. **错误日志**：追踪问题根源

**解决 80% 的问题：**
- ✅ 用户输入错误 → 返回 422
- ✅ LLM 临时故障 → 自动重试
- ✅ LLM 超时 → 超时控制
- ✅ 未知错误 → 统一处理
- ✅ 问题追踪 → 错误日志

**下一步学习：**
- 熔断器（防止雪崩）
- 错误监控（Sentry）
- Request ID 追踪
- 环境感知错误详情
