# 核心概念03：HNSW算法原理

> 深入理解HNSW分层导航小世界图的核心原理与实现

---

## 概述

**HNSW（Hierarchical Navigable Small World）** 是目前最流行的向量检索算法。

**核心特点**：
- 召回率：95-98%
- 查询时间：O(log n)
- 适用规模：<1000万向量

---

## 1. 小世界现象

### 1.1 六度分隔理论

**定义**：任意两个人通过平均6个中间人就能建立联系。

**在图中的体现**：
```
普通图：A → B → C → D → E → F → G（6跳）
小世界图：A → B → G（2跳，通过长距离连接）
```

**数学特性**：
- 平均路径长度：O(log n)
- 聚类系数高

---

### 1.2 NSW（Navigable Small World）

**核心思想**：构建小世界图，通过贪心搜索找到最近邻。

**简化实现**：
```python
import numpy as np

class NSW:
    """简化的NSW实现"""

    def __init__(self, M=16):
        self.M = M  # 每个节点的最大连接数
        self.graph = {}
        self.vectors = {}
        self.entry_point = None

    def add(self, vector, node_id):
        """添加节点"""
        self.vectors[node_id] = vector

        if self.entry_point is None:
            self.entry_point = node_id
            self.graph[node_id] = []
            return

        # 贪心搜索找到最近的节点
        nearest = self._greedy_search(vector, self.entry_point)

        # 找到M个最近邻
        neighbors = self._find_neighbors(vector, nearest, self.M)

        # 双向连接
        self.graph[node_id] = neighbors
        for neighbor in neighbors:
            if len(self.graph[neighbor]) < self.M:
                self.graph[neighbor].append(node_id)

    def _greedy_search(self, query, entry):
        """贪心搜索"""
        current = entry
        visited = set([current])

        while True:
            current_dist = np.linalg.norm(query - self.vectors[current])

            # 检查所有邻居
            found_better = False
            for neighbor in self.graph[current]:
                if neighbor in visited:
                    continue

                neighbor_dist = np.linalg.norm(query - self.vectors[neighbor])
                if neighbor_dist < current_dist:
                    current = neighbor
                    current_dist = neighbor_dist
                    found_better = True
                    break

            visited.add(current)

            if not found_better:
                break

        return current

    def search(self, query, k=10):
        """搜索Top-K"""
        nearest = self._greedy_search(query, self.entry_point)
        neighbors = self._find_neighbors(query, nearest, k)

        results = []
        for node in neighbors:
            dist = np.linalg.norm(query - self.vectors[node])
            results.append((dist, node))

        results.sort()
        return results[:k]
```

**问题**：
- ❌ 入口点选择影响性能
- ❌ 可能陷入局部最优

---

## 2. HNSW分层结构

### 2.1 核心思想

**分层导航**：
```
层级0（顶层）：稀疏连接，快速跳跃（高速公路）
层级1（中层）：中等密度，区域定位（城市道路）
层级2（底层）：稠密连接，精确搜索（小区街道）
```

**类比**：
- 顶层 = 高速公路（快速跨越省份）
- 中层 = 城市道路（定位到具体区域）
- 底层 = 小区街道（精确找到目标）

---

### 2.2 层级分配

**随机层级分配**：
```python
import random

def get_random_level(max_level=5, ml=1.0/np.log(2.0)):
    """随机分配层级"""
    level = int(-np.log(random.uniform(0, 1)) * ml)
    return min(level, max_level)

# 示例
for i in range(10):
    level = get_random_level()
    print(f"节点{i}: 层级{level}")
```

**输出：**
```
节点0: 层级0
节点1: 层级0
节点2: 层级1
节点3: 层级0
节点4: 层级2
...
```

**层级分布**：
- 层级0：100%节点
- 层级1：50%节点
- 层级2：25%节点
- 层级3：12.5%节点

---

### 2.3 HNSW结构

```python
class HNSW:
    """简化的HNSW实现"""

    def __init__(self, M=16, ef_construction=200, max_level=5):
        self.M = M  # 每层的最大连接数
        self.M0 = M * 2  # 底层的最大连接数
        self.ef_construction = ef_construction
        self.max_level = max_level
        self.ml = 1.0 / np.log(2.0)

        self.graphs = {}  # {level: {node_id: [neighbors]}}
        self.vectors = {}
        self.entry_point = None
        self.max_level_current = 0

    def _get_random_level(self):
        """随机分配层级"""
        level = int(-np.log(random.uniform(0, 1)) * self.ml)
        return min(level, self.max_level)

    def add(self, vector, node_id):
        """添加节点"""
        self.vectors[node_id] = vector
        level = self._get_random_level()

        if self.entry_point is None:
            self.entry_point = node_id
            self.max_level_current = level
            for lc in range(level + 1):
                if lc not in self.graphs:
                    self.graphs[lc] = {}
                self.graphs[lc][node_id] = []
            return

        # 从顶层搜索到目标层
        nearest = self._search_layer(vector, self.entry_point, 1, self.max_level_current, level + 1)

        # 在每一层插入节点
        for lc in range(level, -1, -1):
            if lc not in self.graphs:
                self.graphs[lc] = {}

            # 找到最近的M个邻居
            candidates = self._search_layer(vector, nearest[0], self.ef_construction, lc, lc)
            M = self.M if lc > 0 else self.M0
            neighbors = self._select_neighbors(vector, candidates, M)

            # 添加双向连接
            self.graphs[lc][node_id] = neighbors
            for neighbor in neighbors:
                self.graphs[lc][neighbor].append(node_id)

                # 修剪邻居的连接
                if len(self.graphs[lc][neighbor]) > M:
                    self.graphs[lc][neighbor] = self._select_neighbors(
                        self.vectors[neighbor],
                        self.graphs[lc][neighbor],
                        M
                    )

            nearest = neighbors

        # 更新入口点
        if level > self.max_level_current:
            self.max_level_current = level
            self.entry_point = node_id

    def search(self, query, k=10, ef=64):
        """搜索Top-K"""
        if self.entry_point is None:
            return []

        # 从顶层搜索到底层
        nearest = self._search_layer(query, self.entry_point, 1, self.max_level_current, 1)

        # 在底层搜索
        candidates = self._search_layer(query, nearest[0], ef, 0, 0)

        # 排序返回Top-K
        results = []
        for node_id in candidates[:k]:
            dist = np.linalg.norm(query - self.vectors[node_id])
            results.append((dist, node_id))

        results.sort()
        return results[:k]
```

---

## 3. 三个关键参数

### 3.1 M（连接数）

**定义**：每个节点的最大连接数

**影响**：
- M越大：召回率越高，内存占用越大
- M越小：内存占用越小，召回率越低

**推荐值**：
```python
# 平衡配置
M = 16

# 高召回率配置
M = 32

# 低内存配置
M = 8
```

---

### 3.2 efConstruction（构建搜索宽度）

**定义**：构建索引时的搜索宽度

**影响**：
- efConstruction越大：召回率越高，构建时间越长
- efConstruction越小：构建时间越短，召回率越低

**推荐值**：
```python
# 快速构建
ef_construction = 100

# 平衡配置
ef_construction = 200

# 高召回率配置
ef_construction = 500
```

---

### 3.3 efSearch（查询搜索宽度）

**定义**：查询时的搜索宽度

**影响**：
- efSearch越大：召回率越高，查询延迟越高
- efSearch越小：查询延迟越低，召回率越低

**推荐值**：
```python
# 快速查询
ef_search = 16

# 平衡配置
ef_search = 64

# 高召回率配置
ef_search = 128
```

---

## 4. 性能分析

### 4.1 时间复杂度

**构建**：O(n × log n × M × efConstruction)
**查询**：O(log n × efSearch)

---

### 4.2 空间复杂度

**内存占用**：
```
每个向量：d × 4字节（float32）
每个连接：4字节（int32）
总内存：n × (d × 4 + M × 2 × 4)

示例（100万向量，768维，M=16）：
向量：100万 × 768 × 4 = 3GB
连接：100万 × 16 × 2 × 4 = 128MB
总计：~3.1GB
```

---

## 5. 在RAG系统中的应用

### 5.1 ChromaDB配置

```python
import chromadb

client = chromadb.PersistentClient(path="./db")

collection = client.get_or_create_collection(
    name="documents",
    metadata={
        "hnsw:space": "cosine",
        "hnsw:M": 16,
        "hnsw:ef_construction": 200,
        "hnsw:ef_search": 64
    }
)
```

---

### 5.2 Milvus配置

```python
from pymilvus import Collection, connections

connections.connect(host="localhost", port="19530")

index_params = {
    "metric_type": "COSINE",
    "index_type": "HNSW",
    "params": {
        "M": 16,
        "efConstruction": 200
    }
}

collection.create_index(
    field_name="embedding",
    index_params=index_params
)

# 查询参数
search_params = {
    "metric_type": "COSINE",
    "params": {"ef": 64}
}

results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

---

## 6. 2025-2026最新优化

### 6.1 HNSW++（AMCIS 2025）

**核心创新**：
- 双分支搜索策略
- 局部内在维度(LID)优化
- 召回率↑35%，推理时间↓45%

**来源**：AMCIS 2025 Conference

---

### 6.2 Ada-ef（arXiv 2512.06636）

**核心创新**：
- 自适应efSearch参数
- 查询延迟↓4倍
- 内存使用↓100倍

**来源**：arXiv 2512.06636 (2025)

---

### 6.3 ACORN-1（Elastic/Vespa 2025）

**核心创新**：
- 过滤搜索加速5倍
- 支持复杂过滤条件

**来源**：Elastic/Vespa 2025

---

## 总结

### 核心要点

1. **分层结构**：顶层快速跳跃，底层精确搜索
2. **三个参数**：M、efConstruction、efSearch
3. **时间复杂度**：O(log n)
4. **召回率**：95-98%
5. **适用场景**：中小规模（<1000万向量）

### 参数推荐

| 场景 | M | efConstruction | efSearch |
|------|---|----------------|----------|
| 快速原型 | 16 | 100 | 16 |
| 平衡性能 | 16 | 200 | 64 |
| 高召回率 | 32 | 500 | 128 |

### 下一步

学习 `03_核心概念_04_HNSW_2025年最新优化.md`，了解最新优化技术。
