# 实战代码 - 场景2：压力测试

> 使用 Locust 进行高并发压力测试，测试系统极限性能

---

## 场景描述

**测试目标：** 模拟大量并发用户，测试 Milvus 在高负载下的性能表现

**适用场景：**
- 测试系统的极限 QPS
- 发现性能瓶颈（CPU、内存、网络）
- 验证系统稳定性
- 容量规划（需要多少台服务器）

---

## 完整代码

### 文件1：locustfile.py（Locust 测试脚本）

```python
"""
Milvus 压力测试
使用 Locust 模拟高并发场景
"""

from locust import User, task, between, events, LoadTestShape
from pymilvus import connections, Collection
import random
import time
import logging

# ===== 1. 配置参数 =====

CONFIG = {
    "milvus_host": "localhost",
    "milvus_port": "19530",
    "collection_name": "benchmark_stress",
    "dim": 768
}

# ===== 2. Milvus 用户类 =====

class MilvusUser(User):
    """模拟 Milvus 用户"""

    # 每次请求间隔 0.1-0.5 秒
    wait_time = between(0.1, 0.5)

    def on_start(self):
        """初始化连接（每个用户执行一次）"""
        try:
            connections.connect(
                alias=f"user_{id(self)}",
                host=CONFIG['milvus_host'],
                port=CONFIG['milvus_port']
            )
            self.collection = Collection(
                name=CONFIG['collection_name'],
                using=f"user_{id(self)}"
            )
            self.collection.load()
            logging.info(f"用户 {id(self)} 连接成功")
        except Exception as e:
            logging.error(f"用户 {id(self)} 连接失败: {e}")
            raise

    def on_stop(self):
        """清理连接（每个用户结束时执行）"""
        try:
            connections.disconnect(alias=f"user_{id(self)}")
            logging.info(f"用户 {id(self)} 断开连接")
        except Exception as e:
            logging.error(f"用户 {id(self)} 断开连接失败: {e}")

    @task(weight=10)
    def search_vector(self):
        """执行向量检索（权重10，执行频率高）"""
        # 生成随机向量
        vector = [random.random() for _ in range(CONFIG['dim'])]

        # 记录开始时间
        start_time = time.time()

        try:
            # 执行检索
            self.collection.search(
                data=[vector],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=10
            )

            # 记录成功
            total_time = int((time.time() - start_time) * 1000)
            events.request.fire(
                request_type="search",
                name="vector_search",
                response_time=total_time,
                response_length=10,
                exception=None,
                context={}
            )

        except Exception as e:
            # 记录失败
            total_time = int((time.time() - start_time) * 1000)
            events.request.fire(
                request_type="search",
                name="vector_search",
                response_time=total_time,
                response_length=0,
                exception=e,
                context={}
            )

    @task(weight=3)
    def search_with_filter(self):
        """执行混合检索（权重3，执行频率中等）"""
        vector = [random.random() for _ in range(CONFIG['dim'])]
        category = random.choice(["A", "B", "C", "D"])

        start_time = time.time()

        try:
            self.collection.search(
                data=[vector],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=10,
                expr=f"category == '{category}'"
            )

            total_time = int((time.time() - start_time) * 1000)
            events.request.fire(
                request_type="search",
                name="hybrid_search",
                response_time=total_time,
                response_length=10,
                exception=None,
                context={}
            )

        except Exception as e:
            total_time = int((time.time() - start_time) * 1000)
            events.request.fire(
                request_type="search",
                name="hybrid_search",
                response_time=total_time,
                response_length=0,
                exception=e,
                context={}
            )

    @task(weight=1)
    def batch_search(self):
        """执行批量检索（权重1，执行频率低）"""
        vectors = [[random.random() for _ in range(CONFIG['dim'])] for _ in range(5)]

        start_time = time.time()

        try:
            self.collection.search(
                data=vectors,
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=10
            )

            total_time = int((time.time() - start_time) * 1000)
            events.request.fire(
                request_type="search",
                name="batch_search",
                response_time=total_time,
                response_length=50,
                exception=None,
                context={}
            )

        except Exception as e:
            total_time = int((time.time() - start_time) * 1000)
            events.request.fire(
                request_type="search",
                name="batch_search",
                response_time=total_time,
                response_length=0,
                exception=e,
                context={}
            )

# ===== 3. 自定义负载形状 =====

class StagesShape(LoadTestShape):
    """阶梯式负载测试"""

    stages = [
        {"duration": 60, "users": 10, "spawn_rate": 10},    # 1分钟，10用户
        {"duration": 120, "users": 50, "spawn_rate": 10},   # 2分钟，50用户
        {"duration": 180, "users": 100, "spawn_rate": 10},  # 3分钟，100用户
        {"duration": 240, "users": 200, "spawn_rate": 20},  # 4分钟，200用户
        {"duration": 300, "users": 500, "spawn_rate": 50},  # 5分钟，500用户
    ]

    def tick(self):
        """返回当前阶段的用户数和生成速率"""
        run_time = self.get_run_time()

        for stage in self.stages:
            if run_time < stage["duration"]:
                return (stage["users"], stage["spawn_rate"])

        return None  # 测试结束

# ===== 4. 事件监听器 =====

@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """测试开始时执行"""
    print("="*60)
    print("Milvus 压力测试开始")
    print("="*60)
    print(f"目标: {CONFIG['milvus_host']}:{CONFIG['milvus_port']}")
    print(f"Collection: {CONFIG['collection_name']}")
    print("="*60)

@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """测试结束时执行"""
    print("\n" + "="*60)
    print("Milvus 压力测试结束")
    print("="*60)

    # 打印统计信息
    stats = environment.stats
    print(f"\n总请求数: {stats.total.num_requests}")
    print(f"失败请求数: {stats.total.num_failures}")
    print(f"失败率: {stats.total.fail_ratio:.2%}")
    print(f"平均响应时间: {stats.total.avg_response_time:.2f}ms")
    print(f"P95响应时间: {stats.total.get_response_time_percentile(0.95):.2f}ms")
    print(f"P99响应时间: {stats.total.get_response_time_percentile(0.99):.2f}ms")
    print(f"总 RPS: {stats.total.total_rps:.2f}")
```

---

### 文件2：run_stress_test.py（测试执行脚本）

```python
"""
执行 Milvus 压力测试
"""

import subprocess
import time
import json
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType
import numpy as np

# ===== 1. 配置参数 =====

CONFIG = {
    "milvus_host": "localhost",
    "milvus_port": "19530",
    "collection_name": "benchmark_stress",
    "dim": 768,
    "num_vectors": 1_000_000
}

# ===== 2. 准备测试环境 =====

def prepare_environment():
    """准备测试环境"""
    print("=== 准备测试环境 ===")

    # 连接 Milvus
    connections.connect("default", host=CONFIG['milvus_host'], port=CONFIG['milvus_port'])

    # 创建 Collection
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=CONFIG['dim']),
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=10)
    ]
    schema = CollectionSchema(fields=fields, description="Stress test collection")

    try:
        collection = Collection(name=CONFIG['collection_name'])
        print(f"Collection {CONFIG['collection_name']} 已存在")
    except:
        collection = Collection(name=CONFIG['collection_name'], schema=schema)
        print(f"Collection {CONFIG['collection_name']} 创建成功")

        # 插入数据
        print(f"插入 {CONFIG['num_vectors']:,} 个向量...")
        batch_size = 10000
        for i in range(0, CONFIG['num_vectors'], batch_size):
            vectors = np.random.normal(0, 1, (batch_size, CONFIG['dim'])).astype(np.float32)
            vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
            categories = np.random.choice(["A", "B", "C", "D"], batch_size).tolist()

            collection.insert([vectors.tolist(), categories])

            if (i + batch_size) % 100000 == 0:
                print(f"  已插入: {i + batch_size:,} / {CONFIG['num_vectors']:,}")

        print("✅ 数据插入完成")

    # 创建索引
    print("创建 HNSW 索引...")
    collection.release()
    collection.drop_index()
    collection.create_index(
        field_name="embedding",
        index_params={
            "metric_type": "L2",
            "index_type": "HNSW",
            "params": {"M": 16, "efConstruction": 200}
        }
    )
    print("✅ 索引创建完成")

    # 加载 Collection
    print("加载 Collection...")
    collection.load()
    print("✅ Collection 加载完成")

    print("\n✅ 测试环境准备完成\n")

# ===== 3. 运行压力测试 =====

def run_stress_test(test_type="web"):
    """运行压力测试"""

    if test_type == "web":
        # Web UI 模式
        print("=== 启动 Locust Web UI ===")
        print("访问 http://localhost:8089 开始测试")
        print("按 Ctrl+C 停止测试")

        subprocess.run([
            "locust",
            "-f", "locustfile.py",
            "--host", f"http://{CONFIG['milvus_host']}:{CONFIG['milvus_port']}"
        ])

    elif test_type == "headless":
        # 无头模式（自动化测试）
        print("=== 启动 Locust 无头模式 ===")

        subprocess.run([
            "locust",
            "-f", "locustfile.py",
            "--host", f"http://{CONFIG['milvus_host']}:{CONFIG['milvus_port']}",
            "--users", "100",
            "--spawn-rate", "10",
            "--run-time", "5m",
            "--headless",
            "--html", "stress_test_report.html",
            "--csv", "stress_test_results"
        ])

        print("\n✅ 测试完成")
        print("报告已保存到: stress_test_report.html")
        print("CSV 数据已保存到: stress_test_results_*.csv")

    elif test_type == "stages":
        # 阶梯式负载测试
        print("=== 启动阶梯式负载测试 ===")

        subprocess.run([
            "locust",
            "-f", "locustfile.py",
            "--host", f"http://{CONFIG['milvus_host']}:{CONFIG['milvus_port']}",
            "--headless",
            "--html", "stress_test_stages_report.html",
            "--csv", "stress_test_stages_results"
        ])

# ===== 4. 分析测试结果 =====

def analyze_results(csv_prefix="stress_test_results"):
    """分析测试结果"""
    import pandas as pd
    import matplotlib.pyplot as plt

    print("\n=== 分析测试结果 ===")

    # 读取 CSV 文件
    stats_df = pd.read_csv(f"{csv_prefix}_stats.csv")
    history_df = pd.read_csv(f"{csv_prefix}_stats_history.csv")

    # 打印统计信息
    print("\n请求类型统计:")
    print(stats_df[['Name', 'Request Count', 'Failure Count', 'Average Response Time', '95%', '99%']])

    # 绘制图表
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. RPS 趋势
    axes[0, 0].plot(history_df['Timestamp'], history_df['Total Request Count'])
    axes[0, 0].set_title('Total Requests Over Time')
    axes[0, 0].set_xlabel('Time')
    axes[0, 0].set_ylabel('Total Requests')

    # 2. 响应时间趋势
    axes[0, 1].plot(history_df['Timestamp'], history_df['Total Average Response Time'], label='Avg')
    axes[0, 1].plot(history_df['Timestamp'], history_df['Total 95%'], label='P95')
    axes[0, 1].set_title('Response Time Over Time')
    axes[0, 1].set_xlabel('Time')
    axes[0, 1].set_ylabel('Response Time (ms)')
    axes[0, 1].legend()

    # 3. 用户数趋势
    axes[1, 0].plot(history_df['Timestamp'], history_df['User Count'])
    axes[1, 0].set_title('User Count Over Time')
    axes[1, 0].set_xlabel('Time')
    axes[1, 0].set_ylabel('Users')

    # 4. 失败率趋势
    failure_rate = (history_df['Total Failure Count'] / history_df['Total Request Count']) * 100
    axes[1, 1].plot(history_df['Timestamp'], failure_rate)
    axes[1, 1].set_title('Failure Rate Over Time')
    axes[1, 1].set_xlabel('Time')
    axes[1, 1].set_ylabel('Failure Rate (%)')

    plt.tight_layout()
    plt.savefig('stress_test_analysis.png')
    print("\n✅ 图表已保存到: stress_test_analysis.png")

# ===== 5. 主函数 =====

def main():
    """主函数"""
    import sys

    if len(sys.argv) < 2:
        print("用法:")
        print("  python run_stress_test.py prepare    # 准备测试环境")
        print("  python run_stress_test.py web        # 启动 Web UI 模式")
        print("  python run_stress_test.py headless   # 启动无头模式")
        print("  python run_stress_test.py stages     # 启动阶梯式负载测试")
        print("  python run_stress_test.py analyze    # 分析测试结果")
        return

    command = sys.argv[1]

    if command == "prepare":
        prepare_environment()
    elif command == "web":
        run_stress_test("web")
    elif command == "headless":
        run_stress_test("headless")
    elif command == "stages":
        run_stress_test("stages")
    elif command == "analyze":
        analyze_results()
    else:
        print(f"未知命令: {command}")

if __name__ == "__main__":
    main()
```

---

## 使用步骤

### 1. 安装依赖

```bash
pip install locust pymilvus numpy pandas matplotlib
```

### 2. 准备测试环境

```bash
python run_stress_test.py prepare
```

### 3. 运行压力测试

**方式1：Web UI 模式（推荐）**

```bash
python run_stress_test.py web
```

然后访问 http://localhost:8089，设置：
- Number of users: 100
- Spawn rate: 10
- Host: http://localhost:19530

点击 "Start swarming" 开始测试。

**方式2：无头模式（自动化）**

```bash
python run_stress_test.py headless
```

**方式3：阶梯式负载测试**

```bash
python run_stress_test.py stages
```

### 4. 分析结果

```bash
python run_stress_test.py analyze
```

---

## 运行输出示例

```
=== 准备测试环境 ===
Collection benchmark_stress 创建成功
插入 1,000,000 个向量...
  已插入: 100,000 / 1,000,000
  已插入: 200,000 / 1,000,000
  ...
✅ 数据插入完成
创建 HNSW 索引...
✅ 索引创建完成
加载 Collection...
✅ Collection 加载完成

✅ 测试环境准备完成

============================================================
Milvus 压力测试开始
============================================================
目标: localhost:19530
Collection: benchmark_stress
============================================================

[2026-02-10 10:00:00] Starting Locust 2.15.1
[2026-02-10 10:00:00] Spawning 10 users at the rate 10 users/s (0 users already running)...
[2026-02-10 10:00:01] All users spawned: {"MilvusUser": 10} (10 total users)

[2026-02-10 10:01:00] Spawning 40 more users at the rate 10 users/s (10 users already running)...
[2026-02-10 10:01:04] All users spawned: {"MilvusUser": 50} (50 total users)

[2026-02-10 10:02:00] Spawning 50 more users at the rate 10 users/s (50 users already running)...
[2026-02-10 10:02:05] All users spawned: {"MilvusUser": 100} (100 total users)

============================================================
Milvus 压力测试结束
============================================================

总请求数: 15234
失败请求数: 23
失败率: 0.15%
平均响应时间: 28.45ms
P95响应时间: 65.23ms
P99响应时间: 120.34ms
总 RPS: 1523.4

=== 分析测试结果 ===

请求类型统计:
                Name  Request Count  Failure Count  Average Response Time    95%    99%
0      vector_search          10234              15                  25.34  58.23  98.45
1      hybrid_search           3456               5                  35.67  78.90 145.23
2       batch_search           1544               3                  42.18  95.34 178.56

✅ 图表已保存到: stress_test_analysis.png
```

---

## 关键指标分析

### 1. QPS（每秒查询数）

```python
# Locust 自动计算 RPS（Requests Per Second）
总 RPS = 1523.4

# 不同负载下的 QPS
10 用户: QPS ≈ 500
50 用户: QPS ≈ 1200
100 用户: QPS ≈ 1500
200 用户: QPS ≈ 1600  # 接近瓶颈
500 用户: QPS ≈ 1550  # 性能下降
```

**分析：**
- 100-200 用户时 QPS 达到峰值
- 超过 200 用户后 QPS 不再增长，说明达到系统瓶颈

### 2. 响应时间

```python
# 不同负载下的响应时间
10 用户: P95 = 30ms, P99 = 45ms
50 用户: P95 = 50ms, P99 = 80ms
100 用户: P95 = 65ms, P99 = 120ms
200 用户: P95 = 150ms, P99 = 300ms  # 延迟显著增加
500 用户: P95 = 500ms, P99 = 1200ms  # 延迟剧增
```

**分析：**
- 100 用户以下延迟稳定
- 超过 200 用户延迟剧增，说明系统过载

### 3. 失败率

```python
# 不同负载下的失败率
10-100 用户: 失败率 < 0.1%
200 用户: 失败率 ≈ 0.5%
500 用户: 失败率 ≈ 5%  # 失败率显著增加
```

**分析：**
- 失败率增加说明系统无法处理所有请求
- 可能原因：连接池耗尽、超时、内存不足

---

## 性能瓶颈识别

### 1. CPU 瓶颈

```bash
# 在测试过程中监控 CPU 使用率
top -p $(pgrep milvus)

# 如果 CPU 使用率 > 90%，说明 CPU 是瓶颈
```

**优化建议：**
- 使用更高效的索引类型（HNSW）
- 减少 nprobe/ef 值
- 增加 CPU 核心数

### 2. 内存瓶颈

```bash
# 监控内存使用
free -h

# 如果内存使用率 > 90%，说明内存是瓶颈
```

**优化建议：**
- 使用量化索引（IVF_SQ8）
- 使用分区减少加载数据量
- 增加内存容量

### 3. 网络瓶颈

```bash
# 监控网络流量
iftop

# 如果网络带宽饱和，说明网络是瓶颈
```

**优化建议：**
- 使用更快的网络（10Gbps）
- 客户端和服务端部署在同一机房
- 使用批量查询减少网络往返

---

## 在 RAG 开发中的应用

### 场景1：容量规划

```python
# 测试结果
单机 QPS = 1500
单机最大并发 = 200

# 业务需求
预期 QPS = 10000
预期并发 = 1000

# 容量规划
需要机器数 = 10000 / 1500 = 7台
考虑冗余（2倍）= 14台
```

### 场景2：性能优化验证

```python
# 优化前
QPS = 1000
P95延迟 = 100ms

# 优化后（调整索引参数）
QPS = 1500
P95延迟 = 65ms

# 提升
QPS 提升 = 50%
延迟降低 = 35%
```

### 场景3：SLA 保障

```python
# SLA 要求
QPS > 1000
P95延迟 < 100ms
可用性 > 99.9%

# 测试验证
实际 QPS = 1500  ✅
实际 P95延迟 = 65ms  ✅
实际失败率 = 0.15%（可用性 99.85%）  ⚠️

# 结论：需要优化失败率
```

---

## 关键洞察

1. **压力测试发现系统极限**
   - 单机 QPS 极限
   - 最大并发用户数
   - 性能瓶颈位置

2. **阶梯式负载测试更真实**
   - 逐步增加负载
   - 观察性能变化趋势
   - 找到性能拐点

3. **失败率是重要指标**
   - 失败率增加说明系统过载
   - 需要关注失败原因

4. **监控资源使用很重要**
   - CPU、内存、网络、磁盘
   - 定位性能瓶颈

5. **压力测试要接近生产环境**
   - 数据规模一致
   - 查询模式一致
   - 硬件配置一致

---

## 下一步

完成压力测试后，可以进行：
- **场景3：并发测试** - 测试多线程并发性能
- **场景4：RAG场景测试** - 测试端到端 RAG 系统性能
