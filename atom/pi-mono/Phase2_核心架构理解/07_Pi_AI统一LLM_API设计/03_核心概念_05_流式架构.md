# æ ¸å¿ƒæ¦‚å¿µ5ï¼šæµå¼æ¶æ„

> ç†è§£å¦‚ä½•é€šè¿‡ Event-based Streaming ç»Ÿä¸€ä¸åŒ LLM Provider çš„æµå¼å“åº”

---

## æ¦‚å¿µå®šä¹‰

**æµå¼æ¶æ„**æ˜¯æŒ‡ä½¿ç”¨äº‹ä»¶é©±åŠ¨çš„æ–¹å¼å¤„ç† LLM çš„æµå¼å“åº”ï¼Œå°†ä¸åŒ Provider çš„æµå¼æ ¼å¼ç»Ÿä¸€ä¸ºæ ‡å‡†çš„ start/delta/end ä¸‰æ®µå¼äº‹ä»¶æµã€‚

**æ ¸å¿ƒä»·å€¼ï¼š**
- **å®æ—¶å“åº”**ï¼šé€å­—è¾“å‡ºï¼Œæ— éœ€ç­‰å¾…å®Œæ•´å“åº”
- **ç”¨æˆ·ä½“éªŒ**ï¼šç±»ä¼¼ ChatGPT çš„æ‰“å­—æœºæ•ˆæœ
- **äº‹ä»¶ç»Ÿä¸€**ï¼šæ‰€æœ‰ Provider ä½¿ç”¨ç›¸åŒçš„äº‹ä»¶æ ¼å¼
- **é›¶æ‹·è´è½¬å‘**ï¼šç›´æ¥è½¬å‘æµå¼æ•°æ®ï¼Œæ— ç¼“å†²å¼€é”€

---

## ç¬¬ä¸€æ€§åŸç†

### é—®é¢˜çš„æœ¬è´¨

**æ ¸å¿ƒé—®é¢˜ï¼š** ä¸åŒ Provider çš„æµå¼å“åº”æ ¼å¼ä¸åŒï¼Œå¦‚ä½•ç»Ÿä¸€ï¼Ÿ

**OpenAI æµå¼æ ¼å¼ï¼ˆSSEï¼‰ï¼š**
```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","choices":[{"delta":{"content":"Hello"}}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","choices":[{"delta":{"content":" world"}}]}

data: [DONE]
```

**Anthropic æµå¼æ ¼å¼ï¼ˆSSE with eventsï¼‰ï¼š**
```
event: message_start
data: {"type":"message_start","message":{"id":"msg_123"}}

event: content_block_delta
data: {"type":"content_block_delta","delta":{"type":"text_delta","text":"Hello"}}

event: content_block_delta
data: {"type":"content_block_delta","delta":{"type":"text_delta","text":" world"}}

event: message_stop
data: {"type":"message_stop"}
```

**Google æµå¼æ ¼å¼ï¼ˆJSON æµï¼‰ï¼š**
```json
{"candidates":[{"content":{"parts":[{"text":"Hello"}]}}]}
{"candidates":[{"content":{"parts":[{"text":" world"}]}}]}
```

### è®¾è®¡åŸåˆ™

**1. ä¸‰æ®µå¼äº‹ä»¶æµ**
- `start` äº‹ä»¶ï¼šæµå¼€å§‹
- `delta` äº‹ä»¶ï¼šå¢é‡å†…å®¹
- `end` äº‹ä»¶ï¼šæµç»“æŸ

**2. äº‹ä»¶é©±åŠ¨**
- ä½¿ç”¨ AsyncGenerator äº§ç”Ÿäº‹ä»¶
- æ”¯æŒ for-await-of å¾ªç¯
- æ”¯æŒäº‹ä»¶ç›‘å¬å™¨

**3. é›¶æ‹·è´è½¬å‘**
- ç›´æ¥è½¬å‘æµå¼æ•°æ®
- ä¸ç¼“å†²å®Œæ•´å“åº”
- æœ€å°åŒ–å†…å­˜å ç”¨

**4. é”™è¯¯å¤„ç†**
- æµä¸­æ–­æ—¶æŠ›å‡ºå¼‚å¸¸
- æ”¯æŒé‡è¯•æœºåˆ¶
- ä¿ç•™éƒ¨åˆ†å“åº”

---

## æ ¸å¿ƒå®ç°

### 1. æµå¼äº‹ä»¶ç±»å‹å®šä¹‰

```typescript
/**
 * æµå¼äº‹ä»¶ç±»å‹
 * ç»Ÿä¸€çš„äº‹ä»¶æ ¼å¼
 */
type StreamEvent =
  | StreamStartEvent
  | StreamDeltaEvent
  | StreamEndEvent
  | StreamErrorEvent;

/**
 * æµå¼€å§‹äº‹ä»¶
 */
interface StreamStartEvent {
  type: 'start';
  model: string;
  id?: string;
  timestamp: number;
}

/**
 * æµå¢é‡äº‹ä»¶
 */
interface StreamDeltaEvent {
  type: 'delta';
  delta: {
    content?: string;
    toolCalls?: ToolCallDelta[];
  };
  index?: number;
}

/**
 * å·¥å…·è°ƒç”¨å¢é‡
 */
interface ToolCallDelta {
  id?: string;
  name?: string;
  input?: string;  // å¢é‡çš„ JSON å­—ç¬¦ä¸²
}

/**
 * æµç»“æŸäº‹ä»¶
 */
interface StreamEndEvent {
  type: 'end';
  usage: TokenUsage;
  finishReason?: string;
  timestamp: number;
}

/**
 * æµé”™è¯¯äº‹ä»¶
 */
interface StreamErrorEvent {
  type: 'error';
  error: {
    message: string;
    code?: string;
    details?: any;
  };
  timestamp: number;
}

/**
 * Token ä½¿ç”¨ç»Ÿè®¡
 */
interface TokenUsage {
  inputTokens: number;
  outputTokens: number;
  totalTokens: number;
  cost?: number;
}
```

### 2. æµå¼é€‚é…å™¨å®ç°

```typescript
/**
 * OpenAI æµå¼é€‚é…å™¨
 */
class OpenAIStreamAdapter {
  async *stream(
    client: OpenAI,
    request: OpenAI.ChatCompletionCreateParams
  ): AsyncGenerator<StreamEvent> {
    // 1. å‘é€ start äº‹ä»¶
    yield {
      type: 'start',
      model: request.model,
      timestamp: Date.now()
    };

    // 2. è°ƒç”¨ OpenAI Streaming API
    const stream = await client.chat.completions.create({
      ...request,
      stream: true
    });

    // 3. è½¬æ¢æµå¼å“åº”
    let totalTokens = 0;
    try {
      for await (const chunk of stream) {
        const delta = chunk.choices[0]?.delta;

        if (delta?.content) {
          yield {
            type: 'delta',
            delta: { content: delta.content }
          };
        }

        if (delta?.tool_calls) {
          yield {
            type: 'delta',
            delta: {
              toolCalls: delta.tool_calls.map(tc => ({
                id: tc.id,
                name: tc.function?.name,
                input: tc.function?.arguments
              }))
            }
          };
        }
      }

      // 4. å‘é€ end äº‹ä»¶
      yield {
        type: 'end',
        usage: {
          inputTokens: 0,  // OpenAI æµå¼ä¸è¿”å› usage
          outputTokens: 0,
          totalTokens: 0
        },
        timestamp: Date.now()
      };
    } catch (error) {
      // 5. å‘é€ error äº‹ä»¶
      yield {
        type: 'error',
        error: {
          message: error.message,
          code: error.code
        },
        timestamp: Date.now()
      };
    }
  }
}

/**
 * Anthropic æµå¼é€‚é…å™¨
 */
class AnthropicStreamAdapter {
  async *stream(
    client: Anthropic,
    request: Anthropic.MessageCreateParams
  ): AsyncGenerator<StreamEvent> {
    // 1. å‘é€ start äº‹ä»¶
    yield {
      type: 'start',
      model: request.model,
      timestamp: Date.now()
    };

    // 2. è°ƒç”¨ Anthropic Streaming API
    const stream = await client.messages.create({
      ...request,
      stream: true
    });

    // 3. è½¬æ¢æµå¼å“åº”
    let usage: TokenUsage = {
      inputTokens: 0,
      outputTokens: 0,
      totalTokens: 0
    };

    try {
      for await (const event of stream) {
        if (event.type === 'message_start') {
          // æ¶ˆæ¯å¼€å§‹ï¼ˆå·²ç»å‘é€äº† start äº‹ä»¶ï¼‰
          continue;
        } else if (event.type === 'content_block_start') {
          // å†…å®¹å—å¼€å§‹
          continue;
        } else if (event.type === 'content_block_delta') {
          // å†…å®¹å¢é‡
          if (event.delta.type === 'text_delta') {
            yield {
              type: 'delta',
              delta: { content: event.delta.text }
            };
          } else if (event.delta.type === 'input_json_delta') {
            // å·¥å…·è°ƒç”¨å¢é‡
            yield {
              type: 'delta',
              delta: {
                toolCalls: [{
                  input: event.delta.partial_json
                }]
              }
            };
          }
        } else if (event.type === 'content_block_stop') {
          // å†…å®¹å—ç»“æŸ
          continue;
        } else if (event.type === 'message_delta') {
          // æ¶ˆæ¯å…ƒæ•°æ®æ›´æ–°
          if (event.usage) {
            usage.outputTokens = event.usage.output_tokens;
          }
        } else if (event.type === 'message_stop') {
          // æ¶ˆæ¯ç»“æŸ
          break;
        }
      }

      // 4. å‘é€ end äº‹ä»¶
      yield {
        type: 'end',
        usage,
        timestamp: Date.now()
      };
    } catch (error) {
      // 5. å‘é€ error äº‹ä»¶
      yield {
        type: 'error',
        error: {
          message: error.message,
          code: error.code
        },
        timestamp: Date.now()
      };
    }
  }
}

/**
 * Google æµå¼é€‚é…å™¨
 */
class GoogleStreamAdapter {
  async *stream(
    model: any,
    request: any
  ): AsyncGenerator<StreamEvent> {
    // 1. å‘é€ start äº‹ä»¶
    yield {
      type: 'start',
      model: model.model,
      timestamp: Date.now()
    };

    // 2. è°ƒç”¨ Google Streaming API
    const result = await model.generateContentStream(request);

    // 3. è½¬æ¢æµå¼å“åº”
    try {
      for await (const chunk of result.stream) {
        const text = chunk.text();
        if (text) {
          yield {
            type: 'delta',
            delta: { content: text }
          };
        }
      }

      // 4. å‘é€ end äº‹ä»¶
      const response = await result.response;
      yield {
        type: 'end',
        usage: {
          inputTokens: response.usageMetadata?.promptTokenCount || 0,
          outputTokens: response.usageMetadata?.candidatesTokenCount || 0,
          totalTokens: response.usageMetadata?.totalTokenCount || 0
        },
        timestamp: Date.now()
      };
    } catch (error) {
      // 5. å‘é€ error äº‹ä»¶
      yield {
        type: 'error',
        error: {
          message: error.message
        },
        timestamp: Date.now()
      };
    }
  }
}
```

### 3. ç»Ÿä¸€æµå¼æ¥å£

```typescript
/**
 * ç»Ÿä¸€æµå¼æ¥å£
 * æä¾›ä¸€è‡´çš„æµå¼è°ƒç”¨ä½“éªŒ
 */
class UnifiedStreamingAPI {
  private adapters = new Map<string, any>();

  constructor() {
    this.adapters.set('openai', new OpenAIStreamAdapter());
    this.adapters.set('anthropic', new AnthropicStreamAdapter());
    this.adapters.set('google', new GoogleStreamAdapter());
  }

  /**
   * æµå¼è°ƒç”¨
   */
  async *stream(
    provider: string,
    model: string,
    context: Context
  ): AsyncGenerator<StreamEvent> {
    const adapter = this.adapters.get(provider);
    if (!adapter) {
      throw new Error(`Provider "${provider}" not supported`);
    }

    // è½¬æ¢ä¸Šä¸‹æ–‡ä¸º Provider æ ¼å¼
    const converter = new MessageConverter();
    let request: any;

    switch (provider) {
      case 'openai':
        request = converter.toOpenAI(context);
        request.model = model;
        const openai = new OpenAI();
        yield* adapter.stream(openai, request);
        break;

      case 'anthropic':
        request = converter.toAnthropic(context);
        request.model = model;
        const anthropic = new Anthropic();
        yield* adapter.stream(anthropic, request);
        break;

      case 'google':
        request = converter.toGoogle(context);
        const genai = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY!);
        const googleModel = genai.getGenerativeModel({ model });
        yield* adapter.stream(googleModel, request);
        break;

      default:
        throw new Error(`Provider "${provider}" not supported`);
    }
  }
}
```

### 4. æµå¼äº‹ä»¶å¤„ç†å™¨

```typescript
/**
 * æµå¼äº‹ä»¶å¤„ç†å™¨
 * æä¾›ä¾¿æ·çš„äº‹ä»¶å¤„ç†æ–¹æ³•
 */
class StreamEventHandler {
  private onStart?: (event: StreamStartEvent) => void;
  private onDelta?: (event: StreamDeltaEvent) => void;
  private onEnd?: (event: StreamEndEvent) => void;
  private onError?: (event: StreamErrorEvent) => void;

  /**
   * æ³¨å†Œ start äº‹ä»¶å¤„ç†å™¨
   */
  start(handler: (event: StreamStartEvent) => void): this {
    this.onStart = handler;
    return this;
  }

  /**
   * æ³¨å†Œ delta äº‹ä»¶å¤„ç†å™¨
   */
  delta(handler: (event: StreamDeltaEvent) => void): this {
    this.onDelta = handler;
    return this;
  }

  /**
   * æ³¨å†Œ end äº‹ä»¶å¤„ç†å™¨
   */
  end(handler: (event: StreamEndEvent) => void): this {
    this.onEnd = handler;
    return this;
  }

  /**
   * æ³¨å†Œ error äº‹ä»¶å¤„ç†å™¨
   */
  error(handler: (event: StreamErrorEvent) => void): this {
    this.onError = handler;
    return this;
  }

  /**
   * å¤„ç†æµå¼äº‹ä»¶
   */
  async handle(stream: AsyncGenerator<StreamEvent>): Promise<void> {
    for await (const event of stream) {
      switch (event.type) {
        case 'start':
          this.onStart?.(event);
          break;
        case 'delta':
          this.onDelta?.(event);
          break;
        case 'end':
          this.onEnd?.(event);
          break;
        case 'error':
          this.onError?.(event);
          break;
      }
    }
  }
}
```

---

## åœ¨ AI Agent ä¸­çš„åº”ç”¨

### åœºæ™¯1ï¼šå®æ—¶æ‰“å­—æœºæ•ˆæœ

```typescript
/**
 * å®æ—¶æ‰“å­—æœºæ•ˆæœ
 * ç±»ä¼¼ ChatGPT çš„é€å­—è¾“å‡º
 */
async function typewriterEffect(
  provider: string,
  model: string,
  userMessage: string
): Promise<void> {
  const api = new UnifiedStreamingAPI();

  const context: Context = {
    systemPrompt: 'You are a helpful assistant.',
    messages: [{ role: 'user', content: userMessage }],
    temperature: 0.7
  };

  // æµå¼è°ƒç”¨
  for await (const event of api.stream(provider, model, context)) {
    if (event.type === 'start') {
      console.log('\nğŸ¤– Assistant: ');
    } else if (event.type === 'delta' && event.delta.content) {
      // é€å­—è¾“å‡ºï¼ˆæ— æ¢è¡Œï¼‰
      process.stdout.write(event.delta.content);
    } else if (event.type === 'end') {
      console.log('\n');
      console.log(`\nğŸ“Š Tokens: ${event.usage.totalTokens}`);
    } else if (event.type === 'error') {
      console.error(`\nâŒ Error: ${event.error.message}`);
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
await typewriterEffect('openai', 'gpt-4o-mini', 'Write a poem about TypeScript');
```

### åœºæ™¯2ï¼šæµå¼å†…å®¹ç´¯ç§¯

```typescript
/**
 * æµå¼å†…å®¹ç´¯ç§¯
 * ç´¯ç§¯å®Œæ•´å“åº”å¹¶å®æ—¶æ˜¾ç¤ºè¿›åº¦
 */
async function accumulateStreamContent(
  provider: string,
  model: string,
  userMessage: string
): Promise<string> {
  const api = new UnifiedStreamingAPI();
  let fullContent = '';
  let tokenCount = 0;

  const context: Context = {
    messages: [{ role: 'user', content: userMessage }]
  };

  for await (const event of api.stream(provider, model, context)) {
    if (event.type === 'delta' && event.delta.content) {
      fullContent += event.delta.content;
      tokenCount++;

      // æ¯ 10 ä¸ª token æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
      if (tokenCount % 10 === 0) {
        process.stdout.write('.');
      }
    } else if (event.type === 'end') {
      console.log(`\nâœ… Complete (${event.usage.totalTokens} tokens)`);
    }
  }

  return fullContent;
}

// ä½¿ç”¨ç¤ºä¾‹
const content = await accumulateStreamContent(
  'anthropic',
  'claude-opus-4',
  'Explain quantum computing'
);
console.log(content);
```

### åœºæ™¯3ï¼šæµå¼å·¥å…·è°ƒç”¨

```typescript
/**
 * æµå¼å·¥å…·è°ƒç”¨
 * åœ¨æµå¼å“åº”ä¸­å¤„ç†å·¥å…·è°ƒç”¨
 */
async function streamingToolCalling(
  userMessage: string
): Promise<void> {
  const api = new UnifiedStreamingAPI();
  const executor = new ToolExecutor();
  executor.register(weatherTool);

  const context: Context = {
    messages: [{ role: 'user', content: userMessage }],
    tools: executor.list()
  };

  // ç´¯ç§¯å·¥å…·è°ƒç”¨ä¿¡æ¯
  const pendingToolCalls = new Map<string, {
    name: string;
    input: string;
  }>();

  for await (const event of api.stream('anthropic', 'claude-opus-4', context)) {
    if (event.type === 'delta') {
      // æ–‡æœ¬å†…å®¹
      if (event.delta.content) {
        process.stdout.write(event.delta.content);
      }

      // å·¥å…·è°ƒç”¨å¢é‡
      if (event.delta.toolCalls) {
        for (const tc of event.delta.toolCalls) {
          if (!pendingToolCalls.has(tc.id!)) {
            pendingToolCalls.set(tc.id!, { name: '', input: '' });
          }
          const pending = pendingToolCalls.get(tc.id!)!;
          if (tc.name) pending.name = tc.name;
          if (tc.input) pending.input += tc.input;
        }
      }
    } else if (event.type === 'end') {
      // æ‰§è¡Œå·¥å…·è°ƒç”¨
      for (const [id, { name, input }] of pendingToolCalls) {
        console.log(`\nğŸ”§ Executing tool: ${name}`);
        const parsedInput = JSON.parse(input);
        const result = await executor.execute(name, parsedInput);
        console.log(`ğŸ“Š Result: ${JSON.stringify(result.result)}`);
      }
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
await streamingToolCalling('What is the weather in Tokyo?');
```

### åœºæ™¯4ï¼šå¤šæµå¹¶è¡Œå¤„ç†

```typescript
/**
 * å¤šæµå¹¶è¡Œå¤„ç†
 * åŒæ—¶å¤„ç†å¤šä¸ªæµå¼å“åº”
 */
async function parallelStreaming(
  queries: string[]
): Promise<string[]> {
  const api = new UnifiedStreamingAPI();
  const results: string[] = [];

  // åˆ›å»ºå¤šä¸ªæµ
  const streams = queries.map((query, index) => ({
    index,
    query,
    stream: api.stream('openai', 'gpt-4o-mini', {
      messages: [{ role: 'user', content: query }]
    })
  }));

  // å¹¶è¡Œå¤„ç†
  await Promise.all(
    streams.map(async ({ index, query, stream }) => {
      let content = '';
      console.log(`\n[${index}] Processing: ${query}`);

      for await (const event of stream) {
        if (event.type === 'delta' && event.delta.content) {
          content += event.delta.content;
        } else if (event.type === 'end') {
          console.log(`[${index}] âœ… Complete`);
        }
      }

      results[index] = content;
    })
  );

  return results;
}

// ä½¿ç”¨ç¤ºä¾‹
const results = await parallelStreaming([
  'What is TypeScript?',
  'What is Node.js?',
  'What is React?'
]);
```

### åœºæ™¯5ï¼šæµå¼äº‹ä»¶ç›‘å¬

```typescript
/**
 * æµå¼äº‹ä»¶ç›‘å¬
 * ä½¿ç”¨äº‹ä»¶å¤„ç†å™¨æ¨¡å¼
 */
async function eventListenerPattern(
  userMessage: string
): Promise<void> {
  const api = new UnifiedStreamingAPI();
  const handler = new StreamEventHandler();

  // æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
  handler
    .start((event) => {
      console.log(`ğŸš€ Stream started (model: ${event.model})`);
    })
    .delta((event) => {
      if (event.delta.content) {
        process.stdout.write(event.delta.content);
      }
    })
    .end((event) => {
      console.log(`\nâœ… Stream ended (${event.usage.totalTokens} tokens)`);
    })
    .error((event) => {
      console.error(`âŒ Error: ${event.error.message}`);
    });

  // åˆ›å»ºæµ
  const stream = api.stream('openai', 'gpt-4o-mini', {
    messages: [{ role: 'user', content: userMessage }]
  });

  // å¤„ç†æµ
  await handler.handle(stream);
}

// ä½¿ç”¨ç¤ºä¾‹
await eventListenerPattern('Explain async/await in JavaScript');
```

---

## è®¾è®¡æƒè¡¡

### ä¼˜ç‚¹

1. **å®æ—¶å“åº”**
   - é€å­—è¾“å‡ºï¼Œæ— éœ€ç­‰å¾…
   - ç”¨æˆ·ä½“éªŒå¥½

2. **é›¶æ‹·è´è½¬å‘**
   - ç›´æ¥è½¬å‘æµå¼æ•°æ®
   - å†…å­˜å ç”¨å°

3. **äº‹ä»¶ç»Ÿä¸€**
   - æ‰€æœ‰ Provider ä½¿ç”¨ç›¸åŒæ ¼å¼
   - ç®€åŒ–ä¸šåŠ¡é€»è¾‘

4. **çµæ´»å¤„ç†**
   - æ”¯æŒäº‹ä»¶ç›‘å¬å™¨
   - æ”¯æŒ AsyncGenerator

### ç¼ºç‚¹

1. **é”™è¯¯å¤„ç†å¤æ‚**
   - æµä¸­æ–­æ—¶éš¾ä»¥æ¢å¤
   - éœ€è¦ä¿ç•™éƒ¨åˆ†å“åº”

2. **è°ƒè¯•å›°éš¾**
   - æµå¼æ•°æ®éš¾ä»¥è®°å½•
   - éœ€è¦ä¸“é—¨çš„è°ƒè¯•å·¥å…·

3. **Token ç»Ÿè®¡ä¸å‡†**
   - æŸäº› Provider æµå¼ä¸è¿”å› usage
   - éœ€è¦ä¼°ç®—æˆ–åç»­æŸ¥è¯¢

---

## å®é™…æ¡ˆä¾‹ï¼ˆ2025-2026ï¼‰

### æ¡ˆä¾‹1ï¼šVercel AI SDK çš„æµå¼æ¶æ„

**èƒŒæ™¯ï¼š** Vercel AI SDK ä½¿ç”¨ ReadableStream å¤„ç†æµå¼å“åº”

**å®ç°ï¼š**
```typescript
import { streamText } from 'ai';

const result = await streamText({
  model: openai('gpt-4o'),
  prompt: 'Write a poem'
});

// ä½¿ç”¨ AsyncGenerator
for await (const textPart of result.textStream) {
  process.stdout.write(textPart);
}

// æˆ–ä½¿ç”¨ ReadableStream
const stream = result.toAIStream();
```

**ç‰¹ç‚¹ï¼š**
- ç»Ÿä¸€çš„æµå¼æ¥å£
- æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼
- é›¶æ‹·è´è½¬å‘

**æ¥æºï¼š** [Vercel AI SDK Streaming](https://sdk.vercel.ai/docs/ai-sdk-core/streaming) (2026-01-20)

---

### æ¡ˆä¾‹2ï¼šLangChain.js çš„æµå¼æ”¯æŒ

**èƒŒæ™¯ï¼š** LangChain.js ä½¿ç”¨äº‹ä»¶é©±åŠ¨å¤„ç†æµå¼å“åº”

**å®ç°ï¼š**
```typescript
import { ChatOpenAI } from '@langchain/openai';

const model = new ChatOpenAI({ streaming: true });

const stream = await model.stream('Write a poem');

for await (const chunk of stream) {
  process.stdout.write(chunk.content);
}
```

**ç‰¹ç‚¹ï¼š**
- ç»Ÿä¸€çš„ stream() æ¥å£
- æ”¯æŒæ‰€æœ‰ Provider
- äº‹ä»¶é©±åŠ¨æ¶æ„

**æ¥æºï¼š** [LangChain.js Streaming](https://js.langchain.com/docs/modules/model_io/models/chat/streaming) (2026-02-10)

---

## å­¦ä¹ æ£€æŸ¥æ¸…å•

å®Œæˆæœ¬æ¦‚å¿µå­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] ç†è§£æµå¼æ¶æ„çš„ä¸‰æ®µå¼äº‹ä»¶æµ
- [ ] ç†è§£ AsyncGenerator çš„ä½¿ç”¨
- [ ] èƒ½å¤Ÿå®ç°æµå¼é€‚é…å™¨
- [ ] èƒ½å¤Ÿå¤„ç†æµå¼äº‹ä»¶
- [ ] èƒ½å¤Ÿå®ç°å®æ—¶æ‰“å­—æœºæ•ˆæœ
- [ ] èƒ½å¤Ÿç´¯ç§¯æµå¼å†…å®¹
- [ ] èƒ½å¤Ÿå¤„ç†æµå¼å·¥å…·è°ƒç”¨
- [ ] èƒ½å¤Ÿå®ç°å¤šæµå¹¶è¡Œå¤„ç†
- [ ] ç†è§£è®¾è®¡æƒè¡¡

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [OpenAI Streaming](https://platform.openai.com/docs/api-reference/streaming) - OpenAI æµå¼ API
- [Anthropic Streaming](https://docs.anthropic.com/claude/reference/streaming) - Anthropic æµå¼ API
- [Google Streaming](https://ai.google.dev/api/rest/v1beta/models/streamGenerateContent) - Google æµå¼ API

### ç›¸å…³é¡¹ç›®
- [Vercel AI SDK](https://sdk.vercel.ai/docs/ai-sdk-core/streaming) - æµå¼æ¶æ„
- [LangChain.js](https://js.langchain.com/docs/modules/model_io/models/chat/streaming) - æµå¼æ”¯æŒ

### æŠ€æœ¯æ–‡ç« 
- [Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) - SSE è§„èŒƒ
- [AsyncGenerator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AsyncGenerator) - JavaScript å¼‚æ­¥ç”Ÿæˆå™¨

---

**ç‰ˆæœ¬ï¼š** v1.0
**æœ€åæ›´æ–°ï¼š** 2026-02-19
