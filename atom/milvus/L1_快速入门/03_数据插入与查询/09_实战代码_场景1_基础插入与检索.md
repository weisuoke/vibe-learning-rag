# 实战代码 - 场景 1: 基础插入与检索

本文档展示 Milvus 数据插入与查询的最基础工作流程，适合初学者理解完整操作步骤。

---

## 场景描述

**目标**: 实现一个最简单的向量数据库工作流程

**流程**:
```
连接 Milvus → 创建 Collection → 插入数据 → 创建索引 → 加载到内存 → 执行检索 → 处理结果
```

**适用场景**:
- 学习 Milvus 基础操作
- 原型验证
- 小规模数据测试（< 1 万条）

---

## 完整代码实现

### 步骤 1: 环境准备

```python
# 安装依赖
# pip install pymilvus numpy

from pymilvus import (
    connections,
    Collection,
    FieldSchema,
    CollectionSchema,
    DataType,
    utility
)
import numpy as np
import time
```

---

### 步骤 2: 连接 Milvus

```python
def connect_to_milvus():
    """
    连接到 Milvus 服务器
    """
    print("=" * 50)
    print("步骤 1: 连接 Milvus")
    print("=" * 50)

    # 连接到本地 Milvus
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    print("✓ 成功连接到 Milvus")
    print()

# 执行连接
connect_to_milvus()
```

**输出**:
```
==================================================
步骤 1: 连接 Milvus
==================================================
✓ 成功连接到 Milvus
```

---

### 步骤 3: 创建 Collection

```python
def create_collection(collection_name="basic_demo"):
    """
    创建一个简单的 Collection
    """
    print("=" * 50)
    print("步骤 2: 创建 Collection")
    print("=" * 50)

    # 如果 Collection 已存在，先删除
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)
        print(f"✓ 删除已存在的 Collection: {collection_name}")

    # 定义 Schema
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500)
    ]

    schema = CollectionSchema(
        fields=fields,
        description="Basic demo collection"
    )

    # 创建 Collection
    collection = Collection(
        name=collection_name,
        schema=schema
    )

    print(f"✓ 成功创建 Collection: {collection_name}")
    print(f"  - 主键字段: id (auto_id=True)")
    print(f"  - 向量字段: embedding (dim=128)")
    print(f"  - 标量字段: text (max_length=500)")
    print()

    return collection

# 创建 Collection
collection = create_collection()
```

**输出**:
```
==================================================
步骤 2: 创建 Collection
==================================================
✓ 删除已存在的 Collection: basic_demo
✓ 成功创建 Collection: basic_demo
  - 主键字段: id (auto_id=True)
  - 向量字段: embedding (dim=128)
  - 标量字段: text (max_length=500)
```

---

### 步骤 4: 准备数据

```python
def prepare_data(num_entities=1000):
    """
    准备测试数据
    """
    print("=" * 50)
    print("步骤 3: 准备数据")
    print("=" * 50)

    # 生成随机向量
    embeddings = np.random.rand(num_entities, 128).tolist()

    # 生成文本数据
    texts = [f"这是第 {i} 条测试数据" for i in range(num_entities)]

    print(f"✓ 生成 {num_entities} 条数据")
    print(f"  - 向量维度: 128")
    print(f"  - 文本示例: {texts[0]}")
    print()

    return embeddings, texts

# 准备数据
embeddings, texts = prepare_data(num_entities=1000)
```

**输出**:
```
==================================================
步骤 3: 准备数据
==================================================
✓ 生成 1000 条数据
  - 向量维度: 128
  - 文本示例: 这是第 0 条测试数据
```

---

### 步骤 5: 批量插入数据

```python
def insert_data(collection, embeddings, texts):
    """
    批量插入数据到 Collection
    """
    print("=" * 50)
    print("步骤 4: 批量插入数据")
    print("=" * 50)

    # 准备插入数据（注意：不包含 id，因为 auto_id=True）
    data = [
        embeddings,  # 向量字段
        texts        # 文本字段
    ]

    # 插入数据
    start_time = time.time()
    result = collection.insert(data)
    insert_time = time.time() - start_time

    print(f"✓ 成功插入 {len(result.primary_keys)} 条数据")
    print(f"  - 耗时: {insert_time:.3f} 秒")
    print(f"  - 自动生成的 ID 范围: {min(result.primary_keys)} - {max(result.primary_keys)}")
    print()

    return result

# 插入数据
insert_result = insert_data(collection, embeddings, texts)
```

**输出**:
```
==================================================
步骤 4: 批量插入数据
==================================================
✓ 成功插入 1000 条数据
  - 耗时: 0.123 秒
  - 自动生成的 ID 范围: 450215437506453504 - 450215437506454503
```

---

### 步骤 6: 刷新数据

```python
def flush_data(collection):
    """
    刷新数据到磁盘
    """
    print("=" * 50)
    print("步骤 5: 刷新数据到磁盘")
    print("=" * 50)

    start_time = time.time()
    collection.flush()
    flush_time = time.time() - start_time

    print(f"✓ 数据已刷新到磁盘")
    print(f"  - 耗时: {flush_time:.3f} 秒")
    print(f"  - Collection 中的实体数量: {collection.num_entities}")
    print()

# 刷新数据
flush_data(collection)
```

**输出**:
```
==================================================
步骤 5: 刷新数据到磁盘
==================================================
✓ 数据已刷新到磁盘
  - 耗时: 0.056 秒
  - Collection 中的实体数量: 1000
```

---

### 步骤 7: 创建索引

```python
def create_index(collection):
    """
    创建 HNSW 索引
    """
    print("=" * 50)
    print("步骤 6: 创建索引")
    print("=" * 50)

    # 定义索引参数
    index_params = {
        "index_type": "HNSW",
        "metric_type": "COSINE",
        "params": {
            "M": 16,
            "efConstruction": 256
        }
    }

    print("索引配置:")
    print(f"  - 索引类型: HNSW")
    print(f"  - 相似度度量: COSINE")
    print(f"  - M: 16")
    print(f"  - efConstruction: 256")
    print()

    # 创建索引
    start_time = time.time()
    collection.create_index(
        field_name="embedding",
        index_params=index_params
    )
    index_time = time.time() - start_time

    print(f"✓ 索引创建完成")
    print(f"  - 耗时: {index_time:.3f} 秒")
    print()

# 创建索引
create_index(collection)
```

**输出**:
```
==================================================
步骤 6: 创建索引
==================================================
索引配置:
  - 索引类型: HNSW
  - 相似度度量: COSINE
  - M: 16
  - efConstruction: 256

✓ 索引创建完成
  - 耗时: 0.234 秒
```

---

### 步骤 8: 加载到内存

```python
def load_collection(collection):
    """
    加载 Collection 到内存
    """
    print("=" * 50)
    print("步骤 7: 加载 Collection 到内存")
    print("=" * 50)

    start_time = time.time()
    collection.load()
    load_time = time.time() - start_time

    print(f"✓ Collection 已加载到内存")
    print(f"  - 耗时: {load_time:.3f} 秒")
    print(f"  - 状态: 可以开始检索")
    print()

# 加载 Collection
load_collection(collection)
```

**输出**:
```
==================================================
步骤 7: 加载 Collection 到内存
==================================================
✓ Collection 已加载到内存
  - 耗时: 0.089 秒
  - 状态: 可以开始检索
```

---

### 步骤 9: 执行检索

```python
def search_vectors(collection, num_queries=3, top_k=5):
    """
    执行向量相似度检索
    """
    print("=" * 50)
    print("步骤 8: 执行相似度检索")
    print("=" * 50)

    # 生成查询向量
    query_vectors = np.random.rand(num_queries, 128).tolist()

    # 定义检索参数
    search_params = {
        "metric_type": "COSINE",
        "params": {"ef": 64}
    }

    print(f"检索配置:")
    print(f"  - 查询数量: {num_queries}")
    print(f"  - Top-K: {top_k}")
    print(f"  - 相似度度量: COSINE")
    print(f"  - ef: 64")
    print()

    # 执行检索
    start_time = time.time()
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["text"]
    )
    search_time = time.time() - start_time

    print(f"✓ 检索完成")
    print(f"  - 耗时: {search_time:.3f} 秒")
    print(f"  - 平均每次查询: {search_time / num_queries * 1000:.2f} 毫秒")
    print()

    return results

# 执行检索
search_results = search_vectors(collection, num_queries=3, top_k=5)
```

**输出**:
```
==================================================
步骤 8: 执行相似度检索
==================================================
检索配置:
  - 查询数量: 3
  - Top-K: 5
  - 相似度度量: COSINE
  - ef: 64

✓ 检索完成
  - 耗时: 0.012 秒
  - 平均每次查询: 4.00 毫秒
```

---

### 步骤 10: 处理结果

```python
def process_results(results):
    """
    处理并展示检索结果
    """
    print("=" * 50)
    print("步骤 9: 处理检索结果")
    print("=" * 50)

    for i, query_result in enumerate(results):
        print(f"\n查询 {i + 1} 的结果 (Top-5):")
        print("-" * 50)

        for j, hit in enumerate(query_result):
            print(f"  {j + 1}. ID: {hit.id}")
            print(f"     相似度: {hit.score:.4f}")
            print(f"     文本: {hit.entity.get('text')}")
            print()

# 处理结果
process_results(search_results)
```

**输出**:
```
==================================================
步骤 9: 处理检索结果
==================================================

查询 1 的结果 (Top-5):
--------------------------------------------------
  1. ID: 450215437506453789
     相似度: 0.8234
     文本: 这是第 285 条测试数据

  2. ID: 450215437506453612
     相似度: 0.8102
     文本: 这是第 108 条测试数据

  3. ID: 450215437506454123
     相似度: 0.7998
     文本: 这是第 619 条测试数据

  4. ID: 450215437506453890
     相似度: 0.7876
     文本: 这是第 386 条测试数据

  5. ID: 450215437506454234
     相似度: 0.7765
     文本: 这是第 730 条测试数据

查询 2 的结果 (Top-5):
--------------------------------------------------
  ...
```

---

### 步骤 11: 清理资源

```python
def cleanup(collection):
    """
    清理资源
    """
    print("=" * 50)
    print("步骤 10: 清理资源")
    print("=" * 50)

    # 释放 Collection
    collection.release()
    print("✓ Collection 已从内存释放")

    # 可选：删除 Collection
    # utility.drop_collection(collection.name)
    # print(f"✓ Collection {collection.name} 已删除")

    print()

# 清理资源
cleanup(collection)
```

**输出**:
```
==================================================
步骤 10: 清理资源
==================================================
✓ Collection 已从内存释放
```

---

## 完整代码（一体化版本）

```python
"""
Milvus 基础插入与检索 - 完整示例
"""

from pymilvus import (
    connections,
    Collection,
    FieldSchema,
    CollectionSchema,
    DataType,
    utility
)
import numpy as np
import time


def main():
    """
    主函数：完整的 Milvus 工作流程
    """
    collection_name = "basic_demo"

    # 1. 连接 Milvus
    print("=" * 50)
    print("步骤 1: 连接 Milvus")
    print("=" * 50)
    connections.connect(alias="default", host="localhost", port="19530")
    print("✓ 成功连接到 Milvus\n")

    # 2. 创建 Collection
    print("=" * 50)
    print("步骤 2: 创建 Collection")
    print("=" * 50)
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)

    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500)
    ]
    schema = CollectionSchema(fields, description="Basic demo collection")
    collection = Collection(collection_name, schema)
    print(f"✓ 成功创建 Collection: {collection_name}\n")

    # 3. 准备数据
    print("=" * 50)
    print("步骤 3: 准备数据")
    print("=" * 50)
    num_entities = 1000
    embeddings = np.random.rand(num_entities, 128).tolist()
    texts = [f"这是第 {i} 条测试数据" for i in range(num_entities)]
    print(f"✓ 生成 {num_entities} 条数据\n")

    # 4. 插入数据
    print("=" * 50)
    print("步骤 4: 批量插入数据")
    print("=" * 50)
    data = [embeddings, texts]
    start = time.time()
    result = collection.insert(data)
    print(f"✓ 成功插入 {len(result.primary_keys)} 条数据")
    print(f"  - 耗时: {time.time() - start:.3f} 秒\n")

    # 5. 刷新数据
    print("=" * 50)
    print("步骤 5: 刷新数据到磁盘")
    print("=" * 50)
    collection.flush()
    print(f"✓ 数据已刷新，实体数量: {collection.num_entities}\n")

    # 6. 创建索引
    print("=" * 50)
    print("步骤 6: 创建索引")
    print("=" * 50)
    index_params = {
        "index_type": "HNSW",
        "metric_type": "COSINE",
        "params": {"M": 16, "efConstruction": 256}
    }
    start = time.time()
    collection.create_index("embedding", index_params)
    print(f"✓ 索引创建完成，耗时: {time.time() - start:.3f} 秒\n")

    # 7. 加载到内存
    print("=" * 50)
    print("步骤 7: 加载 Collection 到内存")
    print("=" * 50)
    collection.load()
    print("✓ Collection 已加载到内存\n")

    # 8. 执行检索
    print("=" * 50)
    print("步骤 8: 执行相似度检索")
    print("=" * 50)
    query_vectors = np.random.rand(3, 128).tolist()
    search_params = {"metric_type": "COSINE", "params": {"ef": 64}}
    start = time.time()
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param=search_params,
        limit=5,
        output_fields=["text"]
    )
    print(f"✓ 检索完成，耗时: {time.time() - start:.3f} 秒\n")

    # 9. 处理结果
    print("=" * 50)
    print("步骤 9: 处理检索结果")
    print("=" * 50)
    for i, query_result in enumerate(results):
        print(f"\n查询 {i + 1} 的结果 (Top-5):")
        for j, hit in enumerate(query_result):
            print(f"  {j + 1}. 相似度: {hit.score:.4f}, 文本: {hit.entity.get('text')}")
    print()

    # 10. 清理资源
    print("=" * 50)
    print("步骤 10: 清理资源")
    print("=" * 50)
    collection.release()
    print("✓ Collection 已从内存释放\n")

    print("=" * 50)
    print("完成！所有步骤执行成功")
    print("=" * 50)


if __name__ == "__main__":
    main()
```

---

## 关键要点总结

### 1. 完整流程

```
连接 → 创建 → 插入 → 刷新 → 索引 → 加载 → 检索 → 清理
```

### 2. 必须步骤

- **flush()**: 插入后必须刷新
- **create_index()**: 必须创建索引
- **load()**: 必须加载到内存

### 3. 性能数据

| 操作 | 1000 条数据耗时 |
|------|----------------|
| 插入 | 0.1-0.2 秒 |
| 刷新 | 0.05-0.1 秒 |
| 创建索引 | 0.2-0.5 秒 |
| 加载 | 0.05-0.1 秒 |
| 检索 | 3-5 毫秒/次 |

### 4. 常见错误

- 忘记 flush()
- 忘记 create_index()
- 忘记 load()
- 维度不匹配

---

## 下一步

学习 **实战代码 - 场景 2: 批量插入与索引优化**，了解大规模数据的性能优化技巧。
