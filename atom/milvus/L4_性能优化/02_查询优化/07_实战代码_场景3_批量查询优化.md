# 实战代码 - 场景3：批量查询优化实战

本场景演示如何通过批量查询来大幅提升系统吞吐量。

---

## 场景描述

**背景：** 一个批量文档处理系统，需要为100个问题找到相关文档。逐个查询耗时太长，需要优化。

**目标：**
1. 对比逐个查询和批量查询的性能
2. 测试不同批量大小的影响
3. 实现批量RAG查询系统

---

## 完整代码

```python
"""
批量查询优化实战
演示：通过批量查询提升系统吞吐量
"""

import time
import numpy as np
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from typing import List
import os
from dotenv import load_dotenv

load_dotenv()

# ===== 1. 连接和准备 =====
print("=== 连接 Milvus ===")
connections.connect("default", host=os.getenv("MILVUS_HOST", "localhost"), port="19530")
print("✓ 连接成功")

collection_name = "batch_query_test"
if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)

# 创建collection
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
    FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=500),
]
schema = CollectionSchema(fields=fields)
collection = Collection(name=collection_name, schema=schema)

# 插入数据
print("\n=== 插入测试数据 ===")
num_entities = 100000
batch_size = 10000
for i in range(0, num_entities, batch_size):
    entities = [
        np.random.rand(batch_size, 768).tolist(),
        [f"Content {j}" for j in range(i, i + batch_size)],
    ]
    collection.insert(entities)
    print(f"  已插入 {i + batch_size}/{num_entities} 条")

# 创建索引
collection.create_index("embedding", {"index_type": "IVF_FLAT", "metric_type": "L2", "params": {"nlist": 1024}})
collection.load()
print("✓ 准备完成")

# ===== 2. 测试1：逐个查询 vs 批量查询 =====
print("\n=== 测试1：逐个查询 vs 批量查询 ===")

num_queries = 100
query_vectors = [np.random.rand(768).tolist() for _ in range(num_queries)]

# 逐个查询
print(f"\n逐个查询（{num_queries}个）:")
start = time.time()
for query_vector in query_vectors:
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
time_sequential = time.time() - start
qps_sequential = num_queries / time_sequential

print(f"  总延迟: {time_sequential*1000:.2f}ms")
print(f"  平均延迟: {time_sequential*1000/num_queries:.2f}ms")
print(f"  吞吐量: {qps_sequential:.1f} QPS")

# 批量查询
print(f"\n批量查询（{num_queries}个）:")
start = time.time()
results = collection.search(
    data=query_vectors,
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)
time_batch = time.time() - start
qps_batch = num_queries / time_batch

print(f"  总延迟: {time_batch*1000:.2f}ms")
print(f"  平均延迟: {time_batch*1000/num_queries:.2f}ms")
print(f"  吞吐量: {qps_batch:.1f} QPS")

print(f"\n性能提升:")
print(f"  总延迟降低: {time_sequential/time_batch:.1f}x")
print(f"  吞吐量提升: {qps_batch/qps_sequential:.1f}x")

# ===== 3. 测试2：不同批量大小 =====
print("\n=== 测试2：不同批量大小的性能 ===")
print("批量大小 | 总延迟(ms) | 单次延迟(ms) | 吞吐量(QPS)")
print("---------|------------|--------------|------------")

batch_sizes = [1, 5, 10, 20, 50, 100, 200]
for batch_size in batch_sizes:
    query_vecs = [np.random.rand(768).tolist() for _ in range(batch_size)]

    start = time.time()
    results = collection.search(
        data=query_vecs,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
    elapsed = time.time() - start

    avg_latency = elapsed / batch_size
    qps = batch_size / elapsed

    print(f"{batch_size:8d} | {elapsed*1000:10.2f} | {avg_latency*1000:12.2f} | {qps:11.1f}")

print("\n结论：")
print("- 批量大小增加，总延迟增加，但单次延迟降低")
print("- 吞吐量随批量大小增加而提升")
print("- 批量大小=100时，吞吐量达到最优")

# ===== 4. 实战：批量RAG查询 =====
print("\n=== 实战：批量RAG查询系统 ===")

def batch_rag_search(questions: List[str]) -> List[List]:
    """批量RAG搜索"""
    # 模拟：生成查询向量（实际应使用embedding模型）
    query_vectors = [np.random.rand(768).tolist() for _ in questions]

    # 批量检索
    start = time.time()
    results = collection.search(
        data=query_vectors,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=5,
        output_fields=["content"]
    )
    elapsed = time.time() - start

    return results, elapsed

# 测试批量RAG
questions = [f"Question {i}" for i in range(50)]
print(f"\n处理 {len(questions)} 个问题:")

results, elapsed = batch_rag_search(questions)
print(f"  总延迟: {elapsed*1000:.2f}ms")
print(f"  平均延迟: {elapsed*1000/len(questions):.2f}ms/问题")
print(f"  吞吐量: {len(questions)/elapsed:.1f} 问题/秒")

# ===== 5. 动态批量处理器 =====
print("\n=== 动态批量处理器 ===")

class BatchProcessor:
    """动态批量处理器"""
    def __init__(self, collection, batch_size=10, timeout=0.1):
        self.collection = collection
        self.batch_size = batch_size
        self.timeout = timeout
        self.buffer = []
        self.last_flush = time.time()

    def add(self, query_vector: List[float]):
        """添加查询到缓冲区"""
        self.buffer.append(query_vector)

        # 达到批量大小或超时，立即执行
        if len(self.buffer) >= self.batch_size or time.time() - self.last_flush > self.timeout:
            return self.flush()
        return None

    def flush(self):
        """执行批量查询"""
        if not self.buffer:
            return []

        results = self.collection.search(
            data=self.buffer,
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 16}},
            limit=10
        )

        self.buffer = []
        self.last_flush = time.time()
        return results

# 测试动态批量处理
processor = BatchProcessor(collection, batch_size=10, timeout=0.1)
print("测试动态批量处理（batch_size=10）:")

processed_count = 0
for i in range(25):
    query_vec = np.random.rand(768).tolist()
    results = processor.add(query_vec)
    if results:
        processed_count += len(results)
        print(f"  批量处理完成，已处理 {processed_count} 个查询")

# 处理剩余
remaining = processor.flush()
if remaining:
    processed_count += len(remaining)
    print(f"  最后批量处理完成，总共处理 {processed_count} 个查询")

# ===== 6. 性能对比总结 =====
print("\n=== 性能对比总结 ===")

# 测试不同场景
scenarios = [
    ("实时查询", 1),
    ("小批量", 10),
    ("中批量", 50),
    ("大批量", 100),
]

print("场景     | 批量大小 | 吞吐量(QPS) | 适用场景")
print("---------|----------|-------------|----------")

for name, batch_size in scenarios:
    query_vecs = [np.random.rand(768).tolist() for _ in range(batch_size)]
    start = time.time()
    results = collection.search(
        data=query_vecs,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 16}},
        limit=10
    )
    elapsed = time.time() - start
    qps = batch_size / elapsed

    if name == "实时查询":
        use_case = "聊天机器人"
    elif name == "小批量":
        use_case = "在线推荐"
    elif name == "中批量":
        use_case = "批量问答"
    else:
        use_case = "离线分析"

    print(f"{name:8s} | {batch_size:8d} | {qps:11.1f} | {use_case}")

# ===== 7. 最佳实践 =====
print("\n=== 最佳实践总结 ===")
print("""
1. **批量大小选择：**
   - 实时查询（低延迟）：1-10
   - 在线服务（平衡）：10-50
   - 离线处理（高吞吐）：50-200

2. **动态批量处理：**
   - 使用缓冲区收集查询
   - 达到批量大小或超时时执行
   - 适合流式处理场景

3. **性能提升：**
   - 批量查询可提升吞吐量 10-25 倍
   - 减少网络往返次数（100次 → 1次）
   - 利用并行计算（GPU加速）

4. **注意事项：**
   - 批量大小不宜过大（避免OOM）
   - 单次延迟会略有增加
   - 需要权衡延迟和吞吐量
""")

# ===== 8. 清理 =====
print("\n=== 清理资源 ===")
collection.release()
utility.drop_collection(collection_name)
print("✓ 清理完成")
```

---

## 运行输出示例

```
=== 连接 Milvus ===
✓ 连接成功

=== 插入测试数据 ===
  已插入 10000/100000 条
  ...
✓ 准备完成

=== 测试1：逐个查询 vs 批量查询 ===

逐个查询（100个）:
  总延迟: 5000.00ms
  平均延迟: 50.00ms
  吞吐量: 20.0 QPS

批量查询（100个）:
  总延迟: 200.00ms
  平均延迟: 2.00ms
  吞吐量: 500.0 QPS

性能提升:
  总延迟降低: 25.0x
  吞吐量提升: 25.0x

=== 测试2：不同批量大小的性能 ===
批量大小 | 总延迟(ms) | 单次延迟(ms) | 吞吐量(QPS)
---------|------------|--------------|------------
       1 |      50.00 |        50.00 |        20.0
       5 |      70.00 |        14.00 |        71.4
      10 |      80.00 |         8.00 |       125.0
      20 |     100.00 |         5.00 |       200.0
      50 |     150.00 |         3.00 |       333.3
     100 |     200.00 |         2.00 |       500.0
     200 |     350.00 |         1.75 |       571.4

结论：
- 批量大小增加，总延迟增加，但单次延迟降低
- 吞吐量随批量大小增加而提升
- 批量大小=100时，吞吐量达到最优

=== 实战：批量RAG查询系统 ===

处理 50 个问题:
  总延迟: 150.00ms
  平均延迟: 3.00ms/问题
  吞吐量: 333.3 问题/秒

=== 动态批量处理器 ===
测试动态批量处理（batch_size=10）:
  批量处理完成，已处理 10 个查询
  批量处理完成，已处理 20 个查询
  最后批量处理完成，总共处理 25 个查询

=== 性能对比总结 ===
场景     | 批量大小 | 吞吐量(QPS) | 适用场景
---------|----------|-------------|----------
实时查询 |        1 |        20.0 | 聊天机器人
小批量   |       10 |       125.0 | 在线推荐
中批量   |       50 |       333.3 | 批量问答
大批量   |      100 |       500.0 | 离线分析

=== 最佳实践总结 ===
...

=== 清理资源 ===
✓ 清理完成
```

---

## 关键要点

### 1. 批量查询的优势

**减少网络往返：**
- 逐个查询：100次往返
- 批量查询：1次往返
- 网络开销减少99%

**利用并行计算：**
- CPU/GPU并行处理多个向量
- 计算效率提升5-10倍

**减少固定开销：**
- 连接、序列化、验证等只执行1次

### 2. 批量大小选择

| 场景 | 批量大小 | 特点 |
|-----|---------|------|
| 实时查询 | 1-10 | 低延迟 |
| 在线服务 | 10-50 | 平衡 |
| 离线处理 | 50-200 | 高吞吐 |

### 3. 性能提升

- 总延迟降低：10-25倍
- 吞吐量提升：10-25倍
- 成本降低：90%+

---

## 扩展练习

1. **测试异步批量查询**
2. **实现自适应批量大小**
3. **测试批量查询+标量过滤**
4. **实现批量查询的超时控制**
