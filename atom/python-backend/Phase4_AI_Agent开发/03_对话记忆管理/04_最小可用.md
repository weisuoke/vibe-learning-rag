# 最小可用知识

掌握以下内容，就能开始使用对话记忆管理：

---

## 4.1 理解记忆管理的本质

**对话记忆 = 存储历史 + 注入上下文**

```python
# 最简单的记忆管理流程
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()

# 1. 保存对话
memory.save_context({"input": "我叫张三"}, {"output": "你好，张三！"})

# 2. 加载历史
history = memory.load_memory_variables({})

# 3. 注入到 Prompt
# history["history"] 就是要传给 LLM 的上下文
```

**这就是记忆管理的全部核心！**

---

## 4.2 选择合适的记忆类型

**三种基础记忆类型：**

| 记忆类型 | 何时使用 | 代码 |
|---------|---------|------|
| **ConversationBufferMemory** | 短对话（< 10轮） | `ConversationBufferMemory()` |
| **ConversationBufferWindowMemory** | 中等对话（10-30轮） | `ConversationBufferWindowMemory(k=5)` |
| **持久化存储** | 需要跨会话保存 | 自定义 PostgreSQL/Redis |

**80%的场景用 ConversationBufferWindowMemory 就够了。**

```python
from langchain.memory import ConversationBufferWindowMemory

# 保留最近5轮对话
memory = ConversationBufferWindowMemory(k=5)
```

---

## 4.3 在 LangChain 中使用记忆

**最简单的方式：ConversationChain**

```python
from langchain.memory import ConversationBufferWindowMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain

# 1. 创建记忆
memory = ConversationBufferWindowMemory(k=5)

# 2. 创建对话链
llm = ChatOpenAI(temperature=0.7)
conversation = ConversationChain(
    llm=llm,
    memory=memory
)

# 3. 对话（自动管理记忆）
response1 = conversation.predict(input="我叫张三")
response2 = conversation.predict(input="我叫什么名字？")
# "你叫张三。" ✅
```

**就这么简单！LangChain 会自动处理记忆的保存和加载。**

---

## 4.4 在 FastAPI 中集成记忆

**核心：为每个用户维护独立的记忆**

```python
from fastapi import FastAPI
from pydantic import BaseModel
from langchain.memory import ConversationBufferWindowMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from typing import Dict

app = FastAPI()

# 存储每个用户的记忆
user_memories: Dict[str, ConversationBufferWindowMemory] = {}

class ChatRequest(BaseModel):
    user_id: str
    message: str

@app.post("/chat")
async def chat(request: ChatRequest):
    # 1. 获取或创建用户的记忆
    if request.user_id not in user_memories:
        user_memories[request.user_id] = ConversationBufferWindowMemory(k=5)

    memory = user_memories[request.user_id]

    # 2. 创建对话链
    llm = ChatOpenAI(temperature=0.7)
    conversation = ConversationChain(llm=llm, memory=memory)

    # 3. 生成回复
    response = conversation.predict(input=request.message)

    return {"response": response}
```

**这就是一个完整的多用户对话 API！**

---

## 4.5 控制 Token 消耗

**核心：限制历史长度**

```python
from langchain.memory import ConversationBufferWindowMemory

# 方式1：使用窗口记忆（推荐）
memory = ConversationBufferWindowMemory(k=5)  # 只保留最近5轮

# 方式2：手动清理
memory = ConversationBufferMemory()
if len(memory.chat_memory.messages) > 20:
    memory.clear()  # 清空历史

# 方式3：监控 Token 使用
import tiktoken

def count_tokens(text: str) -> int:
    encoding = tiktoken.encoding_for_model("gpt-4")
    return len(encoding.encode(text))

history = memory.load_memory_variables({})
token_count = count_tokens(history["history"])

if token_count > 2000:
    print("警告：Token 使用过多")
```

---

## 这些知识足以：

- ✅ 实现基础的多轮对话
- ✅ 在 FastAPI 中集成对话记忆
- ✅ 为不同用户维护独立记忆
- ✅ 控制 Token 消耗
- ✅ 开始构建简单的 AI Agent

---

## 快速参考卡

```python
# 1. 创建记忆
from langchain.memory import ConversationBufferWindowMemory
memory = ConversationBufferWindowMemory(k=5)

# 2. 创建对话链
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
conversation = ConversationChain(
    llm=ChatOpenAI(),
    memory=memory
)

# 3. 对话
response = conversation.predict(input="你好")

# 4. 查看历史
history = memory.load_memory_variables({})
print(history["history"])

# 5. 清空历史
memory.clear()
```

---

## 下一步学习

掌握了最小可用知识后，可以深入学习：

1. **持久化存储** - 使用 PostgreSQL 或 Redis 存储记忆
2. **ConversationSummaryMemory** - 总结历史以节省 Token
3. **自定义记忆类** - 实现特定业务逻辑的记忆管理
4. **记忆优化策略** - 智能清理、压缩、检索

但对于大多数场景，上面的知识已经足够了！
