# 面试必问：Prompt Engineering进阶

## 概念理解题

### Q1: 解释Few-shot Learning的工作原理

**答案:**

Few-shot Learning通过上下文学习(In-Context Learning)工作:

1. **原理**: 大模型在预训练时见过大量"示例→任务"的模式,学会了从示例中推断任务规则
2. **机制**: 在推理时,模型观察提供的2-5个示例,识别输入输出模式,然后应用到新输入
3. **关键**: 示例质量>数量,相关的3个示例优于不相关的10个

**代码示例:**
```python
prompt = """
示例1: 输入:这个产品很好 → 输出:正面
示例2: 输入:质量太差 → 输出:负面
现在: 输入:还不错 → 输出:
"""
# 模型从示例中学会了情感分类任务
```

**来源:** [GPT-3 Paper (2020)](https://arxiv.org/abs/2005.14165)

---

### Q2: Chain-of-Thought与直接回答的本质区别是什么?

**答案:**

**本质区别: 推理过程的可见性**

| 维度 | 直接回答 | CoT |
|------|---------|-----|
| 推理过程 | 黑盒,不可见 | 白盒,逐步展示 |
| 可验证性 | 无法验证 | 每步可验证 |
| 错误定位 | 困难 | 容易 |
| 准确率 | 较低 | 显著提升 |

**实验数据:**
- 数学推理: 17.7% → 40.7% (+130%)
- 常识推理: 69.0% → 79.0% (+14%)

**关键洞察:** CoT将隐式推理外化为显式步骤,每个正确步骤作为"锚点"引导后续推理。

**来源:** [Chain-of-Thought Prompting (2022)](https://arxiv.org/abs/2201.11903)

---

### Q3: Self-Consistency为什么能提升准确率?

**答案:**

**数学原理:**

假设单次准确率为p,n次投票后准确率为:
```
P(n) = 1 - (1-p)^n

例如: p=0.7, n=5
P(5) = 1 - (1-0.7)^5 = 99.76%
```

**实际原因:**
1. **多样性**: 不同推理路径可能得到相同正确答案
2. **投票机制**: 正确答案出现频率更高
3. **错误分散**: 错误答案通常不一致

**最佳实践:**
- n=3-5: 性价比最高
- temperature=0.7: 保持适度多样性
- 收益递减: n>7后提升有限

**来源:** [Self-Consistency Paper (2022)](https://arxiv.org/abs/2203.11171)

---

### Q4: Tree of Thoughts与Chain-of-Thought的核心差异?

**答案:**

**结构差异:**

```
CoT (线性):
问题 → 步骤1 → 步骤2 → 步骤3 → 答案
       (一条路径,无法回溯)

ToT (树形):
问题 → 思路A → 结果A
    → 思路B → 结果B ✓ (最优)
    → 思路C → 结果C
       (多条路径,可比较选择)
```

**适用场景:**
- CoT: 线性推理任务(数学计算、逻辑推理)
- ToT: 需要探索的任务(创意写作、策略规划、24点游戏)

**性能对比:**
- 24点游戏: CoT 4% vs ToT 74% (+1750%)
- 创意写作: CoT 12% vs ToT 56% (+367%)

**来源:** [Tree of Thoughts (2023)](https://arxiv.org/abs/2305.10601)

---

### Q5: ReAct与静态RAG的本质区别?

**答案:**

**核心区别: 动态vs静态**

```
静态RAG:
查询 → 检索(一次) → 生成 → 答案
      (无法调整)

ReAct:
查询 → 检索1 → 推理1 → 需要更多信息
              ↓
         检索2 → 推理2 → 信息充足 → 答案
              (动态调整)
```

**关键特征:**
1. **推理驱动**: 根据推理结果决定是否继续检索
2. **自我纠错**: 发现信息不足时可以补充
3. **工具调用**: 可以调用多种工具(搜索、计算、API)

**适用场景:**
- 静态RAG: 简单问答,信息充分
- ReAct: 多跳问答,需要多次信息补充

**来源:** [ReAct Paper (2022)](https://arxiv.org/abs/2210.03629)

---

## 实践应用题

### Q6: 如何为RAG系统选择合适的进阶技术?

**答案:**

**决策树:**

```
任务复杂度?
├─ 简单(事实查询)
│  └─ Few-shot + Structured Output
│
├─ 中等(需要推理)
│  └─ CoT + Query Decomposition
│
└─ 复杂(多步推理)
   ├─ 需要高可靠性? → Self-Consistency + CoT
   ├─ 需要探索多种策略? → Tree of Thoughts
   └─ 需要动态调整? → ReAct 或 RAT
```

**成本vs效果权衡:**

| 技术 | 成本 | 效果提升 | 适用场景 |
|------|------|---------|---------|
| Few-shot | 低 | +20% | 格式引导 |
| CoT | 中 | +30% | 推理任务 |
| Self-Consistency | 高 | +40% | 关键任务 |
| Query Decomposition | 中 | +35% | 复杂查询 |
| RAT | 很高 | +50% | 多跳问答 |

**推荐组合:**
- 基础RAG: Few-shot + CoT
- 生产RAG: CoT + Query Decomposition + Structured Output
- 高端RAG: RAT + Self-Consistency

---

### Q7: 实现一个支持多种进阶技术的RAG系统

**答案:**

```python
from typing import List, Dict, Optional
from openai import OpenAI
import chromadb

class AdvancedRAG:
    """支持多种进阶技术的RAG系统"""
    
    def __init__(self, client: OpenAI, collection):
        self.client = client
        self.collection = collection
    
    def query(
        self,
        query: str,
        techniques: List[str] = ["cot"],
        **kwargs
    ) -> Dict:
        """
        查询接口
        
        techniques可选:
        - "few-shot": Few-shot Learning
        - "cot": Chain-of-Thought
        - "self-consistency": Self-Consistency
        - "query-decomposition": Query Decomposition
        - "rat": Retrieval Augmented Thoughts
        """
        if "query-decomposition" in techniques:
            return self._query_decomposition(query, techniques, **kwargs)
        elif "rat" in techniques:
            return self._rat(query, **kwargs)
        elif "self-consistency" in techniques:
            return self._self_consistency(query, techniques, **kwargs)
        else:
            return self._basic_rag(query, techniques, **kwargs)
    
    def _basic_rag(
        self,
        query: str,
        techniques: List[str],
        top_k: int = 3
    ) -> Dict:
        """基础RAG"""
        # 检索
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )
        docs = results['documents'][0]
        
        # 构建提示词
        prompt = self._build_prompt(query, docs, techniques)
        
        # 生成
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return {
            "query": query,
            "docs": docs,
            "answer": response.choices[0].message.content
        }
    
    def _build_prompt(
        self,
        query: str,
        docs: List[str],
        techniques: List[str]
    ) -> str:
        """根据技术构建提示词"""
        prompt = f"文档:\n{chr(10).join(f'{i+1}. {d}' for i, d in enumerate(docs))}\n\n"
        prompt += f"问题:{query}\n\n"
        
        if "few-shot" in techniques:
            prompt = self._add_few_shot(prompt)
        
        if "cot" in techniques:
            prompt += "让我们一步步分析:\n"
        
        return prompt
    
    def _add_few_shot(self, prompt: str) -> str:
        """添加Few-shot示例"""
        examples = """
示例:
文档:Python由Guido创建于1991年
问题:Python是什么时候创建的?
答案:1991年

"""
        return examples + prompt
    
    def _self_consistency(
        self,
        query: str,
        techniques: List[str],
        n: int = 5
    ) -> Dict:
        """Self-Consistency"""
        answers = []
        for _ in range(n):
            result = self._basic_rag(query, techniques)
            answers.append(result['answer'])
        
        # 投票
        from collections import Counter
        final_answer = Counter(answers).most_common(1)[0][0]
        
        return {
            "query": query,
            "all_answers": answers,
            "final_answer": final_answer
        }
    
    def _query_decomposition(
        self,
        query: str,
        techniques: List[str],
        **kwargs
    ) -> Dict:
        """Query Decomposition"""
        # 拆分查询
        sub_queries = self._decompose(query)
        
        # 分别检索
        all_docs = []
        for sq in sub_queries:
            results = self.collection.query(
                query_texts=[sq],
                n_results=2
            )
            all_docs.extend(results['documents'][0])
        
        # 去重
        unique_docs = list(set(all_docs))
        
        # 综合答案
        prompt = f"""
文档:{chr(10).join(f'{i+1}. {d}' for i, d in enumerate(unique_docs))}

问题:{query}

请综合以上信息回答:
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return {
            "query": query,
            "sub_queries": sub_queries,
            "docs": unique_docs,
            "answer": response.choices[0].message.content
        }
    
    def _decompose(self, query: str) -> List[str]:
        """拆分查询"""
        prompt = f"将查询拆分为子查询:\n{query}\n子查询:"
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        # 简化实现
        return [query]  # 实际应解析response
    
    def _rat(
        self,
        query: str,
        max_iterations: int = 3
    ) -> Dict:
        """RAT"""
        context = []
        
        for i in range(max_iterations):
            # 检索
            results = self.collection.query(
                query_texts=[query],
                n_results=2
            )
            new_docs = results['documents'][0]
            context.extend(new_docs)
            
            # 推理
            thought_prompt = f"""
当前信息:{' | '.join(context)}
问题:{query}

信息是否充分?如果不够,还需要什么?
"""
            thought = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": thought_prompt}]
            ).choices[0].message.content
            
            if "充分" in thought or "足够" in thought:
                break
        
        # 最终答案
        final_prompt = f"完整信息:{' | '.join(context)}\n问题:{query}\n答案:"
        answer = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": final_prompt}]
        ).choices[0].message.content
        
        return {
            "query": query,
            "iterations": i + 1,
            "context": context,
            "answer": answer
        }


# 使用示例
if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    client = OpenAI()
    chroma_client = chromadb.Client()
    collection = chroma_client.create_collection("docs")
    
    # 添加文档
    docs = [
        "Python由Guido van Rossum于1991年创建",
        "JavaScript由Brendan Eich于1995年创建"
    ]
    collection.add(documents=docs, ids=[f"doc{i}" for i in range(len(docs))])
    
    rag = AdvancedRAG(client, collection)
    
    # 测试不同技术
    print("=== 基础RAG + CoT ===")
    result1 = rag.query("Python是什么时候创建的?", techniques=["cot"])
    print(result1['answer'])
    
    print("\n=== Self-Consistency ===")
    result2 = rag.query("Python是什么时候创建的?", techniques=["self-consistency", "cot"], n=3)
    print(result2['final_answer'])
    
    print("\n=== RAT ===")
    result3 = rag.query("Python是什么时候创建的?", techniques=["rat"])
    print(result3['answer'])
```

---

## 对比分析题

### Q8: 比较Query Decomposition和RAT的异同

**答案:**

**相同点:**
1. 都是处理复杂查询的技术
2. 都涉及多次检索
3. 都需要综合多个信息源

**不同点:**

| 维度 | Query Decomposition | RAT |
|------|-------------------|-----|
| **拆分时机** | 预先拆分 | 动态拆分 |
| **检索策略** | 并行检索所有子查询 | 迭代检索,按需补充 |
| **推理方式** | 最后综合 | 每次迭代都推理 |
| **适用场景** | 已知需要哪些信息 | 不确定需要什么信息 |
| **成本** | 中等(固定次数) | 较高(可能多次迭代) |
| **灵活性** | 较低 | 高 |

**选择建议:**
- 比较类查询 → Query Decomposition
- 多跳问答 → RAT
- 时间推理 → RAT

---

### Q9: Meta Prompting vs Active Prompting的区别

**答案:**

**核心区别:**

| 维度 | Meta Prompting | Active Prompting |
|------|---------------|-----------------|
| **目标** | 生成最优提示词 | 选择最优示例 |
| **输入** | 查询+任务类型 | 查询+示例池 |
| **输出** | 完整提示词 | Few-shot示例 |
| **方法** | LLM生成或模板 | 相似度计算 |
| **成本** | 高(额外LLM调用) | 低(embedding计算) |

**使用场景:**
- Meta Prompting: 任务类型多样,需要自适应
- Active Prompting: 任务类型固定,有示例库

**可以组合使用:**
```python
# 1. Meta Prompting生成提示词模板
template = meta_prompter.generate(query, task_type)

# 2. Active Prompting选择示例
examples = active_prompter.select(query, k=3)

# 3. 组合使用
final_prompt = template.format(examples=examples, query=query)
```

---

## 系统设计题

### Q10: 设计一个生产级RAG系统的Prompt策略

**答案:**

**分层策略:**

```
Layer 1: 基础层(必需)
├─ Few-shot Learning (格式引导)
├─ Structured Output (确保可解析)
└─ CoT (提升推理质量)

Layer 2: 优化层(推荐)
├─ Query Decomposition (处理复杂查询)
├─ Self-Consistency (关键查询验证)
└─ Active Prompting (动态示例选择)

Layer 3: 高级层(可选)
├─ RAT (多跳问答)
├─ ReAct (需要工具调用)
└─ Meta Prompting (多任务自适应)
```

**实现架构:**

```python
class ProductionRAG:
    def __init__(self):
        self.few_shot_examples = self._load_examples()
        self.query_classifier = QueryClassifier()
        self.retriever = Retriever()
        self.llm = LLM()
    
    def query(self, query: str) -> Dict:
        # 1. 分类查询
        query_type = self.query_classifier.classify(query)
        
        # 2. 选择策略
        if query_type == "simple":
            return self._simple_rag(query)
        elif query_type == "complex":
            return self._complex_rag(query)
        elif query_type == "critical":
            return self._critical_rag(query)
    
    def _simple_rag(self, query):
        """简单查询: Few-shot + CoT"""
        examples = self._select_examples(query, k=2)
        docs = self.retriever.search(query, top_k=3)
        return self._generate_with_cot(query, docs, examples)
    
    def _complex_rag(self, query):
        """复杂查询: Query Decomposition + CoT"""
        sub_queries = self._decompose(query)
        all_docs = []
        for sq in sub_queries:
            docs = self.retriever.search(sq, top_k=2)
            all_docs.extend(docs)
        return self._generate_with_cot(query, all_docs)
    
    def _critical_rag(self, query):
        """关键查询: Self-Consistency + CoT"""
        answers = []
        for _ in range(5):
            result = self._simple_rag(query)
            answers.append(result['answer'])
        return self._vote(answers)
```

**监控指标:**
- 准确率: >90%
- 响应时间: <2s (P95)
- 成本: <$0.01/query
- 格式正确率: 100%

---

## 参考资源

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [OpenAI Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Engineering](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [NVIDIA RAG Blueprint](https://docs.nvidia.com/rag/2.3.0/)
