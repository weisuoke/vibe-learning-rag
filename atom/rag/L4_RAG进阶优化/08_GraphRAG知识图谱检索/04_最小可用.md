# GraphRAG知识图谱检索 - 最小可用

> 掌握20%核心知识,解决80%的GraphRAG应用场景

---

## 核心知识清单

掌握以下5个核心知识点,就能开始使用GraphRAG:

### 1. 理解GraphRAG的本质

**核心概念**: GraphRAG = 知识图谱 + RAG

```python
# 最简单的理解
Vector RAG: 文本 → 向量 → 相似度检索
GraphRAG: 文本 → 实体+关系 → 图遍历检索

# 适用场景
Vector RAG: "什么是X?" (简单语义查询)
GraphRAG: "A和B通过哪些人有联系?" (复杂关系查询)
```

**关键点**:
- GraphRAG保留知识的结构信息
- 适合多跳推理和关系查询
- 成本高于Vector RAG,需要混合使用

---

### 2. 快速搭建GraphRAG系统

**使用Microsoft GraphRAG (最快方式)**:

```bash
# 1. 安装
pip install graphrag

# 2. 初始化项目
python -m graphrag.index --init --root ./ragtest

# 3. 配置API密钥
# 编辑 ./ragtest/settings.yaml
# 添加 OPENAI_API_KEY

# 4. 索引文档
python -m graphrag.index --root ./ragtest

# 5. 查询
python -m graphrag.query \
  --root ./ragtest \
  --method local \
  --query "你的问题"
```

**这就够了!** 5个命令搭建完整的GraphRAG系统。

---

### 3. 理解Local vs Global搜索

**核心区别**:

```python
# Local Search: 找细节
query = "Alice的职位是什么?"
# 流程: 提取实体(Alice) → 构建上下文 → 生成答案
# 适合: 特定实体查询

# Global Search: 看全局
query = "公司的组织结构是什么?"
# 流程: 社区检测 → 生成摘要 → Map-Reduce → 答案
# 适合: 整体结构查询
```

**选择策略**:
- 查询包含具体实体名 → Local
- 查询问整体/模式 → Global
- 不确定 → 先试Local(更快更便宜)

---

### 4. 实现混合检索

**最小可用代码**:

```python
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def classify_query(query: str) -> str:
    """分类查询类型"""
    # 简单规则
    if any(word in query for word in ["什么是", "定义", "解释"]):
        return "vector"
    elif any(word in query for word in ["关系", "联系", "通过"]):
        return "graph"
    else:
        return "vector"  # 默认用便宜的

def hybrid_search(query: str):
    """混合检索"""
    query_type = classify_query(query)
    
    if query_type == "vector":
        # 使用Vector RAG
        return vector_search(query)
    else:
        # 使用GraphRAG
        return graph_search(query)

# 使用
result = hybrid_search("Alice和Bob是什么关系?")
```

**关键点**:
- 简单查询用Vector(快速便宜)
- 复杂查询用Graph(准确强大)
- 查询路由是核心

---

### 5. 成本优化策略

**3个必知技巧**:

```python
# 技巧1: 缓存查询结果
cache = {}

def cached_search(query):
    if query in cache:
        return cache[query]
    
    result = graphrag_search(query)
    cache[query] = result
    return result

# 技巧2: 批量处理
def batch_index(documents, batch_size=10):
    """批量索引,减少API调用"""
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i+batch_size]
        index_batch(batch)

# 技巧3: 使用LazyGraphRAG
# Microsoft 2025推出,成本降至0.1%
# 配置: settings.yaml中设置 lazy_mode: true
```

**成本对比**:
- 传统GraphRAG: $1.00/1000查询
- LazyGraphRAG: $0.001/1000查询 (降低1000x)
- Vector RAG: $0.0001/1000查询

---

## 最小可用实战

### 场景: 企业知识库问答

```python
"""
最小可用GraphRAG系统
功能: 企业文档问答
"""

import os
from openai import OpenAI
import networkx as nx

# ===== 1. 初始化 =====
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
G = nx.Graph()

# ===== 2. 构建知识图谱 =====
def build_graph(documents):
    """从文档构建图"""
    for doc in documents:
        # 提取实体和关系(简化版)
        entities = extract_entities(doc)
        relations = extract_relations(doc)
        
        # 添加到图
        for rel in relations:
            G.add_edge(
                rel["subject"],
                rel["object"],
                relation=rel["predicate"]
            )

def extract_entities(text):
    """提取实体(使用LLM)"""
    # 简化版: 实际应使用完整的提取逻辑
    return []

def extract_relations(text):
    """提取关系(使用LLM)"""
    # 简化版: 实际应使用完整的提取逻辑
    return []

# ===== 3. 查询 =====
def search(query: str) -> str:
    """搜索答案"""
    # 提取查询中的实体
    entities = [node for node in G.nodes() if node.lower() in query.lower()]
    
    if not entities:
        return "未找到相关信息"
    
    # 构建上下文
    context = []
    for entity in entities:
        neighbors = list(G.neighbors(entity))
        context.append(f"{entity}的关系: {', '.join(neighbors)}")
    
    # 生成答案
    prompt = f"""
基于以下上下文回答问题:

{chr(10).join(context)}

问题: {query}
"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    
    return response.choices[0].message.content

# ===== 4. 使用 =====
if __name__ == "__main__":
    # 示例文档
    documents = [
        "Alice是Marketing部门的经理",
        "Bob在Marketing部门工作",
        "Marketing部门向Charlie汇报"
    ]
    
    # 构建图
    build_graph(documents)
    
    # 查询
    queries = [
        "Alice的职位是什么?",
        "Marketing部门向谁汇报?"
    ]
    
    for query in queries:
        answer = search(query)
        print(f"\n问题: {query}")
        print(f"回答: {answer}")
```

---

## 快速参考卡

### GraphRAG vs Vector RAG

| 维度 | Vector RAG | GraphRAG |
|------|-----------|----------|
| **适用场景** | 简单语义查询 | 复杂关系查询 |
| **成本** | 低 | 高(可优化至0.1%) |
| **准确率** | 基线 | 3.4x提升 |
| **实现难度** | 简单 | 中等 |
| **推荐使用** | 80%查询 | 20%查询 |

### 查询路由规则

```python
# 规则1: 包含"什么是"、"定义" → Vector
# 规则2: 包含"关系"、"联系" → Graph
# 规则3: 不确定 → Vector(便宜)
```

### 成本优化清单

- [ ] 使用查询缓存
- [ ] 批量处理文档
- [ ] 启用LazyGraphRAG
- [ ] 混合Vector+Graph
- [ ] 监控成本

---

## 学习路径

### 第1天: 理解概念
- 阅读30字核心
- 理解第一性原理
- 掌握Local vs Global

### 第2天: 动手实践
- 安装Microsoft GraphRAG
- 索引示例文档
- 尝试Local和Global查询

### 第3天: 优化系统
- 实现混合检索
- 添加查询缓存
- 监控成本

### 第4天: 生产部署
- 配置LazyGraphRAG
- 实现查询路由
- 部署API服务

---

## 常见问题

### Q1: GraphRAG一定比Vector RAG好吗?

**A**: 不一定。
- 简单查询: Vector更快更便宜
- 复杂查询: Graph更准确
- 最佳实践: 混合使用

### Q2: 成本太高怎么办?

**A**: 3个方法:
1. 使用LazyGraphRAG (降至0.1%)
2. 混合Vector+Graph (只在必要时用Graph)
3. 缓存热门查询

### Q3: 如何判断查询适合用GraphRAG?

**A**: 看查询类型:
- 包含具体实体名 → 可能适合
- 问关系/联系 → 适合
- 问整体结构 → 适合
- 简单定义 → 不适合

### Q4: 需要多少文档才能用GraphRAG?

**A**: 没有最小限制,但:
- 10+文档: 可以开始
- 100+文档: 效果明显
- 1000+文档: 充分发挥优势

### Q5: 可以用中文吗?

**A**: 可以!
- LLM支持中文实体提取
- 图结构与语言无关
- 注意: 中文分词可能影响效果

---

## 下一步

掌握最小可用知识后,建议:

1. **深入学习**: 阅读核心概念1-5
2. **实战练习**: 完成4个实战代码场景
3. **面试准备**: 学习面试必问
4. **知识内化**: 复习化骨绵掌

---

## 检查清单

完成最小可用学习后,你应该能够:

- [ ] 解释GraphRAG的本质
- [ ] 使用Microsoft GraphRAG搭建系统
- [ ] 理解Local和Global搜索的区别
- [ ] 实现简单的混合检索
- [ ] 应用基本的成本优化策略
- [ ] 判断何时使用GraphRAG

---

**版本**: v1.0 (基于2025-2026生产级实践)
**最后更新**: 2026-02-17
**维护者**: Claude Code
