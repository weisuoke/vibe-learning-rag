# 面试必问

> 监控与健康检查的高频面试题及出彩回答

---

## 问题1："请解释 Prometheus 的 Pull 模型和 Push 模型的区别，为什么 Prometheus 选择 Pull 模型？"

### 普通回答（❌ 不出彩）

"Pull 模型是 Prometheus 主动拉取指标，Push 模型是应用主动推送指标。Prometheus 选择 Pull 模型是因为这样更简单。"

**问题：** 回答过于简单，没有深入分析优缺点和设计考量。

---

### 出彩回答（✅ 推荐）

> **Pull 模型和 Push 模型有三个核心区别：**
>
> **1. 数据流方向不同**
> - Pull 模型：监控系统主动拉取（Prometheus → 应用）
> - Push 模型：应用主动推送（应用 → 监控系统）
>
> **2. 服务发现方式不同**
> - Pull 模型：监控系统需要知道所有目标地址（通过配置或服务发现）
> - Push 模型：应用需要知道监控系统地址
>
> **3. 故障影响不同**
> - Pull 模型：监控系统故障不影响应用运行
> - Push 模型：监控系统故障可能导致应用推送失败、阻塞
>
> **Prometheus 选择 Pull 模型的四个原因：**
>
> **原因1：故障隔离**
> - 监控系统宕机时，应用不受影响
> - 避免监控成为单点故障
>
> **原因2：服务发现灵活**
> - 监控系统可以动态发现新实例（Kubernetes、Consul）
> - 应用无需配置监控地址，降低耦合
>
> **原因3：健康检查内置**
> - 拉取失败即表示目标不可用
> - 无需额外的健康检查机制
>
> **原因4：防止数据丢失**
> - 监控系统控制采集频率，避免数据积压
> - Push 模型在监控系统故障时可能丢失数据
>
> **在 Milvus 监控中的体现：**
> - Milvus 暴露 `:9091/metrics` 端点
> - Prometheus 每 15 秒拉取一次
> - 即使 Prometheus 宕机，Milvus 仍正常运行
> - 通过 Kubernetes Service Discovery 自动发现新的 Milvus 实例

---

### 为什么这个回答出彩？

1. ✅ **结构清晰**：从区别到原因，层次分明
2. ✅ **深入分析**：不仅说"是什么"，还说"为什么"
3. ✅ **实际应用**：联系 Milvus 的具体实现
4. ✅ **对比思考**：分析了两种模型的优缺点

---

## 问题2："Liveness 探针和 Readiness 探针有什么区别？什么情况下应该使用哪个？"

### 普通回答（❌ 不出彩）

"Liveness 检查服务是否存活，Readiness 检查服务是否就绪。Liveness 失败会重启容器，Readiness 失败会停止流量。"

**问题：** 只说了表面现象，没有深入到设计原理和使用场景。

---

### 出彩回答（✅ 推荐）

> **Liveness 和 Readiness 探针的本质区别：**
>
> **1. 检查目标不同**
> - **Liveness**：检查进程是否还活着（死锁、崩溃、内存泄漏）
> - **Readiness**：检查服务是否能处理请求（依赖服务、资源充足）
>
> **2. 失败后果不同**
> - **Liveness 失败** → 重启容器（破坏性操作）
> - **Readiness 失败** → 停止流量（保护性操作）
>
> **3. 设计哲学不同**
> - **Liveness**：回答"需要重启吗？"
> - **Readiness**：回答"能接收流量吗？"
>
> **决策树：这个检查应该放在哪个探针？**
>
> ```
> 问：如果检查失败，重启容器能解决问题吗？
> ├─ 能解决 → Liveness 探针
> │   例如：进程死锁、内存泄漏、无响应
> │
> └─ 不能解决 → Readiness 探针
>     例如：数据库连接失败、依赖服务不可用、资源不足
> ```
>
> **常见错误：Liveness 检查依赖服务**
>
> ```python
> # ❌ 错误：Liveness 检查 etcd 连接
> @app.route('/healthz')
> def liveness():
>     if not check_etcd():
>         return "etcd is down", 500  # 导致不断重启
>     return "OK", 200
>
> # 问题：etcd 故障时，重启 Milvus 无法解决问题
> # 结果：容器不断重启（CrashLoopBackOff）
>
> # ✅ 正确：Liveness 只检查进程本身
> @app.route('/healthz')
> def liveness():
>     return "OK", 200  # 只要能响应就是存活
>
> # ✅ 正确：Readiness 检查依赖服务
> @app.route('/readyz')
> def readiness():
>     if not check_etcd():
>         return "not ready", 503  # 停止流量，等待 etcd 恢复
>     return "OK", 200
> ```
>
> **在 Milvus 中的实践：**
>
> **Liveness 探针配置：**
> - 检查频率：30 秒（不需要太频繁）
> - 失败阈值：3 次（避免误判）
> - 初始延迟：90 秒（给足够启动时间）
>
> **Readiness 探针配置：**
> - 检查频率：10 秒（需要快速发现问题）
> - 失败阈值：2 次（可以更敏感）
> - 检查内容：etcd、MinIO、Pulsar 连接状态

---

### 为什么这个回答出彩？

1. ✅ **本质理解**：从设计哲学角度解释区别
2. ✅ **决策工具**：提供实用的决策树
3. ✅ **常见错误**：指出并纠正典型误区
4. ✅ **代码示例**：用代码说明正确和错误的实现
5. ✅ **实际配置**：给出具体的配置建议

---

## 问题3："如何设计一个生产级的监控告警系统？需要考虑哪些关键因素？"

### 普通回答（❌ 不出彩）

"需要采集指标、设置告警规则、发送通知。关键因素包括采集频率、告警阈值、通知渠道等。"

**问题：** 过于笼统，缺乏系统性思考和实战经验。

---

### 出彩回答（✅ 推荐）

> **生产级监控告警系统的六个关键设计原则：**
>
> **1. 四个黄金信号（Google SRE）**
>
> 任何系统都应该监控这四个核心指标：
> - **延迟（Latency）**：P50、P95、P99 延迟
> - **流量（Traffic）**：QPS、吞吐量
> - **错误（Errors）**：错误率、失败次数
> - **饱和度（Saturation）**：CPU、内存、磁盘使用率
>
> **2. 告警分级策略**
>
> ```
> Critical（严重）：
> - 影响：服务完全不可用或数据丢失
> - 响应：立即处理（5 分钟内）
> - 通知：短信 + 电话 + 钉钉
> - 示例：Milvus 服务宕机、数据库连接失败
>
> Warning（警告）：
> - 影响：性能下降但服务可用
> - 响应：1 小时内处理
> - 通知：邮件 + 钉钉
> - 示例：查询延迟 P95 > 500ms、内存使用 > 80%
>
> Info（信息）：
> - 影响：需要关注但不紧急
> - 响应：工作时间处理
> - 通知：仅记录日志
> - 示例：QPS 异常波动、缓存命中率下降
> ```
>
> **3. 告警收敛机制**
>
> 避免"告警风暴"：
> - **时间收敛**：同一告警 5 分钟内只发送一次
> - **条件收敛**：连续 N 次失败才触发（避免抖动）
> - **依赖收敛**：如果 Milvus 宕机，抑制所有 Milvus 相关告警
>
> ```yaml
> # Prometheus 告警规则示例
> - alert: HighSearchLatency
>   expr: histogram_quantile(0.95, rate(milvus_proxy_search_latency_milliseconds_bucket[5m])) > 500
>   for: 5m  # 持续 5 分钟才触发（避免瞬时抖动）
>   labels:
>     severity: warning
> ```
>
> **4. 可操作性原则**
>
> 每个告警都应该回答三个问题：
> - **What**：发生了什么问题？
> - **Why**：为什么会发生？（可能的原因）
> - **How**：如何解决？（操作手册链接）
>
> ```yaml
> annotations:
>   summary: "Milvus search latency is high"
>   description: |
>     P95 search latency is {{ $value }}ms (threshold: 500ms)
>
>     Possible causes:
>     - High query load
>     - Index not optimized
>     - Insufficient resources
>
>     Troubleshooting guide:
>     https://wiki.company.com/milvus-latency-troubleshooting
> ```
>
> **5. 监控指标的三个层次**
>
> ```
> Layer 1: 业务指标（最重要）
> - 用户体验直接相关
> - 示例：API 响应时间、检索准确率、用户请求成功率
>
> Layer 2: 应用指标
> - 应用层面的健康状况
> - 示例：Milvus QPS、查询延迟、错误率
>
> Layer 3: 基础设施指标
> - 系统资源使用情况
> - 示例：CPU、内存、磁盘、网络
> ```
>
> **6. 避免高基数陷阱**
>
> ```python
> # ❌ 错误：高基数标签
> milvus_search_count{
>   user_id="12345",      # 百万级别的值
>   request_id="abc123"   # 千万级别的值
> }
> # 问题：导致 Prometheus 存储爆炸、查询变慢
>
> # ✅ 正确：低基数标签
> milvus_search_count{
>   collection="knowledge_base",  # 几十个值
>   instance="milvus-1"           # 几十个值
> }
> # 优点：存储高效、查询快速
> ```
>
> **在 RAG 系统中的实践：**
>
> ```
> 监控层次：
> 1. 业务层：RAG 问答成功率、端到端响应时间
> 2. 应用层：Milvus 检索延迟、Embedding 生成耗时
> 3. 基础设施层：Milvus 内存使用、CPU 使用
>
> 告警规则：
> - Critical: RAG 服务不可用、Milvus 连接失败
> - Warning: 检索延迟 P95 > 500ms、缓存命中率 < 50%
> - Info: QPS 异常波动、资源使用趋势
> ```

---

### 为什么这个回答出彩？

1. ✅ **系统性思考**：从六个维度全面分析
2. ✅ **业界最佳实践**：引用 Google SRE 的四个黄金信号
3. ✅ **实战经验**：告警分级、收敛机制、可操作性
4. ✅ **常见陷阱**：指出高基数标签问题
5. ✅ **具体示例**：提供完整的配置示例和实践建议
6. ✅ **联系实际**：结合 RAG 系统的具体应用

---

## 小结

**面试中展示监控与健康检查能力的关键：**

1. **深入理解原理**：不仅知道"是什么"，还要知道"为什么"
2. **系统性思考**：从多个维度分析问题
3. **实战经验**：能指出常见错误和最佳实践
4. **代码示例**：用代码说明概念
5. **联系实际**：结合具体的业务场景（如 RAG 系统）

**回答模板：**
```
1. 定义和区别（是什么）
2. 设计原理（为什么）
3. 常见错误（反面教材）
4. 最佳实践（正确做法）
5. 实际应用（具体场景）
```

---

**下一步：** [09_化骨绵掌](./09_化骨绵掌.md)
