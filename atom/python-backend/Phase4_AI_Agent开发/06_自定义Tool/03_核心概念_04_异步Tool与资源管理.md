# 自定义Tool - 核心概念04：异步Tool与资源管理

> 深入理解异步Tool的优势、实现方式和资源管理最佳实践

---

## 概述

**为什么需要异步Tool？**

Tool通常涉及I/O操作：
- API调用（HTTP请求）
- 数据库查询（SQL执行）
- 文件读写（磁盘I/O）
- 网络通信（Socket连接）

**同步 vs 异步的性能差异：**

```
同步Tool（串行执行）：
用户问："北京和上海的天气"
    ↓
调用get_weather("北京")  ← 等待3秒
    ↓
调用get_weather("上海")  ← 等待3秒
    ↓
总耗时：6秒

异步Tool（并发执行）：
用户问："北京和上海的天气"
    ↓
并发调用：
    get_weather("北京")  ← 等待3秒
    get_weather("上海")  ← 等待3秒
    ↓
总耗时：3秒（快一倍！）
```

---

## 异步编程基础

### 1. async/await语法

```python
import asyncio
import httpx

# 同步函数
def fetch_data_sync(url: str) -> str:
    response = httpx.get(url)  # 阻塞等待
    return response.text

# 异步函数
async def fetch_data_async(url: str) -> str:
    async with httpx.AsyncClient() as client:
        response = await client.get(url)  # 非阻塞等待
        return response.text

# 调用异步函数
async def main():
    result = await fetch_data_async("https://api.example.com/data")
    print(result)

# 运行异步函数
asyncio.run(main())
```

**关键概念：**
- `async def`：定义异步函数（协程）
- `await`：等待异步操作完成
- `async with`：异步上下文管理器
- `asyncio.run()`：运行异步函数

### 2. 并发执行

```python
import asyncio

async def task1():
    print("Task 1 开始")
    await asyncio.sleep(2)
    print("Task 1 完成")
    return "结果1"

async def task2():
    print("Task 2 开始")
    await asyncio.sleep(2)
    print("Task 2 完成")
    return "结果2"

# 串行执行（慢）
async def sequential():
    result1 = await task1()  # 等待2秒
    result2 = await task2()  # 等待2秒
    return [result1, result2]
    # 总耗时：4秒

# 并发执行（快）
async def concurrent():
    results = await asyncio.gather(
        task1(),  # 同时开始
        task2()   # 同时开始
    )
    return results
    # 总耗时：2秒
```

---

## 异步Tool的实现

### 1. 基本异步Tool

```python
from langchain.tools import tool
import httpx

@tool
async def fetch_weather(city: str) -> str:
    """获取指定城市的天气信息

    Args:
        city: 城市名称
    """
    async with httpx.AsyncClient() as client:
        response = await client.get(
            "https://api.weather.com/v1/current",
            params={"city": city}
        )
        data = response.json()
        return f"{city}的天气：{data['weather']}，温度{data['temp']}°C"
```

**关键要素：**
- `async def`：定义异步Tool
- `async with`：异步上下文管理器
- `await`：等待异步操作

### 2. 异步数据库查询

```python
import asyncpg
from langchain.tools import tool

@tool
async def query_order(order_id: str) -> str:
    """查询订单详细信息

    Args:
        order_id: 订单ID
    """
    # 连接数据库
    conn = await asyncpg.connect(
        host='localhost',
        database='mydb',
        user='user',
        password='password'
    )

    try:
        # 执行查询
        row = await conn.fetchrow(
            'SELECT * FROM orders WHERE id = $1',
            order_id
        )

        if not row:
            return f"错误：订单{order_id}不存在"

        return f"""订单信息：
订单号：{row['id']}
状态：{row['status']}
金额：¥{row['amount']}
"""
    finally:
        # 关闭连接
        await conn.close()
```

### 3. 异步文件操作

```python
import aiofiles
from langchain.tools import tool

@tool
async def read_file(file_path: str) -> str:
    """读取文件内容

    Args:
        file_path: 文件路径
    """
    try:
        async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
            content = await f.read()
            return f"文件内容：\n{content}"
    except FileNotFoundError:
        return f"错误：文件{file_path}不存在"
    except Exception as e:
        return f"读取文件失败：{str(e)}"
```

### 4. 多个异步操作

```python
import asyncio
import httpx
from langchain.tools import tool

@tool
async def fetch_multiple_cities(cities: list) -> str:
    """获取多个城市的天气信息

    Args:
        cities: 城市列表
    """
    async def fetch_one(city: str) -> str:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                "https://api.weather.com/v1/current",
                params={"city": city}
            )
            data = response.json()
            return f"{city}：{data['weather']}，{data['temp']}°C"

    # 并发获取所有城市的天气
    results = await asyncio.gather(*[fetch_one(city) for city in cities])
    return "\n".join(results)
```

---

## 资源管理

### 1. 连接池的重要性

**问题：每次都创建新连接**

```python
# ❌ 不复用连接（慢）
@tool
async def fetch_data_bad(url: str) -> str:
    """获取数据（不复用连接）"""
    async with httpx.AsyncClient() as client:  # 每次新建连接
        response = await client.get(url)
        return response.text
    # 每次都要TCP握手，慢！

# 100次调用 = 100次TCP握手 = 10秒
```

**解决方案：使用连接池**

```python
# ✅ 复用连接（快）
# 在模块级别创建客户端
http_client = httpx.AsyncClient(
    limits=httpx.Limits(
        max_connections=10,      # 最大连接数
        max_keepalive_connections=5  # 保持活跃的连接数
    ),
    timeout=httpx.Timeout(10.0)  # 超时设置
)

@tool
async def fetch_data_good(url: str) -> str:
    """获取数据（复用连接）"""
    response = await http_client.get(url)  # 复用连接
    return response.text
    # 复用TCP连接，快！

# 100次调用 = 1次TCP握手 = 2秒（快5倍！）
```

### 2. 数据库连接池

```python
import asyncpg
from langchain.tools import tool

# 创建连接池（模块级别）
db_pool = None

async def init_db_pool():
    """初始化数据库连接池"""
    global db_pool
    db_pool = await asyncpg.create_pool(
        host='localhost',
        database='mydb',
        user='user',
        password='password',
        min_size=5,   # 最小连接数
        max_size=20,  # 最大连接数
        command_timeout=60  # 命令超时（秒）
    )

@tool
async def query_database(query: str) -> str:
    """查询数据库

    Args:
        query: SQL查询语句
    """
    if not db_pool:
        await init_db_pool()

    # 从连接池获取连接
    async with db_pool.acquire() as conn:
        try:
            rows = await conn.fetch(query)
            return str(rows)
        except Exception as e:
            return f"查询失败：{str(e)}"
```

**连接池的优势：**
- ✅ 复用连接，避免重复建立
- ✅ 限制连接数，防止资源耗尽
- ✅ 自动管理连接生命周期
- ✅ 提升性能3-5倍

### 3. 资源清理

```python
from langchain.tools import tool
import httpx

# 全局HTTP客户端
http_client = httpx.AsyncClient()

@tool
async def fetch_data(url: str) -> str:
    """获取数据"""
    response = await http_client.get(url)
    return response.text

# 应用关闭时清理资源
async def cleanup():
    """清理资源"""
    await http_client.aclose()
```

**在FastAPI中集成：**

```python
from fastapi import FastAPI
import httpx

app = FastAPI()

# 全局HTTP客户端
http_client = None

@app.on_event("startup")
async def startup():
    """应用启动时初始化资源"""
    global http_client
    http_client = httpx.AsyncClient(
        limits=httpx.Limits(max_connections=10)
    )

@app.on_event("shutdown")
async def shutdown():
    """应用关闭时清理资源"""
    await http_client.aclose()
```

---

## 超时处理

### 1. HTTP请求超时

```python
import httpx
from langchain.tools import tool

# 配置超时
http_client = httpx.AsyncClient(
    timeout=httpx.Timeout(
        connect=5.0,   # 连接超时
        read=10.0,     # 读取超时
        write=5.0,     # 写入超时
        pool=5.0       # 连接池超时
    )
)

@tool
async def fetch_data(url: str) -> str:
    """获取数据（带超时）"""
    try:
        response = await http_client.get(url)
        return response.text
    except httpx.TimeoutException:
        return f"请求超时：{url}。请稍后重试。"
    except httpx.RequestError as e:
        return f"请求失败：{str(e)}"
```

### 2. 数据库查询超时

```python
import asyncio
import asyncpg
from langchain.tools import tool

@tool
async def query_database(query: str) -> str:
    """查询数据库（带超时）"""
    try:
        # 设置3秒超时
        result = await asyncio.wait_for(
            db_pool.fetch(query),
            timeout=3.0
        )
        return str(result)
    except asyncio.TimeoutError:
        return "查询超时。建议：简化查询条件或稍后重试。"
    except Exception as e:
        return f"查询失败：{str(e)}"
```

### 3. Tool级别超时

```python
import asyncio
from langchain.tools import tool

@tool
async def slow_operation(param: str) -> str:
    """可能很慢的操作"""
    try:
        # 设置5秒超时
        result = await asyncio.wait_for(
            do_slow_operation(param),
            timeout=5.0
        )
        return result
    except asyncio.TimeoutError:
        return "操作超时。建议：请稍后重试或联系客服。"
```

---

## 错误处理

### 1. 网络错误

```python
import httpx
from langchain.tools import tool

@tool
async def fetch_data(url: str) -> str:
    """获取数据（完整错误处理）"""
    try:
        response = await http_client.get(url)
        response.raise_for_status()  # 检查HTTP状态码
        return response.text

    except httpx.TimeoutException:
        return f"请求超时：{url}。建议：请稍后重试。"

    except httpx.HTTPStatusError as e:
        return f"HTTP错误：{e.response.status_code}。建议：检查URL是否正确。"

    except httpx.NetworkError:
        return f"网络错误：无法连接到{url}。建议：检查网络连接。"

    except httpx.RequestError as e:
        return f"请求失败：{str(e)}。建议：请稍后重试。"
```

### 2. 数据库错误

```python
import asyncpg
from langchain.tools import tool

@tool
async def query_database(query: str) -> str:
    """查询数据库（完整错误处理）"""
    try:
        async with db_pool.acquire() as conn:
            result = await conn.fetch(query)
            return str(result)

    except asyncpg.PostgresError as e:
        return f"数据库错误：{str(e)}。建议：检查SQL语句是否正确。"

    except asyncpg.TooManyConnectionsError:
        return "数据库连接数已满。建议：请稍后重试。"

    except asyncpg.QueryCanceledError:
        return "查询被取消。建议：简化查询条件。"

    except Exception as e:
        return f"查询失败：{str(e)}。建议：请联系技术支持。"
```

### 3. 重试机制

```python
import asyncio
from langchain.tools import tool

async def retry_async(func, max_retries=3, delay=1.0):
    """异步重试装饰器"""
    for attempt in range(max_retries):
        try:
            return await func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(delay * (attempt + 1))  # 指数退避

@tool
async def fetch_data_with_retry(url: str) -> str:
    """获取数据（带重试）"""
    async def fetch():
        response = await http_client.get(url)
        response.raise_for_status()
        return response.text

    try:
        result = await retry_async(fetch, max_retries=3)
        return result
    except Exception as e:
        return f"请求失败（已重试3次）：{str(e)}"
```

---

## 并发控制

### 1. 限制并发数

```python
import asyncio
from langchain.tools import tool

# 创建信号量（限制并发数为5）
semaphore = asyncio.Semaphore(5)

@tool
async def fetch_data(url: str) -> str:
    """获取数据（限制并发）"""
    async with semaphore:  # 获取信号量
        response = await http_client.get(url)
        return response.text
    # 释放信号量

# 即使同时调用100次，也只有5个并发请求
```

### 2. 批量处理

```python
import asyncio
from langchain.tools import tool

@tool
async def process_batch(items: list) -> str:
    """批量处理（分批并发）"""
    batch_size = 10  # 每批10个

    async def process_one(item):
        # 处理单个item
        return await do_something(item)

    results = []
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        # 并发处理一批
        batch_results = await asyncio.gather(*[process_one(item) for item in batch])
        results.extend(batch_results)

    return f"处理完成：{len(results)}个项目"
```

---

## 性能优化

### 1. 连接复用

```python
# ❌ 不复用（慢）
@tool
async def fetch_bad(url: str) -> str:
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        return response.text

# ✅ 复用（快）
http_client = httpx.AsyncClient()

@tool
async def fetch_good(url: str) -> str:
    response = await http_client.get(url)
    return response.text
```

**性能对比：**
- 不复用：100次调用 = 10秒
- 复用：100次调用 = 2秒（快5倍）

### 2. 并发执行

```python
# ❌ 串行（慢）
@tool
async def fetch_multiple_serial(urls: list) -> str:
    results = []
    for url in urls:
        response = await http_client.get(url)
        results.append(response.text)
    return "\n".join(results)

# ✅ 并发（快）
@tool
async def fetch_multiple_concurrent(urls: list) -> str:
    async def fetch_one(url):
        response = await http_client.get(url)
        return response.text

    results = await asyncio.gather(*[fetch_one(url) for url in urls])
    return "\n".join(results)
```

**性能对比：**
- 串行：10个URL = 30秒
- 并发：10个URL = 3秒（快10倍）

### 3. 缓存结果

```python
from functools import lru_cache
from langchain.tools import tool

# 缓存同步函数的结果
@lru_cache(maxsize=100)
def get_cached_data(key: str) -> str:
    # 昂贵的计算
    return expensive_computation(key)

@tool
async def fetch_with_cache(key: str) -> str:
    """获取数据（带缓存）"""
    # 先检查缓存
    cached = get_cached_data(key)
    if cached:
        return cached

    # 缓存未命中，获取数据
    response = await http_client.get(f"/api/data?key={key}")
    return response.text
```

---

## 在Agent中使用异步Tool

### 1. 异步Agent执行器

```python
from langchain_openai import ChatOpenAI
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.prompts import ChatPromptTemplate

# 定义异步Tools
tools = [
    fetch_weather,      # 异步Tool
    query_database,     # 异步Tool
    send_email          # 异步Tool
]

# 创建Agent
llm = ChatOpenAI(model="gpt-4", temperature=0)
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个智能助手。"),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}"),
])

agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

# 使用异步调用
result = await agent_executor.ainvoke({
    "input": "北京和上海的天气怎么样？"
})
print(result["output"])
```

**关键：**
- 使用`ainvoke()`而非`invoke()`
- Agent会自动并发调用异步Tool

### 2. 在FastAPI中集成

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class QueryRequest(BaseModel):
    question: str

@app.post("/ask")
async def ask_agent(request: QueryRequest):
    """Agent问答端点（异步）"""
    try:
        result = await agent_executor.ainvoke({
            "input": request.question
        })
        return {"answer": result["output"]}
    except Exception as e:
        return {"error": str(e)}
```

---

## 最佳实践

### 1. 资源初始化和清理

```python
from fastapi import FastAPI
import httpx
import asyncpg

app = FastAPI()

# 全局资源
http_client = None
db_pool = None

@app.on_event("startup")
async def startup():
    """应用启动时初始化资源"""
    global http_client, db_pool

    # 初始化HTTP客户端
    http_client = httpx.AsyncClient(
        limits=httpx.Limits(max_connections=10),
        timeout=httpx.Timeout(10.0)
    )

    # 初始化数据库连接池
    db_pool = await asyncpg.create_pool(
        host='localhost',
        database='mydb',
        min_size=5,
        max_size=20
    )

@app.on_event("shutdown")
async def shutdown():
    """应用关闭时清理资源"""
    await http_client.aclose()
    await db_pool.close()
```

### 2. 错误处理模板

```python
@tool
async def robust_tool(param: str) -> str:
    """健壮的异步Tool"""
    try:
        # 1. 参数验证
        if not param:
            return "错误：参数不能为空"

        # 2. 设置超时
        result = await asyncio.wait_for(
            do_async_operation(param),
            timeout=5.0
        )

        # 3. 返回结果
        return f"成功：{result}"

    except asyncio.TimeoutError:
        return "操作超时。建议：请稍后重试。"

    except httpx.NetworkError:
        return "网络错误。建议：检查网络连接。"

    except asyncpg.PostgresError as e:
        return f"数据库错误：{str(e)}。建议：请联系技术支持。"

    except Exception as e:
        return f"未知错误：{str(e)}。建议：请联系技术支持。"
```

### 3. 性能监控

```python
import time
from langchain.tools import tool

@tool
async def monitored_tool(param: str) -> str:
    """带性能监控的Tool"""
    start_time = time.time()

    try:
        result = await do_async_operation(param)

        # 记录执行时间
        elapsed = time.time() - start_time
        print(f"Tool执行时间：{elapsed:.2f}秒")

        return result

    except Exception as e:
        elapsed = time.time() - start_time
        print(f"Tool执行失败，耗时：{elapsed:.2f}秒，错误：{str(e)}")
        return f"执行失败：{str(e)}"
```

---

## 常见问题

### 1. 同步Tool vs 异步Tool

**何时使用异步Tool？**
- ✅ Tool涉及I/O操作（API、数据库、文件）
- ✅ Agent可能需要调用多个Tool
- ✅ 响应时间要求高

**何时使用同步Tool？**
- ✅ Tool只做CPU密集型计算
- ✅ Tool不涉及I/O操作
- ✅ Tool逻辑非常简单

### 2. 连接池大小设置

**HTTP连接池：**
- 小型应用：5-10个连接
- 中型应用：10-20个连接
- 大型应用：20-50个连接

**数据库连接池：**
- 小型应用：5-10个连接
- 中型应用：10-20个连接
- 大型应用：20-50个连接

**经验法则：**
- 连接池大小 = 并发请求数 / 2
- 不要设置过大（浪费资源）
- 不要设置过小（性能瓶颈）

### 3. 超时时间设置

**HTTP请求：**
- 连接超时：5秒
- 读取超时：10秒
- 总超时：15秒

**数据库查询：**
- 简单查询：3秒
- 复杂查询：10秒
- 报表查询：30秒

**经验法则：**
- 超时时间 = 正常响应时间 × 2
- 不要设置过短（频繁超时）
- 不要设置过长（用户等待太久）

---

## 总结

### 异步Tool的核心价值

1. **性能提升**：并发执行，响应时间减少50%以上
2. **资源复用**：连接池，性能提升3-5倍
3. **更好的用户体验**：更快的响应时间

### 资源管理的关键

1. **连接池**：复用连接，避免重复建立
2. **超时控制**：防止长时间阻塞
3. **错误处理**：友好的错误提示
4. **资源清理**：应用关闭时释放资源

### 最佳实践

```python
# 1. 使用连接池
http_client = httpx.AsyncClient(limits=httpx.Limits(max_connections=10))

# 2. 设置超时
http_client = httpx.AsyncClient(timeout=httpx.Timeout(10.0))

# 3. 错误处理
try:
    result = await http_client.get(url)
except httpx.TimeoutException:
    return "请求超时"

# 4. 资源清理
@app.on_event("shutdown")
async def shutdown():
    await http_client.aclose()
```

### 快速参考

| 操作 | 同步 | 异步 |
|-----|------|------|
| HTTP请求 | `httpx.get()` | `await client.get()` |
| 数据库查询 | `conn.execute()` | `await conn.fetch()` |
| 文件读写 | `open()` | `async with aiofiles.open()` |
| 并发执行 | 串行 | `asyncio.gather()` |
| 超时控制 | 无 | `asyncio.wait_for()` |

---

**记住：** 异步Tool + 连接池 = 性能提升5-10倍！
