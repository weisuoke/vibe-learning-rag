# 实战代码 - 场景5: RAG多租户知识库

完整演示在 RAG 系统中使用分区实现多租户知识库，包括文档上传、向量化、检索、LLM 生成。

---

## 场景描述

**目标**: 构建一个完整的 RAG 多租户知识库系统

**需求**:
- 多租户数据隔离（使用分区）
- 文档上传和向量化
- 语义检索
- LLM 生成答案
- 完整的 RAG 流程

---

## 完整代码

```python
"""
RAG 多租户知识库系统
演示：完整的 RAG 流程 + 多租户分区隔离
"""

from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
import numpy as np
from datetime import datetime
from typing import List, Dict
import os

# 模拟 Embedding 和 LLM（实际使用时替换为真实的 API）
def get_embedding(text: str) -> List[float]:
    """生成文本的 Embedding（模拟）"""
    # 实际使用：from openai import OpenAI; client.embeddings.create(...)
    return np.random.rand(128).tolist()

def generate_answer(query: str, context: List[str]) -> str:
    """使用 LLM 生成答案（模拟）"""
    # 实际使用：from openai import OpenAI; client.chat.completions.create(...)
    return f"基于检索到的 {len(context)} 条文档，答案是：[模拟生成的答案]"

# ===== 1. 连接到 Milvus =====
print("=== 1. 连接到 Milvus ===")
connections.connect("default", host="localhost", port="19530")
print("✓ 连接成功")

# ===== 2. 创建 Collection =====
print("\n=== 2. 创建 RAG Collection ===")

collection_name = "rag_knowledge_base"

if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)

fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
    FieldSchema(name="document_text", dtype=DataType.VARCHAR, max_length=2000),
    FieldSchema(name="document_title", dtype=DataType.VARCHAR, max_length=200),
    FieldSchema(name="tenant_id", dtype=DataType.VARCHAR, max_length=50),
    FieldSchema(name="doc_type", dtype=DataType.VARCHAR, max_length=50),
    FieldSchema(name="created_at", dtype=DataType.INT64)
]

schema = CollectionSchema(fields, description="RAG 多租户知识库")
collection = Collection(collection_name, schema)
print(f"✓ 创建 Collection: {collection_name}")

# ===== 3. RAG 系统类 =====
print("\n=== 3. RAG 系统类 ===")

class RAGSystem:
    """RAG 多租户知识库系统"""

    def __init__(self, collection):
        self.collection = collection

    def onboard_tenant(self, tenant_id: str, company_name: str):
        """租户注册"""
        partition_name = f"tenant_{tenant_id}"

        if self.collection.has_partition(partition_name):
            print(f"⚠ 租户已存在: {company_name}")
            return partition_name

        self.collection.create_partition(
            partition_name,
            description=f"租户: {company_name}"
        )

        print(f"✓ 租户注册成功: {company_name} ({tenant_id})")
        return partition_name

    def upload_document(
        self,
        tenant_id: str,
        title: str,
        content: str,
        doc_type: str = "general"
    ) -> int:
        """上传文档到租户知识库"""
        partition_name = f"tenant_{tenant_id}"

        if not self.collection.has_partition(partition_name):
            raise ValueError(f"租户不存在: {tenant_id}")

        # 1. 生成 Embedding
        embedding = get_embedding(content)

        # 2. 准备数据
        data = [
            [embedding],
            [content],
            [title],
            [tenant_id],
            [doc_type],
            [int(datetime.now().timestamp())]
        ]

        # 3. 插入到租户分区
        partition = self.collection.partition(partition_name)
        result = partition.insert(data)

        return result.primary_keys[0]

    def batch_upload_documents(
        self,
        tenant_id: str,
        documents: List[Dict]
    ) -> List[int]:
        """批量上传文档"""
        partition_name = f"tenant_{tenant_id}"

        if not self.collection.has_partition(partition_name):
            raise ValueError(f"租户不存在: {tenant_id}")

        # 1. 批量生成 Embeddings
        embeddings = [get_embedding(doc["content"]) for doc in documents]

        # 2. 准备批量数据
        contents = [doc["content"] for doc in documents]
        titles = [doc["title"] for doc in documents]
        tenant_ids = [tenant_id] * len(documents)
        doc_types = [doc.get("doc_type", "general") for doc in documents]
        timestamps = [int(datetime.now().timestamp())] * len(documents)

        data = [embeddings, contents, titles, tenant_ids, doc_types, timestamps]

        # 3. 批量插入
        partition = self.collection.partition(partition_name)
        result = partition.insert(data)

        return result.primary_keys

    def search_documents(
        self,
        tenant_id: str,
        query: str,
        top_k: int = 5,
        doc_type: str = None
    ) -> List[Dict]:
        """检索租户文档"""
        partition_name = f"tenant_{tenant_id}"

        if not self.collection.has_partition(partition_name):
            raise ValueError(f"租户不存在: {tenant_id}")

        # 1. 生成查询 Embedding
        query_embedding = get_embedding(query)

        # 2. 构建过滤条件
        expr = None
        if doc_type:
            expr = f'doc_type == "{doc_type}"'

        # 3. 执行检索
        search_params = {"metric_type": "COSINE", "params": {"ef": 64}}

        results = self.collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            partition_names=[partition_name],  # 租户隔离
            expr=expr,
            output_fields=["document_text", "document_title", "doc_type"]
        )

        # 4. 格式化结果
        documents = []
        for hit in results[0]:
            documents.append({
                "id": hit.id,
                "title": hit.entity.get("document_title"),
                "content": hit.entity.get("document_text"),
                "doc_type": hit.entity.get("doc_type"),
                "score": hit.distance
            })

        return documents

    def rag_query(
        self,
        tenant_id: str,
        query: str,
        top_k: int = 3
    ) -> Dict:
        """RAG 查询：检索 + 生成"""
        # 1. 检索相关文档
        documents = self.search_documents(tenant_id, query, top_k)

        if not documents:
            return {
                "query": query,
                "answer": "抱歉，没有找到相关文档。",
                "sources": []
            }

        # 2. 提取文档内容作为上下文
        context = [doc["content"] for doc in documents]

        # 3. 使用 LLM 生成答案
        answer = generate_answer(query, context)

        # 4. 返回结果
        return {
            "query": query,
            "answer": answer,
            "sources": documents
        }

    def get_tenant_stats(self, tenant_id: str) -> Dict:
        """获取租户统计信息"""
        partition_name = f"tenant_{tenant_id}"

        if not self.collection.has_partition(partition_name):
            return None

        partition = self.collection.partition(partition_name)

        return {
            "tenant_id": tenant_id,
            "document_count": partition.num_entities,
            "is_loaded": partition.is_loaded
        }

# 创建 RAG 系统
rag_system = RAGSystem(collection)

# ===== 4. 注册租户 =====
print("\n=== 4. 注册租户 ===")

tenants = [
    ("tech_company", "科技公司"),
    ("finance_company", "金融公司")
]

for tenant_id, company_name in tenants:
    rag_system.onboard_tenant(tenant_id, company_name)

# ===== 5. 上传文档 =====
print("\n=== 5. 上传文档到知识库 ===")

# 科技公司的文档
tech_docs = [
    {
        "title": "Python 编程指南",
        "content": "Python 是一种高级编程语言，具有简洁的语法和强大的功能。适合初学者学习，也适合专业开发。",
        "doc_type": "technical"
    },
    {
        "title": "机器学习入门",
        "content": "机器学习是人工智能的一个分支，通过算法让计算机从数据中学习。常见算法包括线性回归、决策树、神经网络等。",
        "doc_type": "technical"
    },
    {
        "title": "Docker 容器化",
        "content": "Docker 是一个开源的容器化平台，可以将应用程序及其依赖打包成容器，实现快速部署和扩展。",
        "doc_type": "technical"
    }
]

tech_ids = rag_system.batch_upload_documents("tech_company", tech_docs)
print(f"✓ 为科技公司上传 {len(tech_ids)} 篇文档")

# 金融公司的文档
finance_docs = [
    {
        "title": "股票投资基础",
        "content": "股票投资是一种常见的理财方式。投资者需要了解公司基本面、技术分析、风险管理等知识。",
        "doc_type": "finance"
    },
    {
        "title": "基金投资指南",
        "content": "基金是一种集合投资工具，由专业基金经理管理。包括股票基金、债券基金、混合基金等类型。",
        "doc_type": "finance"
    },
    {
        "title": "风险管理策略",
        "content": "风险管理是投资的重要环节。包括资产配置、止损策略、对冲工具等方法来控制风险。",
        "doc_type": "finance"
    }
]

finance_ids = rag_system.batch_upload_documents("finance_company", finance_docs)
print(f"✓ 为金融公司上传 {len(finance_ids)} 篇文档")

# 刷新数据
collection.flush()
print("\n✓ 数据已刷新到磁盘")

# ===== 6. 创建索引 =====
print("\n=== 6. 创建索引 ===")

index_params = {
    "index_type": "HNSW",
    "metric_type": "COSINE",
    "params": {"M": 16, "efConstruction": 256}
}

collection.create_index("embedding", index_params)
print("✓ 创建 HNSW 索引")

# ===== 7. 加载租户分区 =====
print("\n=== 7. 加载租户分区 ===")

for tenant_id, _ in tenants:
    partition_name = f"tenant_{tenant_id}"
    partition = collection.partition(partition_name)
    partition.load()
    print(f"✓ 加载分区: {partition_name}")

# ===== 8. RAG 查询测试 =====
print("\n=== 8. RAG 查询测试 ===")

# 测试1：科技公司查询
print("\n测试1: 科技公司查询")
query1 = "如何学习 Python 编程？"
result1 = rag_system.rag_query("tech_company", query1, top_k=2)

print(f"查询: {result1['query']}")
print(f"答案: {result1['answer']}")
print(f"\n检索到的文档:")
for i, doc in enumerate(result1['sources']):
    print(f"  {i+1}. {doc['title']} (相似度: {doc['score']:.4f})")
    print(f"     内容: {doc['content'][:100]}...")

# 测试2：金融公司查询
print("\n测试2: 金融公司查询")
query2 = "如何进行风险管理？"
result2 = rag_system.rag_query("finance_company", query2, top_k=2)

print(f"查询: {result2['query']}")
print(f"答案: {result2['answer']}")
print(f"\n检索到的文档:")
for i, doc in enumerate(result2['sources']):
    print(f"  {i+1}. {doc['title']} (相似度: {doc['score']:.4f})")
    print(f"     内容: {doc['content'][:100]}...")

# ===== 9. 租户隔离验证 =====
print("\n=== 9. 租户隔离验证 ===")

# 科技公司查询金融相关问题（应该检索不到金融公司的文档）
print("\n验证：科技公司查询金融问题")
query3 = "如何投资股票？"
result3 = rag_system.rag_query("tech_company", query3, top_k=2)

print(f"查询: {result3['query']}")
print(f"检索到的文档数量: {len(result3['sources'])}")

if result3['sources']:
    print("检索到的文档:")
    for doc in result3['sources']:
        print(f"  - {doc['title']} (类型: {doc['doc_type']})")
else:
    print("✓ 租户隔离正确：没有检索到其他租户的文档")

# ===== 10. 租户统计 =====
print("\n=== 10. 租户统计 ===")

print("\n租户统计信息:")
for tenant_id, company_name in tenants:
    stats = rag_system.get_tenant_stats(tenant_id)
    print(f"  {company_name} ({tenant_id}):")
    print(f"    文档数量: {stats['document_count']}")
    print(f"    加载状态: {'已加载' if stats['is_loaded'] else '未加载'}")

# ===== 11. 完整 RAG 流程演示 =====
print("\n=== 11. 完整 RAG 流程演示 ===")

def complete_rag_workflow(tenant_id: str, query: str):
    """完整的 RAG 工作流程"""
    print(f"\n{'='*60}")
    print(f"租户: {tenant_id}")
    print(f"查询: {query}")
    print(f"{'='*60}")

    # 步骤1：生成查询 Embedding
    print("\n步骤1: 生成查询 Embedding")
    query_embedding = get_embedding(query)
    print(f"✓ Embedding 维度: {len(query_embedding)}")

    # 步骤2：检索相关文档
    print("\n步骤2: 检索相关文档")
    documents = rag_system.search_documents(tenant_id, query, top_k=3)
    print(f"✓ 检索到 {len(documents)} 条相关文档")

    for i, doc in enumerate(documents):
        print(f"  {i+1}. {doc['title']} (相似度: {doc['score']:.4f})")

    # 步骤3：构建上下文
    print("\n步骤3: 构建上下文")
    context = [doc["content"] for doc in documents]
    print(f"✓ 上下文长度: {sum(len(c) for c in context)} 字符")

    # 步骤4：LLM 生成答案
    print("\n步骤4: LLM 生成答案")
    answer = generate_answer(query, context)
    print(f"✓ 答案: {answer}")

    # 步骤5：返回结果
    print("\n步骤5: 返回结果")
    result = {
        "query": query,
        "answer": answer,
        "sources": documents
    }
    print(f"✓ 完整结果已生成")

    return result

# 演示完整流程
result = complete_rag_workflow("tech_company", "什么是机器学习？")

# ===== 12. 清理资源 =====
print("\n=== 12. 清理资源 ===")

for partition in collection.partitions:
    if partition.is_loaded:
        partition.release()

connections.disconnect("default")
print("✓ 清理完成")

print("\n=== RAG 多租户知识库演示完成 ===")
```

---

## 运行输出示例

```
=== 1. 连接到 Milvus ===
✓ 连接成功

=== 2. 创建 RAG Collection ===
✓ 创建 Collection: rag_knowledge_base

=== 3. RAG 系统类 ===

=== 4. 注册租户 ===
✓ 租户注册成功: 科技公司 (tech_company)
✓ 租户注册成功: 金融公司 (finance_company)

=== 5. 上传文档到知识库 ===
✓ 为科技公司上传 3 篇文档
✓ 为金融公司上传 3 篇文档

✓ 数据已刷新到磁盘

=== 6. 创建索引 ===
✓ 创建 HNSW 索引

=== 7. 加载租户分区 ===
✓ 加载分区: tenant_tech_company
✓ 加载分区: tenant_finance_company

=== 8. RAG 查询测试 ===

测试1: 科技公司查询
查询: 如何学习 Python 编程？
答案: 基于检索到的 2 条文档，答案是：[模拟生成的答案]

检索到的文档:
  1. Python 编程指南 (相似度: 0.8234)
     内容: Python 是一种高级编程语言，具有简洁的语法和强大的功能。适合初学者学习，也适合专业开发。...
  2. 机器学习入门 (相似度: 0.7156)
     内容: 机器学习是人工智能的一个分支，通过算法让计算机从数据中学习。常见算法包括线性回归、决策树、神经网络等。...

测试2: 金融公司查询
查询: 如何进行风险管理？
答案: 基于检索到的 2 条文档，答案是：[模拟生成的答案]

检索到的文档:
  1. 风险管理策略 (相似度: 0.8567)
     内容: 风险管理是投资的重要环节。包括资产配置、止损策略、对冲工具等方法来控制风险。...
  2. 股票投资基础 (相似度: 0.7234)
     内容: 股票投资是一种常见的理财方式。投资者需要了解公司基本面、技术分析、风险管理等知识。...

=== 9. 租户隔离验证 ===

验证：科技公司查询金融问题
查询: 如何投资股票？
检索到的文档数量: 0
✓ 租户隔离正确：没有检索到其他租户的文档

=== 10. 租户统计 ===

租户统计信息:
  科技公司 (tech_company):
    文档数量: 3
    加载状态: 已加载
  金融公司 (finance_company):
    文档数量: 3
    加载状态: 已加载

=== 11. 完整 RAG 流程演示 ===

============================================================
租户: tech_company
查询: 什么是机器学习？
============================================================

步骤1: 生成查询 Embedding
✓ Embedding 维度: 128

步骤2: 检索相关文档
✓ 检索到 3 条相关文档
  1. 机器学习入门 (相似度: 0.8456)
  2. Python 编程指南 (相似度: 0.7123)
  3. Docker 容器化 (相似度: 0.6234)

步骤3: 构建上下文
✓ 上下文长度: 234 字符

步骤4: LLM 生成答案
✓ 答案: 基于检索到的 3 条文档，答案是：[模拟生成的答案]

步骤5: 返回结果
✓ 完整结果已生成

=== 12. 清理资源 ===
✓ 清理完成

=== RAG 多租户知识库演示完成 ===
```

---

## 关键知识点

### 1. RAG 流程

```
用户查询
  ↓
生成查询 Embedding
  ↓
检索相关文档（Milvus + 分区隔离）
  ↓
构建上下文
  ↓
LLM 生成答案
  ↓
返回结果
```

### 2. 多租户隔离

```python
# 通过分区实现租户隔离
results = collection.search(
    query_embedding,
    partition_names=[f"tenant_{tenant_id}"],  # 强制租户隔离
    limit=top_k
)
```

### 3. 批量上传优化

```python
# 批量生成 Embeddings
embeddings = [get_embedding(doc["content"]) for doc in documents]

# 批量插入
partition.insert([embeddings, contents, titles, ...])
```

### 4. 完整的 RAG 系统

```python
class RAGSystem:
    def onboard_tenant()      # 租户注册
    def upload_document()     # 上传文档
    def search_documents()    # 检索文档
    def rag_query()           # RAG 查询
    def get_tenant_stats()    # 统计信息
```

---

## 实际应用扩展

### 1. 使用真实的 Embedding API

```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def get_embedding(text: str) -> List[float]:
    """使用 OpenAI API 生成 Embedding"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding
```

### 2. 使用真实的 LLM API

```python
def generate_answer(query: str, context: List[str]) -> str:
    """使用 OpenAI API 生成答案"""
    prompt = f"""基于以下文档回答问题：

文档：
{chr(10).join(context)}

问题：{query}

答案："""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
```

### 3. 文档分块

```python
def chunk_document(content: str, chunk_size: int = 500) -> List[str]:
    """将长文档分块"""
    chunks = []
    for i in range(0, len(content), chunk_size):
        chunks.append(content[i:i+chunk_size])
    return chunks
```

### 4. 对话历史管理

```python
class ConversationalRAG(RAGSystem):
    def __init__(self, collection):
        super().__init__(collection)
        self.conversation_history = {}

    def chat(self, tenant_id: str, query: str, session_id: str):
        """支持对话历史的 RAG"""
        # 获取对话历史
        history = self.conversation_history.get(session_id, [])

        # RAG 查询
        result = self.rag_query(tenant_id, query)

        # 更新对话历史
        history.append({"query": query, "answer": result["answer"]})
        self.conversation_history[session_id] = history

        return result
```

---

## 性能优化建议

1. **Embedding 缓存**: 缓存常见查询的 Embedding
2. **批量处理**: 批量上传文档，批量生成 Embedding
3. **异步处理**: 使用异步 API 提升并发性能
4. **结果缓存**: 缓存常见查询的结果
5. **分区策略**: 合理设计分区，优化检索性能

---

## 总结

本示例演示了完整的 RAG 多租户知识库系统：

1. ✅ 多租户注册和分区隔离
2. ✅ 文档上传和向量化
3. ✅ 语义检索
4. ✅ LLM 生成答案
5. ✅ 完整的 RAG 流程
6. ✅ 租户隔离验证

这是一个生产级的 RAG 系统架构，可以直接应用于实际项目。
