# 实战代码 3：错误处理

展示各种错误处理策略的完整可运行代码，包括 OutputFixingParser 和 RetryOutputParser。

---

## 场景 1：基础错误捕获

```python
"""
场景：捕获和处理验证错误
方法：try-except 捕获 ValidationError
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field, ValidationError

load_dotenv()

print("=== 场景 1：基础错误捕获 ===\n")

class Person(BaseModel):
    name: str = Field(description="人名", min_length=1)
    age: int = Field(description="年龄", ge=0, le=150)
    email: str = Field(description="邮箱")

llm = ChatOpenAI(model="gpt-4o", temperature=0)
structured_llm = llm.with_structured_output(Person)

# 测试可能导致错误的输入
test_cases = [
    ("正常输入", "Alice, 25, alice@example.com"),
    ("缺少字段", "Bob, 30"),  # 缺少 email
    ("边界情况", "Charlie, 0, charlie@example.com"),  # 年龄为 0
]

for label, text in test_cases:
    print(f"测试: {label}")
    print(f"输入: {text}")
    try:
        result = structured_llm.invoke(f"提取人物信息：{text}")
        print(f"✅ 成功: {result}\n")
    except ValidationError as e:
        print(f"❌ 验证失败:")
        for error in e.errors():
            print(f"  - 字段 '{error['loc'][0]}': {error['msg']}")
        print()
    except Exception as e:
        print(f"❌ 其他错误: {e}\n")

# 预期输出：
# 测试: 正常输入
# ✅ 成功: Person(name='Alice', age=25, email='alice@example.com')
#
# 测试: 缺少字段
# ✅ 成功: Person(name='Bob', age=30, email='bob@example.com')  # LLM 可能推测
```

---

## 场景 2：OutputFixingParser 自动修复

```python
"""
场景：使用 OutputFixingParser 自动修复错误
方法：包装基础 Parser
"""

print("=== 场景 2：OutputFixingParser 自动修复 ===\n")

from langchain.output_parsers import OutputFixingParser, PydanticOutputParser
from langchain.prompts import PromptTemplate

# 1. 创建基础解析器
base_parser = PydanticOutputParser(pydantic_object=Person)

# 2. 包装为修复解析器
fixing_parser = OutputFixingParser.from_llm(
    parser=base_parser,
    llm=llm
)

# 3. 创建 Prompt
prompt = PromptTemplate(
    template="提取人物信息：{text}\n\n{format_instructions}",
    input_variables=["text"],
    partial_variables={"format_instructions": base_parser.get_format_instructions()}
)

# 4. 构建链
chain = prompt | llm | fixing_parser

# 5. 测试错误输出（模拟 LLM 返回错误格式）
print("测试 1：类型错误（age 是字符串）")
# 注意：实际使用中，LLM 通常会返回正确格式
# 这里我们手动测试 fixing_parser 的修复能力
bad_output = '{"name": "Alice", "age": "twenty-five", "email": "alice@example.com"}'
try:
    result = fixing_parser.parse(bad_output)
    print(f"✅ 修复成功: {result}\n")
except Exception as e:
    print(f"❌ 修复失败: {e}\n")

print("测试 2：字段缺失")
bad_output = '{"name": "Bob", "age": 30}'  # 缺少 email
try:
    result = fixing_parser.parse(bad_output)
    print(f"✅ 修复成功: {result}\n")
except Exception as e:
    print(f"❌ 修复失败: {e}\n")

print("测试 3：完全错误的格式")
bad_output = 'The person is Charlie, 35 years old'  # 不是 JSON
try:
    result = fixing_parser.parse(bad_output)
    print(f"✅ 修复成功: {result}\n")
except Exception as e:
    print(f"❌ 修复失败: {e}\n")

# 预期输出：
# 测试 1：类型错误
# ✅ 修复成功: Person(name='Alice', age=25, email='alice@example.com')
```

---

## 场景 3：RetryOutputParser 重试机制

```python
"""
场景：使用 RetryOutputParser 重试失败的解析
方法：重新调用 LLM
"""

print("=== 场景 3：RetryOutputParser 重试机制 ===\n")

from langchain.output_parsers import RetryWithErrorOutputParser

# 1. 创建重试解析器
retry_parser = RetryWithErrorOutputParser.from_llm(
    parser=base_parser,
    llm=llm,
    max_retries=3
)

# 2. 测试（需要提供 Prompt）
prompt_value = prompt.format_prompt(text="Alice, 25, alice@example.com")

print("测试：重试解析")
# 模拟错误输出
bad_output = '{"name": "Alice", "age": "invalid"}'
try:
    result = retry_parser.parse_with_prompt(bad_output, prompt_value)
    print(f"✅ 重试成功: {result}\n")
except Exception as e:
    print(f"❌ 重试失败（已重试 3 次）: {e}\n")

# 预期输出：
# ✅ 重试成功: Person(name='Alice', age=25, email='alice@example.com')
```

---

## 场景 4：监控修复率

```python
"""
场景：监控 OutputFixingParser 的修复率
方法：自定义包装类
"""

print("=== 场景 4：监控修复率 ===\n")

class MonitoredFixingParser(OutputFixingParser):
    """带监控的修复解析器"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.total_calls = 0
        self.fix_calls = 0
        self.fix_details = []

    def parse(self, completion: str):
        self.total_calls += 1
        try:
            # 尝试直接解析
            result = self.parser.parse(completion)
            self.fix_details.append({
                'input': completion[:50],
                'fixed': False,
                'success': True
            })
            return result
        except Exception as e:
            # 需要修复
            self.fix_calls += 1
            try:
                # 调用 LLM 修复
                fix_prompt = f"""
原始输出有错误：
{completion}

错误信息：
{str(e)}

请修复输出，使其符合以下格式：
{self.parser.get_format_instructions()}
"""
                fixed_output = self.llm.invoke(fix_prompt)
                result = self.parser.parse(fixed_output.content)
                self.fix_details.append({
                    'input': completion[:50],
                    'fixed': True,
                    'success': True
                })
                return result
            except Exception as fix_error:
                self.fix_details.append({
                    'input': completion[:50],
                    'fixed': True,
                    'success': False,
                    'error': str(fix_error)
                })
                raise

    @property
    def fix_rate(self):
        """修复率"""
        return self.fix_calls / self.total_calls if self.total_calls > 0 else 0

    def print_stats(self):
        """打印统计信息"""
        print(f"总调用次数: {self.total_calls}")
        print(f"需要修复次数: {self.fix_calls}")
        print(f"修复率: {self.fix_rate:.2%}")
        if self.fix_rate > 0.2:
            print("⚠️  修复率 > 20%，建议优化 Prompt")

# 使用监控解析器
monitored_parser = MonitoredFixingParser.from_llm(
    parser=base_parser,
    llm=llm
)

# 测试多个输入
test_outputs = [
    '{"name": "Alice", "age": 25, "email": "alice@example.com"}',  # 正确
    '{"name": "Bob", "age": "thirty", "email": "bob@test.com"}',  # 类型错误
    '{"name": "Charlie", "age": 35, "email": "charlie@example.com"}',  # 正确
    'Person: David, 40',  # 格式错误
]

print("处理测试数据...\n")
for i, output in enumerate(test_outputs, 1):
    print(f"测试 {i}: {output[:40]}...")
    try:
        result = monitored_parser.parse(output)
        print(f"  ✅ 成功: {result.name}, {result.age}")
    except Exception as e:
        print(f"  ❌ 失败: {e}")
    print()

# 打印统计
print("=" * 50)
monitored_parser.print_stats()
print("=" * 50)

# 预期输出：
# 总调用次数: 4
# 需要修复次数: 2
# 修复率: 50.00%
# ⚠️  修复率 > 20%，建议优化 Prompt
```

---

## 场景 5：降级策略

```python
"""
场景：多层降级策略
方法：先尝试直接解析，失败后尝试修复，再失败则使用默认值
"""

print("=== 场景 5：降级策略 ===\n")

from typing import Optional

def parse_with_fallback(
    text: str,
    parser: PydanticOutputParser,
    llm: ChatOpenAI,
    default: Optional[Person] = None
) -> Optional[Person]:
    """
    多层降级解析策略

    1. 尝试直接解析
    2. 失败 → 使用 OutputFixingParser 修复
    3. 再失败 → 返回默认值
    """
    # 策略 1：直接解析
    try:
        prompt = PromptTemplate(
            template="提取：{text}\n\n{format_instructions}",
            input_variables=["text"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        chain = prompt | llm | parser
        result = chain.invoke({"text": text})
        print(f"  ✅ 策略 1 成功（直接解析）")
        return result
    except Exception as e1:
        print(f"  ❌ 策略 1 失败: {str(e1)[:50]}")

        # 策略 2：修复解析
        try:
            fixing_parser = OutputFixingParser.from_llm(parser, llm)
            chain = prompt | llm | fixing_parser
            result = chain.invoke({"text": text})
            print(f"  ✅ 策略 2 成功（修复解析）")
            return result
        except Exception as e2:
            print(f"  ❌ 策略 2 失败: {str(e2)[:50]}")

            # 策略 3：返回默认值
            if default:
                print(f"  ⚠️  策略 3：使用默认值")
                return default
            else:
                print(f"  ❌ 所有策略都失败，返回 None")
                return None

# 测试降级策略
default_person = Person(name="Unknown", age=0, email="unknown@example.com")

test_cases = [
    "Alice, 25, alice@example.com",  # 应该策略 1 成功
    "Bob, thirty years old",  # 可能需要策略 2
    "Invalid data xyz",  # 可能需要策略 3
]

for text in test_cases:
    print(f"\n输入: {text}")
    result = parse_with_fallback(text, base_parser, llm, default_person)
    if result:
        print(f"最终结果: {result}")

# 预期输出：
# 输入: Alice, 25, alice@example.com
#   ✅ 策略 1 成功（直接解析）
# 最终结果: Person(name='Alice', age=25, email='alice@example.com')
```

---

## 场景 6：批量处理with错误处理

```python
"""
场景：批量处理时的错误处理
方法：记录成功和失败的条目
"""

print("=== 场景 6：批量处理with错误处理 ===\n")

def batch_parse_with_error_handling(
    texts: list[str],
    parser: PydanticOutputParser,
    llm: ChatOpenAI
) -> dict:
    """
    批量解析with错误处理

    返回：
    {
        'success': [成功的结果],
        'failed': [失败的条目],
        'stats': {统计信息}
    }
    """
    results = {
        'success': [],
        'failed': [],
        'stats': {
            'total': len(texts),
            'success_count': 0,
            'failed_count': 0
        }
    }

    prompt = PromptTemplate(
        template="提取：{text}\n\n{format_instructions}",
        input_variables=["text"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    chain = prompt | llm | parser

    for i, text in enumerate(texts, 1):
        try:
            result = chain.invoke({"text": text})
            results['success'].append({
                'index': i,
                'input': text,
                'output': result
            })
            results['stats']['success_count'] += 1
            print(f"  ✅ {i}/{len(texts)}: {result.name}")
        except Exception as e:
            results['failed'].append({
                'index': i,
                'input': text,
                'error': str(e)
            })
            results['stats']['failed_count'] += 1
            print(f"  ❌ {i}/{len(texts)}: {str(e)[:50]}")

    return results

# 测试批量处理
texts = [
    "Alice, 25, alice@example.com",
    "Bob, 30, bob@test.com",
    "Charlie, 35, charlie@company.org",
    "Invalid data",
    "David, 40, david@example.com"
]

print(f"批量处理 {len(texts)} 条数据...\n")
results = batch_parse_with_error_handling(texts, base_parser, llm)

print("\n" + "=" * 50)
print("统计信息:")
print(f"  总数: {results['stats']['total']}")
print(f"  成功: {results['stats']['success_count']}")
print(f"  失败: {results['stats']['failed_count']}")
print(f"  成功率: {results['stats']['success_count'] / results['stats']['total']:.2%}")

if results['failed']:
    print("\n失败的条目:")
    for item in results['failed']:
        print(f"  - 第 {item['index']} 条: {item['input'][:30]}...")
        print(f"    错误: {item['error'][:50]}")

# 预期输出：
# 批量处理 5 条数据...
#   ✅ 1/5: Alice
#   ✅ 2/5: Bob
#   ✅ 3/5: Charlie
#   ❌ 4/5: Validation error...
#   ✅ 5/5: David
#
# 统计信息:
#   总数: 5
#   成功: 4
#   失败: 1
#   成功率: 80.00%
```

---

## 完整运行示例

```python
"""
完整示例：运行所有错误处理场景
"""

def main():
    """运行所有错误处理场景"""
    print("=" * 60)
    print("OutputParser 错误处理演示")
    print("=" * 60)
    print()

    # 场景 1-6 的代码...
    # （在实际运行时，将上面所有场景的代码整合到这里）

    print("=" * 60)
    print("所有错误处理场景演示完成！")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

---

## 关键要点

1. **基础捕获**：使用 try-except 捕获 ValidationError
2. **自动修复**：OutputFixingParser 调用 LLM 修复错误
3. **重试机制**：RetryOutputParser 重新生成输出
4. **监控修复率**：如果 > 20%，应优化 Prompt
5. **降级策略**：多层降级确保鲁棒性
6. **批量处理**：记录成功和失败，提供统计信息

---

## 错误处理最佳实践

### 1. 优先级

```
1. 优化 Prompt（降低错误率）
2. 使用 with_structured_output()（最可靠）
3. 基础错误捕获（try-except）
4. OutputFixingParser（高价值任务）
5. RetryOutputParser（临时性错误）
```

### 2. 成本考量

- **无修复**：成本最低，但可能失败
- **OutputFixingParser**：成本 +50%，可靠性高
- **RetryOutputParser**：成本 +100%，适合临时错误

### 3. 监控指标

- **修复率**：如果 > 20%，优化 Prompt
- **成功率**：目标 > 95%
- **平均重试次数**：目标 < 0.5

---

**记住**：错误处理不是"银弹"，应该优先优化 Prompt 降低错误率！
