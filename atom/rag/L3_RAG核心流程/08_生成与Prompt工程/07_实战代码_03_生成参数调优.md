# 实战代码3：生成参数调优

> Temperature、Top-P、Max Tokens的实战调优

---

## 代码示例

```python
"""
生成参数调优实战
演示：Temperature、Top-P、Top-K、Max Tokens的实际效果
"""

from openai import OpenAI
import os
from typing import Dict, List

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===== 1. Temperature对比实验 =====

def temperature_comparison():
    """
    Temperature参数对比实验
    """
    print("=== Temperature对比实验 ===\n")
    
    prompt = "Python是一种什么语言？请用一句话回答。"
    
    temperatures = [0.0, 0.3, 0.7, 1.0]
    
    for temp in temperatures:
        print(f"Temperature = {temp}:")
        
        # 生成3次，观察一致性
        responses = []
        for i in range(3):
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=temp,
                max_tokens=50
            )
            responses.append(response.choices[0].message.content)
        
        print(f"  第1次: {responses[0]}")
        print(f"  第2次: {responses[1]}")
        print(f"  第3次: {responses[2]}")
        
        # 检查一致性
        if responses[0] == responses[1] == responses[2]:
            print("  一致性: 完全相同 ✓")
        elif responses[0] == responses[1] or responses[1] == responses[2]:
            print("  一致性: 部分相同")
        else:
            print("  一致性: 完全不同")
        
        print()

# ===== 2. RAG场景Temperature推荐 =====

class RAGTemperatureOptimizer:
    """
    RAG场景Temperature优化器
    """
    
    def __init__(self):
        self.task_temperatures = {
            "factual_qa": 0.1,
            "summarization": 0.2,
            "rewriting": 0.6,
            "creative": 0.8,
            "code": 0.2
        }
    
    def get_temperature(self, task_type: str) -> float:
        """获取推荐Temperature"""
        return self.task_temperatures.get(task_type, 0.3)
    
    def generate_with_optimal_temp(
        self,
        prompt: str,
        task_type: str
    ) -> Dict:
        """使用最优Temperature生成"""
        temp = self.get_temperature(task_type)
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=temp
        )
        
        return {
            "answer": response.choices[0].message.content,
            "temperature": temp,
            "task_type": task_type
        }

def rag_temperature_example():
    """
    RAG场景Temperature示例
    """
    print("=== RAG场景Temperature推荐 ===\n")
    
    optimizer = RAGTemperatureOptimizer()
    
    # 事实性问答
    result1 = optimizer.generate_with_optimal_temp(
        "Python是什么？",
        "factual_qa"
    )
    print(f"事实性问答 (temp={result1['temperature']}):")
    print(f"  {result1['answer']}\n")
    
    # 内容总结
    result2 = optimizer.generate_with_optimal_temp(
        "总结：Python是一种解释型、面向对象的编程语言。",
        "summarization"
    )
    print(f"内容总结 (temp={result2['temperature']}):")
    print(f"  {result2['answer']}\n")

# ===== 3. Top-P实验 =====

def top_p_comparison():
    """
    Top-P参数对比实验
    """
    print("=== Top-P对比实验 ===\n")
    
    prompt = "用3个词描述Python的特点："
    
    top_p_values = [0.1, 0.5, 0.9, 1.0]
    
    for top_p in top_p_values:
        print(f"Top-P = {top_p}:")
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,  # 固定temperature
            top_p=top_p,
            max_tokens=30
        )
        
        print(f"  {response.choices[0].message.content}\n")

# ===== 4. Temperature + Top-P组合 =====

def temp_topp_combination():
    """
    Temperature和Top-P组合实验
    """
    print("=== Temperature + Top-P组合 ===\n")
    
    prompt = "Python的优点是什么？"
    
    combinations = [
        {"temp": 0.1, "top_p": 0.9, "desc": "RAG推荐配置"},
        {"temp": 0.7, "top_p": 0.95, "desc": "创意模式"},
        {"temp": 0.1, "top_p": 0.5, "desc": "极度保守"},
        {"temp": 0.9, "top_p": 0.5, "desc": "不推荐"}
    ]
    
    for combo in combinations:
        print(f"{combo['desc']} (temp={combo['temp']}, top_p={combo['top_p']}):")
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=combo["temp"],
            top_p=combo["top_p"],
            max_tokens=100
        )
        
        print(f"  {response.choices[0].message.content}\n")

# ===== 5. Max Tokens控制 =====

def max_tokens_control():
    """
    Max Tokens控制实验
    """
    print("=== Max Tokens控制 ===\n")
    
    prompt = "详细解释Python的特点："
    
    max_tokens_values = [20, 50, 100, 200]
    
    for max_tokens in max_tokens_values:
        print(f"Max Tokens = {max_tokens}:")
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=max_tokens
        )
        
        answer = response.choices[0].message.content
        actual_tokens = response.usage.completion_tokens
        
        print(f"  实际tokens: {actual_tokens}")
        print(f"  内容: {answer}\n")

# ===== 6. 自适应参数选择 =====

class AdaptiveParameterSelector:
    """
    自适应参数选择器
    """
    
    def select_parameters(
        self,
        task_type: str,
        domain: str,
        context_quality: float
    ) -> Dict:
        """
        根据任务、领域、上下文质量选择参数
        """
        # 基础配置
        params = {
            "temperature": 0.3,
            "top_p": 0.95,
            "max_tokens": 200
        }
        
        # 任务类型调整
        if task_type == "factual_qa":
            params["temperature"] = 0.1
            params["max_tokens"] = 150
        elif task_type == "summarization":
            params["temperature"] = 0.2
            params["max_tokens"] = 300
        elif task_type == "creative":
            params["temperature"] = 0.7
            params["max_tokens"] = 500
        
        # 领域调整
        if domain in ["medical", "legal", "financial"]:
            params["temperature"] = max(0.1, params["temperature"] - 0.1)
        
        # 上下文质量调整
        if context_quality < 0.7:
            params["temperature"] = max(0.1, params["temperature"] - 0.2)
        
        return params

def adaptive_parameter_example():
    """
    自适应参数选择示例
    """
    print("=== 自适应参数选择 ===\n")
    
    selector = AdaptiveParameterSelector()
    
    scenarios = [
        {
            "task": "factual_qa",
            "domain": "medical",
            "quality": 0.85,
            "prompt": "什么是高血压？"
        },
        {
            "task": "creative",
            "domain": "general",
            "quality": 0.9,
            "prompt": "写一个关于AI的故事"
        },
        {
            "task": "factual_qa",
            "domain": "general",
            "quality": 0.6,
            "prompt": "Python有什么特点？"
        }
    ]
    
    for scenario in scenarios:
        params = selector.select_parameters(
            scenario["task"],
            scenario["domain"],
            scenario["quality"]
        )
        
        print(f"场景: {scenario['task']}, {scenario['domain']}, 质量={scenario['quality']}")
        print(f"参数: {params}")
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": scenario["prompt"]}],
            **params
        )
        
        print(f"答案: {response.choices[0].message.content}\n")

# ===== 7. A/B测试框架 =====

class ParameterABTest:
    """
    参数A/B测试框架
    """
    
    def run_test(
        self,
        prompt: str,
        config_a: Dict,
        config_b: Dict,
        iterations: int = 5
    ) -> Dict:
        """
        运行A/B测试
        """
        results_a = []
        results_b = []
        
        for i in range(iterations):
            # 配置A
            response_a = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                **config_a
            )
            results_a.append({
                "answer": response_a.choices[0].message.content,
                "tokens": response_a.usage.completion_tokens
            })
            
            # 配置B
            response_b = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                **config_b
            )
            results_b.append({
                "answer": response_b.choices[0].message.content,
                "tokens": response_b.usage.completion_tokens
            })
        
        return {
            "config_a": {
                "params": config_a,
                "results": results_a,
                "avg_tokens": sum(r["tokens"] for r in results_a) / iterations
            },
            "config_b": {
                "params": config_b,
                "results": results_b,
                "avg_tokens": sum(r["tokens"] for r in results_b) / iterations
            }
        }

def ab_test_example():
    """
    A/B测试示例
    """
    print("=== A/B测试 ===\n")
    
    tester = ParameterABTest()
    
    config_a = {"temperature": 0.1, "top_p": 0.9, "max_tokens": 100}
    config_b = {"temperature": 0.3, "top_p": 0.95, "max_tokens": 100}
    
    results = tester.run_test(
        "Python有什么特点？",
        config_a,
        config_b,
        iterations=3
    )
    
    print("配置A (temp=0.1, top_p=0.9):")
    print(f"  平均tokens: {results['config_a']['avg_tokens']:.1f}")
    for i, r in enumerate(results['config_a']['results']):
        print(f"  第{i+1}次: {r['answer'][:50]}...")
    
    print("\n配置B (temp=0.3, top_p=0.95):")
    print(f"  平均tokens: {results['config_b']['avg_tokens']:.1f}")
    for i, r in enumerate(results['config_b']['results']):
        print(f"  第{i+1}次: {r['answer'][:50]}...")

# ===== 8. 生产环境配置 =====

class ProductionParameterConfig:
    """
    生产环境参数配置
    """
    
    def __init__(self):
        self.configs = {
            "strict_factual": {
                "temperature": 0.1,
                "top_p": 0.9,
                "max_tokens": 200,
                "description": "严格事实性（医疗/法律）"
            },
            "balanced": {
                "temperature": 0.3,
                "top_p": 0.95,
                "max_tokens": 300,
                "description": "平衡模式（一般问答）"
            },
            "creative": {
                "temperature": 0.7,
                "top_p": 0.95,
                "max_tokens": 500,
                "description": "创意模式（内容生成）"
            }
        }
    
    def get_config(self, config_name: str) -> Dict:
        """获取配置"""
        return self.configs.get(config_name, self.configs["balanced"])
    
    def list_configs(self):
        """列出所有配置"""
        for name, config in self.configs.items():
            print(f"{name}:")
            print(f"  {config['description']}")
            print(f"  temperature={config['temperature']}, top_p={config['top_p']}, max_tokens={config['max_tokens']}")

def production_config_example():
    """
    生产环境配置示例
    """
    print("=== 生产环境配置 ===\n")
    
    config_manager = ProductionParameterConfig()
    
    config_manager.list_configs()
    
    print("\n使用strict_factual配置:")
    config = config_manager.get_config("strict_factual")
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": "什么是RAG？"}],
        temperature=config["temperature"],
        top_p=config["top_p"],
        max_tokens=config["max_tokens"]
    )
    
    print(f"答案: {response.choices[0].message.content}")

# ===== 运行所有示例 =====

if __name__ == "__main__":
    temperature_comparison()
    rag_temperature_example()
    top_p_comparison()
    temp_topp_combination()
    max_tokens_control()
    adaptive_parameter_example()
    ab_test_example()
    production_config_example()
```

---

## 关键要点

1. **Temperature**：事实性0.1-0.2，创意性0.7-0.9
2. **Top-P**：RAG推荐0.9-0.95
3. **Max Tokens**：根据任务类型调整
4. **组合优化**：Temperature + Top-P协同调整
5. **A/B测试**：实验验证最佳配置

---

**版本：** v1.0
**最后更新：** 2026-02-16
