# 实战代码：多策略缓解

> 完整可运行的多策略缓解示例，演示如何构建多层防护的 RAG 系统

---

## 场景说明

**目标：** 构建一个完整的多层防护系统，在检索、生成、验证各阶段降低幻觉风险

**应用场景：**
- 高风险场景（医疗、法律、金融）
- 生产环境的 RAG 系统
- 需要高可信度的问答系统

**技术栈：**
- `openai`：LLM 生成
- `sentence-transformers`：NLI 检测和语义相似度
- `chromadb`：向量存储（可选）

---

## 完整代码

```python
"""
多策略缓解实战示例
演示：如何构建多层防护的 RAG 系统
"""

from sentence_transformers import CrossEncoder, SentenceTransformer, util
from openai import OpenAI
import os
import numpy as np
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum

# ===== 配置 =====
class RiskLevel(Enum):
    """风险等级"""
    HIGH = "high"        # 医疗、法律
    MEDIUM = "medium"    # 客服、问答
    LOW = "low"          # 推荐、娱乐

@dataclass
class ScenarioConfig:
    """场景配置"""
    name: str
    risk_level: RiskLevel
    consistency_threshold: float
    min_retrieval_score: float
    temperature: float
    require_citations: bool
    fallback_message: str

# 预定义场景配置
SCENARIO_CONFIGS = {
    "medical": ScenarioConfig(
        name="医疗问答",
        risk_level=RiskLevel.HIGH,
        consistency_threshold=0.9,
        min_retrieval_score=0.8,
        temperature=0.0,
        require_citations=True,
        fallback_message="抱歉，我对这个答案不够确定。请咨询专业医生。"
    ),
    "legal": ScenarioConfig(
        name="法律咨询",
        risk_level=RiskLevel.HIGH,
        consistency_threshold=0.85,
        min_retrieval_score=0.75,
        temperature=0.1,
        require_citations=True,
        fallback_message="抱歉，我对这个答案不够确定。请咨询专业律师。"
    ),
    "customer_service": ScenarioConfig(
        name="客服问答",
        risk_level=RiskLevel.MEDIUM,
        consistency_threshold=0.7,
        min_retrieval_score=0.6,
        temperature=0.3,
        require_citations=False,
        fallback_message="让我为您转接人工客服。"
    ),
    "general": ScenarioConfig(
        name="一般问答",
        risk_level=RiskLevel.MEDIUM,
        consistency_threshold=0.7,
        min_retrieval_score=0.6,
        temperature=0.3,
        require_citations=False,
        fallback_message="抱歉，我对这个答案不够确定。"
    )
}

# ===== 多层防护系统 =====
class MultiLayerProtectionSystem:
    """
    多层防护系统
    在检索、生成、验证各阶段设置防护
    """

    def __init__(self, api_key: str):
        """初始化系统"""
        print("[初始化] 多层防护系统")
        self.client = OpenAI(api_key=api_key)
        self.nli_model = CrossEncoder('cross-encoder/nli-deberta-v3-base')
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
        print("[初始化] ✓ 系统初始化完成\n")

    def layer1_filter_retrieval(
        self,
        docs: List[Dict],
        config: ScenarioConfig
    ) -> List[Dict]:
        """
        第1层：检索质量过滤
        """
        print(f"[第1层] 检索质量过滤（阈值: {config.min_retrieval_score}）")

        filtered = []
        for doc in docs:
            score = doc.get('score', 0)
            content = doc.get('content', '')

            # 检查1：相似度分数
            if score < config.min_retrieval_score:
                print(f"  ✗ 过滤: 分数过低 ({score:.2f})")
                continue

            # 检查2：文档长度
            if len(content) < 50:
                print(f"  ✗ 过滤: 文档过短 ({len(content)} 字符)")
                continue

            filtered.append(doc)
            print(f"  ✓ 保留: {content[:30]}... (分数: {score:.2f})")

        print(f"[第1层] ✓ 过滤完成，保留 {len(filtered)}/{len(docs)} 个文档\n")
        return filtered

    def layer2_constrained_generation(
        self,
        query: str,
        docs: List[Dict],
        config: ScenarioConfig
    ) -> str:
        """
        第2层：约束生成
        """
        print(f"[第2层] 约束生成（温度: {config.temperature}）")

        # 构建严格的 Prompt
        context = "\n\n".join([
            f"文档{i+1}: {doc['content']}"
            for i, doc in enumerate(docs)
        ])

        citation_requirement = ""
        if config.require_citations:
            citation_requirement = "\n2. 每个事实都要标注来源 [1], [2]"

        prompt = f"""基于以下文档回答问题，严格遵守要求。

{context}

问题：{query}

严格要求：
1. 只使用文档中的信息，不要添加任何文档外的内容{citation_requirement}
3. 如果文档中没有答案，明确说"文档中没有相关信息"
4. 不要推测、猜测或编造任何信息

答案："""

        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=config.temperature
        )

        answer = response.choices[0].message.content
        print(f"[第2层] ✓ 答案生成完成\n")
        return answer

    def layer3_consistency_check(
        self,
        answer: str,
        docs: List[Dict]
    ) -> float:
        """
        第3层：一致性检测
        """
        print("[第3层] 一致性检测")

        # 方法1：NLI 检测（50%权重）
        nli_scores = []
        for doc in docs:
            scores = self.nli_model.predict([(doc['content'], answer)])
            nli_scores.append(scores[0][2])

        nli_score = max(nli_scores) if nli_scores else 0.0
        print(f"  NLI 分数: {nli_score:.2f}")

        # 方法2：关键词匹配（30%权重）
        answer_words = set(answer.lower().split())
        doc_words = set()
        for doc in docs:
            doc_words.update(doc['content'].lower().split())

        keyword_coverage = len(answer_words & doc_words) / len(answer_words) if answer_words else 0.0
        print(f"  关键词覆盖率: {keyword_coverage:.2f}")

        # 方法3：语义相似度（20%权重）
        answer_emb = self.encoder.encode(answer)
        doc_embs = self.encoder.encode([doc['content'] for doc in docs])
        similarities = util.cos_sim(answer_emb, doc_embs)[0].numpy()
        semantic_sim = float(np.max(similarities)) if len(similarities) > 0 else 0.0
        print(f"  语义相似度: {semantic_sim:.2f}")

        # 综合评分
        consistency = (
            nli_score * 0.5 +
            keyword_coverage * 0.3 +
            semantic_sim * 0.2
        )
        print(f"  综合一致性: {consistency:.2f}")
        print(f"[第3层] ✓ 一致性检测完成\n")

        return consistency

    def layer4_confidence_decision(
        self,
        answer: str,
        consistency: float,
        config: ScenarioConfig
    ) -> Dict:
        """
        第4层：置信度决策
        """
        print(f"[第4层] 置信度决策（阈值: {config.consistency_threshold}）")

        threshold = config.consistency_threshold

        if consistency >= threshold:
            status = "approved"
            final_answer = answer
            message = "通过所有防护层"
            print(f"  ✓ 通过 ({consistency:.2f} >= {threshold})")
        elif consistency >= threshold - 0.2:
            status = "warning"
            final_answer = f"（不太确定）{answer}"
            message = "置信度较低，建议谨慎参考"
            print(f"  ⚠ 警告 ({consistency:.2f})")
        else:
            status = "rejected"
            final_answer = config.fallback_message
            message = "未通过一致性检测"
            print(f"  ✗ 拒绝 ({consistency:.2f} < {threshold})")

        print(f"[第4层] ✓ 决策完成\n")

        return {
            "status": status,
            "answer": final_answer,
            "original_answer": answer,
            "consistency": consistency,
            "message": message
        }

    def process(
        self,
        query: str,
        docs: List[Dict],
        scenario: str = "general"
    ) -> Dict:
        """
        完整的多层防护流程

        Args:
            query: 用户查询
            docs: 检索到的文档
            scenario: 场景名称

        Returns:
            处理结果
        """
        config = SCENARIO_CONFIGS.get(scenario, SCENARIO_CONFIGS["general"])

        print("=" * 60)
        print(f"场景: {config.name} ({config.risk_level.value})")
        print(f"查询: {query}")
        print(f"检索到 {len(docs)} 个文档")
        print("=" * 60 + "\n")

        # 第1层：检索质量过滤
        filtered_docs = self.layer1_filter_retrieval(docs, config)

        if len(filtered_docs) == 0:
            return {
                "status": "no_docs",
                "answer": "没有找到相关信息",
                "consistency": 0.0,
                "scenario": scenario,
                "message": "检索质量过滤后无可用文档"
            }

        # 第2层：约束生成
        answer = self.layer2_constrained_generation(query, filtered_docs, config)

        # 第3层：一致性检测
        consistency = self.layer3_consistency_check(answer, filtered_docs)

        # 第4层：置信度决策
        result = self.layer4_confidence_decision(answer, consistency, config)

        # 添加元数据
        result["scenario"] = scenario
        result["config"] = config
        result["filtered_docs_count"] = len(filtered_docs)
        result["original_docs_count"] = len(docs)

        return result


# ===== 测试用例 =====
def test_case_1_high_risk_scenario():
    """
    测试用例1：高风险场景（医疗）
    """
    print("\n" + "=" * 60)
    print("测试用例1：高风险场景（医疗问答）")
    print("=" * 60 + "\n")

    system = MultiLayerProtectionSystem(api_key=os.getenv("OPENAI_API_KEY"))

    docs = [
        {
            "content": "阿司匹林是一种常用的解热镇痛药，用于缓解轻至中度疼痛。",
            "score": 0.88
        },
        {
            "content": "阿司匹林也用于预防心血管疾病，但需要在医生指导下使用。",
            "score": 0.85
        },
        {
            "content": "阿司匹林可能引起胃肠道不适等副作用。",
            "score": 0.82
        }
    ]

    query = "阿司匹林有什么作用？"

    result = system.process(query, docs, scenario="medical")

    print_result(result)


def test_case_2_medium_risk_scenario():
    """
    测试用例2：中风险场景（客服）
    """
    print("\n" + "=" * 60)
    print("测试用例2：中风险场景（客服问答）")
    print("=" * 60 + "\n")

    system = MultiLayerProtectionSystem(api_key=os.getenv("OPENAI_API_KEY"))

    docs = [
        {
            "content": "我们的退货政策允许在购买后30天内退货。",
            "score": 0.75
        },
        {
            "content": "退货时需要保持商品原包装完好。",
            "score": 0.72
        },
        {
            "content": "这是一个不太相关的文档。",
            "score": 0.45  # 低分，会被过滤
        }
    ]

    query = "你们的退货政策是什么？"

    result = system.process(query, docs, scenario="customer_service")

    print_result(result)


def test_case_3_low_quality_docs():
    """
    测试用例3：低质量文档（会被过滤）
    """
    print("\n" + "=" * 60)
    print("测试用例3：低质量文档过滤")
    print("=" * 60 + "\n")

    system = MultiLayerProtectionSystem(api_key=os.getenv("OPENAI_API_KEY"))

    docs = [
        {
            "content": "这是一个很短的文档",
            "score": 0.65
        },
        {
            "content": "另一个不相关的文档",
            "score": 0.40
        }
    ]

    query = "Python 3.9 有什么新特性？"

    result = system.process(query, docs, scenario="general")

    print_result(result)


def test_case_4_scenario_comparison():
    """
    测试用例4：不同场景对比
    """
    print("\n" + "=" * 60)
    print("测试用例4：不同场景对比")
    print("=" * 60 + "\n")

    system = MultiLayerProtectionSystem(api_key=os.getenv("OPENAI_API_KEY"))

    docs = [
        {
            "content": "Python 3.9 于 2020 年 10 月发布。",
            "score": 0.75
        },
        {
            "content": "Python 3.9 新增了字典合并运算符。",
            "score": 0.72
        }
    ]

    query = "Python 3.9 有什么新特性？"

    # 测试不同场景
    for scenario in ["medical", "customer_service", "general"]:
        print(f"\n{'='*60}")
        print(f"场景: {scenario}")
        print(f"{'='*60}\n")

        result = system.process(query, docs, scenario=scenario)

        print(f"状态: {result['status']}")
        print(f"一致性: {result['consistency']:.2f}")
        print(f"阈值: {result['config'].consistency_threshold}")
        print(f"答案: {result['answer'][:100]}...")


# ===== 工具函数 =====
def print_result(result: Dict):
    """
    打印结果

    Args:
        result: 处理结果
    """
    print("\n" + "=" * 60)
    print("最终结果")
    print("=" * 60)
    print(f"场景: {result['scenario']}")
    print(f"状态: {result['status']}")
    print(f"消息: {result['message']}")
    print(f"一致性分数: {result['consistency']:.2f}")

    if 'filtered_docs_count' in result:
        print(f"文档过滤: {result['original_docs_count']} → {result['filtered_docs_count']}")

    print(f"\n最终答案:\n{result['answer']}")

    if result.get('original_answer') and result['original_answer'] != result['answer']:
        print(f"\n原始答案:\n{result['original_answer']}")

    print("=" * 60)


# ===== 主函数 =====
def main():
    """
    主函数：运行所有测试用例
    """
    print("\n" + "=" * 60)
    print("多策略缓解实战示例")
    print("=" * 60 + "\n")

    # 检查环境变量
    if not os.getenv("OPENAI_API_KEY"):
        print("错误：未设置 OPENAI_API_KEY 环境变量")
        print("请运行：export OPENAI_API_KEY='your-api-key'")
        return

    try:
        # 测试用例1：高风险场景
        test_case_1_high_risk_scenario()

        # 测试用例2：中风险场景
        # test_case_2_medium_risk_scenario()

        # 测试用例3：低质量文档
        # test_case_3_low_quality_docs()

        # 测试用例4：场景对比
        # test_case_4_scenario_comparison()

    except Exception as e:
        print(f"\n[错误] {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
```

---

## 运行说明

### 1. 安装依赖

```bash
pip install openai sentence-transformers
```

### 2. 设置环境变量

```bash
export OPENAI_API_KEY='your-api-key-here'
```

### 3. 运行代码

```bash
python 11_实战代码_多策略缓解.py
```

---

## 预期输出

```
============================================================
多策略缓解实战示例
============================================================

[初始化] 多层防护系统
[初始化] ✓ 系统初始化完成

============================================================
测试用例1：高风险场景（医疗问答）
============================================================

============================================================
场景: 医疗问答 (high)
查询: 阿司匹林有什么作用？
检索到 3 个文档
============================================================

[第1层] 检索质量过滤（阈值: 0.8）
  ✓ 保留: 阿司匹林是一种常用的解热镇痛药，用于缓解轻至中度疼痛。... (分数: 0.88)
  ✓ 保留: 阿司匹林也用于预防心血管疾病，但需要在医生指导下使用。... (分数: 0.85)
  ✓ 保留: 阿司匹林可能引起胃肠道不适等副作用。... (分数: 0.82)
[第1层] ✓ 过滤完成，保留 3/3 个文档

[第2层] 约束生成（温度: 0.0）
[第2层] ✓ 答案生成完成

[第3层] 一致性检测
  NLI 分数: 0.92
  关键词覆盖率: 0.85
  语义相似度: 0.88
  综合一致性: 0.89
[第3层] ✓ 一致性检测完成

[第4层] 置信度决策（阈值: 0.9）
  ⚠ 警告 (0.89)
[第4层] ✓ 决策完成

============================================================
最终结果
============================================================
场景: medical
状态: warning
消息: 置信度较低，建议谨慎参考
一致性分数: 0.89
文档过滤: 3 → 3

最终答案:
（不太确定）阿司匹林是一种常用的解热镇痛药 [1]，用于缓解轻至中度疼痛。它也用于预防心血管疾病 [2]，但需要在医生指导下使用。阿司匹林可能引起胃肠道不适等副作用 [3]。

免责声明：以上信息仅供参考，请咨询专业医生。
============================================================
```

---

## 代码说明

### 核心组件

#### 1. ScenarioConfig

**功能：** 场景配置，定义不同场景的防护参数

**关键参数：**
- `consistency_threshold`: 一致性阈值
- `min_retrieval_score`: 最小检索分数
- `temperature`: LLM 温度
- `require_citations`: 是否要求引用
- `fallback_message`: 降级消息

#### 2. MultiLayerProtectionSystem

**功能：** 多层防护系统的核心实现

**四层防护：**
1. `layer1_filter_retrieval()`: 检索质量过滤
2. `layer2_constrained_generation()`: 约束生成
3. `layer3_consistency_check()`: 一致性检测
4. `layer4_confidence_decision()`: 置信度决策

### 场景配置对比

| 场景 | 风险等级 | 一致性阈值 | 检索阈值 | 温度 | 要求引用 |
|------|----------|------------|----------|------|----------|
| **医疗** | HIGH | 0.9 | 0.8 | 0.0 | ✓ |
| **法律** | HIGH | 0.85 | 0.75 | 0.1 | ✓ |
| **客服** | MEDIUM | 0.7 | 0.6 | 0.3 | ✗ |
| **一般** | MEDIUM | 0.7 | 0.6 | 0.3 | ✗ |

### 一致性检测方法

| 方法 | 权重 | 说明 |
|------|------|------|
| **NLI 检测** | 50% | 使用 NLI 模型判断逻辑关系 |
| **关键词匹配** | 30% | 检查关键词覆盖率 |
| **语义相似度** | 20% | 计算语义向量相似度 |

---

## 扩展建议

### 1. 添加日志记录

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def layer1_filter_retrieval(self, docs, config):
    logger.info(f"Layer 1: Filtering {len(docs)} documents")
    # ... 过滤逻辑
    logger.info(f"Layer 1: Kept {len(filtered)} documents")
    return filtered
```

### 2. 添加监控指标

```python
from prometheus_client import Counter, Histogram

layer1_filtered = Counter('layer1_filtered_total', 'Documents filtered in layer 1')
consistency_score = Histogram('consistency_score', 'Consistency score distribution')

def layer1_filter_retrieval(self, docs, config):
    filtered = []
    for doc in docs:
        if doc['score'] < config.min_retrieval_score:
            layer1_filtered.inc()
            continue
        filtered.append(doc)
    return filtered
```

### 3. 添加缓存

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def cached_consistency_check(answer_hash: str, docs_hash: str):
    return self.layer3_consistency_check(answer, docs)

def process(self, query, docs, scenario):
    answer_hash = hashlib.md5(answer.encode()).hexdigest()
    docs_hash = hashlib.md5(str(docs).encode()).hexdigest()
    consistency = cached_consistency_check(answer_hash, docs_hash)
```

### 4. 异步处理

```python
import asyncio

async def async_process(self, query, docs, scenario):
    # 第1层：同步过滤
    filtered_docs = self.layer1_filter_retrieval(docs, config)

    # 第2层：异步生成
    answer = await asyncio.to_thread(
        self.layer2_constrained_generation,
        query, filtered_docs, config
    )

    # 第3层：异步检测
    consistency = await asyncio.to_thread(
        self.layer3_consistency_check,
        answer, filtered_docs
    )

    # 第4层：同步决策
    result = self.layer4_confidence_decision(answer, consistency, config)
    return result
```

---

## 总结

**本示例展示了：**

1. ✅ 完整的四层防护体系
2. ✅ 场景化的配置管理
3. ✅ 多种一致性检测方法
4. ✅ 灵活的降级策略
5. ✅ 生产环境可用的架构

**关键要点：**

- 多层防护比单点检测更可靠
- 不同场景需要不同的防护强度
- 预防胜于治疗（在检索和生成阶段就降低风险）
- 需要平衡准确性和用户体验

**四层防护的作用：**

1. **第1层（检索过滤）**：预防低质量输入
2. **第2层（约束生成）**：控制 LLM 行为
3. **第3层（一致性检测）**：验证输出质量
4. **第4层（置信度决策）**：兜底保障

**下一步：**

- 构建端到端 RAG 系统
- 集成到生产环境
- 添加监控和日志
