# 第一性原理

### 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题。

---

## 检索器的第一性原理

### 1. 最基础的定义

**检索器 = 从大量候选中找到最相关的少数**

仅此而已！没有更基础的了。

```
输入：用户问题 + 候选文档集合
输出：最相关的 K 个文档
```

---

### 2. 为什么需要检索器？

**核心问题：大海捞针**

想象一下这个场景：

```
你有一个企业知识库：
- 10,000 篇文档
- 100,000 个文本块
- 每个块平均 500 字

用户问："公司的年假政策是什么？"

问题：如何从 5000 万字中找到那 500 字的答案？
```

**为什么不能把所有内容都给 LLM？**

```
方案1：全部塞给 LLM
- 5000万字 ≈ 2500万 Token
- GPT-4 上下文窗口：128K Token
- 结论：❌ 根本放不下

方案2：随机选一些
- 随机选 10 个块
- 命中答案的概率：10/100000 = 0.01%
- 结论：❌ 几乎不可能找到

方案3：用检索器找最相关的
- 检索 Top-10 最相关的块
- 命中答案的概率：90%+
- 结论：✅ 这就是 RAG 的核心
```

---

### 3. 检索器的三层价值

#### 价值1：缩小搜索范围

**从"大海捞针"变成"小池塘捞针"**

```
原始数据：100,000 个文本块
    ↓ 检索器
Top-K 结果：10 个文本块

搜索范围缩小了 10,000 倍！
```

```python
# 没有检索器：遍历所有内容（不可行）
for chunk in all_100000_chunks:
    answer = llm.generate(question + chunk)  # 调用 10 万次 LLM？

# 有检索器：只处理最相关的
relevant_chunks = retriever.retrieve(question, k=10)
answer = llm.generate(question + relevant_chunks)  # 调用 1 次 LLM
```

#### 价值2：提高答案质量

**相关性决定答案质量**

```
场景：用户问"如何申请年假？"

低质量检索（随机选择）：
- 返回：公司历史、财务报表、技术文档...
- LLM 回答："抱歉，我没有找到相关信息"

高质量检索（语义匹配）：
- 返回：年假政策、请假流程、HR 联系方式
- LLM 回答："根据公司政策，年假申请流程如下..."
```

**GIGO 原则（Garbage In, Garbage Out）：**

```
检索质量 → 上下文质量 → 答案质量

垃圾检索 → 垃圾上下文 → 垃圾答案
精准检索 → 精准上下文 → 精准答案
```

#### 价值3：降低成本

**减少 Token 消耗 = 省钱**

```
假设：
- 每个文本块 500 Token
- GPT-4 价格：$0.03/1K Token（输入）

方案A：塞入 1000 个块
- Token：500,000
- 成本：$15/次查询

方案B：检索 Top-10
- Token：5,000
- 成本：$0.15/次查询

节省 100 倍成本！
```

---

### 4. 从第一性原理推导检索器设计

**推理链：**

```
1. LLM 上下文窗口有限
   ↓
2. 不能把所有文档都塞进去
   ↓
3. 需要选择"最相关"的文档
   ↓
4. 如何定义"相关"？
   ↓
5. 两种相关性：
   - 语义相关（意思相近）→ 向量检索
   - 词汇相关（词语匹配）→ 关键词检索
   ↓
6. 两种方法各有优劣
   ↓
7. 结合两者 → 混合检索
   ↓
8. 返回多少结果？→ Top-K 参数
   ↓
9. 如何保证质量？→ 相似度阈值
   ↓
10. 如何避免重复？→ MMR 多样性
```

---

### 5. 检索器的本质问题

**检索器要回答的核心问题：**

| 问题 | 对应概念 |
|------|----------|
| 什么叫"相关"？ | 相似度度量（Cosine、BM25） |
| 用什么方法找？ | 检索器类型（向量、关键词、混合） |
| 返回多少个？ | Top-K 参数 |
| 质量够不够？ | 相似度阈值 |
| 会不会重复？ | MMR 多样性 |

---

### 6. 检索器的数学本质

**检索 = 排序问题**

```python
def retrieve(query, documents, k):
    """
    检索的本质：计算相关性分数，返回 Top-K
    """
    scores = []
    for doc in documents:
        score = relevance(query, doc)  # 计算相关性
        scores.append((doc, score))

    # 按分数排序，返回前 K 个
    sorted_docs = sorted(scores, key=lambda x: x[1], reverse=True)
    return sorted_docs[:k]
```

**不同检索器的区别在于 `relevance()` 函数的实现：**

```python
# 向量检索：余弦相似度
def vector_relevance(query, doc):
    query_vec = embed(query)
    doc_vec = embed(doc)
    return cosine_similarity(query_vec, doc_vec)

# 关键词检索：BM25 分数
def keyword_relevance(query, doc):
    return bm25_score(query, doc)

# 混合检索：加权组合
def hybrid_relevance(query, doc, alpha=0.5):
    vec_score = vector_relevance(query, doc)
    kw_score = keyword_relevance(query, doc)
    return alpha * vec_score + (1 - alpha) * kw_score
```

---

### 7. 一句话总结第一性原理

**检索器是解决"大海捞针"问题的工具，通过计算相关性分数，从海量文档中找到最相关的少数，让 LLM 能够基于精准上下文生成高质量答案。**

---

## 第一性原理的应用

理解了第一性原理，你就能回答这些问题：

| 问题 | 答案 |
|------|------|
| 为什么需要检索器？ | LLM 上下文有限，需要筛选最相关的内容 |
| 检索器的核心任务是什么？ | 计算相关性，返回 Top-K |
| 为什么有多种检索器？ | "相关性"有多种定义方式 |
| Top-K 设多少合适？ | 取决于上下文窗口和答案复杂度 |
| 检索质量为什么重要？ | GIGO，检索质量决定答案质量 |

---

**下一步：** [03_核心概念](./03_核心概念.md) - 掌握三种检索器类型和关键参数
