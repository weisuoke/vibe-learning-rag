# 实战代码07: 错误处理与重试

> 实现生产级的错误处理和重试机制

---

## 概述

本节实现完整的错误处理和重试机制,确保流式输出在生产环境中的稳定性和可靠性。

**学习目标:**
- 实现完整的错误处理策略
- 实现客户端重连机制
- 处理各种边缘情况
- 优化用户体验

---

## 1. 服务端错误处理

### 1.1 完整的错误处理实现

```python
"""
完整的服务端错误处理
文件: examples/streaming/error_handling_complete.py
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from langchain_openai import ChatOpenAI
from enum import Enum
import json
import traceback
import asyncio
import logging

app = FastAPI()
llm = ChatOpenAI()

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ErrorType(Enum):
    VALIDATION = "validation"
    TIMEOUT = "timeout"
    RATE_LIMIT = "rate_limit"
    LLM_ERROR = "llm_error"
    SYSTEM_ERROR = "system_error"

class ErrorSeverity(Enum):
    WARNING = "warning"
    ERROR = "error"
    FATAL = "fatal"

@app.post("/chat-robust")
async def chat_robust(message: str, timeout: int = 30):
    """生产级错误处理"""

    # 1. 参数验证 (在流式开始前)
    if not message or len(message) > 2000:
        raise HTTPException(
            status_code=400,
            detail="Message length must be between 1 and 2000 characters"
        )

    async def generate():
        request_id = str(uuid.uuid4())
        logger.info(f"[{request_id}] Stream started")

        try:
            # 发送初始化事件
            yield f"event: init\ndata: {json.dumps({
                'request_id': request_id,
                'status': 'started'
            })}\n\n"

            # 设置超时
            try:
                async with asyncio.timeout(timeout):
                    token_count = 0

                    # 流式生成
                    async for chunk in llm.astream(message):
                        if chunk.content:
                            token_count += 1
                            yield f"data: {chunk.content}\n\n"

                    # 发送完成事件
                    logger.info(f"[{request_id}] Stream completed, tokens: {token_count}")
                    yield f"event: done\ndata: {json.dumps({
                        'request_id': request_id,
                        'token_count': token_count
                    })}\n\n"

            except asyncio.TimeoutError:
                # 超时错误
                logger.error(f"[{request_id}] Timeout after {timeout}s")
                error_data = {
                    'request_id': request_id,
                    'type': ErrorType.TIMEOUT.value,
                    'severity': ErrorSeverity.ERROR.value,
                    'message': f'Generation timeout after {timeout} seconds',
                    'recoverable': True
                }
                yield f"event: error\ndata: {json.dumps(error_data)}\n\n"

        except ValueError as e:
            # 业务逻辑错误
            logger.error(f"[{request_id}] Validation error: {str(e)}")
            error_data = {
                'request_id': request_id,
                'type': ErrorType.VALIDATION.value,
                'severity': ErrorSeverity.ERROR.value,
                'message': str(e),
                'recoverable': True
            }
            yield f"event: error\ndata: {json.dumps(error_data)}\n\n"

        except Exception as e:
            # 系统错误
            logger.error(f"[{request_id}] System error: {str(e)}", exc_info=True)
            error_data = {
                'request_id': request_id,
                'type': ErrorType.SYSTEM_ERROR.value,
                'severity': ErrorSeverity.FATAL.value,
                'message': 'Internal server error',
                'detail': str(e) if app.debug else None,
                'traceback': traceback.format_exc() if app.debug else None,
                'recoverable': False
            }
            yield f"event: error\ndata: {json.dumps(error_data)}\n\n"

        finally:
            logger.info(f"[{request_id}] Stream closed")

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )
```

### 1.2 限流错误处理

```python
"""
限流错误处理
"""

from fastapi import Request
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/chat-rate-limited")
@limiter.limit("10/minute")
async def chat_rate_limited(request: Request, message: str):
    """带限流的流式端点"""
    async def generate():
        try:
            async for chunk in llm.astream(message):
                if chunk.content:
                    yield f"data: {chunk.content}\n\n"

        except Exception as e:
            if "rate limit" in str(e).lower():
                error_data = {
                    'type': ErrorType.RATE_LIMIT.value,
                    'message': 'Rate limit exceeded, please try again later',
                    'retry_after': 60
                }
            else:
                error_data = {
                    'type': ErrorType.SYSTEM_ERROR.value,
                    'message': str(e)
                }
            yield f"event: error\ndata: {json.dumps(error_data)}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )
```

---

## 2. 客户端错误处理和重试

### 2.1 完整的重试客户端

```javascript
/**
 * 完整的重试客户端
 * 文件: src/utils/RetryStreamingClient.js
 */

class RetryStreamingClient {
    constructor(url, options = {}) {
        this.url = url;
        this.maxRetries = options.maxRetries || 5;
        this.initialDelay = options.initialDelay || 1000;
        this.maxDelay = options.maxDelay || 30000;
        this.backoffMultiplier = options.backoffMultiplier || 2;

        this.retryCount = 0;
        this.eventSource = null;
        this.handlers = {};
        this.isConnected = false;
        this.shouldRetry = true;
        this.lastEventId = null;
    }

    on(eventType, handler) {
        this.handlers[eventType] = handler;
        return this;
    }

    connect(params = {}) {
        // 构建 URL
        const queryString = new URLSearchParams(params).toString();
        let fullUrl = queryString ? `${this.url}?${queryString}` : this.url;

        // 添加 Last-Event-ID (断点续传)
        if (this.lastEventId) {
            fullUrl += `${queryString ? '&' : '?'}last_event_id=${this.lastEventId}`;
        }

        this.eventSource = new EventSource(fullUrl);

        // 连接打开
        this.eventSource.onopen = () => {
            this.isConnected = true;
            this.retryCount = 0;
            console.log('连接成功');

            const handler = this.handlers['open'];
            if (handler) handler();
        };

        // 接收消息
        this.eventSource.onmessage = (event) => {
            // 保存最后的事件 ID
            if (event.lastEventId) {
                this.lastEventId = event.lastEventId;
            }

            const handler = this.handlers['message'];
            if (handler) handler(event.data);
        };

        // 连接错误
        this.eventSource.onerror = (error) => {
            this.isConnected = false;
            console.error('连接错误:', error);

            const handler = this.handlers['error'];
            if (handler) handler(error);

            // 决定是否重试
            if (this.shouldRetry && this.retryCount < this.maxRetries) {
                this.scheduleRetry(params);
            } else {
                console.error('超过最大重连次数或不应重试');
                this.close();

                const fatalHandler = this.handlers['fatal'];
                if (fatalHandler) fatalHandler('连接失败');
            }
        };

        // 注册自定义事件
        this.registerCustomEvents();
    }

    registerCustomEvents() {
        Object.keys(this.handlers).forEach(eventType => {
            if (!['open', 'message', 'error', 'fatal'].includes(eventType)) {
                this.eventSource.addEventListener(eventType, (event) => {
                    const handler = this.handlers[eventType];
                    if (handler) {
                        try {
                            const data = JSON.parse(event.data);

                            // 处理错误事件
                            if (eventType === 'error') {
                                this.handleServerError(data);
                            } else {
                                handler(data);
                            }
                        } catch {
                            handler(event.data);
                        }
                    }
                });
            }
        });
    }

    handleServerError(errorData) {
        console.error('服务端错误:', errorData);

        // 根据错误类型决定是否重试
        if (errorData.recoverable) {
            // 可恢复错误,可以重试
            this.shouldRetry = true;
        } else {
            // 不可恢复错误,不应重试
            this.shouldRetry = false;
            this.close();

            const fatalHandler = this.handlers['fatal'];
            if (fatalHandler) fatalHandler(errorData.message);
        }
    }

    scheduleRetry(params) {
        this.retryCount++;

        // 计算延迟 (指数退避)
        const delay = Math.min(
            this.initialDelay * Math.pow(this.backoffMultiplier, this.retryCount - 1),
            this.maxDelay
        );

        console.log(`重连中... (${this.retryCount}/${this.maxRetries}), 延迟: ${delay}ms`);

        const retryHandler = this.handlers['retry'];
        if (retryHandler) {
            retryHandler({
                attempt: this.retryCount,
                maxRetries: this.maxRetries,
                delay: delay
            });
        }

        setTimeout(() => {
            this.eventSource.close();
            this.connect(params);
        }, delay);
    }

    close() {
        this.shouldRetry = false;
        if (this.eventSource) {
            this.eventSource.close();
            this.eventSource = null;
            this.isConnected = false;
        }
    }
}

export default RetryStreamingClient;
```

### 2.2 React Hook 实现

```javascript
/**
 * React 重试 Hook
 * 文件: src/hooks/useRetryStreaming.js
 */

import { useState, useRef, useCallback } from 'react';
import RetryStreamingClient from '../utils/RetryStreamingClient';

export function useRetryStreaming(url, options = {}) {
    const [isStreaming, setIsStreaming] = useState(false);
    const [error, setError] = useState(null);
    const [retryInfo, setRetryInfo] = useState(null);
    const clientRef = useRef(null);

    const start = useCallback((params = {}, handlers = {}) => {
        if (isStreaming) return;

        setError(null);
        setRetryInfo(null);
        setIsStreaming(true);

        // 创建客户端
        const client = new RetryStreamingClient(url, {
            maxRetries: options.maxRetries || 5,
            initialDelay: options.initialDelay || 1000,
            maxDelay: options.maxDelay || 30000
        });
        clientRef.current = client;

        // 注册处理器
        Object.keys(handlers).forEach(eventType => {
            client.on(eventType, handlers[eventType]);
        });

        // 注册内部处理器
        client.on('open', () => {
            setRetryInfo(null);
        });

        client.on('retry', (info) => {
            setRetryInfo(info);
        });

        client.on('fatal', (message) => {
            setError(message);
            setIsStreaming(false);
        });

        client.on('done', () => {
            setIsStreaming(false);
        });

        // 开始连接
        client.connect(params);
    }, [url, options, isStreaming]);

    const stop = useCallback(() => {
        if (clientRef.current) {
            clientRef.current.close();
            clientRef.current = null;
            setIsStreaming(false);
        }
    }, []);

    return {
        isStreaming,
        error,
        retryInfo,
        start,
        stop
    };
}
```

### 2.3 使用示例

```javascript
/**
 * 使用重试 Hook
 */

import React, { useState } from 'react';
import { useRetryStreaming } from '../hooks/useRetryStreaming';

function ChatWithRetry() {
    const [message, setMessage] = useState('');
    const [response, setResponse] = useState('');

    const { isStreaming, error, retryInfo, start, stop } = useRetryStreaming(
        'http://localhost:8000/chat-robust',
        {
            maxRetries: 5,
            initialDelay: 1000,
            maxDelay: 30000
        }
    );

    const sendMessage = () => {
        setResponse('');

        start(
            { message },
            {
                message: (data) => {
                    setResponse(prev => prev + data);
                },
                error: (errorData) => {
                    console.error('错误:', errorData);
                }
            }
        );
    };

    return (
        <div>
            <input
                value={message}
                onChange={(e) => setMessage(e.target.value)}
                disabled={isStreaming}
            />
            <button onClick={sendMessage} disabled={isStreaming}>
                发送
            </button>

            {retryInfo && (
                <div className="retry-info">
                    重连中... ({retryInfo.attempt}/{retryInfo.maxRetries})
                    <br />
                    延迟: {retryInfo.delay}ms
                </div>
            )}

            {error && (
                <div className="error">
                    错误: {error}
                </div>
            )}

            <div className="response">{response}</div>
        </div>
    );
}
```

---

## 3. 部分内容已发送的处理

### 3.1 服务端标记

```python
"""
标记部分内容已发送
"""

@app.post("/chat-partial")
async def chat_partial(message: str):
    """处理部分内容已发送的情况"""
    async def generate():
        partial_content = ""

        try:
            async for chunk in llm.astream(message):
                if chunk.content:
                    partial_content += chunk.content
                    yield f"data: {chunk.content}\n\n"

            # 发送完成事件
            yield f"event: done\ndata: {json.dumps({
                'status': 'completed',
                'full_content': partial_content
            })}\n\n"

        except Exception as e:
            # 发送错误事件,包含已生成的内容
            error_data = {
                'error': str(e),
                'partial_content': partial_content,
                'partial_length': len(partial_content)
            }
            yield f"event: error\ndata: {json.dumps(error_data)}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )
```

### 3.2 客户端处理

```javascript
/**
 * 处理部分内容
 */

function handlePartialContent() {
    let partialContent = '';
    let hasError = false;

    const eventSource = new EventSource('/chat-partial?message=Hello');

    eventSource.onmessage = (event) => {
        if (!hasError) {
            partialContent += event.data;
            displayContent(partialContent);
        }
    };

    eventSource.addEventListener('error', (event) => {
        const errorData = JSON.parse(event.data);
        hasError = true;

        // 显示错误,但保留已生成的内容
        displayError(errorData.error);
        displayPartialContent(errorData.partial_content);

        // 提供重试选项
        showRetryButton(() => {
            // 重试时,可以使用已生成的内容作为上下文
            retryWithContext(errorData.partial_content);
        });

        eventSource.close();
    });
}
```

---

## 4. 监控和日志

### 4.1 结构化日志

```python
"""
结构化日志
"""

import structlog

logger = structlog.get_logger()

@app.post("/chat-logged")
async def chat_logged(message: str):
    """带结构化日志的流式端点"""
    request_id = str(uuid.uuid4())

    async def generate():
        start_time = time.time()
        token_count = 0

        try:
            logger.info("stream_started", request_id=request_id, message_length=len(message))

            async for chunk in llm.astream(message):
                if chunk.content:
                    token_count += 1
                    yield f"data: {chunk.content}\n\n"

            duration = time.time() - start_time
            logger.info(
                "stream_completed",
                request_id=request_id,
                token_count=token_count,
                duration=duration,
                tokens_per_second=token_count / duration
            )

            yield f"event: done\ndata: Completed\n\n"

        except Exception as e:
            logger.error(
                "stream_error",
                request_id=request_id,
                error=str(e),
                token_count=token_count,
                exc_info=True
            )
            yield f"event: error\ndata: {str(e)}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )
```

### 4.2 Prometheus 监控

```python
"""
Prometheus 监控
"""

from prometheus_client import Counter, Histogram, Gauge

# 定义指标
stream_requests = Counter('stream_requests_total', 'Total stream requests')
stream_errors = Counter('stream_errors_total', 'Total stream errors', ['error_type'])
stream_duration = Histogram('stream_duration_seconds', 'Stream duration')
active_streams = Gauge('active_streams', 'Number of active streams')

@app.post("/chat-monitored")
async def chat_monitored(message: str):
    """带监控的流式端点"""
    stream_requests.inc()
    active_streams.inc()

    async def generate():
        start_time = time.time()

        try:
            async for chunk in llm.astream(message):
                if chunk.content:
                    yield f"data: {chunk.content}\n\n"

            # 记录成功
            stream_duration.observe(time.time() - start_time)

        except asyncio.TimeoutError:
            stream_errors.labels(error_type='timeout').inc()
            yield f"event: error\ndata: Timeout\n\n"

        except Exception as e:
            stream_errors.labels(error_type='system').inc()
            yield f"event: error\ndata: {str(e)}\n\n"

        finally:
            active_streams.dec()

    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )
```

---

## 5. 测试

### 5.1 错误注入测试

```python
"""
错误注入测试
文件: tests/test_error_handling.py
"""

import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_timeout_error():
    """测试超时错误"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        async with client.stream(
            "POST",
            "/chat-robust?message=test&timeout=1"
        ) as response:
            events = []
            async for line in response.aiter_lines():
                if line.startswith("event: "):
                    events.append(line[7:])

            # 验证收到了错误事件
            assert "error" in events

@pytest.mark.asyncio
async def test_partial_content():
    """测试部分内容处理"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        async with client.stream(
            "POST",
            "/chat-partial?message=test"
        ) as response:
            partial_content = ""

            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    partial_content += line[6:]

            # 验证收到了部分内容
            assert len(partial_content) > 0
```

### 5.2 重连测试

```javascript
/**
 * 重连测试
 * 文件: src/__tests__/RetryStreamingClient.test.js
 */

import RetryStreamingClient from '../utils/RetryStreamingClient';

describe('RetryStreamingClient', () => {
    test('should retry on connection error', async () => {
        const client = new RetryStreamingClient('http://localhost:8000/stream', {
            maxRetries: 3,
            initialDelay: 100
        });

        let retryCount = 0;
        client.on('retry', (info) => {
            retryCount = info.attempt;
        });

        // 模拟连接错误
        client.connect();

        // 等待重试
        await new Promise(resolve => setTimeout(resolve, 1000));

        expect(retryCount).toBeGreaterThan(0);
    });
});
```

---

## 总结

**本节要点:**

1. **服务端错误处理**: 分类错误、记录日志、发送错误事件
2. **客户端重试**: 指数退避、断点续传、错误分类
3. **部分内容处理**: 保留已生成内容、提供重试选项
4. **监控日志**: 结构化日志、Prometheus 指标
5. **测试**: 错误注入、重连测试

**关键代码:**
```python
try:
    async for chunk in llm.astream(message):
        yield f"data: {chunk.content}\n\n"
except Exception as e:
    yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"
```

**下一步:**

掌握了错误处理和重试后,可以学习:
- 性能优化
- 化骨绵掌

---

**记住:** 错误处理和重试是生产环境的关键,良好的错误处理可以大幅提升系统稳定性和用户体验。
