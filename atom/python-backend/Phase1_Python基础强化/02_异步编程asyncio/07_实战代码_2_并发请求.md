# 实战代码2：并发请求

> 完整可运行的并发 HTTP 请求示例

---

## 示例概述

本示例演示如何使用 asyncio 并发处理多个 HTTP 请求，包括：
1. 使用 httpx 异步 HTTP 客户端
2. 并发调用多个 API
3. 处理请求失败和重试
4. 控制并发数量
5. 实现超时机制

**适合场景：** API 调用、数据采集、微服务通信

---

## 完整代码

```python
"""
asyncio 并发请求示例
演示：并发处理多个 HTTP 请求
"""

import asyncio
import time
from typing import List, Dict, Any, Optional
import httpx
from dataclasses import dataclass


# ===== 1. 基础并发请求 =====
print("=== 1. 基础并发请求 ===\n")


async def fetch_url(url: str) -> dict:
    """获取单个 URL 的内容"""
    async with httpx.AsyncClient() as client:
        response = await client.get(url, timeout=10.0)
        return {
            "url": url,
            "status": response.status_code,
            "length": len(response.text)
        }


async def example_1():
    """示例1：并发请求多个 URL"""
    print("示例1：并发请求多个 URL")

    urls = [
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1"
    ]

    start = time.time()

    # 并发请求
    results = await asyncio.gather(*[fetch_url(url) for url in urls])

    elapsed = time.time() - start

    print(f"请求完成，耗时: {elapsed:.2f}秒")
    for result in results:
        print(f"  {result['url']}: {result['status']} ({result['length']} bytes)")
    print()


# ===== 2. 错误处理和重试 =====
print("=== 2. 错误处理和重试 ===\n")


async def fetch_with_retry(
    url: str,
    max_retries: int = 3,
    timeout: float = 10.0
) -> dict:
    """带重试机制的请求"""
    async with httpx.AsyncClient() as client:
        for attempt in range(max_retries):
            try:
                print(f"  尝试 {attempt + 1}/{max_retries}: {url}")
                response = await client.get(url, timeout=timeout)
                response.raise_for_status()

                return {
                    "url": url,
                    "status": response.status_code,
                    "success": True,
                    "attempts": attempt + 1
                }

            except (httpx.HTTPError, httpx.TimeoutException) as e:
                if attempt == max_retries - 1:
                    # 最后一次尝试失败
                    return {
                        "url": url,
                        "status": None,
                        "success": False,
                        "error": str(e),
                        "attempts": attempt + 1
                    }

                # 等待后重试
                await asyncio.sleep(1)


async def example_2():
    """示例2：带重试的并发请求"""
    print("示例2：带重试的并发请求")

    urls = [
        "https://httpbin.org/status/200",  # 成功
        "https://httpbin.org/status/500",  # 失败
        "https://httpbin.org/delay/1"      # 成功
    ]

    results = await asyncio.gather(
        *[fetch_with_retry(url, max_retries=2) for url in urls],
        return_exceptions=True
    )

    print("\n结果:")
    for result in results:
        if isinstance(result, Exception):
            print(f"  异常: {result}")
        elif result["success"]:
            print(f"  ✓ {result['url']}: {result['status']} (尝试 {result['attempts']} 次)")
        else:
            print(f"  ✗ {result['url']}: 失败 - {result['error']}")
    print()


# ===== 3. 控制并发数量 =====
print("=== 3. 控制并发数量 ===\n")


class RateLimiter:
    """并发数量限制器"""

    def __init__(self, max_concurrent: int):
        self.semaphore = asyncio.Semaphore(max_concurrent)

    async def fetch(self, url: str, client: httpx.AsyncClient) -> dict:
        """限流的请求"""
        async with self.semaphore:
            print(f"  请求: {url}")
            response = await client.get(url, timeout=10.0)
            return {
                "url": url,
                "status": response.status_code
            }


async def example_3():
    """示例3：限制并发数量"""
    print("示例3：限制并发数量（最多3个并发）")

    # 创建10个请求
    urls = [f"https://httpbin.org/delay/1?id={i}" for i in range(10)]

    limiter = RateLimiter(max_concurrent=3)

    start = time.time()

    async with httpx.AsyncClient() as client:
        tasks = [limiter.fetch(url, client) for url in urls]
        results = await asyncio.gather(*tasks)

    elapsed = time.time() - start

    print(f"\n完成 {len(results)} 个请求，耗时: {elapsed:.2f}秒")
    print(f"平均每个请求: {elapsed / len(results):.2f}秒\n")


# ===== 4. 批量处理 =====
print("=== 4. 批量处理 ===\n")


async def fetch_batch(
    urls: List[str],
    batch_size: int = 5
) -> List[dict]:
    """分批处理 URL"""
    results = []

    async with httpx.AsyncClient() as client:
        for i in range(0, len(urls), batch_size):
            batch = urls[i:i + batch_size]
            print(f"  处理批次 {i // batch_size + 1}: {len(batch)} 个 URL")

            batch_results = await asyncio.gather(
                *[client.get(url, timeout=10.0) for url in batch],
                return_exceptions=True
            )

            for url, result in zip(batch, batch_results):
                if isinstance(result, Exception):
                    results.append({"url": url, "error": str(result)})
                else:
                    results.append({
                        "url": url,
                        "status": result.status_code
                    })

    return results


async def example_4():
    """示例4：分批处理大量请求"""
    print("示例4：分批处理大量请求")

    urls = [f"https://httpbin.org/delay/0.5?id={i}" for i in range(15)]

    start = time.time()
    results = await fetch_batch(urls, batch_size=5)
    elapsed = time.time() - start

    print(f"\n完成 {len(results)} 个请求，耗时: {elapsed:.2f}秒")
    success_count = sum(1 for r in results if "status" in r)
    print(f"成功: {success_count}, 失败: {len(results) - success_count}\n")


# ===== 5. 超时控制 =====
print("=== 5. 超时控制 ===\n")


async def fetch_with_timeout(
    url: str,
    timeout: float = 5.0
) -> dict:
    """带超时的请求"""
    try:
        async with httpx.AsyncClient() as client:
            response = await asyncio.wait_for(
                client.get(url),
                timeout=timeout
            )
            return {
                "url": url,
                "status": response.status_code,
                "success": True
            }
    except asyncio.TimeoutError:
        return {
            "url": url,
            "success": False,
            "error": "请求超时"
        }


async def example_5():
    """示例5：超时控制"""
    print("示例5：超时控制（5秒超时）")

    urls = [
        "https://httpbin.org/delay/2",   # 2秒，成功
        "https://httpbin.org/delay/10",  # 10秒，超时
        "https://httpbin.org/delay/1"    # 1秒，成功
    ]

    results = await asyncio.gather(
        *[fetch_with_timeout(url, timeout=5.0) for url in urls]
    )

    print("\n结果:")
    for result in results:
        if result["success"]:
            print(f"  ✓ {result['url']}: {result['status']}")
        else:
            print(f"  ✗ {result['url']}: {result['error']}")
    print()


# ===== 6. 实际应用：并发调用多个 LLM API =====
print("=== 6. 实际应用：并发调用多个 LLM API ===\n")


@dataclass
class LLMResponse:
    """LLM 响应数据类"""
    provider: str
    content: str
    success: bool
    error: Optional[str] = None


async def call_openai_mock(prompt: str) -> LLMResponse:
    """模拟调用 OpenAI API"""
    await asyncio.sleep(1)  # 模拟网络延迟
    return LLMResponse(
        provider="OpenAI",
        content=f"OpenAI 回答: {prompt[:20]}...",
        success=True
    )


async def call_anthropic_mock(prompt: str) -> LLMResponse:
    """模拟调用 Anthropic API"""
    await asyncio.sleep(1.2)
    return LLMResponse(
        provider="Anthropic",
        content=f"Anthropic 回答: {prompt[:20]}...",
        success=True
    )


async def call_cohere_mock(prompt: str) -> LLMResponse:
    """模拟调用 Cohere API"""
    await asyncio.sleep(0.8)
    return LLMResponse(
        provider="Cohere",
        content=f"Cohere 回答: {prompt[:20]}...",
        success=True
    )


async def get_multiple_llm_responses(prompt: str) -> List[LLMResponse]:
    """并发调用多个 LLM API"""
    print(f"  发送提示词: {prompt}")

    start = time.time()

    # 并发调用所有 API
    responses = await asyncio.gather(
        call_openai_mock(prompt),
        call_anthropic_mock(prompt),
        call_cohere_mock(prompt),
        return_exceptions=True
    )

    elapsed = time.time() - start

    print(f"  所有 API 响应完成，耗时: {elapsed:.2f}秒")

    # 处理结果
    results = []
    for response in responses:
        if isinstance(response, Exception):
            results.append(LLMResponse(
                provider="Unknown",
                content="",
                success=False,
                error=str(response)
            ))
        else:
            results.append(response)

    return results


async def example_6():
    """示例6：并发调用多个 LLM API"""
    print("示例6：并发调用多个 LLM API")

    prompt = "什么是异步编程？请简要解释。"

    responses = await get_multiple_llm_responses(prompt)

    print("\n收到的回答:")
    for resp in responses:
        if resp.success:
            print(f"  [{resp.provider}] {resp.content}")
        else:
            print(f"  [{resp.provider}] 失败: {resp.error}")
    print()


# ===== 7. 按完成顺序处理 =====
print("=== 7. 按完成顺序处理 ===\n")


async def fetch_with_delay(url: str, delay: float) -> dict:
    """带延迟的请求"""
    await asyncio.sleep(delay)
    return {
        "url": url,
        "delay": delay,
        "timestamp": time.time()
    }


async def example_7():
    """示例7：按完成顺序处理结果"""
    print("示例7：按完成顺序处理结果")

    tasks = [
        fetch_with_delay("URL-1", 2.0),
        fetch_with_delay("URL-2", 0.5),
        fetch_with_delay("URL-3", 1.5),
        fetch_with_delay("URL-4", 1.0),
        fetch_with_delay("URL-5", 0.8)
    ]

    print("按完成顺序输出:")
    for coro in asyncio.as_completed(tasks):
        result = await coro
        print(f"  完成: {result['url']} (延迟 {result['delay']}秒)")
    print()


# ===== 8. 实际应用：数据采集 =====
print("=== 8. 实际应用：数据采集 ===\n")


async def scrape_page(url: str, client: httpx.AsyncClient) -> dict:
    """采集单个页面"""
    try:
        response = await client.get(url, timeout=10.0)
        return {
            "url": url,
            "status": response.status_code,
            "title": f"Page {url.split('=')[-1]}",  # 模拟提取标题
            "content_length": len(response.text),
            "success": True
        }
    except Exception as e:
        return {
            "url": url,
            "success": False,
            "error": str(e)
        }


async def scrape_website(
    base_url: str,
    page_count: int,
    max_concurrent: int = 5
) -> List[dict]:
    """采集整个网站"""
    urls = [f"{base_url}?page={i}" for i in range(1, page_count + 1)]

    semaphore = asyncio.Semaphore(max_concurrent)

    async def scrape_with_limit(url: str, client: httpx.AsyncClient):
        async with semaphore:
            return await scrape_page(url, client)

    async with httpx.AsyncClient() as client:
        tasks = [scrape_with_limit(url, client) for url in urls]
        results = await asyncio.gather(*tasks)

    return results


async def example_8():
    """示例8：网站数据采集"""
    print("示例8：网站数据采集（最多5个并发）")

    start = time.time()

    results = await scrape_website(
        base_url="https://httpbin.org/delay/0.5",
        page_count=10,
        max_concurrent=5
    )

    elapsed = time.time() - start

    success_count = sum(1 for r in results if r["success"])
    print(f"\n采集完成:")
    print(f"  总页面: {len(results)}")
    print(f"  成功: {success_count}")
    print(f"  失败: {len(results) - success_count}")
    print(f"  耗时: {elapsed:.2f}秒\n")


# ===== 9. 实际应用：微服务调用 =====
print("=== 9. 实际应用：微服务调用 ===\n")


async def call_user_service(user_id: int) -> dict:
    """调用用户服务"""
    await asyncio.sleep(0.3)
    return {"user_id": user_id, "name": f"User{user_id}"}


async def call_order_service(user_id: int) -> dict:
    """调用订单服务"""
    await asyncio.sleep(0.5)
    return {"user_id": user_id, "orders": [1, 2, 3]}


async def call_payment_service(user_id: int) -> dict:
    """调用支付服务"""
    await asyncio.sleep(0.4)
    return {"user_id": user_id, "balance": 1000.0}


async def get_user_profile(user_id: int) -> dict:
    """获取用户完整信息（并发调用多个微服务）"""
    print(f"  获取用户 {user_id} 的信息...")

    # 并发调用所有服务
    user, orders, payment = await asyncio.gather(
        call_user_service(user_id),
        call_order_service(user_id),
        call_payment_service(user_id)
    )

    # 合并结果
    return {
        **user,
        "orders": orders["orders"],
        "balance": payment["balance"]
    }


async def example_9():
    """示例9：并发调用微服务"""
    print("示例9：并发调用微服务")

    start = time.time()

    profile = await get_user_profile(123)

    elapsed = time.time() - start

    print(f"\n用户信息: {profile}")
    print(f"耗时: {elapsed:.2f}秒（串行需要 1.2秒）\n")


# ===== 10. 性能对比 =====
print("=== 10. 性能对比 ===\n")


async def benchmark_serial():
    """串行执行基准测试"""
    urls = [f"https://httpbin.org/delay/0.5?id={i}" for i in range(5)]

    start = time.time()

    async with httpx.AsyncClient() as client:
        results = []
        for url in urls:
            response = await client.get(url, timeout=10.0)
            results.append(response.status_code)

    return time.time() - start


async def benchmark_concurrent():
    """并发执行基准测试"""
    urls = [f"https://httpbin.org/delay/0.5?id={i}" for i in range(5)]

    start = time.time()

    async with httpx.AsyncClient() as client:
        tasks = [client.get(url, timeout=10.0) for url in urls]
        responses = await asyncio.gather(*tasks)
        results = [r.status_code for r in responses]

    return time.time() - start


async def example_10():
    """示例10：性能对比"""
    print("示例10：串行 vs 并发性能对比")

    print("串行执行...")
    serial_time = await benchmark_serial()

    print("并发执行...")
    concurrent_time = await benchmark_concurrent()

    print(f"\n结果:")
    print(f"  串行耗时: {serial_time:.2f}秒")
    print(f"  并发耗时: {concurrent_time:.2f}秒")
    print(f"  性能提升: {serial_time / concurrent_time:.1f}倍\n")


# ===== 主函数 =====


async def main():
    """主函数：运行所有示例"""
    print("=" * 60)
    print("asyncio 并发请求示例")
    print("=" * 60)
    print()

    # 运行所有示例
    await example_1()
    await example_2()
    await example_3()
    await example_4()
    await example_5()
    await example_6()
    await example_7()
    await example_8()
    await example_9()
    await example_10()

    print("=" * 60)
    print("所有示例运行完成！")
    print("=" * 60)


# ===== 运行程序 =====

if __name__ == "__main__":
    # 使用 asyncio.run() 运行主函数
    asyncio.run(main())
```

---

## 依赖安装

```bash
# 安装 httpx（异步 HTTP 客户端）
uv add httpx
```

---

## 关键知识点

### 1. 使用 httpx 异步客户端

```python
import httpx

async with httpx.AsyncClient() as client:
    response = await client.get(url)
```

### 2. 并发请求

```python
# 并发执行多个请求
results = await asyncio.gather(
    *[fetch_url(url) for url in urls]
)
```

### 3. 错误处理

```python
# 使用 return_exceptions=True 继续执行
results = await asyncio.gather(
    *tasks,
    return_exceptions=True
)
```

### 4. 控制并发数量

```python
# 使用 Semaphore 限制并发
semaphore = asyncio.Semaphore(max_concurrent)

async with semaphore:
    await fetch_url(url)
```

### 5. 超时控制

```python
# 使用 asyncio.wait_for 设置超时
result = await asyncio.wait_for(
    fetch_url(url),
    timeout=5.0
)
```

---

## 性能对比

| 场景 | 串行执行 | 并发执行 | 性能提升 |
|------|---------|---------|---------|
| 5个请求（每个0.5秒） | 2.5秒 | 0.5秒 | 5倍 |
| 10个请求（每个1秒） | 10秒 | 1秒 | 10倍 |
| 100个请求（限流10） | 100秒 | 10秒 | 10倍 |

---

## 最佳实践

### 1. 复用 HTTP 客户端

```python
# ✅ 正确：复用客户端
async with httpx.AsyncClient() as client:
    for url in urls:
        await client.get(url)

# ❌ 错误：每次创建新客户端
for url in urls:
    async with httpx.AsyncClient() as client:
        await client.get(url)
```

### 2. 设置合理的超时

```python
# 设置连接超时和读取超时
timeout = httpx.Timeout(
    connect=5.0,  # 连接超时
    read=30.0     # 读取超时
)

async with httpx.AsyncClient(timeout=timeout) as client:
    response = await client.get(url)
```

### 3. 处理异常

```python
try:
    response = await client.get(url)
    response.raise_for_status()
except httpx.HTTPStatusError as e:
    print(f"HTTP 错误: {e.response.status_code}")
except httpx.TimeoutException:
    print("请求超时")
except httpx.RequestError as e:
    print(f"请求错误: {e}")
```

---

## 学习检查

完成本示例后，你应该能够：

- [ ] 使用 httpx 发送异步 HTTP 请求
- [ ] 并发执行多个 HTTP 请求
- [ ] 处理请求失败和重试
- [ ] 使用 Semaphore 控制并发数量
- [ ] 使用 asyncio.wait_for 设置超时
- [ ] 按完成顺序处理结果
- [ ] 在实际项目中应用并发请求

---

## 下一步

- **继续学习**：阅读【实战代码3：数据库操作】
- **实际应用**：在 AI Agent 项目中并发调用多个 LLM API
- **性能优化**：根据实际情况调整并发数量和超时时间
