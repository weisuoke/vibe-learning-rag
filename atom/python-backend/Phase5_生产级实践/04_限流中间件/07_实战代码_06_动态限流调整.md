# 实战代码6：动态限流调整

> 根据用户行为和系统负载动态调整限流策略

---

## 动态限流器

```python
"""动态限流器"""
import redis
from fastapi import FastAPI, Depends, HTTPException, Request

app = FastAPI()
redis_client = redis.Redis()

class DynamicRateLimiter:
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    async def get_user_behavior(self, user_id: str) -> dict:
        # 从数据库或缓存获取用户行为
        return {
            "is_abusive": False,
            "is_premium": True,
            "recent_violations": 0
        }

    async def get_system_load(self) -> float:
        # 获取系统负载（0.0-1.0）
        return 0.5

    async def calculate_limits(self, user_id: str) -> dict:
        behavior = await self.get_user_behavior(user_id)
        load = await self.get_system_load()

        # 基础限流
        base_rate, base_capacity = 10, 100

        # 根据用户行为调整
        if behavior["is_abusive"]:
            rate, capacity = 1, 10  # 降低限流
        elif behavior["is_premium"]:
            rate, capacity = 100, 1000  # 提高限流
        else:
            rate, capacity = base_rate, base_capacity

        # 根据系统负载调整
        if load > 0.8:
            rate *= 0.5  # 高负载时降低50%
            capacity *= 0.5
        elif load < 0.3:
            rate *= 1.5  # 低负载时提高50%
            capacity *= 1.5

        return {"rate": rate, "capacity": capacity}

    async def acquire(self, user_id: str) -> bool:
        limits = await self.calculate_limits(user_id)

        limiter = RedisTokenBucket(
            self.redis, f"user:{user_id}:dynamic",
            limits["rate"], limits["capacity"]
        )

        return limiter.acquire()

dynamic_limiter = DynamicRateLimiter(redis_client)

async def dynamic_rate_limit(request: Request):
    user_id = request.headers.get("X-User-ID", "anonymous")

    if not await dynamic_limiter.acquire(user_id):
        raise HTTPException(status_code=429, detail="Rate limit exceeded")

@app.post("/chat")
async def chat(message: str, _: None = Depends(dynamic_rate_limit)):
    return {"response": f"Echo: {message}"}
```

---

## 基于时间段的限流

```python
"""基于时间段的限流"""
from datetime import datetime

class TimeBasedRateLimiter:
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    def get_time_based_limits(self) -> dict:
        hour = datetime.now().hour

        # 高峰时段（9-18点）：降低限流
        if 9 <= hour < 18:
            return {"rate": 5, "capacity": 50}
        # 低峰时段：提高限流
        else:
            return {"rate": 20, "capacity": 200}

    async def acquire(self, user_id: str) -> bool:
        limits = self.get_time_based_limits()

        limiter = RedisTokenBucket(
            self.redis, f"user:{user_id}:time_based",
            limits["rate"], limits["capacity"]
        )

        return limiter.acquire()
```

---

## 渐进式限流

```python
"""渐进式限流（先降级，再拒绝）"""

async def progressive_rate_limit(request: Request):
    user_id = request.headers.get("X-User-ID", "anonymous")

    limiter = RedisTokenBucket(
        redis_client, f"user:{user_id}:progressive",
        rate=10, capacity=100
    )

    status = limiter.get_status()
    usage_ratio = (limiter.capacity - status["tokens"]) / limiter.capacity

    # 使用率 > 150%：拒绝
    if usage_ratio > 1.5:
        raise HTTPException(status_code=429, detail="Rate limit exceeded")

    # 使用率 > 100%：降级（返回缓存）
    elif usage_ratio > 1.0:
        request.state.use_cache = True

    # 使用率 < 100%：正常处理
    else:
        request.state.use_cache = False

@app.post("/chat")
async def chat(message: str, request: Request, _: None = Depends(progressive_rate_limit)):
    if request.state.use_cache:
        # 返回缓存结果
        cached = await cache.get(message)
        if cached:
            return {"response": cached, "from_cache": True}

    # 正常处理
    response = await llm.chat(message)
    await cache.set(message, response)
    return {"response": response, "from_cache": False}
```

---

**记住：** 动态限流根据用户行为和系统负载调整策略，提供更灵活的保护。
