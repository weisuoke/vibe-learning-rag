# 核心概念：API适配器

## 概述

API适配器是pi-mono统一不同LLM API的核心机制。通过streamSimple函数，将各种不同格式的API响应转换为统一的AssistantMessageEventStream，实现核心代码与具体Provider的解耦。

**核心价值：**
- **统一抽象**：所有Provider返回相同的事件流格式
- **解耦设计**：核心代码不依赖具体API实现
- **可扩展性**：新Provider无需修改核心代码

## StreamFunction接口

### 接口定义

```typescript
// packages/ai/src/types.ts
export type StreamFunction<TApi extends Api, TOptions extends StreamOptions> = (
  model: Model<TApi>,
  context: Context,
  options?: TOptions
) => AssistantMessageEventStream;

export type SimpleStreamOptions = {
  apiKey?: string;
  maxTokens?: number;
  reasoning?: "minimal" | "low" | "medium" | "high";
  thinkingBudgets?: Record<string, number>;
  signal?: AbortSignal;
};
```

### 参数说明

**1. model - 模型配置**
```typescript
interface Model<TApi extends Api> {
  id: string;              // 模型ID
  provider: string;        // Provider ID
  api: TApi;              // API类型
  baseUrl: string;        // API端点
  contextWindow: number;  // 上下文窗口
  maxTokens: number;      // 最大输出Token
  reasoning: boolean;     // 是否支持推理
  cost: CostConfig;       // 成本配置
}
```

**2. context - 对话上下文**
```typescript
interface Context {
  messages: Message[];     // 消息历史
  systemPrompt?: string;   // 系统提示词
  tools?: Tool[];          // 可用工具
}
```

**3. options - 请求选项**
```typescript
interface SimpleStreamOptions {
  apiKey?: string;         // API密钥
  maxTokens?: number;      // 最大输出Token
  reasoning?: string;      // 推理级别
  signal?: AbortSignal;    // 取消信号
}
```

### 返回值

```typescript
type AssistantMessageEventStream = AsyncIterator<AssistantMessageEvent>;
```

## AssistantMessageEventStream

### 事件类型

```typescript
type AssistantMessageEvent =
  // 开始事件
  | { type: "start"; partial: AssistantMessage }

  // 文本事件
  | { type: "text_start"; contentIndex: number; partial: AssistantMessage }
  | { type: "text_delta"; contentIndex: number; delta: string; partial: AssistantMessage }
  | { type: "text_end"; contentIndex: number; content: string; partial: AssistantMessage }

  // 推理事件
  | { type: "thinking_start"; contentIndex: number; partial: AssistantMessage }
  | { type: "thinking_delta"; contentIndex: number; delta: string; partial: AssistantMessage }
  | { type: "thinking_end"; contentIndex: number; content: string; partial: AssistantMessage }

  // 工具调用事件
  | { type: "toolcall_start"; contentIndex: number; partial: AssistantMessage }
  | { type: "toolcall_delta"; contentIndex: number; delta: string; partial: AssistantMessage }
  | { type: "toolcall_end"; contentIndex: number; toolCall: ToolCall; partial: AssistantMessage }

  // 结束事件
  | { type: "done"; reason: "stop" | "length" | "toolUse"; message: AssistantMessage }
  | { type: "error"; reason: "error" | "aborted"; error: AssistantMessage };
```

### AssistantMessage结构

```typescript
interface AssistantMessage {
  role: "assistant";
  content: ContentBlock[];
  api: Api;
  provider: string;
  model: string;
  usage: UsageInfo;
  stopReason: StopReason;
  timestamp: number;
  errorMessage?: string;
}

type ContentBlock =
  | { type: "text"; text: string }
  | { type: "thinking"; thinking: string; thinkingSignature?: string }
  | { type: "toolCall"; id: string; name: string; arguments: any };

interface UsageInfo {
  input: number;
  output: number;
  cacheRead: number;
  cacheWrite: number;
  totalTokens: number;
  cost: {
    input: number;
    output: number;
    cacheRead: number;
    cacheWrite: number;
    total: number;
  };
}
```

## 实现streamSimple

### 基本模式

```typescript
import {
  type AssistantMessage,
  type AssistantMessageEventStream,
  type Context,
  type Model,
  type SimpleStreamOptions,
  calculateCost,
  createAssistantMessageEventStream,
} from "@mariozechner/pi-ai";

function streamMyProvider(
  model: Model<Api>,
  context: Context,
  options?: SimpleStreamOptions
): AssistantMessageEventStream {
  const stream = createAssistantMessageEventStream();

  (async () => {
    // 初始化输出消息
    const output: AssistantMessage = {
      role: "assistant",
      content: [],
      api: model.api,
      provider: model.provider,
      model: model.id,
      usage: {
        input: 0,
        output: 0,
        cacheRead: 0,
        cacheWrite: 0,
        totalTokens: 0,
        cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0, total: 0 },
      },
      stopReason: "stop",
      timestamp: Date.now(),
    };

    try {
      // 1. 发送start事件
      stream.push({ type: "start", partial: output });

      // 2. 调用API并处理响应
      // ... 实现细节

      // 3. 计算成本
      calculateCost(model, output.usage);

      // 4. 发送done事件
      stream.push({
        type: "done",
        reason: output.stopReason as "stop" | "length" | "toolUse",
        message: output,
      });
      stream.end();
    } catch (error) {
      output.stopReason = options?.signal?.aborted ? "aborted" : "error";
      output.errorMessage = error instanceof Error ? error.message : String(error);
      stream.push({ type: "error", reason: output.stopReason, error: output });
      stream.end();
    }
  })();

  return stream;
}
```

### 处理文本内容

```typescript
// 开始新的文本块
output.content.push({ type: "text", text: "" });
const contentIndex = output.content.length - 1;
stream.push({ type: "text_start", contentIndex, partial: output });

// 处理文本增量
const block = output.content[contentIndex];
if (block.type === "text") {
  block.text += delta;
  stream.push({ type: "text_delta", contentIndex, delta, partial: output });
}

// 文本块结束
stream.push({ type: "text_end", contentIndex, content: block.text, partial: output });
```

### 处理工具调用

```typescript
// 开始工具调用
output.content.push({
  type: "toolCall",
  id: toolCallId,
  name: toolName,
  arguments: {},
});
const contentIndex = output.content.length - 1;
stream.push({ type: "toolcall_start", contentIndex, partial: output });

// 累积JSON参数
let partialJson = "";
partialJson += jsonDelta;
try {
  block.arguments = JSON.parse(partialJson);
} catch {}
stream.push({ type: "toolcall_delta", contentIndex, delta: jsonDelta, partial: output });

// 工具调用结束
stream.push({
  type: "toolcall_end",
  contentIndex,
  toolCall: { type: "toolCall", id, name, arguments: block.arguments },
  partial: output,
});
```

### 处理使用统计

```typescript
// 更新使用统计
output.usage.input = response.usage.input_tokens;
output.usage.output = response.usage.output_tokens;
output.usage.cacheRead = response.usage.cache_read_tokens || 0;
output.usage.cacheWrite = response.usage.cache_write_tokens || 0;
output.usage.totalTokens =
  output.usage.input + output.usage.output + output.usage.cacheRead + output.usage.cacheWrite;

// 计算成本
calculateCost(model, output.usage);
```

## 完整示例

### OpenAI兼容API适配器

```typescript
function streamOpenAICompatible(
  model: Model<Api>,
  context: Context,
  options?: SimpleStreamOptions
): AssistantMessageEventStream {
  const stream = createAssistantMessageEventStream();

  (async () => {
    const output: AssistantMessage = {
      role: "assistant",
      content: [],
      api: model.api,
      provider: model.provider,
      model: model.id,
      usage: {
        input: 0,
        output: 0,
        cacheRead: 0,
        cacheWrite: 0,
        totalTokens: 0,
        cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0, total: 0 },
      },
      stopReason: "stop",
      timestamp: Date.now(),
    };

    try {
      stream.push({ type: "start", partial: output });

      // 构建请求
      const response = await fetch(model.baseUrl + "/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${options?.apiKey || ""}`,
        },
        body: JSON.stringify({
          model: model.id,
          messages: context.messages.map((m) => ({
            role: m.role,
            content: typeof m.content === "string" ? m.content : m.content.map((c) => c.text).join("\n"),
          })),
          max_tokens: options?.maxTokens || model.maxTokens,
          stream: true,
        }),
        signal: options?.signal,
      });

      // 解析SSE流
      const reader = response.body!.getReader();
      const decoder = new TextDecoder();
      let buffer = "";
      let contentIndex = -1;

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split("\n");
        buffer = lines.pop() || "";

        for (const line of lines) {
          if (!line.trim() || !line.startsWith("data: ")) continue;
          const data = line.slice(6);
          if (data === "[DONE]") continue;

          try {
            const event = JSON.parse(data);
            const choice = event.choices?.[0];
            if (!choice) continue;

            const delta = choice.delta;

            if (delta.content) {
              if (contentIndex === -1) {
                output.content.push({ type: "text", text: "" });
                contentIndex = output.content.length - 1;
                stream.push({ type: "text_start", contentIndex, partial: output });
              }

              const block = output.content[contentIndex];
              if (block.type === "text") {
                block.text += delta.content;
                stream.push({
                  type: "text_delta",
                  contentIndex,
                  delta: delta.content,
                  partial: output,
                });
              }
            }

            if (choice.finish_reason) {
              output.stopReason = choice.finish_reason === "length" ? "length" : "stop";
            }

            if (event.usage) {
              output.usage.input = event.usage.prompt_tokens || 0;
              output.usage.output = event.usage.completion_tokens || 0;
              output.usage.totalTokens = event.usage.total_tokens || 0;
            }
          } catch (error) {
            console.error("Failed to parse SSE event:", error);
          }
        }
      }

      calculateCost(model, output.usage);

      stream.push({
        type: "done",
        reason: output.stopReason as "stop" | "length" | "toolUse",
        message: output,
      });
      stream.end();
    } catch (error) {
      output.stopReason = options?.signal?.aborted ? "aborted" : "error";
      output.errorMessage = error instanceof Error ? error.message : String(error);
      stream.push({ type: "error", reason: output.stopReason, error: output });
      stream.end();
    }
  })();

  return stream;
}
```

## 错误处理

### 网络错误重试

```typescript
async function fetchWithRetry(
  url: string,
  options: RequestInit,
  maxRetries: number = 3
): Promise<Response> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);

      if (response.status === 429) {
        const retryAfter = response.headers.get("retry-after");
        const delay = retryAfter ? parseInt(retryAfter) * 1000 : Math.pow(2, i) * 1000;
        await new Promise((resolve) => setTimeout(resolve, delay));
        continue;
      }

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      return response;
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise((resolve) => setTimeout(resolve, Math.pow(2, i) * 1000));
    }
  }
  throw new Error("Max retries exceeded");
}
```

### 取消支持

```typescript
// 使用AbortSignal
const controller = new AbortController();

const stream = streamMyProvider(model, context, {
  signal: controller.signal,
});

// 取消请求
controller.abort();
```

### 超时处理

```typescript
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 30000); // 30秒超时

try {
  const stream = streamMyProvider(model, context, {
    signal: controller.signal,
  });
  // 处理流
} finally {
  clearTimeout(timeoutId);
}
```

## 最佳实践

### 1. 事件顺序

**正确的事件顺序：**
```
start → text_start → text_delta* → text_end → done
```

**错误的事件顺序：**
```
start → text_delta → text_start → done  // ❌ 错误
```

### 2. partial字段

每个事件都应包含最新的`partial`字段：
```typescript
stream.push({ type: "text_delta", contentIndex, delta, partial: output });
```

### 3. 成本计算

在发送`done`事件前计算成本：
```typescript
calculateCost(model, output.usage);
stream.push({ type: "done", reason: "stop", message: output });
```

### 4. 错误处理

捕获所有错误并发送`error`事件：
```typescript
catch (error) {
  output.stopReason = options?.signal?.aborted ? "aborted" : "error";
  output.errorMessage = error instanceof Error ? error.message : String(error);
  stream.push({ type: "error", reason: output.stopReason, error: output });
  stream.end();
}
```

## 参考实现

**Pi-mono内置Provider：**
- anthropic.ts - Anthropic Messages API
- openai-completions.ts - OpenAI Chat Completions
- google.ts - Google Generative AI

**学习路径：**
1. 阅读openai-completions.ts（最简单）
2. 阅读anthropic.ts（完整功能）
3. 实现自己的streamSimple

## 总结

**API适配器的核心：**
1. 统一的事件流格式
2. 请求/响应转换
3. 错误处理和重试
4. 成本计算

**关键点：**
- 事件顺序正确
- partial字段完整
- 错误处理完善
- 取消支持
