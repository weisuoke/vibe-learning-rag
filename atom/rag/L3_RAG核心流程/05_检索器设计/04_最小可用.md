# 最小可用

掌握以下 20% 的核心知识，就能解决 80% 的 RAG 检索问题。

---

## 4.1 向量检索器 + Top-K（最基础）

**这是最简单也是最常用的检索方式。**

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# 1. 创建向量存储
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documents, embeddings)

# 2. 创建检索器（核心就这一行）
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# 3. 检索
results = retriever.invoke("如何申请年假？")

# 4. 查看结果
for doc in results:
    print(doc.page_content[:100])
```

**记住：** 从 `k=5` 开始，根据效果调整。

---

## 4.2 混合检索器（生产推荐）

**当向量检索效果不够好时，加入关键词检索。**

```python
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

# 1. 创建两个检索器
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
bm25_retriever = BM25Retriever.from_documents(documents, k=10)

# 2. 组合成混合检索器
hybrid_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.5, 0.5]  # 各占 50%
)

# 3. 检索
results = hybrid_retriever.invoke("Python asyncio 异常处理")
```

**记住：** 权重从 `[0.5, 0.5]` 开始，根据场景调整。

---

## 4.3 MMR 去重（避免重复内容）

**当检索结果重复度高时，使用 MMR。**

```python
# 使用 MMR 检索
retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={
        "k": 5,           # 返回 5 个
        "fetch_k": 20,    # 从 20 个候选中选
        "lambda_mult": 0.5  # 多样性参数
    }
)

results = retriever.invoke("Python 异步编程")
```

**记住：** `lambda_mult=0.5` 是平衡点，越小越多样。

---

## 4.4 相似度阈值（质量保证）

**当需要过滤低质量结果时，设置阈值。**

```python
# 方法1：内置阈值过滤
retriever = vectorstore.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={
        "score_threshold": 0.7,  # 只返回相似度 > 0.7 的
        "k": 10
    }
)

# 方法2：手动过滤（更灵活）
def retrieve_with_threshold(query, threshold=0.7):
    results = vectorstore.similarity_search_with_score(query, k=10)
    return [doc for doc, score in results if score >= threshold]
```

**记住：** 阈值从 `0.7` 开始，根据效果调整。

---

## 4.5 完整的检索器模板

**复制这个模板，覆盖 90% 的场景：**

```python
"""
RAG 检索器模板
适用于大多数问答场景
"""
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

def create_retriever(documents, mode="hybrid"):
    """
    创建检索器

    Args:
        documents: 文档列表
        mode: "vector" | "hybrid" | "mmr"

    Returns:
        检索器实例
    """
    # 创建向量存储
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(documents, embeddings)

    if mode == "vector":
        # 简单向量检索
        return vectorstore.as_retriever(search_kwargs={"k": 5})

    elif mode == "mmr":
        # MMR 多样性检索
        return vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 5, "fetch_k": 20, "lambda_mult": 0.5}
        )

    elif mode == "hybrid":
        # 混合检索（推荐）
        vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
        bm25_retriever = BM25Retriever.from_documents(documents, k=10)
        return EnsembleRetriever(
            retrievers=[vector_retriever, bm25_retriever],
            weights=[0.5, 0.5]
        )

# 使用示例
retriever = create_retriever(documents, mode="hybrid")
results = retriever.invoke("你的问题")
```

---

## 最小可用速查表

| 场景 | 推荐方案 | 关键参数 |
|------|----------|----------|
| 快速原型 | 向量检索 | `k=5` |
| 生产环境 | 混合检索 | `weights=[0.5, 0.5]` |
| 结果重复 | MMR | `lambda_mult=0.5` |
| 质量要求高 | 阈值过滤 | `threshold=0.7` |

---

## 这些知识足以：

- ✅ 构建一个基础的 RAG 问答系统
- ✅ 处理大多数检索场景
- ✅ 为后续优化（ReRank、Query 改写）打好基础
- ✅ 应对面试中的检索器相关问题

---

**下一步：** [05_双重类比](./05_双重类比.md) - 用熟悉的概念理解检索器
