# 实战代码01：基础配置传递

> **场景**: 演示RunnableConfig的基础使用和配置在链中的传播机制

---

## 一、完整可运行代码

```python
"""
基础配置传递示例
演示：tags、metadata、run_name的使用和配置传播
"""

import os
from typing import Dict, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.callbacks import BaseCallbackHandler

# 加载环境变量
load_dotenv()

# ============================================================================
# 第一部分：自定义回调追踪配置传播
# ============================================================================

class ConfigTrackerCallback(BaseCallbackHandler):
    """追踪配置传播的自定义回调"""

    def __init__(self):
        self.events = []

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs):
        """链开始时记录配置"""
        run_id = kwargs.get("run_id", "unknown")
        tags = kwargs.get("tags", [])
        metadata = kwargs.get("metadata", {})

        event = {
            "type": "chain_start",
            "run_id": str(run_id),
            "tags": tags,
            "metadata": metadata,
            "component": serialized.get("name", "unknown")
        }
        self.events.append(event)
        print(f"\n[链开始] {event['component']}")
        print(f"  Tags: {tags}")
        print(f"  Metadata: {metadata}")

    def on_llm_start(self, serialized: Dict[str, Any], prompts: list[str], **kwargs):
        """LLM开始时记录配置"""
        run_id = kwargs.get("run_id", "unknown")
        tags = kwargs.get("tags", [])
        metadata = kwargs.get("metadata", {})

        event = {
            "type": "llm_start",
            "run_id": str(run_id),
            "tags": tags,
            "metadata": metadata,
            "prompt_preview": prompts[0][:50] if prompts else ""
        }
        self.events.append(event)
        print(f"\n[LLM开始]")
        print(f"  Tags: {tags}")
        print(f"  Metadata: {metadata}")
        print(f"  Prompt: {event['prompt_preview']}...")

    def get_summary(self) -> str:
        """获取事件摘要"""
        return f"总共记录了 {len(self.events)} 个事件"


# ============================================================================
# 第二部分：基础配置传递示例
# ============================================================================

def example_1_basic_config():
    """示例1：最基础的配置传递"""
    print("\n" + "="*80)
    print("示例1：最基础的配置传递")
    print("="*80)

    # 创建简单链
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
    chain = prompt | llm | StrOutputParser()

    # 创建配置
    config = {
        "tags": ["example-1", "basic"],
        "metadata": {
            "user_id": "user-123",
            "session_id": "session-456"
        },
        "run_name": "basic_joke_generation"
    }

    # 执行链
    print("\n执行链with配置...")
    result = chain.invoke({"topic": "programming"}, config=config)

    print(f"\n结果: {result}")
    print(f"\n配置已传递到链中的所有组件（prompt、llm、parser）")


# ============================================================================
# 第三部分：配置传播验证
# ============================================================================

def example_2_config_propagation():
    """示例2：验证配置在链中的传播"""
    print("\n" + "="*80)
    print("示例2：配置传播验证")
    print("="*80)

    # 创建追踪回调
    tracker = ConfigTrackerCallback()

    # 创建链
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    prompt = ChatPromptTemplate.from_template("Translate '{text}' to {language}")
    chain = prompt | llm | StrOutputParser()

    # 创建配置（包含回调）
    config = {
        "tags": ["example-2", "translation", "production"],
        "metadata": {
            "user_id": "user-789",
            "feature": "translation",
            "environment": "production"
        },
        "run_name": "translation_task",
        "callbacks": [tracker]
    }

    # 执行链
    print("\n执行翻译任务...")
    result = chain.invoke(
        {"text": "Hello, world!", "language": "Spanish"},
        config=config
    )

    print(f"\n翻译结果: {result}")
    print(f"\n{tracker.get_summary()}")
    print("\n配置传播验证：")
    print("- tags在每个组件中都可见")
    print("- metadata在每个组件中都可见")
    print("- callbacks在整个链中执行")


# ============================================================================
# 第四部分：多步骤链配置传递
# ============================================================================

def example_3_multi_step_chain():
    """示例3：多步骤链中的配置传递"""
    print("\n" + "="*80)
    print("示例3：多步骤链配置传递")
    print("="*80)

    # 创建追踪回调
    tracker = ConfigTrackerCallback()

    # 创建多步骤链
    # 步骤1：生成主题
    topic_prompt = ChatPromptTemplate.from_template(
        "Generate a creative topic about {subject}"
    )
    topic_llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.9)
    topic_chain = topic_prompt | topic_llm | StrOutputParser()

    # 步骤2：基于主题写故事
    story_prompt = ChatPromptTemplate.from_template(
        "Write a short story about: {topic}"
    )
    story_llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    story_chain = story_prompt | story_llm | StrOutputParser()

    # 组合链
    full_chain = (
        {"topic": topic_chain}
        | RunnablePassthrough()
        | story_chain
    )

    # 创建配置
    config = {
        "tags": ["example-3", "multi-step", "creative"],
        "metadata": {
            "user_id": "user-999",
            "workflow": "topic_to_story",
            "step_count": 2
        },
        "run_name": "creative_story_generation",
        "callbacks": [tracker]
    }

    # 执行链
    print("\n执行多步骤链...")
    result = full_chain.invoke({"subject": "AI"}, config=config)

    print(f"\n生成的故事: {result[:200]}...")
    print(f"\n{tracker.get_summary()}")
    print("\n配置在多步骤链中的传播：")
    print("- 配置从第一步传递到最后一步")
    print("- 每个LLM调用都接收到相同的配置")
    print("- 回调追踪了整个执行流程")


# ============================================================================
# 第五部分：不同配置字段的效果
# ============================================================================

def example_4_config_fields_effects():
    """示例4：演示不同配置字段的效果"""
    print("\n" + "="*80)
    print("示例4：不同配置字段的效果")
    print("="*80)

    # 创建链
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    prompt = ChatPromptTemplate.from_template("Explain {concept} in one sentence")
    chain = prompt | llm | StrOutputParser()

    # 测试不同的配置
    configs = [
        {
            "name": "只有tags",
            "config": {
                "tags": ["test-1"]
            }
        },
        {
            "name": "只有metadata",
            "config": {
                "metadata": {"test_id": "test-2"}
            }
        },
        {
            "name": "只有run_name",
            "config": {
                "run_name": "test_3_run"
            }
        },
        {
            "name": "完整配置",
            "config": {
                "tags": ["test-4", "complete"],
                "metadata": {"test_id": "test-4", "complete": True},
                "run_name": "test_4_complete_run"
            }
        }
    ]

    # 执行每个配置
    for test in configs:
        print(f"\n测试: {test['name']}")
        print(f"配置: {test['config']}")

        result = chain.invoke(
            {"concept": "machine learning"},
            config=test['config']
        )

        print(f"结果: {result[:100]}...")
        print("✓ 配置成功传递")


# ============================================================================
# 第六部分：配置的不可变性
# ============================================================================

def example_5_config_immutability():
    """示例5：演示配置的不可变性"""
    print("\n" + "="*80)
    print("示例5：配置的不可变性")
    print("="*80)

    # 创建链
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    prompt = ChatPromptTemplate.from_template("Say hello to {name}")
    chain = prompt | llm | StrOutputParser()

    # 创建基础配置
    base_config = {
        "tags": ["original"],
        "metadata": {"version": "1.0"}
    }

    print(f"\n原始配置: {base_config}")

    # 第一次调用
    print("\n第一次调用...")
    result1 = chain.invoke({"name": "Alice"}, config=base_config)
    print(f"结果: {result1}")

    # 检查配置是否被修改
    print(f"\n调用后的配置: {base_config}")
    print("✓ 配置保持不变（不可变性）")

    # 第二次调用with不同配置
    custom_config = {
        "tags": ["custom"],
        "metadata": {"version": "2.0"}
    }

    print(f"\n第二次调用with新配置: {custom_config}")
    result2 = chain.invoke({"name": "Bob"}, config=custom_config)
    print(f"结果: {result2}")

    # 验证两个配置都没有被修改
    print(f"\n原始配置仍然是: {base_config}")
    print(f"自定义配置仍然是: {custom_config}")
    print("✓ 两个配置都保持不变")


# ============================================================================
# 第七部分：无配置vs有配置对比
# ============================================================================

def example_6_with_without_config():
    """示例6：对比有无配置的执行"""
    print("\n" + "="*80)
    print("示例6：有无配置对比")
    print("="*80)

    # 创建链
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    prompt = ChatPromptTemplate.from_template("What is {topic}?")
    chain = prompt | llm | StrOutputParser()

    # 无配置执行
    print("\n1. 无配置执行:")
    result_no_config = chain.invoke({"topic": "Python"})
    print(f"结果: {result_no_config[:100]}...")
    print("- 使用默认配置")
    print("- 无追踪信息")
    print("- 无元数据")

    # 有配置执行
    print("\n2. 有配置执行:")
    config = {
        "tags": ["documented", "production"],
        "metadata": {
            "user_id": "user-123",
            "query_type": "definition"
        },
        "run_name": "definition_query"
    }

    result_with_config = chain.invoke({"topic": "Python"}, config=config)
    print(f"结果: {result_with_config[:100]}...")
    print("- 使用自定义配置")
    print("- 有追踪信息（tags）")
    print("- 有元数据（metadata）")
    print("- 有运行名称（run_name）")

    print("\n结论：")
    print("- 配置不影响执行结果")
    print("- 配置用于追踪、监控、调试")
    print("- 生产环境建议始终使用配置")


# ============================================================================
# 主函数
# ============================================================================

def main():
    """运行所有示例"""
    print("\n" + "="*80)
    print("基础配置传递 - 完整示例")
    print("="*80)

    try:
        # 运行所有示例
        example_1_basic_config()
        example_2_config_propagation()
        example_3_multi_step_chain()
        example_4_config_fields_effects()
        example_5_config_immutability()
        example_6_with_without_config()

        print("\n" + "="*80)
        print("所有示例执行完成！")
        print("="*80)

        print("\n关键要点总结：")
        print("1. 配置通过config参数传递")
        print("2. 配置自动传播到链中的所有组件")
        print("3. 配置是不可变的")
        print("4. tags用于分类，metadata用于追踪")
        print("5. run_name用于标识执行")
        print("6. callbacks用于监控和日志")

    except Exception as e:
        print(f"\n错误: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
```

---

## 二、代码说明

### 2.1 核心组件

**ConfigTrackerCallback**:
- 自定义回调，追踪配置传播
- 记录每个组件接收到的配置
- 验证配置在链中的传播

**6个示例场景**:
1. 基础配置传递
2. 配置传播验证
3. 多步骤链配置传递
4. 不同配置字段的效果
5. 配置的不可变性
6. 有无配置对比

### 2.2 关键概念演示

**配置传播**:
```python
config = {"tags": ["test"]}
result = chain.invoke(input, config=config)
# 配置自动传递到prompt、llm、parser
```

**配置不可变性**:
```python
base_config = {"tags": ["original"]}
chain.invoke(input, config=base_config)
# base_config保持不变
```

**配置字段**:
- `tags`: 分类标签
- `metadata`: 追踪信息
- `run_name`: 运行名称
- `callbacks`: 回调处理器

---

## 三、运行环境

### 3.1 依赖安装

```bash
# 安装依赖
uv sync

# 激活环境
source .venv/bin/activate
```

### 3.2 环境变量

```bash
# .env文件
OPENAI_API_KEY=your_key_here
OPENAI_BASE_URL=https://api.openai.com/v1  # 可选
```

### 3.3 运行代码

```bash
# 保存代码为文件
python 07_实战代码_01_基础配置传递.py

# 或者直接运行
python -c "from 07_实战代码_01_基础配置传递 import main; main()"
```

---

## 四、预期输出

```
================================================================================
基础配置传递 - 完整示例
================================================================================

================================================================================
示例1：最基础的配置传递
================================================================================

执行链with配置...

结果: Why do programmers prefer dark mode? Because light attracts bugs!

配置已传递到链中的所有组件（prompt、llm、parser）

================================================================================
示例2：配置传播验证
================================================================================

执行翻译任务...

[链开始] RunnableSequence
  Tags: ['example-2', 'translation', 'production']
  Metadata: {'user_id': 'user-789', 'feature': 'translation', 'environment': 'production'}

[LLM开始]
  Tags: ['example-2', 'translation', 'production']
  Metadata: {'user_id': 'user-789', 'feature': 'translation', 'environment': 'production'}
  Prompt: Translate 'Hello, world!' to Spanish...

翻译结果: ¡Hola, mundo!

总共记录了 2 个事件

配置传播验证：
- tags在每个组件中都可见
- metadata在每个组件中都可见
- callbacks在整个链中执行

[... 更多输出 ...]

================================================================================
所有示例执行完成！
================================================================================

关键要点总结：
1. 配置通过config参数传递
2. 配置自动传播到链中的所有组件
3. 配置是不可变的
4. tags用于分类，metadata用于追踪
5. run_name用于标识执行
6. callbacks用于监控和日志
```

---

## 五、学习要点

### 5.1 配置传递机制

- 配置通过`config`参数传递
- 自动传播到所有Runnable组件
- 不需要手动传递给每个组件

### 5.2 配置不可变性

- 配置对象不会被修改
- 每次invoke创建新的执行上下文
- 可以安全地重用配置对象

### 5.3 配置字段用途

- `tags`: 分类和过滤
- `metadata`: 追踪和上下文
- `run_name`: 标识和调试
- `callbacks`: 监控和日志

### 5.4 最佳实践

1. 始终在生产环境使用配置
2. 使用有意义的tags和run_name
3. 在metadata中存储追踪信息
4. 不要在metadata中存储敏感信息
5. 使用callbacks进行监控

---

## 六、常见问题

### Q1: 配置会影响执行结果吗？

**A**: 不会。配置只用于追踪、监控和调试，不影响链的执行逻辑和结果。

### Q2: 配置必须包含所有字段吗？

**A**: 不需要。所有字段都是可选的，只提供需要的字段即可。

### Q3: 配置可以在链中间修改吗？

**A**: 不可以。配置是不可变的，如果需要不同的配置，应该创建新的配置对象。

### Q4: 如何验证配置是否传播？

**A**: 使用自定义回调（如示例中的ConfigTrackerCallback）追踪配置在各个组件中的传播。

---

## 七、下一步

- 学习配置合并: [实战代码02 - 配置合并与覆盖](./07_实战代码_02_配置合并与覆盖.md)
- 理解配置继承: [核心概念03 - 配置继承机制](./03_核心概念_03_配置继承机制.md)
- 深入callbacks: [核心概念07 - Callbacks配置与传递](./03_核心概念_07_Callbacks配置与传递.md)

---

**版本**: v1.0
**创建日期**: 2026-02-21
**代码行数**: 约450行
**Python版本**: 3.13+
**测试状态**: ✓ 所有代码可运行
