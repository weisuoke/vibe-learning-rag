# æ ¸å¿ƒæ¦‚å¿µ1ï¼šå›ºå®šå¤§å°åˆ†å—ï¼ˆFixed-size Chunkingï¼‰

**æŒ‰å›ºå®šå­—ç¬¦æ•°æˆ– Token æ•°åˆ‡åˆ†æ–‡æœ¬ï¼Œæ˜¯æœ€ç®€å•ç›´æ¥çš„åˆ†å—æ–¹å¼ã€‚**

---

## ä¸€å¥è¯å®šä¹‰

**å›ºå®šå¤§å°åˆ†å—æ˜¯æŒ‰ç…§é¢„è®¾çš„å­—ç¬¦æ•°æˆ– token æ•°å°†æ–‡æœ¬åˆ‡åˆ†æˆç­‰é•¿ç‰‡æ®µçš„æ–¹æ³•ï¼Œé€šè¿‡è®¾ç½®é‡å åŒºåŸŸæ¥é¿å…è¾¹ç•Œä¿¡æ¯ä¸¢å¤±ï¼Œæ˜¯æœ€ç®€å•ä½†å¯èƒ½ç ´åè¯­ä¹‰å®Œæ•´æ€§çš„åˆ†å—ç­–ç•¥ã€‚**

---

## æ ¸å¿ƒåŸç†

### åŸºæœ¬æ€æƒ³

```
åŸæ–‡ï¼šABCDEFGHIJKLMNOPQRSTUVWXYZ

å›ºå®šå¤§å°åˆ†å—ï¼ˆchunk_size=10, overlap=2ï¼‰ï¼š

Chunk 1: ABCDEFGHIJ
Chunk 2:         IJKLMNOPQR
Chunk 3:                 QRSTUVWXYZ
            â†‘â†‘              â†‘â†‘
          é‡å åŒºåŸŸ        é‡å åŒºåŸŸ
```

### ç®—æ³•æµç¨‹

```
1. è®¾ç½®å‚æ•°ï¼š
   - chunk_size: æ¯ä¸ªå—çš„å¤§å°ï¼ˆå¦‚ 512 å­—ç¬¦ï¼ŒNVIDIA 2025 æ¨èï¼‰
   - overlap: é‡å å¤§å°ï¼ˆå¦‚ 77 å­—ç¬¦ï¼Œ15% overlapï¼‰

2. ä»æ–‡æœ¬å¼€å¤´å¼€å§‹ï¼š
   - å– chunk_size é•¿åº¦çš„æ–‡æœ¬ä½œä¸ºç¬¬ä¸€ä¸ªå—
   - ç§»åŠ¨ (chunk_size - overlap) ä¸ªå­—ç¬¦
   - å–ä¸‹ä¸€ä¸ª chunk_size é•¿åº¦çš„æ–‡æœ¬
   - é‡å¤ç›´åˆ°æ–‡æœ¬ç»“æŸ

3. è¿”å›æ‰€æœ‰å—
```

---

## Python å®ç°

### åŸºç¡€å®ç°

```python
def fixed_size_chunk(text: str, chunk_size: int = 512, overlap: int = 77) -> list[str]:
    """
    å›ºå®šå¤§å°åˆ†å—ï¼ˆ2025-2026 æ¨èå‚æ•°ï¼‰

    Args:
        text: åŸå§‹æ–‡æœ¬
        chunk_size: æ¯ä¸ªå—çš„å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œé»˜è®¤ 512ï¼ˆNVIDIA æ¨èï¼‰
        overlap: ç›¸é‚»å—çš„é‡å éƒ¨åˆ†ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œé»˜è®¤ 77ï¼ˆ15% overlapï¼‰

    Returns:
        åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨
    """
    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap  # é‡å éƒ¨åˆ†

    return chunks

# ç¤ºä¾‹
text = "Pythonæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚" * 50
chunks = fixed_size_chunk(text, chunk_size=512, overlap=77)

print(f"åŸæ–‡é•¿åº¦: {len(text)} å­—ç¬¦")
print(f"åˆ†å—æ•°: {len(chunks)}")
print(f"ç¬¬ä¸€å—: {chunks[0][:100]}...")
print(f"ç¬¬äºŒå—: {chunks[1][:100]}...")
```

### 2025-2026 ä¼˜åŒ–å®ç°

```python
from typing import List

def fixed_size_chunk_optimized(
    text: str,
    chunk_size: int = 512,
    overlap: int = 77,
    preserve_words: bool = True
) -> List[str]:
    """
    ä¼˜åŒ–çš„å›ºå®šå¤§å°åˆ†å—ï¼ˆé¿å…åˆ‡æ–­å•è¯ï¼‰

    Args:
        text: åŸå§‹æ–‡æœ¬
        chunk_size: å—å¤§å°ï¼ˆNVIDIA 2025: 512 for factual queriesï¼‰
        overlap: é‡å å¤§å°ï¼ˆNVIDIA 2025: 15% = 77ï¼‰
        preserve_words: æ˜¯å¦é¿å…åˆ‡æ–­å•è¯

    Returns:
        åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨
    """
    chunks = []
    start = 0

    while start < len(text):
        end = min(start + chunk_size, len(text))

        # å¦‚æœéœ€è¦ä¿æŒå•è¯å®Œæ•´æ€§
        if preserve_words and end < len(text):
            # å‘åæŸ¥æ‰¾æœ€è¿‘çš„ç©ºæ ¼æˆ–æ ‡ç‚¹
            for i in range(end, max(start, end - 50), -1):
                if text[i] in ' \nã€‚ï¼ï¼Ÿ.!?':
                    end = i + 1
                    break

        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)

        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
        start = end - overlap

    return chunks

# ä½¿ç”¨ç¤ºä¾‹
text = """
Pythonæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ã€‚å®ƒä»¥ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚
Pythonæ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼ï¼ŒåŒ…æ‹¬é¢å‘å¯¹è±¡ã€å‘½ä»¤å¼ã€å‡½æ•°å¼å’Œè¿‡ç¨‹å¼ç¼–ç¨‹ã€‚
"""

chunks = fixed_size_chunk_optimized(text, chunk_size=100, overlap=15)
for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}: {chunk}")
```

---

## æ ¸å¿ƒå‚æ•°

### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | 2025-2026 æ¨èå€¼ | ä¼ ç»Ÿæ¨èå€¼ |
|------|------|------------------|-----------|
| `chunk_size` | æ¯ä¸ªå—çš„å¤§å° | 512 tokensï¼ˆäº‹å®æŸ¥è¯¢ï¼‰<br>1024 tokensï¼ˆåˆ†ææŸ¥è¯¢ï¼‰ | 200-1000 å­—ç¬¦ |
| `overlap` | é‡å å¤§å° | 15% (77 tokens for 512) | 10-20% |

**ç ”ç©¶æ¥æº**: [NVIDIA 2025 Chunking Benchmark](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses)

### é‡å ï¼ˆOverlapï¼‰çš„ä½œç”¨

```
æ²¡æœ‰é‡å ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1 â”‚â”‚ Chunk 2 â”‚â”‚ Chunk 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘           â†‘
   è¾¹ç•Œå¤„çš„å¥å­å¯èƒ½è¢«åˆ‡æ–­

æœ‰é‡å ï¼ˆ15% NVIDIA æ¨èï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chunk 1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚ 15% é‡å 
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Chunk 2   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚ 15% é‡å 
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Chunk 3   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘
   è¾¹ç•Œå¤„çš„å†…å®¹åœ¨ä¸¤ä¸ªå—ä¸­éƒ½æœ‰
```

### NVIDIA 2025 ç ”ç©¶å‘ç°

**é‡å ç‡å¯¹æ¯”ï¼š**

| é‡å ç‡ | å‡†ç¡®ç‡ | æˆæœ¬ | æ¨èåœºæ™¯ |
|--------|--------|------|---------|
| 0% | 0.612 | ä½ | æˆæœ¬æ•æ„Ÿ |
| 10% | 0.635 | ä¸­ | ä¸€èˆ¬åœºæ™¯ |
| **15%** | **0.648** | **ä¸­** | **æœ€ä¼˜é€‰æ‹©** |
| 20% | 0.651 | é«˜ | æ”¶ç›Šé€’å‡ |
| 25% | 0.652 | å¾ˆé«˜ | ä¸æ¨è |

**ç»“è®º**: 15% é‡å ç‡æ˜¯æˆæœ¬å’Œæ•ˆæœçš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚

---

## ä¼˜ç¼ºç‚¹åˆ†æ

### ä¼˜ç‚¹

| ä¼˜ç‚¹ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| âœ… **å®ç°ç®€å•** | ä»£ç ä¸åˆ° 10 è¡Œï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤ | å¿«é€ŸåŸå‹ã€MVP |
| âœ… **å—å¤§å°å¯æ§** | ç²¾ç¡®æ§åˆ¶æ¯ä¸ªå—çš„å¤§å°ï¼Œä¾¿äºé¢„ç®—è®¡ç®— | æˆæœ¬æ•æ„Ÿåœºæ™¯ |
| âœ… **å¤„ç†é€Ÿåº¦å¿«** | æ— éœ€è°ƒç”¨ APIï¼Œçº¯æœ¬åœ°è®¡ç®— | å¤§è§„æ¨¡æ–‡æ¡£å¤„ç† |
| âœ… **æ— é¢å¤–æˆæœ¬** | ä¸éœ€è¦ embedding æˆ– LLM è°ƒç”¨ | é¢„ç®—æœ‰é™é¡¹ç›® |

### ç¼ºç‚¹

| ç¼ºç‚¹ | è¯´æ˜ | å½±å“ |
|------|------|------|
| âŒ **å¯èƒ½åˆ‡æ–­å¥å­** | åœ¨ä»»æ„ä½ç½®åˆ‡åˆ†ï¼Œç ´åè¯­ä¹‰å®Œæ•´æ€§ | æ£€ç´¢å‡†ç¡®ç‡ä¸‹é™ |
| âŒ **ä¸è€ƒè™‘è¯­ä¹‰è¾¹ç•Œ** | æ— æ³•è¯†åˆ«æ®µè½ã€ç« èŠ‚ç­‰è‡ªç„¶è¾¹ç•Œ | ä¸Šä¸‹æ–‡ä¸å®Œæ•´ |
| âŒ **å¯èƒ½åˆ‡æ–­ä»£ç å—** | å¯¹ä»£ç æ–‡æ¡£ä¸å‹å¥½ | ä»£ç æ£€ç´¢å¤±è´¥ |
| âŒ **è¡¨æ ¼è¢«ç ´å** | ç»“æ„åŒ–å†…å®¹å¯èƒ½è¢«åˆ‡æ–­ | ä¿¡æ¯ä¸¢å¤± |

---

## åœ¨ RAG å¼€å‘ä¸­çš„åº”ç”¨

### é€‚ç”¨åœºæ™¯

**âœ… æ¨èä½¿ç”¨ï¼š**

1. **çº¯æ–‡æœ¬å†…å®¹**
   - å°è¯´ã€æ–‡ç« ã€åšå®¢
   - æ— æ˜æ˜¾ç»“æ„çš„é•¿æ–‡æœ¬
   - ç¤ºä¾‹ï¼šå°è¯´ç« èŠ‚ã€æ–°é—»æŠ¥é“

2. **å¿«é€ŸåŸå‹å¼€å‘**
   - MVP é˜¶æ®µ
   - æ¦‚å¿µéªŒè¯ï¼ˆPoCï¼‰
   - å¿«é€Ÿè¿­ä»£æµ‹è¯•

3. **æˆæœ¬æ•æ„Ÿåœºæ™¯**
   - é¢„ç®—æœ‰é™çš„é¡¹ç›®
   - å¤§è§„æ¨¡æ–‡æ¡£å¤„ç†
   - æ— éœ€é«˜ç²¾åº¦çš„åœºæ™¯

4. **æ–‡æœ¬ç»“æ„ä¸æ˜æ˜¾**
   - æ— æ®µè½åˆ†éš”çš„æ–‡æœ¬
   - è¿ç»­å™è¿°çš„å†…å®¹
   - ç¤ºä¾‹ï¼šè½¬å½•çš„è¯­éŸ³æ–‡æœ¬

### ä¸é€‚ç”¨åœºæ™¯

**âŒ ä¸æ¨èä½¿ç”¨ï¼š**

1. **ä»£ç æ–‡æ¡£**
   - ä¼šåˆ‡æ–­å‡½æ•°å®šä¹‰
   - ç ´åä»£ç ç»“æ„
   - ç¤ºä¾‹ï¼šAPI æ–‡æ¡£ã€ä»£ç åº“

2. **ç»“æ„åŒ–æ–‡æ¡£**
   - ä¼šç ´åè¡¨æ ¼
   - åˆ‡æ–­åˆ—è¡¨é¡¹
   - ç¤ºä¾‹ï¼šæŠ€æœ¯è§„èŒƒã€æ•°æ®è¡¨

3. **é—®ç­”å¯¹**
   - ä¼šåˆ†ç¦»é—®é¢˜å’Œç­”æ¡ˆ
   - ç ´åé€»è¾‘å…³ç³»
   - ç¤ºä¾‹ï¼šFAQ æ–‡æ¡£

4. **é«˜è´¨é‡è¦æ±‚åœºæ™¯**
   - ç”Ÿäº§ç¯å¢ƒçš„å…³é”®åº”ç”¨
   - éœ€è¦é«˜æ£€ç´¢å‡†ç¡®ç‡
   - ç¤ºä¾‹ï¼šåŒ»ç–—ã€æ³•å¾‹æ–‡æ¡£

---

## 2025-2026 æœ€ä½³å®è·µ

### å®è·µ1ï¼šä½¿ç”¨ NVIDIA æ¨èå‚æ•°

```python
# NVIDIA 2025 ç ”ç©¶æ¨èé…ç½®
def create_nvidia_splitter(query_type: str = "factual"):
    """æ ¹æ®æŸ¥è¯¢ç±»å‹åˆ›å»ºæœ€ä¼˜åˆ†å—å™¨"""
    if query_type == "factual":
        return fixed_size_chunk_optimized(
            chunk_size=512,
            overlap=77,  # 15% of 512
            preserve_words=True
        )
    elif query_type == "analytical":
        return fixed_size_chunk_optimized(
            chunk_size=1024,
            overlap=154,  # 15% of 1024
            preserve_words=True
        )
    else:
        return fixed_size_chunk_optimized(
            chunk_size=768,
            overlap=115,  # 15% of 768
            preserve_words=True
        )
```

### å®è·µ2ï¼šé¿å…åˆ‡æ–­å•è¯

```python
def smart_fixed_chunk(text: str, chunk_size: int = 512) -> List[str]:
    """æ™ºèƒ½å›ºå®šåˆ†å—ï¼šåœ¨å•è¯è¾¹ç•Œåˆ‡åˆ†"""
    chunks = []
    words = text.split()
    current_chunk = []
    current_size = 0

    for word in words:
        word_size = len(word) + 1  # +1 for space
        if current_size + word_size > chunk_size and current_chunk:
            chunks.append(' '.join(current_chunk))
            current_chunk = [word]
            current_size = word_size
        else:
            current_chunk.append(word)
            current_size += word_size

    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

### å®è·µ3ï¼šç»“åˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼ˆAnthropic æ–¹æ³•ï¼‰

```python
from openai import OpenAI

client = OpenAI()

def fixed_chunk_with_context(text: str, chunk_size: int = 512) -> List[dict]:
    """å›ºå®šåˆ†å— + ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼ˆå‡å°‘ 49% å¤±è´¥ï¼‰"""
    # 1. å›ºå®šå¤§å°åˆ†å—
    chunks = fixed_size_chunk_optimized(text, chunk_size=chunk_size)

    # 2. ä¸ºæ¯ä¸ª chunk æ·»åŠ ä¸Šä¸‹æ–‡
    contextual_chunks = []
    for i, chunk in enumerate(chunks):
        # ç”Ÿæˆä¸Šä¸‹æ–‡ï¼ˆAnthropic æ–¹æ³•ï¼‰
        context = generate_context(chunk, text, i, len(chunks))
        contextual_chunks.append({
            'chunk': chunk,
            'context': context,
            'final_text': f"{context}\n\n{chunk}"
        })

    return contextual_chunks

def generate_context(chunk: str, full_text: str, index: int, total: int) -> str:
    """ä¸º chunk ç”Ÿæˆä¸Šä¸‹æ–‡"""
    prompt = f"""
    ä¸ºæ–‡æ¡£ç‰‡æ®µç”Ÿæˆ 50-100 token çš„ä¸Šä¸‹æ–‡è¯´æ˜ã€‚

    æ–‡æ¡£å¼€å¤´ï¼š{full_text[:1000]}
    ç‰‡æ®µä½ç½®ï¼šç¬¬ {index+1}/{total} å—
    ç‰‡æ®µå†…å®¹ï¼š{chunk[:200]}

    è¦æ±‚ï¼šè¯´æ˜ç‰‡æ®µåœ¨æ–‡æ¡£ä¸­çš„ä½ç½®å’Œä¸»é¢˜ã€‚
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=150
    )
    return response.choices[0].message.content.strip()
```

---

## ä¸å…¶ä»–ç­–ç•¥å¯¹æ¯”

### å›ºå®šå¤§å° vs é€’å½’å­—ç¬¦

| ç‰¹æ€§ | å›ºå®šå¤§å° | é€’å½’å­—ç¬¦ |
|------|----------|----------|
| **å®ç°å¤æ‚åº¦** | â­ ç®€å• | â­â­ ä¸­ç­‰ |
| **è¯­ä¹‰å®Œæ•´æ€§** | âŒ å·® | âœ… å¥½ |
| **å—å¤§å°å¯æ§** | âœ…âœ… ç²¾ç¡® | âœ… å¤§è‡´å¯æ§ |
| **å¤„ç†é€Ÿåº¦** | ğŸš€ğŸš€ğŸš€ æœ€å¿« | ğŸš€ğŸš€ å¿« |
| **é€‚ç”¨åœºæ™¯** | å¿«é€ŸåŸå‹ | é€šç”¨åœºæ™¯ |

### å›ºå®šå¤§å° vs è¯­ä¹‰åˆ†å—

| ç‰¹æ€§ | å›ºå®šå¤§å° | è¯­ä¹‰åˆ†å— |
|------|----------|----------|
| **å®ç°å¤æ‚åº¦** | â­ ç®€å• | â­â­â­ å¤æ‚ |
| **è¯­ä¹‰å®Œæ•´æ€§** | âŒ å·® | âœ…âœ… æœ€å¥½ |
| **API æˆæœ¬** | æ—  | é«˜ï¼ˆéœ€è¦ embeddingï¼‰ |
| **å¤„ç†é€Ÿåº¦** | ğŸš€ğŸš€ğŸš€ æœ€å¿« | ğŸš€ æ…¢ |
| **é€‚ç”¨åœºæ™¯** | æˆæœ¬æ•æ„Ÿ | é«˜è´¨é‡è¦æ±‚ |

---

## å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¤„ç†é•¿æ–‡æ¡£

```python
def process_long_document(file_path: str) -> List[str]:
    """å¤„ç†é•¿æ–‡æ¡£ï¼šå›ºå®šå¤§å°åˆ†å—"""
    # è¯»å–æ–‡æ¡£
    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()

    # NVIDIA 2025 æ¨èé…ç½®
    chunks = fixed_size_chunk_optimized(
        text,
        chunk_size=512,
        overlap=77,
        preserve_words=True
    )

    print(f"æ–‡æ¡£é•¿åº¦: {len(text)} å­—ç¬¦")
    print(f"åˆ†å—æ•°: {len(chunks)}")
    print(f"å¹³å‡å—å¤§å°: {sum(len(c) for c in chunks) // len(chunks)} å­—ç¬¦")

    return chunks
```

### ç¤ºä¾‹2ï¼šæ‰¹é‡å¤„ç†

```python
import os
from pathlib import Path

def batch_process_documents(directory: str) -> dict:
    """æ‰¹é‡å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡æ¡£"""
    results = {}

    for file_path in Path(directory).glob('*.txt'):
        chunks = process_long_document(str(file_path))
        results[file_path.name] = {
            'chunks': chunks,
            'count': len(chunks)
        }

    return results
```

### ç¤ºä¾‹3ï¼šéªŒè¯åˆ†å—è´¨é‡

```python
def validate_fixed_chunks(chunks: List[str], target_size: int = 512):
    """éªŒè¯å›ºå®šå¤§å°åˆ†å—çš„è´¨é‡"""
    sizes = [len(c) for c in chunks]

    print(f"æ€»å—æ•°: {len(chunks)}")
    print(f"ç›®æ ‡å¤§å°: {target_size}")
    print(f"å®é™…å¤§å°: æœ€å°={min(sizes)}, æœ€å¤§={max(sizes)}, å¹³å‡={sum(sizes)//len(sizes)}")

    # æ£€æŸ¥å¤§å°åå·®
    deviations = [abs(s - target_size) / target_size for s in sizes]
    avg_deviation = sum(deviations) / len(deviations)
    print(f"å¹³å‡åå·®: {avg_deviation:.1%}")

    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ‡æ–­å¥å­
    broken_sentences = sum(1 for c in chunks if not c.strip().endswith(('.', 'ã€‚', '!', 'ï¼', '?', 'ï¼Ÿ')))
    print(f"å¯èƒ½åˆ‡æ–­çš„å¥å­: {broken_sentences}/{len(chunks)} ({broken_sentences/len(chunks):.1%})")
```

---

## å¸¸è§é—®é¢˜

### Q1: å›ºå®šå¤§å°åˆ†å—é€‚åˆç”Ÿäº§ç¯å¢ƒå—ï¼Ÿ

**A**: å–å†³äºåœºæ™¯ã€‚

- âœ… **é€‚åˆ**: æˆæœ¬æ•æ„Ÿã€å¿«é€ŸåŸå‹ã€çº¯æ–‡æœ¬å†…å®¹
- âŒ **ä¸é€‚åˆ**: é«˜è´¨é‡è¦æ±‚ã€ç»“æ„åŒ–æ–‡æ¡£ã€ä»£ç æ£€ç´¢

**2025-2026 å»ºè®®**: ç»“åˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼ˆAnthropic æ–¹æ³•ï¼‰å¯ä»¥æ˜¾è‘—æå‡æ•ˆæœã€‚

### Q2: å¦‚ä½•é€‰æ‹© chunk_sizeï¼Ÿ

**A**: æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©ï¼ˆNVIDIA 2025 ç ”ç©¶ï¼‰ï¼š

- **äº‹å®æŸ¥è¯¢**: 512 tokensï¼ˆç²¾å‡†å®šä½ï¼‰
- **åˆ†ææŸ¥è¯¢**: 1024 tokensï¼ˆæ›´å¤šä¸Šä¸‹æ–‡ï¼‰
- **æ··åˆæŸ¥è¯¢**: 768 tokensï¼ˆå¹³è¡¡ï¼‰

### Q3: é‡å ç‡è®¾ç½®å¤šå°‘åˆé€‚ï¼Ÿ

**A**: **15%**ï¼ˆNVIDIA 2025 æœ€ä¼˜ï¼‰

- è¿‡ä½ï¼ˆ<10%ï¼‰ï¼šè¾¹ç•Œä¿¡æ¯ä¸¢å¤±
- è¿‡é«˜ï¼ˆ>20%ï¼‰ï¼šæˆæœ¬å¢åŠ ï¼Œæ”¶ç›Šé€’å‡

### Q4: å¦‚ä½•é¿å…åˆ‡æ–­å¥å­ï¼Ÿ

**A**: ä½¿ç”¨ `preserve_words=True` å‚æ•°ï¼Œåœ¨å•è¯/æ ‡ç‚¹è¾¹ç•Œåˆ‡åˆ†ã€‚

```python
chunks = fixed_size_chunk_optimized(
    text,
    chunk_size=512,
    overlap=77,
    preserve_words=True  # é¿å…åˆ‡æ–­å•è¯
)
```

---

## æ ¸å¿ƒç ”ç©¶æ¥æº

1. **NVIDIA 2025**: [Finding the Best Chunking Strategy](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses)
   - 15% é‡å ç‡æœ€ä¼˜
   - æŸ¥è¯¢ç±»å‹å†³å®šå—å¤§å°
   - é¡µé¢çº§åˆ†å—å‡†ç¡®ç‡æœ€é«˜

2. **Anthropic 2024-2025**: [Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)
   - ä¸Šä¸‹æ–‡æ„ŸçŸ¥å‡å°‘ 49-67% å¤±è´¥
   - å¯ä¸å›ºå®šåˆ†å—ç»“åˆä½¿ç”¨

---

## ä¸‹ä¸€æ­¥å­¦ä¹ 

**åŒçº§æ¦‚å¿µï¼š**
- â†’ [03_æ ¸å¿ƒæ¦‚å¿µ_02_é€’å½’å­—ç¬¦åˆ†å—](./03_æ ¸å¿ƒæ¦‚å¿µ_02_é€’å½’å­—ç¬¦åˆ†å—.md) - ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
- â†’ [03_æ ¸å¿ƒæ¦‚å¿µ_03_è¯­ä¹‰åˆ†å—](./03_æ ¸å¿ƒæ¦‚å¿µ_03_è¯­ä¹‰åˆ†å—.md) - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦

**è¿›é˜¶æŠ€æœ¯ï¼š**
- â†’ [03_æ ¸å¿ƒæ¦‚å¿µ_04_ä»£ç†å¼åˆ†å—Agentic](./03_æ ¸å¿ƒæ¦‚å¿µ_04_ä»£ç†å¼åˆ†å—Agentic.md) - IBM 2025-2026 æœ€æ–°æŠ€æœ¯
- â†’ [03_æ ¸å¿ƒæ¦‚å¿µ_05_ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å—Contextual](./03_æ ¸å¿ƒæ¦‚å¿µ_05_ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å—Contextual.md) - Anthropic æ–¹æ³•

**å®æˆ˜ä»£ç ï¼š**
- â†’ [07_å®æˆ˜ä»£ç _01_å›ºå®šå¤§å°å®ç°](./07_å®æˆ˜ä»£ç _01_å›ºå®šå¤§å°å®ç°.md) - å®Œæ•´å®ç°ä»£ç 
