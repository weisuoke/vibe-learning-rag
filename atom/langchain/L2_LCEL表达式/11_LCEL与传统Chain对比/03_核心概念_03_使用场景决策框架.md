# 核心概念 03：使用场景决策框架

> 系统化的决策框架，帮助你选择 LCEL 还是传统 Chain

---

## 概述

选择 LCEL 还是传统 Chain 不是简单的"新 vs 旧"的问题，而是需要根据具体场景、团队能力、项目需求等多个因素综合决策。本文提供一个系统化的决策框架，帮助你做出正确的技术选择。

---

## 1. 决策矩阵

### 1.1 五维决策模型

| 维度 | 权重 | LCEL 得分 | 传统 Chain 得分 | 说明 |
|------|------|-----------|----------------|------|
| **复杂度** | 高 | 8/10 | 4/10 | 工作流复杂度 |
| **性能需求** | 高 | 9/10 | 5/10 | 延迟、吞吐量要求 |
| **功能需求** | 中 | 9/10 | 6/10 | 流式、并行、条件路由 |
| **团队能力** | 中 | 7/10 | 8/10 | 学习曲线、熟悉度 |
| **时间压力** | 中 | 8/10 | 7/10 | 开发速度、迁移成本 |

**计算公式**：
```
总分 = Σ(维度得分 × 权重)

LCEL 总分 = 8×高 + 9×高 + 9×中 + 7×中 + 8×中 = 8.2
传统 Chain 总分 = 4×高 + 5×高 + 6×中 + 8×中 + 7×中 = 5.8

推荐：LCEL
```

### 1.2 复杂度维度

**简单场景**（1-3分）：
- 单次 LLM 调用
- 无需组合多个步骤
- 无需流式或并行

**建议**：直接用 OpenAI SDK，无需框架

**中等场景**（4-6分）：
- 2-5个步骤的线性工作流
- 基本的 RAG 应用
- 简单的对话系统

**建议**：LCEL（简洁、性能好）

**复杂场景**（7-10分）：
- 多步推理
- 条件路由和分支
- 并行执行多个任务
- 需要状态管理

**建议**：LCEL + LangGraph

### 1.3 性能需求维度

**低性能需求**（1-3分）：
- 离线批处理
- 非实时场景
- 用户量小

**建议**：传统 Chain 可接受

**中等性能需求**（4-6分）：
- 实时响应（<2s）
- 中等用户量（<1000 QPS）
- 需要流式输出

**建议**：LCEL

**高性能需求**（7-10分）：
- 极低延迟（<500ms）
- 高并发（>1000 QPS）
- 需要并行优化

**建议**：LCEL + 性能优化

### 1.4 功能需求维度

**基础功能**（1-3分）：
- 简单的 prompt + LLM + parser
- 无需流式输出
- 无需并行执行

**建议**：传统 Chain 可接受

**中等功能**（4-6分）：
- 需要流式输出
- 需要基本的并行执行
- 需要简单的条件路由

**建议**：LCEL

**高级功能**（7-10分）：
- 复杂的条件路由
- 动态工作流
- 状态持久化
- 多代理协作

**建议**：LCEL + LangGraph

### 1.5 团队能力维度

**新手团队**（1-3分）：
- 不熟悉 LangChain
- Python 基础薄弱
- 无 AI 应用开发经验

**建议**：LCEL（学习曲线平缓）

**中级团队**（4-6分）：
- 熟悉 Python
- 有基本的 AI 应用开发经验
- 了解 LangChain 基础

**建议**：LCEL

**高级团队**（7-10分）：
- 精通 Python 和 AI 应用开发
- 深入理解 LangChain 架构
- 有生产环境经验

**建议**：LCEL + 高级特性

### 1.6 时间压力维度

**充裕时间**（1-3分）：
- 有时间学习新技术
- 可以进行充分测试
- 可以逐步优化

**建议**：LCEL（长期收益）

**中等时间**（4-6分）：
- 需要快速交付
- 有一定测试时间
- 可以后续优化

**建议**：LCEL（开发速度快）

**紧急时间**（7-10分）：
- 极度紧急
- 无法学习新技术
- 团队熟悉传统 Chain

**建议**：保持现状（如果已有代码）

---

## 2. 使用场景分类

### 2.1 LCEL 优先场景

#### 场景 1：新项目开发

**特征**：
- 从零开始
- 无历史包袱
- 可以选择最佳技术栈

**为什么选 LCEL**：
- 性能好（2-3倍提升）
- 代码简洁（减少90%代码量）
- 是主流趋势（57%企业采用）
- 生态支持好（新工具只支持 LCEL）

**示例**：
```python
# 新项目：RAG 文档问答
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

#### 场景 2：性能瓶颈优化

**特征**：
- 现有系统性能差
- 用户抱怨响应慢
- 需要支持更高并发

**为什么选 LCEL**：
- 自动并行优化
- 流式输出减少首 token 时间
- 批处理提升吞吐量

**示例**：
```python
# 优化前：顺序执行，3.5s
summary = chain1.run(input)
keywords = chain2.run(input)

# 优化后：并行执行，1.8s
from langchain_core.runnables import RunnableParallel

results = RunnableParallel(
    summary=chain1,
    keywords=chain2
).invoke(input)
```

#### 场景 3：复杂工作流

**特征**：
- 多步推理
- 条件路由
- 并行执行
- 动态组合

**为什么选 LCEL**：
- 灵活的组合方式
- 支持条件路由（RunnableBranch）
- 支持并行执行（RunnableParallel）
- 代码清晰易维护

**示例**：
```python
# 复杂工作流：条件路由 + 并行执行
from langchain_core.runnables import RunnableBranch, RunnableParallel

chain = RunnableBranch(
    (lambda x: len(x) < 100, short_chain),
    (lambda x: len(x) < 1000, RunnableParallel(
        summary=summary_chain,
        keywords=keywords_chain
    )),
    long_chain
)
```

#### 场景 4：需要流式输出

**特征**：
- 实时对话
- 长文本生成
- 用户体验要求高

**为什么选 LCEL**：
- 默认支持流式
- 首 token 时间减少 60-80%
- 无需修改代码

**示例**：
```python
# LCEL 流式输出
for chunk in chain.stream(input):
    print(chunk, end="", flush=True)
```

### 2.2 传统 Chain 可接受场景

#### 场景 1：遗留代码维护

**特征**：
- 已有大量传统 Chain 代码
- 功能稳定，无性能问题
- 无迁移预算

**为什么可接受**：
- 避免不必要的风险
- 节省迁移成本
- 保持稳定性

**注意**：
- 传统 Chain 已弃用，不再维护
- 安全漏洞不会修复
- 新特性无法使用

**建议**：
- 制定长期迁移计划
- 新功能使用 LCEL
- 逐步替换旧代码

#### 场景 2：极简单的单次调用

**特征**：
- 只需要一次 LLM 调用
- 无需组合多个步骤
- 无需框架抽象

**为什么可接受**：
- 框架抽象是多余的
- 直接用 SDK 更简单

**建议**：
- 直接用 OpenAI SDK
- 无需 LangChain

**示例**：
```python
# 直接用 SDK
from openai import OpenAI

client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello"}]
)
```

### 2.3 混合使用场景

#### 场景 1：渐进式迁移

**特征**：
- 正在从传统 Chain 迁移到 LCEL
- 需要保持兼容性
- 逐步替换旧代码

**策略**：
- 用 RunnableLambda 包装旧代码
- 新功能使用 LCEL
- 逐步替换旧代码

**示例**：
```python
from langchain_core.runnables import RunnableLambda

# 包装旧代码
legacy_runnable = RunnableLambda(lambda x: old_chain.run(x))

# 与 LCEL 组合
chain = prompt | llm | legacy_runnable | parser
```

#### 场景 2：团队过渡期

**特征**：
- 团队正在学习 LCEL
- 部分成员熟悉传统 Chain
- 需要平滑过渡

**策略**：
- 培训团队学习 LCEL
- 新项目使用 LCEL
- 旧项目保持原样

---

## 3. 真实案例分析

### 3.1 案例 1：Klarna 客服系统

**背景**：
- 全球支付公司
- 客服系统需要处理大量查询
- 响应时间要求高

**挑战**：
- 传统 Chain 响应慢（平均 5s）
- 用户体验差
- 成本高

**解决方案**：
- 迁移到 LCEL
- 使用 RunnableParallel 并行检索
- 启用流式输出

**结果**：
- 查询时间缩短 **80%**（5s → 1s）
- 用户满意度提升 **40%**
- 成本降低 **30%**

**关键决策因素**：
- 性能需求：高（9/10）
- 复杂度：中（6/10）
- 功能需求：高（需要流式）
- 团队能力：高（8/10）

**决策**：LCEL

### 3.2 案例 2：Elastic 搜索增强

**背景**：
- 搜索引擎公司
- 需要 AI 增强搜索结果
- 高并发场景

**挑战**：
- 传统 Chain 吞吐量低
- 无法支持高并发
- 成本高

**解决方案**：
- 迁移到 LCEL
- 使用 batch 方法批处理
- 优化并发控制

**结果**：
- 性能提升 **3倍**
- 吞吐量提升 **150%**
- 成本降低 **40%**

**关键决策因素**：
- 性能需求：极高（10/10）
- 复杂度：中（5/10）
- 功能需求：高（需要批处理）
- 团队能力：高（9/10）

**决策**：LCEL

### 3.3 案例 3：金融服务公司 RAG 系统

**背景**：
- 金融服务公司
- 内部知识库问答系统
- 需要高准确性和低延迟

**挑战**：
- 传统 Chain 性能差
- 无法并行检索多个数据源
- 维护成本高

**解决方案**：
- 迁移到 LCEL
- 并行检索多个数据源
- 使用 ReRank 提升准确性

**结果**：
- 性能提升 **2.5倍**
- 准确性提升 **15%**
- 年度成本节省 **$4.2M**

**关键决策因素**：
- 性能需求：高（8/10）
- 复杂度：高（8/10）
- 功能需求：高（需要并行）
- 团队能力：高（8/10）

**决策**：LCEL

---

## 4. 反模式（Anti-Patterns）

### 4.1 不应该使用 LCEL 的场景

#### 反模式 1：极简单的脚本

**错误做法**：
```python
# 过度工程：用 LCEL 做简单任务
from langchain_core.runnables import RunnableLambda

chain = RunnableLambda(lambda x: x.upper())
result = chain.invoke("hello")
```

**正确做法**：
```python
# 直接用 Python
result = "hello".upper()
```

**原因**：
- 框架抽象是多余的
- 增加复杂度
- 无性能收益

#### 反模式 2：团队完全不熟悉且时间紧急

**错误做法**：
- 在紧急项目中强行使用 LCEL
- 团队无人熟悉
- 无时间学习

**正确做法**：
- 使用团队熟悉的技术
- 项目完成后再学习 LCEL
- 下个项目使用 LCEL

**原因**：
- 学习成本 > 收益
- 风险高
- 可能延误项目

### 4.2 不应该使用传统 Chain 的场景

#### 反模式 1：新项目使用传统 Chain

**错误做法**：
```python
# 新项目还在用传统 Chain
from langchain.chains import LLMChain

chain = LLMChain(llm=llm, prompt=prompt)
```

**正确做法**：
```python
# 新项目直接用 LCEL
chain = prompt | llm | parser
```

**原因**：
- 传统 Chain 已弃用
- 性能差
- 技术债务

#### 反模式 2：性能瓶颈不优化

**错误做法**：
- 明知性能差
- 不迁移到 LCEL
- 用户抱怨

**正确做法**：
- 识别性能瓶颈
- 迁移到 LCEL
- 优化性能

**原因**：
- 用户体验差
- 竞争力下降
- 成本高

---

## 5. 决策流程图

```
开始
  ↓
是新项目？
  ├─ 是 → 用 LCEL
  └─ 否 → 有性能问题？
           ├─ 是 → 迁移到 LCEL
           └─ 否 → 需要新功能？
                    ├─ 是（流式/并行） → 迁移到 LCEL
                    └─ 否 → 功能稳定？
                             ├─ 是 → 保持原样（制定迁移计划）
                             └─ 否 → 评估迁移成本
                                      ├─ 成本低 → 迁移到 LCEL
                                      └─ 成本高 → 渐进式迁移
```

---

## 6. 决策检查清单

### 6.1 技术因素

- [ ] 工作流复杂度如何？（简单/中等/复杂）
- [ ] 性能需求如何？（低/中/高）
- [ ] 需要哪些功能？（流式/并行/条件路由）
- [ ] 是否需要状态管理？
- [ ] 是否需要多代理协作？

### 6.2 团队因素

- [ ] 团队熟悉 LCEL 吗？
- [ ] 团队熟悉传统 Chain 吗？
- [ ] 有时间学习新技术吗？
- [ ] 有人可以指导吗？

### 6.3 项目因素

- [ ] 是新项目还是旧项目？
- [ ] 时间压力如何？
- [ ] 预算如何？
- [ ] 有迁移风险吗？

### 6.4 长期因素

- [ ] 项目会持续维护吗？
- [ ] 会有新功能开发吗？
- [ ] 团队会扩张吗？
- [ ] 需要招聘新人吗？

---

## 7. 决策建议总结

### 7.1 强烈推荐 LCEL

- ✅ 新项目开发
- ✅ 性能瓶颈优化
- ✅ 复杂工作流
- ✅ 需要流式输出
- ✅ 需要并行执行
- ✅ 长期维护项目

### 7.2 可以使用传统 Chain

- ⚠️ 遗留代码维护（短期）
- ⚠️ 功能稳定无性能问题（短期）
- ⚠️ 无迁移预算（短期）

**注意**：传统 Chain 已弃用，只是短期可接受

### 7.3 直接用 SDK

- ✅ 极简单的单次调用
- ✅ 无需组合多个步骤
- ✅ 无需框架抽象

### 7.4 混合使用

- ✅ 渐进式迁移
- ✅ 团队过渡期
- ✅ 保持兼容性

---

## 8. 实战决策示例

### 示例 1：创业公司 MVP

**场景**：
- 创业公司开发 MVP
- 团队 3 人，都是新手
- 时间紧急（2周）
- 简单的 RAG 应用

**决策过程**：
1. 是新项目？是 → 考虑 LCEL
2. 团队熟悉吗？否 → 但学习曲线平缓
3. 时间紧急？是 → 但 LCEL 开发速度快
4. 复杂度？中等 → LCEL 适合

**决策**：LCEL

**理由**：
- 新项目应该用最佳技术
- LCEL 学习曲线平缓
- 开发速度快
- 长期收益大

### 示例 2：大型企业遗留系统

**场景**：
- 大型企业遗留系统
- 10万行传统 Chain 代码
- 功能稳定，无性能问题
- 无迁移预算

**决策过程**：
1. 是新项目？否
2. 有性能问题？否
3. 需要新功能？否
4. 功能稳定？是 → 保持原样

**决策**：保持原样（短期），制定迁移计划（长期）

**理由**：
- 避免不必要的风险
- 节省迁移成本
- 但需要制定长期迁移计划

### 示例 3：高并发 API 服务

**场景**：
- 高并发 API 服务
- 现有传统 Chain 性能差
- 用户抱怨响应慢
- 需要支持 1000+ QPS

**决策过程**：
1. 是新项目？否
2. 有性能问题？是 → 迁移到 LCEL

**决策**：迁移到 LCEL

**理由**：
- 性能瓶颈明显
- LCEL 可提升 2-3 倍性能
- 用户体验改善
- ROI 高

---

## 9. 总结

### 9.1 核心原则

1. **新项目优先 LCEL**：性能好、代码简洁、是趋势
2. **性能瓶颈必须迁移**：2-3倍性能提升
3. **遗留代码短期可接受**：但需制定迁移计划
4. **极简单场景用 SDK**：无需框架抽象

### 9.2 决策框架

1. **评估五个维度**：复杂度、性能、功能、团队、时间
2. **计算总分**：加权求和
3. **参考案例**：学习成功经验
4. **避免反模式**：不要过度工程或固守旧技术

### 9.3 行动建议

1. **立即行动**：新项目直接用 LCEL
2. **短期计划**：评估旧项目迁移优先级
3. **长期投资**：学习 LCEL 和 LangGraph
4. **持续学习**：关注 2025-2026 年的最新发展

---

**下一步**：阅读 `03_核心概念_04_迁移策略与路径规划.md` 学习如何安全地迁移到 LCEL
