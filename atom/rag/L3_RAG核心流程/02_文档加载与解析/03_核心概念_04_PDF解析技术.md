# 核心概念4：PDF解析技术

> 对比pypdf、pdfplumber、PyMuPDF、Docling等PDF解析器的特点和适用场景

---

## 为什么PDF解析如此重要？

PDF是RAG系统中最常见的文档格式，但也是最难解析的格式之一：
- PDF是**页面描述语言**，不是文档格式
- 文本可能是图片（扫描版）
- 布局复杂（多列、表格、图表）
- 字体编码问题

**选择合适的PDF解析器直接影响RAG系统的数据质量。**

---

## 1. PDF解析器对比（2025-2026）

### 1.1 主流解析器概览

| 解析器 | 速度 | 文本提取 | 表格提取 | 布局保留 | 维护状态 | 适用场景 |
|--------|------|---------|---------|---------|---------|---------|
| **pypdf** | ⚡⚡⚡ | ⭐⭐⭐ | ⭐ | ⭐ | 活跃 | 简单PDF、快速原型 |
| **pdfplumber** | ⚡⚡ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | 活跃 | 复杂PDF、表格提取 |
| **PyMuPDF** | ⚡⚡⚡ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | 活跃 | 高性能需求 |
| **Docling** | ⚡ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 新兴(2025) | 高质量要求、AI增强 |
| **pdfminer.six** | ⚡ | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ | 维护中 | 低级控制需求 |

---

## 2. pypdf - 轻量级快速解析

### 2.1 特点

**优势：**
- 纯Python实现，无外部依赖
- 速度快，内存占用小
- API简单易用
- 支持PDF合并、分割、加密

**劣势：**
- 表格提取能力弱
- 复杂布局处理不佳
- 不保留格式信息

### 2.2 使用示例

```python
"""
pypdf基础使用
适用场景：简单PDF文本提取
"""

from pypdf import PdfReader
from langchain.schema import Document

def load_pdf_with_pypdf(file_path: str) -> list[Document]:
    """使用pypdf加载PDF"""
    reader = PdfReader(file_path)
    documents = []

    for page_num, page in enumerate(reader.pages):
        # 提取文本
        text = page.extract_text()

        # 创建Document
        doc = Document(
            page_content=text,
            metadata={
                "source": file_path,
                "page": page_num,
                "total_pages": len(reader.pages),
                "parser": "pypdf"
            }
        )
        documents.append(doc)

    return documents

# 使用示例
docs = load_pdf_with_pypdf("simple_report.pdf")
print(f"提取了 {len(docs)} 页")
print(f"第一页内容: {docs[0].page_content[:200]}...")
```

### 2.3 提取PDF元数据

```python
from pypdf import PdfReader

def extract_pdf_metadata(file_path: str) -> dict:
    """提取PDF元数据"""
    reader = PdfReader(file_path)
    metadata = reader.metadata

    return {
        "title": metadata.get("/Title", ""),
        "author": metadata.get("/Author", ""),
        "subject": metadata.get("/Subject", ""),
        "creator": metadata.get("/Creator", ""),
        "producer": metadata.get("/Producer", ""),
        "creation_date": metadata.get("/CreationDate", ""),
        "page_count": len(reader.pages)
    }

# 使用示例
meta = extract_pdf_metadata("report.pdf")
print(f"标题: {meta['title']}")
print(f"作者: {meta['author']}")
print(f"页数: {meta['page_count']}")
```

---

## 3. pdfplumber - 表格和布局专家

### 3.1 特点

**优势：**
- 优秀的表格提取能力
- 保留文本位置信息
- 支持提取图片、线条
- 可以获取字体、颜色等格式信息

**劣势：**
- 速度较慢
- 内存占用较大
- 依赖pdfminer.six

### 3.2 文本提取

```python
"""
pdfplumber文本提取
适用场景：需要保留布局信息的PDF
"""

import pdfplumber
from langchain.schema import Document

def load_pdf_with_pdfplumber(file_path: str) -> list[Document]:
    """使用pdfplumber加载PDF"""
    documents = []

    with pdfplumber.open(file_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            # 提取文本
            text = page.extract_text()

            # 提取页面信息
            metadata = {
                "source": file_path,
                "page": page_num,
                "total_pages": len(pdf.pages),
                "parser": "pdfplumber",
                "page_width": page.width,
                "page_height": page.height
            }

            doc = Document(page_content=text, metadata=metadata)
            documents.append(doc)

    return documents
```

### 3.3 表格提取（核心优势）

```python
import pdfplumber
import pandas as pd

def extract_tables_from_pdf(file_path: str) -> list[pd.DataFrame]:
    """提取PDF中的所有表格"""
    all_tables = []

    with pdfplumber.open(file_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            # 提取表格
            tables = page.extract_tables()

            for table_num, table in enumerate(tables):
                # 转换为DataFrame
                df = pd.DataFrame(table[1:], columns=table[0])

                # 添加元数据
                df.attrs['page'] = page_num
                df.attrs['table_num'] = table_num

                all_tables.append(df)

                print(f"页面 {page_num}, 表格 {table_num}:")
                print(df.head())
                print()

    return all_tables

# 使用示例
tables = extract_tables_from_pdf("report_with_tables.pdf")
print(f"提取了 {len(tables)} 个表格")
```

### 3.4 提取文本位置信息

```python
import pdfplumber

def extract_text_with_positions(file_path: str, page_num: int = 0):
    """提取文本及其位置信息"""
    with pdfplumber.open(file_path) as pdf:
        page = pdf.pages[page_num]

        # 提取单词及位置
        words = page.extract_words()

        for word in words[:10]:  # 只显示前10个词
            print(f"文本: {word['text']}")
            print(f"位置: ({word['x0']:.2f}, {word['top']:.2f})")
            print(f"字体大小: {word['height']:.2f}")
            print()

# 使用示例
extract_text_with_positions("report.pdf")
```

---

## 4. PyMuPDF (fitz) - 高性能解析器

### 4.1 特点

**优势：**
- 速度极快（C++实现）
- 功能全面（文本、图片、注释）
- 支持PDF编辑和创建
- 内存效率高

**劣势：**
- 表格提取需要额外处理
- API相对复杂
- 依赖外部C库

### 4.2 基础使用

```python
"""
PyMuPDF (fitz) 基础使用
适用场景：高性能需求、大批量PDF处理
"""

import fitz  # PyMuPDF
from langchain.schema import Document

def load_pdf_with_pymupdf(file_path: str) -> list[Document]:
    """使用PyMuPDF加载PDF"""
    doc = fitz.open(file_path)
    documents = []

    for page_num in range(len(doc)):
        page = doc[page_num]

        # 提取文本
        text = page.get_text()

        # 创建Document
        document = Document(
            page_content=text,
            metadata={
                "source": file_path,
                "page": page_num,
                "total_pages": len(doc),
                "parser": "pymupdf"
            }
        )
        documents.append(document)

    doc.close()
    return documents
```

### 4.3 提取图片

```python
import fitz
import os

def extract_images_from_pdf(file_path: str, output_dir: str = "images"):
    """提取PDF中的所有图片"""
    os.makedirs(output_dir, exist_ok=True)

    doc = fitz.open(file_path)
    image_count = 0

    for page_num in range(len(doc)):
        page = doc[page_num]

        # 获取页面中的图片
        image_list = page.get_images()

        for img_index, img in enumerate(image_list):
            xref = img[0]
            base_image = doc.extract_image(xref)

            # 保存图片
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = f"{output_dir}/page{page_num}_img{img_index}.{image_ext}"

            with open(image_filename, "wb") as f:
                f.write(image_bytes)

            image_count += 1
            print(f"提取图片: {image_filename}")

    doc.close()
    print(f"\n总共提取 {image_count} 张图片")

# 使用示例
extract_images_from_pdf("report.pdf")
```

### 4.4 高级文本提取（保留格式）

```python
import fitz

def extract_text_with_format(file_path: str, page_num: int = 0):
    """提取文本并保留格式信息"""
    doc = fitz.open(file_path)
    page = doc[page_num]

    # 提取文本块（包含格式信息）
    blocks = page.get_text("dict")["blocks"]

    for block in blocks:
        if block["type"] == 0:  # 文本块
            for line in block["lines"]:
                for span in line["spans"]:
                    print(f"文本: {span['text']}")
                    print(f"字体: {span['font']}")
                    print(f"大小: {span['size']}")
                    print(f"颜色: {span['color']}")
                    print()

    doc.close()

# 使用示例
extract_text_with_format("report.pdf")
```

---

## 5. Docling - AI增强解析器（2025新技术）

### 5.1 特点

**优势：**
- AI驱动的布局理解
- 优秀的表格识别和提取
- 保留文档结构（标题、段落、列表）
- 支持复杂多列布局
- 输出Markdown格式

**劣势：**
- 速度较慢
- 需要较多计算资源
- 相对较新，生态系统还在发展

### 5.2 基础使用

```python
"""
Docling基础使用（2025最新）
适用场景：高质量要求、复杂文档结构
"""

from docling.document_converter import DocumentConverter

def load_pdf_with_docling(file_path: str):
    """使用Docling加载PDF"""
    # 初始化转换器
    converter = DocumentConverter()

    # 转换PDF
    result = converter.convert(file_path)

    # 获取Markdown格式输出
    markdown_text = result.document.export_to_markdown()

    print("=== Docling解析结果 ===")
    print(markdown_text[:500])
    print("\n...")

    # 获取结构化数据
    print("\n=== 文档结构 ===")
    for element in result.document.elements[:5]:
        print(f"类型: {element.type}")
        print(f"内容: {element.text[:100]}...")
        print()

    return result

# 使用示例
# result = load_pdf_with_docling("complex_report.pdf")
```

### 5.3 表格提取（Docling优势）

```python
from docling.document_converter import DocumentConverter

def extract_tables_with_docling(file_path: str):
    """使用Docling提取表格（高质量）"""
    converter = DocumentConverter()
    result = converter.convert(file_path)

    # 提取所有表格
    tables = [elem for elem in result.document.elements if elem.type == "table"]

    print(f"找到 {len(tables)} 个表格\n")

    for i, table in enumerate(tables):
        print(f"=== 表格 {i+1} ===")
        print(f"页码: {table.page_number}")
        print(f"内容:\n{table.text}")
        print()

# 使用示例
# extract_tables_with_docling("report_with_tables.pdf")
```

---

## 6. 解析器选择策略

### 6.1 决策树

```python
def choose_pdf_parser(file_path: str, requirements: dict) -> str:
    """
    根据需求选择PDF解析器

    requirements = {
        'speed_priority': bool,      # 速度优先
        'quality_priority': bool,    # 质量优先
        'has_tables': bool,          # 包含表格
        'complex_layout': bool,      # 复杂布局
        'batch_processing': bool     # 批量处理
    }
    """

    # 1. 速度优先 + 简单文档
    if requirements.get('speed_priority') and not requirements.get('complex_layout'):
        return 'pypdf'

    # 2. 包含表格
    if requirements.get('has_tables'):
        if requirements.get('quality_priority'):
            return 'docling'  # 最高质量
        else:
            return 'pdfplumber'  # 平衡质量和速度

    # 3. 复杂布局 + 高质量要求
    if requirements.get('complex_layout') and requirements.get('quality_priority'):
        return 'docling'

    # 4. 批量处理 + 性能要求
    if requirements.get('batch_processing'):
        return 'pymupdf'  # 最快

    # 5. 默认：平衡方案
    return 'pdfplumber'

# 使用示例
requirements = {
    'speed_priority': False,
    'quality_priority': True,
    'has_tables': True,
    'complex_layout': True,
    'batch_processing': False
}

parser = choose_pdf_parser("report.pdf", requirements)
print(f"推荐使用: {parser}")
```

### 6.2 自适应解析

```python
from langchain.schema import Document
from typing import List

class AdaptivePDFLoader:
    """自适应PDF加载器：自动选择最优解析器"""

    def __init__(self, quality_threshold: float = 0.8):
        self.quality_threshold = quality_threshold

    def load(self, file_path: str) -> List[Document]:
        """
        自适应加载策略：
        1. 先用pypdf快速尝试
        2. 评估质量
        3. 如果质量不够，升级到pdfplumber
        4. 如果还不够，使用docling
        """
        # 第一次尝试：pypdf（最快）
        print("尝试 pypdf...")
        docs = self._load_with_pypdf(file_path)
        quality = self._assess_quality(docs)
        print(f"pypdf 质量评分: {quality:.2f}")

        if quality >= self.quality_threshold:
            print("✅ pypdf 质量足够")
            return docs

        # 第二次尝试：pdfplumber（平衡）
        print("\n升级到 pdfplumber...")
        docs = self._load_with_pdfplumber(file_path)
        quality = self._assess_quality(docs)
        print(f"pdfplumber 质量评分: {quality:.2f}")

        if quality >= self.quality_threshold:
            print("✅ pdfplumber 质量足够")
            return docs

        # 第三次尝试：docling（最高质量）
        print("\n升级到 docling（最高质量）...")
        # docs = self._load_with_docling(file_path)
        # return docs

        # 如果没有docling，返回pdfplumber结果
        return docs

    def _load_with_pypdf(self, file_path: str) -> List[Document]:
        """使用pypdf加载"""
        from pypdf import PdfReader

        reader = PdfReader(file_path)
        docs = []

        for page_num, page in enumerate(reader.pages):
            text = page.extract_text()
            doc = Document(
                page_content=text,
                metadata={"source": file_path, "page": page_num, "parser": "pypdf"}
            )
            docs.append(doc)

        return docs

    def _load_with_pdfplumber(self, file_path: str) -> List[Document]:
        """使用pdfplumber加载"""
        import pdfplumber

        docs = []
        with pdfplumber.open(file_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                text = page.extract_text()
                doc = Document(
                    page_content=text,
                    metadata={"source": file_path, "page": page_num, "parser": "pdfplumber"}
                )
                docs.append(doc)

        return docs

    def _assess_quality(self, docs: List[Document]) -> float:
        """评估解析质量"""
        if not docs:
            return 0.0

        scores = []
        for doc in docs:
            text = doc.page_content

            # 指标1：文本长度
            length_score = min(len(text) / 500, 1.0)

            # 指标2：特殊字符比例
            if len(text) > 0:
                special_ratio = sum(1 for c in text if not c.isalnum() and not c.isspace()) / len(text)
                special_score = 1.0 - min(special_ratio / 0.3, 1.0)
            else:
                special_score = 0.0

            # 综合评分
            doc_score = (length_score + special_score) / 2
            scores.append(doc_score)

        return sum(scores) / len(scores)

# 使用示例
loader = AdaptivePDFLoader(quality_threshold=0.8)
docs = loader.load("report.pdf")
print(f"\n最终得到 {len(docs)} 个文档")
```

---

## 7. 性能对比（2025-2026基准测试）

### 7.1 测试场景

```python
import time
from typing import Callable

def benchmark_pdf_parser(
    file_path: str,
    parser_func: Callable,
    parser_name: str
):
    """性能基准测试"""
    print(f"\n=== 测试 {parser_name} ===")

    # 测试速度
    start_time = time.time()
    docs = parser_func(file_path)
    end_time = time.time()

    elapsed = end_time - start_time

    # 统计结果
    total_chars = sum(len(doc.page_content) for doc in docs)
    avg_chars_per_page = total_chars / len(docs) if docs else 0

    print(f"页数: {len(docs)}")
    print(f"总字符数: {total_chars}")
    print(f"平均每页字符数: {avg_chars_per_page:.0f}")
    print(f"耗时: {elapsed:.2f}秒")
    print(f"速度: {len(docs)/elapsed:.2f} 页/秒")

# 测试所有解析器
# benchmark_pdf_parser("test.pdf", load_pdf_with_pypdf, "pypdf")
# benchmark_pdf_parser("test.pdf", load_pdf_with_pdfplumber, "pdfplumber")
# benchmark_pdf_parser("test.pdf", load_pdf_with_pymupdf, "pymupdf")
```

### 7.2 典型性能数据（参考）

| 解析器 | 10页PDF | 100页PDF | 表格提取 | 内存占用 |
|--------|---------|----------|---------|---------|
| pypdf | 0.5秒 | 3秒 | 不支持 | 低 |
| pdfplumber | 2秒 | 15秒 | 优秀 | 中等 |
| PyMuPDF | 0.3秒 | 2秒 | 需处理 | 低 |
| Docling | 5秒 | 40秒 | 优秀 | 高 |

---

## 8. 在RAG中的应用

### 8.1 构建高质量知识库

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# 1. 使用自适应加载器
loader = AdaptivePDFLoader(quality_threshold=0.8)
documents = loader.load("knowledge_base/report.pdf")

# 2. 分块
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
chunks = splitter.split_documents(documents)

# 3. 向量化并存储
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    chunks,
    embeddings,
    persist_directory="./chroma_db"
)

print(f"知识库构建完成，包含 {len(chunks)} 个文本块")
```

---

## 总结

**PDF解析器选择指南：**

1. **简单PDF + 速度优先** → pypdf
2. **包含表格** → pdfplumber 或 Docling
3. **复杂布局 + 高质量** → Docling
4. **批量处理 + 高性能** → PyMuPDF
5. **不确定** → 使用自适应策略

**在RAG中的最佳实践：**
- 先用简单解析器尝试
- 评估质量后决定是否升级
- 批量处理时考虑性能
- 表格密集型文档优先使用pdfplumber或Docling

---

## 参考来源

> **参考来源：**
> - [pypdf Documentation](https://pypdf.readthedocs.io/) (2025)
> - [pdfplumber Documentation](https://github.com/jsvine/pdfplumber) (2025)
> - [PyMuPDF Documentation](https://pymupdf.readthedocs.io/) (2025)
> - [Docling Documentation](https://www.docling.ai/) - IBM最新PDF解析器 (2025)
> - [PDF Parsing Benchmarks](https://github.com/py-pdf/benchmarks) (2025-2026)

---

**版本：** v1.0
**最后更新：** 2026-02-15
**下一步：** 阅读 [03_核心概念_05_Office文档处理.md](./03_核心概念_05_Office文档处理.md)
