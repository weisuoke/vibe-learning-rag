# 化骨绵掌

> 10个2分钟知识卡片，系统掌握多向量检索

---

## 卡片1：直觉理解

**一句话：** 多向量检索就像"问多个专家的意见，然后综合决策"

**举例：**
```
你想买一台笔记本电脑：
- 问技术专家：性能如何？（CPU、GPU、内存）
- 问设计师：外观如何？（颜色、材质、重量）
- 问销售：价格如何？（性价比、促销）

最后综合三个专家的意见，选择最合适的。

多向量检索 = 同时问多个"专家"（向量字段），然后融合结果。
```

**应用：** 在 RAG 系统中，同时检索文档的文本向量和图表向量，融合后的结果比单一向量更准确。

---

## 卡片2：形式化定义

**一句话：** 在单个 Collection 中定义多个向量字段，通过 `hybrid_search()` 并行检索并融合结果

**精确表述：**
```python
# 定义：多个向量字段
fields = [
    FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=1536),
    FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=512),
]

# 检索：并行执行
results = collection.hybrid_search(
    reqs=[text_req, image_req],  # 多个检索请求
    rerank=RRFRanker(),          # 融合算法
    limit=5                      # 最终返回数量
)
```

**关键要素：**
1. 多个向量字段（2-3个为宜）
2. 并行检索（延迟 ≈ max(单个延迟)）
3. 融合算法（RRF 或加权平均）

---

## 卡片3：核心概念 - 多字段向量

**一句话：** 每个向量字段存储对象的不同维度特征，独立索引和检索

**关键特性：**
```python
# 1. 维度可以不同
FieldSchema(name="text_vector", dim=1536)   # OpenAI
FieldSchema(name="image_vector", dim=512)   # CLIP

# 2. 索引类型可以不同
collection.create_index("text_vector", {"index_type": "HNSW"})
collection.create_index("image_vector", {"index_type": "IVF_FLAT"})

# 3. 度量方式可以不同
text_req = AnnSearchRequest(param={"metric_type": "COSINE"})
image_req = AnnSearchRequest(param={"metric_type": "L2"})
```

**应用：** 在电商搜索中，商品描述向量（1536维）和商品图片向量（512维）可以使用不同的 Embedding 模型和索引类型。

---

## 卡片4：核心概念 - 混合检索

**一句话：** 并行执行多个 ANN 检索，每个请求独立配置参数

**执行流程：**
```
1. 定义多个检索请求
   ├─ text_req: 检索 text_vector, limit=20
   └─ image_req: 检索 image_vector, limit=10

2. 并行执行（内部优化）
   ├─ text_vector ANN 检索（30ms）
   └─ image_vector ANN 检索（40ms）
   总延迟 ≈ 40ms（取最大值）

3. 融合结果
   RRF 或加权平均（5ms）

4. 返回 Top-K
   最终返回 5 个文档
```

**应用：** 在文档问答中，同时检索文本内容和图表，融合后返回最相关的文档。

---

## 卡片5：核心概念 - RRF 融合

**一句话：** 只看排名不看分数，通过倒数排名加权融合

**公式：**
```
RRF(d) = Σ 1 / (k + rank_i(d))

其中：
- d：文档
- rank_i(d)：文档 d 在第 i 个检索结果中的排名
- k：平滑参数（通常为60）
```

**示例计算：**
```python
# text_vector 结果：Doc A(rank=0), Doc B(rank=1), Doc C(rank=2)
# image_vector 结果：Doc B(rank=0), Doc A(rank=1), Doc D(rank=2)

# RRF 分数（k=60）：
# Doc A: 1/(60+0) + 1/(60+1) = 0.0167 + 0.0164 = 0.0331
# Doc B: 1/(60+1) + 1/(60+0) = 0.0164 + 0.0167 = 0.0331
# Doc C: 1/(60+2) + 0 = 0.0161
# Doc D: 0 + 1/(60+2) = 0.0161

# 排序：Doc A ≈ Doc B > Doc C ≈ Doc D
```

**应用：** 适合不同度量方式（COSINE vs L2）的融合，无需调参。

---

## 卡片6：核心概念 - 加权平均

**一句话：** 对原始相似度分数进行加权平均，可精确控制权重

**公式：**
```
Score(d) = Σ w_i * score_i(d)

其中：
- w_i：第 i 个检索结果的权重
- score_i(d)：文档 d 在第 i 个检索结果中的相似度分数
- Σ w_i = 1（权重和为1）
```

**示例计算：**
```python
# text_vector 结果：Doc A(score=0.95), Doc B(score=0.90)
# image_vector 结果：Doc B(score=0.92), Doc A(score=0.88)

# 加权平均（w1=0.6, w2=0.4）：
# Doc A: 0.95*0.6 + 0.88*0.4 = 0.57 + 0.352 = 0.922
# Doc B: 0.90*0.6 + 0.92*0.4 = 0.54 + 0.368 = 0.908

# 排序：Doc A > Doc B
```

**应用：** 适合相同度量方式，需要精确控制权重比例（如文本70%，图片30%）。

---

## 卡片7：RRF vs 加权平均

**一句话：** RRF 适合不同度量方式，加权平均适合相同度量方式

**对比表：**
| 维度 | RRF | 加权平均 |
|------|-----|---------|
| **输入** | 排名 | 原始分数 |
| **度量方式** | 可以不同（COSINE vs L2） | 必须相同（或归一化） |
| **权重控制** | 无法精确控制 | 可精确控制（如70:30） |
| **调参需求** | 无需调参（k=60） | 需要A/B测试 |
| **适用场景** | 快速原型、不同度量方式 | 生产优化、相同度量方式 |

**选择标准：**
```python
if 度量方式不同:
    使用 RRF
elif 需要精确控制权重:
    使用加权平均
else:
    使用 RRF（默认）
```

**应用：** 在 RAG 系统中，如果文本和图片都用 COSINE，且需要文本权重70%，用加权平均；如果度量方式不同，用 RRF。

---

## 卡片8：性能优化

**一句话：** 控制向量字段数量、调整召回数量、使用标量过滤

**优化策略（按优先级）：**
```python
# 1. 控制向量字段数量（最重要）
# ✅ 推荐：2-3个
# ❌ 避免：5个以上

# 2. 调整召回数量
# 实时搜索：limit=5-10（延迟~25ms）
# 通用场景：limit=10-20（延迟~35ms）
# 离线分析：limit=20-50（延迟~50ms）

# 3. 使用标量过滤预先缩小范围
results = collection.hybrid_search(
    reqs=[text_req, image_req],
    rerank=RRFRanker(),
    limit=10,
    expr="price < 1000 and stock > 0"  # 先过滤
)
# 性能提升：30-50%

# 4. 统一度量方式
# 所有字段都用 COSINE，简化融合逻辑
# 性能提升：10-15%
```

**应用：** 在电商搜索中，通过将向量字段从5个减少到3个，召回数量从50调整到20，并添加标量过滤，延迟从80ms降低到35ms。

---

## 卡片9：在 RAG 中的应用

**一句话：** 同时检索文档的文本和图表，提升召回率和准确率

**RAG 流程：**
```
用户问题："如何安装 Python？"
   ↓
生成查询向量（OpenAI Embedding）
   ↓
多模态检索（Milvus）
   ├─ 文本向量检索（召回20个）
   └─ 图片向量检索（召回10个）
   ↓
RRF 融合（返回Top 3）
   ↓
构建上下文
   ├─ 文档1：Python 安装步骤（文本）
   ├─ 文档2：安装截图（图片）
   └─ 文档3：配置说明（文本）
   ↓
调用 LLM（GPT-4）
   ↓
生成答案
```

**效果提升：**
- 召回率：70% → 85%（+21%）
- 准确率：75% → 90%（+20%）
- 用户满意度：3.5/5 → 4.3/5（+23%）

**应用：** 技术文档问答、产品手册检索、教程系统。

---

## 卡片10：常见误区

**一句话：** 避免向量字段过多、盲目选择融合算法、混淆多向量和标量过滤

**误区1：向量字段越多越好 ❌**
```python
# ❌ 错误：10个向量字段
# 性能灾难，延迟400ms+

# ✅ 正确：2-3个核心字段
# 性能可控，延迟35ms
```

**误区2：RRF 一定比加权平均好 ❌**
```python
# 场景决定算法：
# - 不同度量方式 → RRF
# - 相同度量方式 + 需要精确权重 → 加权平均
# - 快速原型 → RRF
```

**误区3：多向量可以替代标量过滤 ❌**
```python
# 多向量检索：语义匹配（模糊）
# 标量过滤：精确条件（硬约束）
# 两者互补，不能替代

# ✅ 正确：组合使用
results = collection.hybrid_search(
    reqs=[text_req, image_req],  # 多向量
    rerank=RRFRanker(),
    limit=10,
    expr="price < 1000"  # 标量过滤
)
```

**应用：** 在实际项目中，避免这些误区可以节省大量调试时间。

---

## 知识卡片总结

**10个卡片的递进关系：**
```
1. 直觉理解（是什么）
   ↓
2. 形式化定义（精确表述）
   ↓
3-6. 核心概念（多字段向量、混合检索、RRF、加权平均）
   ↓
7. 算法对比（RRF vs 加权平均）
   ↓
8. 性能优化（实战技巧）
   ↓
9. RAG 应用（实际场景）
   ↓
10. 常见误区（避坑指南）
```

---

## 快速复习

### 30秒版本

**多向量检索 = 多个向量字段 + 并行检索 + 融合算法**

- **多字段向量**：text_vector（1536维）+ image_vector（512维）
- **混合检索**：并行执行，延迟 ≈ max(单个延迟)
- **融合算法**：RRF（无需调参）或加权平均（精确控制）
- **性能优化**：2-3个字段，召回10-20个，标量过滤
- **RAG 应用**：召回率+21%，准确率+20%

---

### 2分钟版本

**核心原理：**
1. 单一向量无法完整表达复杂对象（文本、图片、音频）
2. 多个向量提供互补信息，减少误判
3. 通过融合算法整合多个检索结果

**关键技术：**
1. **多字段向量**：每个字段独立索引，维度可以不同
2. **混合检索**：并行执行，总延迟 ≈ max(单个延迟)
3. **RRF 融合**：只看排名，适合不同度量方式
4. **加权平均**：精确控制权重，适合相同度量方式

**实战要点：**
1. 向量字段数量：2-3个（不超过5个）
2. 召回数量：实时10个，通用20个，离线50个
3. 标量过滤：预先缩小范围，性能提升30-50%
4. 统一度量：所有字段用 COSINE，简化融合

**RAG 应用：**
- 同时检索文本和图表
- 召回率从70%提升到85%
- 准确率从75%提升到90%

---

### 5分钟版本

**第一性原理：**
- 现实对象是多模态的（文本、图片、音频）
- 单一向量无法完整表达 → 需要多个向量
- 多个向量互补 → 提升检索准确率

**技术实现：**
```python
# 1. 定义多个向量字段
fields = [
    FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=1536),
    FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=512),
]

# 2. 创建索引
collection.create_index("text_vector", {"index_type": "HNSW", "metric_type": "COSINE"})
collection.create_index("image_vector", {"index_type": "HNSW", "metric_type": "COSINE"})

# 3. 混合检索
text_req = AnnSearchRequest(data=[text_embedding], anns_field="text_vector", limit=20)
image_req = AnnSearchRequest(data=[image_embedding], anns_field="image_vector", limit=10)

results = collection.hybrid_search(
    reqs=[text_req, image_req],
    rerank=RRFRanker(),
    limit=5
)
```

**融合算法：**
- **RRF**：`Score(d) = Σ 1/(k + rank_i(d))`，只看排名
- **加权平均**：`Score(d) = Σ w_i * score_i(d)`，加权原始分数

**选择标准：**
- 不同度量方式 → RRF
- 相同度量方式 + 精确权重 → 加权平均
- 快速原型 → RRF

**性能优化：**
1. 控制字段数量（2-3个）
2. 调整召回数量（10-20个）
3. 标量过滤（性能+30-50%）
4. 统一度量（性能+10-15%）

**RAG 应用：**
- 用户问题 → 生成向量 → 多模态检索 → 融合 → 构建上下文 → LLM 生成答案
- 效果：召回率+21%，准确率+20%，满意度+23%

**常见误区：**
1. 向量字段越多越好 ❌（2-3个即可）
2. RRF 一定比加权平均好 ❌（场景决定）
3. 多向量可以替代标量过滤 ❌（互补关系）

---

## 学习检查清单

完成本知识点学习后，检查是否掌握：

- [ ] 能解释多向量检索的核心原理
- [ ] 能创建包含多个向量字段的 Collection
- [ ] 能实现混合检索（hybrid_search）
- [ ] 能实现 RRF 融合算法
- [ ] 能实现加权平均融合算法
- [ ] 能根据场景选择合适的融合算法
- [ ] 能优化多向量检索的性能
- [ ] 能在 RAG 系统中应用多模态检索
- [ ] 能避免常见误区
- [ ] 能回答面试中的相关问题

---

## 下一步学习

- **L3_高级特性/01_分区管理** - 进一步优化检索性能
- **L3_高级特性/02_混合检索** - 向量检索 + 标量过滤的高级组合
- **L4_性能优化/01_索引参数调优** - 优化多向量检索性能

---

**恭喜！** 你已经系统掌握了多向量检索的核心知识！
