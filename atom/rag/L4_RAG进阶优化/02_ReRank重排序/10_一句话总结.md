# 一句话总结

**ReRank 是使用 Cross-Encoder 对向量检索候选结果进行二次精排的技术，通过 Query 和 Document 的深度语义交互，将检索准确率提升 5-15%，是生产级 RAG 系统的标准优化手段。**

---

## 拆解这句话

| 关键词 | 含义 |
|-------|------|
| **Cross-Encoder** | 将 Query 和 Doc 拼接后一起编码，实现 Token 级深度交互 |
| **向量检索候选** | Bi-Encoder 快速召回的 Top-N 文档（通常 50-100） |
| **二次精排** | 对候选结果重新计算相关性分数并排序 |
| **深度语义交互** | 每个 Token 都能相互 Attention，理解细粒度语义关系 |
| **5-15% 提升** | 典型的检索准确率提升范围 |
| **标准优化手段** | 生产级 RAG 系统的必备组件 |

---

## 核心公式

```
ReRank = Bi-Encoder 召回 + Cross-Encoder 精排

两阶段检索 = 速度（向量检索） + 精度（ReRank）
```

---

## 记忆口诀

```
向量召回一百篇，
Cross-Encoder 精排选，
深度交互提精度，
RAG 系统更出彩。
```

---

## 学习检查清单

完成本知识点学习后，你应该能够：

- [ ] 解释 ReRank 的作用和原理
- [ ] 区分 Bi-Encoder 和 Cross-Encoder
- [ ] 使用 sentence-transformers 实现 ReRank
- [ ] 在 RAG 系统中集成两阶段检索
- [ ] 选择合适的候选数量（Top-N）
- [ ] 避免 ReRank 的三个常见误区

---

## 下一步学习

**前置知识回顾：**
- ← [L1_NLP基础/02_Embedding原理与选型](../../L1_NLP基础/02_Embedding原理与选型.md)
- ← [L3_RAG核心流程/04_向量存储](../../L3_RAG核心流程/04_向量存储/)

**后续知识：**
- → [L4_RAG进阶优化/03_Query改写](../03_Query改写/) - 优化用户查询表达
- → [L4_RAG进阶优化/01_混合检索策略](../01_混合检索策略/) - 结合关键词和语义检索

---

## 参考资源

**论文：**
- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
- [MS MARCO: A Human Generated MAchine Reading COmprehension Dataset](https://arxiv.org/abs/1611.09268)

**工具：**
- [sentence-transformers](https://www.sbert.net/) - 开源 Bi-Encoder 和 Cross-Encoder
- [Cohere Rerank](https://cohere.com/rerank) - 商业 ReRank API
- [BGE Reranker](https://huggingface.co/BAAI/bge-reranker-base) - 中文 ReRank 模型

---

**恭喜完成 ReRank 重排序的学习！**
