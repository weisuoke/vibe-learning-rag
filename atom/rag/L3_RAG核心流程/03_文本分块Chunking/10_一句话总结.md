# 一句话总结

**文本分块（Chunking）是将长文档按策略切分成适合检索的小片段的技术，通过控制块大小和切分边界来平衡检索精度与上下文完整性，2025-2026年演进出代理式分块（Agentic Chunking）和上下文感知分块（Contextual Retrieval），使分块从规则驱动进化为智能驱动，是 RAG 系统中连接文档加载与向量化的关键环节，直接决定检索质量和最终答案效果。**

---

## 关键词拆解

| 关键词 | 含义 |
|--------|------|
| **按策略切分** | 不是随意切分，而是有方法论（固定大小、递归字符、语义分块、代理式、上下文感知） |
| **适合检索的小片段** | 大小适中（256-1024 tokens），语义完整，便于向量化 |
| **平衡精度与完整性** | 块太小精度高但上下文不全，块太大上下文全但噪音多 |
| **2025-2026年演进** | 从固定规则到 LLM 驱动的智能分块 |
| **代理式分块** | LLM 像人类编辑一样理解文档结构，智能确定边界（IBM） |
| **上下文感知分块** | 为每个块添加 50-100 token 上下文，减少 49-67% 检索失败（Anthropic） |
| **规则驱动 → 智能驱动** | 从硬编码规则到 AI 理解语义的技术革命 |
| **关键环节** | 位于文档加载之后、向量化之前，承上启下 |
| **直接决定** | 分块质量是 RAG 效果的基础，垃圾进垃圾出 |

---

## 五大分块策略全景（2025-2026）

### 1. 固定大小分块（Fixed-size Chunking）
**年份**: 传统方法
**原理**: 按固定字符数或 token 数切分
**适用**: 简单文档、快速原型、成本敏感场景
**优势**: 实现简单、速度快、成本低
**劣势**: 可能破坏语义完整性

### 2. 递归字符分块（Recursive Character Splitting）
**年份**: 传统方法（LangChain 默认）
**原理**: 按层级分隔符递归切分（段落 → 句子 → 词）
**适用**: 通用场景、结构化文档
**优势**: 保持文档结构、平衡性好
**劣势**: 依赖分隔符质量

### 3. 语义分块（Semantic Chunking）
**年份**: 2024
**原理**: 基于 embedding 相似度确定边界
**适用**: 高质量要求、长文档、复杂内容
**优势**: 语义完整、准确率高
**劣势**: 计算成本高（需要多次 embedding）

### 4. 代理式分块（Agentic Chunking）⭐ NEW
**年份**: 2025-2026（IBM Research）
**原理**: LLM 理解文档结构，动态确定分块边界和元数据
**适用**: 复杂文档、高价值场景、需要深度理解的内容
**优势**: 最高质量、智能边界、自动元数据标注
**劣势**: 成本最高、速度较慢
**效果**: 比传统方法提升 15-20% 检索准确率

**研究来源**: [IBM Agentic Chunking](https://www.ibm.com/think/topics/agentic-chunking)

### 5. 上下文感知分块（Contextual Retrieval）⭐ NEW
**年份**: 2024-2025（Anthropic）
**原理**: 为每个 chunk 添加 50-100 token 的文档级上下文说明
**适用**: 生产环境、关键应用、需要高召回率的场景
**优势**: 显著减少检索失败、提升召回率
**劣势**: 增加存储成本、需要额外 LLM 调用
**效果**:
- 单独使用：减少 49% 检索失败
- 结合 reranking：减少 67% 检索失败

**研究来源**: [Anthropic Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)

---

## NVIDIA 2025 研究发现

**研究来源**: [NVIDIA Chunking Benchmark](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses)

### 核心发现

1. **页面级分块表现最佳**
   - 准确率：0.648（最高）
   - 方差：0.107（最稳定）
   - 适用于多数场景

2. **查询类型决定最优块大小**
   - 事实查询（Factual）：256-512 tokens
   - 分析查询（Analytical）：1024+ tokens
   - 混合查询：512-768 tokens

3. **重叠率建议**
   - 15% 重叠表现最佳
   - 过高重叠（>20%）增加成本但收益递减
   - 过低重叠（<10%）可能丢失边界信息

---

## 记忆口诀

```
分块五策略：固定、递归、语义、代理、上下文
分块三要素：大小、重叠、切分点
分块三权衡：精度、完整、成本
分块三步骤：选策略、调参数、做评估

2025-2026 革命：
传统规则 → LLM 智能
固定边界 → 动态理解
孤立块 → 上下文注入
```

---

## 速查配置（2025-2026 推荐）

### 快速原型（成本优先）
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=75,  # 15% overlap
    separators=["\n\n", "\n", "。", ".", "！", "？", " ", ""]
)
chunks = splitter.split_text(your_text)
```

### 生产环境（质量优先）
```python
# 1. 代理式分块（最高质量）
from openai import OpenAI

client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{
        "role": "system",
        "content": "你是文档分块专家。分析文档结构，确定最佳分块边界。"
    }, {
        "role": "user",
        "content": f"为以下文档确定分块边界：\n\n{document}"
    }]
)

# 2. 上下文感知（减少 49% 失败）
def add_context_to_chunk(chunk: str, document: str) -> str:
    """为 chunk 添加文档级上下文"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{
            "role": "system",
            "content": "为文档片段生成 50-100 token 的上下文说明。"
        }, {
            "role": "user",
            "content": f"文档：{document}\n\n片段：{chunk}"
        }]
    )
    context = response.choices[0].message.content
    return f"{context}\n\n{chunk}"
```

---

## 学习检查清单

- [ ] 理解为什么 RAG 系统必须分块
- [ ] 掌握五大分块策略的适用场景
- [ ] 了解 2025-2026 年的技术演进（代理式 + 上下文感知）
- [ ] 知道 NVIDIA 研究的核心发现（页面级、查询类型、15% 重叠）
- [ ] 能使用 RecursiveCharacterTextSplitter
- [ ] 理解代理式分块的工作原理（LLM 驱动）
- [ ] 理解上下文感知分块的效果（减少 49-67% 失败）
- [ ] 知道不同场景如何选择分块策略
- [ ] 了解分块的常见误区（见 06_反直觉点.md）
- [ ] 能验证分块效果（检索准确率、召回率）

---

## 技术演进时间线

```
2023 年前：固定大小 + 递归字符（规则驱动）
    ↓
2024 年：语义分块（embedding 驱动）
    ↓
2024-2025：上下文感知分块（Anthropic，减少 49-67% 失败）
    ↓
2025-2026：代理式分块（IBM，LLM 智能驱动，提升 15-20% 准确率）
    ↓
2025：NVIDIA 基准测试（页面级最优，查询类型决定块大小）
```

---

## 下一步学习

**前置知识回顾：**
- ← [02_文档加载与解析](../02_文档加载与解析/) - 分块的输入来源

**深入学习：**
- → [02_第一性原理](./02_第一性原理.md) - 从根本理解为什么需要分块
- → [03_核心概念_04_代理式分块Agentic](./03_核心概念_04_代理式分块Agentic.md) - 2025-2026 最新技术
- → [03_核心概念_05_上下文感知分块Contextual](./03_核心概念_05_上下文感知分块Contextual.md) - Anthropic 方法

**后续知识：**
- → [04_向量存储](../04_向量存储/) - 分块后的向量如何存储
- → [05_检索器设计](../05_检索器设计/) - 如何检索分块后的内容

---

## 核心研究来源

1. **NVIDIA 2025**: [Finding the Best Chunking Strategy](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses)
2. **Anthropic 2024-2025**: [Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)
3. **IBM 2025-2026**: [Agentic Chunking](https://www.ibm.com/think/topics/agentic-chunking)

---

**恭喜！** 你已经完成了文本分块（Chunking）的学习，掌握了从传统方法到 2025-2026 年最新智能分块技术的完整知识体系。
