# 核心概念3：数据流转机制

> 理解数据如何在 RunnableSequence 中流转

---

## 数据流转的本质

**一句话**：数据从左到右依次流转，每个组件的输出自动成为下一个组件的输入。

```python
chain = step1 | step2 | step3

# 数据流转
input → step1.invoke(input) → output1
output1 → step2.invoke(output1) → output2
output2 → step3.invoke(output2) → final_output
```

---

## 基础数据流转

### 简单类型传递

```python
from langchain_core.runnables import RunnableLambda

# 定义三个简单函数
add_one = RunnableLambda(lambda x: x + 1)
multiply_two = RunnableLambda(lambda x: x * 2)
square = RunnableLambda(lambda x: x ** 2)

# 组合成链
chain = add_one | multiply_two | square

# 执行
result = chain.invoke(10)
# 流转过程：
# 10 → add_one → 11
# 11 → multiply_two → 22
# 22 → square → 484
print(result)  # 484
```

### 复杂类型传递

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 步骤1：dict → PromptValue
prompt = ChatPromptTemplate.from_template("解释：{topic}")

# 步骤2：PromptValue → AIMessage
llm = ChatOpenAI(model="gpt-4o-mini")

# 步骤3：AIMessage → str
parser = StrOutputParser()

# 组合
chain = prompt | llm | parser

# 执行
result = chain.invoke({"topic": "量子计算"})
# 流转过程：
# {"topic": "量子计算"} → prompt → PromptValue
# PromptValue → llm → AIMessage
# AIMessage → parser → str
```

---

## 类型转换与适配

### 自动类型适配

LangChain 会自动适配不同类型：

```python
from langchain_core.messages import HumanMessage, AIMessage

# 步骤1：dict → PromptValue
prompt = ChatPromptTemplate.from_template("问题：{question}")

# 步骤2：PromptValue → AIMessage
# LLM 自动接受 PromptValue，输出 AIMessage
llm = ChatOpenAI()

# 步骤3：AIMessage → str
# Parser 自动接受 AIMessage，输出 str
parser = StrOutputParser()

chain = prompt | llm | parser
```

**类型流转图**：

```
dict → PromptValue → AIMessage → str
     (prompt)      (llm)       (parser)
```

### 手动类型转换

如果类型不匹配，需要手动转换：

```python
from langchain_core.runnables import RunnableLambda

# 步骤1：输出 int
step1 = RunnableLambda(lambda x: len(x))

# 步骤2：需要 str，但收到 int
# 需要手动转换
step2 = RunnableLambda(lambda x: f"长度是 {x}")

# 组合
chain = step1 | step2

result = chain.invoke("Hello")
# 流转：
# "Hello" → step1 → 5 (int)
# 5 → step2 → "长度是 5" (str)
print(result)  # "长度是 5"
```

---

## 字典输入与 RunnableParallel

### 字典输入的特殊处理

```python
from langchain_core.runnables import RunnablePassthrough, RunnableParallel

# 使用字典输入
chain = (
    {
        "context": retriever,  # 检索文档
        "question": RunnablePassthrough()  # 透传问题
    }
    | prompt  # 接收字典，展开为变量
    | llm
    | parser
)

# 执行
result = chain.invoke("什么是 AI？")
# 流转：
# "什么是 AI？" → RunnableParallel → {"context": [...], "question": "什么是 AI？"}
# {"context": [...], "question": "什么是 AI？"} → prompt → PromptValue
# PromptValue → llm → AIMessage
# AIMessage → parser → str
```

**关键点**：
- 字典语法 `{...}` 自动创建 `RunnableParallel`
- `RunnableParallel` 并行执行所有键对应的 Runnable
- 结果合并为字典，传递给下一步

### RunnablePassthrough 的作用

```python
# RunnablePassthrough：透传输入
from langchain_core.runnables import RunnablePassthrough

passthrough = RunnablePassthrough()
result = passthrough.invoke("Hello")
print(result)  # "Hello"（原样返回）

# 在字典中使用
chain = {
    "original": RunnablePassthrough(),  # 保留原始输入
    "processed": some_processor  # 处理输入
}
```

---

## 数据流转的实现原理

### 手写简化版

```python
from typing import Any, List

class DataFlowRunnable:
    """展示数据流转的简化版 Runnable"""

    def invoke(self, input: Any) -> Any:
        raise NotImplementedError

    def __or__(self, other):
        return DataFlowSequence(self, other)


class DataFlowSequence(DataFlowRunnable):
    """展示数据流转的简化版 RunnableSequence"""

    def __init__(self, *steps):
        self.steps = list(steps)

    def invoke(self, input: Any) -> Any:
        """
        顺序执行，展示数据流转

        Args:
            input: 初始输入

        Returns:
            最后一步的输出
        """
        result = input
        print(f"初始输入: {result}")

        for i, step in enumerate(self.steps, 1):
            print(f"\n步骤{i}: {step.__class__.__name__}")
            print(f"  输入: {result}")

            result = step.invoke(result)

            print(f"  输出: {result}")

        print(f"\n最终输出: {result}")
        return result


# ===== 测试组件 =====

class AddOne(DataFlowRunnable):
    def invoke(self, input: int) -> int:
        return input + 1


class MultiplyTwo(DataFlowRunnable):
    def invoke(self, input: int) -> int:
        return input * 2


class ToStr(DataFlowRunnable):
    def invoke(self, input: int) -> str:
        return f"结果是 {input}"


# ===== 测试 =====

if __name__ == "__main__":
    add_one = AddOne()
    multiply_two = MultiplyTwo()
    to_str = ToStr()

    chain = add_one | multiply_two | to_str

    result = chain.invoke(10)
    # 输出：
    # 初始输入: 10
    #
    # 步骤1: AddOne
    #   输入: 10
    #   输出: 11
    #
    # 步骤2: MultiplyTwo
    #   输入: 11
    #   输出: 22
    #
    # 步骤3: ToStr
    #   输入: 22
    #   输出: 结果是 22
    #
    # 最终输出: 结果是 22
```

### 数据流追踪器

```python
from typing import Any, Dict, List
from datetime import datetime

class DataFlowTracker:
    """数据流追踪器"""

    def __init__(self):
        self.traces: List[Dict] = []

    def record(self, step_name: str, input_data: Any, output_data: Any):
        """记录一次数据流转"""
        self.traces.append({
            "timestamp": datetime.now().isoformat(),
            "step": step_name,
            "input": str(input_data)[:100],  # 限制长度
            "output": str(output_data)[:100],
            "input_type": type(input_data).__name__,
            "output_type": type(output_data).__name__
        })

    def print_trace(self):
        """打印追踪信息"""
        print("=== 数据流转追踪 ===\n")
        for i, trace in enumerate(self.traces, 1):
            print(f"步骤{i}: {trace['step']}")
            print(f"  时间: {trace['timestamp']}")
            print(f"  输入类型: {trace['input_type']}")
            print(f"  输入值: {trace['input']}")
            print(f"  输出类型: {trace['output_type']}")
            print(f"  输出值: {trace['output']}")
            print()


class TrackedRunnable(DataFlowRunnable):
    """支持追踪的 Runnable"""

    def __init__(self, tracker: DataFlowTracker):
        self.tracker = tracker

    def invoke(self, input: Any) -> Any:
        output = self._invoke(input)
        self.tracker.record(
            self.__class__.__name__,
            input,
            output
        )
        return output

    def _invoke(self, input: Any) -> Any:
        """子类实现"""
        raise NotImplementedError


# ===== 使用示例 =====

class TrackedAddOne(TrackedRunnable):
    def _invoke(self, input: int) -> int:
        return input + 1


class TrackedMultiplyTwo(TrackedRunnable):
    def _invoke(self, input: int) -> int:
        return input * 2


if __name__ == "__main__":
    tracker = DataFlowTracker()

    add_one = TrackedAddOne(tracker)
    multiply_two = TrackedMultiplyTwo(tracker)

    chain = add_one | multiply_two

    result = chain.invoke(10)
    tracker.print_trace()
```

---

## 复杂数据流转场景

### 场景1：RAG 链的数据流转

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 构建 RAG 链
vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

prompt = ChatPromptTemplate.from_template("""
上下文：{context}
问题：{question}
答案：
""")

llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

rag_chain = (
    {
        "context": retriever,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | parser
)

# 数据流转分析
result = rag_chain.invoke("什么是向量数据库？")

# 流转过程：
# 1. "什么是向量数据库？" → RunnableParallel
#    - retriever.invoke("什么是向量数据库？") → [Document(...), ...]
#    - RunnablePassthrough().invoke("什么是向量数据库？") → "什么是向量数据库？"
#    → {"context": [Document(...), ...], "question": "什么是向量数据库？"}
#
# 2. {"context": [...], "question": "..."} → prompt
#    → PromptValue([HumanMessage(content="上下文：...\n问题：...\n答案：")])
#
# 3. PromptValue → llm
#    → AIMessage(content="向量数据库是...")
#
# 4. AIMessage → parser
#    → "向量数据库是..."
```

**关键点**：
- 第1步：并行执行 retriever 和 RunnablePassthrough
- 第2步：字典展开为 prompt 变量
- 第3步：PromptValue 转换为 AIMessage
- 第4步：AIMessage 提取文本

### 场景2：多步推理的数据流转

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 步骤1：分解问题
decompose_prompt = ChatPromptTemplate.from_template(
    "将问题分解为3个子问题：{question}"
)

# 步骤2：解决子问题（简化版）
solve_prompt = ChatPromptTemplate.from_template(
    "解决：{subquestions}"
)

# 步骤3：合并答案
synthesize_prompt = ChatPromptTemplate.from_template(
    "根据以下内容回答原始问题：{answers}"
)

llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

# 组合
reasoning_chain = (
    decompose_prompt
    | llm
    | parser
    | (lambda x: {"subquestions": x})  # 转换为字典
    | solve_prompt
    | llm
    | parser
    | (lambda x: {"answers": x})  # 转换为字典
    | synthesize_prompt
    | llm
    | parser
)

# 数据流转：
# "复杂问题" → decompose_prompt → PromptValue
# PromptValue → llm → AIMessage("子问题1\n子问题2\n子问题3")
# AIMessage → parser → "子问题1\n子问题2\n子问题3"
# "子问题1\n..." → lambda → {"subquestions": "子问题1\n..."}
# {"subquestions": "..."} → solve_prompt → PromptValue
# PromptValue → llm → AIMessage("答案1\n答案2\n答案3")
# AIMessage → parser → "答案1\n答案2\n答案3"
# "答案1\n..." → lambda → {"answers": "答案1\n..."}
# {"answers": "..."} → synthesize_prompt → PromptValue
# PromptValue → llm → AIMessage("最终答案")
# AIMessage → parser → "最终答案"
```

---

## 数据流转的可视化

### 使用 astream_events 追踪

```python
import asyncio
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

async def visualize_data_flow():
    """可视化数据流转"""
    prompt = ChatPromptTemplate.from_template("解释：{topic}")
    llm = ChatOpenAI(model="gpt-4o-mini")
    parser = StrOutputParser()

    chain = prompt | llm | parser

    print("=== 数据流转可视化 ===\n")

    async for event in chain.astream_events(
        {"topic": "量子计算"},
        version="v2"
    ):
        kind = event["event"]
        name = event.get("name", "")

        if kind == "on_chain_start":
            print(f"▶ 开始: {name}")
            if "input" in event.get("data", {}):
                print(f"  输入: {event['data']['input']}")

        elif kind == "on_chain_end":
            print(f"◀ 结束: {name}")
            if "output" in event.get("data", {}):
                output = event['data']['output']
                if isinstance(output, str):
                    print(f"  输出: {output[:100]}...")
                else:
                    print(f"  输出类型: {type(output).__name__}")
            print()

asyncio.run(visualize_data_flow())
```

**输出示例**：

```
=== 数据流转可视化 ===

▶ 开始: RunnableSequence
  输入: {'topic': '量子计算'}
▶ 开始: ChatPromptTemplate
  输入: {'topic': '量子计算'}
◀ 结束: ChatPromptTemplate
  输出类型: ChatPromptValue

▶ 开始: ChatOpenAI
◀ 结束: ChatOpenAI
  输出类型: AIMessage

▶ 开始: StrOutputParser
◀ 结束: StrOutputParser
  输出: 量子计算是利用量子力学原理进行信息处理的计算方式...

◀ 结束: RunnableSequence
  输出: 量子计算是利用量子力学原理进行信息处理的计算方式...
```

---

## 数据流转的优化技巧

### 1. 避免不必要的转换

```python
# ❌ 不必要的转换
chain = (
    prompt
    | llm
    | (lambda x: x)  # 不必要的透传
    | parser
)

# ✅ 直接连接
chain = prompt | llm | parser
```

### 2. 合并多个转换

```python
# ❌ 多个小转换
chain = (
    step1
    | (lambda x: x.strip())
    | (lambda x: x.lower())
    | (lambda x: x.replace(" ", "_"))
    | step2
)

# ✅ 合并转换
def transform(x):
    return x.strip().lower().replace(" ", "_")

chain = step1 | transform | step2
```

### 3. 使用 RunnableLambda 包装

```python
from langchain_core.runnables import RunnableLambda

# ✅ 使用 RunnableLambda 包装复杂逻辑
def complex_transform(x):
    # 复杂的转换逻辑
    result = x.strip().lower()
    if len(result) > 100:
        result = result[:100] + "..."
    return result

chain = (
    step1
    | RunnableLambda(complex_transform)
    | step2
)
```

---

## 2025-2026 应用场景

### 场景1：多模态数据流转

**来源**：LangChain 2025 多模态支持

```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage

# 多模态 LLM
llm = ChatGoogleGenerativeAI(model="gemini-2.5-pro")

# 数据流转：文本 + 图像 → 分析结果
chain = (
    lambda x: [
        HumanMessage(content=[
            {"type": "text", "text": x["question"]},
            {"type": "image_url", "image_url": x["image_url"]}
        ])
    ]
    | llm
    | StrOutputParser()
)

result = chain.invoke({
    "question": "这张图片中有什么？",
    "image_url": "https://example.com/image.jpg"
})
```

### 场景2：结构化输出流转

**来源**：LangChain 2025 结构化输出

```python
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI

class Person(BaseModel):
    name: str = Field(description="人名")
    age: int = Field(description="年龄")
    occupation: str = Field(description="职业")

# 结构化输出
llm = ChatOpenAI(model="gpt-4o-mini")
structured_llm = llm.with_structured_output(Person)

chain = prompt | structured_llm

result = chain.invoke({"text": "张三，35岁，软件工程师"})
# 输出: Person(name="张三", age=35, occupation="软件工程师")
```

---

## 常见问题

### Q1: 如何查看中间步骤的输出？

**A**: 使用 `astream_events`：

```python
async for event in chain.astream_events(input, version="v2"):
    if event["event"] == "on_chain_end":
        print(f"{event['name']}: {event['data']['output']}")
```

### Q2: 如何在中间插入调试输出？

**A**: 使用 RunnableLambda：

```python
def debug_print(x):
    print(f"中间结果: {x}")
    return x

chain = step1 | RunnableLambda(debug_print) | step2
```

### Q3: 数据类型不匹配怎么办？

**A**: 添加类型转换步骤：

```python
chain = (
    step1  # 输出 int
    | RunnableLambda(lambda x: str(x))  # 转换为 str
    | step2  # 需要 str
)
```

---

## 学习检查清单

- [ ] 理解数据流转的基本原理
- [ ] 理解类型转换与适配
- [ ] 理解字典输入与 RunnableParallel
- [ ] 能手写数据流追踪器
- [ ] 能使用 astream_events 可视化数据流
- [ ] 能优化数据流转性能
- [ ] 理解 2025-2026 新场景

---

**版本**: v1.0
**最后更新**: 2026-02-18
**参考来源**:
- LangChain 官方文档
- LangChain 源码
- LangChain 2025 多模态支持
