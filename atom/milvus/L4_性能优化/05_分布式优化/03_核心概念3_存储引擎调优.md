# 核心概念3：存储引擎调优

## 什么是存储引擎调优？

**存储引擎调优**是优化 Milvus 数据存储和持久化机制的技术，包括 WAL 配置、Compaction 策略、缓存管理和磁盘 I/O 优化。

在 Milvus 中，存储引擎负责：
- **数据持久化**：将数据写入磁盘（Object Storage）
- **WAL（Write-Ahead Log）**：保证数据不丢失
- **Compaction**：整理数据碎片，优化存储空间
- **缓存管理**：加速数据访问

---

## 1. WAL（Write-Ahead Log）配置

### 1.1 什么是 WAL？

**WAL**：在数据写入存储前，先写入日志，保证数据不丢失。

**工作流程**：
```
1. 客户端插入数据
   ↓
2. 写入 WAL（磁盘）
   ↓
3. 返回成功（数据已持久化）
   ↓
4. 异步写入 Object Storage
   ↓
5. WAL 清理
```

**好处**：
- 即使系统崩溃，也能从 WAL 恢复数据
- 写入性能高（顺序写入）

**代价**：
- 磁盘 I/O 开销
- 存储空间占用

### 1.2 WAL 参数配置

```yaml
# milvus.yaml
dataNode:
  wal:
    # WAL 刷盘间隔（秒）
    flushInterval: 1  # 每 1 秒刷盘一次

    # WAL 文件大小（MB）
    maxSize: 512  # 单个 WAL 文件最大 512MB

    # WAL 保留时间（小时）
    retentionTime: 24  # 保留 24 小时

    # WAL 压缩
    compressionEnabled: false  # 不压缩（性能优先）
```

### 1.3 WAL 调优策略

#### 策略1：高性能（读多写少）

```yaml
dataNode:
  wal:
    flushInterval: 5  # 延长刷盘间隔
    compressionEnabled: false  # 不压缩
```

**效果**：
- 写入性能提升 30-50%
- 风险：系统崩溃可能丢失最近 5 秒的数据

**适用场景**：
- RAG 文档检索（可以容忍少量数据丢失）
- 推荐系统（数据可以重新生成）

#### 策略2：高可靠（写多读少）

```yaml
dataNode:
  wal:
    flushInterval: 0.5  # 缩短刷盘间隔
    compressionEnabled: true  # 启用压缩
```

**效果**：
- 数据丢失风险降低
- 写入性能下降 20-30%

**适用场景**：
- 金融交易（不能丢失数据）
- 用户生成内容（重要数据）

#### 策略3：平衡（推荐）

```yaml
dataNode:
  wal:
    flushInterval: 1  # 默认值
    compressionEnabled: false
```

### 1.4 Python 代码示例

```python
from pymilvus import Collection, connections
import time

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("wal_test")

# 测试写入性能
data = [[i] + [0.1] * 127 for i in range(10000)]

# 批量插入
start = time.time()
collection.insert(data)
collection.flush()  # 强制刷盘
elapsed = time.time() - start

print(f"插入 10000 条数据: {elapsed:.2f}秒")
print(f"吞吐量: {10000/elapsed:.0f} 条/秒")

# 不同 WAL 配置的性能对比：
# flushInterval=0.5: 4.5秒 (2222 条/秒)
# flushInterval=1.0: 3.2秒 (3125 条/秒) ← 推荐
# flushInterval=5.0: 2.5秒 (4000 条/秒)
```

---

## 2. Compaction 策略

### 2.1 什么是 Compaction？

**Compaction**：合并小 Segment，删除已标记删除的数据，优化存储空间和查询性能。

**问题**：
- 频繁插入会产生大量小 Segment
- 删除操作只是标记，不会立即释放空间
- 小 Segment 过多会降低查询性能

**Compaction 的作用**：
```
合并前：
Segment 1: 100MB (50% 已删除)
Segment 2: 80MB (30% 已删除)
Segment 3: 120MB (20% 已删除)
→ 总大小：300MB，实际有效数据：195MB

合并后：
Segment 1: 195MB (0% 已删除)
→ 总大小：195MB，节省 35% 空间
```

### 2.2 Compaction 类型

| 类型 | 说明 | 触发条件 |
|------|------|----------|
| **Minor Compaction** | 合并小 Segment | Segment 数量 > 阈值 |
| **Major Compaction** | 清理已删除数据 | 删除比例 > 阈值 |
| **Manual Compaction** | 手动触发 | 用户调用 API |

### 2.3 Compaction 参数配置

```yaml
# milvus.yaml
dataCoord:
  compaction:
    # 启用自动 Compaction
    enableAutoCompaction: true

    # Minor Compaction 阈值
    minSegmentToMerge: 4  # 至少 4 个 Segment 才合并
    maxSegmentToMerge: 10  # 最多合并 10 个 Segment

    # Major Compaction 阈值
    deletedRatioThreshold: 0.2  # 删除比例超过 20% 触发

    # Compaction 调度间隔（秒）
    interval: 3600  # 每小时检查一次

    # Compaction 并发数
    maxParallelTasks: 2  # 最多 2 个并发任务
```

### 2.4 Compaction 调优策略

#### 策略1：高写入场景

```yaml
dataCoord:
  compaction:
    enableAutoCompaction: true
    interval: 1800  # 30 分钟检查一次（更频繁）
    maxParallelTasks: 4  # 增加并发
```

**效果**：
- 及时合并小 Segment
- 避免 Segment 数量过多

#### 策略2：低写入场景

```yaml
dataCoord:
  compaction:
    enableAutoCompaction: true
    interval: 7200  # 2 小时检查一次（降低频率）
    maxParallelTasks: 1  # 减少并发
```

**效果**：
- 减少 Compaction 开销
- 节省 CPU 和磁盘 I/O

#### 策略3：业务低峰期执行

```yaml
dataCoord:
  compaction:
    enableAutoCompaction: false  # 禁用自动 Compaction
```

```python
# 在业务低峰期（如凌晨）手动触发
import schedule
import time
from pymilvus import Collection, connections

connections.connect(alias="default", host="localhost", port="19530")

def run_compaction():
    collection = Collection("my_collection")
    print("开始 Compaction...")
    collection.compact()
    print("Compaction 完成")

# 每天凌晨 2 点执行
schedule.every().day.at("02:00").do(run_compaction)

while True:
    schedule.run_pending()
    time.sleep(60)
```

### 2.5 Python 代码示例

```python
from pymilvus import Collection, connections, utility

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("compaction_test")

# 查看 Compaction 状态
def check_compaction_status():
    stats = collection.get_compaction_state()
    print(f"Compaction 状态: {stats}")

# 手动触发 Compaction
def trigger_compaction():
    print("触发 Compaction...")
    collection.compact()

    # 等待 Compaction 完成
    while True:
        state = collection.get_compaction_state()
        if state.state == 3:  # Completed
            print("Compaction 完成")
            break
        time.sleep(5)

# 查看 Compaction 效果
def show_compaction_effect():
    stats = collection.get_stats()
    print(f"Segment 数量: {stats['segment_count']}")
    print(f"数据大小: {stats['data_size'] / 1024 / 1024:.2f} MB")

# 执行
print("=== Compaction 前 ===")
show_compaction_effect()

trigger_compaction()

print("=== Compaction 后 ===")
show_compaction_effect()

# 预期效果：
# Compaction 前: Segment 数量 50, 数据大小 5000 MB
# Compaction 后: Segment 数量 10, 数据大小 3500 MB (节省 30%)
```

---

## 3. 缓存管理

### 3.1 缓存层次

Milvus 有多层缓存：

```
L1: 内存缓存（QueryNode）
    ↓ 未命中
L2: 磁盘缓存（SSD）
    ↓ 未命中
L3: Object Storage（S3/MinIO）
```

**访问延迟**：
- L1（内存）：1-5ms
- L2（SSD）：10-50ms
- L3（Object Storage）：100-500ms

### 3.2 内存缓存配置

```yaml
# milvus.yaml
queryNode:
  cache:
    # 启用缓存
    enabled: true

    # 缓存大小（字节）
    memoryLimit: 21474836480  # 20GB

    # 缓存淘汰策略
    evictionPolicy: "LRU"  # LRU, LFU, FIFO

    # 缓存预热
    preloadEnabled: true
```

### 3.3 缓存大小计算

```python
# 缓存大小 = 热数据大小 × 1.2（预留 20% 空间）

# 示例：
# - 总数据量：100GB
# - 热数据比例：20%（80/20 法则）
# - 热数据大小：20GB
# - 推荐缓存大小：20GB × 1.2 = 24GB

# 如果内存有限：
# - 可用内存：32GB
# - 系统预留：8GB
# - 缓存大小：(32 - 8) × 70% = 16.8GB
```

### 3.4 缓存淘汰策略

| 策略 | 说明 | 适用场景 |
|------|------|----------|
| **LRU** | 淘汰最久未使用的数据 | 大多数场景（推荐） |
| **LFU** | 淘汰访问频率最低的数据 | 热点数据明显 |
| **FIFO** | 淘汰最早加载的数据 | 时间序列数据 |

### 3.5 Python 代码示例

```python
from pymilvus import Collection, connections
import time

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("cache_test")
collection.load()

# 测试缓存效果
def test_cache_performance():
    query_vector = [[0.1] * 128]

    # 第一次查询（冷启动）
    start = time.time()
    results = collection.search(
        data=query_vector,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10
    )
    cold_time = time.time() - start

    # 第二次查询（缓存命中）
    start = time.time()
    results = collection.search(
        data=query_vector,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10
    )
    hot_time = time.time() - start

    print(f"冷启动: {cold_time*1000:.1f}ms")
    print(f"缓存命中: {hot_time*1000:.1f}ms")
    print(f"性能提升: {cold_time/hot_time:.1f}x")

test_cache_performance()

# 预期结果：
# 冷启动: 50ms
# 缓存命中: 5ms
# 性能提升: 10x
```

### 3.6 缓存预热

```python
from pymilvus import Collection, connections

connections.connect(alias="default", host="localhost", port="19530")

collection = Collection("cache_warmup")

# 加载 Collection 时预热缓存
collection.load()

# 预热热点数据（查询最常用的向量）
hot_vectors = [
    # 从业务日志中提取最常查询的向量
    [0.1] * 128,
    [0.2] * 128,
    [0.3] * 128,
]

print("开始缓存预热...")
for vector in hot_vectors:
    collection.search(
        data=[vector],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10
    )
print("缓存预热完成")

# 好处：
# - 避免冷启动延迟
# - 提升用户体验
```

---

## 4. 磁盘 I/O 优化

### 4.1 SSD vs HDD

| 指标 | SSD | HDD |
|------|-----|-----|
| 随机读取 | 0.1ms | 10ms |
| 顺序读取 | 500 MB/s | 150 MB/s |
| 价格 | 高 | 低 |
| 适用场景 | 索引存储 | 归档数据 |

**推荐配置**：
- **索引**：SSD（需要随机读取）
- **原始数据**：HDD 或 Object Storage（顺序读取）
- **WAL**：SSD（需要快速写入）

### 4.2 存储分层

```yaml
# milvus.yaml
common:
  storage:
    # 索引存储路径（SSD）
    indexStoragePath: "/mnt/ssd/milvus/index"

    # 数据存储路径（HDD 或 Object Storage）
    dataStoragePath: "s3://milvus-bucket/data"

    # WAL 存储路径（SSD）
    walStoragePath: "/mnt/ssd/milvus/wal"
```

### 4.3 I/O 调度优化

```yaml
# milvus.yaml
dataNode:
  io:
    # I/O 并发数
    ioThreadNum: 8  # 根据 CPU 核心数调整

    # 读取缓冲区大小（MB）
    readBufferSize: 16

    # 写入缓冲区大小（MB）
    writeBufferSize: 16
```

### 4.4 Python 代码示例

```python
from pymilvus import Collection, connections
import time

connections.connect(alias="default", host="localhost", port="19530")

# 测试不同存储介质的性能
def test_storage_performance(collection_name):
    collection = Collection(collection_name)
    collection.load()

    # 查询测试
    start = time.time()
    for _ in range(100):
        results = collection.search(
            data=[[0.1] * 128],
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=10
        )
    elapsed = time.time() - start

    print(f"{collection_name}: {elapsed:.2f}秒 ({100/elapsed:.1f} QPS)")

# 对比测试
test_storage_performance("collection_on_ssd")  # 索引在 SSD
test_storage_performance("collection_on_hdd")  # 索引在 HDD

# 预期结果：
# collection_on_ssd: 2.5秒 (40 QPS)
# collection_on_hdd: 8.0秒 (12.5 QPS)
# SSD 性能提升 3.2x
```

---

## 5. Object Storage 优化

### 5.1 Object Storage 选择

| 存储 | 延迟 | 吞吐量 | 成本 | 适用场景 |
|------|------|--------|------|----------|
| MinIO（本地） | 低（10-50ms） | 高 | 中 | 自建集群 |
| AWS S3 | 中（50-200ms） | 高 | 低 | 云上部署 |
| 阿里云 OSS | 中（50-200ms） | 高 | 低 | 国内部署 |

### 5.2 MinIO 配置优化

```yaml
# milvus.yaml
minio:
  # MinIO 地址
  address: "localhost:9000"

  # 访问密钥
  accessKeyID: "minioadmin"
  secretAccessKey: "minioadmin"

  # 连接池大小
  maxConnectionNum: 100

  # 请求超时（秒）
  requestTimeout: 60

  # 分片上传阈值（MB）
  multipartUploadThreshold: 100
```

### 5.3 S3 配置优化

```yaml
# milvus.yaml
minio:
  # 使用 S3
  address: "s3.amazonaws.com"
  bucketName: "milvus-bucket"

  # S3 区域
  region: "us-west-2"

  # 启用 S3 加速
  useAccelerate: true

  # 启用 IAM 角色
  useIAM: true
```

### 5.4 Python 代码示例

```python
from pymilvus import connections, utility

# 配置 Object Storage
connections.connect(
    alias="default",
    host="localhost",
    port="19530"
)

# 查看存储使用情况
def show_storage_usage():
    # 通过 Milvus metrics 查看
    import requests
    response = requests.get("http://localhost:9091/metrics")

    for line in response.text.split('\n'):
        if 'milvus_storage_size' in line:
            print(line)

show_storage_usage()

# 示例输出：
# milvus_storage_size_bytes{type="index"} 5368709120  # 5GB 索引
# milvus_storage_size_bytes{type="data"} 21474836480  # 20GB 数据
```

---

## 6. 存储引擎监控指标

### 6.1 关键指标

| 指标 | 说明 | 目标值 |
|------|------|--------|
| `milvus_datanode_wal_latency` | WAL 写入延迟 | < 10ms |
| `milvus_datanode_compaction_duration` | Compaction 耗时 | < 300s |
| `milvus_querynode_cache_hit_ratio` | 缓存命中率 | > 80% |
| `milvus_storage_io_latency` | 磁盘 I/O 延迟 | < 50ms |
| `milvus_storage_size` | 存储空间使用 | < 80% |

### 6.2 监控示例

```python
import requests
import time

def monitor_storage_metrics():
    metrics_url = "http://localhost:9091/metrics"

    while True:
        response = requests.get(metrics_url)
        metrics = response.text

        # 解析关键指标
        for line in metrics.split('\n'):
            if 'milvus_querynode_cache_hit_ratio' in line:
                print(f"缓存命中率: {line}")
            if 'milvus_datanode_wal_latency' in line:
                print(f"WAL 延迟: {line}")

        time.sleep(60)  # 每分钟检查一次

# 运行监控
# monitor_storage_metrics()
```

---

## 7. 存储引擎最佳实践

### 7.1 RAG 文档检索场景

**需求**：
- 1 亿篇文档
- 读多写少（写入：100 TPS，查询：5000 QPS）
- P99 延迟 < 100ms

**存储配置**：
```yaml
# WAL 配置（写入不频繁，可以延长刷盘间隔）
dataNode:
  wal:
    flushInterval: 5  # 5 秒刷盘
    compressionEnabled: false

# Compaction 配置（业务低峰期执行）
dataCoord:
  compaction:
    enableAutoCompaction: false  # 禁用自动
    # 手动在凌晨 2 点执行

# 缓存配置（热数据占 20%）
queryNode:
  cache:
    enabled: true
    memoryLimit: 21474836480  # 20GB
    evictionPolicy: "LRU"

# 存储分层
common:
  storage:
    indexStoragePath: "/mnt/ssd/milvus/index"  # SSD
    dataStoragePath: "s3://milvus-bucket/data"  # S3
```

### 7.2 实时推荐场景

**需求**：
- 1000 万用户画像
- 写多读多（写入：1000 TPS，查询：10000 QPS）
- P99 延迟 < 50ms

**存储配置**：
```yaml
# WAL 配置（写入频繁，缩短刷盘间隔）
dataNode:
  wal:
    flushInterval: 1  # 1 秒刷盘
    compressionEnabled: false

# Compaction 配置（频繁执行）
dataCoord:
  compaction:
    enableAutoCompaction: true
    interval: 1800  # 30 分钟
    maxParallelTasks: 4

# 缓存配置（全内存）
queryNode:
  cache:
    enabled: true
    memoryLimit: 53687091200  # 50GB（全部数据）
    preloadEnabled: true

# 存储分层（全 SSD）
common:
  storage:
    indexStoragePath: "/mnt/ssd/milvus/index"
    dataStoragePath: "/mnt/ssd/milvus/data"
```

---

## 8. 存储成本优化

### 8.1 成本分析

```python
# 存储成本 = 索引成本 + 数据成本 + WAL 成本

# 示例：1 亿向量（128维）
vector_count = 100_000_000
vector_dim = 128

# 原始数据大小
raw_data_size = vector_count * vector_dim * 4 / 1024 / 1024 / 1024  # GB
print(f"原始数据: {raw_data_size:.1f} GB")

# 索引大小（IVF_FLAT，约 1.2x 原始数据）
index_size = raw_data_size * 1.2
print(f"索引大小: {index_size:.1f} GB")

# WAL 大小（约 10% 原始数据）
wal_size = raw_data_size * 0.1
print(f"WAL 大小: {wal_size:.1f} GB")

# 总存储
total_size = raw_data_size + index_size + wal_size
print(f"总存储: {total_size:.1f} GB")

# 成本估算（AWS S3）
s3_cost_per_gb = 0.023  # $0.023/GB/月
monthly_cost = total_size * s3_cost_per_gb
print(f"月成本: ${monthly_cost:.2f}")

# 输出：
# 原始数据: 47.7 GB
# 索引大小: 57.2 GB
# WAL 大小: 4.8 GB
# 总存储: 109.7 GB
# 月成本: $2.52
```

### 8.2 成本优化策略

#### 策略1：使用量化索引

```python
# IVF_FLAT: 1.2x 原始数据
# IVF_SQ8: 0.3x 原始数据（节省 75% 存储）

# 成本对比：
# IVF_FLAT: 57.2 GB → $1.32/月
# IVF_SQ8: 14.3 GB → $0.33/月
# 节省: $0.99/月 (75%)
```

#### 策略2：定期清理 WAL

```python
from pymilvus import utility

# 手动清理 WAL
utility.flush_all()

# 效果：释放 WAL 空间（约 10% 总存储）
```

#### 策略3：使用对象存储生命周期

```yaml
# S3 生命周期策略
# - 30 天后转移到 S3 Glacier（成本降低 80%）
# - 90 天后删除

# 成本对比：
# S3 Standard: $0.023/GB/月
# S3 Glacier: $0.004/GB/月
# 节省: 83%
```

---

## 总结

**存储引擎调优的核心要点**：

1. **WAL 配置**：根据写入频率和可靠性要求权衡
2. **Compaction 策略**：定期清理碎片，优化存储空间
3. **缓存管理**：合理配置缓存大小，提升查询性能
4. **磁盘 I/O**：使用 SSD 存储索引，HDD 存储归档数据
5. **Object Storage**：选择合适的存储服务，优化成本

**记住**：存储优化需要在性能、可靠性和成本之间找到平衡点。
