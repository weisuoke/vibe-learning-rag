# 核心概念：连接池优雅关闭

> 深入理解如何正确关闭 SQLAlchemy 和 Redis 连接池

---

## 什么是连接池？

**连接池（Connection Pool）** 是预先创建并维护的数据库连接集合，用于复用连接，避免频繁创建和销毁连接的开销。

**核心概念：**
- **连接复用**：多个请求共享连接
- **连接管理**：自动创建、回收、销毁连接
- **性能优化**：减少连接建立时间

**类比：**
- **前端视角**：类似于 HTTP Keep-Alive，复用 TCP 连接
- **日常视角**：类似于图书馆的借书证，借完书后归还，下次可以继续借

---

## 为什么需要优雅关闭连接池？

### 问题场景：不关闭连接池

```python
# 不关闭连接池的"伪优雅关闭"
def signal_handler(signum, frame):
    print("收到信号，立即退出")
    sys.exit(0)  # 立即退出，不关闭连接池

# 问题：
# 1. 数据库端显示大量 "idle in transaction" 连接
# 2. 连接池资源未释放
# 3. 可能导致连接池耗尽
# 4. 重启后无法连接数据库
```

**实际后果：**
```
数据库端：
- 显示大量未关闭的连接
- 连接数达到上限，新连接无法建立
- 需要手动清理或等待超时（可能需要数小时）

应用端：
- 重启后无法连接数据库（连接池满）
- 需要重启数据库或等待连接超时
- 影响业务连续性
```

---

## SQLAlchemy 连接池

### 1. 连接池的工作原理

```python
from sqlalchemy import create_engine

# 创建引擎（包含连接池）
engine = create_engine(
    "postgresql://user:pass@localhost/db",
    pool_size=10,          # 连接池大小
    max_overflow=20,       # 最大溢出连接数
    pool_timeout=30,       # 获取连接超时时间
    pool_recycle=3600,     # 连接回收时间（秒）
    pool_pre_ping=True,    # 使用前检查连接是否有效
)

# 连接池状态：
# - pool_size=10: 保持10个空闲连接
# - max_overflow=20: 最多再创建20个临时连接
# - 总连接数 = pool_size + max_overflow = 30
```

**连接生命周期：**
```
1. 请求到达
   ↓
2. 从连接池获取连接（checkout）
   ↓
3. 执行查询
   ↓
4. 归还连接到连接池（checkin）
   ↓
5. 连接变为空闲状态
```

### 2. 连接池状态监控

```python
def monitor_connection_pool(engine):
    """监控连接池状态"""
    pool = engine.pool

    print("连接池状态:")
    print(f"  连接池大小: {pool.size()}")
    print(f"  已签出连接: {pool.checkedout()}")
    print(f"  溢出连接: {pool.overflow()}")
    print(f"  空闲连接: {pool.size() - pool.checkedout()}")

    # 检查连接泄漏
    if pool.checkedout() > 0:
        print("⚠️  警告：有连接未归还")
```

### 3. 优雅关闭连接池

```python
async def cleanup_database(engine):
    """优雅关闭数据库连接池"""
    print("关闭数据库连接池...")

    # 1. 获取连接池状态
    pool = engine.pool
    print(f"当前连接池状态:")
    print(f"  连接池大小: {pool.size()}")
    print(f"  已签出连接: {pool.checkedout()}")

    # 2. dispose() 会：
    #    - 关闭所有空闲连接
    #    - 等待所有活跃连接归还
    #    - 标记连接池为已关闭
    await engine.dispose()

    print("数据库连接池已关闭")
```

**dispose() 的行为：**
- 关闭所有空闲连接
- 等待活跃连接归还（不会强制中断）
- 归还的连接会被立即关闭
- 连接池标记为已关闭，无法再获取连接

### 4. 带超时的连接池关闭

```python
async def cleanup_database_with_timeout(engine, timeout: int = 10):
    """带超时的连接池关闭"""
    print("关闭数据库连接池...")

    try:
        # 设置超时
        await asyncio.wait_for(
            engine.dispose(),
            timeout=timeout
        )
        print("数据库连接池已关闭")

    except asyncio.TimeoutError:
        print(f"连接池关闭超时（{timeout}秒）")

        # 检查是否有连接泄漏
        pool = engine.pool
        if pool.checkedout() > 0:
            print(f"⚠️  警告：还有 {pool.checkedout()} 个连接未归还")
            print("可能存在连接泄漏")
```

---

## Redis 连接池

### 1. Redis 连接池的工作原理

```python
from redis.asyncio import Redis, ConnectionPool

# 创建连接池
pool = ConnectionPool.from_url(
    "redis://localhost:6379/0",
    max_connections=10,      # 最大连接数
    decode_responses=True,   # 自动解码响应
)

# 创建 Redis 客户端
redis_client = Redis(connection_pool=pool)

# 连接池状态：
# - max_connections=10: 最多10个连接
# - 连接会自动创建和复用
```

### 2. 优雅关闭 Redis 连接

```python
async def cleanup_redis(redis_client):
    """优雅关闭 Redis 连接"""
    print("关闭 Redis 连接...")

    # 1. 关闭客户端
    #    - 等待所有待处理的命令完成
    #    - 关闭连接
    await redis_client.close()

    # 2. 断开连接池
    #    - 关闭所有连接
    #    - 释放资源
    await redis_client.connection_pool.disconnect()

    print("Redis 连接已关闭")
```

### 3. 检查 Redis 连接状态

```python
async def check_redis_connection(redis_client):
    """检查 Redis 连接状态"""
    try:
        # 发送 PING 命令
        await redis_client.ping()
        print("Redis 连接正常")
        return True

    except Exception as e:
        print(f"Redis 连接异常: {e}")
        return False
```

### 4. 带超时的 Redis 关闭

```python
async def cleanup_redis_with_timeout(redis_client, timeout: int = 5):
    """带超时的 Redis 关闭"""
    print("关闭 Redis 连接...")

    try:
        # 关闭客户端
        await asyncio.wait_for(
            redis_client.close(),
            timeout=timeout
        )

        # 断开连接池
        await asyncio.wait_for(
            redis_client.connection_pool.disconnect(),
            timeout=timeout
        )

        print("Redis 连接已关闭")

    except asyncio.TimeoutError:
        print(f"Redis 关闭超时（{timeout}秒）")
```

---

## 连接泄漏检测

### 1. SQLAlchemy 连接泄漏检测

```python
class ConnectionLeakDetector:
    """连接泄漏检测器"""

    def __init__(self, engine, threshold: int = 5):
        self.engine = engine
        self.threshold = threshold  # 泄漏阈值

    def check_leak(self) -> bool:
        """检查是否有连接泄漏"""
        pool = self.engine.pool
        checkedout = pool.checkedout()

        if checkedout > self.threshold:
            print(f"⚠️  警告：检测到连接泄漏")
            print(f"  已签出连接: {checkedout}")
            print(f"  阈值: {self.threshold}")
            return True

        return False

    def get_leak_info(self) -> dict:
        """获取泄漏信息"""
        pool = self.engine.pool

        return {
            "pool_size": pool.size(),
            "checkedout": pool.checkedout(),
            "overflow": pool.overflow(),
            "idle": pool.size() - pool.checkedout(),
        }

# 使用示例
detector = ConnectionLeakDetector(engine, threshold=5)

if detector.check_leak():
    info = detector.get_leak_info()
    print(f"连接池信息: {info}")
```

### 2. 连接泄漏的常见原因

```python
# ❌ 原因1：忘记关闭连接
async def bad_example_1():
    conn = await engine.connect()
    result = await conn.execute("SELECT * FROM users")
    # 忘记关闭连接！
    return result.fetchall()

# ✅ 正确：使用上下文管理器
async def good_example_1():
    async with engine.connect() as conn:
        result = await conn.execute("SELECT * FROM users")
        return result.fetchall()
    # 连接自动关闭

# ❌ 原因2：异常时未关闭连接
async def bad_example_2():
    conn = await engine.connect()
    result = await conn.execute("SELECT * FROM users")
    # 如果这里抛出异常，连接不会关闭
    process_result(result)
    await conn.close()

# ✅ 正确：使用 try-finally
async def good_example_2():
    conn = await engine.connect()
    try:
        result = await conn.execute("SELECT * FROM users")
        process_result(result)
    finally:
        await conn.close()

# ❌ 原因3：Session 未关闭
async def bad_example_3():
    session = AsyncSession(engine)
    users = await session.execute("SELECT * FROM users")
    # 忘记关闭 Session！
    return users.fetchall()

# ✅ 正确：使用上下文管理器
async def good_example_3():
    async with AsyncSession(engine) as session:
        users = await session.execute("SELECT * FROM users")
        return users.fetchall()
    # Session 自动关闭
```

---

## 完整示例：生产级连接池管理

```python
"""
生产级连接池管理
演示：完整的连接池初始化、监控和关闭
"""

import asyncio
from typing import Optional
from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine
from redis.asyncio import Redis
import structlog

logger = structlog.get_logger()

class ConnectionPoolManager:
    """连接池管理器"""

    def __init__(self):
        self.db_engine: Optional[AsyncEngine] = None
        self.redis_client: Optional[Redis] = None

    async def initialize(
        self,
        database_url: str,
        redis_url: str
    ):
        """初始化连接池"""
        logger.info("初始化连接池...")

        # 1. 初始化数据库连接池
        self.db_engine = create_async_engine(
            database_url,
            pool_size=10,
            max_overflow=20,
            pool_timeout=30,
            pool_recycle=3600,
            pool_pre_ping=True,
            echo_pool=True,  # 打印连接池日志
        )

        # 测试数据库连接
        try:
            async with self.db_engine.connect() as conn:
                await conn.execute("SELECT 1")
            logger.info("数据库连接测试成功")
        except Exception as e:
            logger.error("数据库连接测试失败", error=str(e))
            raise

        # 2. 初始化 Redis 连接池
        self.redis_client = Redis.from_url(
            redis_url,
            max_connections=10,
            decode_responses=True,
        )

        # 测试 Redis 连接
        try:
            await self.redis_client.ping()
            logger.info("Redis 连接测试成功")
        except Exception as e:
            logger.error("Redis 连接测试失败", error=str(e))
            raise

        logger.info("连接池初始化完成")

    def get_pool_status(self) -> dict:
        """获取连接池状态"""
        if not self.db_engine:
            return {}

        pool = self.db_engine.pool

        return {
            "database": {
                "pool_size": pool.size(),
                "checkedout": pool.checkedout(),
                "overflow": pool.overflow(),
                "idle": pool.size() - pool.checkedout(),
            },
            "redis": {
                "max_connections": self.redis_client.connection_pool.max_connections
                if self.redis_client else 0,
            },
        }

    async def cleanup(self, timeout: int = 30):
        """优雅关闭连接池"""
        logger.info("开始关闭连接池", timeout=timeout)

        # 记录关闭前的状态
        status = self.get_pool_status()
        logger.info("关闭前连接池状态", status=status)

        # 1. 关闭数据库连接池
        if self.db_engine:
            try:
                await asyncio.wait_for(
                    self._cleanup_database(),
                    timeout=timeout
                )
                logger.info("数据库连接池已关闭")
            except asyncio.TimeoutError:
                logger.warning("数据库连接池关闭超时", timeout=timeout)
            except Exception as e:
                logger.error("数据库连接池关闭失败", error=str(e))

        # 2. 关闭 Redis 连接
        if self.redis_client:
            try:
                await asyncio.wait_for(
                    self._cleanup_redis(),
                    timeout=timeout
                )
                logger.info("Redis 连接已关闭")
            except asyncio.TimeoutError:
                logger.warning("Redis 连接关闭超时", timeout=timeout)
            except Exception as e:
                logger.error("Redis 连接关闭失败", error=str(e))

        logger.info("连接池关闭完成")

    async def _cleanup_database(self):
        """关闭数据库连接池"""
        if not self.db_engine:
            return

        # 获取连接池状态
        pool = self.db_engine.pool
        checkedout = pool.checkedout()

        if checkedout > 0:
            logger.warning(
                "数据库连接池有未归还的连接",
                checkedout=checkedout
            )

        # 关闭连接池
        await self.db_engine.dispose()

    async def _cleanup_redis(self):
        """关闭 Redis 连接"""
        if not self.redis_client:
            return

        # 关闭客户端
        await self.redis_client.close()

        # 断开连接池
        await self.redis_client.connection_pool.disconnect()

# ===== 使用示例 =====
pool_manager = ConnectionPoolManager()

# 初始化
await pool_manager.initialize(
    database_url="postgresql+asyncpg://user:pass@localhost/db",
    redis_url="redis://localhost:6379/0"
)

# 获取状态
status = pool_manager.get_pool_status()
print(f"连接池状态: {status}")

# 优雅关闭
await pool_manager.cleanup(timeout=30)
```

---

## AI Agent 后端的连接池管理

### 1. 向量数据库连接池

```python
from pymilvus import connections, Collection

async def cleanup_vector_db():
    """关闭向量数据库连接"""
    print("关闭向量数据库连接...")

    # 1. 等待所有查询完成
    # Milvus 客户端会自动等待

    # 2. 断开连接
    connections.disconnect("default")

    print("向量数据库连接已关闭")
```

### 2. LLM 客户端连接池

```python
from openai import AsyncOpenAI

async def cleanup_llm_client(client: AsyncOpenAI):
    """关闭 LLM 客户端"""
    print("关闭 LLM 客户端...")

    # OpenAI 客户端基于 httpx
    await client.close()

    print("LLM 客户端已关闭")
```

---

## 总结

### 核心要点

1. **连接池的重要性**：
   - 复用连接，提升性能
   - 需要正确关闭，避免泄漏

2. **SQLAlchemy 连接池**：
   - 使用 `engine.dispose()` 关闭
   - 会等待活跃连接归还
   - 监控 `checkedout()` 检测泄漏

3. **Redis 连接池**：
   - 先 `close()` 客户端
   - 再 `disconnect()` 连接池

4. **连接泄漏检测**：
   - 监控已签出连接数
   - 使用上下文管理器
   - 异常时确保关闭

### 检查清单

- [ ] 使用 `engine.dispose()` 关闭数据库连接池
- [ ] 使用 `redis_client.close()` 关闭 Redis 连接
- [ ] 设置连接池关闭超时
- [ ] 监控连接池状态
- [ ] 检测连接泄漏
- [ ] 使用上下文管理器管理连接
- [ ] 记录连接池关闭日志

---

**下一步**：学习 **03_核心概念_09_AI_Agent特定清理.md**，了解 AI Agent 后端的特殊清理需求。
