# 面试必问

如何在面试中出彩回答关于 RAG 上下文注入与生成的问题。

---

## 问题1："RAG 系统中，如何优化生成质量？"

### 普通回答（❌ 不出彩）

"优化生成质量主要是调整 Prompt 模板和 LLM 参数，比如设置合适的 temperature。"

### 出彩回答（✅ 推荐）

> **RAG 生成质量优化可以从三个层面来看：**
>
> **1. 上下文质量层面（最重要）**
>
> 生成质量的上限由检索质量决定。我会：
> - 控制检索数量（通常 3-5 个文档），避免信息过载
> - 使用相关性阈值过滤低质量结果
> - 考虑使用 ReRank 进行二次筛选
>
> **2. Prompt 设计层面**
>
> 好的 Prompt 模板包含四个要素：
> - 角色定义：明确 LLM 的身份和专业领域
> - 行为约束：如"只基于提供的资料回答"
> - 输出格式：结构化要求，便于解析
> - 引用规范：要求标注信息来源
>
> 同时要注意 **Lost in the Middle** 现象——把最相关的内容放在开头和结尾。
>
> **3. 生成参数层面**
>
> - 问答场景用 `temperature=0`，保证确定性
> - 合理设置 `max_tokens`，预留足够输出空间
> - 生产环境考虑流式输出，提升用户体验
>
> **在实际项目中**，我发现检索质量对最终效果的影响占 70% 以上，所以我会优先优化检索环节，再调优 Prompt 和生成参数。

### 为什么这个回答出彩？

1. ✅ **分层思考**：从三个层面系统性分析，展示全局视角
2. ✅ **有优先级**：明确指出检索质量最重要，展示实战经验
3. ✅ **有细节**：提到 Lost in the Middle、ReRank 等进阶概念
4. ✅ **有数据**：给出 70% 的经验数据，增加可信度
5. ✅ **有实践**：结合实际项目经验，不是纸上谈兵

---

## 问题2："什么是 Lost in the Middle？如何解决？"

### 普通回答（❌ 不出彩）

"Lost in the Middle 是说 LLM 对中间内容注意力不够，解决方法是把重要内容放前面。"

### 出彩回答（✅ 推荐）

> **Lost in the Middle 是斯坦福 2023 年的研究发现：**
>
> 当上下文较长时，LLM 对开头和结尾的内容注意力明显高于中间部分。实验数据显示，关键信息放在中间位置时，准确率可能下降 20-30%。
>
> **产生原因有两个：**
> 1. Transformer 的注意力机制对位置有隐式偏好
> 2. 训练数据中，重要信息通常在开头（标题、摘要）和结尾（总结）
>
> **我在项目中用过三种解决方案：**
>
> **方案1：重排序策略**
> ```
> 最相关 → 开头
> 次相关 → 结尾
> 其他 → 中间
> ```
>
> **方案2：控制上下文长度**
> - 尽量保持在 4K tokens 以内
> - 超过时用 Map-Reduce 分块处理
>
> **方案3：结构化标记**
> - 用【重要】【关键】等标记突出重点
> - 在结尾重复核心问题，强化 LLM 关注
>
> 实际效果来看，方案1最简单有效，方案2适合长文档场景。

### 为什么这个回答出彩？

1. ✅ **有来源**：提到斯坦福研究，展示知识深度
2. ✅ **有数据**：20-30% 的准确率下降，量化说明问题严重性
3. ✅ **有原理**：解释了为什么会这样，不只是知其然
4. ✅ **有方案**：给出三种解决方案，展示实战能力
5. ✅ **有评价**：对比不同方案的适用场景

---

## 问题3："如何处理 RAG 系统中的幻觉问题？"

### 普通回答（❌ 不出彩）

"在 Prompt 里告诉 LLM 不要编造，如果不知道就说不知道。"

### 出彩回答（✅ 推荐）

> **RAG 中的幻觉问题需要从源头到输出全链路防控：**
>
> **1. 检索阶段（预防）**
> - 设置相关性阈值，过滤低相关结果
> - 宁可返回"找不到相关信息"，也不要塞无关内容
> - 无关内容反而会"诱导"LLM 编造
>
> **2. Prompt 阶段（约束）**
> ```
> 【行为约束】
> 1. 只基于【参考资料】回答
> 2. 如果资料不足，明确说"无法回答"
> 3. 不要推测或补充资料中没有的信息
> ```
>
> **3. 生成阶段（控制）**
> - 使用 `temperature=0`，减少随机性
> - 要求引用来源，便于验证
>
> **4. 输出阶段（验证）**
> - 可以用另一个 LLM 做事实核查
> - 检查答案中的关键信息是否在上下文中出现
> - 对高风险场景（医疗、法律）加人工审核
>
> **实际经验**：最有效的是第1步——控制输入质量。很多幻觉问题的根源是检索到了不相关的内容，LLM 被迫"发挥"。

### 为什么这个回答出彩？

1. ✅ **全链路思维**：从检索到输出，系统性防控
2. ✅ **有代码示例**：展示具体的 Prompt 约束写法
3. ✅ **有优先级**：强调检索阶段最重要
4. ✅ **有场景意识**：提到高风险场景需要人工审核
5. ✅ **有根因分析**：指出幻觉的根源往往是检索问题

---

## 面试技巧总结

| 技巧 | 说明 |
|------|------|
| 分层回答 | 从多个层面/维度分析问题 |
| 有数据支撑 | 引用研究数据或实践经验数据 |
| 有优先级 | 指出哪个最重要，展示判断力 |
| 有代码/示例 | 用具体代码或配置说明 |
| 有实践经验 | 结合实际项目，不纸上谈兵 |

---

**下一步：** [09_化骨绵掌](./09_化骨绵掌.md) - 10个2分钟知识卡片
