# 实战代码2：故障转移测试验证

本示例演示如何测试和验证 Milvus 高可用集群的故障转移能力，包括模拟节点故障、监控恢复过程、测量 RTO 等。

---

## 场景说明

**目标：** 验证 Milvus 高可用集群在节点故障时的自动恢复能力

**测试内容：**
1. Coordinator 故障转移测试（主从切换）
2. Worker 故障转移测试（负载均衡）
3. 网络分区测试（脑裂预防）
4. 并发故障测试（多节点同时故障）

**测试指标：**
- RTO（恢复时间目标）：< 15 秒
- 失败请求数：< 10 次
- 数据一致性：无数据丢失

---

## 完整测试代码

### 1. 故障转移测试框架

```python
"""
Milvus 高可用集群故障转移测试框架
"""
from pymilvus import connections, Collection, utility
import time
import datetime
import threading
import subprocess
from typing import List, Dict, Tuple

class FailoverTester:
    """故障转移测试器"""

    def __init__(self, host: str, port: str = "19530"):
        self.host = host
        self.port = port
        self.test_results = []
        self.failure_start_time = None
        self.recovery_time = None
        self.failure_count = 0

    def connect(self):
        """连接到 Milvus 集群"""
        try:
            connections.connect(
                alias="default",
                host=self.host,
                port=self.port
            )
            print(f"✅ 连接成功: {self.host}:{self.port}")
            return True
        except Exception as e:
            print(f"❌ 连接失败: {e}")
            return False

    def create_test_collection(self, collection_name: str = "failover_test"):
        """创建测试 Collection"""
        from pymilvus import FieldSchema, CollectionSchema, DataType
        import numpy as np

        # 删除已存在的 Collection
        if utility.has_collection(collection_name):
            Collection(collection_name).drop()

        # 创建 Collection
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128)
        ]
        schema = CollectionSchema(fields=fields, description="Failover test collection")
        collection = Collection(name=collection_name, schema=schema)

        # 插入测试数据
        vectors = np.random.rand(1000, 128).tolist()
        collection.insert([vectors])

        # 创建索引
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 128}
        }
        collection.create_index(field_name="embedding", index_params=index_params)

        # 加载 Collection（3 副本）
        collection.load(replica_number=3)

        print(f"✅ 测试 Collection 创建成功: {collection_name}")
        return collection

    def continuous_query(self, collection_name: str, duration: int = 120):
        """持续查询，监控故障转移过程"""
        import numpy as np

        collection = Collection(collection_name)
        query_vector = np.random.rand(1, 128).tolist()

        print(f"\n=== 开始持续查询测试（{duration} 秒）===\n")

        start_time = time.time()
        query_count = 0
        success_count = 0
        failure_count = 0
        latencies = []

        while time.time() - start_time < duration:
            query_count += 1

            try:
                query_start = time.time()
                results = collection.search(
                    data=query_vector,
                    anns_field="embedding",
                    param={"metric_type": "L2", "params": {"nprobe": 10}},
                    limit=10
                )
                latency = (time.time() - query_start) * 1000
                latencies.append(latency)

                success_count += 1

                # 检测到故障恢复
                if self.failure_count > 0 and self.recovery_time is None:
                    self.recovery_time = time.time() - self.failure_start_time
                    print(f"\n✅ 服务恢复！")
                    print(f"   RTO: {self.recovery_time:.2f} 秒")
                    print(f"   失败请求数: {self.failure_count}\n")

                if query_count % 10 == 0:
                    print(f"查询 {query_count}: 成功，延迟 {latency:.2f} ms")

            except Exception as e:
                failure_count += 1

                # 记录第一次故障时间
                if self.failure_count == 0:
                    self.failure_start_time = time.time()
                    print(f"\n❌ 检测到故障！时间: {datetime.datetime.now().strftime('%H:%M:%S')}\n")

                self.failure_count += 1
                print(f"查询 {query_count}: 失败 - {str(e)[:50]}")

            time.sleep(1)

        # 统计结果
        total_time = time.time() - start_time
        avg_latency = sum(latencies) / len(latencies) if latencies else 0

        result = {
            "total_queries": query_count,
            "success_count": success_count,
            "failure_count": failure_count,
            "success_rate": success_count / query_count * 100,
            "avg_latency": avg_latency,
            "rto": self.recovery_time,
            "total_time": total_time
        }

        self.test_results.append(result)
        return result

    def simulate_pod_failure(self, pod_label: str, namespace: str = "milvus-ha"):
        """模拟 Pod 故障"""
        print(f"\n⚠️  模拟故障: 删除 Pod (label={pod_label})\n")

        cmd = [
            "kubectl", "delete", "pod",
            "-l", pod_label,
            "-n", namespace,
            "--force",
            "--grace-period=0"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            print(f"✅ Pod 删除成功")
            print(f"   输出: {result.stdout.strip()}")
        else:
            print(f"❌ Pod 删除失败: {result.stderr}")

    def print_test_report(self):
        """打印测试报告"""
        print("\n" + "="*60)
        print("故障转移测试报告")
        print("="*60)

        for i, result in enumerate(self.test_results, 1):
            print(f"\n测试 {i}:")
            print(f"  总查询数: {result['total_queries']}")
            print(f"  成功: {result['success_count']}")
            print(f"  失败: {result['failure_count']}")
            print(f"  成功率: {result['success_rate']:.2f}%")
            print(f"  平均延迟: {result['avg_latency']:.2f} ms")
            print(f"  RTO: {result['rto']:.2f} 秒" if result['rto'] else "  RTO: N/A")
            print(f"  总耗时: {result['total_time']:.2f} 秒")

            # 评估结果
            if result['rto'] and result['rto'] < 15:
                print(f"  ✅ RTO 达标 (< 15 秒)")
            elif result['rto']:
                print(f"  ❌ RTO 不达标 (>= 15 秒)")

            if result['failure_count'] < 10:
                print(f"  ✅ 失败请求数达标 (< 10 次)")
            else:
                print(f"  ❌ 失败请求数不达标 (>= 10 次)")

        print("\n" + "="*60)
```

---

### 2. Coordinator 故障转移测试

```python
"""
测试 Coordinator 的故障转移能力
"""
def test_coordinator_failover():
    """测试 Root Coordinator 故障转移"""
    print("="*60)
    print("测试1: Root Coordinator 故障转移")
    print("="*60)

    tester = FailoverTester(
        host="milvus-proxy.milvus-ha.svc.cluster.local",
        port="19530"
    )

    # 连接到集群
    if not tester.connect():
        return

    # 创建测试 Collection
    collection = tester.create_test_collection("coordinator_failover_test")

    # 启动持续查询线程
    query_thread = threading.Thread(
        target=tester.continuous_query,
        args=("coordinator_failover_test", 120)
    )
    query_thread.start()

    # 等待 20 秒后模拟故障
    time.sleep(20)
    tester.simulate_pod_failure(
        pod_label="app=milvus-rootcoord",
        namespace="milvus-ha"
    )

    # 等待查询线程完成
    query_thread.join()

    # 打印测试报告
    tester.print_test_report()

    # 清理
    collection.drop()

if __name__ == "__main__":
    test_coordinator_failover()
```

**预期输出：**

```
============================================================
测试1: Root Coordinator 故障转移
============================================================
✅ 连接成功: milvus-proxy.milvus-ha.svc.cluster.local:19530
✅ 测试 Collection 创建成功: coordinator_failover_test

=== 开始持续查询测试（120 秒）===

查询 10: 成功，延迟 45.23 ms
查询 20: 成功，延迟 48.12 ms

⚠️  模拟故障: 删除 Pod (label=app=milvus-rootcoord)

✅ Pod 删除成功
   输出: pod "milvus-rootcoord-0" deleted

❌ 检测到故障！时间: 14:23:45

查询 21: 失败 - connection refused
查询 22: 失败 - connection refused
查询 23: 失败 - connection refused

✅ 服务恢复！
   RTO: 8.5 秒
   失败请求数: 3

查询 30: 成功，延迟 52.34 ms
查询 40: 成功，延迟 46.78 ms
...

============================================================
故障转移测试报告
============================================================

测试 1:
  总查询数: 120
  成功: 117
  失败: 3
  成功率: 97.50%
  平均延迟: 48.56 ms
  RTO: 8.50 秒
  总耗时: 120.00 秒
  ✅ RTO 达标 (< 15 秒)
  ✅ 失败请求数达标 (< 10 次)

============================================================
```

---

### 3. Worker 故障转移测试

```python
"""
测试 Worker 组件的故障转移能力
"""
def test_worker_failover():
    """测试 Proxy 和 QueryNode 故障转移"""
    print("="*60)
    print("测试2: Worker 组件故障转移")
    print("="*60)

    tester = FailoverTester(
        host="milvus-proxy.milvus-ha.svc.cluster.local",
        port="19530"
    )

    # 连接到集群
    if not tester.connect():
        return

    # 创建测试 Collection
    collection = tester.create_test_collection("worker_failover_test")

    # 测试 Proxy 故障转移
    print("\n--- 子测试 2.1: Proxy 故障转移 ---")
    tester.failure_count = 0
    tester.recovery_time = None

    query_thread = threading.Thread(
        target=tester.continuous_query,
        args=("worker_failover_test", 60)
    )
    query_thread.start()

    time.sleep(15)
    tester.simulate_pod_failure(
        pod_label="app=milvus-proxy",
        namespace="milvus-ha"
    )

    query_thread.join()

    # 测试 QueryNode 故障转移
    print("\n--- 子测试 2.2: QueryNode 故障转移 ---")
    tester.failure_count = 0
    tester.recovery_time = None

    query_thread = threading.Thread(
        target=tester.continuous_query,
        args=("worker_failover_test", 60)
    )
    query_thread.start()

    time.sleep(15)
    tester.simulate_pod_failure(
        pod_label="app=milvus-querynode",
        namespace="milvus-ha"
    )

    query_thread.join()

    # 打印测试报告
    tester.print_test_report()

    # 清理
    collection.drop()

if __name__ == "__main__":
    test_worker_failover()
```

---

### 4. 并发故障测试

```python
"""
测试多个节点同时故障的情况
"""
def test_concurrent_failures():
    """测试并发故障"""
    print("="*60)
    print("测试3: 并发故障测试")
    print("="*60)

    tester = FailoverTester(
        host="milvus-proxy.milvus-ha.svc.cluster.local",
        port="19530"
    )

    # 连接到集群
    if not tester.connect():
        return

    # 创建测试 Collection
    collection = tester.create_test_collection("concurrent_failover_test")

    # 启动持续查询线程
    query_thread = threading.Thread(
        target=tester.continuous_query,
        args=("concurrent_failover_test", 120)
    )
    query_thread.start()

    # 等待 20 秒后同时删除多个 Pod
    time.sleep(20)

    print("\n⚠️  模拟并发故障: 同时删除多个 Pod\n")

    # 同时删除 1 个 Proxy 和 1 个 QueryNode
    pods_to_delete = [
        ("app=milvus-proxy", "Proxy"),
        ("app=milvus-querynode", "QueryNode")
    ]

    for pod_label, pod_type in pods_to_delete:
        print(f"删除 {pod_type} Pod...")
        subprocess.run([
            "kubectl", "delete", "pod",
            "-l", pod_label,
            "-n", "milvus-ha",
            "--force",
            "--grace-period=0"
        ], capture_output=True)

    print("✅ 所有 Pod 删除完成\n")

    # 等待查询线程完成
    query_thread.join()

    # 打印测试报告
    tester.print_test_report()

    # 清理
    collection.drop()

if __name__ == "__main__":
    test_concurrent_failures()
```

---

### 5. 网络分区测试（脑裂预防）

```python
"""
测试网络分区情况下的脑裂预防
"""
def test_network_partition():
    """测试网络分区"""
    print("="*60)
    print("测试4: 网络分区测试（脑裂预防）")
    print("="*60)

    # 使用 NetworkPolicy 模拟网络分区
    network_policy = """
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: isolate-rootcoord
  namespace: milvus-ha
spec:
  podSelector:
    matchLabels:
      app: milvus-rootcoord
  policyTypes:
  - Ingress
  - Egress
  ingress: []
  egress: []
"""

    # 应用 NetworkPolicy（隔离 Root Coordinator）
    print("应用 NetworkPolicy，隔离 Root Coordinator...")
    with open("/tmp/network-policy.yaml", "w") as f:
        f.write(network_policy)

    subprocess.run([
        "kubectl", "apply", "-f", "/tmp/network-policy.yaml"
    ])

    print("✅ NetworkPolicy 应用成功")
    print("   Root Coordinator 已被隔离，无法与其他组件通信\n")

    # 启动测试
    tester = FailoverTester(
        host="milvus-proxy.milvus-ha.svc.cluster.local",
        port="19530"
    )

    if not tester.connect():
        return

    collection = tester.create_test_collection("partition_test")

    # 持续查询 60 秒
    query_thread = threading.Thread(
        target=tester.continuous_query,
        args=("partition_test", 60)
    )
    query_thread.start()
    query_thread.join()

    # 移除 NetworkPolicy
    print("\n移除 NetworkPolicy...")
    subprocess.run([
        "kubectl", "delete", "networkpolicy",
        "isolate-rootcoord",
        "-n", "milvus-ha"
    ])

    print("✅ NetworkPolicy 移除成功\n")

    # 打印测试报告
    tester.print_test_report()

    # 清理
    collection.drop()

if __name__ == "__main__":
    test_network_partition()
```

---

### 6. 自动化测试套件

```python
"""
完整的故障转移测试套件
"""
import argparse

def run_all_tests():
    """运行所有测试"""
    print("\n" + "="*60)
    print("Milvus 高可用集群故障转移测试套件")
    print("="*60 + "\n")

    tests = [
        ("Coordinator 故障转移", test_coordinator_failover),
        ("Worker 故障转移", test_worker_failover),
        ("并发故障", test_concurrent_failures),
        ("网络分区", test_network_partition)
    ]

    results = []

    for test_name, test_func in tests:
        print(f"\n{'='*60}")
        print(f"运行测试: {test_name}")
        print(f"{'='*60}\n")

        try:
            test_func()
            results.append((test_name, "✅ 通过"))
        except Exception as e:
            results.append((test_name, f"❌ 失败: {e}"))

        # 等待集群恢复
        print("\n等待集群完全恢复...")
        time.sleep(30)

    # 打印总结
    print("\n" + "="*60)
    print("测试总结")
    print("="*60)

    for test_name, result in results:
        print(f"{test_name}: {result}")

    print("\n" + "="*60)

def main():
    parser = argparse.ArgumentParser(description="Milvus 故障转移测试")
    parser.add_argument(
        "--test",
        choices=["coordinator", "worker", "concurrent", "partition", "all"],
        default="all",
        help="选择要运行的测试"
    )

    args = parser.parse_args()

    if args.test == "coordinator":
        test_coordinator_failover()
    elif args.test == "worker":
        test_worker_failover()
    elif args.test == "concurrent":
        test_concurrent_failures()
    elif args.test == "partition":
        test_network_partition()
    else:
        run_all_tests()

if __name__ == "__main__":
    main()
```

---

## 运行测试

### 1. 运行单个测试

```bash
# 测试 Coordinator 故障转移
python failover_test.py --test coordinator

# 测试 Worker 故障转移
python failover_test.py --test worker

# 测试并发故障
python failover_test.py --test concurrent

# 测试网络分区
python failover_test.py --test partition
```

### 2. 运行所有测试

```bash
python failover_test.py --test all
```

---

## 测试结果分析

### 1. RTO 分析

```python
"""
分析 RTO 数据
"""
def analyze_rto(test_results: List[Dict]):
    """分析 RTO 数据"""
    rtos = [r['rto'] for r in test_results if r['rto']]

    if not rtos:
        print("没有 RTO 数据")
        return

    print("\n=== RTO 分析 ===")
    print(f"平均 RTO: {sum(rtos)/len(rtos):.2f} 秒")
    print(f"最小 RTO: {min(rtos):.2f} 秒")
    print(f"最大 RTO: {max(rtos):.2f} 秒")
    print(f"中位数 RTO: {sorted(rtos)[len(rtos)//2]:.2f} 秒")

    # RTO 分布
    print("\nRTO 分布:")
    ranges = [(0, 5), (5, 10), (10, 15), (15, 30), (30, float('inf'))]
    for start, end in ranges:
        count = sum(1 for rto in rtos if start <= rto < end)
        percentage = count / len(rtos) * 100
        print(f"  {start}-{end if end != float('inf') else '∞'} 秒: {count} 次 ({percentage:.1f}%)")
```

### 2. 可用性计算

```python
"""
计算集群可用性
"""
def calculate_availability(test_results: List[Dict]):
    """计算可用性"""
    total_queries = sum(r['total_queries'] for r in test_results)
    success_queries = sum(r['success_count'] for r in test_results)

    availability = success_queries / total_queries * 100

    print("\n=== 可用性分析 ===")
    print(f"总查询数: {total_queries}")
    print(f"成功查询数: {success_queries}")
    print(f"失败查询数: {total_queries - success_queries}")
    print(f"可用性: {availability:.4f}%")

    # 换算成年度宕机时间
    downtime_per_year = (100 - availability) / 100 * 365 * 24 * 60  # 分钟
    print(f"预计年度宕机时间: {downtime_per_year:.2f} 分钟 ({downtime_per_year/60:.2f} 小时)")

    # 评估等级
    if availability >= 99.99:
        print("等级: ✅ 四个九（99.99%）")
    elif availability >= 99.9:
        print("等级: ✅ 三个九（99.9%）")
    elif availability >= 99:
        print("等级: ⚠️  两个九（99%）")
    else:
        print("等级: ❌ 不达标（< 99%）")
```

---

## 关键要点

1. **测试覆盖**：
   - Coordinator 故障转移（主从切换）
   - Worker 故障转移（负载均衡）
   - 并发故障（多节点同时故障）
   - 网络分区（脑裂预防）

2. **测试指标**：
   - RTO：恢复时间目标（< 15 秒）
   - 失败请求数：< 10 次
   - 可用性：> 99.9%

3. **自动化**：
   - 使用脚本自动化测试流程
   - 自动收集和分析测试数据
   - 生成测试报告

4. **定期测试**：
   - 建议每月运行一次完整测试
   - 在重大变更后运行测试
   - 记录测试结果，跟踪趋势
