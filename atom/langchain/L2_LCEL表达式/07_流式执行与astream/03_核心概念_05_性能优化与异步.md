# 核心概念 05：性能优化与异步

## 概述

深入理解流式执行的性能优化策略和异步编程最佳实践。

---

## 性能基准

### 2025-2026 性能数据

```python
# 单次调用性能对比
invoke():  5.23 秒
stream():  5.45 秒 (+4.2%)
astream(): 5.47 秒 (+4.6%)

# 10 次并发性能对比
invoke() 串行:  52.3 秒
stream() 串行:  54.5 秒
astream() 并发:  5.5 秒 (-89%)

# 首字节时间（TTFB）
invoke():  5.23 秒
stream():  0.10 秒 (-98%)
astream(): 0.10 秒 (-98%)
```

### 性能演进历史

| 年份 | 流式开销 | 主要优化 |
|------|---------|---------|
| 2023 | ~30% | 初始实现 |
| 2024 | ~20% | 连接池 |
| 2025 | ~10% | 序列化优化 |
| 2026 | <10% | 异步优化 |

---

## 异步编程基础

### 为什么使用异步

```python
# 同步阻塞（串行）
def sync_process():
    result1 = task1()  # 等待 1 秒
    result2 = task2()  # 等待 1 秒
    return [result1, result2]  # 总共 2 秒

# 异步非阻塞（并发）
async def async_process():
    result1, result2 = await asyncio.gather(
        task1(),  # 并发执行
        task2()   # 并发执行
    )
    return [result1, result2]  # 总共 1 秒
```

### asyncio 核心概念

```python
import asyncio

# 1. 协程（Coroutine）
async def my_coroutine():
    await asyncio.sleep(1)
    return "Done"

# 2. 任务（Task）
task = asyncio.create_task(my_coroutine())

# 3. 事件循环（Event Loop）
asyncio.run(my_coroutine())

# 4. 并发执行
results = await asyncio.gather(
    my_coroutine(),
    my_coroutine(),
    my_coroutine()
)
```

---

## 流式异步优化

### 优化 1：使用 astream 而非 stream

```python
# ❌ 同步流式（阻塞）
for chunk in chain.stream(input):
    print(chunk.content, end="", flush=True)

# ✅ 异步流式（非阻塞）
async for chunk in chain.astream(input):
    print(chunk.content, end="", flush=True)
```

**性能提升**：
- 单请求：相同
- 多请求并发：10 倍提升

---

### 优化 2：并发处理多个流

```python
async def process_multiple_streams():
    """并发处理多个流式请求"""
    inputs = [
        {"input": "介绍 Python"},
        {"input": "介绍 JavaScript"},
        {"input": "介绍 Go"}
    ]

    # 创建并发任务
    tasks = [
        asyncio.create_task(collect_stream(chain.astream(inp)))
        for inp in inputs
    ]

    # 等待所有任务完成
    results = await asyncio.gather(*tasks)
    return results

async def collect_stream(stream):
    """收集流式输出"""
    content = ""
    async for chunk in stream:
        content += chunk.content
    return content

# 使用
results = asyncio.run(process_multiple_streams())
```

---

### 优化 3：流式 + 批处理组合

```python
async def batch_with_streaming(inputs: list):
    """批量输入，每个输入流式输出"""
    for i, input_data in enumerate(inputs):
        print(f"\n处理 {i+1}/{len(inputs)}")

        async for chunk in chain.astream(input_data):
            print(chunk.content, end="", flush=True)

        print()  # 换行

# 使用
asyncio.run(batch_with_streaming(inputs))
```

---

## 性能优化策略

### 策略 1：连接池复用

```python
# 2025+ LangChain 内部自动使用连接池
# 无需手动配置

# 性能提升：~3% 开销降低
```

### 策略 2：禁用不需要的流式

```python
# 场景：后台批处理任务
model = ChatOpenAI(
    model="gpt-4o-mini",
    streaming=False  # 禁用流式
)

# 性能提升：~5% 开销降低
```

### 策略 3：减少流式模式

```python
# ❌ 不推荐：启用所有模式
stream_mode=["updates", "messages", "custom"]  # ~8% 开销

# ✅ 推荐：只启用需要的
stream_mode="messages"  # ~5% 开销
```

### 策略 4：批量发送自定义数据

```python
# ❌ 不推荐：频繁发送
for i in range(1000):
    writer(f"处理 {i}")  # 1000 次写入

# ✅ 推荐：批量发送
for i in range(1000):
    if i % 100 == 0:
        writer(f"处理 {i}/1000")  # 10 次写入
```

---

## 高级异步模式

### 模式 1：异步生成器

```python
async def async_generator():
    """异步生成器"""
    for i in range(10):
        await asyncio.sleep(0.1)
        yield i

# 使用
async for value in async_generator():
    print(value)
```

### 模式 2：异步上下文管理器

```python
class AsyncStreamManager:
    """异步上下文管理器"""
    async def __aenter__(self):
        self.stream = chain.astream(input)
        return self.stream

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # 清理资源
        pass

# 使用
async with AsyncStreamManager() as stream:
    async for chunk in stream:
        print(chunk.content, end="")
```

### 模式 3：异步队列

```python
import asyncio

async def producer(queue: asyncio.Queue):
    """生产者：流式读取数据"""
    async for chunk in chain.astream(input):
        await queue.put(chunk)
    await queue.put(None)  # 结束信号

async def consumer(queue: asyncio.Queue):
    """消费者：处理数据"""
    while True:
        chunk = await queue.get()
        if chunk is None:
            break
        print(chunk.content, end="")

async def main():
    queue = asyncio.Queue()
    await asyncio.gather(
        producer(queue),
        consumer(queue)
    )

asyncio.run(main())
```

---

## 性能监控

### 监控指标

```python
import time

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "ttfb": 0,
            "total_time": 0,
            "chunk_count": 0,
            "bytes_received": 0
        }
        self.start_time = None
        self.first_chunk_time = None

    async def monitor_stream(self, chain, input):
        """监控流式执行"""
        self.start_time = time.time()

        async for chunk in chain.astream(input):
            if self.first_chunk_time is None:
                self.first_chunk_time = time.time()
                self.metrics["ttfb"] = self.first_chunk_time - self.start_time

            self.metrics["chunk_count"] += 1
            self.metrics["bytes_received"] += len(chunk.content.encode())

            yield chunk

        self.metrics["total_time"] = time.time() - self.start_time

    def get_report(self) -> dict:
        """生成性能报告"""
        return {
            **self.metrics,
            "chunks_per_second": self.metrics["chunk_count"] / self.metrics["total_time"],
            "bytes_per_second": self.metrics["bytes_received"] / self.metrics["total_time"]
        }

# 使用
monitor = PerformanceMonitor()
async for chunk in monitor.monitor_stream(chain, input):
    print(chunk.content, end="")

print(f"\n性能报告: {monitor.get_report()}")
```

---

## 错误处理与重试

### 重试策略

```python
async def stream_with_retry(chain, input, max_retries=3):
    """带指数退避的重试"""
    for attempt in range(max_retries):
        try:
            async for chunk in chain.astream(input):
                yield chunk
            break  # 成功完成

        except Exception as e:
            if attempt == max_retries - 1:
                raise

            wait_time = 2 ** attempt
            print(f"\n重试 {attempt + 1}/{max_retries}，等待 {wait_time}秒...")
            await asyncio.sleep(wait_time)

# 使用
async for chunk in stream_with_retry(chain, input):
    print(chunk.content, end="")
```

### 超时处理

```python
async def stream_with_timeout(chain, input, timeout=30):
    """带超时的流式执行"""
    try:
        async with asyncio.timeout(timeout):
            async for chunk in chain.astream(input):
                yield chunk

    except asyncio.TimeoutError:
        print(f"\n超时 ({timeout}秒)")
        # 降级到批量模式
        result = chain.invoke(input)
        yield result

# 使用
async for chunk in stream_with_timeout(chain, input):
    print(chunk.content, end="")
```

---

## 内存优化

### 优化 1：避免累积所有 chunks

```python
# ❌ 不推荐：累积所有数据
chunks = []
async for chunk in chain.astream(input):
    chunks.append(chunk)  # 内存持续增长

# ✅ 推荐：逐步处理
async for chunk in chain.astream(input):
    process_chunk(chunk)  # 立即处理，不累积
```

### 优化 2：使用生成器

```python
# ✅ 推荐：生成器模式
async def process_stream(chain, input):
    """生成器模式，内存高效"""
    async for chunk in chain.astream(input):
        # 处理并立即 yield
        processed = process_chunk(chunk)
        yield processed

# 使用
async for result in process_stream(chain, input):
    print(result)
```

---

## 并发控制

### 限制并发数

```python
import asyncio

async def process_with_semaphore(inputs: list, max_concurrent=5):
    """限制并发数"""
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_one(input_data):
        async with semaphore:
            result = ""
            async for chunk in chain.astream(input_data):
                result += chunk.content
            return result

    tasks = [process_one(inp) for inp in inputs]
    results = await asyncio.gather(*tasks)
    return results

# 使用
results = asyncio.run(process_with_semaphore(inputs, max_concurrent=5))
```

---

## 生产环境优化

### 优化清单

```python
# 1. 使用异步流式
async for chunk in chain.astream(input):
    pass

# 2. 禁用不需要的流式模式
stream_mode="messages"  # 而非 ["updates", "messages", "custom"]

# 3. 合理设置超时
async with asyncio.timeout(30):
    async for chunk in chain.astream(input):
        pass

# 4. 实现重试机制
async for chunk in stream_with_retry(chain, input):
    pass

# 5. 监控性能指标
monitor = PerformanceMonitor()
async for chunk in monitor.monitor_stream(chain, input):
    pass

# 6. 限制并发数
await process_with_semaphore(inputs, max_concurrent=10)

# 7. 使用连接池（2025+ 自动）
# 无需手动配置
```

---

## 最佳实践

### 1. 总是使用异步

```python
# ✅ 推荐
async for chunk in chain.astream(input):
    print(chunk.content, end="", flush=True)

# ❌ 不推荐
for chunk in chain.stream(input):
    print(chunk.content, end="", flush=True)
```

### 2. 合理使用并发

```python
# ✅ 推荐：限制并发数
semaphore = asyncio.Semaphore(10)

# ❌ 不推荐：无限并发
tasks = [chain.astream(inp) for inp in inputs]  # 可能耗尽资源
```

### 3. 实现错误处理

```python
# ✅ 推荐：完整的错误处理
try:
    async for chunk in chain.astream(input):
        print(chunk.content, end="")
except Exception as e:
    logger.error(f"流式执行失败: {e}")
    # 降级处理

# ❌ 不推荐：不处理错误
async for chunk in chain.astream(input):
    print(chunk.content, end="")
```

---

## 总结

### 核心要点

1. **异步流式比同步流式性能更好（并发场景）**
2. **2025-2026 流式开销 <10%**
3. **使用连接池、禁用不需要的模式可进一步优化**
4. **实现重试、超时、并发控制是生产环境必需**
5. **监控 TTFB、总时间、吞吐量等关键指标**

### 性能优化优先级

1. **使用 astream（高优先级）**
2. **限制并发数（高优先级）**
3. **禁用不需要的流式模式（中优先级）**
4. **实现重试和超时（中优先级）**
5. **监控性能指标（低优先级）**

---

## 参考资源

- **官方文档**: https://docs.langchain.com/oss/python/langchain/streaming/overview
- **相关知识点**:
  - 03_核心概念_01 - Stream 模式详解
  - 07_实战代码 - 完整代码示例

---

**版本**: LangChain 0.3.x (2025-2026)
**最后更新**: 2026-02-21
