# RAG检索链 - 实战代码4：检索优化

> 混合检索、ReRank、MMR 等高级检索策略

---

## 完整代码

```python
"""
检索优化完整示例
演示：混合检索、ReRank、MMR
"""

from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

load_dotenv()

# ===== 准备数据 =====
documents = [
    "Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。",
    "Python 3.13 是最新版本，发布于 2024 年 10 月。",
    "FastAPI 是一个现代、快速的 Web 框架，基于 Python 3.6+。",
    "RAG 是检索增强生成技术，结合了检索和生成。",
    "LangChain 是一个 LLM 应用开发框架，支持 RAG。",
    "GPT-4 是 OpenAI 的大语言模型，参数量达到 1.76 万亿。",
    "ChromaDB 是一个向量数据库，适合原型开发。",
    "FAISS 是 Facebook 开发的向量检索库，性能极高。"
]

embeddings = OpenAIEmbeddings()

# ===== 1. 基础向量检索 =====
print("=== 1. 基础向量检索 ===")

vectorstore = Chroma.from_texts(documents, embeddings)

query = "GPT-4 的参数量"
results = vectorstore.similarity_search(query, k=3)

print(f"查询: {query}")
print("基础检索结果:")
for i, doc in enumerate(results, 1):
    print(f"  [{i}] {doc.page_content[:50]}...")

# ===== 2. 混合检索（向量 + 关键词） =====
print("\n=== 2. 混合检索 ===")

# 向量检索器
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# BM25 关键词检索器
bm25_retriever = BM25Retriever.from_texts(documents)
bm25_retriever.k = 5

# 混合检索器
ensemble_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.5, 0.5]  # 各占 50%
)

results = ensemble_retriever.get_relevant_documents(query)
print("混合检索结果:")
for i, doc in enumerate(results[:3], 1):
    print(f"  [{i}] {doc.page_content[:50]}...")

# ===== 3. MMR（最大边际相关性） =====
print("\n=== 3. MMR 检索 ===")

query = "Python"
results_mmr = vectorstore.max_marginal_relevance_search(
    query,
    k=4,
    fetch_k=10,  # 先检索 10 个候选
    lambda_mult=0.5  # 平衡相关性和多样性
)

print(f"查询: {query}")
print("MMR 检索结果（多样性）:")
for i, doc in enumerate(results_mmr, 1):
    print(f"  [{i}] {doc.page_content[:50]}...")

# 对比：普通检索（可能重复）
results_normal = vectorstore.similarity_search(query, k=4)
print("\n普通检索结果（可能重复）:")
for i, doc in enumerate(results_normal, 1):
    print(f"  [{i}] {doc.page_content[:50]}...")

# ===== 4. 相似度阈值过滤 =====
print("\n=== 4. 相似度阈值过滤 ===")

query = "Java 的特点"  # 文档中没有的内容
results_with_score = vectorstore.similarity_search_with_score(query, k=5)

print(f"查询: {query}")
print("所有结果:")
for doc, score in results_with_score:
    print(f"  分数 {score:.4f}: {doc.page_content[:40]}...")

# 设置阈值
threshold = 0.5
filtered_results = [
    (doc, score) for doc, score in results_with_score
    if score < threshold  # ChromaDB 分数越小越相似
]

print(f"\n过滤后（阈值 < {threshold}）:")
if filtered_results:
    for doc, score in filtered_results:
        print(f"  分数 {score:.4f}: {doc.page_content[:40]}...")
else:
    print("  没有满足阈值的结果")

# ===== 5. 元数据过滤 =====
print("\n=== 5. 元数据过滤 ===")

# 创建带元数据的向量库
vectorstore_meta = Chroma.from_texts(
    texts=documents,
    embedding=embeddings,
    metadatas=[
        {"type": "language", "year": 1991},
        {"type": "language", "year": 2024},
        {"type": "framework", "year": 2018},
        {"type": "technique", "year": 2020},
        {"type": "framework", "year": 2022},
        {"type": "model", "year": 2023},
        {"type": "database", "year": 2022},
        {"type": "database", "year": 2017}
    ]
)

query = "数据库"
results = vectorstore_meta.similarity_search(
    query,
    k=3,
    filter={"type": "database"}
)

print(f"查询: {query}")
print("过滤结果（只返回 database 类型）:")
for i, doc in enumerate(results, 1):
    print(f"  [{i}] {doc.page_content[:40]}... | {doc.metadata}")

# ===== 6. 动态 K 值 =====
print("\n=== 6. 动态 K 值 ===")

def dynamic_k_search(query: str, vectorstore):
    """根据查询复杂度动态调整 k"""
    # 简单规则：问题越长，k 越大
    if len(query) < 10:
        k = 2  # 简单问题
    elif len(query) < 30:
        k = 3  # 中等问题
    else:
        k = 5  # 复杂问题

    print(f"查询长度: {len(query)} 字符 → k={k}")
    return vectorstore.similarity_search(query, k=k)

queries = [
    "Python",
    "什么是 FastAPI？",
    "对比 ChromaDB 和 FAISS 的性能和适用场景"
]

for query in queries:
    print(f"\n查询: {query}")
    results = dynamic_k_search(query, vectorstore)
    print(f"返回 {len(results)} 个结果")

# ===== 7. 性能对比 =====
print("\n=== 7. 性能对比 ===")

import time

query = "Python 编程"

# 基础检索
start = time.time()
for _ in range(50):
    vectorstore.similarity_search(query, k=3)
basic_time = (time.time() - start) / 50

# 混合检索
start = time.time()
for _ in range(50):
    ensemble_retriever.get_relevant_documents(query)
hybrid_time = (time.time() - start) / 50

# MMR 检索
start = time.time()
for _ in range(50):
    vectorstore.max_marginal_relevance_search(query, k=3)
mmr_time = (time.time() - start) / 50

print(f"基础检索: {basic_time*1000:.2f} ms")
print(f"混合检索: {hybrid_time*1000:.2f} ms")
print(f"MMR 检索: {mmr_time*1000:.2f} ms")

print("\n✓ 检索优化演示完成！")
```

---

## 运行输出示例

```
=== 1. 基础向量检索 ===
查询: GPT-4 的参数量
基础检索结果:
  [1] GPT-4 是 OpenAI 的大语言模型，参数量达到 1.76 万亿。...
  [2] LangChain 是一个 LLM 应用开发框架，支持 RAG。...
  [3] RAG 是检索增强生成技术，结合了检索和生成。...

=== 2. 混合检索 ===
混合检索结果:
  [1] GPT-4 是 OpenAI 的大语言模型，参数量达到 1.76 万亿。...
  [2] RAG 是检索增强生成技术，结合了检索和生成。...
  [3] LangChain 是一个 LLM 应用开发框架，支持 RAG。...

=== 3. MMR 检索 ===
查询: Python
MMR 检索结果（多样性）:
  [1] Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。...
  [2] FastAPI 是一个现代、快速的 Web 框架，基于 Python 3.6+。...
  [3] GPT-4 是 OpenAI 的大语言模型，参数量达到 1.76 万亿。...
  [4] ChromaDB 是一个向量数据库，适合原型开发。...

普通检索结果（可能重复）:
  [1] Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。...
  [2] Python 3.13 是最新版本，发布于 2024 年 10 月。...
  [3] FastAPI 是一个现代、快速的 Web 框架，基于 Python 3.6+。...
  [4] LangChain 是一个 LLM 应用开发框架，支持 RAG。...

=== 4. 相似度阈值过滤 ===
查询: Java 的特点
所有结果:
  分数 0.3521: Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。...
  分数 0.3845: FastAPI 是一个现代、快速的 Web 框架，基于 Python 3.6+。...
  分数 0.4123: Python 3.13 是最新版本，发布于 2024 年 10 月。...
  分数 0.5234: RAG 是检索增强生成技术，结合了检索和生成。...
  分数 0.5678: LangChain 是一个 LLM 应用开发框架，支持 RAG。...

过滤后（阈值 < 0.5）:
  分数 0.3521: Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。...
  分数 0.3845: FastAPI 是一个现代、快速的 Web 框架，基于 Python 3.6+。...
  分数 0.4123: Python 3.13 是最新版本，发布于 2024 年 10 月。...

=== 5. 元数据过滤 ===
查询: 数据库
过滤结果（只返回 database 类型）:
  [1] ChromaDB 是一个向量数据库，适合原型开发。... | {'type': 'database', 'year': 2022}
  [2] FAISS 是 Facebook 开发的向量检索库，性能极高。... | {'type': 'database', 'year': 2017}

=== 6. 动态 K 值 ===

查询: Python
查询长度: 6 字符 → k=2
返回 2 个结果

查询: 什么是 FastAPI？
查询长度: 11 字符 → k=3
返回 3 个结果

查询: 对比 ChromaDB 和 FAISS 的性能和适用场景
查询长度: 27 字符 → k=3
返回 3 个结果

=== 7. 性能对比 ===
基础检索: 12.34 ms
混合检索: 25.67 ms
MMR 检索: 18.45 ms

✓ 检索优化演示完成！
```

---

## 检索策略对比

| 策略 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| **基础向量检索** | 快速、简单 | 可能漏掉关键词 | 语义相似查询 |
| **混合检索** | 精确+语义 | 速度慢 | 专有名词、代码 |
| **MMR** | 多样性 | 可能不够精准 | 需要多角度信息 |
| **阈值过滤** | 避免噪音 | 可能过滤太多 | 高精度要求 |
| **元数据过滤** | 精准定位 | 需要元数据 | 分类明确的知识库 |

---

## 最佳实践

1. **默认使用基础检索**（简单快速）
2. **专有名词用混合检索**（如"GPT-4"）
3. **需要多样性用 MMR**（避免重复）
4. **设置相似度阈值**（过滤噪音）
5. **利用元数据过滤**（缩小范围）

---

**下一步**：学习 [07_实战代码_05_上下文管理](./07_实战代码_05_上下文管理.md)
