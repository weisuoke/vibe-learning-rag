# 化骨绵掌

本文档通过 10 个知识卡片，帮助你快速掌握 Milvus 数据插入与查询的核心要点。

---

## 卡片 1: 数据插入的本质

### 一句话核心

**数据插入是将向量数据和元数据批量写入 Milvus Collection 的过程，批量插入比单条插入快 20-100 倍。**

### 代码示例

```python
from pymilvus import Collection
import numpy as np

collection = Collection("my_collection")

# 准备批量数据
num_entities = 1000
embeddings = np.random.rand(num_entities, 384).tolist()
texts = [f"文档 {i}" for i in range(num_entities)]

# 批量插入（推荐）
data = [embeddings, texts]
result = collection.insert(data)
collection.flush()  # 刷新到磁盘

print(f"成功插入 {len(result.primary_keys)} 条数据")
```

### 实际应用

- **RAG 文档导入**: 批量插入文档向量到知识库
- **推荐系统**: 批量插入商品向量
- **图像检索**: 批量插入图像特征向量

### 关键要点

- 批量大小推荐：1000-5000
- 插入后必须 flush()
- 数据顺序必须与 Schema 一致

---

## 卡片 2: 批量插入 vs 单条插入

### 一句话核心

**批量插入通过减少网络往返次数，性能比单条插入提升 20-100 倍，是生产环境的必选方案。**

### 代码示例

```python
import time

# ❌ 单条插入（慢）
start = time.time()
for i in range(1000):
    collection.insert([[embedding], [text]])
single_time = time.time() - start
print(f"单条插入耗时: {single_time:.2f} 秒")

# ✅ 批量插入（快）
start = time.time()
collection.insert([embeddings, texts])  # 1000 条
batch_time = time.time() - start
print(f"批量插入耗时: {batch_time:.2f} 秒")

print(f"性能提升: {single_time / batch_time:.0f}x")
```

### 实际应用

- **大规模文档导入**: 10 万+ 文档快速入库
- **实时数据同步**: 定期批量同步新数据
- **数据迁移**: 从其他系统批量迁移数据

### 关键要点

- 单条插入：~3ms/条（网络开销大）
- 批量插入：~0.15ms/条（网络开销小）
- 推荐批量大小：1000-5000

---

## 卡片 3: 索引是检索的前提

### 一句话核心

**Milvus 强制要求创建索引才能执行 search() 操作，这是性能优先的设计理念。**

### 代码示例

```python
from pymilvus import Collection

collection = Collection("my_collection")

# ❌ 没有索引就 search()
# collection.search(...)  # 报错：index not exist

# ✅ 创建索引后 search()
index_params = {
    "index_type": "HNSW",
    "metric_type": "COSINE",
    "params": {"M": 16, "efConstruction": 256}
}
collection.create_index("embedding", index_params)
collection.load()

# 现在可以检索
results = collection.search(...)
```

### 实际应用

- **RAG 系统初始化**: 创建索引后才能提供检索服务
- **性能优化**: 索引使检索速度提升 100-1000 倍
- **生产环境**: 必须创建索引才能上线

### 关键要点

- 没有索引无法 search()
- 索引创建需要时间（大数据量）
- 必须 load() 才能检索

---

## 卡片 4: HNSW 是 RAG 的最佳选择

### 一句话核心

**HNSW 索引基于图结构，具有高召回率（95-99%）和快速检索速度（毫秒级），是 RAG 场景的最佳选择。**

### 代码示例

```python
# RAG 推荐配置
index_params = {
    "index_type": "HNSW",
    "metric_type": "COSINE",  # 文本向量推荐
    "params": {
        "M": 16,              # 每个节点的最大连接数
        "efConstruction": 256 # 构建索引时的搜索深度
    }
}

collection.create_index("embedding", index_params)

# 检索参数
search_params = {
    "metric_type": "COSINE",
    "params": {"ef": 64}  # 检索时的搜索深度
}

results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

### 实际应用

- **文档问答系统**: 快速检索相关文档
- **知识库检索**: 毫秒级响应
- **大规模数据**: 支持百万级向量检索

### 关键要点

- M=16, efConstruction=256, ef=64 是通用配置
- 召回率 95-99%
- 检索延迟 < 10ms

---

## 卡片 5: 相似度度量的选择

### 一句话核心

**COSINE 相似度只关注向量方向不关注长度，适合文本向量；L2 距离考虑长度和方向，适合图像向量。**

### 代码示例

```python
# COSINE 相似度（推荐用于文本）
index_params = {
    "index_type": "HNSW",
    "metric_type": "COSINE",  # 值越大越相似，范围 [-1, 1]
    "params": {"M": 16, "efConstruction": 256}
}

search_params = {
    "metric_type": "COSINE",
    "params": {"ef": 64}
}

results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
)

# 处理结果
for hit in results[0]:
    print(f"相似度: {hit.score:.4f}")  # 越大越相似
```

### 实际应用

- **文本检索**: 使用 COSINE（不受文本长度影响）
- **图像检索**: 使用 L2（长度有意义）
- **推荐系统**: 使用 IP（归一化向量）

### 关键要点

- COSINE: 范围 [-1, 1]，越大越相似
- L2: 范围 [0, +∞)，越小越相似
- RAG 推荐 COSINE

---

## 卡片 6: Top-K 参数控制返回数量

### 一句话核心

**limit 参数控制返回 Top-K 个最相似的结果，RAG 场景推荐初始检索 Top-20-50，ReRank 后取 Top-5。**

### 代码示例

```python
# 初始检索：召回更多候选
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=20  # 召回 Top-20
)

# 提取候选文档
candidates = [hit.entity.get("text") for hit in results[0]]

# ReRank（可选）
# reranked = rerank_model.rerank(query, candidates)

# 最终选择 Top-5
final_docs = candidates[:5]
```

### 实际应用

- **RAG 检索**: 初始召回 20-50，ReRank 后取 5
- **推荐系统**: 召回 100，排序后展示 10
- **图像检索**: 返回 Top-10 相似图像

### 关键要点

- limit 越大，召回率越高，但速度越慢
- RAG 推荐：初始 20-50，最终 5
- ef 必须 >= limit

---

## 卡片 7: 标量过滤实现混合检索

### 一句话核心

**expr 表达式支持标量字段过滤，实现向量检索 + 条件筛选的混合检索，提高结果精准度。**

### 代码示例

```python
# 向量检索 + 标量过滤
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category == 'technology' and rating >= 4.0",  # 过滤条件
    output_fields=["text", "category", "rating"]
)

# 所有结果都满足过滤条件
for hit in results[0]:
    print(f"分类: {hit.entity.get('category')}, "
          f"评分: {hit.entity.get('rating')}")
```

### 实际应用

- **文档分类检索**: 按类别、标签过滤
- **时间范围检索**: 按时间戳过滤
- **权限控制**: 按用户权限过滤

### 关键要点

- expr 语法：==, !=, >, <, >=, <=, and, or, in
- 字符串必须用单引号
- 过滤后再做向量检索，性能更好

---

## 卡片 8: ef 参数控制检索精度

### 一句话核心

**ef 参数控制 HNSW 索引的检索深度，ef 越大召回率越高但速度越慢，推荐 ef=64 平衡性能。**

### 代码示例

```python
# 不同 ef 值的性能对比
ef_configs = [32, 64, 128]

for ef in ef_configs:
    search_params = {
        "metric_type": "COSINE",
        "params": {"ef": ef}
    }
    
    start = time.time()
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=10
    )
    latency = (time.time() - start) * 1000
    
    print(f"ef={ef}: 延迟 {latency:.2f}ms")

# 输出示例:
# ef=32:  延迟 3.2ms
# ef=64:  延迟 5.1ms
# ef=128: 延迟 9.8ms
```

### 实际应用

- **速度优先**: ef=32（延迟 < 5ms）
- **平衡性能**: ef=64（推荐）
- **精度优先**: ef=128（召回率 > 98%）

### 关键要点

- ef 必须 >= limit
- ef 越大，召回率越高，速度越慢
- RAG 推荐 ef=64

---

## 卡片 9: output_fields 控制返回字段

### 一句话核心

**output_fields 参数指定返回的标量字段，只返回需要的字段可以减少网络传输，提高性能。**

### 代码示例

```python
# 只返回需要的字段
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    output_fields=["text", "doc_id"]  # 只返回这两个字段
)

# 处理结果
for hit in results[0]:
    text = hit.entity.get("text")
    doc_id = hit.entity.get("doc_id")
    print(f"文档ID: {doc_id}, 文本: {text[:50]}...")
```

### 实际应用

- **RAG 检索**: 只返回 text 和 doc_id
- **推荐系统**: 只返回 item_id 和 title
- **性能优化**: 减少不必要的字段传输

### 关键要点

- 不指定 output_fields 则不返回任何标量字段
- 向量字段不能通过 output_fields 返回
- 只返回需要的字段可以提高性能

---

## 卡片 10: 完整的 RAG 检索流程

### 一句话核心

**RAG 检索流程包括：向量化问题 → 检索相关文档 → 提取文本 → 构建 Prompt → LLM 生成答案。**

### 代码示例

```python
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# 1. 初始化组件
connections.connect(host="localhost", port="19530")
collection = Collection("rag_knowledge_base")
collection.load()

embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
llm_client = OpenAI()

# 2. RAG 检索函数
def rag_search(question, top_k=5):
    # 向量化问题
    query_vector = embedding_model.encode(question).tolist()
    
    # 检索相关文档
    search_params = {"metric_type": "COSINE", "params": {"ef": 64}}
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["text"]
    )
    
    # 提取文档
    documents = [hit.entity.get("text") for hit in results[0]]
    return documents

# 3. RAG 生成函数
def rag_generate(question, documents):
    # 构建上下文
    context = "\n\n".join(documents)
    
    # 构建 Prompt
    prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{question}

答案："""
    
    # 调用 LLM
    response = llm_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    
    return response.choices[0].message.content

# 4. 完整流程
question = "什么是向量数据库？"
documents = rag_search(question, top_k=5)
answer = rag_generate(question, documents)
print(f"答案: {answer}")
```

### 实际应用

- **企业知识库问答**: 基于内部文档回答问题
- **技术文档检索**: 快速找到相关技术文档
- **客服智能问答**: 自动回答常见问题

### 关键要点

- 检索 Top-5 到 Top-10 文档
- 使用 COSINE 相似度
- 构建清晰的 Prompt 模板
- 设置合适的 temperature

---

## 知识卡片总结

### 核心流程

```
数据插入 → 创建索引 → 加载到内存 → 执行检索 → 处理结果
```

### 关键参数

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| batch_size | 1000-5000 | 批量插入大小 |
| index_type | HNSW | 索引类型 |
| metric_type | COSINE | 相似度度量 |
| M | 16 | HNSW 连接数 |
| efConstruction | 256 | HNSW 构建深度 |
| ef | 64 | HNSW 检索深度 |
| limit | 5-10 | 返回结果数量 |

### 性能优化

1. **批量插入**: 比单条插入快 20-100 倍
2. **HNSW 索引**: 比暴力搜索快 100-1000 倍
3. **标量过滤**: 先过滤再检索，提高精准度
4. **减少返回字段**: 只返回需要的字段

### RAG 最佳实践

1. 使用 HNSW 索引（M=16, efConstruction=256）
2. 使用 COSINE 相似度度量
3. 批量插入文档（batch_size=2000）
4. 检索 Top-20-50，ReRank 后取 Top-5
5. 使用标量过滤实现分类检索
6. 定期监控性能指标

---

## 记忆口诀

```
批量插入效率高，索引必须先创建
HNSW 适合大规模，COSINE 文本最合适
ef 参数控精度，limit 控制返回数
标量过滤更精准，RAG 流程要完整
```

---

## 快速检查清单

### 数据插入

- [ ] 使用批量插入（batch_size=1000-5000）
- [ ] 插入后调用 flush()
- [ ] 数据顺序与 Schema 一致
- [ ] 向量维度匹配

### 索引创建

- [ ] 选择 HNSW 索引
- [ ] 使用 COSINE 度量
- [ ] 设置 M=16, efConstruction=256
- [ ] 创建后调用 load()

### 相似度检索

- [ ] 设置 ef=64
- [ ] 设置合适的 limit
- [ ] 使用 expr 过滤（如需要）
- [ ] 只返回需要的字段

### RAG 应用

- [ ] 初始化 Embedding 模型
- [ ] 初始化 LLM 客户端
- [ ] 实现检索函数
- [ ] 实现生成函数
- [ ] 构建完整流程

---

## 下一步

学习 **一句话总结**，用一句话概括 Milvus 数据插入与查询的核心要点。
