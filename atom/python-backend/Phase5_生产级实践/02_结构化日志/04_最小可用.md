# 最小可用：5个核心知识点快速上手

## 学习目标

**用最少的时间（30分钟），掌握在 AI Agent API 中使用结构化日志的核心知识。**

这5个知识点是"最小可用集合"，掌握它们就能在生产环境中使用结构化日志。

---

## 知识点1：理解结构化日志的本质（5分钟）

### 核心概念

**结构化日志 = 键值对格式的日志**

**对比：**

```python
# ❌ 传统日志（纯文本）
print("User john called API at 10:30:45")

# ✅ 结构化日志（键值对）
logger.info("api_call", user="john", timestamp="10:30:45")
```

**输出对比：**

```
# 传统日志
User john called API at 10:30:45

# 结构化日志（JSON格式）
{"event": "api_call", "user": "john", "timestamp": "10:30:45"}
```

### 为什么重要？

**场景：** 你想查询"所有用户john的请求"

**传统日志：**
```bash
grep "john" app.log  # 可能匹配到其他包含"john"的日志
```

**结构化日志：**
```bash
jq 'select(.user == "john")' app.log  # 精确匹配user字段
```

### 类比

**传统日志 = Word文档**
- 人类可读
- 机器难处理

**结构化日志 = Excel表格**
- 机器可处理
- 人类通过工具查看

### 最小实践

```python
import structlog

# 配置结构化日志
structlog.configure(
    processors=[
        structlog.processors.JSONRenderer()  # 输出JSON格式
    ]
)

logger = structlog.get_logger()

# 使用
logger.info("user_login", user_id="user_123", ip="192.168.1.1")
```

**输出：**
```json
{"event": "user_login", "user_id": "user_123", "ip": "192.168.1.1"}
```

---

## 知识点2：日志级别的正确使用（5分钟）

### 5个标准级别

| 级别 | 用途 | 示例 | 生产环境 |
|------|------|------|----------|
| **DEBUG** | 详细调试信息 | 变量值、函数调用 | ❌ 不用 |
| **INFO** | 关键操作记录 | 用户登录、API调用 | ✅ 使用 |
| **WARNING** | 潜在问题 | 重试、降级 | ✅ 使用 |
| **ERROR** | 错误但可恢复 | API调用失败 | ✅ 使用 |
| **CRITICAL** | 严重错误 | 数据库连接失败 | ✅ 使用 |

### 核心原则

**开发环境：** 使用 DEBUG 级别，看到所有日志

**生产环境：** 使用 INFO 级别，只记录关键操作

### 常见错误

```python
# ❌ 错误：生产环境用DEBUG
logger.debug("processing data", data=large_data)  # 日志量太大

# ✅ 正确：生产环境用INFO
logger.info("processing_data", data_size=len(large_data))  # 只记录大小
```

### 最小实践

```python
import structlog

logger = structlog.get_logger()

# AI Agent API 的典型日志
logger.info("request_received", endpoint="/chat", user_id="user_123")
logger.info("rag_search", query="Python", results_count=5)
logger.info("llm_call", model="gpt-4", tokens=100)
logger.error("llm_call_failed", error="timeout", retry_count=3)
```

### 决策树

```
需要记录日志？
├─ 是正常操作？
│  ├─ 是关键操作（用户登录、API调用）？ → INFO
│  └─ 是调试信息（变量值）？ → DEBUG
├─ 是潜在问题（重试、降级）？ → WARNING
├─ 是错误但可恢复？ → ERROR
└─ 是严重错误（系统崩溃）？ → CRITICAL
```

---

## 知识点3：请求ID追踪（10分钟）

### 核心概念

**请求ID = 每个HTTP请求的唯一标识符**

**作用：** 关联一个请求产生的所有日志

### 为什么需要？

**场景：** 一个AI Agent请求的处理流程

```
用户请求 → RAG检索 → LLM调用 → 工具调用 → 返回结果
   ↓          ↓         ↓         ↓         ↓
 日志1      日志2      日志3     日志4     日志5
```

**问题：** 这5条日志混在10万条日志中，如何关联？

**解决：** 给每个请求分配一个唯一ID，所有日志都带上这个ID

```json
{"request_id": "req_abc", "event": "request_received"}
{"request_id": "req_abc", "event": "rag_search"}
{"request_id": "req_abc", "event": "llm_call"}
{"request_id": "req_abc", "event": "tool_call"}
{"request_id": "req_abc", "event": "response_sent"}
```

**查询：** `request_id="req_abc"` 立即找到所有相关日志

### 最小实践

```python
import uuid
from fastapi import FastAPI, Request
import structlog

app = FastAPI()
logger = structlog.get_logger()

@app.middleware("http")
async def add_request_id(request: Request, call_next):
    # 生成请求ID
    request_id = str(uuid.uuid4())

    # 绑定到日志上下文
    structlog.contextvars.bind_contextvars(request_id=request_id)

    # 记录请求开始
    logger.info("request_start", method=request.method, path=request.url.path)

    # 处理请求
    response = await call_next(request)

    # 记录请求结束
    logger.info("request_end", status_code=response.status_code)

    # 清理上下文
    structlog.contextvars.clear_contextvars()

    return response

@app.get("/chat")
async def chat():
    # 所有日志自动带上request_id
    logger.info("processing_chat")
    logger.info("calling_llm", model="gpt-4")
    return {"message": "Hello"}
```

**输出：**
```json
{"request_id": "req_abc", "event": "request_start", "method": "GET", "path": "/chat"}
{"request_id": "req_abc", "event": "processing_chat"}
{"request_id": "req_abc", "event": "calling_llm", "model": "gpt-4"}
{"request_id": "req_abc", "event": "request_end", "status_code": 200}
```

### 类比

**请求ID = 快递单号**
- 快递从发出到送达，经过多个环节
- 通过快递单号可以追踪整个流程
- 请求ID也是如此，追踪请求的完整链路

---

## 知识点4：上下文绑定（5分钟）

### 核心概念

**上下文绑定 = 把信息"绑定"到日志上下文，后续所有日志自动包含**

### 为什么需要？

**问题：** 每次记录日志都要手动传递 `request_id`、`user_id` 等信息

```python
# ❌ 繁琐：每次都要传
logger.info("event1", request_id=request_id, user_id=user_id)
logger.info("event2", request_id=request_id, user_id=user_id)
logger.info("event3", request_id=request_id, user_id=user_id)
```

**解决：** 绑定一次，后续自动包含

```python
# ✅ 简洁：绑定一次
structlog.contextvars.bind_contextvars(
    request_id=request_id,
    user_id=user_id
)

logger.info("event1")  # 自动包含 request_id 和 user_id
logger.info("event2")  # 自动包含 request_id 和 user_id
logger.info("event3")  # 自动包含 request_id 和 user_id
```

### 最小实践

```python
import structlog
from fastapi import FastAPI, Request

app = FastAPI()
logger = structlog.get_logger()

# 配置structlog使用contextvars
structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,  # 合并上下文变量
        structlog.processors.JSONRenderer()
    ]
)

@app.middleware("http")
async def add_context(request: Request, call_next):
    # 绑定请求级别的上下文
    structlog.contextvars.bind_contextvars(
        request_id=str(uuid.uuid4()),
        user_id=request.headers.get("X-User-ID", "anonymous")
    )

    response = await call_next(request)

    # 清理上下文
    structlog.contextvars.clear_contextvars()

    return response

@app.get("/chat")
async def chat():
    # 所有日志自动包含 request_id 和 user_id
    logger.info("chat_start")

    # 可以临时绑定更多上下文
    structlog.contextvars.bind_contextvars(model="gpt-4")
    logger.info("llm_call")  # 包含 request_id, user_id, model

    return {"message": "Hello"}
```

**输出：**
```json
{"request_id": "req_abc", "user_id": "user_123", "event": "chat_start"}
{"request_id": "req_abc", "user_id": "user_123", "model": "gpt-4", "event": "llm_call"}
```

### 类比

**上下文绑定 = 对话上下文**
- 对话开始时说"我是张三"
- 后续对话不需要每次都说"我是张三"
- 对方自动知道你是张三

---

## 知识点5：AI Agent 特定日志（5分钟）

### 核心概念

**AI Agent API 需要记录的关键信息：**

1. **LLM 调用**：prompt、response、tokens、耗时
2. **RAG 检索**：query、结果数量、相似度分数
3. **工具调用**：工具名称、参数、结果
4. **错误信息**：错误类型、堆栈、上下文

### 最小实践

```python
import structlog
import time
from openai import OpenAI

logger = structlog.get_logger()
client = OpenAI()

async def call_llm(prompt: str, model: str = "gpt-4"):
    """调用LLM并记录日志"""
    start_time = time.time()

    # 记录调用开始
    logger.info("llm_call_start", model=model, prompt_length=len(prompt))

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}]
        )

        duration_ms = (time.time() - start_time) * 1000

        # 记录调用成功
        logger.info(
            "llm_call_success",
            model=model,
            tokens_used=response.usage.total_tokens,
            duration_ms=duration_ms,
            response_length=len(response.choices[0].message.content)
        )

        return response.choices[0].message.content

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        # 记录调用失败
        logger.error(
            "llm_call_failed",
            model=model,
            error=str(e),
            error_type=type(e).__name__,
            duration_ms=duration_ms
        )
        raise

async def rag_search(query: str):
    """RAG检索并记录日志"""
    logger.info("rag_search_start", query=query)

    # 模拟检索
    results = ["doc1", "doc2", "doc3"]

    logger.info(
        "rag_search_success",
        query=query,
        results_count=len(results),
        top_score=0.95
    )

    return results
```

**输出示例：**
```json
{"event": "llm_call_start", "model": "gpt-4", "prompt_length": 100}
{"event": "llm_call_success", "model": "gpt-4", "tokens_used": 150, "duration_ms": 1200, "response_length": 200}

{"event": "rag_search_start", "query": "Python"}
{"event": "rag_search_success", "query": "Python", "results_count": 3, "top_score": 0.95}
```

### 关键指标

**LLM 调用必记录：**
- ✅ 模型名称（model）
- ✅ Token 消耗（tokens_used）
- ✅ 耗时（duration_ms）
- ✅ 成功/失败状态

**RAG 检索必记录：**
- ✅ 查询内容（query）
- ✅ 结果数量（results_count）
- ✅ 最高相似度分数（top_score）
- ✅ 耗时（duration_ms）

### 类比

**AI Agent 日志 = 飞机黑匣子**
- 记录关键操作（起飞、降落、转向）
- 记录性能指标（速度、高度、油耗）
- 出问题时可以回放整个过程

---

## 快速上手检查清单

完成以下5个任务，你就掌握了结构化日志的最小可用知识：

### ✅ 任务1：安装和配置 structlog（5分钟）

```bash
# 安装
pip install structlog

# 测试
python -c "import structlog; print('OK')"
```

### ✅ 任务2：创建第一个结构化日志（5分钟）

```python
import structlog

structlog.configure(
    processors=[
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()
logger.info("hello", name="world")
```

**期望输出：**
```json
{"event": "hello", "name": "world"}
```

### ✅ 任务3：在 FastAPI 中添加请求ID（10分钟）

```python
import uuid
from fastapi import FastAPI, Request
import structlog

app = FastAPI()
logger = structlog.get_logger()

structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.JSONRenderer()
    ]
)

@app.middleware("http")
async def add_request_id(request: Request, call_next):
    request_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(request_id=request_id)

    logger.info("request_start", path=request.url.path)
    response = await call_next(request)
    logger.info("request_end", status=response.status_code)

    structlog.contextvars.clear_contextvars()
    return response

@app.get("/")
async def root():
    logger.info("processing_request")
    return {"message": "Hello"}
```

**测试：**
```bash
uvicorn main:app --reload
curl http://localhost:8000/
```

**期望输出：**
```json
{"request_id": "...", "event": "request_start", "path": "/"}
{"request_id": "...", "event": "processing_request"}
{"request_id": "...", "event": "request_end", "status": 200}
```

### ✅ 任务4：记录 LLM 调用日志（5分钟）

```python
import structlog
import time

logger = structlog.get_logger()

def call_llm(prompt: str):
    start = time.time()
    logger.info("llm_call_start", prompt_length=len(prompt))

    # 模拟LLM调用
    time.sleep(0.1)
    response = "This is a response"

    duration_ms = (time.time() - start) * 1000
    logger.info("llm_call_end", duration_ms=duration_ms, response_length=len(response))

    return response

call_llm("What is Python?")
```

### ✅ 任务5：查询日志（5分钟）

```bash
# 假设日志保存在 app.log

# 查询特定请求的所有日志
jq 'select(.request_id == "req_abc")' app.log

# 查询所有LLM调用
jq 'select(.event == "llm_call_end")' app.log

# 统计平均耗时
jq -s 'map(select(.event == "llm_call_end")) | map(.duration_ms) | add / length' app.log
```

---

## 最小可用配置模板

### 完整的最小配置

```python
# config/logging.py
import structlog
import logging

def setup_logging(log_level: str = "INFO"):
    """配置结构化日志"""

    # 配置标准库logging
    logging.basicConfig(
        format="%(message)s",
        level=log_level,
    )

    # 配置structlog
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,  # 合并上下文变量
            structlog.processors.add_log_level,        # 添加日志级别
            structlog.processors.TimeStamper(fmt="iso"),  # 添加时间戳
            structlog.processors.JSONRenderer()        # JSON格式输出
        ],
        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )

# main.py
import uuid
from fastapi import FastAPI, Request
import structlog
from config.logging import setup_logging

# 初始化日志
setup_logging()

app = FastAPI()
logger = structlog.get_logger()

@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    # 生成请求ID
    request_id = str(uuid.uuid4())

    # 绑定上下文
    structlog.contextvars.bind_contextvars(
        request_id=request_id,
        method=request.method,
        path=request.url.path
    )

    # 记录请求开始
    logger.info("request_start")

    # 处理请求
    response = await call_next(request)

    # 记录请求结束
    logger.info("request_end", status_code=response.status_code)

    # 清理上下文
    structlog.contextvars.clear_contextvars()

    return response

@app.get("/")
async def root():
    logger.info("processing_root")
    return {"message": "Hello"}
```

---

## 下一步

**掌握了这5个知识点后，你可以：**

1. ✅ 在 AI Agent API 中使用结构化日志
2. ✅ 通过请求ID追踪完整的请求链路
3. ✅ 记录 LLM 调用的关键指标
4. ✅ 使用日志快速定位问题

**继续学习：**

- 【核心概念】- 深入理解结构化日志的原理
- 【实战代码】- 更多实际场景的代码示例
- 【生产级日志系统】- 日志轮转、性能优化、安全性

**记住：** 这5个知识点是"最小可用集合"，足以在生产环境中使用。不要追求完美，先用起来，再逐步优化。
