# 化骨绵掌：10个2分钟知识卡片

## 卡片1：pgvector 是什么？

**一句话：** pgvector 是 PostgreSQL 的向量扩展，让关系数据库具备向量存储和相似度检索能力。

**举例：**
```sql
-- 创建向量表
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding vector(1536)  -- 1536 维向量
);

-- 插入向量
INSERT INTO documents (content, embedding)
VALUES ('什么是向量数据库？', '[0.1, 0.2, ...]');

-- 相似度检索
SELECT content, embedding <=> '[0.1, 0.2, ...]' AS distance
FROM documents
ORDER BY distance
LIMIT 5;
```

**应用：** 在 RAG 系统中，pgvector 存储文档的 Embedding，用户提问时检索最相关的文档，然后输入给 LLM 生成回答。

---

## 卡片2：vector 数据类型

**一句话：** `vector(N)` 是 pgvector 提供的数据类型，存储 N 维浮点数向量。

**举例：**
```sql
-- 不同维度的向量
CREATE TABLE embeddings (
    openai_small vector(1536),   -- OpenAI text-embedding-3-small
    openai_large vector(3072),   -- OpenAI text-embedding-3-large
    sentence_bert vector(384)    -- Sentence-Transformers
);

-- 维度必须匹配
INSERT INTO embeddings (openai_small)
VALUES ('[0.1, 0.2, ...]');  -- 必须是 1536 维
```

**应用：** 选择向量维度时，使用 Embedding 模型的默认维度。OpenAI 的 text-embedding-3-small（1536 维）适合大多数文本检索场景。

---

## 卡片3：三种距离函数

**一句话：** pgvector 支持余弦距离（`<=>`）、欧氏距离（`<->`）、内积距离（`<#>`）三种相似度计算方法。

**举例：**
```sql
-- 余弦距离（推荐用于文本）
SELECT content, embedding <=> query_embedding AS distance
FROM documents ORDER BY distance LIMIT 10;

-- 欧氏距离（用于图像）
SELECT content, embedding <-> query_embedding AS distance
FROM documents ORDER BY distance LIMIT 10;

-- 内积距离（用于推荐系统）
SELECT content, embedding <#> query_embedding AS distance
FROM documents ORDER BY distance LIMIT 10;
```

**应用：** 文本 Embedding（OpenAI、Sentence-Transformers）使用余弦距离，因为这些模型的输出已归一化，只需比较方向。

---

## 卡片4：Top-K 检索

**一句话：** Top-K 检索返回与查询向量最相似的 K 个结果，而不是所有结果。

**举例：**
```python
# 动态 Top-K
def search_documents(query: str, top_k: int = 5):
    query_embedding = client.embeddings.create(
        input=query,
        model="text-embedding-3-small"
    ).data[0].embedding

    cursor.execute(
        """
        SELECT id, content, embedding <=> %s AS distance
        FROM documents
        ORDER BY distance
        LIMIT %s
        """,
        (query_embedding, top_k)
    )
    return cursor.fetchall()

# 使用
results = search_documents("向量数据库", top_k=5)
```

**应用：** RAG 系统通常只需要 Top-3 到 Top-5 的文档作为上下文，不需要返回所有相关文档。

---

## 卡片5：HNSW 索引

**一句话：** HNSW 是多层图结构的向量索引，查询复杂度 O(log N)，召回率高（95-99%）。

**举例：**
```sql
-- 创建 HNSW 索引
CREATE INDEX ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 查询时调整搜索范围
SET hnsw.ef_search = 100;

-- 查询（自动使用索引）
SELECT * FROM documents
ORDER BY embedding <=> query_embedding
LIMIT 10;
```

**应用：** 适合查询频繁、插入不频繁的场景（如文档知识库）。50 万文档时，HNSW 索引可将查询延迟从 5 秒降到 30 毫秒。

---

## 卡片6：IVFFlat 索引

**一句话：** IVFFlat 使用聚类和倒排索引加速检索，构建快、内存小，召回率中等（80-95%）。

**举例：**
```sql
-- 创建 IVFFlat 索引
CREATE INDEX ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);  -- 聚类数

-- 查询时调整探测簇数
SET ivfflat.probes = 10;

-- 查询
SELECT * FROM documents
ORDER BY embedding <=> query_embedding
LIMIT 10;
```

**应用：** 适合数据频繁插入/更新的场景（如实时聊天记录）。lists 推荐值为 sqrt(N)，probes 推荐值为 lists/10。

---

## 卡片7：过滤条件的组合

**一句话：** 向量检索可以结合 WHERE 条件过滤，预过滤适合高选择性条件，后过滤适合低选择性条件。

**举例：**
```sql
-- 预过滤（高选择性：user_id）
SELECT * FROM documents
WHERE user_id = 123  -- 先过滤
ORDER BY embedding <=> query_embedding
LIMIT 10;

-- 后过滤（低选择性：时间范围）
SELECT * FROM documents
WHERE created_at > '2024-01-01'  -- 后过滤
ORDER BY embedding <=> query_embedding
LIMIT 10;

-- 复杂过滤
SELECT * FROM documents
WHERE category IN ('tech', 'ai')
  AND priority >= 3
ORDER BY embedding <=> query_embedding
LIMIT 10;
```

**应用：** 在 RAG 系统中，可以按用户权限、文档分类、时间范围等条件过滤，只检索用户有权访问的相关文档。

---

## 卡片8：RAG 系统的完整流程

**一句话：** RAG = 检索（Retrieval）+ 增强（Augmented）+ 生成（Generation），先检索相关文档，再输入 LLM 生成回答。

**举例：**
```python
def rag_qa(question: str):
    # 1. 生成查询向量
    query_embedding = client.embeddings.create(
        input=question,
        model="text-embedding-3-small"
    ).data[0].embedding

    # 2. 检索相关文档（Top-3）
    cursor.execute(
        "SELECT content FROM documents ORDER BY embedding <=> %s LIMIT 3",
        (query_embedding,)
    )
    docs = [row[0] for row in cursor.fetchall()]

    # 3. 构建上下文
    context = "\n\n".join(docs)

    # 4. LLM 生成回答
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "根据文档回答问题"},
            {"role": "user", "content": f"文档：\n{context}\n\n问题：{question}"}
        ]
    )

    return response.choices[0].message.content
```

**应用：** pgvector 在 RAG 系统中负责第2步（检索），是数据层的核心组件。

---

## 卡片9：性能优化策略

**一句话：** 优化 pgvector 性能的四个层次：索引层、查询层、数据层、架构层。

**举例：**
```python
# 1. 索引层：创建 HNSW 索引
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);

# 2. 查询层：预过滤 + 限制返回数量
SELECT * FROM documents
WHERE user_id = 123  -- 预过滤
ORDER BY embedding <=> query_embedding
LIMIT 10;  -- 限制返回数量

# 3. 数据层：使用 halfvec 减少存储
ALTER TABLE documents ALTER COLUMN embedding TYPE halfvec(1536);

# 4. 架构层：读写分离 + 缓存
# - 查询走只读副本
# - 高频查询结果缓存到 Redis（TTL 5-10 分钟）
```

**应用：** 在生产环境中，从索引优化开始，逐步优化查询、数据、架构，最终实现毫秒级检索。

---

## 卡片10：常见误区与正确理解

**一句话：** pgvector 的5个常见误区：维度越高越好、距离函数可互换、索引一定生效、只能用于文本、召回率100%。

**举例：**
```python
# 误区1：维度越高越好 ❌
# 正确：使用模型默认维度（1536），高维度有维度灾难

# 误区2：余弦/欧氏距离可互换 ❌
# 正确：文本用余弦（<=>），图像用欧氏（<->）

# 误区3：索引一定生效 ❌
# 正确：需要数据量足够（> 1万）+ LIMIT + EXPLAIN 验证

# 误区4：只能用于文本 ❌
# 正确：可用于任何向量（文本/图像/音频/行为）

# 误区5：召回率100% ❌
# 正确：近似搜索，召回率95-99%，换取速度提升
```

**应用：** 理解这些误区可以避免在实际开发中走弯路，正确使用 pgvector 构建高性能的向量检索系统。

---

## 知识卡片总结

| 卡片 | 主题 | 核心要点 |
|------|------|----------|
| 1 | pgvector 是什么 | PostgreSQL 向量扩展，存储 + 检索 |
| 2 | vector 数据类型 | `vector(N)` 存储 N 维向量 |
| 3 | 三种距离函数 | 余弦（文本）、欧氏（图像）、内积（推荐） |
| 4 | Top-K 检索 | 只返回最相似的 K 个结果 |
| 5 | HNSW 索引 | 多层图，O(log N)，召回率高 |
| 6 | IVFFlat 索引 | 聚类 + 倒排，构建快，内存小 |
| 7 | 过滤条件 | 预过滤（高选择性）vs 后过滤（低选择性） |
| 8 | RAG 流程 | 检索 → 上下文 → LLM 生成 |
| 9 | 性能优化 | 索引/查询/数据/架构四层优化 |
| 10 | 常见误区 | 5个误区 + 正确理解 |

---

## 学习路径建议

**第一阶段：基础理解（卡片1-4）**
- 理解 pgvector 的基本概念
- 掌握 vector 数据类型和距离函数
- 学会 Top-K 检索

**第二阶段：索引优化（卡片5-7）**
- 理解 HNSW 和 IVFFlat 索引原理
- 学会创建和调优索引
- 掌握过滤条件的使用

**第三阶段：实战应用（卡片8-10）**
- 构建完整的 RAG 系统
- 掌握性能优化策略
- 避免常见误区

---

## 快速参考

### 常用命令

```sql
-- 启用扩展
CREATE EXTENSION vector;

-- 创建向量表
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding vector(1536)
);

-- 创建 HNSW 索引
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);

-- 相似度检索
SELECT * FROM documents
ORDER BY embedding <=> '[0.1, 0.2, ...]'
LIMIT 10;
```

### 性能参数

```sql
-- HNSW 参数
m = 16                    -- 邻居数（默认）
ef_construction = 64      -- 构建时搜索范围（默认）
ef_search = 100           -- 查询时搜索范围（推荐）

-- IVFFlat 参数
lists = sqrt(N)           -- 聚类数（推荐）
probes = lists / 10       -- 探测簇数（推荐）
```

### 选型决策

```
数据量 < 10,000：无需索引
查询频繁 + 召回率 > 95%：HNSW
插入频繁 + 内存受限：IVFFlat
```

---

## 延伸学习

完成这10个知识卡片后，可以继续学习：

1. **混合检索**：向量检索 + 全文检索
2. **多模态检索**：文本 + 图像联合检索
3. **ReRank**：重排序提高精度
4. **分布式部署**：多副本 + 负载均衡
5. **监控与调优**：性能指标监控和优化

---

**记住：** pgvector 是 RAG 系统的数据层基础，掌握向量存储、相似度检索、索引优化三大核心，就能构建高性能的向量检索系统。
