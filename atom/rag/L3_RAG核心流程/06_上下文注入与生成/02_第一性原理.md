# 第一性原理

### 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题。

---

## 上下文注入与生成的第一性原理

### 1. 最基础的定义

**上下文注入与生成 = 把"参考资料"放进"问题"里，让 LLM 基于资料回答**

仅此而已！没有更基础的了。

```
普通问答：
用户："公司年假政策是什么？"
LLM：（凭记忆回答，可能过时或错误）

RAG 问答：
用户："公司年假政策是什么？"
+ 注入上下文："【参考资料】根据《员工手册》第3章..."
LLM：（基于参考资料回答，准确且可溯源）
```

---

### 2. 为什么需要上下文注入？

**核心问题：LLM 的知识是"冻结"的，无法获取实时、私有、专业的信息**

```
┌─────────────────────────────────────────────────────────────┐
│                    LLM 的三大局限                            │
│                                                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   时效性    │  │   私有性    │  │   专业性    │         │
│  │             │  │             │  │             │         │
│  │ 训练数据有  │  │ 无法访问    │  │ 通用模型    │         │
│  │ 截止日期    │  │ 企业内部    │  │ 缺乏垂直    │         │
│  │             │  │ 知识库      │  │ 领域深度    │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
│                                                             │
│  解决方案：在提问时"注入"最新、私有、专业的上下文            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**类比理解：**

```
LLM 就像一个"博学但与世隔绝"的专家：
- 他读过很多书（训练数据）
- 但他被关在房间里，不知道外面发生了什么（无法联网）
- 也不知道你公司的内部规定（无法访问私有数据）

上下文注入 = 给这个专家递一份"参考资料"
- 他可以基于资料回答问题
- 答案有据可查
- 不需要"猜测"或"编造"
```

---

### 3. 上下文注入的三层价值

#### 价值1：知识增强（Knowledge Augmentation）

**让 LLM 获得它原本不知道的信息**

```python
# 没有上下文注入
prompt = "我们公司的年假政策是什么？"
# LLM 回答："抱歉，我不知道贵公司的具体政策..."

# 有上下文注入
prompt = """
【参考资料】
根据《员工手册》第3章第2节：
- 入职满1年：5天年假
- 入职满3年：10天年假
- 入职满5年：15天年假

【问题】
我们公司的年假政策是什么？
"""
# LLM 回答："根据《员工手册》，贵公司的年假政策如下..."
```

#### 价值2：答案可溯源（Traceability）

**每个答案都能追溯到具体来源**

```
普通 LLM 回答：
"年假是5天。"
→ 无法验证，可能是幻觉

RAG 回答：
"根据《员工手册》第3章第2节，入职满1年的员工享有5天年假。"
→ 可以验证，有据可查
```

#### 价值3：减少幻觉（Hallucination Reduction）

**LLM 有"参考资料"时，更不容易"编造"**

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  没有上下文：                                                │
│  LLM 被迫"猜测" → 容易产生幻觉                              │
│                                                             │
│  有上下文：                                                  │
│  LLM 可以"引用" → 答案更可靠                                │
│                                                             │
│  + 明确指令"只基于提供的资料回答"                            │
│  → 进一步减少幻觉                                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

### 4. 从第一性原理推导 RAG 生成

**推理链：**

```
1. LLM 的知识是"冻结"的，有截止日期
   ↓
2. 用户需要的信息可能是最新的、私有的、专业的
   ↓
3. 直接问 LLM 会得到过时/错误/编造的答案
   ↓
4. 解决方案：在提问时"注入"相关的参考资料
   ↓
5. 参考资料从哪来？→ 检索系统（前面章节的内容）
   ↓
6. 如何注入？→ 组装成 Prompt（本章核心）
   ↓
7. 如何生成高质量答案？→ 模板设计 + 参数调优
   ↓
8. 最终产出：基于真实资料的、可溯源的、高质量的答案
```

---

### 5. 上下文注入的本质模型

```
┌─────────────────────────────────────────────────────────────┐
│                    上下文注入的本质                          │
│                                                             │
│                                                             │
│    ┌─────────┐                                              │
│    │  System │  ← 定义 LLM 的角色和行为规则                  │
│    │  Prompt │    "你是一个专业的客服助手..."                │
│    └────┬────┘                                              │
│         │                                                   │
│         ▼                                                   │
│    ┌─────────┐                                              │
│    │ Context │  ← 注入检索到的参考资料                       │
│    │  (RAG)  │    "【参考资料】根据文档..."                  │
│    └────┬────┘                                              │
│         │                                                   │
│         ▼                                                   │
│    ┌─────────┐                                              │
│    │  User   │  ← 用户的原始问题                            │
│    │  Query  │    "年假政策是什么？"                        │
│    └────┬────┘                                              │
│         │                                                   │
│         ▼                                                   │
│    ┌─────────┐                                              │
│    │   LLM   │  ← 基于上下文生成答案                        │
│    │ 生成答案 │                                              │
│    └─────────┘                                              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**关键洞察：**

```
Prompt = System + Context + Query

- System：不变的部分（角色定义、行为约束）
- Context：动态的部分（每次检索的结果不同）
- Query：用户输入的部分（每次问题不同）
```

---

### 6. 为什么 Prompt 组装如此重要？

**同样的检索结果，不同的组装方式，效果天差地别：**

```python
# 差的组装方式
prompt = f"{context}\n{query}"
# 问题：LLM 不知道哪部分是参考资料，哪部分是问题

# 好的组装方式
prompt = f"""
你是一个专业的客服助手。请基于以下参考资料回答用户问题。
如果资料中没有相关信息，请如实告知。

【参考资料】
{context}

【用户问题】
{query}

【回答要求】
1. 只基于参考资料回答
2. 引用具体来源
3. 如果不确定，说明不确定
"""
# 效果：LLM 清楚知道自己的角色、资料来源、回答要求
```

---

### 7. 一句话总结第一性原理

**上下文注入是"给 LLM 递参考资料"的过程，让它基于真实信息回答，而非凭记忆猜测。**

---

## 第一性原理的实践指导

基于以上原理，我们可以推导出几个关键实践：

| 原理 | 实践指导 |
|------|----------|
| LLM 知识有限 | 必须注入相关上下文 |
| 上下文决定答案质量 | 检索质量 > 生成技巧 |
| Prompt 结构影响理解 | 使用清晰的模板结构 |
| 明确指令减少幻觉 | 加入"只基于资料回答"的约束 |
| 答案需要可溯源 | 要求 LLM 引用来源 |

---

**下一步：** [03_核心概念](./03_核心概念.md) - 掌握 Prompt 模板设计、Lost in the Middle、Token 预算管理
