# 核心概念：错误处理策略

> **本节目标**：掌握LCEL的错误处理机制，学会使用RunnableWithFallbacks和RunnableRetry构建弹性系统。

---

## 一、为什么需要错误处理？

### 1.1 生产环境的现实

**外部API不可靠**：
- OpenAI API失败率：2-5%
- 原因：网络超时、限流、服务故障

**后果**：
- 无错误处理：用户看到错误页面
- 有错误处理：自动重试或降级，用户无感知

### 1.2 错误处理的价值

| 指标 | 无错误处理 | 有错误处理 |
|------|------------|------------|
| **可用性** | 95-98% | 99.9%+ |
| **用户体验** | 频繁失败 | 平滑降级 |
| **成本** | 人工介入 | 自动恢复 |

---

## 二、RunnableRetry：自动重试

### 2.1 核心原理

**RunnableRetry** 在失败时自动重试，使用指数退避策略。

**重试策略**：
```
第1次失败 → 等待1秒 → 重试
第2次失败 → 等待2秒 → 重试
第3次失败 → 等待4秒 → 重试
...
```

### 2.2 基础用法

```python
from langchain_openai import ChatOpenAI

# 方式1：LLM内置重试
llm = ChatOpenAI(
    model="gpt-4o-mini",
    max_retries=3  # 最多重试3次
)

# 方式2：链级别重试
chain = (
    prompt
    | llm
    | parser
).with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True
)
```

### 2.3 高级配置

```python
from tenacity import (
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential
)

# 精细控制重试行为
chain = base_chain.with_retry(
    # 重试条件
    retry_if_exception_type=(
        TimeoutError,
        ConnectionError,
        RateLimitError
    ),
    # 停止条件
    stop_after_attempt=5,
    # 等待策略
    wait_exponential_jitter=True,
    # 最大等待时间
    wait_exponential_max=60
)
```

### 2.4 实战场景：API限流处理

```python
from openai import RateLimitError

# 处理OpenAI限流
llm_with_retry = ChatOpenAI(
    model="gpt-4o-mini"
).with_retry(
    retry_if_exception_type=(RateLimitError,),
    stop_after_attempt=5,
    wait_exponential_jitter=True
)

chain = prompt | llm_with_retry | parser
```

---

## 三、RunnableWithFallbacks：降级策略

### 3.1 核心原理

**RunnableWithFallbacks** 在主链失败时，依次尝试备用链。

**执行流程**：
```
尝试主链 → 失败
  ↓
尝试备用链1 → 失败
  ↓
尝试备用链2 → 成功 ✓
```

### 3.2 基础用法

```python
# 定义主链和备用链
primary_chain = prompt | ChatOpenAI(model="gpt-4o")
fallback_chain = prompt | ChatOpenAI(model="gpt-3.5-turbo")

# 添加降级
chain = primary_chain.with_fallbacks([fallback_chain])

# 执行
result = chain.invoke(input)
# GPT-4失败 → 自动切换到GPT-3.5
```

### 3.3 多层降级

```python
# 多层降级策略
chain = (
    primary_chain  # 主模型：GPT-4
    .with_fallbacks([
        secondary_chain,  # 备用1：GPT-3.5
        tertiary_chain,   # 备用2：本地模型
        default_chain     # 最终：默认响应
    ])
)
```

### 3.4 实战场景：多模型降级

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.runnables import RunnableLambda

# 主模型：OpenAI GPT-4
primary = prompt | ChatOpenAI(model="gpt-4o") | parser

# 备用1：Anthropic Claude
secondary = prompt | ChatAnthropic(model="claude-3-sonnet") | parser

# 备用2：OpenAI GPT-3.5
tertiary = prompt | ChatOpenAI(model="gpt-3.5-turbo") | parser

# 最终降级：缓存或默认响应
def get_default_response(input):
    # 尝试从缓存获取
    cached = cache.get(input)
    if cached:
        return cached
    # 返回默认响应
    return "抱歉，系统暂时无法处理您的请求，请稍后重试。"

fallback_final = RunnableLambda(get_default_response)

# 组合
resilient_chain = (
    primary
    .with_fallbacks([secondary, tertiary, fallback_final])
)
```

---

## 四、组合使用：重试+降级

### 4.1 最佳实践

**策略**：每层都重试，失败后降级

```python
# 主链：重试3次
primary = (
    prompt
    | ChatOpenAI(model="gpt-4o")
    | parser
).with_retry(stop_after_attempt=3)

# 备用链：重试2次
secondary = (
    prompt
    | ChatOpenAI(model="gpt-3.5-turbo")
    | parser
).with_retry(stop_after_attempt=2)

# 组合：重试+降级
chain = primary.with_fallbacks([secondary])
```

### 4.2 执行流程

```
1. 尝试GPT-4 → 失败
2. 重试GPT-4 (1/3) → 失败
3. 重试GPT-4 (2/3) → 失败
4. 重试GPT-4 (3/3) → 失败
5. 切换到GPT-3.5 → 失败
6. 重试GPT-3.5 (1/2) → 成功 ✓
```

### 4.3 实战案例：生产级RAG

```python
from langchain_core.runnables import RunnablePassthrough

# 检索链（带重试）
retrieval = (
    vectorstore.as_retriever()
    .with_retry(stop_after_attempt=3)
)

# 生成链（带重试+降级）
primary_gen = (
    prompt | ChatOpenAI(model="gpt-4o") | parser
).with_retry(stop_after_attempt=3)

secondary_gen = (
    prompt | ChatOpenAI(model="gpt-3.5-turbo") | parser
).with_retry(stop_after_attempt=2)

generation = primary_gen.with_fallbacks([secondary_gen])

# 完整RAG链
rag_chain = (
    {
        "context": retrieval | format_docs,
        "question": RunnablePassthrough()
    }
    | generation
)
```

---

## 五、错误传播与异常处理

### 5.1 异常传播

**默认行为**：异常向上传播

```python
chain = step1 | step2 | step3

# step2失败 → 整个链失败
```

### 5.2 捕获异常

```python
from langchain_core.runnables import RunnableLambda

def safe_step(input):
    try:
        return risky_operation(input)
    except Exception as e:
        # 记录错误
        logger.error(f"操作失败: {e}")
        # 返回默认值
        return default_value

chain = step1 | RunnableLambda(safe_step) | step3
```

### 5.3 异常注入

```python
# 将异常信息传递给降级链
chain = primary_chain.with_fallbacks(
    [fallback_chain],
    exception_key="error"  # 异常信息注入到input["error"]
)

# 降级链可以访问异常
def fallback_with_error(input):
    error = input.get("error")
    if isinstance(error, RateLimitError):
        return "系统繁忙，请稍后重试"
    return "系统错误，请联系客服"
```

---

## 六、监控与日志

### 6.1 记录重试

```python
from langchain.callbacks import StdOutCallbackHandler

# 添加回调记录重试
chain = base_chain.with_retry(
    stop_after_attempt=3
).with_config({
    "callbacks": [StdOutCallbackHandler()]
})

# 输出：
# Retrying (1/3)...
# Retrying (2/3)...
# Success!
```

### 6.2 记录降级

```python
import logging

logger = logging.getLogger(__name__)

def log_fallback(input, error):
    logger.warning(f"主链失败，切换到备用链: {error}")
    return fallback_chain.invoke(input)

# 使用
chain = primary_chain.with_fallbacks([
    RunnableLambda(lambda x: log_fallback(x, "error"))
])
```

### 6.3 指标收集

```python
from prometheus_client import Counter, Histogram

# 定义指标
retry_counter = Counter('chain_retries_total', 'Total retries')
fallback_counter = Counter('chain_fallbacks_total', 'Total fallbacks')
latency_histogram = Histogram('chain_latency_seconds', 'Chain latency')

# 在回调中收集
class MetricsCallback:
    def on_retry(self, run):
        retry_counter.inc()

    def on_fallback(self, run):
        fallback_counter.inc()

    def on_chain_end(self, run):
        latency = run.end_time - run.start_time
        latency_histogram.observe(latency)
```

---

## 七、最佳实践

### 7.1 重试策略选择

| 场景 | 推荐策略 | 原因 |
|------|----------|------|
| **临时网络故障** | 重试3-5次 | 通常能恢复 |
| **API限流** | 指数退避 | 避免加剧限流 |
| **永久性错误** | 不重试 | 浪费资源 |

### 7.2 降级策略选择

| 场景 | 推荐降级 | 原因 |
|------|----------|------|
| **模型不可用** | 备用模型 | 保证服务 |
| **延迟过高** | 快速模型 | 用户体验 |
| **成本过高** | 便宜模型 | 成本控制 |
| **完全失败** | 缓存/默认 | 最后保障 |

### 7.3 避免的陷阱

**陷阱1：无限重试**
```python
# ❌ 可能永远重试
chain.with_retry()  # 默认无限重试

# ✅ 设置上限
chain.with_retry(stop_after_attempt=5)
```

**陷阱2：重试永久性错误**
```python
# ❌ 对所有错误都重试
chain.with_retry(stop_after_attempt=3)

# ✅ 只重试临时错误
chain.with_retry(
    retry_if_exception_type=(TimeoutError, ConnectionError)
)
```

**陷阱3：降级链也失败**
```python
# ❌ 降级链没有保底
chain.with_fallbacks([fallback1, fallback2])

# ✅ 最后一层保底
chain.with_fallbacks([
    fallback1,
    fallback2,
    RunnableLambda(lambda x: "默认响应")  # 保底
])
```

---

## 八、综合实战案例

### 场景：企业级客服系统

```python
from langchain_openai import ChatOpenAI
from langchain_core.runnables import (
    RunnableLambda,
    RunnablePassthrough
)
import logging

logger = logging.getLogger(__name__)

# 1. 主模型链（GPT-4 + 重试）
primary_chain = (
    prompt
    | ChatOpenAI(model="gpt-4o", temperature=0)
    | parser
).with_retry(
    stop_after_attempt=3,
    retry_if_exception_type=(TimeoutError, ConnectionError)
)

# 2. 备用模型链（GPT-3.5 + 重试）
secondary_chain = (
    prompt
    | ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    | parser
).with_retry(
    stop_after_attempt=2
)

# 3. 缓存降级
def get_cached_response(input):
    cached = cache.get(input["question"])
    if cached:
        logger.info("使用缓存响应")
        return cached
    raise ValueError("缓存未命中")

cache_chain = RunnableLambda(get_cached_response)

# 4. 默认降级
def get_default_response(input):
    logger.warning("所有链都失败，返回默认响应")
    return "抱歉，系统暂时无法处理您的请求。请稍后重试或联系人工客服。"

default_chain = RunnableLambda(get_default_response)

# 5. 组合完整链
customer_service_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | primary_chain.with_fallbacks([
        secondary_chain,
        cache_chain,
        default_chain
    ])
).with_config({
    "run_name": "customer_service",
    "tags": ["prod", "resilient"],
    "callbacks": [monitoring_callback]
})

# 使用
result = customer_service_chain.invoke("如何退货？")
```

---

## 九、总结

### 核心要点

1. **RunnableRetry**：自动重试临时故障
2. **RunnableWithFallbacks**：多层降级保证可用性
3. **组合使用**：每层重试，失败后降级
4. **监控日志**：记录重试和降级事件

### 错误处理金字塔

```
主链（高质量）+ 重试
  ↓ 失败
备用链1（中质量）+ 重试
  ↓ 失败
备用链2（低质量）
  ↓ 失败
缓存/默认响应（保底）
```

### 实施建议

- ✅ 从第一天就添加错误处理
- ✅ 为每层设置合理的重试次数
- ✅ 至少有一层保底降级
- ✅ 监控重试和降级频率
- ✅ 定期审查和优化策略

---

**下一步**：学习【配置管理最佳实践】，掌握RunnableConfig的使用。
