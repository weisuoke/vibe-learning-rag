# 04_æœ€å°å¯ç”¨

> **æœ¬æ–‡æ¡£æä¾› RunnableLambda çš„ 20% æ ¸å¿ƒçŸ¥è¯†ï¼Œè®©ä½ å¿«é€ŸæŒæ¡ 80% çš„åº”ç”¨åœºæ™¯ã€‚**

---

## æ ¸å¿ƒç†å¿µ

**æœ€å°å¯ç”¨çŸ¥è¯†ï¼ˆMinimum Viable Knowledgeï¼‰ï¼š**
- åªå­¦ä¹ æœ€æ ¸å¿ƒçš„ 20% çŸ¥è¯†
- è¶³ä»¥è§£å†³ 80% çš„å®é™…é—®é¢˜
- å¿«é€Ÿä¸Šæ‰‹ï¼Œè¾¹ç”¨è¾¹å­¦

**æœ¬æ–‡æ¡£åŒ…å«ï¼š**
- 5 ä¸ªæ ¸å¿ƒæ¦‚å¿µ
- 3 ä¸ªåŸºç¡€ç”¨æ³•
- 2 ä¸ªå¸¸è§åœºæ™¯
- 1 ä¸ªé¿å‘æŒ‡å—

---

## 5 ä¸ªæ ¸å¿ƒæ¦‚å¿µ

### æ¦‚å¿µ 1ï¼šRunnableLambda æ˜¯é€‚é…å™¨

**ä¸€å¥è¯ï¼š** å°†æ™®é€š Python å‡½æ•°è½¬æ¢ä¸º Runnable ç»„ä»¶

```python
from langchain_core.runnables import RunnableLambda

# æ™®é€šå‡½æ•°
def uppercase(text: str) -> str:
    return text.upper()

# è½¬æ¢ä¸º Runnable
runnable = RunnableLambda(uppercase)

# ç°åœ¨å¯ä»¥ç”¨ Runnable çš„æ–¹å¼è°ƒç”¨
result = runnable.invoke("hello")  # "HELLO"
```

**è®°ä½ï¼š**
- RunnableLambda ä¸æ”¹å˜å‡½æ•°æœ¬èº«
- åªæ˜¯ç»™å‡½æ•°åŠ äº†ä¸€å±‚"Runnable å¤–å¥—"
- è®©å‡½æ•°èƒ½èå…¥ LCEL é“¾

---

### æ¦‚å¿µ 2ï¼šæ”¯æŒé“¾å¼ç»„åˆ

**ä¸€å¥è¯ï¼š** é€šè¿‡ | æ“ä½œç¬¦å°†å¤šä¸ª Runnable è¿æ¥æˆé“¾

```python
# å®šä¹‰å¤šä¸ªå¤„ç†å‡½æ•°
def clean(text: str) -> str:
    return text.strip().lower()

def add_prefix(text: str) -> str:
    return f"processed: {text}"

# ç»„åˆæˆé“¾
chain = RunnableLambda(clean) | RunnableLambda(add_prefix)

# æ‰§è¡Œé“¾
result = chain.invoke("  Hello  ")  # "processed: hello"
```

**è®°ä½ï¼š**
- | æ“ä½œç¬¦è¿æ¥ Runnable
- æ•°æ®ä»å·¦åˆ°å³æµåŠ¨
- å‰ä¸€ä¸ªçš„è¾“å‡ºæ˜¯åä¸€ä¸ªçš„è¾“å…¥

---

### æ¦‚å¿µ 3ï¼šç»Ÿä¸€çš„è°ƒç”¨æ¥å£

**ä¸€å¥è¯ï¼š** æ‰€æœ‰ Runnable éƒ½æœ‰ invokeã€batchã€stream ç­‰æ ‡å‡†æ–¹æ³•

```python
runnable = RunnableLambda(uppercase)

# å•ä¸ªè°ƒç”¨
result = runnable.invoke("hello")  # "HELLO"

# æ‰¹é‡è°ƒç”¨
results = runnable.batch(["hello", "world"])  # ["HELLO", "WORLD"]

# æµå¼è°ƒç”¨ï¼ˆé»˜è®¤å§”æ‰˜ invokeï¼‰
for chunk in runnable.stream("hello"):
    print(chunk)  # "HELLO"
```

**è®°ä½ï¼š**
- invokeï¼šå¤„ç†å•ä¸ªè¾“å…¥
- batchï¼šæ‰¹é‡å¤„ç†å¤šä¸ªè¾“å…¥
- streamï¼šæµå¼è¾“å‡ºï¼ˆé»˜è®¤ä¸€æ¬¡æ€§è¿”å›ï¼‰

---

### æ¦‚å¿µ 4ï¼šå¼‚æ­¥æ”¯æŒ

**ä¸€å¥è¯ï¼š** æ”¯æŒå¼‚æ­¥è°ƒç”¨ï¼Œä½†éœ€è¦æä¾› afunc æ‰èƒ½é«˜æ•ˆ

```python
import asyncio

# æ–¹å¼ 1ï¼šé»˜è®¤å§”æ‰˜ï¼ˆæ€§èƒ½è¾ƒä½ï¼‰
runnable = RunnableLambda(uppercase)
result = await runnable.ainvoke("hello")  # é€šè¿‡çº¿ç¨‹æ± å§”æ‰˜

# æ–¹å¼ 2ï¼šæä¾› afuncï¼ˆæ€§èƒ½é«˜ 10-20xï¼‰
async def async_uppercase(text: str) -> str:
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ
    return text.upper()

runnable = RunnableLambda(uppercase, afunc=async_uppercase)
result = await runnable.ainvoke("hello")  # ç›´æ¥ä½¿ç”¨ afunc
```

**è®°ä½ï¼š**
- é»˜è®¤çš„å¼‚æ­¥æ˜¯é€šè¿‡çº¿ç¨‹æ± å§”æ‰˜ï¼Œæœ‰æ€§èƒ½æŸè€—
- æä¾› afunc å‚æ•°å¯ä»¥å®ç°çœŸæ­£çš„å¼‚æ­¥ï¼Œæ€§èƒ½æå‡ 10-20x
- é«˜å¹¶å‘åœºæ™¯å¿…é¡»æä¾› afunc

---

### æ¦‚å¿µ 5ï¼šé”™è¯¯é‡è¯•

**ä¸€å¥è¯ï¼š** é€šè¿‡ with_retry æ–¹æ³•æ·»åŠ é‡è¯•æœºåˆ¶

```python
def risky_operation(text: str) -> str:
    if len(text) < 3:
        raise ValueError("Text too short")
    return text.upper()

# æ·»åŠ é‡è¯•æœºåˆ¶
runnable = RunnableLambda(risky_operation).with_retry(
    stop_after_attempt=3,  # æœ€å¤šé‡è¯• 3 æ¬¡
    wait_exponential_multiplier=1,  # æŒ‡æ•°é€€é¿
    wait_exponential_max=10  # æœ€å¤§ç­‰å¾… 10 ç§’
)

# ç°åœ¨ä¼šè‡ªåŠ¨é‡è¯•
try:
    result = runnable.invoke("ab")  # ä¼šé‡è¯• 3 æ¬¡åå¤±è´¥
except Exception as e:
    print(f"Failed after retries: {e}")
```

**è®°ä½ï¼š**
- with_retry è¿”å›æ–°çš„ Runnable
- æ”¯æŒæŒ‡æ•°é€€é¿ç­–ç•¥
- é€‚åˆå¤„ç†ä¸ç¨³å®šçš„å¤–éƒ¨è°ƒç”¨

---

## 3 ä¸ªåŸºç¡€ç”¨æ³•

### ç”¨æ³• 1ï¼šåŸºç¡€åŒ…è£…

**åœºæ™¯ï¼š** å°†å•ä¸ªå‡½æ•°è½¬æ¢ä¸º Runnable

```python
from langchain_core.runnables import RunnableLambda

# å®šä¹‰å‡½æ•°
def process(text: str) -> str:
    return text.strip().upper()

# åŒ…è£…ä¸º Runnable
runnable = RunnableLambda(process)

# è°ƒç”¨
result = runnable.invoke("  hello  ")  # "HELLO"
```

**ä½•æ—¶ä½¿ç”¨ï¼š**
- éœ€è¦åœ¨ LCEL é“¾ä¸­ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
- éœ€è¦ Runnable çš„æ ‡å‡†æ¥å£

---

### ç”¨æ³• 2ï¼šé“¾å¼ç»„åˆ

**åœºæ™¯ï¼š** å°†å¤šä¸ªå‡½æ•°ç»„åˆæˆå¤„ç†é“¾

```python
from langchain_core.runnables import RunnableLambda

# å®šä¹‰å¤šä¸ªå¤„ç†æ­¥éª¤
def clean(text: str) -> str:
    return text.strip().lower()

def tokenize(text: str) -> list[str]:
    return text.split()

def count_words(tokens: list[str]) -> int:
    return len(tokens)

# ç»„åˆæˆé“¾
chain = (
    RunnableLambda(clean)
    | RunnableLambda(tokenize)
    | RunnableLambda(count_words)
)

# æ‰§è¡Œ
result = chain.invoke("  Hello World  ")  # 2
```

**ä½•æ—¶ä½¿ç”¨ï¼š**
- éœ€è¦å¤šæ­¥æ•°æ®å¤„ç†
- æ¯ä¸€æ­¥éƒ½æ˜¯ç‹¬ç«‹çš„å‡½æ•°
- éœ€è¦æ¸…æ™°çš„å¤„ç†æµç¨‹

---

### ç”¨æ³• 3ï¼šä¸å…¶ä»– Runnable ç»„åˆ

**åœºæ™¯ï¼š** åœ¨ LangChain é“¾ä¸­æ’å…¥è‡ªå®šä¹‰é€»è¾‘

```python
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# è‡ªå®šä¹‰é¢„å¤„ç†
def preprocess(text: str) -> str:
    return text.strip().lower()

# è‡ªå®šä¹‰åå¤„ç†
def postprocess(text: str) -> str:
    return f"Result: {text}"

# ç»„åˆå®Œæ•´é“¾
chain = (
    RunnableLambda(preprocess)
    | ChatPromptTemplate.from_template("Translate to French: {text}")
    | ChatOpenAI(model="gpt-4")
    | StrOutputParser()
    | RunnableLambda(postprocess)
)

# æ‰§è¡Œ
result = chain.invoke({"text": "  Hello  "})
# "Result: Bonjour"
```

**ä½•æ—¶ä½¿ç”¨ï¼š**
- éœ€è¦åœ¨ LangChain é“¾ä¸­æ’å…¥è‡ªå®šä¹‰é€»è¾‘
- å†…ç½®ç»„ä»¶æ— æ³•æ»¡è¶³éœ€æ±‚
- éœ€è¦ç‰¹æ®Šçš„æ•°æ®å¤„ç†

---

## 2 ä¸ªå¸¸è§åœºæ™¯

### åœºæ™¯ 1ï¼šæ•°æ®é¢„å¤„ç†

**é—®é¢˜ï¼š** åŸå§‹æ•°æ®éœ€è¦æ¸…æ´—å’Œæ ‡å‡†åŒ–

**è§£å†³æ–¹æ¡ˆï¼š**
```python
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# æ•°æ®æ¸…æ´—å‡½æ•°
def clean_text(text: str) -> str:
    """æ¸…æ´—æ–‡æœ¬ï¼šå»ç©ºæ ¼ã€è½¬å°å†™ã€å»ç‰¹æ®Šå­—ç¬¦"""
    import re
    text = text.strip().lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text

# æ„å»ºå¤„ç†é“¾
chain = (
    RunnableLambda(clean_text)  # é¢„å¤„ç†
    | ChatPromptTemplate.from_template("Analyze: {text}")
    | ChatOpenAI(model="gpt-4")
)

# ä½¿ç”¨
result = chain.invoke({"text": "  Hello, World!  "})
```

**å…³é”®ç‚¹ï¼š**
- åœ¨é“¾çš„å¼€å§‹æ’å…¥æ¸…æ´—é€»è¾‘
- ç¡®ä¿æ•°æ®æ ¼å¼ç¬¦åˆåç»­ç»„ä»¶çš„è¦æ±‚
- å¯ä»¥ç»„åˆå¤šä¸ªæ¸…æ´—æ­¥éª¤

---

### åœºæ™¯ 2ï¼šæ ¼å¼è½¬æ¢

**é—®é¢˜ï¼š** ä¸åŒç»„ä»¶ä¹‹é—´çš„æ•°æ®æ ¼å¼ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆï¼š**
```python
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# è¾“å…¥æ ¼å¼è½¬æ¢
def dict_to_text(data: dict) -> str:
    """å°†å­—å…¸è½¬æ¢ä¸ºæ–‡æœ¬"""
    return f"Name: {data['name']}, Age: {data['age']}"

# è¾“å‡ºæ ¼å¼è½¬æ¢
def text_to_dict(text: str) -> dict:
    """å°†æ–‡æœ¬è½¬æ¢ä¸ºå­—å…¸"""
    lines = text.split('\n')
    return {
        "summary": lines[0],
        "details": lines[1:] if len(lines) > 1 else []
    }

# æ„å»ºå¤„ç†é“¾
chain = (
    RunnableLambda(dict_to_text)  # è¾“å…¥è½¬æ¢
    | ChatPromptTemplate.from_template("Summarize: {text}")
    | ChatOpenAI(model="gpt-4")
    | RunnableLambda(text_to_dict)  # è¾“å‡ºè½¬æ¢
)

# ä½¿ç”¨
result = chain.invoke({"name": "Alice", "age": 30})
# {"summary": "...", "details": [...]}
```

**å…³é”®ç‚¹ï¼š**
- åœ¨é“¾çš„ä¸åŒä½ç½®æ’å…¥è½¬æ¢é€»è¾‘
- ç¡®ä¿æ•°æ®æ ¼å¼çš„å…¼å®¹æ€§
- å¯ä»¥åŒå‘è½¬æ¢ï¼ˆè¾“å…¥å’Œè¾“å‡ºï¼‰

---

## 1 ä¸ªé¿å‘æŒ‡å—

### é™·é˜± 1ï¼šå¿˜è®°æä¾› afunc å¯¼è‡´æ€§èƒ½å·®

**é—®é¢˜ï¼š**
```python
# âŒ é”™è¯¯ï¼šé«˜å¹¶å‘åœºæ™¯ä¸æä¾› afunc
def slow_operation(text: str) -> str:
    time.sleep(1)  # æ¨¡æ‹Ÿæ…¢æ“ä½œ
    return text.upper()

runnable = RunnableLambda(slow_operation)

# å¼‚æ­¥è°ƒç”¨æ€§èƒ½å¾ˆå·®ï¼ˆé€šè¿‡çº¿ç¨‹æ± å§”æ‰˜ï¼‰
results = await runnable.abatch(["a", "b", "c"])  # å¾ˆæ…¢
```

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# âœ… æ­£ç¡®ï¼šæä¾› afunc
import asyncio

async def async_slow_operation(text: str) -> str:
    await asyncio.sleep(1)  # å¼‚æ­¥ç­‰å¾…
    return text.upper()

runnable = RunnableLambda(slow_operation, afunc=async_slow_operation)

# å¼‚æ­¥è°ƒç”¨æ€§èƒ½æå‡ 10-20x
results = await runnable.abatch(["a", "b", "c"])  # å¿«å¾ˆå¤š
```

**è®°ä½ï¼š**
- é»˜è®¤çš„å¼‚æ­¥æ˜¯é€šè¿‡çº¿ç¨‹æ± å§”æ‰˜ï¼Œæ€§èƒ½è¾ƒå·®
- é«˜å¹¶å‘åœºæ™¯å¿…é¡»æä¾› afunc
- æ€§èƒ½æå‡å¯è¾¾ 10-20x

---

### é™·é˜± 2ï¼šè¿‡åº¦ä½¿ç”¨é™ä½å¯è¯»æ€§

**é—®é¢˜ï¼š**
```python
# âŒ é”™è¯¯ï¼šå¤æ‚é€»è¾‘ç”¨ lambda
chain = RunnableLambda(lambda x: {
    "key1": complex_logic_1(x),
    "key2": complex_logic_2(x),
    "key3": complex_logic_3(x),
    "key4": complex_logic_4(x)
})  # éš¾ä»¥ç†è§£å’Œç»´æŠ¤
```

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# âœ… æ­£ç¡®ï¼šç®€å•é€»è¾‘ç”¨ RunnableLambda
chain = RunnableLambda(lambda x: x.upper())

# âœ… æ­£ç¡®ï¼šå¤æ‚é€»è¾‘ç”¨è‡ªå®šä¹‰ç±»
class ComplexProcessor(Runnable):
    def invoke(self, input):
        return {
            "key1": self._process_1(input),
            "key2": self._process_2(input),
            "key3": self._process_3(input),
            "key4": self._process_4(input)
        }

    def _process_1(self, input):
        # æ¸…æ™°çš„æ–¹æ³•å®ç°
        pass
```

**è®°ä½ï¼š**
- ç®€å•é€»è¾‘ï¼ˆ1-2 è¡Œï¼‰ç”¨ RunnableLambda
- å¤æ‚é€»è¾‘ï¼ˆ3+ è¡Œï¼‰ç”¨è‡ªå®šä¹‰ Runnable ç±»
- å¯è¯»æ€§ä¼˜äºç®€æ´æ€§

---

### é™·é˜± 3ï¼šè¯¯ä»¥ä¸º stream ä¼šæµå¼è¾“å‡º

**é—®é¢˜ï¼š**
```python
# âŒ è¯¯è§£ï¼šä»¥ä¸ºä¼šæµå¼è¾“å‡º
runnable = RunnableLambda(lambda x: x.upper())

for chunk in runnable.stream("hello"):
    print(chunk)  # å®é™…ä¸Šä¸€æ¬¡æ€§è¾“å‡º "HELLO"
```

**çœŸç›¸ï¼š**
- RunnableLambda çš„ stream é»˜è®¤å§”æ‰˜ invoke
- ä¸ä¼šçœŸæ­£æµå¼è¾“å‡º
- åªæ˜¯è¿”å›ä¸€ä¸ªåŒ…å«å®Œæ•´ç»“æœçš„è¿­ä»£å™¨

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# âœ… å¦‚æœéœ€è¦çœŸæ­£çš„æµå¼è¾“å‡ºï¼Œä½¿ç”¨ RunnableGenerator
from langchain_core.runnables import RunnableGenerator

def stream_processor(input):
    for char in input:
        yield char.upper()

runnable = RunnableGenerator(stream_processor)

for chunk in runnable.stream("hello"):
    print(chunk)  # çœŸæ­£çš„æµå¼è¾“å‡ºï¼šH E L L O
```

**è®°ä½ï¼š**
- RunnableLambda ä¸æ”¯æŒçœŸæ­£çš„æµå¼è¾“å‡º
- éœ€è¦æµå¼è¾“å‡ºæ—¶ä½¿ç”¨ RunnableGenerator
- æˆ–è€…è‡ªå®šä¹‰ Runnable ç±»å®ç° stream æ–¹æ³•

---

## å¿«é€Ÿå‚è€ƒå¡ç‰‡

### åŸºç¡€è¯­æ³•

```python
from langchain_core.runnables import RunnableLambda

# 1. åŸºç¡€åŒ…è£…
runnable = RunnableLambda(func)

# 2. æä¾›å¼‚æ­¥å‡½æ•°
runnable = RunnableLambda(sync_func, afunc=async_func)

# 3. é“¾å¼ç»„åˆ
chain = runnable1 | runnable2 | runnable3

# 4. è°ƒç”¨æ–¹å¼
result = runnable.invoke(input)           # å•ä¸ª
results = runnable.batch(inputs)          # æ‰¹é‡
async_result = await runnable.ainvoke(input)  # å¼‚æ­¥

# 5. é”™è¯¯é‡è¯•
safe_runnable = runnable.with_retry(stop_after_attempt=3)
```

---

### å¸¸ç”¨æ¨¡å¼

```python
# æ¨¡å¼ 1ï¼šæ•°æ®æ¸…æ´—
chain = RunnableLambda(clean) | model

# æ¨¡å¼ 2ï¼šæ ¼å¼è½¬æ¢
chain = RunnableLambda(to_text) | model | RunnableLambda(to_dict)

# æ¨¡å¼ 3ï¼šå¤šæ­¥å¤„ç†
chain = (
    RunnableLambda(step1)
    | RunnableLambda(step2)
    | RunnableLambda(step3)
)

# æ¨¡å¼ 4ï¼šå¼‚æ­¥æ‰¹å¤„ç†
runnable = RunnableLambda(sync_func, afunc=async_func)
results = await runnable.abatch(inputs)
```

---

### å†³ç­–æ ‘

**ä½•æ—¶ä½¿ç”¨ RunnableLambdaï¼Ÿ**

```
éœ€è¦åœ¨ LCEL é“¾ä¸­ä½¿ç”¨è‡ªå®šä¹‰é€»è¾‘ï¼Ÿ
â”œâ”€ æ˜¯ â†’ é€»è¾‘ç®€å•ï¼ˆ1-2 è¡Œï¼‰ï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ âœ… ä½¿ç”¨ RunnableLambda
â”‚  â””â”€ å¦ â†’ é€»è¾‘å¤æ‚ï¼ˆ3+ è¡Œï¼‰ï¼Ÿ
â”‚     â”œâ”€ æ˜¯ â†’ âŒ ä½¿ç”¨è‡ªå®šä¹‰ Runnable ç±»
â”‚     â””â”€ å¦ â†’ âœ… ä½¿ç”¨ RunnableLambda
â””â”€ å¦ â†’ ç›´æ¥è°ƒç”¨å‡½æ•°
```

**ä½•æ—¶æä¾› afuncï¼Ÿ**

```
éœ€è¦å¼‚æ­¥è°ƒç”¨ï¼Ÿ
â”œâ”€ æ˜¯ â†’ é«˜å¹¶å‘åœºæ™¯ï¼ˆ10+ å¹¶å‘ï¼‰ï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ âœ… å¿…é¡»æä¾› afunc
â”‚  â””â”€ å¦ â†’ ä½å¹¶å‘åœºæ™¯ï¼Ÿ
â”‚     â”œâ”€ æ˜¯ â†’ âš ï¸ å¯é€‰æä¾› afunc
â”‚     â””â”€ å¦ â†’ âŒ ä¸éœ€è¦ afunc
â””â”€ å¦ â†’ âŒ ä¸éœ€è¦ afunc
```

---

## å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹ï¼šæ„å»ºæ–‡æœ¬å¤„ç†é“¾

```python
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import re

# æ­¥éª¤ 1ï¼šå®šä¹‰å¤„ç†å‡½æ•°
def clean_text(text: str) -> str:
    """æ¸…æ´—æ–‡æœ¬"""
    text = text.strip().lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text

def add_context(text: str) -> dict:
    """æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    return {
        "text": text,
        "length": len(text),
        "word_count": len(text.split())
    }

def format_output(text: str) -> str:
    """æ ¼å¼åŒ–è¾“å‡º"""
    return f"=== Result ===\n{text}\n============="

# æ­¥éª¤ 2ï¼šæ„å»ºå¤„ç†é“¾
chain = (
    RunnableLambda(clean_text)  # æ¸…æ´—
    | RunnableLambda(add_context)  # æ·»åŠ ä¸Šä¸‹æ–‡
    | ChatPromptTemplate.from_template(
        "Summarize this text (length: {length}, words: {word_count}):\n{text}"
    )
    | ChatOpenAI(model="gpt-4")
    | StrOutputParser()
    | RunnableLambda(format_output)  # æ ¼å¼åŒ–
)

# æ­¥éª¤ 3ï¼šä½¿ç”¨
result = chain.invoke("  Hello, World! This is a TEST.  ")
print(result)
# === Result ===
# This is a greeting message with a test statement.
# =============
```

**å…³é”®ç‚¹ï¼š**
1. æ¯ä¸ªå‡½æ•°èŒè´£å•ä¸€
2. é€šè¿‡ | æ“ä½œç¬¦æ¸…æ™°åœ°è¡¨è¾¾å¤„ç†æµç¨‹
3. å¯ä»¥è½»æ¾æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹æ­¥éª¤
4. ç±»å‹å®‰å…¨ï¼ˆé€šè¿‡ç±»å‹æ³¨è§£ï¼‰

---

## å­¦ä¹ æ£€æŸ¥æ¸…å•

å®Œæˆæœ¬æ–‡æ¡£åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] è§£é‡Š RunnableLambda çš„ä½œç”¨
- [ ] å°†å‡½æ•°è½¬æ¢ä¸º Runnable
- [ ] ä½¿ç”¨ | æ“ä½œç¬¦ç»„åˆé“¾
- [ ] ä½¿ç”¨ invokeã€batch æ–¹æ³•
- [ ] ç†è§£ä½•æ—¶éœ€è¦æä¾› afunc
- [ ] æ·»åŠ é”™è¯¯é‡è¯•æœºåˆ¶
- [ ] åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨ RunnableLambda
- [ ] é¿å… 3 ä¸ªå¸¸è§é™·é˜±

---

## ä¸‹ä¸€æ­¥å­¦ä¹ 

### å¦‚æœä½ æƒ³æ·±å…¥ç†è§£

- **é˜…è¯»**: `02_ç¬¬ä¸€æ€§åŸç†.md` - ç†è§£è®¾è®¡å“²å­¦
- **é˜…è¯»**: `03_æ ¸å¿ƒæ¦‚å¿µ_*.md` - æŒæ¡æŠ€æœ¯ç»†èŠ‚

### å¦‚æœä½ æƒ³å®æˆ˜åº”ç”¨

- **é˜…è¯»**: `07_å®æˆ˜ä»£ç _01_æ•°æ®å¤„ç†ä¸è½¬æ¢.md` - æ•°æ®å¤„ç†åœºæ™¯
- **é˜…è¯»**: `07_å®æˆ˜ä»£ç _02_RAGåº”ç”¨é›†æˆ.md` - RAG åº”ç”¨åœºæ™¯

### å¦‚æœä½ æƒ³é¿å‘

- **é˜…è¯»**: `06_åç›´è§‰ç‚¹.md` - äº†è§£å¸¸è§è¯¯åŒº
- **é˜…è¯»**: `09_åŒ–éª¨ç»µæŒ.md` - å†…åŒ–çŸ¥è¯†

---

## å®è·µå»ºè®®

### ç«‹å³å®è·µ

1. **å¤åˆ¶ä¸Šé¢çš„å®Œæ•´ç¤ºä¾‹**
   - åœ¨æœ¬åœ°è¿è¡Œ
   - ä¿®æ”¹å‡½æ•°é€»è¾‘
   - è§‚å¯Ÿç»“æœå˜åŒ–

2. **å°è¯•è‡ªå·±çš„åœºæ™¯**
   - æƒ³ä¸€ä¸ªå®é™…éœ€æ±‚
   - ç”¨ RunnableLambda å®ç°
   - ä¸ç›´æ¥è°ƒç”¨å‡½æ•°å¯¹æ¯”

3. **æµ‹è¯•æ€§èƒ½å·®å¼‚**
   - å¯¹æ¯”æœ‰æ—  afunc çš„æ€§èƒ½
   - éªŒè¯ 10-20x çš„æå‡

### å­¦ä¹ æŠ€å·§

1. **å…ˆç”¨èµ·æ¥ï¼Œå†æ·±å…¥**
   - ä¸è¦ä¸€å¼€å§‹å°±è¿½æ±‚å®Œç¾ç†è§£
   - å…ˆèƒ½ç”¨ï¼Œå†ä¼˜åŒ–

2. **å¯¹æ¯”å­¦ä¹ **
   - å¯¹æ¯” RunnableLambda å’Œç›´æ¥è°ƒç”¨
   - å¯¹æ¯”ç®€å•é€»è¾‘å’Œå¤æ‚é€»è¾‘çš„å¤„ç†æ–¹å¼

3. **è®°å½•ç¬”è®°**
   - è®°å½•è‡ªå·±è¸©è¿‡çš„å‘
   - è®°å½•æœ‰ç”¨çš„ä»£ç ç‰‡æ®µ

---

## å¼•ç”¨æ¥æº

- [LangChain å®˜æ–¹æ–‡æ¡£ - RunnableLambda](https://python.langchain.com/docs/expression_language/primitives/lambda) - å®˜æ–¹åŸºç¡€æ•™ç¨‹
- [LangChain API Reference v0.3](https://reference.langchain.com/v0.3/python/core/runnables/) - API æ–‡æ¡£
- [LCEL Tutorial (GeeksforGeeks 2026)](https://www.geeksforgeeks.org/langchain-expression-language-lcel/) - å®æˆ˜æ•™ç¨‹
- [Building Production-Ready AI Pipelines (2026)](https://medium.com/@techsachin/building-production-ready-ai-pipelines-with-langchain-a-comprehensive-guide-2026-edition) - ç”Ÿäº§çº§å®è·µ

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-20
**é€‚ç”¨äº**: LangChain v0.3+
**Python ç‰ˆæœ¬**: 3.13+

---

**æ­å–œï¼** ä½ å·²ç»æŒæ¡äº† RunnableLambda çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œå¯ä»¥å¼€å§‹å®æˆ˜äº†ï¼ğŸ‰
