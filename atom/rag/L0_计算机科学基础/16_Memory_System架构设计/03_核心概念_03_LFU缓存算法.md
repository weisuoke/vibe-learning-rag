# 核心概念：LFU缓存算法

> **理解基于访问频率的缓存淘汰策略**

---

## 概念定义

**LFU (Least Frequently Used) = 淘汰访问频率最低的数据，保留访问频率最高的数据**

### 核心思想

基于**频率局部性原理**：
- 访问频率高的数据（热点数据），未来被访问的概率高
- 访问频率低的数据（冷数据），未来被访问的概率低

---

## LRU vs LFU

### 核心区别

| 维度 | LRU | LFU |
|------|-----|-----|
| **淘汰依据** | 最久未使用的时间 | 访问频率最低 |
| **适用场景** | 时间局部性强 | 热点数据明显 |
| **实现复杂度** | 简单（双向链表） | 复杂（频率计数） |
| **时间复杂度** | O(1) | O(1) 或 O(log n) |

### 场景对比

```python
# 访问模式：A 访问 100 次，B 访问 1 次
access_pattern = ["A"] * 100 + ["B"] + ["C"]

# LRU 结果：
# - 最近访问：C, B, A
# - 如果容量=2，淘汰 A（最久未使用）
# - 问题：A 是热点数据，不应该被淘汰！

# LFU 结果：
# - 访问频率：A=100, B=1, C=1
# - 如果容量=2，淘汰 B 或 C（频率最低）
# - 正确：保留了热点数据 A
```

---

## 实现方式

### 方式1：简单实现（O(n) 淘汰）

```python
from collections import defaultdict

class LFUCache:
    """LFU 缓存（简单实现）"""
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}  # key → value
        self.freq = defaultdict(int)  # key → 访问频率

    def get(self, key: str) -> any:
        """获取数据"""
        if key not in self.cache:
            return None

        # 增加访问频率
        self.freq[key] += 1
        return self.cache[key]

    def put(self, key: str, value: any) -> None:
        """存入数据"""
        if self.capacity == 0:
            return

        if key in self.cache:
            # 更新已有数据
            self.cache[key] = value
            self.freq[key] += 1
        else:
            # 新增数据
            if len(self.cache) >= self.capacity:
                # 找到频率最低的键（O(n)）
                min_freq_key = min(self.freq, key=self.freq.get)
                del self.cache[min_freq_key]
                del self.freq[min_freq_key]

            self.cache[key] = value
            self.freq[key] = 1

# 测试
cache = LFUCache(capacity=2)

cache.put("A", 1)
cache.put("B", 2)

# A 访问 5 次
for _ in range(5):
    cache.get("A")

# B 访问 1 次
cache.get("B")

# 添加 C，应该淘汰 B（频率最低）
cache.put("C", 3)

print(cache.get("A"))  # 1（保留）
print(cache.get("B"))  # None（被淘汰）
print(cache.get("C"))  # 3（新增）
```

**问题**：
- 淘汰操作是 O(n)，需要遍历所有键找到最小频率
- 性能不够好

---

### 方式2：优化实现（O(1) 操作）

**数据结构设计**：
1. **freq_map**：频率 → 该频率的所有键（双向链表）
2. **key_map**：键 → (值, 频率, 节点)
3. **min_freq**：当前最小频率

```python
from collections import defaultdict

class Node:
    """双向链表节点"""
    def __init__(self, key: str = "", value: any = None):
        self.key = key
        self.value = value
        self.freq = 1
        self.prev: Node | None = None
        self.next: Node | None = None

class DoublyLinkedList:
    """双向链表（存储相同频率的键）"""
    def __init__(self):
        self.head = Node()
        self.tail = Node()
        self.head.next = self.tail
        self.tail.prev = self.head
        self.size = 0

    def add_to_head(self, node: Node):
        """添加到头部"""
        node.next = self.head.next
        node.prev = self.head
        self.head.next.prev = node
        self.head.next = node
        self.size += 1

    def remove_node(self, node: Node):
        """移除节点"""
        node.prev.next = node.next
        node.next.prev = node.prev
        self.size -= 1

    def remove_tail(self) -> Node:
        """移除尾部节点"""
        if self.size == 0:
            return None
        node = self.tail.prev
        self.remove_node(node)
        return node

    def is_empty(self) -> bool:
        return self.size == 0

class LFUCache:
    """LFU 缓存（O(1) 实现）"""
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.min_freq = 0
        self.key_map = {}  # key → Node
        self.freq_map = defaultdict(DoublyLinkedList)  # freq → DoublyLinkedList

    def _update_freq(self, node: Node):
        """更新节点频率"""
        # 从旧频率链表中移除
        old_freq = node.freq
        self.freq_map[old_freq].remove_node(node)

        # 如果旧频率链表为空且是最小频率，更新最小频率
        if self.freq_map[old_freq].is_empty() and old_freq == self.min_freq:
            self.min_freq += 1

        # 增加频率
        node.freq += 1

        # 添加到新频率链表
        self.freq_map[node.freq].add_to_head(node)

    def get(self, key: str) -> any:
        """O(1) 获取数据"""
        if key not in self.key_map:
            return None

        node = self.key_map[key]
        self._update_freq(node)
        return node.value

    def put(self, key: str, value: any) -> None:
        """O(1) 写入数据"""
        if self.capacity == 0:
            return

        if key in self.key_map:
            # 更新已有数据
            node = self.key_map[key]
            node.value = value
            self._update_freq(node)
        else:
            # 新增数据
            if len(self.key_map) >= self.capacity:
                # 淘汰最小频率的最久未使用的节点
                min_freq_list = self.freq_map[self.min_freq]
                removed = min_freq_list.remove_tail()
                del self.key_map[removed.key]

            # 创建新节点
            node = Node(key, value)
            self.key_map[key] = node
            self.freq_map[1].add_to_head(node)
            self.min_freq = 1

# 测试
cache = LFUCache(capacity=2)

cache.put("A", 1)
cache.put("B", 2)

# A 访问 5 次
for _ in range(5):
    cache.get("A")

# B 访问 1 次
cache.get("B")

# 添加 C，应该淘汰 B（频率最低）
cache.put("C", 3)

print(cache.get("A"))  # 1（保留，频率=6）
print(cache.get("B"))  # None（被淘汰，频率=2）
print(cache.get("C"))  # 3（新增，频率=1）
```

**时间复杂度**：
- `get`: O(1)
- `put`: O(1)

**空间复杂度**：
- O(capacity)

---

## AI Agent 应用

### 1. 热门问题缓存

```python
class HotQuestionCache:
    """热门问题缓存（LFU 策略）"""
    def __init__(self, capacity: int = 100):
        self.cache = LFUCache(capacity=capacity)

    def get_answer(self, question: str) -> str | None:
        """获取问题答案"""
        return self.cache.get(question)

    def cache_answer(self, question: str, answer: str):
        """缓存问题答案"""
        self.cache.put(question, answer)

    def get_hot_questions(self, top_n: int = 10) -> list:
        """获取最热门的问题"""
        # 按频率排序
        questions = sorted(
            self.cache.key_map.items(),
            key=lambda x: x[1].freq,
            reverse=True
        )
        return [q for q, _ in questions[:top_n]]

# 使用示例
hot_cache = HotQuestionCache(capacity=100)

# 模拟用户提问
questions = [
    "什么是 RAG？",
    "如何实现 LRU 缓存？",
    "什么是 RAG？",  # 重复
    "Python 如何异步编程？",
    "什么是 RAG？",  # 重复
]

for q in questions:
    answer = hot_cache.get_answer(q)
    if answer is None:
        # 调用 LLM 生成答案
        answer = f"答案：{q}"
        hot_cache.cache_answer(q, answer)

# 获取热门问题
hot = hot_cache.get_hot_questions(top_n=3)
print("热门问题:", hot)
# 输出: ['什么是 RAG？', '如何实现 LRU 缓存？', 'Python 如何异步编程？']
```

### 2. API 调用频率限制

```python
import time

class APIRateLimiter:
    """API 调用频率限制（LFU 策略）"""
    def __init__(self, max_calls: int = 100):
        self.cache = LFUCache(capacity=max_calls)
        self.call_count = {}

    def can_call(self, api_key: str) -> bool:
        """检查是否可以调用 API"""
        # 获取调用次数
        count = self.cache.get(api_key)
        if count is None:
            # 首次调用
            self.cache.put(api_key, 1)
            return True

        # 检查是否超过限制
        if count >= 100:  # 每小时 100 次
            return False

        # 增加调用次数
        self.cache.put(api_key, count + 1)
        return True

    def get_top_users(self, top_n: int = 10) -> list:
        """获取调用最频繁的用户"""
        users = sorted(
            self.cache.key_map.items(),
            key=lambda x: x[1].freq,
            reverse=True
        )
        return [(user, node.value) for user, node in users[:top_n]]

# 使用示例
limiter = APIRateLimiter(max_calls=1000)

# 模拟 API 调用
for _ in range(150):
    if limiter.can_call("user_123"):
        print("✅ API 调用成功")
    else:
        print("❌ API 调用被限制")

# 获取调用最频繁的用户
top_users = limiter.get_top_users(top_n=5)
print("Top 5 用户:", top_users)
```

### 3. 知识库热点文档

```python
class KnowledgeBaseCache:
    """知识库热点文档缓存（LFU 策略）"""
    def __init__(self, capacity: int = 50):
        self.cache = LFUCache(capacity=capacity)

    def get_document(self, doc_id: str) -> dict | None:
        """获取文档"""
        return self.cache.get(doc_id)

    def cache_document(self, doc_id: str, content: dict):
        """缓存文档"""
        self.cache.put(doc_id, content)

    def get_hot_documents(self) -> list:
        """获取热点文档"""
        docs = sorted(
            self.cache.key_map.items(),
            key=lambda x: x[1].freq,
            reverse=True
        )
        return [
            {
                "doc_id": doc_id,
                "access_count": node.freq,
                "content": node.value
            }
            for doc_id, node in docs
        ]

# 使用示例
kb_cache = KnowledgeBaseCache(capacity=50)

# 模拟文档访问
doc_ids = ["doc_1", "doc_2", "doc_1", "doc_3", "doc_1"]

for doc_id in doc_ids:
    doc = kb_cache.get_document(doc_id)
    if doc is None:
        # 从数据库加载
        doc = {"id": doc_id, "content": f"内容 {doc_id}"}
        kb_cache.cache_document(doc_id, doc)

# 获取热点文档
hot_docs = kb_cache.get_hot_documents()
print("热点文档:", hot_docs)
```

---

## LFU 的优缺点

### 优点

1. **识别热点数据**：高频访问的数据长期保留
2. **抗扫描攻击**：偶尔的大量访问不会污染缓存
3. **适合长期运行**：频率统计越久越准确

### 缺点

1. **新数据劣势**：
   - 新数据频率为 1，容易被淘汰
   - 即使是未来的热点数据，也需要时间积累频率

2. **历史数据优势**：
   - 历史热点数据频率高，即使不再访问也不会被淘汰
   - 需要定期重置频率

3. **实现复杂**：
   - 需要维护频率计数
   - O(1) 实现需要复杂的数据结构

---

## LFU 变种

### 1. LFU with Decay（频率衰减）

**思想**：定期衰减频率，避免历史数据长期占据缓存

```python
import time

class LFUWithDecay:
    """带频率衰减的 LFU 缓存"""
    def __init__(self, capacity: int, decay_interval: int = 3600):
        self.cache = {}
        self.freq = {}
        self.last_access = {}
        self.capacity = capacity
        self.decay_interval = decay_interval

    def _decay_freq(self, key: str):
        """衰减频率"""
        now = time.time()
        if key in self.last_access:
            elapsed = now - self.last_access[key]
            decay_factor = elapsed / self.decay_interval
            self.freq[key] = max(1, self.freq[key] - int(decay_factor))

    def get(self, key: str) -> any:
        if key not in self.cache:
            return None

        # 衰减频率
        self._decay_freq(key)

        # 增加频率
        self.freq[key] += 1
        self.last_access[key] = time.time()

        return self.cache[key]

    def put(self, key: str, value: any):
        if len(self.cache) >= self.capacity and key not in self.cache:
            # 淘汰频率最低的
            min_freq_key = min(self.freq, key=self.freq.get)
            del self.cache[min_freq_key]
            del self.freq[min_freq_key]
            del self.last_access[min_freq_key]

        self.cache[key] = value
        self.freq[key] = self.freq.get(key, 0) + 1
        self.last_access[key] = time.time()
```

### 2. W-TinyLFU（Window Tiny LFU）

**思想**：结合 LRU 和 LFU，新数据先进入 LRU 窗口，再进入 LFU 主缓存

```python
class WTinyLFU:
    """W-TinyLFU 缓存"""
    def __init__(self, capacity: int):
        self.window_size = capacity // 10  # 10% 窗口
        self.main_size = capacity - self.window_size

        self.window = LRUCache(self.window_size)  # LRU 窗口
        self.main = LFUCache(self.main_size)      # LFU 主缓存

    def get(self, key: str) -> any:
        # 先查窗口
        value = self.window.get(key)
        if value is not None:
            return value

        # 再查主缓存
        return self.main.get(key)

    def put(self, key: str, value: any):
        # 新数据先进入窗口
        if key not in self.window.cache and key not in self.main.key_map:
            self.window.put(key, value)

            # 窗口满了，提升到主缓存
            if len(self.window.cache) >= self.window_size:
                # 获取窗口中最久未使用的
                oldest_key = next(iter(self.window.cache))
                oldest_value = self.window.cache[oldest_key]

                # 移到主缓存
                self.main.put(oldest_key, oldest_value)
                del self.window.cache[oldest_key]
        else:
            # 更新已有数据
            if key in self.window.cache:
                self.window.put(key, value)
            else:
                self.main.put(key, value)
```

---

## Redis 中的 LFU

### Redis LFU 实现

Redis 4.0+ 支持 LFU 淘汰策略：

```bash
# 配置 Redis 使用 LFU
redis-cli CONFIG SET maxmemory-policy allkeys-lfu
```

**特点**：
1. **近似 LFU**：使用概率计数器，节省内存
2. **频率衰减**：定期衰减频率，避免历史数据长期占据
3. **高性能**：O(1) 操作

### Python 使用 Redis LFU

```python
import redis

class RedisLFUCache:
    """基于 Redis 的 LFU 缓存"""
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379)
        # 配置 LFU 策略
        self.redis.config_set('maxmemory-policy', 'allkeys-lfu')
        self.redis.config_set('maxmemory', '100mb')

    def get(self, key: str) -> str | None:
        return self.redis.get(key)

    def put(self, key: str, value: str, ttl: int = 3600):
        self.redis.setex(key, ttl, value)

    def get_freq(self, key: str) -> int:
        """获取访问频率"""
        info = self.redis.object('freq', key)
        return info if info else 0

# 使用示例
cache = RedisLFUCache()

cache.put("key1", "value1")
cache.put("key2", "value2")

# 访问 key1 多次
for _ in range(10):
    cache.get("key1")

# 查看频率
print(f"key1 频率: {cache.get_freq('key1')}")
print(f"key2 频率: {cache.get_freq('key2')}")
```

---

## 最佳实践

### 1. 选择 LRU 还是 LFU？

| 场景 | 推荐策略 | 原因 |
|------|----------|------|
| **Web 缓存** | LRU | 时间局部性强 |
| **热点数据** | LFU | 频率局部性强 |
| **混合场景** | W-TinyLFU | 结合两者优势 |
| **短期缓存** | LRU | LFU 需要时间积累频率 |
| **长期缓存** | LFU | 频率统计越久越准确 |

### 2. 频率衰减策略

```python
def should_decay(last_access_time: float, decay_interval: int = 3600) -> bool:
    """判断是否需要衰减频率"""
    elapsed = time.time() - last_access_time
    return elapsed > decay_interval
```

### 3. 监控频率分布

```python
def analyze_freq_distribution(cache: LFUCache) -> dict:
    """分析频率分布"""
    freq_dist = {}
    for node in cache.key_map.values():
        freq = node.freq
        freq_dist[freq] = freq_dist.get(freq, 0) + 1

    return {
        "distribution": freq_dist,
        "max_freq": max(freq_dist.keys()) if freq_dist else 0,
        "avg_freq": sum(k * v for k, v in freq_dist.items()) / sum(freq_dist.values())
    }
```

---

## 参考资源

### LeetCode 题目
- [460. LFU Cache](https://leetcode.com/problems/lfu-cache/) - 困难难度

### 2025-2026 最新研究
- [Redis LFU vs LRU](https://redis.io/blog/lfu-vs-lru-how-to-choose-the-right-cache-eviction-policy) - Redis 官方对比
- [W-TinyLFU Paper](https://arxiv.org/abs/1512.00727) - 学术论文

### 实现参考
- [Redis LFU Implementation](https://github.com/redis/redis/blob/unstable/src/evict.c) - Redis 源码
- [Caffeine Cache](https://github.com/ben-manes/caffeine) - Java 高性能缓存库
