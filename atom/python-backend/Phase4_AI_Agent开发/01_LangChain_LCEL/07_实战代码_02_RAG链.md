# 实战代码 02 - RAG 链

> 完整可运行的 RAG 检索链实现

---

## 场景1：基础 RAG 链

### 需求

构建一个基础的 RAG 链：问题 → 向量检索 → Prompt → LLM → 回答。

---

### 完整代码

```python
"""
场景1：基础 RAG 链
演示：Retriever → Prompt → LLM → Parser
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import Chroma

load_dotenv()

# ===== 1. 准备文档数据 =====
print("=== 准备文档数据 ===")

documents = [
    "LCEL 是 LangChain Expression Language 的缩写，是一种用于构建 AI 应用的表达式语言。",
    "Runnable 是 LCEL 的核心接口，所有组件都实现这个接口。",
    "管道操作符 | 用于连接多个 Runnable 组件，让数据从左到右流动。",
    "RunnablePassthrough 用于保留原始输入，常用于 RAG 场景。",
    "RunnableParallel 用于并行执行多个任务，通过字典语法触发。"
]

print(f"文档数量: {len(documents)}")

# ===== 2. 创建向量存储 =====
print("\n=== 创建向量存储 ===")

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(
    texts=documents,
    embedding=embeddings
)

print(f"向量存储创建完成")

# ===== 3. 创建检索器 =====
print("\n=== 创建检索器 ===")

retriever = vectorstore.as_retriever(
    search_kwargs={"k": 2}  # 返回最相关的2个文档
)

print(f"检索器: {retriever}")

# ===== 4. 定义格式化函数 =====
def format_docs(docs):
    """格式化检索到的文档"""
    return "\n\n".join(doc.page_content for doc in docs)

# ===== 5. 构建 RAG 链 =====
print("\n=== 构建 RAG 链 ===")

prompt = ChatPromptTemplate.from_template("""
基于以下上下文回答问题。如果上下文中没有相关信息，请说"我不知道"。

上下文：
{context}

问题：{question}

回答：
""")

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
parser = StrOutputParser()

# 完整的 RAG 链
rag_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | parser
)

print(f"RAG 链构建完成")

# ===== 6. 测试 RAG 链 =====
print("\n=== 测试 RAG 链 ===")

questions = [
    "什么是 LCEL？",
    "什么是 Runnable？",
    "什么是 FastAPI？"  # 不在文档中
]

for question in questions:
    print(f"\n问题: {question}")
    answer = rag_chain.invoke(question)
    print(f"回答: {answer}")
```

**运行输出示例**：
```
=== 准备文档数据 ===
文档数量: 5

=== 创建向量存储 ===
向量存储创建完成

=== 创建检索器 ===
检索器: VectorStoreRetriever(...)

=== 构建 RAG 链 ===
RAG 链构建完成

=== 测试 RAG 链 ===

问题: 什么是 LCEL？
回答: LCEL 是 LangChain Expression Language 的缩写，是一种用于构建 AI 应用的表达式语言。

问题: 什么是 Runnable？
回答: Runnable 是 LCEL 的核心接口，所有组件都实现这个接口。

问题: 什么是 FastAPI？
回答: 我不知道
```

---

### 代码解析

**1. RAG 链的核心结构**：
```python
{
    "context": retriever | format_docs,  # 检索并格式化
    "question": RunnablePassthrough()    # 保留原始问题
}
| prompt  # 构建 Prompt
| llm     # LLM 生成
| parser  # 解析输出
```

**2. 为什么需要 RunnablePassthrough**：
- 检索器只返回文档，不返回原始问题
- 需要同时传递检索结果和原始问题给 Prompt
- RunnablePassthrough 保留原始输入

---

## 场景2：带来源引用的 RAG 链

### 需求

在回答中引用来源文档，提高可信度。

---

### 完整代码

```python
"""
场景2：带来源引用的 RAG 链
演示：返回答案 + 来源文档
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_community.vectorstores import Chroma

load_dotenv()

# ===== 1. 准备带元数据的文档 =====
print("=== 准备文档数据 ===")

from langchain_core.documents import Document

documents = [
    Document(
        page_content="LCEL 是 LangChain Expression Language 的缩写。",
        metadata={"source": "官方文档", "page": 1}
    ),
    Document(
        page_content="Runnable 是 LCEL 的核心接口。",
        metadata={"source": "官方文档", "page": 2}
    ),
    Document(
        page_content="管道操作符 | 用于连接组件。",
        metadata={"source": "教程", "page": 5}
    ),
]

# ===== 2. 创建向量存储 =====
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=documents,
    embedding=embeddings
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# ===== 3. 定义格式化函数 =====
def format_docs_with_sources(docs):
    """格式化文档并保留来源信息"""
    formatted = []
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get("source", "未知")
        page = doc.metadata.get("page", "未知")
        formatted.append(
            f"[文档{i}] (来源: {source}, 页码: {page})\n{doc.page_content}"
        )
    return "\n\n".join(formatted)

# ===== 4. 构建 RAG 链（返回答案 + 来源） =====
print("\n=== 构建 RAG 链 ===")

prompt = ChatPromptTemplate.from_template("""
基于以下上下文回答问题，并在回答中引用文档编号。

上下文：
{context}

问题：{question}

回答格式：
答案内容 [文档1] [文档2]
""")

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
parser = StrOutputParser()

# 使用 RunnableParallel 同时返回答案和来源
rag_chain_with_sources = RunnableParallel(
    {
        "answer": (
            {
                "context": retriever | format_docs_with_sources,
                "question": RunnablePassthrough()
            }
            | prompt
            | llm
            | parser
        ),
        "sources": retriever  # 直接返回检索到的文档
    }
)

# ===== 5. 测试 =====
print("\n=== 测试 RAG 链 ===")

question = "什么是 LCEL？"
result = rag_chain_with_sources.invoke(question)

print(f"问题: {question}")
print(f"\n回答: {result['answer']}")
print(f"\n来源文档:")
for i, doc in enumerate(result['sources'], 1):
    print(f"  [{i}] {doc.metadata.get('source')} - 页码 {doc.metadata.get('page')}")
    print(f"      {doc.page_content[:50]}...")
```

**运行输出示例**：
```
=== 准备文档数据 ===

=== 构建 RAG 链 ===

=== 测试 RAG 链 ===
问题: 什么是 LCEL？

回答: LCEL 是 LangChain Expression Language 的缩写 [文档1]

来源文档:
  [1] 官方文档 - 页码 1
      LCEL 是 LangChain Expression Language 的缩写。
  [2] 官方文档 - 页码 2
      Runnable 是 LCEL 的核心接口。
```

---

## 场景3：多查询 RAG 链

### 需求

将用户问题改写成多个查询，提高检索召回率。

---

### 完整代码

```python
"""
场景3：多查询 RAG 链
演示：Query 改写 + 多次检索 + 去重
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import Chroma

load_dotenv()

# ===== 1. 准备文档 =====
documents = [
    "LCEL 是 LangChain 的表达式语言，用于构建 AI 应用。",
    "Runnable 接口是 LCEL 的核心，提供统一的调用方式。",
    "管道操作符 | 连接多个组件，实现链式调用。",
    "RunnablePassthrough 保留原始输入，常用于 RAG。",
    "RunnableParallel 并行执行多个任务，提升性能。",
]

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(texts=documents, embedding=embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# ===== 2. 创建查询改写链 =====
print("=== 创建查询改写链 ===")

query_rewrite_prompt = ChatPromptTemplate.from_template("""
将以下问题改写成3个不同的查询，用于向量检索。
每个查询用换行符分隔。

原始问题：{question}

改写后的查询：
""")

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

query_rewriter = query_rewrite_prompt | llm | StrOutputParser()

# ===== 3. 定义多查询检索函数 =====
def multi_query_retrieval(question: str):
    """多查询检索"""
    # 1. 改写查询
    rewritten_queries = query_rewriter.invoke({"question": question})
    queries = [q.strip() for q in rewritten_queries.split("\n") if q.strip()]

    print(f"\n改写后的查询:")
    for i, q in enumerate(queries, 1):
        print(f"  {i}. {q}")

    # 2. 对每个查询进行检索
    all_docs = []
    for query in queries:
        docs = retriever.invoke(query)
        all_docs.extend(docs)

    # 3. 去重（基于内容）
    unique_docs = []
    seen_contents = set()
    for doc in all_docs:
        if doc.page_content not in seen_contents:
            unique_docs.append(doc)
            seen_contents.add(doc.page_content)

    print(f"\n检索到 {len(all_docs)} 个文档，去重后 {len(unique_docs)} 个")

    return unique_docs

# ===== 4. 构建多查询 RAG 链 =====
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

prompt = ChatPromptTemplate.from_template("""
基于以下上下文回答问题：

上下文：
{context}

问题：{question}

回答：
""")

multi_query_rag_chain = (
    {
        "context": lambda x: format_docs(multi_query_retrieval(x)),
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)

# ===== 5. 测试 =====
print("\n=== 测试多查询 RAG 链 ===")

question = "LCEL 的核心概念是什么？"
print(f"原始问题: {question}")

answer = multi_query_rag_chain.invoke(question)
print(f"\n最终回答: {answer}")
```

**运行输出示例**：
```
=== 创建查询改写链 ===

=== 测试多查询 RAG 链 ===
原始问题: LCEL 的核心概念是什么？

改写后的查询:
  1. LCEL 的主要组成部分有哪些？
  2. LangChain 表达式语言的关键特性是什么？
  3. LCEL 中最重要的概念是什么？

检索到 6 个文档，去重后 4 个

最终回答: LCEL 的核心概念包括：1) Runnable 接口，提供统一的调用方式；2) 管道操作符 |，用于连接多个组件实现链式调用；3) RunnablePassthrough 和 RunnableParallel 等特殊组件，用于数据传递和并行执行。
```

---

## 总结

### 三个场景对比

| 场景 | 核心特性 | 适用场景 | 关键代码 |
|------|---------|---------|---------|
| **场景1** | 基础 RAG | 简单问答 | `retriever \| format_docs` |
| **场景2** | 带来源引用 | 需要可信度 | `RunnableParallel` 返回答案+来源 |
| **场景3** | 多查询检索 | 提高召回率 | Query 改写 + 多次检索 + 去重 |

---

### 学习检查清单

- [ ] 构建基础 RAG 链（Retriever → Prompt → LLM）
- [ ] 使用 RunnablePassthrough 保留原始问题
- [ ] 返回答案和来源文档
- [ ] 实现多查询检索提高召回率
- [ ] 理解 RAG 链的数据流

---

**版本**: v1.0
**最后更新**: 2026-02-12
