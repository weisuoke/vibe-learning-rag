# 实战代码01：HNSW基础使用

## 代码说明

本示例展示如何使用hnswlib构建HNSW索引，包括基础使用、参数调优和性能测试。

**环境要求**：
```bash
pip install hnswlib sentence-transformers numpy
```

---

## 完整代码

```python
"""
HNSW基础使用示例
演示hnswlib的核心功能和参数调优
"""

import hnswlib
import numpy as np
import time
from sentence_transformers import SentenceTransformer
from typing import List, Tuple

# ============================================
# 1. 基础使用：创建索引和查询
# ============================================

def basic_hnsw_example():
    """HNSW基础使用示例"""
    print("=" * 50)
    print("1. HNSW基础使用")
    print("=" * 50)

    # 初始化embedding模型
    model = SentenceTransformer('all-MiniLM-L6-v2')
    dimension = 384

    # 准备文档
    documents = [
        "RAG是检索增强生成技术",
        "HNSW是高效的向量索引算法",
        "向量数据库用于存储和检索embedding",
        "Transformer是现代LLM的基础架构",
        "Prompt Engineering是LLM应用的关键技能"
    ]

    # 生成embeddings
    print(f"\n生成{len(documents)}个文档的embeddings...")
    embeddings = model.encode(documents)
    print(f"Embedding维度: {embeddings.shape}")

    # 创建HNSW索引
    print("\n创建HNSW索引...")
    index = hnswlib.Index(space='cosine', dim=dimension)

    # 初始化索引
    index.init_index(
        max_elements=10000,      # 最大元素数
        ef_construction=200,     # 构建时的候选数
        M=16                     # 每个节点的连接数
    )

    # 添加向量
    ids = list(range(len(documents)))
    index.add_items(embeddings, ids)
    print(f"已添加{len(documents)}个向量到索引")

    # 查询
    query = "什么是RAG技术？"
    print(f"\n查询: {query}")
    query_embedding = model.encode(query)

    # 设置查询时的ef参数
    index.set_ef(50)

    # 执行查询
    labels, distances = index.knn_query(query_embedding, k=3)

    print("\nTop 3结果:")
    for i, (label, distance) in enumerate(zip(labels[0], distances[0])):
        print(f"{i+1}. 文档{label}: {documents[label]}")
        print(f"   相似度: {1 - distance:.4f}")


# ============================================
# 2. 参数调优对比
# ============================================

def parameter_tuning_comparison():
    """对比不同参数配置的性能"""
    print("\n" + "=" * 50)
    print("2. 参数调优对比")
    print("=" * 50)

    # 准备测试数据
    dimension = 128
    num_elements = 10000
    num_queries = 100

    print(f"\n生成测试数据: {num_elements}个向量, 维度{dimension}")
    data = np.random.random((num_elements, dimension)).astype('float32')
    queries = np.random.random((num_queries, dimension)).astype('float32')

    # 测试配置
    configs = [
        {"M": 8, "ef_construction": 100, "ef_search": 50, "name": "快速配置"},
        {"M": 16, "ef_construction": 200, "ef_search": 100, "name": "平衡配置"},
        {"M": 32, "ef_construction": 400, "ef_search": 200, "name": "高精度配置"}
    ]

    results = []

    for config in configs:
        print(f"\n测试配置: {config['name']}")
        print(f"  M={config['M']}, ef_construction={config['ef_construction']}, ef_search={config['ef_search']}")

        # 创建索引
        index = hnswlib.Index(space='cosine', dim=dimension)

        # 构建索引并计时
        build_start = time.time()
        index.init_index(
            max_elements=num_elements,
            ef_construction=config["ef_construction"],
            M=config["M"]
        )
        index.add_items(data, list(range(num_elements)))
        build_time = time.time() - build_start

        # 查询并计时
        index.set_ef(config["ef_search"])
        query_start = time.time()
        labels, distances = index.knn_query(queries, k=10)
        query_time = time.time() - query_start

        # 计算平均延迟
        avg_latency = (query_time / num_queries) * 1000  # 转换为毫秒

        # 估算召回率（使用暴力搜索作为ground truth）
        # 注意：这里简化处理，实际应该用FAISS的Flat索引
        recall = estimate_recall(index, queries, data, k=10)

        result = {
            "config": config["name"],
            "M": config["M"],
            "ef_search": config["ef_search"],
            "build_time": build_time,
            "avg_latency": avg_latency,
            "recall": recall
        }
        results.append(result)

        print(f"  构建时间: {build_time:.2f}秒")
        print(f"  平均查询延迟: {avg_latency:.2f}ms")
        print(f"  估算召回率: {recall:.2%}")

    # 打印对比表
    print("\n" + "=" * 80)
    print("性能对比总结")
    print("=" * 80)
    print(f"{'配置':<15} {'M':<5} {'ef_search':<12} {'构建时间(s)':<12} {'延迟(ms)':<12} {'召回率':<10}")
    print("-" * 80)
    for r in results:
        print(f"{r['config']:<15} {r['M']:<5} {r['ef_search']:<12} {r['build_time']:<12.2f} {r['avg_latency']:<12.2f} {r['recall']:<10.2%}")


def estimate_recall(index, queries, data, k=10):
    """估算召回率（简化版本）"""
    # 使用HNSW查询
    hnsw_labels, _ = index.knn_query(queries, k=k)

    # 使用暴力搜索作为ground truth
    # 注意：这里简化处理，实际应该用更高效的方法
    gt_labels = []
    for query in queries:
        # 计算与所有向量的距离
        distances = np.linalg.norm(data - query, axis=1)
        # 获取top-k
        top_k_indices = np.argsort(distances)[:k]
        gt_labels.append(set(top_k_indices))

    # 计算召回率
    total_recall = 0
    for hnsw_result, gt_result in zip(hnsw_labels, gt_labels):
        intersection = len(set(hnsw_result) & gt_result)
        total_recall += intersection / k

    return total_recall / len(queries)


# ============================================
# 3. 持久化与加载
# ============================================

def persistence_example():
    """索引持久化示例"""
    print("\n" + "=" * 50)
    print("3. 索引持久化与加载")
    print("=" * 50)

    dimension = 128
    num_elements = 1000

    # 创建并保存索引
    print("\n创建索引...")
    data = np.random.random((num_elements, dimension)).astype('float32')

    index = hnswlib.Index(space='cosine', dim=dimension)
    index.init_index(max_elements=num_elements, ef_construction=200, M=16)
    index.add_items(data, list(range(num_elements)))

    # 保存索引
    index_path = "/tmp/hnsw_index.bin"
    print(f"保存索引到: {index_path}")
    index.save_index(index_path)

    # 加载索引
    print(f"\n从文件加载索引...")
    loaded_index = hnswlib.Index(space='cosine', dim=dimension)
    loaded_index.load_index(index_path, max_elements=num_elements)

    # 验证加载的索引
    query = np.random.random((1, dimension)).astype('float32')
    loaded_index.set_ef(50)
    labels, distances = loaded_index.knn_query(query, k=5)

    print(f"加载成功！查询返回{len(labels[0])}个结果")
    print(f"Top 5结果ID: {labels[0]}")


# ============================================
# 4. 增量更新
# ============================================

def incremental_update_example():
    """增量更新示例"""
    print("\n" + "=" * 50)
    print("4. 增量更新")
    print("=" * 50)

    dimension = 128
    initial_size = 1000

    # 创建初始索引
    print(f"\n创建初始索引（{initial_size}个向量）...")
    data = np.random.random((initial_size, dimension)).astype('float32')

    index = hnswlib.Index(space='cosine', dim=dimension)
    index.init_index(
        max_elements=10000,  # 预留空间
        ef_construction=200,
        M=16
    )
    index.add_items(data, list(range(initial_size)))
    print(f"当前索引大小: {index.get_current_count()}")

    # 增量添加
    batch_size = 500
    print(f"\n增量添加{batch_size}个向量...")
    new_data = np.random.random((batch_size, dimension)).astype('float32')
    new_ids = list(range(initial_size, initial_size + batch_size))

    index.add_items(new_data, new_ids)
    print(f"更新后索引大小: {index.get_current_count()}")

    # 查询验证
    query = np.random.random((1, dimension)).astype('float32')
    index.set_ef(50)
    labels, distances = index.knn_query(query, k=5)

    print(f"\n查询结果ID: {labels[0]}")
    print(f"包含新添加的向量: {any(label >= initial_size for label in labels[0])}")


# ============================================
# 5. RAG应用场景
# ============================================

def rag_application_example():
    """RAG应用场景示例"""
    print("\n" + "=" * 50)
    print("5. RAG应用场景")
    print("=" * 50)

    # 模拟知识库
    knowledge_base = [
        "Python是一种高级编程语言，广泛用于数据科学和AI开发",
        "FastAPI是现代Python Web框架，支持异步和类型提示",
        "Docker容器化技术简化了应用部署和环境管理",
        "Kubernetes是容器编排平台，用于大规模容器管理",
        "RAG结合检索和生成，提升LLM的知识准确性",
        "向量数据库通过语义检索快速找到相关文档",
        "HNSW算法在大规模向量检索中表现优异",
        "Transformer架构是现代NLP模型的基础",
        "Prompt Engineering通过优化提示词提升LLM效果",
        "LangChain简化了LLM应用的开发流程"
    ]

    # 初始化
    model = SentenceTransformer('all-MiniLM-L6-v2')
    dimension = 384

    print(f"\n构建知识库索引（{len(knowledge_base)}个文档）...")
    embeddings = model.encode(knowledge_base)

    index = hnswlib.Index(space='cosine', dim=dimension)
    index.init_index(
        max_elements=len(knowledge_base),
        ef_construction=200,
        M=16
    )
    index.add_items(embeddings, list(range(len(knowledge_base))))

    # RAG查询流程
    queries = [
        "如何部署Python应用？",
        "什么是RAG技术？",
        "如何提升LLM效果？"
    ]

    for query in queries:
        print(f"\n查询: {query}")
        query_embedding = model.encode(query)

        # 检索Top-3相关文档
        index.set_ef(50)
        labels, distances = index.knn_query(query_embedding, k=3)

        print("检索到的相关文档:")
        for i, (label, distance) in enumerate(zip(labels[0], distances[0])):
            similarity = 1 - distance
            print(f"  {i+1}. [{similarity:.3f}] {knowledge_base[label]}")


# ============================================
# 主函数
# ============================================

if __name__ == "__main__":
    print("HNSW基础使用示例")
    print("=" * 50)

    # 1. 基础使用
    basic_hnsw_example()

    # 2. 参数调优对比
    parameter_tuning_comparison()

    # 3. 持久化
    persistence_example()

    # 4. 增量更新
    incremental_update_example()

    # 5. RAG应用
    rag_application_example()

    print("\n" + "=" * 50)
    print("所有示例执行完成！")
    print("=" * 50)
```

---

## 预期输出

```
==================================================
1. HNSW基础使用
==================================================

生成5个文档的embeddings...
Embedding维度: (5, 384)

创建HNSW索引...
已添加5个向量到索引

查询: 什么是RAG技术？

Top 3结果:
1. 文档0: RAG是检索增强生成技术
   相似度: 0.7234
2. 文档2: 向量数据库用于存储和检索embedding
   相似度: 0.5123
3. 文档1: HNSW是高效的向量索引算法
   相似度: 0.4567

==================================================
2. 参数调优对比
==================================================

生成测试数据: 10000个向量, 维度128

测试配置: 快速配置
  M=8, ef_construction=100, ef_search=50
  构建时间: 0.45秒
  平均查询延迟: 0.52ms
  估算召回率: 87.34%

测试配置: 平衡配置
  M=16, ef_construction=200, ef_search=100
  构建时间: 0.89秒
  平均查询延迟: 1.23ms
  估算召回率: 94.56%

测试配置: 高精度配置
  M=32, ef_construction=400, ef_search=200
  构建时间: 1.78秒
  平均查询延迟: 2.45ms
  估算召回率: 97.89%

================================================================================
性能对比总结
================================================================================
配置             M     ef_search    构建时间(s)   延迟(ms)     召回率
--------------------------------------------------------------------------------
快速配置         8     50           0.45         0.52         87.34%
平衡配置         16    100          0.89         1.23         94.56%
高精度配置       32    200          1.78         2.45         97.89%
```

---

## 关键要点

### 1. 参数选择建议

**M参数**（每个节点的连接数）：
- M=8: 快速构建，适合原型开发
- M=16: 平衡性能，推荐生产环境
- M=32: 高召回率，适合精度要求高的场景

**ef_construction**（构建时的候选数）：
- 通常设置为 M 的 10-20 倍
- 越大构建越慢，但索引质量越高

**ef_search**（查询时的候选数）：
- 动态调整，根据召回率要求
- 推荐范围：50-200

### 2. 性能权衡

```
延迟 ↔ 召回率
  - ef_search越大，召回率越高，但延迟增加
  - 生产环境需要找到平衡点

构建时间 ↔ 查询质量
  - ef_construction越大，索引质量越高，但构建越慢
  - 一次构建，多次查询，值得投入
```

### 3. RAG应用建议

- **小规模（<10K文档）**：M=16, ef_construction=200, ef_search=100
- **中等规模（10K-100K）**：M=16, ef_construction=200, ef_search=50-100
- **大规模（>100K）**：考虑分片或使用Milvus等分布式方案

---

## 引用来源

1. **hnswlib官方文档**：https://github.com/nmslib/hnswlib
2. **HNSW参数指南**：https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md
3. **Milvus HNSW教程**：https://milvus.io/blog/getting-started-with-hnswlib.md
4. **IBM RAG教程**：https://developer.ibm.com/tutorials/awb-enhancing-retrieval-hnsw-rag

---

**最后更新**：2026-02-15
**基于资料**：2025-2026最新HNSW实践
