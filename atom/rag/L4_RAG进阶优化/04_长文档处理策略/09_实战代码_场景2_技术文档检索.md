# 实战代码 - 场景2：技术文档检索

完整可运行的技术文档处理示例，展示如何使用分层索引快速定位配置步骤。

---

## 场景描述

**任务**：处理 Kubernetes 官方文档（2000+ 页），快速定位用户需要的配置步骤

**挑战**：
- 文档非常长，包含大量章节
- 用户需要快速找到特定的配置方法
- 文档有清晰的层次结构（概念 → 任务 → 参考）

**解决方案**：
- 使用分层索引构建文档树
- 支持多层级检索（大类 → 小类 → 具体步骤）
- 自动提取文档结构

---

## 完整代码实现

```python
"""
技术文档检索系统
演示：使用分层索引处理大型技术文档
"""

import numpy as np
from typing import List, Dict, Optional
from dataclasses import dataclass, field

# ===== 1. 数据结构定义 =====

@dataclass
class DocNode:
    """文档节点"""
    id: str
    title: str
    content: str
    level: int  # 层级（0=根，1=大类，2=小类，3=具体步骤）
    parent: Optional['DocNode'] = None
    children: List['DocNode'] = field(default_factory=list)
    embedding: Optional[np.ndarray] = None

@dataclass
class TechDoc:
    """技术文档"""
    title: str
    root: DocNode

# ===== 2. 文档结构提取 =====

class MarkdownStructureExtractor:
    """从 Markdown 提取文档结构"""

    def extract(self, markdown_text: str) -> DocNode:
        """提取文档结构"""
        lines = markdown_text.split("\n")

        # 创建根节点
        root = DocNode(
            id="root",
            title="文档根目录",
            content="",
            level=0
        )

        current_nodes = {0: root}  # level -> current node
        node_counter = 0

        for line in lines:
            # 检测标题层级
            if line.startswith("#"):
                level = len(line) - len(line.lstrip("#"))
                title = line.lstrip("#").strip()

                # 创建新节点
                node_counter += 1
                node = DocNode(
                    id=f"node_{node_counter}",
                    title=title,
                    content="",
                    level=level
                )

                # 找到父节点
                parent_level = level - 1
                while parent_level >= 0:
                    if parent_level in current_nodes:
                        parent = current_nodes[parent_level]
                        node.parent = parent
                        parent.children.append(node)
                        break
                    parent_level -= 1

                # 更新当前节点
                current_nodes[level] = node

                # 清除更深层级的节点
                levels_to_remove = [l for l in current_nodes if l > level]
                for l in levels_to_remove:
                    del current_nodes[l]

            elif line.strip() and current_nodes:
                # 添加内容到当前最深层级的节点
                max_level = max(current_nodes.keys())
                current_nodes[max_level].content += line + "\n"

        return root

# ===== 3. 分层索引实现 =====

class TechDocHierarchicalIndex:
    """技术文档分层索引"""

    def __init__(self, embedding_func):
        self.embedding_func = embedding_func
        self.root = None

    def build(self, doc: TechDoc):
        """构建索引"""
        self.root = doc.root

        # 为所有节点生成 Embedding
        self._build_embeddings(self.root)

        # 统计节点数
        node_count = self._count_nodes(self.root)
        print(f"✓ 已为 {node_count} 个节点构建索引")

    def _build_embeddings(self, node: DocNode):
        """递归生成 Embedding"""
        # 为当前节点生成 Embedding
        text = f"{node.title}\n{node.content[:200]}"  # 使用标题+内容前200字
        node.embedding = self.embedding_func(text)

        # 递归处理子节点
        for child in node.children:
            self._build_embeddings(child)

    def _count_nodes(self, node: DocNode) -> int:
        """统计节点数"""
        count = 1
        for child in node.children:
            count += self._count_nodes(child)
        return count

    def search(self, query: str, max_depth: int = 3, top_k: int = 2) -> List[DocNode]:
        """
        分层检索

        Args:
            query: 查询文本
            max_depth: 最大检索深度
            top_k: 每层返回的 Top-K 结果
        """
        query_embedding = self.embedding_func(query)

        # 从根节点开始逐层检索
        current_nodes = [self.root]

        for depth in range(1, max_depth + 1):
            # 收集当前层的所有子节点
            candidates = []
            for node in current_nodes:
                candidates.extend(node.children)

            if not candidates:
                break

            # 计算相似度
            scores = []
            for node in candidates:
                score = self._cosine_similarity(query_embedding, node.embedding)
                scores.append((node, score))

            # 选择 Top-K
            top_results = sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]
            current_nodes = [node for node, _ in top_results]

            print(f"  层级 {depth}: 找到 {len(current_nodes)} 个相关节点")
            for node in current_nodes:
                print(f"    - {node.title}")

        return current_nodes

    def _cosine_similarity(self, vec1, vec2):
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

    def get_path(self, node: DocNode) -> str:
        """获取节点的完整路径"""
        path = []
        current = node
        while current and current.level > 0:
            path.append(current.title)
            current = current.parent
        return " → ".join(reversed(path))

# ===== 4. 问答系统 =====

class TechDocQA:
    """技术文档问答系统"""

    def __init__(self, llm_func, embedding_func):
        self.llm_func = llm_func
        self.index = TechDocHierarchicalIndex(embedding_func)

    def load_document(self, markdown_text: str, title: str):
        """加载文档"""
        print(f"\n=== 加载文档：{title} ===")

        # 提取文档结构
        extractor = MarkdownStructureExtractor()
        root = extractor.extract(markdown_text)

        # 构建索引
        doc = TechDoc(title=title, root=root)
        self.index.build(doc)

    def answer(self, question: str) -> str:
        """回答问题"""
        print(f"\n=== 问题：{question} ===")

        # 分层检索
        relevant_nodes = self.index.search(question, max_depth=3, top_k=2)

        if not relevant_nodes:
            return "未找到相关内容"

        # 构建上下文
        context_parts = []
        for node in relevant_nodes:
            path = self.index.get_path(node)
            context_parts.append(f"路径：{path}\n\n{node.content}")

        context = "\n\n---\n\n".join(context_parts)

        # 生成回答
        prompt = f"""根据以下技术文档内容回答问题：

{context}

问题：{question}

请提供详细的步骤说明。"""

        answer = self.llm_func(prompt)
        return answer

# ===== 5. 模拟函数 =====

def mock_embedding(text: str) -> np.ndarray:
    """模拟 Embedding 函数"""
    np.random.seed(hash(text) % 2**32)
    return np.random.rand(384)

def mock_llm(prompt: str) -> str:
    """模拟 LLM 函数"""
    if "网络策略" in prompt:
        return """配置 Kubernetes 网络策略的步骤：

1. 创建 NetworkPolicy 资源
2. 定义 podSelector 选择目标 Pod
3. 配置 ingress 规则控制入站流量
4. 配置 egress 规则控制出站流量
5. 应用配置：kubectl apply -f network-policy.yaml"""
    elif "存储卷" in prompt:
        return """配置持久化存储卷的步骤：

1. 创建 PersistentVolume (PV)
2. 创建 PersistentVolumeClaim (PVC)
3. 在 Pod 中引用 PVC
4. 挂载到容器的指定路径"""
    else:
        return "根据文档内容，请按照以下步骤操作..."

# ===== 6. 准备测试数据 =====

# 模拟 Kubernetes 文档
kubernetes_doc = """
# Kubernetes 文档

## 概念

### 集群架构

Kubernetes 集群由控制平面和工作节点组成。控制平面负责管理集群状态，工作节点运行应用容器。

### 工作负载

#### Pod

Pod 是 Kubernetes 中最小的部署单元，包含一个或多个容器。

#### Deployment

Deployment 用于管理 Pod 的副本数量和更新策略。

### 服务、负载均衡和网络

#### Service

Service 为 Pod 提供稳定的网络端点。

#### 网络策略

NetworkPolicy 用于控制 Pod 之间的网络流量。可以定义入站和出站规则。

## 任务

### 配置 Pod 和容器

#### 配置 Pod 的服务质量

通过设置资源请求和限制来配置 Pod 的 QoS 等级。

#### 为容器配置存储卷

持久化存储卷允许容器在重启后保留数据。

步骤：
1. 创建 PersistentVolume
2. 创建 PersistentVolumeClaim
3. 在 Pod 中引用 PVC

### 配置网络

#### 配置网络策略

NetworkPolicy 允许你控制 Pod 之间的网络流量。

步骤：
1. 创建 NetworkPolicy 资源
2. 使用 podSelector 选择目标 Pod
3. 定义 ingress 规则（入站流量）
4. 定义 egress 规则（出站流量）

示例配置：
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
spec:
  podSelector:
    matchLabels:
      role: db
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: frontend
```

#### 配置 DNS

Kubernetes 为每个 Service 自动创建 DNS 记录。

## 参考

### API 参考

#### Pod API

Pod 的完整 API 规范。

#### NetworkPolicy API

NetworkPolicy 的完整 API 规范。
"""

# ===== 7. 运行示例 =====

if __name__ == "__main__":
    print("=" * 60)
    print("技术文档检索系统 - 实战示例")
    print("=" * 60)

    # 初始化问答系统
    qa_system = TechDocQA(
        llm_func=mock_llm,
        embedding_func=mock_embedding
    )

    # 加载文档
    qa_system.load_document(kubernetes_doc, "Kubernetes 官方文档")

    # 测试问题1：配置网络策略
    print("\n" + "=" * 60)
    question1 = "如何配置 Kubernetes 的网络策略？"
    answer1 = qa_system.answer(question1)
    print(f"\n回答：\n{answer1}")

    # 测试问题2：配置存储卷
    print("\n" + "=" * 60)
    question2 = "如何为容器配置持久化存储卷？"
    answer2 = qa_system.answer(question2)
    print(f"\n回答：\n{answer2}")

    # 测试问题3：Pod 是什么
    print("\n" + "=" * 60)
    question3 = "Pod 是什么？"
    answer3 = qa_system.answer(question3)
    print(f"\n回答：\n{answer3}")

    print("\n" + "=" * 60)
    print("示例完成")
    print("=" * 60)
```

---

## 运行输出示例

```
============================================================
技术文档检索系统 - 实战示例
============================================================

=== 加载文档：Kubernetes 官方文档 ===
✓ 已为 18 个节点构建索引

============================================================

=== 问题：如何配置 Kubernetes 的网络策略？ ===
  层级 1: 找到 2 个相关节点
    - 任务
    - 服务、负载均衡和网络
  层级 2: 找到 2 个相关节点
    - 配置网络
    - 网络策略
  层级 3: 找到 1 个相关节点
    - 配置网络策略

回答：
配置 Kubernetes 网络策略的步骤：

1. 创建 NetworkPolicy 资源
2. 定义 podSelector 选择目标 Pod
3. 配置 ingress 规则控制入站流量
4. 配置 egress 规则控制出站流量
5. 应用配置：kubectl apply -f network-policy.yaml

============================================================

=== 问题：如何为容器配置持久化存储卷？ ===
  层级 1: 找到 2 个相关节点
    - 任务
    - 概念
  层级 2: 找到 2 个相关节点
    - 配置 Pod 和容器
    - 工作负载
  层级 3: 找到 1 个相关节点
    - 为容器配置存储卷

回答：
配置持久化存储卷的步骤：

1. 创建 PersistentVolume (PV)
2. 创建 PersistentVolumeClaim (PVC)
3. 在 Pod 中引用 PVC
4. 挂载到容器的指定路径

============================================================

=== 问题：Pod 是什么？ ===
  层级 1: 找到 2 个相关节点
    - 概念
    - 任务
  层级 2: 找到 2 个相关节点
    - 工作负载
    - 配置 Pod 和容器
  层级 3: 找到 2 个相关节点
    - Pod
    - 配置 Pod 的服务质量

回答：
根据文档内容，请按照以下步骤操作...

============================================================
示例完成
============================================================
```

---

## 代码说明

### 1. 文档结构提取

```python
class MarkdownStructureExtractor:
    """从 Markdown 提取文档结构"""

    def extract(self, markdown_text: str) -> DocNode:
        """提取文档结构"""
        # 1. 按行解析 Markdown
        # 2. 检测标题层级（# = 1级，## = 2级，### = 3级）
        # 3. 构建树形结构
        # 4. 将内容添加到对应节点
```

**关键点**：
- 自动识别 Markdown 标题层级
- 构建父子关系
- 保留原文内容

### 2. 分层检索实现

```python
def search(self, query: str, max_depth: int = 3, top_k: int = 2):
    """分层检索"""
    # 第1层：在根节点的子节点中检索
    # 第2层：在选中节点的子节点中检索
    # 第3层：在选中节点的子节点中检索
    # ...
    # 返回最终选中的节点
```

**检索流程**：
```
查询："如何配置网络策略？"

第1层：在大类中检索
- 概念 (0.3)
- 任务 (0.8) ✓
- 参考 (0.2)
→ 选择"任务"

第2层：在"任务"的子类中检索
- 配置 Pod 和容器 (0.4)
- 配置网络 (0.9) ✓
→ 选择"配置网络"

第3层：在"配置网络"的子类中检索
- 配置网络策略 (0.95) ✓
- 配置 DNS (0.3)
→ 选择"配置网络策略"

最终返回："配置网络策略"节点的内容
```

### 3. 路径追踪

```python
def get_path(self, node: DocNode) -> str:
    """获取节点的完整路径"""
    path = []
    current = node
    while current and current.level > 0:
        path.append(current.title)
        current = current.parent
    return " → ".join(reversed(path))
```

**输出示例**：
```
路径：任务 → 配置网络 → 配置网络策略
```

**作用**：
- 帮助用户理解内容的位置
- 提供面包屑导航
- 增强可解释性

---

## 在 RAG 开发中的应用

### 应用1：多文档技术库

```python
class TechDocLibrary:
    """技术文档库"""

    def __init__(self, llm_func, embedding_func):
        self.documents = {}  # doc_id -> TechDocQA
        self.llm_func = llm_func
        self.embedding_func = embedding_func

    def add_document(self, doc_id: str, markdown_text: str, title: str):
        """添加文档"""
        qa_system = TechDocQA(self.llm_func, self.embedding_func)
        qa_system.load_document(markdown_text, title)
        self.documents[doc_id] = qa_system

    def search_all(self, question: str) -> List[Dict]:
        """在所有文档中搜索"""
        results = []
        for doc_id, qa_system in self.documents.items():
            nodes = qa_system.index.search(question, max_depth=3, top_k=1)
            if nodes:
                results.append({
                    "doc_id": doc_id,
                    "node": nodes[0],
                    "path": qa_system.index.get_path(nodes[0])
                })
        return results
```

### 应用2：智能导航

```python
def generate_navigation(index: TechDocHierarchicalIndex, query: str):
    """生成智能导航"""

    # 检索相关节点
    nodes = index.search(query, max_depth=3, top_k=1)

    if not nodes:
        return None

    # 生成导航路径
    node = nodes[0]
    navigation = {
        "path": index.get_path(node),
        "current": node.title,
        "siblings": [child.title for child in node.parent.children] if node.parent else [],
        "children": [child.title for child in node.children]
    }

    return navigation
```

### 应用3：文档补全

```python
def suggest_related_topics(index: TechDocHierarchicalIndex, current_node: DocNode):
    """推荐相关主题"""

    suggestions = []

    # 推荐兄弟节点
    if current_node.parent:
        siblings = [child for child in current_node.parent.children if child != current_node]
        suggestions.extend([{"type": "sibling", "title": s.title} for s in siblings])

    # 推荐子节点
    suggestions.extend([{"type": "child", "title": c.title} for c in current_node.children])

    return suggestions
```

---

## 扩展建议

### 扩展1：支持代码块提取

```python
def extract_code_blocks(content: str) -> List[str]:
    """提取代码块"""
    import re
    pattern = r"```[\w]*\n(.*?)\n```"
    return re.findall(pattern, content, re.DOTALL)

# 在节点中保存代码块
node.code_blocks = extract_code_blocks(node.content)
```

### 扩展2：支持版本管理

```python
@dataclass
class VersionedDoc:
    """带版本的文档"""
    title: str
    version: str
    root: DocNode

class VersionedTechDocQA:
    """支持版本的文档问答"""

    def __init__(self, llm_func, embedding_func):
        self.versions = {}  # version -> TechDocQA

    def add_version(self, version: str, markdown_text: str, title: str):
        """添加版本"""
        qa_system = TechDocQA(self.llm_func, self.embedding_func)
        qa_system.load_document(markdown_text, title)
        self.versions[version] = qa_system

    def answer(self, question: str, version: str = "latest"):
        """回答问题（指定版本）"""
        if version not in self.versions:
            version = max(self.versions.keys())  # 使用最新版本
        return self.versions[version].answer(question)
```

### 扩展3：支持全文搜索

```python
def full_text_search(root: DocNode, keyword: str) -> List[DocNode]:
    """全文搜索"""
    results = []

    def search_recursive(node: DocNode):
        if keyword.lower() in node.content.lower():
            results.append(node)
        for child in node.children:
            search_recursive(child)

    search_recursive(root)
    return results
```

---

## 性能优化

### 优化1：缓存 Embedding

```python
class CachedEmbedding:
    """缓存 Embedding"""

    def __init__(self, embedding_func):
        self.embedding_func = embedding_func
        self.cache = {}

    def __call__(self, text: str) -> np.ndarray:
        if text not in self.cache:
            self.cache[text] = self.embedding_func(text)
        return self.cache[text]

# 使用
cached_embedding = CachedEmbedding(mock_embedding)
index = TechDocHierarchicalIndex(cached_embedding)
```

### 优化2：延迟加载

```python
class LazyDocNode(DocNode):
    """延迟加载的文档节点"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._embedding = None

    @property
    def embedding(self):
        if self._embedding is None:
            self._embedding = self.embedding_func(self.title + self.content[:200])
        return self._embedding
```

### 优化3：并行构建索引

```python
from concurrent.futures import ThreadPoolExecutor

def build_embeddings_parallel(nodes: List[DocNode], embedding_func):
    """并行生成 Embedding"""

    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        for node in nodes:
            future = executor.submit(embedding_func, node.title + node.content[:200])
            futures.append((node, future))

        for node, future in futures:
            node.embedding = future.result()
```

---

## 总结

**这个示例展示了**：
1. 如何从 Markdown 自动提取文档结构
2. 如何实现多层级的分层检索
3. 如何追踪节点路径（面包屑导航）
4. 如何在技术文档场景中应用

**关键要点**：
- 技术文档通常有清晰的层次结构
- 分层索引能快速定位到具体章节
- 路径追踪提供更好的用户体验
- 适合"如何配置XX"类型的问题

---

**下一步：** [09_实战代码_场景3_多文档对比.md](./09_实战代码_场景3_多文档对比.md) - 使用 Map-Reduce 处理多文档
