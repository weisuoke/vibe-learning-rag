# 最小可用知识

掌握以下内容，就能开始使用管道操作符构建 AI 应用：

---

## 4.1 基础语法：用 `|` 连接 Runnable

**核心概念**：任何实现了 Runnable 接口的对象都可以用 `|` 连接

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 三个 Runnable 组件
prompt = ChatPromptTemplate.from_template("讲一个关于{topic}的笑话")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

# 用 | 连接
chain = prompt | model | parser

# 调用
result = chain.invoke({"topic": "程序员"})
print(result)
```

**输出示例**：
```
为什么程序员总是分不清万圣节和圣诞节？
因为 Oct 31 == Dec 25！
```

**记住**：
- `|` 左边的输出类型必须匹配右边的输入类型
- 数据从左到右流动
- 最终返回最右边组件的输出

---

## 4.2 调用方式：invoke、batch、stream

**核心概念**：管道支持4种调用方式

```python
chain = prompt | model | parser

# 1. 同步单次调用
result = chain.invoke({"topic": "AI"})

# 2. 批量调用（并行处理多个输入）
results = chain.batch([
    {"topic": "AI"},
    {"topic": "Python"},
    {"topic": "数据库"}
])

# 3. 流式调用（逐块返回）
for chunk in chain.stream({"topic": "AI"}):
    print(chunk, end="", flush=True)

# 4. 异步调用
import asyncio
result = await chain.ainvoke({"topic": "AI"})
```

**在 AI Agent 中的应用**：
- **invoke**: 单个用户请求
- **batch**: 批量评估、数据标注
- **stream**: 实时对话、打字机效果
- **ainvoke**: 高并发场景

---

## 4.3 数据传递：字典、RunnablePassthrough

**核心概念**：用字典和 RunnablePassthrough 控制数据流

```python
from langchain_core.runnables import RunnablePassthrough

# 场景1：传递单个值
chain = RunnablePassthrough() | model | parser
result = chain.invoke("你好")  # 直接传递字符串

# 场景2：传递多个值（用字典）
prompt = ChatPromptTemplate.from_template(
    "将{language}翻译成英文：{text}"
)

chain = (
    {
        "language": lambda x: x["language"],
        "text": lambda x: x["text"]
    }
    | prompt
    | model
    | parser
)

result = chain.invoke({
    "language": "中文",
    "text": "你好世界"
})
```

**简化写法**：
```python
# 使用 RunnablePassthrough 简化
chain = (
    {
        "language": RunnablePassthrough(),
        "text": RunnablePassthrough()
    }
    | prompt
    | model
    | parser
)
```

**记住**：
- 字典的 key 必须匹配 prompt 的变量名
- RunnablePassthrough() 表示"原样传递"
- lambda 函数可以做数据转换

---

## 4.4 RAG 基础管道：retriever | prompt | model

**核心概念**：RAG 的最小可用管道

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# 1. 创建向量存储和检索器
vector_store = Chroma(
    collection_name="docs",
    embedding_function=OpenAIEmbeddings()
)
retriever = vector_store.as_retriever()

# 2. 构建 RAG 管道
prompt = ChatPromptTemplate.from_template(
    """基于以下上下文回答问题：

上下文：{context}

问题：{question}

答案："""
)

rag_chain = (
    {
        "context": retriever,  # 自动检索相关文档
        "question": RunnablePassthrough()  # 传递原始问题
    }
    | prompt
    | model
    | parser
)

# 3. 使用
answer = rag_chain.invoke("什么是向量数据库？")
```

**数据流**：
```
用户问题 "什么是向量数据库？"
    ↓
retriever 检索相关文档 → context: [doc1, doc2, ...]
question 原样传递 → question: "什么是向量数据库？"
    ↓
prompt 构建完整提示词
    ↓
model 生成答案
    ↓
parser 提取文本
    ↓
最终答案
```

**在 AI Agent 中的应用**：
- 知识库问答
- 文档助手
- 客服机器人

---

## 4.5 错误处理：try-except 包装

**核心概念**：在调用时捕获错误

```python
try:
    result = chain.invoke({"topic": "AI"})
    print(result)
except Exception as e:
    print(f"错误：{e}")
    # 降级处理
    result = "抱歉，我现在无法回答这个问题。"
```

**生产级错误处理**：
```python
from langchain_core.runnables import RunnableLambda

def safe_invoke(chain, input_data, default="抱歉，出错了"):
    """安全调用链，失败时返回默认值"""
    try:
        return chain.invoke(input_data)
    except Exception as e:
        print(f"链执行失败：{e}")
        return default

# 使用
result = safe_invoke(chain, {"topic": "AI"})
```

**常见错误**：
- **类型不匹配**：`prompt | model` 输出 AIMessage，但下一个组件期望 str
- **API 错误**：OpenAI API 超时、限流
- **配置错误**：缺少 API key

---

## 这些知识足以

掌握以上5个要点，你就能：

✅ **构建基础链**：prompt | model | parser
✅ **构建 RAG 应用**：retriever | prompt | model | parser
✅ **选择调用方式**：invoke、batch、stream、ainvoke
✅ **控制数据流**：字典、RunnablePassthrough、lambda
✅ **处理错误**：try-except 包装

---

## 快速参考卡

| 场景 | 代码模板 |
|------|----------|
| **基础链** | `prompt \| model \| parser` |
| **RAG链** | `{"context": retriever, "question": pass} \| prompt \| model \| parser` |
| **单次调用** | `chain.invoke(input)` |
| **批量调用** | `chain.batch([input1, input2])` |
| **流式调用** | `for chunk in chain.stream(input): ...` |
| **异步调用** | `await chain.ainvoke(input)` |
| **传递原值** | `RunnablePassthrough()` |
| **数据转换** | `lambda x: transform(x)` |

---

## 下一步学习

掌握最小可用知识后，建议学习：

1. **核心概念**：深入理解 `__or__` 实现机制
2. **高级特性**：RunnableParallel、RunnableBranch
3. **生产实践**：监控、日志、成本优化

---

## 实战练习

### 练习1：构建翻译链

**需求**：输入中文，输出英文

```python
# 提示：使用 ChatPromptTemplate + ChatOpenAI + StrOutputParser
```

<details>
<summary>参考答案</summary>

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("将以下中文翻译成英文：{text}")
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

translation_chain = prompt | model | parser

result = translation_chain.invoke({"text": "你好世界"})
print(result)  # Hello World
```

</details>

### 练习2：构建摘要链

**需求**：输入长文本，输出摘要

```python
# 提示：prompt 中要求"用3句话总结"
```

<details>
<summary>参考答案</summary>

```python
prompt = ChatPromptTemplate.from_template(
    "用3句话总结以下内容：\n\n{content}"
)
model = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

summary_chain = prompt | model | parser

long_text = """
LangChain 是一个用于构建 AI 应用的框架...
（长文本）
"""

summary = summary_chain.invoke({"content": long_text})
print(summary)
```

</details>

### 练习3：构建简单 RAG

**需求**：基于文档回答问题

```python
# 提示：需要先创建向量存储，然后构建 retriever | prompt | model | parser
```

<details>
<summary>参考答案</summary>

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.runnables import RunnablePassthrough

# 1. 准备文档
docs = [
    "LangChain 是一个 AI 应用开发框架",
    "LCEL 是 LangChain 的表达式语言",
    "管道操作符 | 用于组合 Runnable"
]

# 2. 创建向量存储
vector_store = Chroma.from_texts(
    docs,
    embedding=OpenAIEmbeddings()
)
retriever = vector_store.as_retriever()

# 3. 构建 RAG 链
prompt = ChatPromptTemplate.from_template(
    "基于上下文回答：{context}\n\n问题：{question}"
)

rag_chain = (
    {
        "context": retriever,
        "question": RunnablePassthrough()
    }
    | prompt
    | model
    | parser
)

# 4. 使用
answer = rag_chain.invoke("什么是 LCEL？")
print(answer)
```

</details>

---

## 学习检查清单

完成本节后，检查是否掌握：

- [ ] 能写出 `prompt | model | parser` 基础链
- [ ] 理解 `|` 左右两边的类型匹配规则
- [ ] 能使用 invoke、batch、stream 三种调用方式
- [ ] 能用字典和 RunnablePassthrough 控制数据流
- [ ] 能构建简单的 RAG 管道
- [ ] 知道如何用 try-except 处理错误

---

[Source: LangChain Official Docs - https://python.langchain.com/docs/concepts/]
[Source: Pinecone LCEL Tutorial - https://www.pinecone.io/learn/series/langchain/langchain-expression-language]
