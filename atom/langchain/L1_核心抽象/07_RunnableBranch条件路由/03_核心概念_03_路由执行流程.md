# 核心概念3：路由执行流程

深入理解 RunnableBranch 的执行机制和生命周期。

---

## 3.1 顺序评估机制

### 执行流程

```python
# RunnableBranch 的执行流程
def invoke(self, input: Input, config: RunnableConfig = None) -> Output:
    """
    执行流程：
    1. 遍历所有条件-分支对
    2. 评估每个条件
    3. 第一个返回 True 的分支执行
    4. 返回分支的结果
    5. 如果所有条件都是 False，执行默认分支
    """
    for condition, branch in self.branches:
        # 评估条件
        if condition(input):
            # 第一个匹配，执行分支
            return branch.invoke(input, config)

    # 所有条件都不匹配，执行默认分支
    return self.default.invoke(input, config)
```

### 可视化流程

```
输入 → RunnableBranch
         ↓
    评估 condition1
         ↓
    True? ──Yes→ 执行 branch1 → 返回结果
         ↓
        No
         ↓
    评估 condition2
         ↓
    True? ──Yes→ 执行 branch2 → 返回结果
         ↓
        No
         ↓
    评估 condition3
         ↓
    True? ──Yes→ 执行 branch3 → 返回结果
         ↓
        No
         ↓
    执行 default_branch → 返回结果
```

### 关键特性

1. **顺序性**：条件按定义顺序评估
2. **短路性**：第一个匹配就停止
3. **确定性**：相同输入总是相同结果
4. **完整性**：总有一个分支会执行（默认分支保证）

---

## 3.2 第一匹配原则

### 原理

**第一匹配原则**：只执行第一个条件为 True 的分支，即使后续条件也为 True。

### 示例

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 创建 Branch
branch = RunnableBranch(
    (lambda x: x > 50, RunnableLambda(lambda x: f"Branch 1: {x}")),
    (lambda x: x > 100, RunnableLambda(lambda x: f"Branch 2: {x}")),
    (lambda x: x > 0, RunnableLambda(lambda x: f"Branch 3: {x}")),
    RunnableLambda(lambda x: f"Default: {x}")
)

# 测试
print(branch.invoke(150))
# 输出：Branch 1: 150
# 注意：即使 150 > 100 和 150 > 0 也为 True，但只执行 Branch 1
```

### 为什么是第一匹配？

**设计理由**：
1. **简单性**：行为可预测，易于理解
2. **效率**：避免不必要的条件评估
3. **优先级**：条件顺序定义了优先级
4. **一致性**：与 if-elif-else 语义一致

### 与其他模式的对比

```python
# 1. if-elif-else（第一匹配）
if x > 50:
    result = "Branch 1"
elif x > 100:  # 即使 x=150，也不会执行
    result = "Branch 2"
else:
    result = "Default"

# 2. 多个独立 if（全部评估）
if x > 50:
    result1 = "Branch 1"
if x > 100:  # x=150 时也会执行
    result2 = "Branch 2"
if x > 0:  # x=150 时也会执行
    result3 = "Branch 3"

# 3. RunnableBranch（第一匹配）
branch = RunnableBranch(
    (lambda x: x > 50, handler1),
    (lambda x: x > 100, handler2),  # 不会执行
    default_handler
)
```

---

## 3.3 默认分支触发

### 触发条件

默认分支在以下情况触发：
- 所有条件都返回 False
- 所有条件都抛出异常（取决于错误处理策略）

### 示例

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 创建 Branch
branch = RunnableBranch(
    (lambda x: x > 100, RunnableLambda(lambda x: "Large")),
    (lambda x: x > 50, RunnableLambda(lambda x: "Medium")),
    RunnableLambda(lambda x: "Small or negative")  # 默认分支
)

# 测试
print(branch.invoke(150))  # 输出：Large
print(branch.invoke(75))   # 输出：Medium
print(branch.invoke(25))   # 输出：Small or negative
print(branch.invoke(-10))  # 输出：Small or negative
```

### 默认分支的重要性

**为什么必须提供默认分支？**

1. **完整性**：保证所有输入都有处理方式
2. **健壮性**：避免未处理的情况导致错误
3. **可预测性**：明确兜底行为

```python
# ❌ 没有默认分支会报错
try:
    branch = RunnableBranch(
        (lambda x: x > 100, handler1),
        (lambda x: x > 50, handler2)
    )
except TypeError as e:
    print(f"Error: {e}")
    # TypeError: RunnableBranch requires a default branch
```

---

## 3.4 同步执行流程（invoke）

### 方法签名

```python
def invoke(
    self,
    input: Input,
    config: Optional[RunnableConfig] = None
) -> Output:
    """
    同步执行 RunnableBranch

    Args:
        input: 输入数据
        config: 运行时配置（可选）

    Returns:
        执行分支的输出
    """
```

### 执行步骤

```python
# 伪代码
def invoke(self, input, config):
    # 1. 准备配置
    config = config or {}

    # 2. 遍历条件-分支对
    for condition, branch in self.branches:
        # 3. 评估条件
        try:
            if isinstance(condition, Runnable):
                # 条件是 Runnable
                result = condition.invoke(input, config)
            else:
                # 条件是函数
                result = condition(input)

            # 4. 检查结果
            if result:
                # 5. 执行分支
                return branch.invoke(input, config)

        except Exception as e:
            # 6. 错误处理（可选）
            logger.error(f"Condition evaluation failed: {e}")
            continue

    # 7. 执行默认分支
    return self.default.invoke(input, config)
```

### 完整示例

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda
from langchain_core.runnables.config import RunnableConfig

# 创建 Branch
branch = RunnableBranch(
    (lambda x: x["type"] == "A", RunnableLambda(lambda x: f"Handler A: {x['data']}")),
    (lambda x: x["type"] == "B", RunnableLambda(lambda x: f"Handler B: {x['data']}")),
    RunnableLambda(lambda x: f"Default: {x['data']}")
)

# 同步执行
input_data = {"type": "A", "data": "test"}
config = RunnableConfig(tags=["production"])

result = branch.invoke(input_data, config)
print(result)  # 输出：Handler A: test
```

### 配置传递

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda
from langchain_core.callbacks import StdOutCallbackHandler

# 创建带回调的配置
config = RunnableConfig(
    callbacks=[StdOutCallbackHandler()],
    tags=["production"],
    metadata={"user_id": "123"}
)

# 配置会自动传递到条件和分支
branch = RunnableBranch(
    (condition, handler),
    default_handler
)

# 执行时传递配置
result = branch.invoke(input_data, config)
# 条件和分支都会收到相同的配置
```

---

## 3.5 异步执行流程（ainvoke）

### 方法签名

```python
async def ainvoke(
    self,
    input: Input,
    config: Optional[RunnableConfig] = None
) -> Output:
    """
    异步执行 RunnableBranch

    Args:
        input: 输入数据
        config: 运行时配置（可选）

    Returns:
        执行分支的输出
    """
```

### 执行步骤

```python
# 伪代码
async def ainvoke(self, input, config):
    # 1. 准备配置
    config = config or {}

    # 2. 遍历条件-分支对
    for condition, branch in self.branches:
        # 3. 异步评估条件
        try:
            if isinstance(condition, Runnable):
                # 条件是 Runnable，异步调用
                result = await condition.ainvoke(input, config)
            else:
                # 条件是函数，同步调用
                result = condition(input)

            # 4. 检查结果
            if result:
                # 5. 异步执行分支
                return await branch.ainvoke(input, config)

        except Exception as e:
            logger.error(f"Condition evaluation failed: {e}")
            continue

    # 6. 异步执行默认分支
    return await self.default.ainvoke(input, config)
```

### 完整示例

```python
import asyncio
from langchain_core.runnables import RunnableBranch, RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 创建异步 Branch
async_branch = RunnableBranch(
    (lambda x: "code" in x.lower(),
     ChatPromptTemplate.from_template("Generate code: {text}") | ChatOpenAI()),
    (lambda x: "math" in x.lower(),
     ChatPromptTemplate.from_template("Solve math: {text}") | ChatOpenAI()),
    ChatPromptTemplate.from_template("Answer: {text}") | ChatOpenAI()
)

# 异步执行
async def main():
    result = await async_branch.ainvoke({"text": "Write a Python function"})
    print(result.content)

asyncio.run(main())
```

### 异步的优势

1. **非阻塞**：不会阻塞事件循环
2. **并发**：可以与其他异步操作并发执行
3. **性能**：适合 I/O 密集型任务（LLM 调用、API 请求）

```python
# 并发执行多个 Branch
async def process_multiple():
    tasks = [
        async_branch.ainvoke({"text": "code question"}),
        async_branch.ainvoke({"text": "math question"}),
        async_branch.ainvoke({"text": "general question"})
    ]
    results = await asyncio.gather(*tasks)
    return results
```

---

## 3.6 批处理执行（batch）

### 方法签名

```python
def batch(
    self,
    inputs: List[Input],
    config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
    *,
    return_exceptions: bool = False,
    **kwargs
) -> List[Output]:
    """
    批量执行 RunnableBranch

    Args:
        inputs: 输入列表
        config: 配置（单个或列表）
        return_exceptions: 是否返回异常而非抛出

    Returns:
        输出列表
    """
```

### 执行机制

```python
# 伪代码
def batch(self, inputs, config=None):
    results = []
    for input_item in inputs:
        try:
            # 每个输入独立执行
            result = self.invoke(input_item, config)
            results.append(result)
        except Exception as e:
            if return_exceptions:
                results.append(e)
            else:
                raise
    return results
```

### 完整示例

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 创建 Branch
branch = RunnableBranch(
    (lambda x: x > 100, RunnableLambda(lambda x: f"Large: {x}")),
    (lambda x: x > 50, RunnableLambda(lambda x: f"Medium: {x}")),
    RunnableLambda(lambda x: f"Small: {x}")
)

# 批量执行
inputs = [150, 75, 25, -10]
results = branch.batch(inputs)

for inp, res in zip(inputs, results):
    print(f"{inp} → {res}")

# 输出：
# 150 → Large: 150
# 75 → Medium: 75
# 25 → Small: 25
# -10 → Small: -10
```

### 异步批处理

```python
# 异步批处理
async def async_batch_example():
    inputs = [
        {"text": "code question"},
        {"text": "math question"},
        {"text": "general question"}
    ]

    results = await async_branch.abatch(inputs)
    return results
```

### 批处理优化

```python
# 使用 max_concurrency 控制并发
results = await async_branch.abatch(
    inputs,
    config={"max_concurrency": 5}  # 最多5个并发
)
```

---

## 3.7 流式执行（stream）

### 方法签名

```python
def stream(
    self,
    input: Input,
    config: Optional[RunnableConfig] = None
) -> Iterator[Output]:
    """
    流式执行 RunnableBranch

    Args:
        input: 输入数据
        config: 运行时配置

    Yields:
        分支输出的流式块
    """
```

### 执行机制

```python
# 伪代码
def stream(self, input, config):
    # 1. 找到匹配的分支
    for condition, branch in self.branches:
        if condition(input):
            # 2. 流式执行分支
            for chunk in branch.stream(input, config):
                yield chunk
            return

    # 3. 流式执行默认分支
    for chunk in self.default.stream(input, config):
        yield chunk
```

### 完整示例

```python
from langchain_core.runnables import RunnableBranch
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 创建流式 Branch
stream_branch = RunnableBranch(
    (lambda x: "code" in x["text"].lower(),
     ChatPromptTemplate.from_template("Generate code: {text}") | ChatOpenAI()),
    (lambda x: "math" in x["text"].lower(),
     ChatPromptTemplate.from_template("Solve math: {text}") | ChatOpenAI()),
    ChatPromptTemplate.from_template("Answer: {text}") | ChatOpenAI()
)

# 流式执行
input_data = {"text": "Write a Python function to sort a list"}

for chunk in stream_branch.stream(input_data):
    print(chunk.content, end="", flush=True)
```

### 异步流式执行

```python
# 异步流式执行
async def async_stream_example():
    async for chunk in stream_branch.astream(input_data):
        print(chunk.content, end="", flush=True)

asyncio.run(async_stream_example())
```

### 流式执行的应用场景

1. **实时反馈**：用户可以立即看到输出
2. **长文本生成**：逐步显示生成的内容
3. **降低延迟感**：提升用户体验

---

## 3.8 错误处理与传播

### 条件评估错误

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda

# 条件可能抛出异常
def risky_condition(x):
    if "error" in x:
        raise ValueError("Invalid input")
    return "urgent" in x

branch = RunnableBranch(
    (risky_condition, urgent_handler),
    default_handler
)

# 执行
try:
    result = branch.invoke({"text": "error message"})
except ValueError as e:
    print(f"Condition error: {e}")
```

### 分支执行错误

```python
# 分支可能抛出异常
def failing_handler(x):
    raise RuntimeError("Handler failed")

branch = RunnableBranch(
    (lambda x: True, RunnableLambda(failing_handler)),
    default_handler
)

# 执行
try:
    result = branch.invoke({"text": "test"})
except RuntimeError as e:
    print(f"Branch error: {e}")
```

### 错误处理策略

#### 策略1：捕获并继续

```python
def safe_branch_invoke(branch, input):
    """安全执行 Branch，捕获条件错误"""
    for condition, handler in branch.branches:
        try:
            if condition(input):
                return handler.invoke(input)
        except Exception as e:
            logger.warning(f"Condition failed: {e}, trying next")
            continue

    # 执行默认分支
    return branch.default.invoke(input)
```

#### 策略2：记录并抛出

```python
def logged_branch_invoke(branch, input):
    """记录错误并抛出"""
    try:
        return branch.invoke(input)
    except Exception as e:
        logger.error(f"Branch execution failed", exc_info=True)
        raise
```

#### 策略3：降级处理

```python
def fallback_branch_invoke(branch, input):
    """失败时使用降级处理"""
    try:
        return branch.invoke(input)
    except Exception as e:
        logger.error(f"Branch failed: {e}, using fallback")
        return fallback_response(input)
```

### 错误传播

```python
# 错误会沿着 LCEL 链传播
chain = (
    preprocessor
    | RunnableBranch(...)  # 如果这里出错
    | postprocessor        # 不会执行
)

try:
    result = chain.invoke(input)
except Exception as e:
    # 捕获整个链的错误
    print(f"Chain error: {e}")
```

---

## 3.9 配置传递机制

### RunnableConfig 结构

```python
from langchain_core.runnables.config import RunnableConfig
from langchain_core.callbacks import StdOutCallbackHandler

config = RunnableConfig(
    # 回调处理器
    callbacks=[StdOutCallbackHandler()],

    # 标签（用于追踪）
    tags=["production", "user-123"],

    # 元数据
    metadata={"user_id": "123", "session_id": "abc"},

    # 运行时名称
    run_name="my-branch",

    # 最大并发数
    max_concurrency=5,

    # 递归限制
    recursion_limit=25
)
```

### 配置传递流程

```python
# 配置会自动传递到所有子 Runnable
branch = RunnableBranch(
    (condition1, handler1),  # handler1 会收到 config
    (condition2, handler2),  # handler2 会收到 config
    default_handler          # default_handler 会收到 config
)

# 执行时传递配置
result = branch.invoke(input, config)
```

### 配置合并

```python
# 子 Runnable 可以覆盖配置
handler_with_custom_config = handler.with_config(
    tags=["custom-tag"]
)

branch = RunnableBranch(
    (condition, handler_with_custom_config),
    default_handler
)

# 执行时，handler_with_custom_config 会合并两个配置
result = branch.invoke(input, config)
```

---

## 3.10 性能特性

### 时间复杂度

- **最好情况**：O(1) - 第一个条件匹配
- **最坏情况**：O(n) - 所有条件都不匹配，n 是条件数量
- **平均情况**：O(n/2) - 假设条件均匀分布

### 空间复杂度

- **O(1)** - 不需要额外空间存储中间结果

### 性能优化建议

1. **条件顺序**：把最常匹配的条件放在前面
2. **条件简化**：避免复杂的条件计算
3. **预计算**：在条件外预先计算共享值
4. **缓存**：缓存条件评估结果（如果适用）

```python
# ❌ 不好：复杂条件在前
branch = RunnableBranch(
    (expensive_condition, handler1),  # 慢
    (simple_condition, handler2),     # 快
    default_handler
)

# ✅ 好：简单条件在前
branch = RunnableBranch(
    (simple_condition, handler2),     # 快
    (expensive_condition, handler1),  # 慢
    default_handler
)
```

---

## 3.11 执行追踪

### 使用 LangSmith 追踪

```python
import os
os.environ["LANGSMITH_API_KEY"] = "your-api-key"
os.environ["LANGSMITH_TRACING"] = "true"

from langchain_core.runnables import RunnableBranch

# 执行会自动追踪
branch = RunnableBranch(...)
result = branch.invoke(input)

# 在 LangSmith 中可以看到：
# - 哪些条件被评估了
# - 哪个条件返回了 True
# - 哪个分支被执行了
# - 每个步骤的执行时间
```

### 自定义回调

```python
from langchain_core.callbacks import BaseCallbackHandler

class BranchTracker(BaseCallbackHandler):
    """追踪 Branch 执行"""

    def on_chain_start(self, serialized, inputs, **kwargs):
        print(f"Branch started with input: {inputs}")

    def on_chain_end(self, outputs, **kwargs):
        print(f"Branch ended with output: {outputs}")

# 使用
config = RunnableConfig(callbacks=[BranchTracker()])
result = branch.invoke(input, config)
```

---

## 3.12 小结

**路由执行流程的关键要点**：

1. **顺序评估**：从上到下，第一个匹配就停止
2. **第一匹配**：只执行一个分支
3. **默认分支**：保证总有分支执行
4. **同步/异步**：支持 invoke/ainvoke
5. **批处理**：支持 batch/abatch
6. **流式执行**：支持 stream/astream
7. **错误处理**：错误会传播，需要适当处理
8. **配置传递**：RunnableConfig 自动传递到所有子 Runnable
9. **性能**：O(n) 时间复杂度，条件顺序影响性能
10. **可追踪**：支持 LangSmith 和自定义回调

**下一步**：学习与其他路由方式的对比（核心概念4）。
