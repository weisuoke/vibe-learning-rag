# 面试必问

## 问题 1：什么是 Prompt Engineering？为什么它对 RAG 系统至关重要？

### 标准答案

**定义：**
Prompt Engineering 是通过精心设计输入指令，让大语言模型准确理解意图并生成高质量输出的技术。它包括五大核心技巧：角色设定、指令清晰、格式控制、上下文工程和输出质量控制。

**对 RAG 的重要性：**

1. **检索精度提升（30-50%）**
   - 清晰的查询改写指令 → 更准确的向量检索
   - 明确的相关性判断标准 → 更好的文档筛选

2. **生成质量提升（40-60%）**
   - 结构化输出格式 → 易于解析和展示
   - 上下文工程优化 → 减少幻觉和错误

3. **用户体验提升（50%+）**
   - 一致的角色设定 → 专业可信的助手形象
   - 质量控制机制 → 可靠的答案输出

**RAG 特有挑战：**
- **Context Window 限制**：如何在有限空间内注入最相关的检索内容
- **幻觉问题**：如何确保模型只基于检索到的文档回答
- **多文档整合**：如何让模型综合多个来源的信息

**来源：** [Source: IBM 2026 Prompt Engineering Guide](https://www.ibm.com/think/prompt-engineering)

### 加分点

**提到 2025-2026 的新趋势：**
- **Context Engineering（上下文工程）**：从"怎么问"转向"给什么上下文"
- **输出质量控制**：从"生成答案"转向"可靠答案"
- **RAG 专用 Prompt 模式**：System/User Prompt 分离、Few-shot 示例、推理链

**来源：** [Source: Context Engineering - The Next Frontier](https://www.deepset.ai/blog/context-engineering-the-next-frontier-beyond-prompt-engineering)

---

## 问题 2：如何设计一个生产级的 RAG Prompt？请给出具体示例。

### 标准答案

**设计原则：**

生产级 RAG Prompt 必须整合五大技巧：

```python
PRODUCTION_RAG_PROMPT = """
# 1. 角色设定（System Prompt）
你是一个专业的技术文档助手，擅长从检索到的文档中提取准确信息。

你的行为准则：
- 只基于提供的上下文回答
- 不确定时明确说明
- 保持专业和客观

---

# 2. 指令清晰
任务：基于检索到的文档回答用户问题

步骤：
1. 仔细阅读所有文档片段
2. 识别与问题最相关的信息
3. 综合信息形成答案
4. 验证答案的准确性

---

# 3. 上下文工程
## 检索到的文档（按相关性排序）

{context}

---

# 4. 用户问题
{question}

---

# 5. 格式控制
返回格式（必须是有效的 JSON）：
{{
  "answer": "基于上下文的答案（50-200字）",
  "sources": ["来源文档列表"],
  "confidence": 0.0-1.0,
  "has_sufficient_context": true/false,
  "reasoning": "为什么这样回答的简短说明"
}}

---

# 6. 输出质量控制
约束条件：
- 答案必须完全基于上下文
- 不要添加推测或个人观点
- 如果上下文不足，confidence < 0.5

验证清单：
- [ ] 每个事实都能在上下文中找到？
- [ ] 是否标注了来源？
- [ ] 格式是否正确？

如果验证失败，返回：
{{
  "error": "验证失败的原因",
  "suggestion": "需要什么额外信息",
  "validation_passed": false
}}
"""
```

**实现代码：**

```python
from openai import OpenAI
import json
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def production_rag_query(question: str, context: str) -> dict:
    """生产级 RAG 查询函数"""
    response = client.chat.completions.create(
        model="gpt-4",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": "你是一个严格的 RAG 助手，总是返回 JSON"},
            {"role": "user", "content": PRODUCTION_RAG_PROMPT.format(
                context=context,
                question=question
            )}
        ],
        temperature=0.1  # 低温度确保稳定输出
    )

    result = json.loads(response.choices[0].message.content)

    # 质量验证
    if not result.get("validation_passed", True):
        print(f"⚠️ 验证失败: {result['error']}")
        return None

    return result

# 使用示例
result = production_rag_query(
    question="什么是 RAG？",
    context="RAG（检索增强生成）是一种结合检索和生成的技术..."
)

if result:
    print(f"✅ 答案: {result['answer']}")
    print(f"📚 来源: {result['sources']}")
    print(f"🎯 置信度: {result['confidence']}")
```

**关键设计决策：**

| 决策 | 理由 | 效果 |
|------|------|------|
| JSON 格式输出 | 易于解析和验证 | 可靠性 +100% |
| 置信度评分 | 量化答案质量 | 可信度 +60% |
| 验证清单 | 自我检查机制 | 准确度 +40% |
| 低温度（0.1） | 确保输出稳定 | 一致性 +80% |
| 来源标注 | 可追溯性 | 信任度 +50% |

**来源：** [Source: Stack AI RAG Prompting Guide](https://www.stack-ai.com/blog/prompt-engineering-for-rag-pipelines-the-complete-guide-to-prompt-engineering-for-retrieval-augmented-generation)

### 加分点

**提到生产环境的额外考虑：**

1. **多语言支持**：在 System Prompt 中指定语言
2. **错误处理**：明确定义失败场景的返回格式
3. **监控指标**：confidence、has_sufficient_context 用于质量监控
4. **A/B 测试**：通过 temperature 和 prompt 变体优化
5. **成本优化**：根据查询复杂度选择模型（GPT-4 vs GPT-3.5）

---

## 问题 3：解释 Context Engineering 在 RAG 中的作用，以及如何优化上下文注入？

### 标准答案

**Context Engineering 定义：**

Context Engineering（上下文工程）是 2025-2026 年 Prompt Engineering 的新重点，关注如何在有限的 Context Window 内，精心组织和注入最相关的上下文信息。

**来源：** [Source: Context Engineering - The Next Frontier](https://www.deepset.ai/blog/context-engineering-the-next-frontier-beyond-prompt-engineering)

**在 RAG 中的核心挑战：**

1. **Context Window 限制**
   - GPT-4：8K-128K tokens
   - 检索到 10 篇文档，但只能放 3 篇
   - 多轮对话历史 + 检索内容 → 如何平衡？

2. **相关性排序**
   - 向量相似度高 ≠ 语义相关
   - 需要 ReRank 重排序

3. **上下文质量 > 上下文数量**
   - 精选 3 篇高质量文档 > 堆砌 10 篇低质量文档

**优化策略：**

```python
def optimize_context_injection(
    query: str,
    retrieved_docs: list,
    max_tokens: int = 2000
) -> str:
    """优化上下文注入策略"""

    # 1. 按相关性排序（ReRank）
    sorted_docs = sorted(
        retrieved_docs,
        key=lambda x: x['relevance_score'],
        reverse=True
    )

    # 2. 动态选择文档数量（基于 token 预算）
    selected_docs = []
    current_tokens = 0

    for doc in sorted_docs:
        doc_tokens = estimate_tokens(doc['content'])

        if current_tokens + doc_tokens <= max_tokens:
            selected_docs.append(doc)
            current_tokens += doc_tokens
        else:
            break

    # 3. 构建结构化上下文
    context = "\n\n".join([
        f"## 文档 {i+1}（相关度：{doc['relevance_score']:.2f}）\n"
        f"来源：{doc['source']}\n"
        f"内容：{doc['content']}"
        for i, doc in enumerate(selected_docs)
    ])

    # 4. 添加元信息
    context_header = f"""
# 检索到 {len(retrieved_docs)} 篇文档，选择了最相关的 {len(selected_docs)} 篇
# 总 tokens：{current_tokens}/{max_tokens}
# 查询：{query}

---

"""

    return context_header + context

def estimate_tokens(text: str) -> int:
    """估算文本的 token 数量（粗略估计：1 token ≈ 4 字符）"""
    return len(text) // 4
```

**最佳实践：**

| 策略 | 说明 | 效果提升 |
|------|------|---------|
| **Top-K 限制** | 只取前 K 个最相关文档 | 准确度 +30% |
| **Token 预算** | 动态调整文档数量 | 效率 +50% |
| **ReRank 重排序** | 二次排序提升相关性 | 相关性 +40% |
| **结构化注入** | 标注来源和相关度 | 可解释性 +60% |
| **元信息添加** | 告诉模型上下文的质量 | 可靠性 +20% |

**来源：** [Source: Google Research - RAG Context](https://research.google/blog/deeper-insights-into-retrieval-augmented-generation-the-role-of-sufficient-context)

### 加分点

**提到高级技巧：**

1. **分层上下文注入**
   - 第一层：最相关的核心文档
   - 第二层：补充背景信息
   - 第三层：相关但次要的内容

2. **动态上下文压缩**
   - 使用摘要模型压缩长文档
   - 只保留与查询相关的段落

3. **上下文缓存**
   - 对于重复查询，缓存上下文以节省成本
   - Anthropic Claude 的 Prompt Caching 功能

4. **多模态上下文**
   - 文本 + 图片 + 表格
   - 结构化数据的特殊处理

---

## 快速复习卡片

### 卡片 1：五大核心技巧

| 技巧 | 一句话 | RAG 应用 |
|------|--------|---------|
| 角色设定 | 定义 AI 的身份和行为 | 一致的助手风格 |
| 指令清晰 | 明确具体的任务步骤 | 精确控制检索和生成 |
| 格式控制 | 规定结构化输出 | JSON 格式易于解析 |
| 上下文工程 ⭐ | 优化注入的上下文 | RAG 的核心挑战 |
| 输出质量控制 ⭐ | 约束和验证输出 | 防止幻觉 |

### 卡片 2：常见误区

| 误区 | 正确理解 |
|------|---------|
| "Prompt 越长越好" | 清晰 > 冗长，去除无关信息 |
| "温度越高越创意" | RAG 需要低温度（0.1-0.3）确保稳定 |
| "塞入所有检索结果" | 精选 Top-K，质量 > 数量 |
| "模型会自动忽略无关上下文" | 需要明确指令和质量控制 |

### 卡片 3：生产级检查清单

- [ ] System Prompt 定义了角色和行为规范？
- [ ] 任务步骤明确且可验证？
- [ ] 输出格式是 JSON 且有 Schema？
- [ ] 上下文按相关性排序且有 Token 限制？
- [ ] 有约束条件和验证机制？
- [ ] 有置信度评分和来源标注？
- [ ] 有错误处理和降级策略？

---

**版本：** v1.0 | **更新：** 2026-02-14 | **阅读时间：** 6分钟
