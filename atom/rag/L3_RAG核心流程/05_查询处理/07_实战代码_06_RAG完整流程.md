# 实战代码 06：RAG 完整流程

## 概述

本文提供整合所有查询处理技术的完整 RAG 系统实现，包括查询理解、查询改写、多查询生成、查询分解、HyDE 等技术的智能选择和组合。所有代码基于 Python 3.13+，使用 OpenAI API 和 ChromaDB。

---

## 场景 1：智能查询处理 RAG 系统

### 需求

构建一个智能的 RAG 系统，能够：
1. 自动理解查询意图
2. 根据查询类型选择最佳处理策略
3. 整合多种查询处理技术
4. 提供完整的端到端流程

### 完整代码

```python
from openai import OpenAI
import chromadb
from typing import List, Dict, Optional
from dataclasses import dataclass
import json
import time

client = OpenAI()

# 初始化向量数据库
chroma_client = chromadb.Client()
collection = chroma_client.create_collection("knowledge_base")

# 添加示例知识库
collection.add(
    documents=[
        "RAG 系统的检索准确性可以通过优化 Embedding 模型、改进分块策略、使用混合检索来提升。",
        "减少 RAG 幻觉的方法包括：使用 ReRank、添加引用来源、限制生成长度、使用思维链。",
        "RAG 评估指标包括召回率、精确率、MRR、NDCG 等，需要构建测试集进行评估。",
        "Prompt 优化可以显著提升 RAG 生成质量，包括明确指令、提供示例、限制输出格式。",
        "LangChain 的优势包括：丰富的组件生态、灵活的链式调用、强大的社区支持。",
        "LangChain 的劣势包括：学习曲线陡峭、抽象层次过多、性能开销较大。",
        "LlamaIndex 的优势包括：专注于 RAG 场景、简单易用的 API、高效的索引结构。",
        "LlamaIndex 的劣势包括：功能相对单一、社区规模较小、文档不够完善。",
        "Transformer 的自注意力机制通过计算 Query、Key、Value 之间的相似度实现序列建模。",
        "Python 性能优化的核心方法包括：使用内置函数、避免全局变量、使用列表推导式。"
    ],
    ids=[f"doc{i}" for i in range(1, 11)]
)

@dataclass
class QueryUnderstanding:
    """查询理解结果"""
    original_query: str
    intent: str
    complexity: str
    entities: List[Dict[str, str]]
    recommended_strategy: str

class IntelligentRAG:
    """智能查询处理 RAG 系统"""

    def __init__(self, collection):
        self.collection = collection
        self.client = OpenAI()

    def understand_query(self, query: str) -> QueryUnderstanding:
        """理解查询"""
        # 1. 意图识别
        intent = self._detect_intent(query)

        # 2. 复杂度评估
        complexity = self._estimate_complexity(query)

        # 3. 实体提取
        entities = self._extract_entities(query)

        # 4. 推荐策略
        strategy = self._recommend_strategy(intent, complexity)

        return QueryUnderstanding(
            original_query=query,
            intent=intent,
            complexity=complexity,
            entities=entities,
            recommended_strategy=strategy
        )

    def _detect_intent(self, query: str) -> str:
        """检测查询意图"""
        query_lower = query.lower()

        if any(kw in query_lower for kw in ["什么是", "是什么", "概念"]):
            return "concept"
        elif any(kw in query_lower for kw in ["如何", "怎么", "方法"]):
            return "how-to"
        elif any(kw in query_lower for kw in ["对比", "比较", "优缺点"]):
            return "comparison"
        elif any(kw in query_lower for kw in ["为什么", "原因"]):
            return "why"
        else:
            return "exploratory"

    def _estimate_complexity(self, query: str) -> str:
        """评估查询复杂度"""
        query_length = len(query.split())

        if query_length < 5:
            return "simple"
        elif query_length < 10:
            return "medium"
        else:
            return "complex"

    def _extract_entities(self, query: str) -> List[Dict[str, str]]:
        """提取实体（简化版）"""
        # 这里使用简单的关键词匹配
        entities = []
        keywords = ["RAG", "LangChain", "LlamaIndex", "Transformer", "Python"]

        for keyword in keywords:
            if keyword in query:
                entities.append({"text": keyword, "type": "concept"})

        return entities

    def _recommend_strategy(self, intent: str, complexity: str) -> str:
        """推荐查询处理策略"""
        if intent == "concept" and complexity == "simple":
            return "hyde"
        elif intent == "comparison":
            return "decompose"
        elif complexity == "complex":
            return "multi-query"
        elif intent == "how-to":
            return "rewrite"
        else:
            return "direct"

    def process_query(
        self,
        query: str,
        strategy: Optional[str] = None
    ) -> Dict:
        """处理查询"""
        # 1. 理解查询
        understanding = self.understand_query(query)

        # 2. 选择策略
        if strategy is None:
            strategy = understanding.recommended_strategy

        print(f"查询: {query}")
        print(f"意图: {understanding.intent}")
        print(f"复杂度: {understanding.complexity}")
        print(f"策略: {strategy}\n")

        # 3. 根据策略处理
        if strategy == "hyde":
            return self._hyde_process(query)
        elif strategy == "multi-query":
            return self._multi_query_process(query)
        elif strategy == "decompose":
            return self._decompose_process(query)
        elif strategy == "rewrite":
            return self._rewrite_process(query)
        else:
            return self._direct_process(query)

    def _hyde_process(self, query: str) -> Dict:
        """HyDE 处理"""
        print("使用 HyDE 策略")

        # 生成假设答案
        hypothesis = self._generate_hypothesis(query)
        print(f"假设答案: {hypothesis[:100]}...\n")

        # 检索
        results = self.collection.query(
            query_texts=[hypothesis],
            n_results=5
        )

        return {
            "strategy": "hyde",
            "hypothesis": hypothesis,
            "documents": results['documents'][0]
        }

    def _multi_query_process(self, query: str) -> Dict:
        """多查询生成处理"""
        print("使用多查询生成策略")

        # 生成多个查询
        queries = self._generate_multi_queries(query, num_queries=3)
        print(f"生成的查询:")
        for i, q in enumerate(queries, 1):
            print(f"  {i}. {q}")

        # 并行检索
        all_docs = []
        seen = set()

        for q in queries:
            results = self.collection.query(
                query_texts=[q],
                n_results=3
            )

            for doc in results['documents'][0]:
                if doc not in seen:
                    all_docs.append(doc)
                    seen.add(doc)

        print(f"\n检索到 {len(all_docs)} 个唯一文档\n")

        return {
            "strategy": "multi-query",
            "queries": queries,
            "documents": all_docs[:5]
        }

    def _decompose_process(self, query: str) -> Dict:
        """查询分解处理"""
        print("使用查询分解策略")

        # 分解查询
        sub_queries = self._decompose_query(query)
        print(f"分解为 {len(sub_queries)} 个子查询:")
        for i, sq in enumerate(sub_queries, 1):
            print(f"  {i}. {sq}")

        # 执行子查询
        all_docs = []
        for sq in sub_queries:
            results = self.collection.query(
                query_texts=[sq],
                n_results=2
            )
            all_docs.extend(results['documents'][0])

        # 去重
        unique_docs = list(dict.fromkeys(all_docs))

        print(f"\n检索到 {len(unique_docs)} 个唯一文档\n")

        return {
            "strategy": "decompose",
            "sub_queries": sub_queries,
            "documents": unique_docs[:5]
        }

    def _rewrite_process(self, query: str) -> Dict:
        """查询改写处理"""
        print("使用查询改写策略")

        # 改写查询
        rewritten = self._rewrite_query(query)
        print(f"改写查询: {rewritten}\n")

        # 检索
        results = self.collection.query(
            query_texts=[rewritten],
            n_results=5
        )

        return {
            "strategy": "rewrite",
            "rewritten_query": rewritten,
            "documents": results['documents'][0]
        }

    def _direct_process(self, query: str) -> Dict:
        """直接检索"""
        print("使用直接检索策略\n")

        results = self.collection.query(
            query_texts=[query],
            n_results=5
        )

        return {
            "strategy": "direct",
            "documents": results['documents'][0]
        }

    def _generate_hypothesis(self, query: str) -> str:
        """生成假设答案"""
        prompt = f"""请为以下问题生成一个详细的假设性答案。

问题：{query}

假设答案："""

        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=200
        )

        return response.choices[0].message.content.strip()

    def _generate_multi_queries(self, query: str, num_queries: int = 3) -> List[str]:
        """生成多个查询"""
        prompt = f"""为以下查询生成 {num_queries} 个不同角度的变体。

原始查询：{query}

变体查询（每行一个）："""

        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        queries = response.choices[0].message.content.strip().split('\n')
        return [q.strip() for q in queries if q.strip()][:num_queries]

    def _decompose_query(self, query: str) -> List[str]:
        """分解查询"""
        prompt = f"""将以下复杂查询分解为多个简单子查询。

原始查询：{query}

子查询（每行一个）："""

        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )

        sub_queries = response.choices[0].message.content.strip().split('\n')
        return [q.strip() for q in sub_queries if q.strip()]

    def _rewrite_query(self, query: str) -> str:
        """改写查询"""
        prompt = f"""将以下查询改写为更适合检索的形式。

原始查询：{query}

改写查询："""

        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        return response.choices[0].message.content.strip()

    def generate_answer(
        self,
        query: str,
        documents: List[str]
    ) -> str:
        """生成最终答案"""
        context = "\n\n".join(documents[:5])

        prompt = f"""基于以下上下文回答问题：

上下文：
{context}

问题：{query}

答案："""

        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        return response.choices[0].message.content.strip()

    def query(
        self,
        query: str,
        strategy: Optional[str] = None
    ) -> Dict:
        """完整的 RAG 查询流程"""
        print("=" * 80)
        print("智能查询处理 RAG 系统")
        print("=" * 80 + "\n")

        start_time = time.time()

        # 1. 处理查询
        process_result = self.process_query(query, strategy)

        # 2. 生成答案
        print("生成答案...")
        answer = self.generate_answer(query, process_result['documents'])

        elapsed = time.time() - start_time

        print(f"\n答案:\n{answer}\n")
        print(f"总耗时: {elapsed*1000:.0f}ms")
        print("=" * 80 + "\n")

        return {
            "query": query,
            "strategy": process_result['strategy'],
            "documents": process_result['documents'],
            "answer": answer,
            "elapsed_ms": elapsed * 1000
        }

# 测试
if __name__ == "__main__":
    rag = IntelligentRAG(collection)

    test_queries = [
        "什么是 Transformer 的自注意力机制？",  # concept -> HyDE
        "如何优化 RAG 系统性能？",  # how-to -> rewrite
        "对比 LangChain 和 LlamaIndex 的优缺点",  # comparison -> decompose
        "RAG 系统如何提升准确性？"  # complex -> multi-query
    ]

    for query in test_queries:
        result = rag.query(query)
        print("\n")
```

### 运行结果

```
================================================================================
智能查询处理 RAG 系统
================================================================================

查询: 什么是 Transformer 的自注意力机制？
意图: concept
复杂度: simple
策略: hyde

使用 HyDE 策略
假设答案: Transformer 的自注意力机制（Self-Attention）是一种允许模型在处理序列时关注序列中不同位置的机制...

生成答案...

答案:
Transformer 的自注意力机制通过计算查询（Query）、键（Key）和值（Value）之间的相似度，为每个位置生成加权表示。这种机制使得模型能够捕捉序列中的长距离依赖关系，是 Transformer 强大性能的关键。

总耗时: 1245ms
================================================================================
```

---

## 场景 2：性能监控与优化

### 需求

添加性能监控和优化功能，跟踪各个环节的耗时和效果。

### 完整代码

```python
from dataclasses import dataclass, field
from typing import List, Dict
import time

@dataclass
class PerformanceMetrics:
    """性能指标"""
    query_understanding_ms: float = 0
    query_processing_ms: float = 0
    retrieval_ms: float = 0
    answer_generation_ms: float = 0
    total_ms: float = 0
    num_documents: int = 0
    strategy_used: str = ""

class MonitoredRAG(IntelligentRAG):
    """带性能监控的 RAG 系统"""

    def __init__(self, collection):
        super().__init__(collection)
        self.metrics_history: List[PerformanceMetrics] = []

    def query(
        self,
        query: str,
        strategy: Optional[str] = None
    ) -> Dict:
        """带监控的查询"""
        metrics = PerformanceMetrics()
        total_start = time.time()

        print("=" * 80)
        print("带性能监控的 RAG 系统")
        print("=" * 80 + "\n")

        # 1. 查询理解
        start = time.time()
        understanding = self.understand_query(query)
        metrics.query_understanding_ms = (time.time() - start) * 1000

        if strategy is None:
            strategy = understanding.recommended_strategy

        metrics.strategy_used = strategy

        print(f"查询: {query}")
        print(f"意图: {understanding.intent}")
        print(f"复杂度: {understanding.complexity}")
        print(f"策略: {strategy}")
        print(f"查询理解耗时: {metrics.query_understanding_ms:.0f}ms\n")

        # 2. 查询处理
        start = time.time()
        process_result = self.process_query(query, strategy)
        metrics.query_processing_ms = (time.time() - start) * 1000
        metrics.num_documents = len(process_result['documents'])

        print(f"查询处理耗时: {metrics.query_processing_ms:.0f}ms\n")

        # 3. 生成答案
        start = time.time()
        answer = self.generate_answer(query, process_result['documents'])
        metrics.answer_generation_ms = (time.time() - start) * 1000

        print(f"答案生成耗时: {metrics.answer_generation_ms:.0f}ms\n")

        # 4. 总耗时
        metrics.total_ms = (time.time() - total_start) * 1000

        # 保存指标
        self.metrics_history.append(metrics)

        # 显示结果
        print(f"答案:\n{answer}\n")
        print("=" * 80)
        print("性能统计")
        print("=" * 80)
        print(f"查询理解: {metrics.query_understanding_ms:.0f}ms")
        print(f"查询处理: {metrics.query_processing_ms:.0f}ms")
        print(f"答案生成: {metrics.answer_generation_ms:.0f}ms")
        print(f"总耗时: {metrics.total_ms:.0f}ms")
        print(f"检索文档数: {metrics.num_documents}")
        print("=" * 80 + "\n")

        return {
            "query": query,
            "strategy": strategy,
            "documents": process_result['documents'],
            "answer": answer,
            "metrics": metrics
        }

    def get_performance_summary(self) -> Dict:
        """获取性能摘要"""
        if not self.metrics_history:
            return {}

        total_queries = len(self.metrics_history)

        avg_understanding = sum(m.query_understanding_ms for m in self.metrics_history) / total_queries
        avg_processing = sum(m.query_processing_ms for m in self.metrics_history) / total_queries
        avg_generation = sum(m.answer_generation_ms for m in self.metrics_history) / total_queries
        avg_total = sum(m.total_ms for m in self.metrics_history) / total_queries

        strategy_counts = {}
        for m in self.metrics_history:
            strategy_counts[m.strategy_used] = strategy_counts.get(m.strategy_used, 0) + 1

        return {
            "total_queries": total_queries,
            "avg_understanding_ms": avg_understanding,
            "avg_processing_ms": avg_processing,
            "avg_generation_ms": avg_generation,
            "avg_total_ms": avg_total,
            "strategy_distribution": strategy_counts
        }

# 测试
if __name__ == "__main__":
    rag = MonitoredRAG(collection)

    test_queries = [
        "什么是 RAG？",
        "如何优化 RAG？",
        "对比 LangChain 和 LlamaIndex"
    ]

    for query in test_queries:
        result = rag.query(query)

    # 显示性能摘要
    summary = rag.get_performance_summary()

    print("\n" + "=" * 80)
    print("性能摘要")
    print("=" * 80)
    print(f"总查询数: {summary['total_queries']}")
    print(f"平均查询理解耗时: {summary['avg_understanding_ms']:.0f}ms")
    print(f"平均查询处理耗时: {summary['avg_processing_ms']:.0f}ms")
    print(f"平均答案生成耗时: {summary['avg_generation_ms']:.0f}ms")
    print(f"平均总耗时: {summary['avg_total_ms']:.0f}ms")
    print(f"\n策略分布:")
    for strategy, count in summary['strategy_distribution'].items():
        print(f"  {strategy}: {count} 次")
```

---

## 场景 3：缓存优化

### 需求

添加多级缓存，优化高频查询的性能。

### 完整代码

```python
from functools import lru_cache
import hashlib

class CachedRAG(MonitoredRAG):
    """带缓存的 RAG 系统"""

    def __init__(self, collection):
        super().__init__(collection)
        self.query_cache: Dict[str, Dict] = {}
        self.document_cache: Dict[str, List[str]] = {}

    def _get_cache_key(self, query: str, strategy: str) -> str:
        """生成缓存键"""
        content = f"{query}:{strategy}"
        return hashlib.md5(content.encode()).hexdigest()

    def query(
        self,
        query: str,
        strategy: Optional[str] = None,
        use_cache: bool = True
    ) -> Dict:
        """带缓存的查询"""
        # 1. 查询理解
        understanding = self.understand_query(query)

        if strategy is None:
            strategy = understanding.recommended_strategy

        # 2. 检查缓存
        cache_key = self._get_cache_key(query, strategy)

        if use_cache and cache_key in self.query_cache:
            print("=" * 80)
            print("从缓存返回结果")
            print("=" * 80 + "\n")

            cached_result = self.query_cache[cache_key]
            print(f"查询: {query}")
            print(f"策略: {strategy}")
            print(f"来源: 缓存\n")
            print(f"答案:\n{cached_result['answer']}\n")

            return cached_result

        # 3. 执行查询
        result = super().query(query, strategy)

        # 4. 缓存结果
        if use_cache:
            self.query_cache[cache_key] = result

        return result

# 测试
if __name__ == "__main__":
    rag = CachedRAG(collection)

    # 第一次查询
    print("第一次查询:")
    result1 = rag.query("什么是 RAG？")

    print("\n" + "-" * 80 + "\n")

    # 第二次相同查询（从缓存）
    print("第二次相同查询:")
    result2 = rag.query("什么是 RAG？")
```

---

## 总结

### 关键要点

1. **智能策略选择**：根据查询意图和复杂度自动选择最佳策略
2. **完整流程整合**：整合查询理解、处理、检索、生成全流程
3. **性能监控**：跟踪各环节耗时，持续优化
4. **缓存优化**：多级缓存提升高频查询性能
5. **可扩展架构**：模块化设计，易于扩展新策略

### 代码特点

- 所有代码可直接运行
- 使用 Python 3.13+ 特性
- 基于 OpenAI API 和 ChromaDB
- 完整的端到端实现
- 包含性能监控和优化

### 性能优化建议

1. **智能策略选择**：根据查询特征自动选择
2. **并行处理**：多查询并行检索
3. **缓存机制**：缓存高频查询结果
4. **异步处理**：使用异步 API 减少延迟
5. **批量处理**：批量处理多个查询

### 生产部署建议

1. **添加日志**：记录所有查询和结果
2. **错误处理**：完善的异常处理机制
3. **限流保护**：防止 API 调用过载
4. **监控告警**：实时监控系统性能
5. **A/B 测试**：持续优化策略选择

---

**记住：** 完整的 RAG 系统不仅需要实现各种查询处理技术，更重要的是根据实际场景智能选择和组合这些技术，持续监控和优化性能。
