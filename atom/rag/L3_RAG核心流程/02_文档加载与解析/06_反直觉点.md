# 反直觉点

> 文档加载与解析中最常见的3个误区

---

## 误区1："PDF 解析很简单，就是提取文字" ❌

### 为什么错？

PDF 的设计目标是**精确还原打印效果**，而不是方便文本提取。

```
你以为的 PDF：
┌─────────────────────────────────┐
│  第一章 退款政策                  │
│                                 │
│  1.1 退款条件                    │
│  客户可在购买后7天内申请退款。    │
└─────────────────────────────────┘
↓ 简单提取
"第一章 退款政策\n1.1 退款条件\n客户可在购买后7天内申请退款。"

实际的 PDF 内部结构：
BT
/F1 18 Tf          % 设置字体
100 750 Td         % 移动到坐标 (100, 750)
(第) Tj            % 绘制"第"
115 750 Td
(一) Tj            % 绘制"一"
130 750 Td
(章) Tj            % 绘制"章"
...
ET

每个字符都是独立的绘制指令！
```

### 为什么人们容易这样错？

- 我们看到的是渲染后的效果，不是原始数据
- 其他格式（TXT、Markdown）确实很简单
- PDF 阅读器隐藏了复杂性

### 正确理解

```python
# PDF 解析的真实挑战

# 1. 文本重组：把分散的字符拼回段落
# 2. 布局分析：区分标题、正文、页眉页脚
# 3. 表格识别：表格在 PDF 中只是一堆线条和文字
# 4. 多栏处理：两栏文字的阅读顺序

# 不同 PDF 解析库的效果差异很大
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import PDFPlumberLoader

# 简单 PDF：两者效果差不多
# 复杂 PDF（表格、多栏）：PDFPlumber 通常更好

# 最佳实践：先用简单的，效果不好再换
loader = PyPDFLoader("simple.pdf")  # 先试这个
# loader = PDFPlumberLoader("complex.pdf")  # 效果不好再换这个
```

**记住：PDF 解析是一个"尽力而为"的过程，不可能 100% 完美。**

---

## 误区2："所有文档都应该用同一个 Loader" ❌

### 为什么错？

不同格式的文档有完全不同的内部结构，需要专门的解析策略。

```
错误做法：
def load_any_document(file_path):
    # 试图用一个通用方法处理所有格式
    with open(file_path, 'r') as f:
        return f.read()  # PDF 会乱码！Word 会报错！

正确做法：
def load_document(file_path):
    ext = Path(file_path).suffix.lower()

    loaders = {
        '.pdf': PyPDFLoader,
        '.docx': Docx2txtLoader,
        '.html': UnstructuredHTMLLoader,
        '.md': UnstructuredMarkdownLoader,
        '.txt': TextLoader,
    }

    if ext not in loaders:
        raise ValueError(f"不支持的格式: {ext}")

    return loaders[ext](file_path).load()
```

### 为什么人们容易这样错？

- DRY 原则（Don't Repeat Yourself）的过度应用
- 希望代码更"优雅"
- 不了解不同格式的本质差异

### 正确理解

```python
# 每种格式都有其特殊性

# PDF：二进制格式，需要专门的解析库
# - 可能有加密
# - 可能有扫描图片（需要 OCR）
# - 表格提取困难

# Word：ZIP 压缩的 XML
# - 样式信息复杂
# - 可能有嵌入对象
# - 修订记录处理

# HTML：标签嵌套的文本
# - 需要去除 script/style
# - 需要处理实体编码
# - 可能有 iframe

# Markdown：纯文本 + 语法标记
# - 是否保留格式？
# - 代码块如何处理？

# TXT：最简单，但编码是个坑
# - UTF-8? GBK? Latin-1?
# - 换行符：\n? \r\n?

# 最佳实践：为每种格式选择最合适的 Loader
```

---

## 误区3："文档加载后直接用于检索就行" ❌

### 为什么错？

原始加载的文档通常需要**预处理**才能获得好的检索效果。

```
错误流程：
文档 → Loader → 直接存入向量库 → 检索效果差

正确流程：
文档 → Loader → 预处理 → 分块 → 存入向量库 → 检索效果好
              ↑
           这一步很重要！
```

### 常见的预处理需求

```python
def preprocess_document(doc):
    """文档预处理"""
    text = doc.page_content

    # 1. 清理多余空白
    import re
    text = re.sub(r'\s+', ' ', text)  # 多个空白变一个
    text = text.strip()

    # 2. 移除页眉页脚（PDF 常见问题）
    # "第 1 页 / 共 10 页" 这种信息对检索没用
    text = re.sub(r'第\s*\d+\s*页.*?共\s*\d+\s*页', '', text)

    # 3. 处理特殊字符
    text = text.replace('\x00', '')  # 移除空字符
    text = text.replace('\ufeff', '')  # 移除 BOM

    # 4. 标准化标点
    text = text.replace('，', ', ')  # 统一逗号（可选）

    # 5. 移除无意义内容
    if len(text) < 10:  # 太短的内容没有价值
        return None

    return Document(
        page_content=text,
        metadata=doc.metadata
    )
```

### 为什么人们容易这样错？

- 急于看到结果，跳过预处理
- 不知道原始文档有这么多"噪音"
- 测试时用的是干净的文档

### 正确理解

```python
# 完整的文档加载流程

def load_and_preprocess(file_path: str):
    """加载并预处理文档"""

    # Step 1: 加载
    loader = get_loader(file_path)
    raw_docs = loader.load()

    # Step 2: 预处理
    processed_docs = []
    for doc in raw_docs:
        processed = preprocess_document(doc)
        if processed:
            processed_docs.append(processed)

    # Step 3: 质量检查
    print(f"原始文档数: {len(raw_docs)}")
    print(f"处理后文档数: {len(processed_docs)}")

    # 检查是否有内容丢失过多
    if len(processed_docs) < len(raw_docs) * 0.5:
        print("警告：超过50%的内容被过滤，请检查预处理逻辑")

    return processed_docs

# 使用
docs = load_and_preprocess("policy.pdf")
# 然后再进行分块和向量化
```

---

## 误区速查表

| 误区 | 现实 | 正确做法 |
|-----|------|---------|
| PDF 解析很简单 | PDF 内部结构复杂 | 选择合适的解析库，接受不完美 |
| 一个 Loader 搞定所有 | 不同格式需要不同策略 | 根据扩展名选择对应 Loader |
| 加载后直接用 | 原始文档有很多噪音 | 加载 → 预处理 → 分块 |

---

## 额外提醒

### 关于 OCR（图片文字识别）

```
误区：PDF 里的文字都能提取出来
现实：扫描版 PDF 里的"文字"其实是图片

如何判断：
- 用鼠标选中 PDF 中的文字
- 如果能选中 → 文本型 PDF → 可以直接提取
- 如果选不中 → 扫描型 PDF → 需要 OCR

解决方案：
# pip install pytesseract pdf2image
# 需要安装 Tesseract OCR 引擎
```

### 关于编码问题

```
误区：所有文本文件都是 UTF-8
现实：中文文件经常是 GBK/GB2312

# 自动检测编码
import chardet

with open(file_path, 'rb') as f:
    raw = f.read()
    detected = chardet.detect(raw)
    encoding = detected['encoding']

with open(file_path, 'r', encoding=encoding) as f:
    content = f.read()
```

---

**下一步：** [07_实战代码](./07_实战代码.md) - 完整可运行的文档加载示例
