# 实战代码：API适配器开发

## 场景描述

**需求：** 集成一个非标准API格式的LLM服务，需要自定义streamSimple函数。

**背景：**
- 自建LLM服务，API格式不兼容OpenAI/Anthropic
- 使用自定义的流式协议
- 需要特殊的请求/响应转换

**技术要求：**
- 实现streamSimple函数
- 转换请求格式
- 解析流式响应
- 统一事件格式

## 完整实现

### 步骤1：创建Extension

```bash
mkdir -p ~/.pi/agent/extensions/custom-api-provider
cd ~/.pi/agent/extensions/custom-api-provider

cat > package.json << 'EOF'
{
  "name": "custom-api-provider",
  "version": "1.0.0",
  "type": "module",
  "main": "index.ts",
  "dependencies": {
    "@mariozechner/pi-coding-agent": "latest",
    "@mariozechner/pi-ai": "latest"
  }
}
EOF

npm install
```

### 步骤2：实现streamSimple

```typescript
// index.ts
import type { ExtensionAPI } from "@mariozechner/pi-coding-agent";
import type {
  Api,
  AssistantMessage,
  AssistantMessageEventStream,
  Context,
  Model,
  SimpleStreamOptions,
} from "@mariozechner/pi-ai";
import {
  calculateCost,
  createAssistantMessageEventStream,
} from "@mariozechner/pi-ai";

// 自定义API的streamSimple实现
function streamCustomAPI(
  model: Model<Api>,
  context: Context,
  options?: SimpleStreamOptions
): AssistantMessageEventStream {
  const stream = createAssistantMessageEventStream();

  (async () => {
    // 初始化输出消息
    const output: AssistantMessage = {
      role: "assistant",
      content: [],
      api: model.api,
      provider: model.provider,
      model: model.id,
      usage: {
        input: 0,
        output: 0,
        cacheRead: 0,
        cacheWrite: 0,
        totalTokens: 0,
        cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0, total: 0 },
      },
      stopReason: "stop",
      timestamp: Date.now(),
    };

    try {
      // 1. 转换请求格式
      const apiRequest = convertToCustomFormat(context, model, options);

      // 2. 发送start事件
      stream.push({ type: "start", partial: output });

      // 3. 调用API
      const response = await fetch(model.baseUrl + "/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${options?.apiKey || ""}`,
        },
        body: JSON.stringify(apiRequest),
        signal: options?.signal,
      });

      if (!response.ok) {
        throw new Error(`API request failed: ${response.statusText}`);
      }

      // 4. 解析流式响应
      const reader = response.body!.getReader();
      const decoder = new TextDecoder();
      let buffer = "";
      let contentIndex = -1;

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split("\n");
        buffer = lines.pop() || "";

        for (const line of lines) {
          if (!line.trim() || !line.startsWith("data: ")) continue;

          const data = line.slice(6);
          if (data === "[DONE]") continue;

          try {
            const event = JSON.parse(data);
            processCustomEvent(event, output, stream, contentIndex);
          } catch (error) {
            console.error("Failed to parse event:", error);
          }
        }
      }

      // 5. 计算成本
      calculateCost(model, output.usage);

      // 6. 发送done事件
      stream.push({
        type: "done",
        reason: output.stopReason as "stop" | "length" | "toolUse",
        message: output,
      });
      stream.end();
    } catch (error) {
      output.stopReason = options?.signal?.aborted ? "aborted" : "error";
      output.errorMessage =
        error instanceof Error ? error.message : String(error);
      stream.push({ type: "error", reason: output.stopReason, error: output });
      stream.end();
    }
  })();

  return stream;
}

// 转换请求格式
function convertToCustomFormat(
  context: Context,
  model: Model<Api>,
  options?: SimpleStreamOptions
) {
  return {
    model: model.id,
    messages: context.messages.map((msg) => ({
      role: msg.role,
      content:
        typeof msg.content === "string"
          ? msg.content
          : msg.content.map((c) => c.text || "").join("\n"),
    })),
    max_tokens: options?.maxTokens || model.maxTokens,
    temperature: 0.7,
    stream: true,
  };
}

// 处理自定义事件
function processCustomEvent(
  event: any,
  output: AssistantMessage,
  stream: AssistantMessageEventStream,
  contentIndex: number
) {
  if (event.type === "content_start") {
    // 开始新的内容块
    output.content.push({ type: "text", text: "" });
    contentIndex = output.content.length - 1;
    stream.push({ type: "text_start", contentIndex, partial: output });
  } else if (event.type === "content_delta") {
    // 内容增量
    const block = output.content[contentIndex];
    if (block && block.type === "text") {
      block.text += event.delta;
      stream.push({
        type: "text_delta",
        contentIndex,
        delta: event.delta,
        partial: output,
      });
    }
  } else if (event.type === "content_end") {
    // 内容块结束
    const block = output.content[contentIndex];
    if (block && block.type === "text") {
      stream.push({
        type: "text_end",
        contentIndex,
        content: block.text,
        partial: output,
      });
    }
  } else if (event.type === "usage") {
    // 使用统计
    output.usage.input = event.input_tokens || 0;
    output.usage.output = event.output_tokens || 0;
    output.usage.totalTokens = output.usage.input + output.usage.output;
  } else if (event.type === "done") {
    // 完成
    output.stopReason = event.reason || "stop";
  }
}

// Extension入口
export default function (pi: ExtensionAPI) {
  pi.registerProvider("custom-api", {
    baseUrl: "https://api.custom-llm.com/v1",
    apiKey: "CUSTOM_API_KEY",
    api: "custom-api",

    models: [
      {
        id: "custom-model-7b",
        name: "Custom Model 7B",
        reasoning: false,
        input: ["text"],
        contextWindow: 32768,
        maxTokens: 8192,
        cost: {
          input: 0,
          output: 0,
          cacheRead: 0,
          cacheWrite: 0,
        },
      },
    ],

    streamSimple: streamCustomAPI,
  });

  console.log("Custom API Provider registered");
}
```

### 步骤3：测试

```bash
# 配置Extension
echo '{"extensions": ["~/.pi/agent/extensions/custom-api-provider"]}' > ~/.pi/agent/settings.json

# 设置API Key
export CUSTOM_API_KEY=your-api-key

# 启动pi
pi

# 选择模型
/model custom-api/custom-model-7b

# 测试
Hello, can you hear me?
```

## 进阶示例

### 示例1：支持工具调用

```typescript
function processCustomEvent(
  event: any,
  output: AssistantMessage,
  stream: AssistantMessageEventStream,
  contentIndex: number
) {
  if (event.type === "tool_call_start") {
    output.content.push({
      type: "toolCall",
      id: event.id,
      name: event.name,
      arguments: {},
    });
    contentIndex = output.content.length - 1;
    stream.push({ type: "toolcall_start", contentIndex, partial: output });
  } else if (event.type === "tool_call_delta") {
    const block = output.content[contentIndex];
    if (block && block.type === "toolCall") {
      try {
        block.arguments = JSON.parse(event.arguments);
      } catch {}
      stream.push({
        type: "toolcall_delta",
        contentIndex,
        delta: event.arguments,
        partial: output,
      });
    }
  } else if (event.type === "tool_call_end") {
    const block = output.content[contentIndex];
    if (block && block.type === "toolCall") {
      stream.push({
        type: "toolcall_end",
        contentIndex,
        toolCall: block,
        partial: output,
      });
    }
  }
}
```

### 示例2：错误重试

```typescript
async function fetchWithRetry(
  url: string,
  options: RequestInit,
  maxRetries: number = 3
): Promise<Response> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);

      if (response.status === 429) {
        // Rate limit
        const retryAfter = response.headers.get("retry-after");
        const delay = retryAfter ? parseInt(retryAfter) * 1000 : Math.pow(2, i) * 1000;
        await new Promise((resolve) => setTimeout(resolve, delay));
        continue;
      }

      return response;
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise((resolve) => setTimeout(resolve, Math.pow(2, i) * 1000));
    }
  }
  throw new Error("Max retries exceeded");
}
```

### 示例3：支持图像输入

```typescript
function convertToCustomFormat(
  context: Context,
  model: Model<Api>,
  options?: SimpleStreamOptions
) {
  return {
    model: model.id,
    messages: context.messages.map((msg) => {
      if (typeof msg.content === "string") {
        return { role: msg.role, content: msg.content };
      }

      // 处理多模态内容
      const parts = msg.content.map((c) => {
        if (c.type === "text") {
          return { type: "text", text: c.text };
        } else if (c.type === "image") {
          return {
            type: "image",
            image: {
              format: c.mimeType,
              data: c.data,
            },
          };
        }
      });

      return { role: msg.role, content: parts };
    }),
    max_tokens: options?.maxTokens || model.maxTokens,
    stream: true,
  };
}
```

## 参考资源

**Pi-mono源码：**
- anthropic.ts: https://github.com/badlogic/pi-mono/blob/main/packages/ai/src/providers/anthropic.ts
- openai-completions.ts: https://github.com/badlogic/pi-mono/blob/main/packages/ai/src/providers/openai-completions.ts

**文档：**
- Custom Provider: https://github.com/badlogic/pi-mono/blob/main/packages/coding-agent/docs/custom-provider.md

## 总结

**streamSimple的核心步骤：**
1. 创建AssistantMessageEventStream
2. 转换请求格式
3. 调用API
4. 解析流式响应
5. 转换为统一事件格式
6. 发送done/error事件

**关键点：**
- 请求/响应格式转换
- 流式事件处理
- 错误处理和重试
- 成本计算
