# 错误处理策略 - 第一性原理

## 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题。

不是"别人都这么做"，而是"为什么要这么做"。

---

## 错误处理策略的第一性原理

### 1. 最基础的定义

**错误处理策略 = 预测错误 + 分类错误 + 响应错误 + 记录错误**

仅此而已！没有更基础的了。

**拆解：**
- **预测错误**：知道哪里可能出错（LLM 超时、数据库连接失败）
- **分类错误**：区分错误类型（临时性 vs 永久性、可重试 vs 不可重试）
- **响应错误**：采取行动（重试、降级、返回错误）
- **记录错误**：追踪错误（日志、监控、告警）

---

### 2. 为什么需要错误处理策略？

**核心问题：分布式系统中的不确定性**

在 AI Agent API 中，你依赖多个外部服务：
- LLM API（OpenAI、Anthropic）
- 向量数据库（Chroma、Milvus）
- 关系数据库（PostgreSQL）
- 缓存（Redis）

**每个服务都可能失败：**
- 网络抖动
- 服务过载
- 配额限制
- 硬件故障

**没有错误处理的后果：**
```python
# ❌ 没有错误处理
async def chat(message: str):
    response = await openai.chat.completions.create(...)  # 可能超时
    return response.choices[0].message.content

# 用户看到：500 Internal Server Error
# 开发者看到：Timeout after 30s
# 实际问题：OpenAI API 临时过载，1秒后就恢复了
```

**有错误处理的结果：**
```python
# ✅ 有错误处理
async def chat(message: str):
    for attempt in range(3):
        try:
            response = await openai.chat.completions.create(...)
            return response.choices[0].message.content
        except Timeout:
            if attempt < 2:
                await asyncio.sleep(2 ** attempt)  # 指数退避
            else:
                raise ServiceUnavailableError("LLM 服务暂时不可用")

# 用户看到：正常响应（第2次重试成功）
# 开发者看到：日志显示第1次超时，第2次成功
# 实际问题：自动恢复，用户无感知
```

---

### 3. 错误处理策略的三层价值

#### 价值1：可靠性（Reliability）

**定义：** 系统在面对故障时仍能正常工作

**示例：**
```python
# 场景：OpenAI API 返回 429 Rate Limit
# 没有错误处理：服务直接返回 500，用户无法使用
# 有错误处理：自动重试（等待 1 秒），用户无感知

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10))
async def call_llm(prompt: str):
    return await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
```

**价值：** 临时故障不会导致永久失败

---

#### 价值2：用户体验（User Experience）

**定义：** 用户看到友好的错误提示，而非技术错误

**示例：**
```python
# 场景：用户输入超长文本（超过 token 限制）
# 没有错误处理：
# {
#   "error": "InvalidRequestError: This model's maximum context length is 8192 tokens..."
# }

# 有错误处理：
# {
#   "error": "您的输入文本过长，请缩短至 2000 字以内",
#   "error_code": "TEXT_TOO_LONG"
# }

class TextTooLongError(Exception):
    """用户输入文本过长"""
    pass

@app.exception_handler(TextTooLongError)
async def text_too_long_handler(request, exc):
    return JSONResponse(
        status_code=422,
        content={
            "error": "您的输入文本过长，请缩短至 2000 字以内",
            "error_code": "TEXT_TOO_LONG"
        }
    )
```

**价值：** 用户理解错误原因，知道如何修正

---

#### 价值3：可维护性（Maintainability）

**定义：** 开发者能快速定位和修复问题

**示例：**
```python
# 场景：生产环境出现错误
# 没有错误处理：
# 日志：Exception occurred
# 开发者：什么异常？哪里出错？用户输入是什么？

# 有错误处理：
# 日志：
# {
#   "timestamp": "2026-02-12T08:00:00Z",
#   "level": "ERROR",
#   "request_id": "req_abc123",
#   "user_id": "user_456",
#   "endpoint": "/api/chat",
#   "error_type": "OpenAITimeout",
#   "error_message": "Request timeout after 30s",
#   "input_length": 1500,
#   "retry_count": 3,
#   "stack_trace": "..."
# }

import structlog

logger = structlog.get_logger()

async def chat(message: str, request_id: str, user_id: str):
    try:
        response = await call_llm(message)
        return response
    except Timeout as e:
        logger.error(
            "llm_timeout",
            request_id=request_id,
            user_id=user_id,
            endpoint="/api/chat",
            error_type="OpenAITimeout",
            input_length=len(message),
            retry_count=3
        )
        raise
```

**价值：** 快速定位问题，减少 MTTR（Mean Time To Recovery）

---

### 4. 从第一性原理推导 AI Agent API 的错误处理策略

**推理链：**

```
1. AI Agent API 依赖多个外部服务（LLM、数据库、缓存）
   ↓
2. 外部服务可能失败（网络、过载、配额）
   ↓
3. 失败分为两类：临时性（可恢复）和永久性（不可恢复）
   ↓
4. 临时性失败应该自动重试（指数退避）
   ↓
5. 重试失败后应该熔断（防止雪崩）
   ↓
6. 永久性失败应该立即返回错误（不浪费资源）
   ↓
7. 所有错误都应该记录（可观测性）
   ↓
8. 用户看到的错误应该友好（不暴露技术细节）
   ↓
9. 开发者看到的错误应该详细（快速定位问题）
   ↓
10. 因此，需要一个完整的错误处理策略：
    - 异常分层（业务异常 vs 系统异常）
    - 重试机制（指数退避）
    - 熔断器（防止雪崩）
    - 超时控制（资源保护）
    - 错误监控（可观测性）
    - 统一异常处理（用户友好 + 开发者友好）
```

---

### 5. 一句话总结第一性原理

**错误处理策略是通过预测、分类、响应和记录错误，保障分布式系统在面对不确定性时的可靠性、用户体验和可维护性。**

---

## 从第一性原理看错误处理的核心决策

### 决策1：是否重试？

**第一性原理：** 临时性错误应该重试，永久性错误不应该重试

**判断标准：**
- ✅ 重试：网络超时、Rate Limit、服务过载（429、503、504）
- ❌ 不重试：参数错误、认证失败、资源不存在（400、401、404）

**代码示例：**
```python
class RetryableError(Exception):
    """可重试的错误"""
    pass

class NonRetryableError(Exception):
    """不可重试的错误"""
    pass

def should_retry(error: Exception) -> bool:
    """判断是否应该重试"""
    if isinstance(error, RetryableError):
        return True
    if isinstance(error, NonRetryableError):
        return False

    # 根据 HTTP 状态码判断
    if hasattr(error, 'status_code'):
        return error.status_code in [429, 500, 502, 503, 504]

    return False
```

---

### 决策2：重试多少次？

**第一性原理：** 平衡恢复概率和用户等待时间

**推理：**
- 重试 1 次：恢复概率 ~50%
- 重试 2 次：恢复概率 ~75%
- 重试 3 次：恢复概率 ~87.5%
- 重试 10 次：恢复概率 ~99.9%，但用户等待时间过长

**最佳实践：** 3 次重试（指数退避）

```python
# 重试间隔：1s, 2s, 4s
# 总等待时间：7s
# 恢复概率：87.5%

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10)
)
async def call_llm(prompt: str):
    return await openai.chat.completions.create(...)
```

---

### 决策3：何时熔断？

**第一性原理：** 当依赖服务持续失败时，停止调用以防止雪崩

**推理：**
- 依赖服务故障 → 大量请求失败 → 重试加剧负载 → 服务雪崩
- 熔断器：检测失败率 → 超过阈值 → 停止调用 → 快速失败 → 服务恢复后重试

**状态机：**
```
Closed（正常）
  ↓ 失败率 > 50%
Open（熔断）
  ↓ 等待 30s
Half-Open（半开）
  ↓ 测试请求成功
Closed（恢复）
```

**代码示例：**
```python
class CircuitBreaker:
    def __init__(self, failure_threshold: float = 0.5, timeout: int = 30):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.state = "closed"
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None

    async def call(self, func, *args, **kwargs):
        if self.state == "open":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "half-open"
            else:
                raise CircuitBreakerOpenError("服务暂时不可用")

        try:
            result = await func(*args, **kwargs)
            self.on_success()
            return result
        except Exception as e:
            self.on_failure()
            raise

    def on_success(self):
        self.success_count += 1
        if self.state == "half-open":
            self.state = "closed"
            self.failure_count = 0

    def on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()

        total = self.failure_count + self.success_count
        if total > 0 and self.failure_count / total > self.failure_threshold:
            self.state = "open"
```

---

### 决策4：超时时间设置多少？

**第一性原理：** 平衡用户等待时间和服务恢复时间

**推理：**
- 超时太短：正常请求被误杀
- 超时太长：用户等待时间过长

**最佳实践：**
- LLM API 调用：30-60s（生成时间较长）
- 数据库查询：5-10s（应该很快）
- 向量检索：10-20s（取决于数据量）

```python
import asyncio

async def call_llm_with_timeout(prompt: str, timeout: int = 30):
    try:
        async with asyncio.timeout(timeout):
            return await openai.chat.completions.create(...)
    except asyncio.TimeoutError:
        raise LLMTimeoutError(f"LLM 调用超时（{timeout}s）")
```

---

## 错误处理策略的权衡

### 权衡1：可靠性 vs 性能

**可靠性：** 重试、熔断、超时 → 增加延迟
**性能：** 快速失败 → 降低可靠性

**平衡：**
- 关键路径（用户对话）：优先可靠性，允许重试
- 非关键路径（后台任务）：优先性能，快速失败

---

### 权衡2：用户体验 vs 开发者体验

**用户体验：** 友好的错误提示 → 隐藏技术细节
**开发者体验：** 详细的错误信息 → 暴露技术细节

**平衡：**
- 生产环境：用户看到友好提示，开发者看到详细日志
- 开发环境：用户和开发者都看到详细信息

```python
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    # 开发环境：返回详细错误
    if settings.ENVIRONMENT == "development":
        return JSONResponse(
            status_code=500,
            content={
                "error": str(exc),
                "type": type(exc).__name__,
                "traceback": traceback.format_exc()
            }
        )

    # 生产环境：返回友好提示
    return JSONResponse(
        status_code=500,
        content={
            "error": "服务暂时不可用，请稍后重试",
            "error_code": "INTERNAL_ERROR"
        }
    )
```

---

### 权衡3：自动化 vs 人工干预

**自动化：** 重试、熔断 → 自动恢复
**人工干预：** 告警、日志 → 人工修复

**平衡：**
- 临时性错误：自动恢复（重试、熔断）
- 永久性错误：人工干预（告警、修复）

---

## 总结

**错误处理策略的本质：**
1. **预测错误**：知道哪里可能出错
2. **分类错误**：区分临时性和永久性
3. **响应错误**：重试、熔断、降级
4. **记录错误**：日志、监控、告警

**核心价值：**
1. **可靠性**：临时故障不会导致永久失败
2. **用户体验**：友好的错误提示
3. **可维护性**：快速定位和修复问题

**从第一性原理推导：**
- 分布式系统 → 不确定性 → 需要错误处理
- 临时性错误 → 重试（指数退避）
- 持续失败 → 熔断（防止雪崩）
- 永久性错误 → 快速失败（不浪费资源）
- 所有错误 → 记录（可观测性）

**一句话：** 错误处理策略是通过系统化的方法应对分布式系统的不确定性，保障服务的可靠性、用户体验和可维护性。
