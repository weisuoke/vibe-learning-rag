# 核心概念2：混合检索

> 如何同时检索多个向量字段并获取结果

---

## 什么是混合检索？

**一句话定义：** 在单次查询中同时对多个向量字段执行 ANN 检索，并返回各自的 Top-K 结果。

```python
from pymilvus import AnnSearchRequest, RRFRanker

# 定义多个检索请求
req1 = AnnSearchRequest(
    data=[text_embedding],      # 查询向量1
    anns_field="text_vector",   # 检索字段1
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=10
)

req2 = AnnSearchRequest(
    data=[image_embedding],     # 查询向量2
    anns_field="image_vector",  # 检索字段2
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=10
)

# 混合检索（Milvus 2.4+）
results = collection.hybrid_search(
    reqs=[req1, req2],          # 多个检索请求
    rerank=RRFRanker(),         # 融合算法
    limit=5,                    # 最终返回Top 5
    output_fields=["text", "image_url"]
)
```

---

## 核心特性

### 特性1：并行执行多个 ANN 检索

**含义：** 多个向量字段的检索是并行执行的，不是串行

```python
# 内部执行流程（简化）
def hybrid_search(reqs, rerank, limit):
    # 1. 并行执行多个 ANN 检索
    results_list = []
    for req in reqs:
        # 每个请求独立执行 ANN 检索
        result = ann_search(
            field=req.anns_field,
            query=req.data,
            metric=req.param["metric_type"],
            limit=req.limit
        )
        results_list.append(result)

    # 2. 融合结果
    merged_results = rerank.merge(results_list)

    # 3. 返回 Top-K
    return merged_results[:limit]
```

**性能优势：**
- 并行执行，总延迟 ≈ max(单个检索延迟)
- 而非串行执行的 sum(单个检索延迟)

**示例：**
```python
# 假设单个检索延迟：
# - text_vector 检索：30ms
# - image_vector 检索：40ms

# 并行执行：总延迟 ≈ 40ms（取最大值）
# 串行执行：总延迟 ≈ 70ms（求和）

# 性能提升：(70-40)/70 = 42.8%
```

---

### 特性2：每个检索请求独立配置

**含义：** 每个 `AnnSearchRequest` 可以有不同的参数

```python
from pymilvus import AnnSearchRequest

# 请求1：text_vector，使用 COSINE，ef=100
req1 = AnnSearchRequest(
    data=[text_embedding],
    anns_field="text_vector",
    param={
        "metric_type": "COSINE",
        "params": {"ef": 100}  # HNSW 参数
    },
    limit=20  # 召回20个候选
)

# 请求2：image_vector，使用 L2，nprobe=10
req2 = AnnSearchRequest(
    data=[image_embedding],
    anns_field="image_vector",
    param={
        "metric_type": "L2",
        "params": {"nprobe": 10}  # IVF 参数
    },
    limit=10  # 召回10个候选
)

# 请求3：title_vector，使用 IP，ef=200
req3 = AnnSearchRequest(
    data=[title_embedding],
    anns_field="title_vector",
    param={
        "metric_type": "IP",
        "params": {"ef": 200}
    },
    limit=15  # 召回15个候选
)

# 混合检索
results = collection.hybrid_search(
    reqs=[req1, req2, req3],
    rerank=RRFRanker(),
    limit=5
)
```

**灵活性：**
- 不同字段可以使用不同的度量方式
- 不同字段可以有不同的召回数量
- 不同字段可以有不同的索引参数

---

### 特性3：支持标量过滤

**含义：** 可以在混合检索中添加标量过滤条件

```python
# 场景：电商搜索 "红色连衣裙，价格<1000，有货"

req1 = AnnSearchRequest(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=50
)

req2 = AnnSearchRequest(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=50
)

# 添加标量过滤
results = collection.hybrid_search(
    reqs=[req1, req2],
    rerank=RRFRanker(),
    limit=10,
    # 硬约束：价格、库存、类别
    expr="price < 1000 and stock > 0 and category == 'dress'"
)

# 结果：
# - 语义上相似（红色、连衣裙）
# - 满足硬约束（价格<1000、有货、类别是dress）
```

**执行顺序：**
```
1. 并行执行多个 ANN 检索（召回候选）
   ↓
2. 应用标量过滤（过滤不符合条件的候选）
   ↓
3. 融合剩余候选
   ↓
4. 返回 Top-K
```

---

## 在实际应用中的使用

### 场景1：文档问答（文本 + 图表）

```python
from pymilvus import Collection, AnnSearchRequest, RRFRanker
from openai import OpenAI

client = OpenAI()
collection = Collection("doc_qa")
collection.load()

# 用户问题
user_query = "如何安装 Python？"

# 1. 生成查询向量
def get_text_embedding(text):
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

text_embedding = get_text_embedding(user_query)

# 2. 定义检索请求
# 请求1：检索文本内容
text_req = AnnSearchRequest(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=20  # 召回20个文本候选
)

# 请求2：检索图表（使用相同的文本向量，因为图表有文字描述）
image_req = AnnSearchRequest(
    data=[text_embedding],  # 复用文本向量
    anns_field="image_vector",
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=10  # 召回10个图表候选
)

# 3. 混合检索
results = collection.hybrid_search(
    reqs=[text_req, image_req],
    rerank=RRFRanker(),
    limit=3,  # 最终返回Top 3
    output_fields=["content", "image_url"]
)

# 4. 构建 RAG 上下文
context_parts = []
for hit in results[0]:
    content = hit.entity.get("content")
    image_url = hit.entity.get("image_url")

    context_parts.append(f"文本：{content}")
    if image_url:
        context_parts.append(f"图表：{image_url}")

context = "\n\n".join(context_parts)

# 5. 调用 LLM 生成答案
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "你是一个技术文档助手"},
        {"role": "user", "content": f"根据以下内容回答：{user_query}\n\n{context}"}
    ]
)

answer = response.choices[0].message.content
print(f"答案：{answer}")
```

---

### 场景2：电商搜索（文本 + 图片）

```python
from pymilvus import Collection, AnnSearchRequest, RRFRanker
import clip
import torch
from PIL import Image

collection = Collection("products")
collection.load()

# 加载 CLIP 模型
clip_model, preprocess = clip.load("ViT-B/32")

# 用户输入
user_text = "红色连衣裙"
user_image_path = "user_sketch.jpg"  # 用户上传的手绘草图

# 1. 生成查询向量
def get_text_embedding(text):
    # 使用 OpenAI Embedding
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def get_image_embedding(image_path):
    # 使用 CLIP Embedding
    image = preprocess(Image.open(image_path)).unsqueeze(0)
    with torch.no_grad():
        features = clip_model.encode_image(image)
    return features.squeeze().tolist()

text_embedding = get_text_embedding(user_text)
image_embedding = get_image_embedding(user_image_path)

# 2. 定义检索请求
desc_req = AnnSearchRequest(
    data=[text_embedding],
    anns_field="desc_vector",
    param={"metric_type": "COSINE"},
    limit=30
)

image_req = AnnSearchRequest(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=30
)

# 3. 混合检索 + 标量过滤
results = collection.hybrid_search(
    reqs=[desc_req, image_req],
    rerank=RRFRanker(),
    limit=10,
    expr="price < 500 and stock > 0",  # 价格<500，有货
    output_fields=["name", "description", "price", "image_url"]
)

# 4. 展示结果
print("搜索结果：")
for i, hit in enumerate(results[0], 1):
    print(f"{i}. {hit.entity.get('name')}")
    print(f"   价格：¥{hit.entity.get('price')}")
    print(f"   描述：{hit.entity.get('description')}")
    print(f"   图片：{hit.entity.get('image_url')}")
    print()
```

---

### 场景3：多语言检索（中文 + 英文）

```python
from pymilvus import Collection, AnnSearchRequest, RRFRanker

collection = Collection("multilingual_docs")
collection.load()

# 用户问题（中文）
user_query = "如何使用 Python 读取 CSV 文件？"

# 1. 生成查询向量
# 使用多语言 Embedding 模型（如 multilingual-e5）
def get_multilingual_embedding(text):
    # 假设使用 sentence-transformers
    from sentence_transformers import SentenceTransformer
    model = SentenceTransformer('intfloat/multilingual-e5-large')
    return model.encode(text).tolist()

query_embedding = get_multilingual_embedding(user_query)

# 2. 定义检索请求
# 请求1：检索中文文档
zh_req = AnnSearchRequest(
    data=[query_embedding],
    anns_field="zh_vector",
    param={"metric_type": "COSINE"},
    limit=20
)

# 请求2：检索英文文档
en_req = AnnSearchRequest(
    data=[query_embedding],
    anns_field="en_vector",
    param={"metric_type": "COSINE"},
    limit=20
)

# 3. 混合检索
results = collection.hybrid_search(
    reqs=[zh_req, en_req],
    rerank=RRFRanker(),
    limit=5,
    output_fields=["content", "language"]
)

# 4. 展示结果（中英文混合）
for hit in results[0]:
    lang = hit.entity.get("language")
    content = hit.entity.get("content")
    print(f"[{lang}] {content[:100]}...")
```

---

## 兼容旧版本：手动实现混合检索

**适用场景：** Milvus < 2.4，不支持 `hybrid_search()`

```python
from pymilvus import Collection

collection = Collection("multi_vector_demo")
collection.load()

# 1. 分别检索多个向量字段
results1 = collection.search(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=20,
    output_fields=["id", "text"]
)

results2 = collection.search(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE", "params": {"ef": 100}},
    limit=20,
    output_fields=["id", "text"]
)

# 2. 手动融合结果（RRF）
def rrf_fusion(results_list, k=60):
    """RRF 融合算法"""
    scores = {}

    for results in results_list:
        for rank, hit in enumerate(results[0]):
            doc_id = hit.id
            # RRF 公式：1 / (k + rank)
            scores[doc_id] = scores.get(doc_id, 0) + 1 / (k + rank + 1)

    # 按分数排序
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_docs

# 3. 融合
final_results = rrf_fusion([results1, results2], k=60)

# 4. 获取 Top 5
top5_ids = [doc_id for doc_id, score in final_results[:5]]

# 5. 查询完整信息
final_docs = collection.query(
    expr=f"id in {top5_ids}",
    output_fields=["id", "text", "image_url"]
)

print("融合后的 Top 5：")
for doc in final_docs:
    print(f"ID: {doc['id']}, Text: {doc['text']}")
```

---

## 性能优化

### 优化1：调整召回数量（limit）

**原则：** 召回数量越多，融合效果越好，但性能越差

```python
# 场景1：高性能要求（实时搜索）
req1 = AnnSearchRequest(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=10  # 少召回，快速返回
)

req2 = AnnSearchRequest(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

results = collection.hybrid_search(
    reqs=[req1, req2],
    rerank=RRFRanker(),
    limit=5
)
# 延迟：~30ms

# ---

# 场景2：高准确率要求（离线分析）
req1 = AnnSearchRequest(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=100  # 多召回，提升准确率
)

req2 = AnnSearchRequest(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=100
)

results = collection.hybrid_search(
    reqs=[req1, req2],
    rerank=RRFRanker(),
    limit=10
)
# 延迟：~80ms，但准确率更高
```

**推荐配置：**
| 场景 | 召回数量 | 最终返回 | 延迟 | 准确率 |
|------|---------|---------|------|--------|
| 实时搜索 | 10-20 | 5 | ~30ms | 中 |
| 通用场景 | 20-50 | 10 | ~50ms | 高 |
| 离线分析 | 50-100 | 20 | ~80ms | 很高 |

---

### 优化2：使用相同的度量方式

**原则：** 统一度量方式可以简化融合逻辑

```python
# ✅ 推荐：统一使用 COSINE
req1 = AnnSearchRequest(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},  # 统一
    limit=20
)

req2 = AnnSearchRequest(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},  # 统一
    limit=20
)

# 可以使用加权平均（更快）
results = weighted_fusion([results1, results2], weights=[0.6, 0.4])

# ⚠️ 不推荐：混合度量方式
req1 = AnnSearchRequest(
    param={"metric_type": "COSINE"}  # 0-1
)

req2 = AnnSearchRequest(
    param={"metric_type": "L2"}  # 0-∞
)

# 必须使用 RRF（只看排名）
results = collection.hybrid_search(reqs=[req1, req2], rerank=RRFRanker())
```

---

### 优化3：预先过滤（标量过滤）

**原则：** 先用标量过滤缩小候选集，再做向量检索

```python
# ✅ 推荐：先过滤再检索
results = collection.hybrid_search(
    reqs=[req1, req2],
    rerank=RRFRanker(),
    limit=10,
    expr="price < 1000 and stock > 0"  # 先过滤
)
# 只在符合条件的文档中检索，更快

# ❌ 不推荐：检索后再过滤
results = collection.hybrid_search(
    reqs=[req1, req2],
    rerank=RRFRanker(),
    limit=100  # 召回100个
)
# 手动过滤
filtered = [hit for hit in results[0] if hit.entity.get("price") < 1000]
# 浪费了检索不符合条件的文档的时间
```

---

## 常见问题

### Q1：混合检索的延迟是多少？

**答：** 延迟 ≈ max(单个检索延迟) + 融合开销

```python
# 示例
# text_vector 检索：30ms
# image_vector 检索：40ms
# RRF 融合：5ms

# 总延迟 ≈ 40ms + 5ms = 45ms
```

---

### Q2：可以混合检索超过2个向量字段吗？

**答：** 可以，但不推荐超过3个

```python
# ✅ 可以：3个向量字段
results = collection.hybrid_search(
    reqs=[req1, req2, req3],
    rerank=RRFRanker(),
    limit=5
)

# ⚠️ 不推荐：5个向量字段（性能差）
results = collection.hybrid_search(
    reqs=[req1, req2, req3, req4, req5],
    rerank=RRFRanker(),
    limit=5
)
# 延迟会显著增加
```

---

### Q3：如何调试混合检索？

**答：** 分别查看每个检索请求的结果

```python
# 1. 分别检索
results1 = collection.search(
    data=[text_embedding],
    anns_field="text_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

results2 = collection.search(
    data=[image_embedding],
    anns_field="image_vector",
    param={"metric_type": "COSINE"},
    limit=10
)

# 2. 查看各自的 Top 10
print("text_vector Top 10:")
for hit in results1[0]:
    print(f"  ID: {hit.id}, Score: {hit.distance}")

print("\nimage_vector Top 10:")
for hit in results2[0]:
    print(f"  ID: {hit.id}, Score: {hit.distance}")

# 3. 手动融合并对比
manual_fusion = rrf_fusion([results1, results2])
print("\n手动融合 Top 5:")
for doc_id, score in manual_fusion[:5]:
    print(f"  ID: {doc_id}, RRF Score: {score}")

# 4. 使用 hybrid_search 对比
results = collection.hybrid_search(
    reqs=[req1, req2],
    rerank=RRFRanker(),
    limit=5
)
print("\nhybrid_search Top 5:")
for hit in results[0]:
    print(f"  ID: {hit.id}")
```

---

## 总结

**混合检索的核心要点：**

1. **定义**：同时对多个向量字段执行 ANN 检索
2. **并行执行**：多个检索请求并行，延迟 ≈ max(单个延迟)
3. **独立配置**：每个请求可以有不同的参数
4. **支持过滤**：可以添加标量过滤条件
5. **性能优化**：调整召回数量、统一度量方式、预先过滤
6. **兼容性**：Milvus 2.4+ 原生支持，旧版本需手动实现

---

**继续学习：** [05_核心概念_加权融合.md](./05_核心概念_加权融合.md)
