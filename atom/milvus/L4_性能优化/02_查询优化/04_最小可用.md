# 最小可用

掌握以下内容，就能开始优化 Milvus 查询性能：

### 4.1 调整 top_k 参数（最常用）

**核心：** 只返回真正需要的结果数量

```python
from pymilvus import Collection

collection = Collection("documents")

# ❌ 错误：返回太多结果
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=1000  # 返回 1000 个结果，但实际只用前 10 个
)

# ✅ 正确：只返回需要的数量
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10  # 只返回 10 个结果
)

# 性能提升：
# - 计算量减少 99%（只计算 10 个而非 1000 个）
# - 网络传输减少 99%
# - 延迟降低 50%-80%
```

**在 RAG 中的应用：**
```python
# RAG 场景：文档问答
# 通常只需要 top 3-5 个最相关的文档片段

# ❌ 过度检索
chunks = vector_db.search(query_embedding, limit=100)  # 浪费
top_chunks = chunks[:5]  # 只用前 5 个

# ✅ 精准检索
chunks = vector_db.search(query_embedding, limit=5)  # 刚好够用
```

---

### 4.2 使用标量过滤减少搜索范围

**核心：** 先用标量字段过滤，再做向量检索

```python
# ❌ 错误：在全部数据中搜索
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10
)
# 搜索范围：1000 万条数据

# ✅ 正确：先过滤再搜索
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    expr="category == 'technology' and publish_date > '2024-01-01'"
)
# 搜索范围：10 万条数据（减少 99%）

# 性能提升：
# - 搜索范围减少 99%
# - 延迟降低 90%
# - 结果更精准（只在相关类别中搜索）
```

**在 RAG 中的应用：**
```python
# RAG 场景：多租户知识库
# 每个用户只能搜索自己的文档

# ❌ 搜索全部文档，再过滤
all_results = vector_db.search(query_embedding, limit=100)
user_results = [r for r in all_results if r.user_id == current_user_id]

# ✅ 先过滤用户，再搜索
user_results = vector_db.search(
    query_embedding,
    limit=10,
    expr=f"user_id == '{current_user_id}'"
)
```

---

### 4.3 使用批量查询提升吞吐量

**核心：** 一次查询多个向量，减少网络往返

```python
# ❌ 错误：逐个查询
for query_vector in query_vectors:  # 100 个查询
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10
    )
    process_results(results)
# 网络往返：100 次
# 总延迟：100 × 50ms = 5000ms

# ✅ 正确：批量查询
results = collection.search(
    data=query_vectors,  # 一次查询 100 个向量
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10
)
for result in results:
    process_results(result)
# 网络往返：1 次
# 总延迟：200ms

# 性能提升：
# - 网络往返减少 99%
# - 总延迟降低 96%（5000ms → 200ms）
# - 吞吐量提升 25 倍
```

**在 RAG 中的应用：**
```python
# RAG 场景：批量文档处理
# 需要为 100 个问题找到相关文档

# ❌ 逐个查询
answers = []
for question in questions:  # 100 个问题
    embedding = embed_model.encode(question)
    docs = vector_db.search(embedding, limit=5)
    answer = llm.generate(question, docs)
    answers.append(answer)
# 总时间：100 × 100ms = 10000ms

# ✅ 批量查询
embeddings = embed_model.encode_batch(questions)  # 批量编码
all_docs = vector_db.search(embeddings, limit=5)  # 批量检索
answers = llm.generate_batch(questions, all_docs)  # 批量生成
# 总时间：500ms（编码） + 200ms（检索） + 5000ms（生成） = 5700ms
# 提升：43% 的时间节省
```

---

### 4.4 只返回必要的字段

**核心：** 不返回向量字段，减少数据传输

```python
# ❌ 错误：返回所有字段（包括向量）
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    output_fields=["*"]  # 返回所有字段，包括 768 维向量
)
# 数据传输：10 × (768 × 4 bytes + 其他字段) ≈ 30KB

# ✅ 正确：只返回需要的字段
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    output_fields=["id", "title", "content"]  # 不返回向量
)
# 数据传输：10 × (其他字段) ≈ 2KB

# 性能提升：
# - 数据传输减少 93%
# - 网络延迟降低 50%
# - 内存占用减少 90%
```

**在 RAG 中的应用：**
```python
# RAG 场景：文档检索
# 只需要文档内容，不需要向量

# ❌ 返回向量（浪费）
results = vector_db.search(
    query_embedding,
    limit=5,
    output_fields=["id", "content", "embedding"]  # 不需要 embedding
)

# ✅ 只返回内容
results = vector_db.search(
    query_embedding,
    limit=5,
    output_fields=["id", "content"]  # 只返回需要的字段
)

# 传给 LLM 生成答案
context = "\n".join([r.content for r in results])
answer = llm.generate(query, context)
```

---

### 4.5 根据索引类型调整搜索参数

**核心：** 不同索引类型有不同的搜索参数

```python
# IVF 索引：调整 nprobe
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={
        "metric_type": "L2",
        "params": {"nprobe": 16}  # 搜索 16 个桶
    },
    limit=10
)

# HNSW 索引：调整 ef
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={
        "metric_type": "L2",
        "params": {"ef": 64}  # 搜索时的候选集大小
    },
    limit=10
)

# 参数选择原则：
# - nprobe/ef 越大 → 召回率越高，但延迟越高
# - nprobe/ef 越小 → 延迟越低，但召回率越低
# - 根据业务需求权衡：延迟要求 vs 召回率要求
```

**快速参考：**

| 索引类型 | 搜索参数 | 推荐值（100万数据） | 说明 |
|---------|---------|-------------------|------|
| IVF_FLAT | nprobe | 8-16 | 桶数量，越大越慢但越准 |
| IVF_SQ8 | nprobe | 8-16 | 同上 |
| IVF_PQ | nprobe | 16-32 | PQ 需要更多候选 |
| HNSW | ef | 32-64 | 候选集大小 |
| FLAT | 无 | - | 暴力搜索，无参数 |

---

## 这些知识足以：

**1. 立即优化现有查询**
- 调整 `limit` 参数，只返回需要的结果
- 添加标量过滤，减少搜索范围
- 使用批量查询，提升吞吐量

**2. 解决 80% 的性能问题**
- 延迟过高 → 降低 top_k，调整 nprobe/ef
- 吞吐量不足 → 使用批量查询
- 结果不精准 → 添加标量过滤

**3. 为 RAG 系统优化检索性能**
- 文档问答：top_k=3-5，添加时间/类别过滤
- 多租户：使用 user_id 过滤
- 批量处理：使用批量查询

**4. 为后续学习打基础**
- 理解查询优化的核心思路（减少计算量和传输量）
- 掌握基本的优化手段（参数、过滤、批量）
- 为深入学习索引调优、分布式优化做准备

---

## 快速实践检查清单

完成以下任务，验证你已掌握最小可用知识：

- [ ] 将一个查询的 `limit` 从 100 降低到 10，测量延迟变化
- [ ] 为一个查询添加标量过滤（如 `category == 'tech'`），测量性能提升
- [ ] 将 10 个单独的查询改为 1 个批量查询，测量吞吐量提升
- [ ] 移除 `output_fields` 中的向量字段，测量数据传输减少
- [ ] 调整 `nprobe` 或 `ef` 参数，观察延迟和召回率的权衡

---

## 下一步学习

掌握最小可用知识后，可以深入学习：

1. **核心概念**：详细理解 Search 参数、标量过滤、批量查询的原理
2. **双重类比**：通过类比加深理解
3. **反直觉点**：避免常见误区
4. **实战代码**：完整的优化示例
5. **化骨绵掌**：10 个知识卡片，全面掌握查询优化
