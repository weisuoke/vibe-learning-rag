# 07_å®æˆ˜ä»£ç _01_Cross-EncoderåŸºç¡€å®ç°

## åœºæ™¯è¯´æ˜

Cross-Encoderæ˜¯ReRankçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œé€šè¿‡å°†queryå’Œdocumentè”åˆç¼–ç å®ç°æ·±åº¦è¯­ä¹‰äº¤äº’ã€‚æœ¬æ–‡å±•ç¤ºå¦‚ä½•ä½¿ç”¨sentence-transformersåº“å’ŒBGE-reranker-v2-m3æ¨¡å‹å®ç°ç”Ÿäº§çº§çš„Cross-Encoderé‡æ’åºç³»ç»Ÿã€‚

**æ ¸å¿ƒä»·å€¼ï¼š**
- å¼€æºå…è´¹ï¼Œå¯è‡ªæ‰˜ç®¡éƒ¨ç½²
- ç²¾åº¦æå‡15-48%ï¼ˆç›¸æ¯”å‘é‡æ£€ç´¢ï¼‰
- æ”¯æŒä¸­è‹±æ–‡å¤šè¯­è¨€
- ä¸RAGç®¡é“æ— ç¼é›†æˆ

**é€‚ç”¨åœºæ™¯ï¼š**
- æ–‡æ¡£é—®ç­”ç³»ç»Ÿçš„ç²¾æ’
- æœç´¢ç»“æœè´¨é‡ä¼˜åŒ–
- çŸ¥è¯†åº“æ£€ç´¢å¢å¼º
- å¯¹è¯ç³»ç»Ÿä¸Šä¸‹æ–‡é€‰æ‹©

---

## å®Œæ•´å®ç°ä»£ç 

### 1. åŸºç¡€å®ç°ï¼š10è¡Œä»£ç ä¸Šæ‰‹

```python
"""
Cross-Encoderæœ€å°å¯ç”¨å®ç°
å±•ç¤ºæ ¸å¿ƒAPIä½¿ç”¨å’ŒåŸºæœ¬æµç¨‹
"""

from sentence_transformers import CrossEncoder
import numpy as np

# 1. åŠ è½½æ¨¡å‹ï¼ˆæ¨èBGE-reranker-v2-m3ï¼‰
reranker = CrossEncoder('BAAI/bge-reranker-v2-m3')

# 2. å‡†å¤‡æ•°æ®
query = "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
candidates = [
    "RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆä¸¤ä¸ªæ­¥éª¤",
    "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥",
    "Pythonæ˜¯ä¸€ç§æµè¡Œçš„ç¼–ç¨‹è¯­è¨€",
    "RAGé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºLLMçš„å›ç­”è´¨é‡",
    "å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢embedding"
]

# 3. è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
scores = reranker.predict([(query, doc) for doc in candidates])

# 4. æ’åºå¹¶è¿”å›Top-K
top_k = 3
ranked_indices = np.argsort(scores)[::-1][:top_k]

# 5. è¾“å‡ºç»“æœ
print(f"Query: {query}\n")
for rank, idx in enumerate(ranked_indices, 1):
    print(f"Rank {rank} [åˆ†æ•°: {scores[idx]:.4f}]")
    print(f"  {candidates[idx]}\n")
```

**é¢„æœŸè¾“å‡ºï¼š**
```
Query: ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ

Rank 1 [åˆ†æ•°: 0.9876]
  RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆä¸¤ä¸ªæ­¥éª¤

Rank 2 [åˆ†æ•°: 0.8543]
  RAGé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºLLMçš„å›ç­”è´¨é‡

Rank 3 [åˆ†æ•°: 0.3421]
  å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢embedding
```

---

### 2. å®Œæ•´RAGç®¡é“ï¼šå‘é‡æ£€ç´¢ + Cross-Encoderç²¾æ’

```python
"""
å®Œæ•´çš„ä¸¤é˜¶æ®µæ£€ç´¢ç®¡é“
åˆæ£€ï¼šå‘é‡æ£€ç´¢ï¼ˆå¿«é€Ÿå¬å›ï¼‰
ç²¾æ’ï¼šCross-Encoderï¼ˆé«˜ç²¾åº¦æ’åºï¼‰
"""

from sentence_transformers import CrossEncoder, SentenceTransformer
import chromadb
import numpy as np
from typing import List, Dict

class TwoStageRetriever:
    """ä¸¤é˜¶æ®µæ£€ç´¢å™¨ï¼šå‘é‡æ£€ç´¢ + ReRank"""

    def __init__(
        self,
        embedding_model_name: str = "BAAI/bge-small-zh-v1.5",
        reranker_model_name: str = "BAAI/bge-reranker-v2-m3",
        collection_name: str = "documents"
    ):
        # åˆå§‹åŒ–embeddingæ¨¡å‹ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
        self.embedding_model = SentenceTransformer(embedding_model_name)

        # åˆå§‹åŒ–rerankeræ¨¡å‹ï¼ˆç”¨äºç²¾æ’ï¼‰
        self.reranker = CrossEncoder(reranker_model_name)

        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        self.client = chromadb.Client()
        self.collection = self.client.create_collection(collection_name)

    def index_documents(self, documents: List[str]):
        """ç´¢å¼•æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"""
        # ç”Ÿæˆembeddings
        embeddings = self.embedding_model.encode(
            documents,
            show_progress_bar=True,
            convert_to_numpy=True
        )

        # å­˜å‚¨åˆ°ChromaDB
        self.collection.add(
            embeddings=embeddings.tolist(),
            documents=documents,
            ids=[f"doc_{i}" for i in range(len(documents))]
        )

        print(f"âœ… å·²ç´¢å¼• {len(documents)} ä¸ªæ–‡æ¡£")

    def search(
        self,
        query: str,
        initial_k: int = 50,
        top_k: int = 5
    ) -> List[Dict]:
        """
        ä¸¤é˜¶æ®µæ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            initial_k: åˆæ£€è¿”å›çš„å€™é€‰æ•°é‡
            top_k: æœ€ç»ˆè¿”å›çš„ç»“æœæ•°é‡

        Returns:
            æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        # é˜¶æ®µ1ï¼šå‘é‡æ£€ç´¢ï¼ˆå¿«é€Ÿå¬å›ï¼‰
        query_embedding = self.embedding_model.encode([query])
        initial_results = self.collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=initial_k
        )

        candidates = initial_results['documents'][0]
        candidate_ids = initial_results['ids'][0]

        print(f"ğŸ“Š åˆæ£€å¬å›: {len(candidates)} ä¸ªå€™é€‰æ–‡æ¡£")

        # é˜¶æ®µ2ï¼šCross-Encoderç²¾æ’
        pairs = [(query, doc) for doc in candidates]
        rerank_scores = self.reranker.predict(pairs)

        # æ’åº
        ranked_indices = np.argsort(rerank_scores)[::-1][:top_k]

        # æ„å»ºç»“æœ
        results = []
        for rank, idx in enumerate(ranked_indices, 1):
            results.append({
                'rank': rank,
                'document': candidates[idx],
                'doc_id': candidate_ids[idx],
                'rerank_score': float(rerank_scores[idx]),
                'initial_rank': idx + 1
            })

        print(f"âœ¨ ç²¾æ’å®Œæˆ: è¿”å›Top {top_k}")

        return results


# ä½¿ç”¨ç¤ºä¾‹
def main():
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = TwoStageRetriever()

    # å‡†å¤‡æ–‡æ¡£
    documents = [
        "RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºLLMçš„å›ç­”è´¨é‡",
        "å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢embeddingï¼Œæ”¯æŒè¯­ä¹‰æœç´¢",
        "Cross-Encoderé€šè¿‡è”åˆç¼–ç å®ç°æ·±åº¦è¯­ä¹‰äº¤äº’",
        "ReRankæ˜¯RAGç®¡é“ä¸­çš„å…³é”®ä¼˜åŒ–æ­¥éª¤ï¼Œå¯æ˜¾è‘—æå‡æ£€ç´¢ç²¾åº¦",
        "Pythonæ˜¯ä¸€ç§æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºAIå¼€å‘",
        "Transformeræ˜¯æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ¶æ„ï¼Œç”¨äºNLPä»»åŠ¡",
        "BERTæ˜¯åŸºäºTransformerçš„é¢„è®­ç»ƒæ¨¡å‹",
        "Embeddingå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º",
        "è¯­ä¹‰ç›¸ä¼¼åº¦è¡¡é‡ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰æ¥è¿‘ç¨‹åº¦",
        "BM25æ˜¯ä¼ ç»Ÿçš„å…³é”®è¯æ£€ç´¢ç®—æ³•"
    ]

    # ç´¢å¼•æ–‡æ¡£
    retriever.index_documents(documents)

    # æ‰§è¡Œæ£€ç´¢
    query = "å¦‚ä½•æå‡RAGç³»ç»Ÿçš„æ£€ç´¢è´¨é‡ï¼Ÿ"
    results = retriever.search(
        query=query,
        initial_k=10,
        top_k=3
    )

    # æ‰“å°ç»“æœ
    print(f"\nğŸ” Query: {query}\n")
    for result in results:
        print(f"Rank {result['rank']} (åˆæ£€æ’å: {result['initial_rank']})")
        print(f"  åˆ†æ•°: {result['rerank_score']:.4f}")
        print(f"  æ–‡æ¡£: {result['document']}\n")


if __name__ == "__main__":
    main()
```

---

### 3. æ‰¹å¤„ç†ä¼˜åŒ–ï¼šé«˜æ•ˆå¤„ç†å¤§é‡æ–‡æ¡£

```python
"""
æ‰¹å¤„ç†ä¼˜åŒ–å®ç°
é€šè¿‡æ‰¹é‡å¤„ç†æå‡æ¨ç†é€Ÿåº¦5-10å€
"""

from sentence_transformers import CrossEncoder
import numpy as np
from typing import List, Tuple
import time

class BatchReranker:
    """æ”¯æŒæ‰¹å¤„ç†çš„Reranker"""

    def __init__(
        self,
        model_name: str = "BAAI/bge-reranker-v2-m3",
        batch_size: int = 32,
        device: str = "cpu"
    ):
        self.reranker = CrossEncoder(model_name, device=device)
        self.batch_size = batch_size
        self.device = device

    def rerank(
        self,
        query: str,
        documents: List[str],
        top_k: int = 10
    ) -> List[Tuple[int, float, str]]:
        """
        æ‰¹å¤„ç†rerank

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡

        Returns:
            (åŸå§‹ç´¢å¼•, åˆ†æ•°, æ–‡æ¡£) çš„åˆ—è¡¨
        """
        # æ„å»ºquery-documentå¯¹
        pairs = [(query, doc) for doc in documents]

        # æ‰¹å¤„ç†è®¡ç®—åˆ†æ•°
        scores = self.reranker.predict(
            pairs,
            batch_size=self.batch_size,
            show_progress_bar=len(documents) > 100
        )

        # æ’åº
        ranked_indices = np.argsort(scores)[::-1][:top_k]

        # è¿”å›ç»“æœ
        results = [
            (int(idx), float(scores[idx]), documents[idx])
            for idx in ranked_indices
        ]

        return results

    def benchmark(self, num_documents: int = 100):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        query = "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
        documents = [f"è¿™æ˜¯ç¬¬{i}ä¸ªæµ‹è¯•æ–‡æ¡£" for i in range(num_documents)]

        # æµ‹è¯•æ‰¹å¤„ç†
        start = time.time()
        results = self.rerank(query, documents, top_k=10)
        batch_time = time.time() - start

        print(f"ğŸ“Š æ‰¹å¤„ç†æ€§èƒ½æµ‹è¯•")
        print(f"  æ–‡æ¡£æ•°é‡: {num_documents}")
        print(f"  æ‰¹å¤„ç†å¤§å°: {self.batch_size}")
        print(f"  è®¾å¤‡: {self.device}")
        print(f"  æ€»è€—æ—¶: {batch_time:.2f}s")
        print(f"  å¹³å‡å»¶è¿Ÿ: {batch_time/num_documents*1000:.2f}ms/doc")
        print(f"  ååé‡: {num_documents/batch_time:.1f} docs/s")


# ä½¿ç”¨ç¤ºä¾‹
def main():
    # CPUæ‰¹å¤„ç†
    print("=== CPUæ‰¹å¤„ç† ===")
    cpu_reranker = BatchReranker(
        batch_size=16,
        device="cpu"
    )
    cpu_reranker.benchmark(num_documents=50)

    # GPUæ‰¹å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        print("\n=== GPUæ‰¹å¤„ç† ===")
        gpu_reranker = BatchReranker(
            batch_size=32,
            device="cuda"
        )
        gpu_reranker.benchmark(num_documents=50)
    except Exception as e:
        print(f"GPUä¸å¯ç”¨: {e}")


if __name__ == "__main__":
    main()
```

---

### 4. GPUåŠ é€Ÿï¼š10å€æ€§èƒ½æå‡

```python
"""
GPUåŠ é€Ÿå®ç°
å±•ç¤ºCPU vs GPUæ€§èƒ½å¯¹æ¯”
"""

from sentence_transformers import CrossEncoder
import numpy as np
import time
import torch

class GPUAcceleratedReranker:
    """GPUåŠ é€Ÿçš„Reranker"""

    def __init__(self, model_name: str = "BAAI/bge-reranker-v2-m3"):
        # æ£€æµ‹GPUå¯ç”¨æ€§
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")

        if self.device == "cuda":
            print(f"   GPUå‹å·: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")

        # åŠ è½½æ¨¡å‹åˆ°GPU
        self.reranker = CrossEncoder(model_name, device=self.device)

    def rerank_with_timing(
        self,
        query: str,
        documents: List[str],
        batch_size: int = 32
    ):
        """å¸¦è®¡æ—¶çš„rerank"""
        pairs = [(query, doc) for doc in documents]

        start = time.time()
        scores = self.reranker.predict(pairs, batch_size=batch_size)
        elapsed = time.time() - start

        return scores, elapsed

    def compare_cpu_gpu(self, num_documents: int = 100):
        """å¯¹æ¯”CPUå’ŒGPUæ€§èƒ½"""
        query = "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
        documents = [
            f"è¿™æ˜¯å…³äºRAGæŠ€æœ¯çš„ç¬¬{i}ä¸ªæ–‡æ¡£ï¼ŒåŒ…å«äº†è¯¦ç»†çš„æŠ€æœ¯è¯´æ˜"
            for i in range(num_documents)
        ]

        results = {}

        # CPUæµ‹è¯•
        print("\nğŸ“Š CPUæ€§èƒ½æµ‹è¯•...")
        cpu_reranker = CrossEncoder(
            'BAAI/bge-reranker-v2-m3',
            device='cpu'
        )
        pairs = [(query, doc) for doc in documents]

        start = time.time()
        cpu_scores = cpu_reranker.predict(pairs, batch_size=16)
        cpu_time = time.time() - start

        results['cpu'] = {
            'time': cpu_time,
            'throughput': num_documents / cpu_time
        }

        # GPUæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            print("ğŸ“Š GPUæ€§èƒ½æµ‹è¯•...")
            gpu_reranker = CrossEncoder(
                'BAAI/bge-reranker-v2-m3',
                device='cuda'
            )

            # é¢„çƒ­
            _ = gpu_reranker.predict(pairs[:10], batch_size=32)

            start = time.time()
            gpu_scores = gpu_reranker.predict(pairs, batch_size=32)
            gpu_time = time.time() - start

            results['gpu'] = {
                'time': gpu_time,
                'throughput': num_documents / gpu_time
            }

        # æ‰“å°å¯¹æ¯”
        print(f"\n{'='*50}")
        print(f"æ€§èƒ½å¯¹æ¯” ({num_documents}ä¸ªæ–‡æ¡£)")
        print(f"{'='*50}")

        print(f"\nCPU:")
        print(f"  è€—æ—¶: {results['cpu']['time']:.2f}s")
        print(f"  ååé‡: {results['cpu']['throughput']:.1f} docs/s")

        if 'gpu' in results:
            print(f"\nGPU:")
            print(f"  è€—æ—¶: {results['gpu']['time']:.2f}s")
            print(f"  ååé‡: {results['gpu']['throughput']:.1f} docs/s")

            speedup = results['cpu']['time'] / results['gpu']['time']
            print(f"\nğŸš€ åŠ é€Ÿæ¯”: {speedup:.1f}x")


# ä½¿ç”¨ç¤ºä¾‹
def main():
    reranker = GPUAcceleratedReranker()
    reranker.compare_cpu_gpu(num_documents=100)


if __name__ == "__main__":
    main()
```

---

## ä»£ç è¯´æ˜

### æ ¸å¿ƒç»„ä»¶

1. **æ¨¡å‹åŠ è½½**
   ```python
   reranker = CrossEncoder('BAAI/bge-reranker-v2-m3')
   ```
   - è‡ªåŠ¨ä»HuggingFaceä¸‹è½½æ¨¡å‹ï¼ˆ~600MBï¼‰
   - é¦–æ¬¡è¿è¡Œéœ€è¦ç½‘ç»œè¿æ¥
   - æ¨¡å‹ç¼“å­˜åœ¨`~/.cache/huggingface/`

2. **è¾“å…¥æ ¼å¼**
   ```python
   pairs = [(query, doc) for doc in candidates]
   ```
   - æ¯ä¸ªå…ƒç´ æ˜¯(query, document)å…ƒç»„
   - æ¨¡å‹å†…éƒ¨ä¼šæ‹¼æ¥ä¸º`[CLS] query [SEP] doc [SEP]`

3. **åˆ†æ•°è®¡ç®—**
   ```python
   scores = reranker.predict(pairs, batch_size=32)
   ```
   - è¿”å›numpyæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ç›¸å…³æ€§åˆ†æ•°
   - åˆ†æ•°èŒƒå›´é€šå¸¸åœ¨[-10, 10]ï¼Œè¶Šé«˜è¶Šç›¸å…³
   - å¯é€šè¿‡sigmoidå½’ä¸€åŒ–åˆ°[0, 1]

4. **æ‰¹å¤„ç†ä¼˜åŒ–**
   - `batch_size=32`ï¼šGPUæ¨èå€¼
   - `batch_size=16`ï¼šCPUæ¨èå€¼
   - æ‰¹å¤„ç†å¯æå‡5-10å€é€Ÿåº¦

---

## è¿è¡Œç¤ºä¾‹

### ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install sentence-transformers chromadb numpy torch

# éªŒè¯å®‰è£…
python -c "from sentence_transformers import CrossEncoder; print('âœ… å®‰è£…æˆåŠŸ')"
```

### æ‰§è¡Œä»£ç 

```bash
# åŸºç¡€å®ç°
python 01_basic_cross_encoder.py

# å®Œæ•´RAGç®¡é“
python 02_two_stage_retriever.py

# æ‰¹å¤„ç†ä¼˜åŒ–
python 03_batch_reranker.py

# GPUåŠ é€Ÿ
python 04_gpu_accelerated.py
```

### é¢„æœŸè¾“å‡º

```
ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: cuda
   GPUå‹å·: NVIDIA GeForce RTX 3090
   æ˜¾å­˜: 24.0GB

ğŸ“Š åˆæ£€å¬å›: 50 ä¸ªå€™é€‰æ–‡æ¡£
âœ¨ ç²¾æ’å®Œæˆ: è¿”å›Top 5

ğŸ” Query: å¦‚ä½•æå‡RAGç³»ç»Ÿçš„æ£€ç´¢è´¨é‡ï¼Ÿ

Rank 1 (åˆæ£€æ’å: 4)
  åˆ†æ•°: 0.9876
  æ–‡æ¡£: ReRankæ˜¯RAGç®¡é“ä¸­çš„å…³é”®ä¼˜åŒ–æ­¥éª¤ï¼Œå¯æ˜¾è‘—æå‡æ£€ç´¢ç²¾åº¦

Rank 2 (åˆæ£€æ’å: 1)
  åˆ†æ•°: 0.9234
  æ–‡æ¡£: RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºLLMçš„å›ç­”è´¨é‡

Rank 3 (åˆæ£€æ’å: 3)
  åˆ†æ•°: 0.8765
  æ–‡æ¡£: Cross-Encoderé€šè¿‡è”åˆç¼–ç å®ç°æ·±åº¦è¯­ä¹‰äº¤äº’
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. å»¶è¿Ÿä¼˜åŒ–

| ä¼˜åŒ–ç­–ç•¥ | å»¶è¿Ÿæ”¹å–„ | å®ç°éš¾åº¦ |
|---------|---------|---------|
| ä½¿ç”¨GPU | 10x | ä½ |
| æ‰¹å¤„ç† | 5x | ä½ |
| å‡å°‘å€™é€‰é›† | 2x | ä½ |
| æ¨¡å‹é‡åŒ– | 1.5x | ä¸­ |
| ONNXä¼˜åŒ– | 2x | é«˜ |

**æ¨èé…ç½®ï¼š**
```python
# ç”Ÿäº§ç¯å¢ƒæ¨è
reranker = CrossEncoder(
    'BAAI/bge-reranker-v2-m3',
    device='cuda',          # ä½¿ç”¨GPU
    max_length=512          # é™åˆ¶æœ€å¤§é•¿åº¦
)

scores = reranker.predict(
    pairs,
    batch_size=32,          # GPUæ‰¹å¤„ç†
    show_progress_bar=False # å…³é—­è¿›åº¦æ¡
)
```

### 2. æˆæœ¬ä¼˜åŒ–

```python
# é™ä½æˆæœ¬çš„ç­–ç•¥
initial_k = 50  # å‡å°‘å€™é€‰é›†ï¼ˆvs 100ï¼‰
top_k = 5       # å‡å°‘è¿”å›ç»“æœï¼ˆvs 10ï¼‰

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
reranker = CrossEncoder('BAAI/bge-reranker-base')  # vs v2-m3
```

### 3. è´¨é‡ä¼˜åŒ–

```python
# æå‡è´¨é‡çš„ç­–ç•¥
initial_k = 100  # å¢åŠ å€™é€‰é›†
top_k = 10       # å¢åŠ è¿”å›ç»“æœ

# ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
reranker = CrossEncoder('BAAI/bge-reranker-large')  # vs v2-m3
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†é•¿æ–‡æ¡£ï¼Ÿ

**é—®é¢˜ï¼š** Cross-Encoderæœ‰æœ€å¤§é•¿åº¦é™åˆ¶ï¼ˆ512 tokensï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ1ï¼šæˆªæ–­ï¼ˆç®€å•ä½†å¯èƒ½ä¸¢å¤±ä¿¡æ¯ï¼‰
reranker = CrossEncoder('BAAI/bge-reranker-v2-m3', max_length=512)

# æ–¹æ¡ˆ2ï¼šæ»‘åŠ¨çª—å£ï¼ˆæ›´å‡†ç¡®ï¼‰
def rerank_long_doc(query, doc, window_size=400, stride=200):
    chunks = split_with_overlap(doc, window_size, stride)
    scores = reranker.predict([(query, chunk) for chunk in chunks])
    return max(scores)  # å–æœ€é«˜åˆ†
```

### Q2: CPUæ¨ç†å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. å‡å°‘å€™é€‰é›†å¤§å°ï¼ˆ50 â†’ 20ï¼‰
2. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆv2-m3 â†’ baseï¼‰
3. è€ƒè™‘ä½¿ç”¨GPUæˆ–äº‘ç«¯API

### Q3: å¦‚ä½•è¯„ä¼°ReRankæ•ˆæœï¼Ÿ

```python
from sklearn.metrics import ndcg_score

# å‡†å¤‡æµ‹è¯•æ•°æ®
ground_truth = [1, 0, 1, 0, 0]  # ç›¸å…³æ€§æ ‡ç­¾
initial_scores = [0.8, 0.7, 0.6, 0.5, 0.4]  # åˆæ£€åˆ†æ•°
rerank_scores = [0.95, 0.3, 0.9, 0.2, 0.1]  # rerankåˆ†æ•°

# è®¡ç®—NDCG@5
ndcg_initial = ndcg_score([ground_truth], [initial_scores])
ndcg_rerank = ndcg_score([ground_truth], [rerank_scores])

print(f"NDCG@5 æå‡: {ndcg_initial:.4f} â†’ {ndcg_rerank:.4f}")
print(f"ç›¸å¯¹æå‡: {(ndcg_rerank-ndcg_initial)/ndcg_initial*100:.1f}%")
```

### Q4: å¦‚ä½•é€‰æ‹©initial_kå’Œtop_kï¼Ÿ

**2026å¹´æœ€ä½³å®è·µï¼š**

| åœºæ™¯ | initial_k | top_k | åŸå›  |
|------|-----------|-------|------|
| å®æ—¶é—®ç­” | 50 | 5 | å¹³è¡¡å»¶è¿Ÿå’Œç²¾åº¦ |
| æ–‡æ¡£æ£€ç´¢ | 100 | 10 | æ›´é«˜å¬å›ç‡ |
| å¿«é€Ÿé¢„è§ˆ | 20 | 3 | æœ€ä½å»¶è¿Ÿ |
| æ·±åº¦åˆ†æ | 200 | 20 | æœ€é«˜ç²¾åº¦ |

---

## å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£
- [BGE Reranker v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3) - HuggingFaceæ¨¡å‹é¡µ
- [Sentence-Transformers Cross-Encoders](https://sbert.net/docs/cross_encoder/usage/usage.html) - å®˜æ–¹ä½¿ç”¨æŒ‡å—
- [FlagEmbedding GitHub](https://github.com/FlagOpen/FlagEmbedding) - å®˜æ–¹å®ç°ä»£ç 

### æŠ€æœ¯æ–‡ç« 
- [How to Build Cross-Encoder Re-Ranking](https://oneuptime.com/blog/post/2026-01-30-cross-encoder-reranking/view) - 2026å¹´å®è·µæŒ‡å—
- [Training and Finetuning Reranker Models](https://huggingface.co/blog/train-reranker) - HuggingFaceæ•™ç¨‹
- [Speeding up Inference](https://sbert.net/docs/cross_encoder/usage/efficiency.html) - æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### æ€§èƒ½åŸºå‡†
- [Ultimate Guide to Choosing the Best Reranking Model in 2026](https://www.zeroentropy.dev/articles/ultimate-guide-to-choosing-the-best-reranking-model-in-2025) - æ¨¡å‹å¯¹æ¯”
- [Speed Showdown for RAG Reranker Performance](https://medium.com/@xiweizhou/speed-showdown-reranker-1f7987400077) - æ€§èƒ½æµ‹è¯•

---

**ç‰ˆæœ¬ï¼š** v1.0 (2026å¹´æ ‡å‡†)
**æœ€åæ›´æ–°ï¼š** 2026-02-16
**ä»£ç æµ‹è¯•ï¼š** Python 3.13 + sentence-transformers 3.x + torch 2.x
**æ¨èæ¨¡å‹ï¼š** BAAI/bge-reranker-v2-m3
