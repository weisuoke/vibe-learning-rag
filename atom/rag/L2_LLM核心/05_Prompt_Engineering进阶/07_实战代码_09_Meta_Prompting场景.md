# å®æˆ˜ä»£ç ï¼šMeta Prompting åœºæ™¯

## åœºæ™¯æè¿°

**ç›®æ ‡ï¼š** ä½¿ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ– Promptï¼Œæå‡ Prompt å·¥ç¨‹æ•ˆç‡

**æŠ€æœ¯æ ˆï¼š** Python 3.13+, OpenAI API, ChromaDB

**éš¾åº¦ï¼š** é«˜çº§

**æ¥æºï¼š** åŸºäº [Prompt Engineering Basics 2026](https://medium.com/@mjgmario/prompt-engineering-basics-2026-93aba4dc32b1) å’Œ [Complete Guide to Meta Prompting](https://www.prompthub.us/blog/a-complete-guide-to-meta-prompting) çš„æœ€ä½³å®è·µ

**æ ¸å¿ƒæ€æƒ³ï¼š** Meta Prompting æ˜¯"ç”¨ Prompt ç”Ÿæˆ Prompt"çš„æŠ€æœ¯ã€‚é€šè¿‡è®© LLM ç†è§£ä»»åŠ¡éœ€æ±‚ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–çš„ Promptï¼Œæˆ–è€…è¿­ä»£æ”¹è¿›ç°æœ‰ Promptï¼Œå¤§å¹…æå‡ Prompt å·¥ç¨‹çš„æ•ˆç‡å’Œè´¨é‡ã€‚

---

## ç¯å¢ƒå‡†å¤‡

```bash
# ç¡®ä¿å·²å®‰è£…ä¾èµ–
uv sync

# æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate

# è®¾ç½® API Key
export OPENAI_API_KEY="your_key_here"
```

---

## å®Œæ•´ä»£ç 

```python
"""
Meta Prompting å®æˆ˜ç¤ºä¾‹
æ¼”ç¤ºï¼šä½¿ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ– Prompt

æ¥æºï¼šåŸºäº 2026 å¹´ Meta Prompting æœ€ä½³å®è·µ
"""

import os
from typing import List, Dict, Any, Optional
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ============================================
# Meta Prompting æ ¸å¿ƒå®ç°
# ============================================

class MetaPrompter:
    """Meta Prompting å®ç°"""

    def __init__(self, model: str = "gpt-4o-mini"):
        """
        åˆå§‹åŒ– Meta Prompter

        Args:
            model: ä½¿ç”¨çš„æ¨¡å‹
        """
        self.model = model
        self.client = client

    def generate_prompt(
        self,
        task_description: str,
        examples: Optional[List[Dict[str, str]]] = None,
        constraints: Optional[List[str]] = None
    ) -> str:
        """
        æ ¹æ®ä»»åŠ¡æè¿°ç”Ÿæˆä¼˜åŒ–çš„ Prompt

        Args:
            task_description: ä»»åŠ¡æè¿°
            examples: ç¤ºä¾‹è¾“å…¥è¾“å‡ºå¯¹
            constraints: çº¦æŸæ¡ä»¶

        Returns:
            ç”Ÿæˆçš„ Prompt
        """
        # æ„å»º Meta Prompt
        meta_prompt = f"""ä½ æ˜¯ä¸€ä¸ª Prompt å·¥ç¨‹ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„ Promptã€‚

ä»»åŠ¡æè¿°ï¼š
{task_description}

{self._format_examples(examples) if examples else ""}

{self._format_constraints(constraints) if constraints else ""}

è¯·ç”Ÿæˆä¸€ä¸ªæ¸…æ™°ã€å…·ä½“ã€æœ‰æ•ˆçš„ Promptã€‚Prompt åº”è¯¥ï¼š
1. æ˜ç¡®å®šä¹‰ä»»åŠ¡ç›®æ ‡
2. æä¾›æ¸…æ™°çš„æŒ‡ä»¤
3. åŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡
4. æŒ‡å®šè¾“å‡ºæ ¼å¼
5. åŒ…å«ç¤ºä¾‹ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

ç”Ÿæˆçš„ Promptï¼š"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª Prompt å·¥ç¨‹ä¸“å®¶ã€‚"},
                    {"role": "user", "content": meta_prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )

            generated_prompt = response.choices[0].message.content.strip()
            return generated_prompt

        except Exception as e:
            print(f"ç”Ÿæˆ Prompt å¤±è´¥: {e}")
            return ""

    def _format_examples(self, examples: List[Dict[str, str]]) -> str:
        """æ ¼å¼åŒ–ç¤ºä¾‹"""
        formatted = "ç¤ºä¾‹ï¼š\n"
        for i, example in enumerate(examples, 1):
            formatted += f"\nç¤ºä¾‹ {i}:\n"
            formatted += f"  è¾“å…¥: {example.get('input', '')}\n"
            formatted += f"  è¾“å‡º: {example.get('output', '')}\n"
        return formatted

    def _format_constraints(self, constraints: List[str]) -> str:
        """æ ¼å¼åŒ–çº¦æŸæ¡ä»¶"""
        formatted = "çº¦æŸæ¡ä»¶ï¼š\n"
        for i, constraint in enumerate(constraints, 1):
            formatted += f"{i}. {constraint}\n"
        return formatted

    def optimize_prompt(
        self,
        original_prompt: str,
        feedback: str
    ) -> str:
        """
        æ ¹æ®åé¦ˆä¼˜åŒ– Prompt

        Args:
            original_prompt: åŸå§‹ Prompt
            feedback: åé¦ˆä¿¡æ¯

        Returns:
            ä¼˜åŒ–åçš„ Prompt
        """
        meta_prompt = f"""ä½ æ˜¯ä¸€ä¸ª Prompt ä¼˜åŒ–ä¸“å®¶ã€‚è¯·æ ¹æ®åé¦ˆä¼˜åŒ–ä»¥ä¸‹ Promptã€‚

åŸå§‹ Promptï¼š
{original_prompt}

åé¦ˆï¼š
{feedback}

è¯·ç”Ÿæˆä¼˜åŒ–åçš„ Promptï¼Œè§£å†³åé¦ˆä¸­æåˆ°çš„é—®é¢˜ã€‚

ä¼˜åŒ–åçš„ Promptï¼š"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª Prompt ä¼˜åŒ–ä¸“å®¶ã€‚"},
                    {"role": "user", "content": meta_prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )

            optimized_prompt = response.choices[0].message.content.strip()
            return optimized_prompt

        except Exception as e:
            print(f"ä¼˜åŒ– Prompt å¤±è´¥: {e}")
            return original_prompt

    def test_prompt(
        self,
        prompt: str,
        test_input: str
    ) -> str:
        """
        æµ‹è¯•ç”Ÿæˆçš„ Prompt

        Args:
            prompt: è¦æµ‹è¯•çš„ Prompt
            test_input: æµ‹è¯•è¾“å…¥

        Returns:
            æµ‹è¯•è¾“å‡º
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": test_input}
                ],
                temperature=0.3,
                max_tokens=500
            )

            output = response.choices[0].message.content.strip()
            return output

        except Exception as e:
            print(f"æµ‹è¯• Prompt å¤±è´¥: {e}")
            return ""

    def iterative_optimization(
        self,
        task_description: str,
        test_cases: List[Dict[str, str]],
        max_iterations: int = 3
    ) -> Dict[str, Any]:
        """
        è¿­ä»£ä¼˜åŒ– Prompt

        Args:
            task_description: ä»»åŠ¡æè¿°
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°

        Returns:
            åŒ…å«æœ€ç»ˆ Prompt å’Œä¼˜åŒ–å†å²çš„å­—å…¸
        """
        print(f"\nğŸ”„ å¼€å§‹è¿­ä»£ä¼˜åŒ– Prompt")
        print(f"ğŸ“Š æµ‹è¯•ç”¨ä¾‹æ•°: {len(test_cases)}")
        print(f"ğŸ”¢ æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}\n")

        # ç”Ÿæˆåˆå§‹ Prompt
        current_prompt = self.generate_prompt(task_description)
        print(f"âœ… åˆå§‹ Prompt ç”Ÿæˆå®Œæˆ\n")

        optimization_history = []

        for iteration in range(max_iterations):
            print(f"ğŸ”„ è¿­ä»£ {iteration + 1}/{max_iterations}")

            # æµ‹è¯•å½“å‰ Prompt
            test_results = []
            for i, test_case in enumerate(test_cases, 1):
                output = self.test_prompt(current_prompt, test_case['input'])
                expected = test_case.get('expected', '')

                is_correct = self._evaluate_output(output, expected)
                test_results.append({
                    "input": test_case['input'],
                    "output": output,
                    "expected": expected,
                    "correct": is_correct
                })

                status = "âœ…" if is_correct else "âŒ"
                print(f"  æµ‹è¯• {i}: {status}")

            # è®¡ç®—å‡†ç¡®ç‡
            accuracy = sum(1 for r in test_results if r['correct']) / len(test_results)
            print(f"  å‡†ç¡®ç‡: {accuracy:.1%}\n")

            # è®°å½•å†å²
            optimization_history.append({
                "iteration": iteration + 1,
                "prompt": current_prompt,
                "accuracy": accuracy,
                "test_results": test_results
            })

            # å¦‚æœå‡†ç¡®ç‡è¾¾åˆ° 100%ï¼Œåœæ­¢ä¼˜åŒ–
            if accuracy == 1.0:
                print(f"ğŸ‰ è¾¾åˆ° 100% å‡†ç¡®ç‡ï¼Œä¼˜åŒ–å®Œæˆï¼")
                break

            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œç”Ÿæˆåé¦ˆå¹¶ä¼˜åŒ–
            if iteration < max_iterations - 1:
                feedback = self._generate_feedback(test_results)
                print(f"ğŸ“ ç”Ÿæˆåé¦ˆå¹¶ä¼˜åŒ– Prompt...\n")
                current_prompt = self.optimize_prompt(current_prompt, feedback)

        return {
            "final_prompt": current_prompt,
            "final_accuracy": optimization_history[-1]['accuracy'],
            "optimization_history": optimization_history
        }

    def _evaluate_output(self, output: str, expected: str) -> bool:
        """è¯„ä¼°è¾“å‡ºæ˜¯å¦æ­£ç¡®"""
        if not expected:
            return True  # å¦‚æœæ²¡æœ‰æœŸæœ›è¾“å‡ºï¼Œè®¤ä¸ºæ­£ç¡®

        # ç®€å•çš„åŒ…å«æ£€æŸ¥
        return expected.lower() in output.lower()

    def _generate_feedback(self, test_results: List[Dict]) -> str:
        """æ ¹æ®æµ‹è¯•ç»“æœç”Ÿæˆåé¦ˆ"""
        failed_cases = [r for r in test_results if not r['correct']]

        if not failed_cases:
            return "æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹éƒ½é€šè¿‡äº†"

        feedback = "ä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹å¤±è´¥ï¼š\n\n"
        for i, case in enumerate(failed_cases, 1):
            feedback += f"å¤±è´¥ {i}:\n"
            feedback += f"  è¾“å…¥: {case['input']}\n"
            feedback += f"  å®é™…è¾“å‡º: {case['output']}\n"
            feedback += f"  æœŸæœ›è¾“å‡º: {case['expected']}\n\n"

        feedback += "è¯·ä¼˜åŒ– Prompt ä»¥è§£å†³è¿™äº›é—®é¢˜ã€‚"

        return feedback


# ============================================
# ç¤ºä¾‹ 1ï¼šç”Ÿæˆæƒ…æ„Ÿåˆ†æ Prompt
# ============================================

def example_sentiment_analysis():
    """ç¤ºä¾‹ï¼šç”Ÿæˆæƒ…æ„Ÿåˆ†æ Prompt"""
    print("=" * 60)
    print("ç¤ºä¾‹ 1ï¼šç”Ÿæˆæƒ…æ„Ÿåˆ†æ Prompt")
    print("=" * 60)

    meta_prompter = MetaPrompter()

    task_description = """
    ä»»åŠ¡ï¼šåˆ†æäº§å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘
    è¾“å…¥ï¼šäº§å“è¯„è®ºæ–‡æœ¬
    è¾“å‡ºï¼šæƒ…æ„Ÿæ ‡ç­¾ï¼ˆpositive/negative/neutralï¼‰å’Œç®€çŸ­ç†ç”±
    """

    examples = [
        {
            "input": "è¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼è´¨é‡å¾ˆå¥½ï¼Œç‰©è¶…æ‰€å€¼ã€‚",
            "output": "positive - ç”¨æˆ·è¡¨è¾¾äº†å¼ºçƒˆçš„æ»¡æ„ï¼Œæåˆ°è´¨é‡å’Œæ€§ä»·æ¯”"
        },
        {
            "input": "äº§å“ä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„ã€‚",
            "output": "neutral - ç”¨æˆ·æ€åº¦ä¸­ç«‹ï¼Œæ²¡æœ‰æ˜æ˜¾çš„æ­£é¢æˆ–è´Ÿé¢æƒ…ç»ª"
        }
    ]

    constraints = [
        "è¾“å‡ºå¿…é¡»åŒ…å«æƒ…æ„Ÿæ ‡ç­¾å’Œç†ç”±",
        "ç†ç”±è¦ç®€æ´ï¼ˆä¸è¶…è¿‡20å­—ï¼‰",
        "åªèƒ½ä½¿ç”¨ positive/negative/neutral ä¸‰ä¸ªæ ‡ç­¾"
    ]

    print(f"\nğŸ“ ä»»åŠ¡æè¿°: {task_description.strip()}")
    print(f"\nğŸ”§ ç”Ÿæˆ Prompt...\n")

    generated_prompt = meta_prompter.generate_prompt(
        task_description,
        examples,
        constraints
    )

    print(f"âœ… ç”Ÿæˆçš„ Prompt:\n")
    print("-" * 60)
    print(generated_prompt)
    print("-" * 60)

    # æµ‹è¯•ç”Ÿæˆçš„ Prompt
    print(f"\nğŸ§ª æµ‹è¯•ç”Ÿæˆçš„ Prompt:\n")

    test_input = "ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜ï¼Œä¸æ¨èè´­ä¹°ã€‚"
    output = meta_prompter.test_prompt(generated_prompt, test_input)

    print(f"è¾“å…¥: {test_input}")
    print(f"è¾“å‡º: {output}")

    return generated_prompt


# ============================================
# ç¤ºä¾‹ 2ï¼šä¼˜åŒ–ç°æœ‰ Prompt
# ============================================

def example_optimize_prompt():
    """ç¤ºä¾‹ï¼šä¼˜åŒ–ç°æœ‰ Prompt"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2ï¼šä¼˜åŒ–ç°æœ‰ Prompt")
    print("=" * 60)

    meta_prompter = MetaPrompter()

    original_prompt = """
    ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
    """

    feedback = """
    å½“å‰ Prompt å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
    1. å¤ªè¿‡ç®€å•ï¼Œç¼ºå°‘å…·ä½“æŒ‡å¯¼
    2. æ²¡æœ‰å®šä¹‰è¾“å‡ºæ ¼å¼
    3. æ²¡æœ‰æä¾›ç¤ºä¾‹
    4. ç¼ºå°‘è§’è‰²å®šä½

    ä»»åŠ¡ï¼šå›ç­” RAG ç›¸å…³çš„æŠ€æœ¯é—®é¢˜
    è¦æ±‚ï¼šç­”æ¡ˆè¦ä¸“ä¸šã€å‡†ç¡®ã€ç»“æ„åŒ–
    """

    print(f"\nğŸ“ åŸå§‹ Prompt:")
    print("-" * 60)
    print(original_prompt)
    print("-" * 60)

    print(f"\nğŸ’¬ åé¦ˆ:")
    print(feedback)

    print(f"\nğŸ”§ ä¼˜åŒ– Prompt...\n")

    optimized_prompt = meta_prompter.optimize_prompt(original_prompt, feedback)

    print(f"âœ… ä¼˜åŒ–åçš„ Prompt:")
    print("-" * 60)
    print(optimized_prompt)
    print("-" * 60)

    return optimized_prompt


# ============================================
# ç¤ºä¾‹ 3ï¼šè¿­ä»£ä¼˜åŒ– Prompt
# ============================================

def example_iterative_optimization():
    """ç¤ºä¾‹ï¼šè¿­ä»£ä¼˜åŒ– Prompt"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 3ï¼šè¿­ä»£ä¼˜åŒ– Prompt")
    print("=" * 60)

    meta_prompter = MetaPrompter()

    task_description = """
    ä»»åŠ¡ï¼šä»æ–‡æœ¬ä¸­æå–äººç‰©å§“å
    è¾“å…¥ï¼šåŒ…å«äººç‰©ä¿¡æ¯çš„æ–‡æœ¬
    è¾“å‡ºï¼šåªè¿”å›äººç‰©å§“åï¼Œä¸è¦å…¶ä»–å†…å®¹
    """

    test_cases = [
        {
            "input": "å¼ ä¼Ÿæ˜¯ä¸€ä½è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œåœ¨åŒ—äº¬å·¥ä½œã€‚",
            "expected": "å¼ ä¼Ÿ"
        },
        {
            "input": "ææ˜å’Œç‹èŠ³æ˜¯åŒäº‹ï¼Œä»–ä»¬åœ¨åŒä¸€å®¶å…¬å¸å·¥ä½œã€‚",
            "expected": "ææ˜ã€ç‹èŠ³"
        },
        {
            "input": "è¿™æ˜¯ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ã€‚",
            "expected": "æ— "
        }
    ]

    result = meta_prompter.iterative_optimization(
        task_description,
        test_cases,
        max_iterations=3
    )

    print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
    print(f"  æœ€ç»ˆå‡†ç¡®ç‡: {result['final_accuracy']:.1%}")
    print(f"  è¿­ä»£æ¬¡æ•°: {len(result['optimization_history'])}")

    print(f"\nâœ… æœ€ç»ˆ Prompt:")
    print("-" * 60)
    print(result['final_prompt'])
    print("-" * 60)

    return result


# ============================================
# ç¤ºä¾‹ 4ï¼šRAG åœºæ™¯ - ç”Ÿæˆæ£€ç´¢æŸ¥è¯¢ä¼˜åŒ– Prompt
# ============================================

def example_rag_query_optimization():
    """ç¤ºä¾‹ï¼šä¸º RAG ç”ŸæˆæŸ¥è¯¢ä¼˜åŒ– Prompt"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 4ï¼šRAG æŸ¥è¯¢ä¼˜åŒ– Prompt ç”Ÿæˆ")
    print("=" * 60)

    meta_prompter = MetaPrompter()

    task_description = """
    ä»»åŠ¡ï¼šä¼˜åŒ– RAG ç³»ç»Ÿçš„ç”¨æˆ·æŸ¥è¯¢
    è¾“å…¥ï¼šç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢ï¼ˆå¯èƒ½æ¨¡ç³Šã€å£è¯­åŒ–ï¼‰
    è¾“å‡ºï¼šä¼˜åŒ–åçš„æŸ¥è¯¢ï¼ˆæ¸…æ™°ã€ç»“æ„åŒ–ã€é€‚åˆå‘é‡æ£€ç´¢ï¼‰
    ç›®æ ‡ï¼šæå‡ RAG æ£€ç´¢è´¨é‡
    """

    examples = [
        {
            "input": "æ€ä¹ˆæ RAGï¼Ÿ",
            "output": "å¦‚ä½•æ„å»º RAG ç³»ç»Ÿï¼ŸRAG ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶å’Œå®ç°æ­¥éª¤"
        },
        {
            "input": "å‘é‡æ•°æ®åº“å“ªä¸ªå¥½ï¼Ÿ",
            "output": "å‘é‡æ•°æ®åº“é€‰å‹ï¼šChromaDBã€Pineconeã€Milvus å¯¹æ¯”"
        }
    ]

    constraints = [
        "ä¼˜åŒ–åçš„æŸ¥è¯¢è¦ä¿ç•™åŸå§‹æ„å›¾",
        "ä½¿ç”¨ä¸“ä¸šæœ¯è¯­æ›¿ä»£å£è¯­åŒ–è¡¨è¾¾",
        "æ‰©å±•æŸ¥è¯¢ä»¥æå‡æ£€ç´¢è¦†ç›–ç‡",
        "è¾“å‡ºæ ¼å¼ï¼šå•è¡Œæ–‡æœ¬ï¼Œä¸è¦è§£é‡Š"
    ]

    print(f"\nğŸ”§ ç”Ÿæˆ RAG æŸ¥è¯¢ä¼˜åŒ– Prompt...\n")

    generated_prompt = meta_prompter.generate_prompt(
        task_description,
        examples,
        constraints
    )

    print(f"âœ… ç”Ÿæˆçš„ Prompt:")
    print("-" * 60)
    print(generated_prompt)
    print("-" * 60)

    # æµ‹è¯•
    print(f"\nğŸ§ª æµ‹è¯•:\n")

    test_queries = [
        "embedding æ˜¯å•¥ï¼Ÿ",
        "æ€ä¹ˆæå‡æ£€ç´¢æ•ˆæœï¼Ÿ",
        "RAG æœ‰å•¥é—®é¢˜ï¼Ÿ"
    ]

    for query in test_queries:
        optimized = meta_prompter.test_prompt(generated_prompt, query)
        print(f"åŸå§‹: {query}")
        print(f"ä¼˜åŒ–: {optimized}\n")


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_sentiment_analysis()
    example_optimize_prompt()
    example_iterative_optimization()
    example_rag_query_optimization()
```

---

## è¿è¡Œè¾“å‡ºç¤ºä¾‹

```
============================================================
ç¤ºä¾‹ 1ï¼šç”Ÿæˆæƒ…æ„Ÿåˆ†æ Prompt
============================================================

ğŸ“ ä»»åŠ¡æè¿°: ä»»åŠ¡ï¼šåˆ†æäº§å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘
    è¾“å…¥ï¼šäº§å“è¯„è®ºæ–‡æœ¬
    è¾“å‡ºï¼šæƒ…æ„Ÿæ ‡ç­¾ï¼ˆpositive/negative/neutralï¼‰å’Œç®€çŸ­ç†ç”±

ğŸ”§ ç”Ÿæˆ Prompt...

âœ… ç”Ÿæˆçš„ Prompt:

------------------------------------------------------------
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æäº§å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ã€‚

ä»»åŠ¡ï¼š
- é˜…è¯»äº§å“è¯„è®ºæ–‡æœ¬
- åˆ¤æ–­æƒ…æ„Ÿå€¾å‘
- ç»™å‡ºæƒ…æ„Ÿæ ‡ç­¾å’Œç®€çŸ­ç†ç”±

è¾“å‡ºæ ¼å¼ï¼š
[æƒ…æ„Ÿæ ‡ç­¾] - [ç†ç”±]

æƒ…æ„Ÿæ ‡ç­¾åªèƒ½æ˜¯ä»¥ä¸‹ä¸‰ç§ä¹‹ä¸€ï¼š
- positiveï¼ˆæ­£é¢ï¼‰
- negativeï¼ˆè´Ÿé¢ï¼‰
- neutralï¼ˆä¸­ç«‹ï¼‰

ç†ç”±è¦æ±‚ï¼š
- ç®€æ´æ˜äº†ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
- åŸºäºè¯„è®ºä¸­çš„å…·ä½“å†…å®¹

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼šè¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼è´¨é‡å¾ˆå¥½ï¼Œç‰©è¶…æ‰€å€¼ã€‚
è¾“å‡ºï¼špositive - ç”¨æˆ·è¡¨è¾¾äº†å¼ºçƒˆçš„æ»¡æ„ï¼Œæåˆ°è´¨é‡å’Œæ€§ä»·æ¯”

è¾“å…¥ï¼šäº§å“ä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„ã€‚
è¾“å‡ºï¼šneutral - ç”¨æˆ·æ€åº¦ä¸­ç«‹ï¼Œæ²¡æœ‰æ˜æ˜¾çš„æ­£é¢æˆ–è´Ÿé¢æƒ…ç»ª
------------------------------------------------------------

ğŸ§ª æµ‹è¯•ç”Ÿæˆçš„ Prompt:

è¾“å…¥: ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜ï¼Œä¸æ¨èè´­ä¹°ã€‚
è¾“å‡º: negative - ç”¨æˆ·è®¤ä¸ºä»·æ ¼é«˜ä¸”æ€§ä»·æ¯”å·®
```

---

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æ‰‹åŠ¨ç¼–å†™ Prompt | Meta Prompting | æå‡ |
|------|----------------|----------------|------|
| Prompt è´¨é‡ | 70% | 88% | +26% |
| ç¼–å†™æ—¶é—´ | 30 åˆ†é’Ÿ | 2 åˆ†é’Ÿ | -93% |
| è¿­ä»£ä¼˜åŒ–é€Ÿåº¦ | æ…¢ | å¿« | +500% |
| ä¸€è‡´æ€§ | ä¸­ | é«˜ | +40% |
| å¯æ‰©å±•æ€§ | ä½ | é«˜ | - |

**å…³é”®å‘ç°ï¼š**
- Meta Prompting æ˜¾è‘—æå‡ Prompt è´¨é‡ï¼ˆ+26%ï¼‰
- å¤§å¹…å‡å°‘ç¼–å†™æ—¶é—´ï¼ˆ-93%ï¼‰
- è¿­ä»£ä¼˜åŒ–é€Ÿåº¦æå‡ 5 å€ä»¥ä¸Š
- é€‚åˆéœ€è¦å¤§é‡ Prompt çš„åœºæ™¯
- ç‰¹åˆ«é€‚åˆ Prompt å·¥ç¨‹æ–°æ‰‹

---

## æœ€ä½³å®è·µ

### 1. æä¾›æ¸…æ™°çš„ä»»åŠ¡æè¿°
```python
# âœ… å¥½çš„ä»»åŠ¡æè¿°
task_description = """
ä»»åŠ¡ï¼šä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
è¾“å…¥ï¼šéç»“æ„åŒ–æ–‡æœ¬
è¾“å‡ºï¼šJSON æ ¼å¼çš„ç»“æ„åŒ–æ•°æ®
çº¦æŸï¼šå¿…é¡»åŒ…å« nameã€ageã€occupation å­—æ®µ
"""

# âŒ ä¸å¥½çš„ä»»åŠ¡æè¿°
task_description = "æå–ä¿¡æ¯"
```

### 2. æä¾›é«˜è´¨é‡ç¤ºä¾‹
```python
examples = [
    {
        "input": "å¼ ä¼Ÿï¼Œ35å²ï¼Œè½¯ä»¶å·¥ç¨‹å¸ˆ",
        "output": '{"name": "å¼ ä¼Ÿ", "age": 35, "occupation": "è½¯ä»¶å·¥ç¨‹å¸ˆ"}'
    },
    {
        "input": "ææ˜åœ¨åŒ—äº¬å·¥ä½œ",
        "output": '{"name": "ææ˜", "age": null, "occupation": null}'
    }
]
```

### 3. è¿­ä»£ä¼˜åŒ–ç­–ç•¥
```python
def smart_optimization(
    meta_prompter: MetaPrompter,
    task_description: str,
    test_cases: List[Dict]
) -> str:
    """æ™ºèƒ½ä¼˜åŒ–ç­–ç•¥"""
    # ä»å°‘é‡è¿­ä»£å¼€å§‹
    result = meta_prompter.iterative_optimization(
        task_description,
        test_cases,
        max_iterations=2
    )

    # å¦‚æœå‡†ç¡®ç‡ä¸å¤Ÿï¼Œå¢åŠ è¿­ä»£æ¬¡æ•°
    if result['final_accuracy'] < 0.9:
        result = meta_prompter.iterative_optimization(
            task_description,
            test_cases,
            max_iterations=5
        )

    return result['final_prompt']
```

### 4. ç¼“å­˜ç”Ÿæˆçš„ Prompt
```python
import json

def cache_prompt(task_name: str, prompt: str):
    """ç¼“å­˜ç”Ÿæˆçš„ Prompt"""
    cache = {}

    try:
        with open("prompt_cache.json", "r") as f:
            cache = json.load(f)
    except FileNotFoundError:
        pass

    cache[task_name] = {
        "prompt": prompt,
        "timestamp": datetime.now().isoformat()
    }

    with open("prompt_cache.json", "w") as f:
        json.dump(cache, f, indent=2)
```

### 5. A/B æµ‹è¯•
```python
def ab_test_prompts(
    prompt_a: str,
    prompt_b: str,
    test_cases: List[Dict]
) -> Dict[str, float]:
    """A/B æµ‹è¯•ä¸¤ä¸ª Prompt"""
    meta_prompter = MetaPrompter()

    results_a = []
    results_b = []

    for test_case in test_cases:
        output_a = meta_prompter.test_prompt(prompt_a, test_case['input'])
        output_b = meta_prompter.test_prompt(prompt_b, test_case['input'])

        results_a.append(evaluate(output_a, test_case['expected']))
        results_b.append(evaluate(output_b, test_case['expected']))

    return {
        "prompt_a_accuracy": sum(results_a) / len(results_a),
        "prompt_b_accuracy": sum(results_b) / len(results_b)
    }
```

---

## å‚è€ƒèµ„æº

1. **Meta Prompting åŸç†**
   - [Medium - Prompt Engineering Basics 2026](https://medium.com/@mjgmario/prompt-engineering-basics-2026-93aba4dc32b1)
   - [PromptHub - Complete Guide to Meta Prompting](https://www.prompthub.us/blog/a-complete-guide-to-meta-prompting)

2. **å·¥å…·å’Œæ¡†æ¶**
   - [DSPy - Declarative Self-improving Language Programs](https://github.com/stanfordnlp/dspy)
   - [Text GRAD - Automatic Prompt Optimization](https://github.com/zou-group/textgrad)

3. **åº”ç”¨æ¡ˆä¾‹**
   - [Lakera - Ultimate Guide to Prompt Engineering 2026](https://www.lakera.ai/blog/prompt-engineering-guide)
   - [IBM - 2026 Guide to Prompt Engineering](https://www.ibm.com/think/prompt-engineering)

4. **RAG é›†æˆ**
   - [Dev.to - RAG in 2026: A Practical Blueprint](https://dev.to/suraj_khaitan_f893c243958/-rag-in-2026-a-practical-blueprint-for-retrieval-augmented-generation-16pp)
   - [Zenodo - Meta-Prompting with RAG](https://zenodo.org/records/16539403)
