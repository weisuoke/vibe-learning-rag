# 核心概念 07：混合向量图检索

## 什么是混合检索？

**混合检索**（Hybrid Retrieval）是结合多种检索方法的优势，提供更准确、更全面的检索结果。

**核心组合**：
- 向量检索：语义相似度匹配
- 图检索：关系遍历和推理
- 关键词检索：精确匹配（可选）

**在RAG中的价值**：
- 提高检索准确率
- 支持复杂查询
- 提供可解释性
- 减少幻觉

---

## 三种检索方法对比

### 1. 向量检索

**原理**：将文本转换为向量，通过余弦相似度查找相似文档。

**优势**：
- 语义理解能力强
- 支持模糊匹配
- 跨语言检索

**劣势**：
- 无法理解实体关系
- 缺乏推理能力
- 黑盒，不可解释

**示例**：
```python
from openai import OpenAI
import chromadb

client = OpenAI()
chroma_client = chromadb.Client()
collection = chroma_client.create_collection("docs")

def vector_search(query: str, top_k: int = 5):
    # 生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    )
    query_embedding = response.data[0].embedding

    # 向量检索
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    return results["documents"][0]
```

### 2. 图检索

**原理**：在知识图谱中遍历实体和关系，查找相关路径。

**优势**：
- 理解实体关系
- 支持多跳推理
- 结果可解释

**劣势**：
- 需要结构化知识
- 覆盖率可能不足
- 依赖图谱质量

**示例**：
```python
from neo4j import GraphDatabase

driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))

def graph_search(entity: str, max_hops: int = 2):
    with driver.session() as session:
        result = session.run("""
            MATCH path = (e:Entity {name: $entity})-[*1..$max_hops]-(related)
            RETURN path
            LIMIT 10
        """, entity=entity, max_hops=max_hops)

        paths = []
        for record in result:
            path = record["path"]
            paths.append(format_path(path))

        return paths
```

### 3. 关键词检索

**原理**：基于BM25等算法的精确匹配。

**优势**：
- 精确匹配
- 速度快
- 无需训练

**劣势**：
- 无语义理解
- 词汇不匹配问题
- 无法处理同义词

---

## 混合检索架构

### 基本架构

```
查询
  ↓
┌─────────────────────────────────┐
│  查询处理                        │
│  - 实体识别                      │
│  - 查询改写                      │
└─────────────────────────────────┘
  ↓
┌─────────────┬─────────────┬─────────────┐
│ 向量检索    │ 图检索      │ 关键词检索  │
│ (语义)      │ (关系)      │ (精确)      │
└─────────────┴─────────────┴─────────────┘
  ↓
┌─────────────────────────────────┐
│  结果融合                        │
│  - RRF (Reciprocal Rank Fusion) │
│  - 加权融合                      │
│  - ReRank重排序                  │
└─────────────────────────────────┘
  ↓
最终结果
```

---

## 实现混合检索

### 1. 基础实现

```python
from typing import List, Dict
from dataclasses import dataclass

@dataclass
class SearchResult:
    """检索结果"""
    content: str
    score: float
    source: str  # "vector", "graph", "keyword"
    metadata: Dict = None

class HybridRetriever:
    """混合检索器"""

    def __init__(self, vector_db, graph_db):
        self.vector_db = vector_db
        self.graph_db = graph_db

    def search(self, query: str, top_k: int = 10) -> List[SearchResult]:
        """混合检索"""
        # 1. 向量检索
        vector_results = self._vector_search(query, top_k)

        # 2. 图检索
        graph_results = self._graph_search(query, top_k)

        # 3. 结果融合
        merged_results = self._merge_results(
            vector_results,
            graph_results,
            top_k
        )

        return merged_results

    def _vector_search(self, query: str, top_k: int) -> List[SearchResult]:
        """向量检索"""
        # 生成查询向量
        query_embedding = self._get_embedding(query)

        # 检索
        results = self.vector_db.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        return [
            SearchResult(
                content=doc,
                score=1 - distance,  # 转换为相似度
                source="vector"
            )
            for doc, distance in zip(
                results["documents"][0],
                results["distances"][0]
            )
        ]

    def _graph_search(self, query: str, top_k: int) -> List[SearchResult]:
        """图检索"""
        # 提取实体
        entities = self._extract_entities(query)

        results = []
        for entity in entities:
            # 图遍历
            paths = self.graph_db.find_paths(entity, max_hops=2)

            for path in paths[:top_k]:
                results.append(SearchResult(
                    content=self._format_path(path),
                    score=self._calculate_path_score(path),
                    source="graph",
                    metadata={"entity": entity, "path": path}
                ))

        return results

    def _merge_results(
        self,
        vector_results: List[SearchResult],
        graph_results: List[SearchResult],
        top_k: int
    ) -> List[SearchResult]:
        """结果融合（RRF）"""
        # Reciprocal Rank Fusion
        k = 60  # RRF参数

        # 计算RRF分数
        rrf_scores = {}

        for rank, result in enumerate(vector_results, 1):
            key = result.content
            rrf_scores[key] = rrf_scores.get(key, 0) + 1 / (k + rank)

        for rank, result in enumerate(graph_results, 1):
            key = result.content
            rrf_scores[key] = rrf_scores.get(key, 0) + 1 / (k + rank)

        # 排序
        sorted_results = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        # 返回top_k
        return [
            SearchResult(content=content, score=score, source="hybrid")
            for content, score in sorted_results[:top_k]
        ]
```

### 2. 加权融合

```python
class WeightedHybridRetriever(HybridRetriever):
    """加权混合检索器"""

    def __init__(self, vector_db, graph_db, weights: Dict[str, float] = None):
        super().__init__(vector_db, graph_db)
        self.weights = weights or {
            "vector": 0.5,
            "graph": 0.3,
            "keyword": 0.2
        }

    def _merge_results(
        self,
        vector_results: List[SearchResult],
        graph_results: List[SearchResult],
        top_k: int
    ) -> List[SearchResult]:
        """加权融合"""
        # 归一化分数
        vector_results = self._normalize_scores(vector_results)
        graph_results = self._normalize_scores(graph_results)

        # 合并结果
        all_results = {}

        for result in vector_results:
            key = result.content
            all_results[key] = all_results.get(key, 0) + \
                result.score * self.weights["vector"]

        for result in graph_results:
            key = result.content
            all_results[key] = all_results.get(key, 0) + \
                result.score * self.weights["graph"]

        # 排序
        sorted_results = sorted(
            all_results.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return [
            SearchResult(content=content, score=score, source="hybrid")
            for content, score in sorted_results[:top_k]
        ]

    def _normalize_scores(self, results: List[SearchResult]) -> List[SearchResult]:
        """归一化分数到[0, 1]"""
        if not results:
            return results

        max_score = max(r.score for r in results)
        min_score = min(r.score for r in results)

        if max_score == min_score:
            return results

        for result in results:
            result.score = (result.score - min_score) / (max_score - min_score)

        return results
```

---

## Neo4j向量索引集成

### 2025-2026新特性

```python
from neo4j import GraphDatabase
from openai import OpenAI

client = OpenAI()
driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))

def setup_vector_index():
    """创建向量索引"""
    with driver.session() as session:
        session.run("""
            CREATE VECTOR INDEX entity_embedding IF NOT EXISTS
            FOR (e:Entity)
            ON (e.embedding)
            OPTIONS {
              indexConfig: {
                `vector.dimensions`: 1536,
                `vector.similarity_function`: 'cosine'
              }
            }
        """)

def add_entity_with_embedding(name: str, description: str):
    """添加实体和向量"""
    # 生成向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=f"{name}: {description}"
    )
    embedding = response.data[0].embedding

    # 存储到Neo4j
    with driver.session() as session:
        session.run("""
            MERGE (e:Entity {name: $name})
            SET e.description = $description,
                e.embedding = $embedding
        """, name=name, description=description, embedding=embedding)

def hybrid_search_neo4j(query: str, top_k: int = 10):
    """Neo4j混合检索"""
    # 生成查询向量
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    )
    query_embedding = response.data[0].embedding

    with driver.session() as session:
        # 向量检索 + 图遍历
        result = session.run("""
            // 1. 向量检索
            CALL db.index.vector.queryNodes(
                'entity_embedding',
                $top_k,
                $query_embedding
            ) YIELD node AS entity, score AS vector_score

            // 2. 图遍历
            OPTIONAL MATCH path = (entity)-[*1..2]-(related:Entity)

            // 3. 返回结果
            RETURN
                entity.name AS name,
                entity.description AS description,
                vector_score,
                collect(DISTINCT related.name) AS related_entities,
                count(path) AS relation_count
            ORDER BY vector_score DESC, relation_count DESC
            LIMIT $top_k
        """, query_embedding=query_embedding, top_k=top_k)

        return [dict(record) for record in result]

# 使用
setup_vector_index()
add_entity_with_embedding("张三", "阿里巴巴的高级工程师")
results = hybrid_search_neo4j("工程师")
print(results)
```

---

## ReRank重排序

### 使用Cohere ReRank

```python
import cohere

co = cohere.Client("your-api-key")

def rerank_results(query: str, results: List[SearchResult], top_k: int = 5):
    """使用Cohere ReRank重排序"""
    # 准备文档
    documents = [r.content for r in results]

    # ReRank
    rerank_response = co.rerank(
        model="rerank-english-v3.0",
        query=query,
        documents=documents,
        top_n=top_k
    )

    # 重新排序
    reranked_results = []
    for result in rerank_response.results:
        original_result = results[result.index]
        reranked_results.append(SearchResult(
            content=original_result.content,
            score=result.relevance_score,
            source="reranked",
            metadata=original_result.metadata
        ))

    return reranked_results
```

### 使用LLM ReRank

```python
from openai import OpenAI

client = OpenAI()

def llm_rerank(query: str, results: List[SearchResult], top_k: int = 5):
    """使用LLM重排序"""
    # 构建prompt
    documents_text = "\n\n".join([
        f"[{i}] {r.content}"
        for i, r in enumerate(results)
    ])

    prompt = f"""
给定查询和文档列表，按相关性从高到低排序文档。

查询：{query}

文档：
{documents_text}

返回文档编号列表（JSON格式）：["0", "2", "1", ...]
只返回最相关的{top_k}个文档编号。
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    import json
    ranked_indices = json.loads(response.choices[0].message.content)["indices"]

    # 重新排序
    reranked_results = [
        results[int(idx)]
        for idx in ranked_indices[:top_k]
    ]

    return reranked_results
```

---

## 完整的混合检索RAG

```python
class HybridRAG:
    """混合检索RAG系统"""

    def __init__(self, vector_db, graph_db, llm_client):
        self.retriever = WeightedHybridRetriever(vector_db, graph_db)
        self.llm = llm_client

    def query(self, question: str) -> Dict:
        """查询"""
        # 1. 混合检索
        results = self.retriever.search(question, top_k=20)

        # 2. ReRank重排序
        reranked_results = rerank_results(question, results, top_k=5)

        # 3. 构建上下文
        context = self._build_context(reranked_results)

        # 4. LLM生成答案
        answer = self._generate_answer(question, context)

        # 5. 返回结果
        return {
            "answer": answer,
            "sources": reranked_results,
            "context": context
        }

    def _build_context(self, results: List[SearchResult]) -> str:
        """构建上下文"""
        context_parts = []

        for i, result in enumerate(results, 1):
            context_parts.append(f"[{i}] {result.content}")

            # 如果是图检索结果，添加关系信息
            if result.source == "graph" and result.metadata:
                path = result.metadata.get("path")
                if path:
                    context_parts.append(f"   关系路径: {path}")

        return "\n\n".join(context_parts)

    def _generate_answer(self, question: str, context: str) -> str:
        """生成答案"""
        prompt = f"""
基于以下上下文回答问题。如果上下文中没有相关信息，请说"我不知道"。

上下文：
{context}

问题：{question}

答案：
"""

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        return response.choices[0].message.content

# 使用
rag = HybridRAG(vector_db, graph_db, client)
result = rag.query("张三在哪个城市工作？")
print(result["answer"])
print("\n来源：")
for source in result["sources"]:
    print(f"- {source.content} (分数: {source.score:.2f})")
```

---

## 性能优化

### 1. 并行检索

```python
import asyncio

async def parallel_search(query: str):
    """并行检索"""
    # 并行执行向量检索和图检索
    vector_task = asyncio.create_task(vector_search_async(query))
    graph_task = asyncio.create_task(graph_search_async(query))

    # 等待结果
    vector_results, graph_results = await asyncio.gather(
        vector_task,
        graph_task
    )

    # 融合结果
    return merge_results(vector_results, graph_results)
```

### 2. 缓存

```python
from functools import lru_cache
import hashlib

class CachedHybridRetriever(HybridRetriever):
    """带缓存的混合检索器"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cache = {}

    def search(self, query: str, top_k: int = 10):
        """带缓存的检索"""
        cache_key = self._get_cache_key(query, top_k)

        if cache_key in self.cache:
            return self.cache[cache_key]

        results = super().search(query, top_k)
        self.cache[cache_key] = results

        return results

    def _get_cache_key(self, query: str, top_k: int):
        """生成缓存键"""
        key_str = f"{query}_{top_k}"
        return hashlib.md5(key_str.encode()).hexdigest()
```

---

## 评估混合检索

### 评估指标

```python
def evaluate_retrieval(
    queries: List[str],
    ground_truth: List[List[str]],
    retriever
):
    """评估检索质量"""
    metrics = {
        "precision": [],
        "recall": [],
        "mrr": [],  # Mean Reciprocal Rank
        "ndcg": []  # Normalized Discounted Cumulative Gain
    }

    for query, truth in zip(queries, ground_truth):
        results = retriever.search(query, top_k=10)
        retrieved = [r.content for r in results]

        # Precision@K
        relevant = set(truth) & set(retrieved)
        precision = len(relevant) / len(retrieved) if retrieved else 0
        metrics["precision"].append(precision)

        # Recall@K
        recall = len(relevant) / len(truth) if truth else 0
        metrics["recall"].append(recall)

        # MRR
        for i, doc in enumerate(retrieved, 1):
            if doc in truth:
                metrics["mrr"].append(1 / i)
                break
        else:
            metrics["mrr"].append(0)

    # 计算平均值
    return {
        metric: sum(values) / len(values)
        for metric, values in metrics.items()
    }
```

---

## 总结

### 混合检索的核心价值

1. **互补优势**：
   - 向量：语义理解
   - 图：关系推理
   - 关键词：精确匹配

2. **提高准确率**：
   - 多路召回
   - 结果融合
   - ReRank优化

3. **可解释性**：
   - 图路径可视化
   - 来源追溯
   - 推理过程透明

### 最佳实践

1. **权重调优**：根据场景调整向量/图/关键词权重
2. **ReRank必备**：使用ReRank提升最终结果质量
3. **并行检索**：提高检索速度
4. **缓存优化**：减少重复计算
5. **持续评估**：监控检索质量指标

---

**引用来源**：
- [Neo4j向量索引](https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/)
- [Cohere ReRank](https://docs.cohere.com/docs/reranking)
- [混合检索最佳实践](https://www.pinecone.io/learn/hybrid-search/)
- [RRF算法](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)

---

**版本**：v1.0
**最后更新**：2026-02-14
**维护者**：Claude Code
