# 实战代码 02：实时 LLM 响应

完整的实时 LLM 响应代码示例，展示如何构建生产级的流式对话应用。

---

## 示例 1：打字机效果

```python
"""
打字机效果的流式输出
模拟 ChatGPT 的逐字显示效果
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template("{input}")
chain = prompt | model

async def typewriter_effect(user_input: str, delay=0.03):
    """打字机效果"""
    print(f"用户: {user_input}")
    print("助手: ", end="", flush=True)

    async for chunk in chain.astream({"input": user_input}):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            await asyncio.sleep(delay)  # 延迟显示

    print("\n")

# 使用示例
async def main():
    await typewriter_effect("讲一个关于程序员的笑话", delay=0.03)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 2：实时翻译

```python
"""
实时流式翻译
边生成边显示翻译结果
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")

async def streaming_translation(text: str, target_lang: str):
    """实时翻译"""
    prompt = ChatPromptTemplate.from_template(
        "将以下文本翻译成{target_lang}，保持原文的语气和风格：\n\n{text}"
    )
    chain = prompt | model

    print(f"原文: {text}")
    print(f"翻译({target_lang}): ", end="", flush=True)

    async for chunk in chain.astream({"text": text, "target_lang": target_lang}):
        print(chunk.content, end="", flush=True)

    print("\n")

# 使用示例
async def main():
    await streaming_translation(
        "The quick brown fox jumps over the lazy dog.",
        "中文"
    )

    await streaming_translation(
        "人工智能正在改变世界",
        "English"
    )

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 3：流式摘要生成

```python
"""
流式文本摘要
实时生成长文本的摘要
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")

async def streaming_summarize(text: str, max_words: int = 100):
    """流式摘要"""
    prompt = ChatPromptTemplate.from_template(
        "请用不超过{max_words}字总结以下文本的核心内容：\n\n{text}"
    )
    chain = prompt | model

    print(f"原文长度: {len(text)} 字")
    print(f"摘要({max_words}字以内): ", end="", flush=True)

    word_count = 0
    async for chunk in chain.astream({"text": text, "max_words": max_words}):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            word_count += len(chunk.content)

    print(f"\n摘要长度: {word_count} 字\n")

# 使用示例
async def main():
    long_text = """
    人工智能（Artificial Intelligence，AI）是计算机科学的一个分支，
    它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。
    该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。
    人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大。
    可以设想，未来人工智能带来的科技产品，将会是人类智慧的"容器"。
    """

    await streaming_summarize(long_text, max_words=50)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 4：多语言代码生成

```python
"""
流式代码生成
实时生成多种编程语言的代码
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")

async def streaming_code_generation(task: str, language: str):
    """流式代码生成"""
    prompt = ChatPromptTemplate.from_template(
        "用{language}编写代码实现以下功能：{task}\n\n"
        "只返回代码，不要解释。"
    )
    chain = prompt | model

    print(f"任务: {task}")
    print(f"语言: {language}")
    print("代码:\n```" + language.lower())

    async for chunk in chain.astream({"task": task, "language": language}):
        print(chunk.content, end="", flush=True)

    print("```\n")

# 使用示例
async def main():
    await streaming_code_generation(
        "实现快速排序算法",
        "Python"
    )

    await streaming_code_generation(
        "实现二分查找算法",
        "JavaScript"
    )

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 5：流式问答系统

```python
"""
流式问答系统
基于上下文的实时问答
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")

class StreamingQASystem:
    def __init__(self, context: str):
        self.context = context
        self.prompt = ChatPromptTemplate.from_template(
            "基于以下上下文回答问题：\n\n"
            "上下文：{context}\n\n"
            "问题：{question}\n\n"
            "回答："
        )
        self.chain = self.prompt | model

    async def ask(self, question: str):
        """流式问答"""
        print(f"问题: {question}")
        print("回答: ", end="", flush=True)

        async for chunk in self.chain.astream({
            "context": self.context,
            "question": question
        }):
            print(chunk.content, end="", flush=True)

        print("\n")

# 使用示例
async def main():
    context = """
    Python 是一种高级编程语言，由 Guido van Rossum 于 1991 年首次发布。
    Python 的设计哲学强调代码的可读性和简洁的语法。
    Python 支持多种编程范式，包括面向对象、命令式、函数式和过程式编程。
    Python 拥有丰富的标准库和第三方库，广泛应用于 Web 开发、数据分析、
    人工智能、科学计算等领域。
    """

    qa_system = StreamingQASystem(context)

    await qa_system.ask("Python 是谁创建的？")
    await qa_system.ask("Python 有哪些应用领域？")
    await qa_system.ask("Python 的设计哲学是什么？")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 6：流式内容审核

```python
"""
流式内容审核
实时检测和过滤不当内容
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4o-mini")

async def streaming_content_moderation(user_input: str):
    """流式内容审核"""
    # 先审核
    moderation_prompt = ChatPromptTemplate.from_template(
        "判断以下内容是否包含不当信息（暴力、色情、仇恨言论等）。"
        "只回答'安全'或'不安全'：\n\n{input}"
    )
    moderation_chain = moderation_prompt | model

    print(f"用户输入: {user_input}")
    print("审核中...", end="", flush=True)

    # 收集审核结果
    moderation_result = ""
    async for chunk in moderation_chain.astream({"input": user_input}):
        moderation_result += chunk.content

    print(f" {moderation_result.strip()}\n")

    if "不安全" in moderation_result:
        print("⚠️ 内容包含不当信息，已拒绝处理\n")
        return

    # 安全内容，继续处理
    response_prompt = ChatPromptTemplate.from_template(
        "请回答以下问题：{input}"
    )
    response_chain = response_prompt | model

    print("助手: ", end="", flush=True)
    async for chunk in response_chain.astream({"input": user_input}):
        print(chunk.content, end="", flush=True)

    print("\n")

# 使用示例
async def main():
    await streaming_content_moderation("介绍一下人工智能")
    await streaming_content_moderation("如何制作炸弹")  # 不安全内容

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 示例 7：流式多轮对话

```python
"""
流式多轮对话
支持上下文的连续对话
"""

import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferWindowMemory

model = ChatOpenAI(model="gpt-4o-mini")

class StreamingMultiTurnChat:
    def __init__(self, window_size=5):
        self.memory = ConversationBufferWindowMemory(
            k=window_size,
            return_messages=True
        )
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个友好的助手，记住之前的对话内容"),
            ("placeholder", "{history}"),
            ("user", "{input}")
        ])
        self.chain = self.prompt | model

    async def chat(self, user_input: str):
        """流式对话"""
        history = self.memory.load_memory_variables({})["history"]

        print(f"用户: {user_input}")
        print("助手: ", end="", flush=True)

        full_response = ""
        async for chunk in self.chain.astream({
            "input": user_input,
            "history": history
        }):
            print(chunk.content, end="", flush=True)
            full_response += chunk.content

        print("\n")

        # 保存对话
        self.memory.save_context(
            {"input": user_input},
            {"output": full_response}
        )

# 使用示例
async def main():
    chat = StreamingMultiTurnChat(window_size=5)

    await chat.chat("我叫小明")
    await chat.chat("我喜欢编程")
    await chat.chat("我叫什么名字？")
    await chat.chat("我喜欢什么？")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 运行说明

### 环境配置

```bash
# 安装依赖
uv add langchain langchain-openai langchain-core

# 配置 API 密钥
export OPENAI_API_KEY="your_key_here"
```

### 运行示例

```bash
# 示例 1: 打字机效果
python 01_typewriter.py

# 示例 2: 实时翻译
python 02_translation.py

# 示例 3: 流式摘要
python 03_summarize.py

# 示例 4: 代码生成
python 04_code_gen.py

# 示例 5: 问答系统
python 05_qa_system.py

# 示例 6: 内容审核
python 06_moderation.py

# 示例 7: 多轮对话
python 07_multi_turn.py
```

---

## 关键要点

1. **打字机效果**：使用 `asyncio.sleep()` 控制显示速度
2. **实时翻译**：边生成边显示翻译结果
3. **流式摘要**：实时生成长文本摘要
4. **代码生成**：流式输出代码
5. **问答系统**：基于上下文的实时问答
6. **内容审核**：先审核再处理
7. **多轮对话**：支持上下文的连续对话

---

**版本**: LangChain 0.3.x (2025-2026)
**最后更新**: 2026-02-21
