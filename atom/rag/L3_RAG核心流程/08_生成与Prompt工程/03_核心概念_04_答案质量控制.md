# 核心概念4：答案质量控制

> RAG Triad评估体系、Groundedness检测、幻觉缓解的2025-2026生产标准

---

## 概述

答案质量控制是RAG系统可靠性的核心保障，确保生成的答案准确、相关、基于事实。2025-2026年的标准已形成完整的RAG Triad评估体系。

**核心指标：**
1. **Context Relevance** - 检索上下文的相关性
2. **Groundedness** - 答案基于上下文的程度
3. **Answer Relevance** - 答案对问题的相关性

**来源：** Openlayer "Measuring RAG groundedness: complete evaluation guide" (2026年2月)
https://www.openlayer.com/blog/post/measuring-rag-groundedness-complete-evaluation-guide

---

## 1. RAG Triad评估体系

### 1.1 三大核心指标

```python
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class RAGTriadEvaluator:
    """
    RAG Triad评估器
    """
    
    def __init__(self):
        self.client = client
    
    def evaluate_context_relevance(
        self,
        query: str,
        context: str
    ) -> float:
        """
        评估上下文相关性
        """
        prompt = f"""
评估以下上下文对问题的相关性（0-1分）：

问题：{query}

上下文：{context}

评分标准：
- 1.0：完全相关，包含回答问题所需的所有信息
- 0.7-0.9：高度相关，包含大部分所需信息
- 0.4-0.6：部分相关，包含一些有用信息
- 0.1-0.3：低相关性，信息不太有用
- 0.0：完全无关

只返回数字分数：
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "你是评估专家"},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        
        try:
            score = float(response.choices[0].message.content.strip())
            return max(0.0, min(1.0, score))
        except:
            return 0.0
    
    def evaluate_groundedness(
        self,
        answer: str,
        context: str
    ) -> float:
        """
        评估答案的Groundedness
        """
        prompt = f"""
评估答案是否基于上下文（0-1分）：

上下文：{context}

答案：{answer}

评分标准：
- 1.0：完全基于上下文，没有添加额外信息
- 0.7-0.9：主要基于上下文，有少量合理推断
- 0.4-0.6：部分基于上下文，有一些额外信息
- 0.1-0.3：少量基于上下文，大量额外信息
- 0.0：完全不基于上下文，全是幻觉

只返回数字分数：
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "你是评估专家"},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        
        try:
            score = float(response.choices[0].message.content.strip())
            return max(0.0, min(1.0, score))
        except:
            return 0.0
    
    def evaluate_answer_relevance(
        self,
        query: str,
        answer: str
    ) -> float:
        """
        评估答案相关性
        """
        prompt = f"""
评估答案对问题的相关性（0-1分）：

问题：{query}

答案：{answer}

评分标准：
- 1.0：完全回答问题，直接相关
- 0.7-0.9：很好地回答问题，略有偏离
- 0.4-0.6：部分回答问题，有些离题
- 0.1-0.3：勉强相关，大部分离题
- 0.0：完全不相关，答非所问

只返回数字分数：
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "你是评估专家"},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        
        try:
            score = float(response.choices[0].message.content.strip())
            return max(0.0, min(1.0, score))
        except:
            return 0.0
    
    def evaluate_full_triad(
        self,
        query: str,
        context: str,
        answer: str
    ) -> dict:
        """
        完整RAG Triad评估
        """
        context_rel = self.evaluate_context_relevance(query, context)
        groundedness = self.evaluate_groundedness(answer, context)
        answer_rel = self.evaluate_answer_relevance(query, answer)
        
        # 综合分数
        overall = (context_rel + groundedness + answer_rel) / 3
        
        return {
            "context_relevance": context_rel,
            "groundedness": groundedness,
            "answer_relevance": answer_rel,
            "overall_score": overall,
            "passed": overall >= 0.75  # 生产阈值
        }

# 使用示例
evaluator = RAGTriadEvaluator()

query = "Python有什么特点？"
context = "Python是一种解释型、面向对象的编程语言。"
answer = "Python是一种解释型语言，支持面向对象编程。"

result = evaluator.evaluate_full_triad(query, context, answer)

print("=== RAG Triad评估结果 ===")
print(f"上下文相关性: {result['context_relevance']:.2f}")
print(f"Groundedness: {result['groundedness']:.2f}")
print(f"答案相关性: {result['answer_relevance']:.2f}")
print(f"综合分数: {result['overall_score']:.2f}")
print(f"是否通过: {'✅' if result['passed'] else '❌'}")
```

---

## 2. 生产环境阈值设置

### 2.1 2025-2026行业标准

**来源：** Openlayer "Measuring RAG groundedness" (2026年2月)

| 领域 | Context Relevance | Groundedness | Answer Relevance | 综合分数 |
|------|------------------|--------------|------------------|----------|
| 医疗/法律 | >0.90 | >0.90 | >0.85 | >0.88 |
| 金融/保险 | >0.85 | >0.85 | >0.80 | >0.83 |
| 客服支持 | >0.75 | >0.80 | >0.75 | >0.77 |
| 一般问答 | >0.70 | >0.75 | >0.70 | >0.72 |

### 2.2 动态阈值调整

```python
def get_quality_threshold(domain: str, risk_level: str) -> dict:
    """
    根据领域和风险级别获取质量阈值
    """
    base_thresholds = {
        "medical": {"context": 0.90, "groundedness": 0.90, "answer": 0.85},
        "legal": {"context": 0.90, "groundedness": 0.90, "answer": 0.85},
        "financial": {"context": 0.85, "groundedness": 0.85, "answer": 0.80},
        "customer_service": {"context": 0.75, "groundedness": 0.80, "answer": 0.75},
        "general": {"context": 0.70, "groundedness": 0.75, "answer": 0.70}
    }
    
    thresholds = base_thresholds.get(domain, base_thresholds["general"])
    
    # 根据风险级别调整
    if risk_level == "critical":
        thresholds = {k: v + 0.05 for k, v in thresholds.items()}
    elif risk_level == "low":
        thresholds = {k: v - 0.05 for k, v in thresholds.items()}
    
    return thresholds

# 使用示例
thresholds = get_quality_threshold("medical", "critical")
print(f"医疗领域（关键）阈值：{thresholds}")
```

---

## 3. 幻觉检测技术

### 3.1 基于规则的检测

```python
def detect_hallucination_rules(answer: str, context: str) -> dict:
    """
    基于规则的幻觉检测
    """
    issues = []
    
    # 规则1：检查数字是否在上下文中
    import re
    answer_numbers = set(re.findall(r'\d+', answer))
    context_numbers = set(re.findall(r'\d+', context))
    
    hallucinated_numbers = answer_numbers - context_numbers
    if hallucinated_numbers:
        issues.append({
            "type": "hallucinated_numbers",
            "values": list(hallucinated_numbers)
        })
    
    # 规则2：检查专有名词
    # 简化示例：检查大写开头的词
    answer_proper_nouns = set(re.findall(r'\b[A-Z][a-z]+\b', answer))
    context_proper_nouns = set(re.findall(r'\b[A-Z][a-z]+\b', context))
    
    hallucinated_nouns = answer_proper_nouns - context_proper_nouns
    if hallucinated_nouns:
        issues.append({
            "type": "hallucinated_proper_nouns",
            "values": list(hallucinated_nouns)
        })
    
    # 规则3：检查绝对性词汇
    absolute_words = ["总是", "从不", "所有", "没有", "必须", "一定"]
    found_absolutes = [w for w in absolute_words if w in answer]
    if found_absolutes and not any(w in context for w in found_absolutes):
        issues.append({
            "type": "absolute_statements",
            "values": found_absolutes
        })
    
    return {
        "has_hallucination": len(issues) > 0,
        "issues": issues,
        "confidence": 1.0 - (len(issues) * 0.2)
    }

# 使用示例
context = "Python是一种编程语言"
answer = "Python是世界上最好的编程语言，有1000万用户"

result = detect_hallucination_rules(answer, context)
print("幻觉检测结果：", result)
```

### 3.2 基于LLM的检测

```python
def detect_hallucination_llm(answer: str, context: str) -> dict:
    """
    使用LLM进行幻觉检测
    """
    prompt = f"""
分析答案中是否存在幻觉（不基于上下文的信息）。

上下文：
{context}

答案：
{answer}

请逐句分析答案，识别：
1. 完全基于上下文的内容
2. 合理推断的内容
3. 幻觉内容（上下文中没有的信息）

以JSON格式返回：
{{
  "grounded_statements": ["句子1", "句子2"],
  "inferred_statements": ["句子3"],
  "hallucinated_statements": ["句子4"],
  "overall_score": 0.0-1.0
}}
"""
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是幻觉检测专家"},
            {"role": "user", "content": prompt}
        ],
        temperature=0
    )
    
    import json
    try:
        result = json.loads(response.choices[0].message.content)
        return result
    except:
        return {"error": "解析失败"}

# 使用示例
result = detect_hallucination_llm(answer, context)
print("LLM幻觉检测：", result)
```

---

## 4. 自动质量控制流程

### 4.1 生成前验证

```python
def pre_generation_check(query: str, context: str) -> dict:
    """
    生成前检查上下文质量
    """
    evaluator = RAGTriadEvaluator()
    
    # 检查上下文相关性
    context_rel = evaluator.evaluate_context_relevance(query, context)
    
    if context_rel < 0.7:
        return {
            "proceed": False,
            "reason": "上下文相关性过低",
            "score": context_rel,
            "suggestion": "需要改进检索质量或扩展查询"
        }
    
    # 检查上下文长度
    context_tokens = len(context.split()) * 1.3
    if context_tokens > 3000:
        return {
            "proceed": False,
            "reason": "上下文过长",
            "tokens": context_tokens,
            "suggestion": "需要Context Pruning"
        }
    
    return {
        "proceed": True,
        "context_relevance": context_rel,
        "context_tokens": context_tokens
    }
```

### 4.2 生成后验证

```python
def post_generation_check(
    query: str,
    context: str,
    answer: str,
    domain: str = "general"
) -> dict:
    """
    生成后完整质量检查
    """
    evaluator = RAGTriadEvaluator()
    
    # RAG Triad评估
    triad = evaluator.evaluate_full_triad(query, context, answer)
    
    # 幻觉检测
    hallucination = detect_hallucination_rules(answer, context)
    
    # 获取阈值
    thresholds = get_quality_threshold(domain, "normal")
    
    # 综合判断
    passed = (
        triad["groundedness"] >= thresholds["groundedness"] and
        triad["answer_relevance"] >= thresholds["answer"] and
        not hallucination["has_hallucination"]
    )
    
    return {
        "passed": passed,
        "triad_scores": triad,
        "hallucination_check": hallucination,
        "thresholds": thresholds,
        "recommendation": "通过" if passed else "需要重新生成"
    }

# 使用示例
check = post_generation_check(query, context, answer, domain="general")
print("质量检查结果：", check)
```

---

## 5. 质量改进策略

### 5.1 迭代改进

```python
def iterative_improvement(
    query: str,
    context: str,
    max_iterations: int = 3
) -> dict:
    """
    迭代改进答案质量
    """
    best_answer = None
    best_score = 0
    
    for i in range(max_iterations):
        # 生成答案
        answer = generate_answer(query, context, temperature=0.1 + i*0.1)
        
        # 评估质量
        check = post_generation_check(query, context, answer)
        
        if check["triad_scores"]["overall_score"] > best_score:
            best_score = check["triad_scores"]["overall_score"]
            best_answer = answer
        
        # 如果通过，提前返回
        if check["passed"]:
            return {
                "answer": answer,
                "iterations": i + 1,
                "final_score": check["triad_scores"]["overall_score"],
                "passed": True
            }
    
    return {
        "answer": best_answer,
        "iterations": max_iterations,
        "final_score": best_score,
        "passed": False
    }

def generate_answer(query: str, context: str, temperature: float) -> str:
    """生成答案"""
    prompt = f"上下文：{context}\n\n问题：{query}\n\n回答："
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是知识助手"},
            {"role": "user", "content": prompt}
        ],
        temperature=temperature
    )
    return response.choices[0].message.content
```

### 5.2 反馈循环

```python
def feedback_loop_generation(
    query: str,
    context: str
) -> dict:
    """
    带反馈循环的生成
    """
    # 第一次生成
    draft = generate_answer(query, context, temperature=0.1)
    
    # 自我批评
    critique_prompt = f"""
评估以下答案的质量：

上下文：{context}

问题：{query}

答案：{draft}

请指出：
1. 哪些内容不基于上下文
2. 哪些内容不够准确
3. 如何改进

批评：
"""
    
    critique = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是严格的评审专家"},
            {"role": "user", "content": critique_prompt}
        ],
        temperature=0
    ).choices[0].message.content
    
    # 基于批评改进
    improve_prompt = f"""
基于以下批评改进答案：

原答案：{draft}

批评：{critique}

上下文：{context}

问题：{query}

改进后的答案：
"""
    
    improved = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "你是知识助手"},
            {"role": "user", "content": improve_prompt}
        ],
        temperature=0.1
    ).choices[0].message.content
    
    return {
        "draft": draft,
        "critique": critique,
        "improved": improved
    }
```

---

## 6. 生产环境监控

### 6.1 质量监控仪表板

```python
import logging
from datetime import datetime
from collections import defaultdict

class QualityMonitor:
    """
    质量监控系统
    """
    
    def __init__(self):
        self.metrics = defaultdict(list)
        self.logger = logging.getLogger("quality_monitor")
    
    def log_generation(
        self,
        session_id: str,
        query: str,
        answer: str,
        scores: dict
    ):
        """
        记录生成质量
        """
        record = {
            "timestamp": datetime.now().isoformat(),
            "session_id": session_id,
            "query": query,
            "answer_length": len(answer),
            "scores": scores
        }
        
        self.metrics["generations"].append(record)
        
        # 记录低质量案例
        if scores["overall_score"] < 0.75:
            self.logger.warning(
                f"Low quality generation: {session_id}, "
                f"score: {scores['overall_score']:.2f}"
            )
    
    def get_statistics(self, time_window: str = "1h") -> dict:
        """
        获取统计数据
        """
        recent = self.metrics["generations"][-100:]  # 最近100条
        
        if not recent:
            return {"error": "No data"}
        
        avg_groundedness = sum(
            r["scores"]["groundedness"] for r in recent
        ) / len(recent)
        
        avg_relevance = sum(
            r["scores"]["answer_relevance"] for r in recent
        ) / len(recent)
        
        pass_rate = sum(
            1 for r in recent if r["scores"]["overall_score"] >= 0.75
        ) / len(recent)
        
        return {
            "total_generations": len(recent),
            "avg_groundedness": avg_groundedness,
            "avg_relevance": avg_relevance,
            "pass_rate": pass_rate,
            "time_window": time_window
        }

# 使用示例
monitor = QualityMonitor()

# 记录生成
monitor.log_generation(
    session_id="session_123",
    query="Python有什么特点？",
    answer="Python是一种解释型语言...",
    scores={"groundedness": 0.85, "answer_relevance": 0.82, "overall_score": 0.83}
)

# 获取统计
stats = monitor.get_statistics()
print("质量统计：", stats)
```

---

## 7. 常见问题

### Q1: 如何平衡质量和性能？

**答：** 使用分层策略

```python
def adaptive_quality_check(
    query: str,
    context: str,
    answer: str,
    priority: str = "normal"
) -> dict:
    """
    根据优先级自适应质量检查
    """
    if priority == "high":
        # 完整检查
        return post_generation_check(query, context, answer)
    elif priority == "normal":
        # 快速检查
        evaluator = RAGTriadEvaluator()
        groundedness = evaluator.evaluate_groundedness(answer, context)
        return {"passed": groundedness >= 0.75, "groundedness": groundedness}
    else:
        # 最小检查
        return {"passed": len(answer) > 10}
```

### Q2: 如何处理边缘案例？

**答：** 使用人工审核队列

```python
class HumanReviewQueue:
    """
    人工审核队列
    """
    
    def __init__(self):
        self.queue = []
    
    def should_review(self, scores: dict) -> bool:
        """
        判断是否需要人工审核
        """
        # 分数在阈值边缘
        if 0.70 <= scores["overall_score"] <= 0.80:
            return True
        
        # 各指标差异大
        score_range = max(scores.values()) - min(scores.values())
        if score_range > 0.3:
            return True
        
        return False
    
    def add_to_queue(self, item: dict):
        """
        添加到审核队列
        """
        self.queue.append(item)
```

---

## 总结

### 核心原则

1. **RAG Triad评估**：Context Relevance + Groundedness + Answer Relevance
2. **生产阈值**：根据领域设置合适的质量阈值
3. **幻觉检测**：结合规则和LLM进行检测
4. **持续监控**：实时监控质量指标
5. **迭代改进**：使用反馈循环提升质量

### 2025-2026标准配置

```python
# 生产级质量控制配置
QUALITY_CONTROL_CONFIG_2026 = {
    "evaluation_method": "rag_triad",
    "thresholds": {
        "critical": {"groundedness": 0.90, "relevance": 0.85},
        "normal": {"groundedness": 0.75, "relevance": 0.75}
    },
    "hallucination_detection": True,
    "iterative_improvement": True,
    "max_iterations": 3,
    "monitoring": True,
    "human_review_threshold": 0.75
}
```

---

**版本：** v1.0 (2025-2026最新标准)
**最后更新：** 2026-02-16
**参考来源：**
- Openlayer "Measuring RAG Groundedness" (2026-02)
- https://www.openlayer.com/blog/post/measuring-rag-groundedness-complete-evaluation-guide
