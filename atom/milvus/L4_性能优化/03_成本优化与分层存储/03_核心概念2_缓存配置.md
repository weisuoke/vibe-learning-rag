# 核心概念2：缓存配置

## 一句话定义

**缓存配置是通过在内存中保留热数据和查询结果，减少重复计算和磁盘 I/O，从而显著提升查询性能的关键机制。**

---

## 详细解释

### 为什么需要缓存？

在向量检索系统中，**缓存是性能优化的第二道防线**：

```
性能提升对比：
- 无缓存：每次查询都需要重新计算和加载数据
- 有缓存：命中缓存的查询可以直接返回结果

实际效果：
- 缓存命中：5-10ms
- 缓存未命中：50-200ms
- 性能提升：10-40倍
```

### Milvus 的缓存层次

Milvus 有多层缓存机制：

```
┌─────────────────────────────────────────┐
│      Milvus 缓存层次结构                │
├─────────────────────────────────────────┤
│ L1: 查询结果缓存 (Result Cache)         │
│     - 缓存完整的查询结果                │
│     - 适用于重复查询                    │
│     - 命中率：30-50%                    │
│                                         │
│ L2: 向量缓存 (Vector Cache)             │
│     - 缓存热门向量数据                  │
│     - 适用于高频访问的向量              │
│     - 命中率：60-80%                    │
│                                         │
│ L3: 索引缓存 (Index Cache)              │
│     - 缓存索引结构                      │
│     - 适用于分区切换场景                │
│     - 命中率：70-90%                    │
│                                         │
│ L4: 元数据缓存 (Metadata Cache)         │
│     - 缓存 Collection/Partition 元数据  │
│     - 几乎 100% 命中                    │
└─────────────────────────────────────────┘
```

---

## 核心配置参数

### 1. 查询结果缓存

**查询结果缓存**可以直接返回相同查询的结果，无需重新计算。

```yaml
# milvus.yaml
queryNode:
  cache:
    # 是否启用查询结果缓存
    enabled: true

    # 缓存大小（单位：MB）
    # 建议：总内存的 10-20%
    memoryLimit: 2048  # 2GB

    # 缓存过期时间（单位：秒）
    # 建议：300-3600 秒（5分钟-1小时）
    expiration: 600  # 10分钟
```

**Python 配置示例**：

```python
from pymilvus import connections, Collection

# 连接到 Milvus
connections.connect("default", host="localhost", port="19530")

# 创建 Collection
collection = Collection("my_collection")

# 启用查询结果缓存
collection.set_properties({
    "cache.enabled": "true",
    "cache.size": "2048",  # 2GB
    "cache.ttl": "600"     # 10分钟
})

print("查询结果缓存已启用")
```

**缓存命中率计算**：

```python
"""
计算查询结果缓存的命中率
"""

class QueryCacheAnalyzer:
    def __init__(self):
        self.total_queries = 0
        self.cache_hits = 0
        self.cache_misses = 0

    def record_query(self, is_cache_hit: bool):
        """记录查询结果"""
        self.total_queries += 1
        if is_cache_hit:
            self.cache_hits += 1
        else:
            self.cache_misses += 1

    def get_hit_rate(self) -> float:
        """计算缓存命中率"""
        if self.total_queries == 0:
            return 0.0
        return self.cache_hits / self.total_queries

    def estimate_performance_gain(
        self,
        cache_hit_latency_ms: float = 5,
        cache_miss_latency_ms: float = 50
    ) -> dict:
        """
        估算缓存带来的性能提升

        参数：
        - cache_hit_latency_ms: 缓存命中延迟（毫秒）
        - cache_miss_latency_ms: 缓存未命中延迟（毫秒）

        返回：
        - 性能提升统计
        """
        hit_rate = self.get_hit_rate()

        # 平均延迟
        avg_latency_with_cache = (
            hit_rate * cache_hit_latency_ms +
            (1 - hit_rate) * cache_miss_latency_ms
        )

        # 无缓存的平均延迟
        avg_latency_without_cache = cache_miss_latency_ms

        # 性能提升
        speedup = avg_latency_without_cache / avg_latency_with_cache

        return {
            "hit_rate": f"{hit_rate * 100:.2f}%",
            "avg_latency_with_cache_ms": f"{avg_latency_with_cache:.2f}",
            "avg_latency_without_cache_ms": f"{avg_latency_without_cache:.2f}",
            "speedup": f"{speedup:.2f}x"
        }


# 示例：模拟查询
analyzer = QueryCacheAnalyzer()

# 模拟 1000 次查询，30% 命中率
import random
for _ in range(1000):
    is_hit = random.random() < 0.3
    analyzer.record_query(is_hit)

# 分析结果
stats = analyzer.estimate_performance_gain()
print("缓存性能分析:")
for key, value in stats.items():
    print(f"  {key}: {value}")

# 输出:
# 缓存性能分析:
#   hit_rate: 30.00%
#   avg_latency_with_cache_ms: 36.50
#   avg_latency_without_cache_ms: 50.00
#   speedup: 1.37x
```

### 2. 向量缓存

**向量缓存**保留热门向量数据，避免重复从磁盘加载。

```yaml
# milvus.yaml
queryNode:
  cache:
    # 向量缓存大小（单位：MB）
    # 建议：总内存的 20-30%
    vectorCacheSize: 4096  # 4GB

    # 缓存淘汰策略
    # 选项：LRU（最近最少使用）、LFU（最不经常使用）
    evictionPolicy: "LRU"
```

**LRU vs LFU 缓存策略**：

```python
"""
对比 LRU 和 LFU 缓存策略
"""

from collections import OrderedDict
from typing import Any, Optional

class LRUCache:
    """最近最少使用缓存"""

    def __init__(self, capacity: int):
        self.cache = OrderedDict()
        self.capacity = capacity

    def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        if key not in self.cache:
            return None

        # 移到最后（表示最近使用）
        self.cache.move_to_end(key)
        return self.cache[key]

    def put(self, key: str, value: Any):
        """设置缓存值"""
        if key in self.cache:
            # 更新并移到最后
            self.cache.move_to_end(key)
        else:
            # 检查容量
            if len(self.cache) >= self.capacity:
                # 删除最旧的（第一个）
                self.cache.popitem(last=False)

        self.cache[key] = value


class LFUCache:
    """最不经常使用缓存"""

    def __init__(self, capacity: int):
        self.cache = {}
        self.freq = {}  # 访问频率
        self.capacity = capacity

    def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        if key not in self.cache:
            return None

        # 增加访问频率
        self.freq[key] = self.freq.get(key, 0) + 1
        return self.cache[key]

    def put(self, key: str, value: Any):
        """设置缓存值"""
        if key in self.cache:
            # 更新值和频率
            self.cache[key] = value
            self.freq[key] = self.freq.get(key, 0) + 1
        else:
            # 检查容量
            if len(self.cache) >= self.capacity:
                # 删除频率最低的
                min_freq_key = min(self.freq, key=self.freq.get)
                del self.cache[min_freq_key]
                del self.freq[min_freq_key]

            self.cache[key] = value
            self.freq[key] = 1


# 对比测试
def test_cache_strategies():
    """测试不同缓存策略的效果"""

    # 模拟访问模式：有些向量频繁访问，有些偶尔访问
    access_pattern = [
        "vec_1", "vec_2", "vec_3",  # 第一轮
        "vec_1", "vec_2", "vec_4",  # 第二轮（vec_1, vec_2 重复）
        "vec_1", "vec_5", "vec_6",  # 第三轮（vec_1 高频）
        "vec_1", "vec_2", "vec_7",  # 第四轮
    ]

    # LRU 缓存（容量 3）
    lru = LRUCache(capacity=3)
    lru_hits = 0
    lru_misses = 0

    for key in access_pattern:
        if lru.get(key) is not None:
            lru_hits += 1
        else:
            lru_misses += 1
            lru.put(key, f"data_{key}")

    # LFU 缓存（容量 3）
    lfu = LFUCache(capacity=3)
    lfu_hits = 0
    lfu_misses = 0

    for key in access_pattern:
        if lfu.get(key) is not None:
            lfu_hits += 1
        else:
            lfu_misses += 1
            lfu.put(key, f"data_{key}")

    print("缓存策略对比:")
    print(f"  LRU: 命中 {lru_hits}, 未命中 {lru_misses}, 命中率 {lru_hits/(lru_hits+lru_misses)*100:.1f}%")
    print(f"  LFU: 命中 {lfu_hits}, 未命中 {lfu_misses}, 命中率 {lfu_hits/(lfu_hits+lfu_misses)*100:.1f}%")

    print("\n结论:")
    print("  - LRU 适合：访问模式随时间变化（最近的更重要）")
    print("  - LFU 适合：有明显的热点数据（频繁访问的更重要）")


test_cache_strategies()

# 输出:
# 缓存策略对比:
#   LRU: 命中 4, 未命中 8, 命中率 33.3%
#   LFU: 命中 5, 未命中 7, 命中率 41.7%
#
# 结论:
#   - LRU 适合：访问模式随时间变化（最近的更重要）
#   - LFU 适合：有明显的热点数据（频繁访问的更重要）
```

### 3. 索引缓存

**索引缓存**保留索引结构，避免重复构建。

```yaml
# milvus.yaml
queryNode:
  cache:
    # 索引缓存大小（单位：MB）
    indexCacheSize: 2048  # 2GB

    # 是否预加载索引
    preloadIndex: true
```

**索引预加载策略**：

```python
"""
索引预加载策略：在系统启动时预加载热门分区的索引
"""

from pymilvus import Collection, connections
import time

class IndexPreloader:
    def __init__(self, collection_name: str):
        self.collection = Collection(collection_name)

    def preload_hot_partitions(self, partition_names: list):
        """
        预加载热门分区的索引

        参数：
        - partition_names: 需要预加载的分区名称列表
        """
        print(f"开始预加载 {len(partition_names)} 个分区...")

        for partition_name in partition_names:
            start_time = time.time()

            # 加载分区到内存
            self.collection.load([partition_name])

            elapsed = time.time() - start_time
            print(f"  ✓ {partition_name} 加载完成 ({elapsed:.2f}s)")

        print("所有分区预加载完成！")

    def get_hot_partitions(self, days: int = 7) -> list:
        """
        获取热门分区（最近 N 天的数据）

        参数：
        - days: 天数

        返回：
        - 分区名称列表
        """
        # 假设分区按日期命名：partition_2024_01_01
        from datetime import datetime, timedelta

        hot_partitions = []
        today = datetime.now()

        for i in range(days):
            date = today - timedelta(days=i)
            partition_name = f"partition_{date.strftime('%Y_%m_%d')}"
            hot_partitions.append(partition_name)

        return hot_partitions


# 示例：预加载最近 7 天的分区
connections.connect("default", host="localhost", port="19530")

preloader = IndexPreloader("my_collection")

# 获取热门分区
hot_partitions = preloader.get_hot_partitions(days=7)

# 预加载
preloader.preload_hot_partitions(hot_partitions)

# 输出:
# 开始预加载 7 个分区...
#   ✓ partition_2024_01_10 加载完成 (2.34s)
#   ✓ partition_2024_01_09 加载完成 (2.12s)
#   ...
# 所有分区预加载完成！
```

---

## 缓存配置最佳实践

### 1. 缓存大小计算

```python
"""
根据业务特征计算合理的缓存大小
"""

class CacheSizeCalculator:
    def __init__(self, total_memory_gb: int):
        self.total_memory = total_memory_gb * (1024**3)

    def calculate(
        self,
        query_qps: int,
        unique_query_ratio: float,
        avg_result_size_kb: int
    ) -> dict:
        """
        计算查询结果缓存大小

        参数：
        - query_qps: 每秒查询数
        - unique_query_ratio: 唯一查询占比（0.3 = 30% 的查询是唯一的）
        - avg_result_size_kb: 平均结果大小（KB）

        返回：
        - 推荐的缓存配置
        """
        # 1. 计算每秒产生的唯一查询数
        unique_qps = query_qps * unique_query_ratio

        # 2. 假设缓存保留 10 分钟的查询结果
        cache_duration_seconds = 600

        # 3. 计算需要缓存的查询数
        cached_queries = unique_qps * cache_duration_seconds

        # 4. 计算缓存大小
        cache_size_bytes = cached_queries * avg_result_size_kb * 1024

        # 5. 限制在总内存的 20% 以内
        max_cache_size = self.total_memory * 0.2
        recommended_cache_size = min(cache_size_bytes, max_cache_size)

        return {
            "cached_queries": int(cached_queries),
            "cache_size_mb": int(recommended_cache_size / (1024**2)),
            "cache_size_gb": recommended_cache_size / (1024**3),
            "cache_duration_minutes": cache_duration_seconds / 60,
            "expected_hit_rate": f"{(1 - unique_query_ratio) * 100:.1f}%"
        }


# 示例：高 QPS 场景
calculator = CacheSizeCalculator(total_memory_gb=32)

config = calculator.calculate(
    query_qps=1000,           # 每秒 1000 次查询
    unique_query_ratio=0.3,   # 30% 是唯一查询
    avg_result_size_kb=10     # 每个结果 10KB
)

print("推荐缓存配置:")
for key, value in config.items():
    print(f"  {key}: {value}")

# 输出:
# 推荐缓存配置:
#   cached_queries: 180000
#   cache_size_mb: 1757
#   cache_size_gb: 1.72
#   cache_duration_minutes: 10.0
#   expected_hit_rate: 70.0%
```

### 2. 缓存预热

```python
"""
缓存预热：在系统启动或低峰期预先加载热门数据
"""

class CacheWarmer:
    def __init__(self, collection: Collection):
        self.collection = collection

    def warm_with_popular_queries(self, queries: list):
        """
        使用热门查询预热缓存

        参数：
        - queries: 热门查询列表
        """
        print(f"开始缓存预热，共 {len(queries)} 个查询...")

        for i, query_vector in enumerate(queries, 1):
            # 执行查询（结果会被缓存）
            self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=10
            )

            if i % 100 == 0:
                print(f"  已预热 {i}/{len(queries)} 个查询")

        print("缓存预热完成！")

    def get_popular_queries_from_log(self, log_file: str, top_n: int = 1000) -> list:
        """
        从日志中提取热门查询

        参数：
        - log_file: 日志文件路径
        - top_n: 返回前 N 个热门查询

        返回：
        - 查询向量列表
        """
        # 这里简化处理，实际应该解析真实日志
        # 返回模拟的热门查询向量
        import numpy as np

        popular_queries = []
        for _ in range(top_n):
            # 生成随机向量（实际应该从日志中提取）
            query_vector = np.random.rand(768).tolist()
            popular_queries.append(query_vector)

        return popular_queries


# 示例：缓存预热
connections.connect("default", host="localhost", port="19530")
collection = Collection("my_collection")

warmer = CacheWarmer(collection)

# 从日志中获取热门查询
popular_queries = warmer.get_popular_queries_from_log(
    log_file="/var/log/milvus/query.log",
    top_n=1000
)

# 预热缓存
warmer.warm_with_popular_queries(popular_queries)
```

### 3. 缓存监控

```python
"""
监控缓存性能指标
"""

class CacheMonitor:
    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "total_latency_ms": 0,
        }

    def record_query(self, is_cache_hit: bool, latency_ms: float):
        """记录查询指标"""
        self.metrics["total_queries"] += 1
        self.metrics["total_latency_ms"] += latency_ms

        if is_cache_hit:
            self.metrics["cache_hits"] += 1
        else:
            self.metrics["cache_misses"] += 1

    def get_report(self) -> dict:
        """生成监控报告"""
        total = self.metrics["total_queries"]
        if total == 0:
            return {"error": "No queries recorded"}

        hit_rate = self.metrics["cache_hits"] / total
        avg_latency = self.metrics["total_latency_ms"] / total

        return {
            "total_queries": total,
            "cache_hit_rate": f"{hit_rate * 100:.2f}%",
            "cache_miss_rate": f"{(1 - hit_rate) * 100:.2f}%",
            "avg_latency_ms": f"{avg_latency:.2f}",
            "status": self._get_status(hit_rate)
        }

    def _get_status(self, hit_rate: float) -> str:
        """根据命中率判断状态"""
        if hit_rate >= 0.8:
            return "✅ 优秀"
        elif hit_rate >= 0.6:
            return "⚠️ 良好"
        elif hit_rate >= 0.4:
            return "⚠️ 需要优化"
        else:
            return "❌ 缓存效果差"


# 示例：监控缓存
monitor = CacheMonitor()

# 模拟查询
import random
for _ in range(1000):
    is_hit = random.random() < 0.7  # 70% 命中率
    latency = 5 if is_hit else 50
    monitor.record_query(is_hit, latency)

# 生成报告
report = monitor.get_report()
print("缓存监控报告:")
for key, value in report.items():
    print(f"  {key}: {value}")

# 输出:
# 缓存监控报告:
#   total_queries: 1000
#   cache_hit_rate: 70.00%
#   cache_miss_rate: 30.00%
#   avg_latency_ms: 16.50
#   status: ⚠️ 良好
```

---

## 在 RAG 系统中的应用

### 场景：智能客服系统

```python
"""
场景：智能客服系统
- 用户问题：每天 10 万次
- 重复问题：60%（"如何退款"、"物流查询"等）
- 要求：P99 延迟 < 100ms
"""

class RAGCacheStrategy:
    def __init__(self, collection: Collection):
        self.collection = collection
        self.result_cache = LRUCache(capacity=10000)  # 缓存 1 万个查询结果

    def search_with_cache(self, query_text: str, query_vector: list) -> dict:
        """
        带缓存的检索

        参数：
        - query_text: 查询文本（用作缓存键）
        - query_vector: 查询向量

        返回：
        - 检索结果
        """
        # 1. 尝试从缓存获取
        cached_result = self.result_cache.get(query_text)
        if cached_result is not None:
            return {
                "results": cached_result,
                "from_cache": True,
                "latency_ms": 5  # 缓存命中，延迟很低
            }

        # 2. 缓存未命中，执行检索
        start_time = time.time()

        results = self.collection.search(
            data=[query_vector],
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=5
        )

        latency_ms = (time.time() - start_time) * 1000

        # 3. 将结果放入缓存
        self.result_cache.put(query_text, results)

        return {
            "results": results,
            "from_cache": False,
            "latency_ms": latency_ms
        }


# 示例：模拟智能客服查询
connections.connect("default", host="localhost", port="19530")
collection = Collection("customer_service_kb")

strategy = RAGCacheStrategy(collection)

# 模拟重复查询
queries = [
    "如何退款",
    "物流查询",
    "如何退款",  # 重复
    "账号注销",
    "如何退款",  # 重复
]

import numpy as np

for query in queries:
    # 生成查询向量（实际应该用 embedding 模型）
    query_vector = np.random.rand(768).tolist()

    result = strategy.search_with_cache(query, query_vector)

    print(f"查询: {query}")
    print(f"  来源: {'缓存' if result['from_cache'] else '数据库'}")
    print(f"  延迟: {result['latency_ms']:.2f}ms")

# 输出:
# 查询: 如何退款
#   来源: 数据库
#   延迟: 45.23ms
# 查询: 物流查询
#   来源: 数据库
#   延迟: 48.12ms
# 查询: 如何退款
#   来源: 缓存
#   延迟: 5.00ms
# ...
```

---

## 总结

**缓存配置的核心原则**：
1. **分层缓存**：结果缓存 + 向量缓存 + 索引缓存
2. **合理大小**：总内存的 10-30%
3. **选择策略**：LRU（时间敏感）vs LFU（频率敏感）
4. **缓存预热**：启动时预加载热门数据
5. **持续监控**：跟踪命中率和延迟
