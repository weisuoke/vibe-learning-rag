# 最小可用

> 掌握以下内容，就能开始 LCEL 与传统 Chain 的对比和迁移

---

## 核心知识：20% 解决 80% 问题

### 4.1 理解两种编程范式

**传统 Chain（命令式）**：
```python
from langchain.chains import LLMChain

# 告诉计算机"怎么做"
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run({"input": "你好"})
```

**LCEL（声明式）**：
```python
# 告诉计算机"做什么"
chain = prompt | llm | StrOutputParser()
result = chain.invoke({"input": "你好"})
```

**关键区别**：
- 传统 Chain：需要实例化类、配置参数、调用特定方法
- LCEL：直接组合、自动推断、统一接口

---

### 4.2 掌握基础迁移模式

#### 模式 1：LLMChain → LCEL

**传统方式**：
```python
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template("翻译成英文：{text}")

chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(text="你好")
```

**LCEL 方式**：
```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

llm = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template("翻译成英文：{text}")

chain = prompt | llm | StrOutputParser()
result = chain.invoke({"text": "你好"})
```

**迁移要点**：
- 移除 `LLMChain` 类
- 使用 `|` 操作符组合
- 添加 `StrOutputParser()` 提取文本
- `run()` → `invoke()`

#### 模式 2：SequentialChain → LCEL

**传统方式**：
```python
from langchain.chains import LLMChain, SequentialChain

chain1 = LLMChain(llm=llm, prompt=prompt1, output_key="summary")
chain2 = LLMChain(llm=llm, prompt=prompt2, output_key="keywords")

overall_chain = SequentialChain(
    chains=[chain1, chain2],
    input_variables=["text"],
    output_variables=["summary", "keywords"]
)
```

**LCEL 方式**：
```python
from langchain_core.runnables import RunnablePassthrough

chain = (
    {"text": RunnablePassthrough()}
    | {"summary": prompt1 | llm | StrOutputParser()}
    | {"keywords": prompt2 | llm | StrOutputParser()}
)
```

**迁移要点**：
- 移除 `SequentialChain` 类
- 使用字典组合并行步骤
- 自动推断输入输出变量

---

### 4.3 理解性能差异的核心原因

**为什么 LCEL 更快？**

1. **自动并行**：
```python
# LCEL 自动识别可并行步骤
chain = RunnableParallel(
    summary=prompt1 | llm,
    keywords=prompt2 | llm
)
# 两个 LLM 调用并发执行，耗时 = max(time1, time2)
```

2. **流式输出**：
```python
# LCEL 默认支持流式
for chunk in chain.stream({"text": "长文本"}):
    print(chunk, end="", flush=True)
# 首 token 时间减少 60-80%
```

3. **批处理优化**：
```python
# LCEL 的 batch 使用线程池
results = chain.batch([input1, input2, input3])
# 吞吐量提升 40-50%
```

**实测数据**（2025-2026）：
- 并行场景：LCEL 快 2-3 倍
- 流式场景：首 token 时间减少 60-80%
- 批处理场景：吞吐量提升 40-50%

---

### 4.4 掌握使用场景决策

**决策矩阵**：

| 场景 | 推荐方式 | 原因 |
|------|----------|------|
| **新项目** | LCEL | 性能好、可维护、是趋势 |
| **简单单次调用** | 直接用 SDK | 无需框架抽象 |
| **遗留代码维护** | 保持原样 | 避免不必要的风险 |
| **性能瓶颈优化** | 迁移到 LCEL | 2-3倍性能提升 |
| **需要流式输出** | LCEL | 默认支持，体验好 |

**快速判断**：
```
是新项目？ → 是 → 用 LCEL
         → 否 → 有性能问题？ → 是 → 迁移到 LCEL
                           → 否 → 保持原样
```

---

### 4.5 掌握渐进式迁移策略

**三步迁移法**：

#### 步骤 1：评估（1天）
```python
# 扫描代码库，找出所有传统 Chain
import ast
import os

def find_legacy_chains(directory):
    legacy_patterns = [
        "LLMChain",
        "SequentialChain",
        "TransformChain",
        "RouterChain"
    ]

    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                with open(os.path.join(root, file)) as f:
                    content = f.read()
                    for pattern in legacy_patterns:
                        if pattern in content:
                            print(f"Found {pattern} in {file}")

find_legacy_chains("./src")
```

#### 步骤 2：迁移（1-2周）
```python
# 优先迁移热点路径（性能瓶颈）
# 使用 RunnableLambda 包装暂时无法迁移的代码

from langchain_core.runnables import RunnableLambda

def legacy_function(input):
    # 旧代码逻辑
    return old_chain.run(input)

# 包装成 Runnable
legacy_runnable = RunnableLambda(legacy_function)

# 与 LCEL 组合
chain = prompt | llm | legacy_runnable | parser
```

#### 步骤 3：验证（3-5天）
```python
# 对比测试：确保迁移后结果一致
def test_migration():
    test_inputs = [...]

    # 旧版本结果
    old_results = [old_chain.run(inp) for inp in test_inputs]

    # 新版本结果
    new_results = [new_chain.invoke(inp) for inp in test_inputs]

    # 对比
    for old, new in zip(old_results, new_results):
        assert old == new, "Migration failed!"
```

---

## 这些知识足以

### 能做什么

1. **理解差异**：
   - 知道 LCEL 和传统 Chain 的本质区别
   - 理解性能差异的原因
   - 掌握使用场景决策

2. **基础迁移**：
   - 迁移 LLMChain 到 LCEL
   - 迁移 SequentialChain 到 LCEL
   - 使用 RunnableLambda 包装旧代码

3. **性能优化**：
   - 识别性能瓶颈
   - 使用 LCEL 的并行和流式特性
   - 测量和对比性能

### 为后续学习打基础

- **深入理解**：架构差异、设计哲学
- **高级迁移**：复杂 Chain、条件路由、Memory
- **生产实践**：监控、成本优化、部署

---

## 快速实战：5分钟迁移示例

### 场景：RAG 文档问答

**传统 Chain 版本**：
```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# 初始化
llm = ChatOpenAI(model="gpt-4o-mini")
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(embedding_function=embeddings)
retriever = vectorstore.as_retriever()

# 创建 Chain
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever
)

# 使用
result = qa_chain({"query": "什么是 LCEL？"})
print(result["result"])
```

**LCEL 版本**：
```python
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 初始化（相同）
llm = ChatOpenAI(model="gpt-4o-mini")
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(embedding_function=embeddings)
retriever = vectorstore.as_retriever()

# 定义 prompt
template = """基于以下上下文回答问题：

上下文：{context}

问题：{question}

答案："""
prompt = ChatPromptTemplate.from_template(template)

# 创建 LCEL 链
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 使用
result = chain.invoke("什么是 LCEL？")
print(result)
```

**对比**：
- **代码行数**：相似（但 LCEL 更灵活）
- **可定制性**：LCEL 完全可控（prompt、格式化、解析）
- **性能**：LCEL 支持流式输出
- **可维护性**：LCEL 逻辑清晰

**流式版本**（LCEL 独有）：
```python
# 实时输出，用户体验更好
for chunk in chain.stream("什么是 LCEL？"):
    print(chunk, end="", flush=True)
```

---

## 常见问题速查

### Q1: 必须全部迁移吗？

**A**: 不必须。优先迁移：
- 新功能开发
- 性能瓶颈路径
- 需要流式输出的场景

非关键路径可以保持原样。

### Q2: 迁移会破坏现有功能吗？

**A**: 不会，如果：
- 充分测试
- 渐进式迁移
- 保留回滚能力

建议使用特性开关（feature flag）控制新旧版本。

### Q3: LCEL 学习曲线陡峭吗？

**A**: 不陡峭。核心概念：
- 管道操作符 `|`
- Runnable 接口
- 字典组合

比传统 Chain 更简单（声明式 < 命令式）。

### Q4: 性能提升有多大？

**A**: 取决于场景：
- 并行场景：2-3倍
- 流式场景：首 token 时间减少 60-80%
- 批处理场景：吞吐量提升 40-50%
- 顺序场景：相似（无损失）

### Q5: 有自动化迁移工具吗？

**A**: 有，但需要手动调整：
- AST 分析工具（识别传统 Chain）
- 代码生成脚本（生成 LCEL 代码）
- 测试生成器（生成对比测试）

详见 `07_实战代码_06_迁移自动化工具.md`

---

## 学习检查清单

完成以下检查，确保掌握最小可用知识：

- [ ] 能说出 LCEL 和传统 Chain 的本质区别（声明式 vs 命令式）
- [ ] 能迁移 LLMChain 到 LCEL
- [ ] 能迁移 SequentialChain 到 LCEL
- [ ] 理解 LCEL 性能优势的三个原因（并行、流式、批处理）
- [ ] 能根据场景决策使用 LCEL 还是传统 Chain
- [ ] 掌握渐进式迁移的三步法（评估、迁移、验证）
- [ ] 能使用 RunnableLambda 包装旧代码
- [ ] 能编写对比测试验证迁移结果

---

## 下一步学习建议

### 如果你想深入理解

→ 阅读 `03_核心概念_01_架构差异与设计哲学.md`
→ 阅读 `03_核心概念_02_性能差异深度剖析.md`

### 如果你想实战迁移

→ 阅读 `07_实战代码_01_基础迁移模式.md`
→ 阅读 `07_实战代码_02_复杂链迁移.md`

### 如果你想优化性能

→ 阅读 `07_实战代码_03_性能基准测试.md`
→ 阅读 `07_实战代码_04_成本优化实践.md`

### 如果你想生产部署

→ 阅读 `03_核心概念_05_生产环境考量.md`
→ 阅读 `07_实战代码_05_生产部署模式.md`

---

**记住**：掌握这 20% 的核心知识，就能解决 80% 的实际问题。先用起来，再深入学习！
