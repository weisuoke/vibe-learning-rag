# 实战代码 4：限流中间件

本文提供完整的限流中间件实现，包括固定窗口、滑动窗口和令牌桶算法。

---

## 1. 基础固定窗口限流

### 1.1 简单固定窗口限流中间件

```python
"""
固定窗口限流中间件
演示：每分钟最多 N 次请求
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict

app = FastAPI()

# 限流配置
MAX_REQUESTS = 10  # 每分钟最多 10 次请求
WINDOW_SIZE = 60   # 窗口大小：60 秒

# 存储请求计数：{client_ip: {"count": int, "reset_time": float}}
rate_limit_store = defaultdict(lambda: {"count": 0, "reset_time": time.time() + WINDOW_SIZE})

@app.middleware("http")
async def fixed_window_rate_limit(request: Request, call_next):
    client_ip = request.client.host
    now = time.time()

    # 获取客户端记录
    record = rate_limit_store[client_ip]

    # 检查窗口是否过期
    if now >= record["reset_time"]:
        # 重置窗口
        record["count"] = 0
        record["reset_time"] = now + WINDOW_SIZE

    # 检查是否超过限制
    if record["count"] >= MAX_REQUESTS:
        retry_after = int(record["reset_time"] - now)
        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Max {MAX_REQUESTS} requests per {WINDOW_SIZE} seconds",
                "retry_after": retry_after
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 增加计数
    record["count"] += 1

    # 处理请求
    response = await call_next(request)

    # 添加限流信息到响应头
    response.headers["X-RateLimit-Limit"] = str(MAX_REQUESTS)
    response.headers["X-RateLimit-Remaining"] = str(MAX_REQUESTS - record["count"])
    response.headers["X-RateLimit-Reset"] = str(int(record["reset_time"]))

    return response

@app.get("/")
async def root():
    return {"message": "Hello World"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**测试：**

```bash
# 快速发送 15 次请求
$ for i in {1..15}; do curl http://localhost:8000/; done

# 前 10 次成功
{"message":"Hello World"}

# 第 11 次开始被限流
{"error":"Rate limit exceeded","message":"Max 10 requests per 60 seconds","retry_after":58}
```

---

## 2. 滑动窗口限流

### 2.1 滑动窗口限流中间件

```python
"""
滑动窗口限流中间件
演示：更精确的限流算法
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict

app = FastAPI()

MAX_REQUESTS = 10
WINDOW_SIZE = 60

# 存储请求时间戳：{client_ip: [timestamps]}
rate_limit_store = defaultdict(list)

@app.middleware("http")
async def sliding_window_rate_limit(request: Request, call_next):
    client_ip = request.client.host
    now = time.time()

    # 获取客户端的请求记录
    timestamps = rate_limit_store[client_ip]

    # 清理过期的时间戳（超过窗口大小）
    rate_limit_store[client_ip] = [
        ts for ts in timestamps
        if now - ts < WINDOW_SIZE
    ]

    # 检查是否超过限制
    if len(rate_limit_store[client_ip]) >= MAX_REQUESTS:
        # 计算最早的请求何时过期
        oldest_timestamp = rate_limit_store[client_ip][0]
        retry_after = int(WINDOW_SIZE - (now - oldest_timestamp))

        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Max {MAX_REQUESTS} requests per {WINDOW_SIZE} seconds",
                "retry_after": retry_after
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 记录本次请求
    rate_limit_store[client_ip].append(now)

    # 处理请求
    response = await call_next(request)

    # 添加限流信息
    response.headers["X-RateLimit-Limit"] = str(MAX_REQUESTS)
    response.headers["X-RateLimit-Remaining"] = str(
        MAX_REQUESTS - len(rate_limit_store[client_ip])
    )

    return response

@app.get("/")
async def root():
    return {"message": "Hello World"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 3. 基于用户的限流

### 3.1 用户级别限流中间件

```python
"""
基于用户的限流中间件
演示：不同用户有不同的限流配置
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict

app = FastAPI()

# 用户限流配置
USER_RATE_LIMITS = {
    "free": {"max_requests": 10, "window": 60},
    "pro": {"max_requests": 100, "window": 60},
    "enterprise": {"max_requests": 1000, "window": 60},
}

rate_limit_store = defaultdict(list)

@app.middleware("http")
async def user_based_rate_limit(request: Request, call_next):
    # 获取用户信息（假设已经通过认证中间件设置）
    user_id = getattr(request.state, "user_id", None)
    user_plan = getattr(request.state, "user_plan", "free")

    if not user_id:
        # 未认证用户，使用 IP 限流
        user_id = f"ip_{request.client.host}"
        user_plan = "free"

    # 获取用户的限流配置
    config = USER_RATE_LIMITS.get(user_plan, USER_RATE_LIMITS["free"])
    max_requests = config["max_requests"]
    window = config["window"]

    now = time.time()

    # 清理过期记录
    rate_limit_store[user_id] = [
        ts for ts in rate_limit_store[user_id]
        if now - ts < window
    ]

    # 检查限流
    if len(rate_limit_store[user_id]) >= max_requests:
        oldest_timestamp = rate_limit_store[user_id][0]
        retry_after = int(window - (now - oldest_timestamp))

        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Max {max_requests} requests per {window} seconds for {user_plan} plan",
                "retry_after": retry_after,
                "plan": user_plan
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 记录请求
    rate_limit_store[user_id].append(now)

    response = await call_next(request)

    # 添加限流信息
    response.headers["X-RateLimit-Limit"] = str(max_requests)
    response.headers["X-RateLimit-Remaining"] = str(
        max_requests - len(rate_limit_store[user_id])
    )
    response.headers["X-RateLimit-Plan"] = user_plan

    return response

@app.get("/api/data")
async def get_data(request: Request):
    user_plan = getattr(request.state, "user_plan", "free")
    return {"message": "Data", "plan": user_plan}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 4. 令牌桶算法限流

### 4.1 令牌桶限流中间件

```python
"""
令牌桶算法限流中间件
演示：允许突发流量，但长期平均速率受限
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict

app = FastAPI()

# 令牌桶配置
BUCKET_CAPACITY = 10  # 桶容量
REFILL_RATE = 1       # 每秒补充 1 个令牌

# 存储令牌桶：{client_ip: {"tokens": float, "last_refill": float}}
token_buckets = defaultdict(lambda: {"tokens": BUCKET_CAPACITY, "last_refill": time.time()})

@app.middleware("http")
async def token_bucket_rate_limit(request: Request, call_next):
    client_ip = request.client.host
    now = time.time()

    # 获取令牌桶
    bucket = token_buckets[client_ip]

    # 计算应该补充的令牌数
    time_passed = now - bucket["last_refill"]
    tokens_to_add = time_passed * REFILL_RATE

    # 补充令牌（不超过桶容量）
    bucket["tokens"] = min(BUCKET_CAPACITY, bucket["tokens"] + tokens_to_add)
    bucket["last_refill"] = now

    # 检查是否有足够的令牌
    if bucket["tokens"] < 1:
        # 计算需要等待多久才能获得 1 个令牌
        retry_after = int((1 - bucket["tokens"]) / REFILL_RATE)

        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Token bucket empty. Refill rate: {REFILL_RATE} tokens/second",
                "retry_after": retry_after
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 消耗 1 个令牌
    bucket["tokens"] -= 1

    response = await call_next(request)

    # 添加限流信息
    response.headers["X-RateLimit-Limit"] = str(BUCKET_CAPACITY)
    response.headers["X-RateLimit-Remaining"] = str(int(bucket["tokens"]))

    return response

@app.get("/")
async def root():
    return {"message": "Hello World"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 5. 按路径分级限流

### 5.1 不同路径不同限流策略

```python
"""
按路径分级限流中间件
演示：不同的 API 端点有不同的限流配置
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict

app = FastAPI()

# 路径限流配置
PATH_RATE_LIMITS = {
    "/api/expensive": {"max_requests": 5, "window": 60},   # 昂贵的操作
    "/api/moderate": {"max_requests": 20, "window": 60},   # 中等操作
    "/api/cheap": {"max_requests": 100, "window": 60},     # 便宜的操作
}

# 默认限流配置
DEFAULT_RATE_LIMIT = {"max_requests": 50, "window": 60}

rate_limit_store = defaultdict(lambda: defaultdict(list))

@app.middleware("http")
async def path_based_rate_limit(request: Request, call_next):
    client_ip = request.client.host
    path = request.url.path
    now = time.time()

    # 获取路径的限流配置
    config = PATH_RATE_LIMITS.get(path, DEFAULT_RATE_LIMIT)
    max_requests = config["max_requests"]
    window = config["window"]

    # 清理过期记录
    rate_limit_store[client_ip][path] = [
        ts for ts in rate_limit_store[client_ip][path]
        if now - ts < window
    ]

    # 检查限流
    if len(rate_limit_store[client_ip][path]) >= max_requests:
        oldest_timestamp = rate_limit_store[client_ip][path][0]
        retry_after = int(window - (now - oldest_timestamp))

        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Max {max_requests} requests per {window} seconds for {path}",
                "retry_after": retry_after
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 记录请求
    rate_limit_store[client_ip][path].append(now)

    response = await call_next(request)

    # 添加限流信息
    response.headers["X-RateLimit-Limit"] = str(max_requests)
    response.headers["X-RateLimit-Remaining"] = str(
        max_requests - len(rate_limit_store[client_ip][path])
    )

    return response

@app.get("/api/expensive")
async def expensive_operation():
    return {"message": "Expensive operation (5 req/min)"}

@app.get("/api/moderate")
async def moderate_operation():
    return {"message": "Moderate operation (20 req/min)"}

@app.get("/api/cheap")
async def cheap_operation():
    return {"message": "Cheap operation (100 req/min)"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 6. 生产级限流中间件（完整版）

### 6.1 完整的生产级限流中间件

```python
"""
生产级限流中间件
演示：完整的限流功能，支持多种策略
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict
from typing import Optional
from starlette.middleware.base import BaseHTTPMiddleware

app = FastAPI()

class RateLimitMiddleware(BaseHTTPMiddleware):
    """生产级限流中间件"""

    def __init__(
        self,
        app,
        default_limit: int = 60,
        default_window: int = 60,
        path_limits: Optional[dict] = None,
        user_limits: Optional[dict] = None,
        enabled: bool = True,
    ):
        super().__init__(app)
        self.default_limit = default_limit
        self.default_window = default_window
        self.path_limits = path_limits or {}
        self.user_limits = user_limits or {}
        self.enabled = enabled
        self.rate_limit_store = defaultdict(lambda: defaultdict(list))

    async def dispatch(self, request: Request, call_next):
        # 测试模式下跳过限流
        if not self.enabled:
            return await call_next(request)

        # 获取客户端标识
        client_id = self._get_client_id(request)

        # 获取限流配置
        max_requests, window = self._get_rate_limit_config(request)

        # 检查限流
        is_allowed, retry_after = self._check_rate_limit(
            client_id, request.url.path, max_requests, window
        )

        if not is_allowed:
            return self._rate_limit_response(
                max_requests, window, retry_after, request.url.path
            )

        # 记录请求
        self._record_request(client_id, request.url.path)

        # 处理请求
        response = await call_next(request)

        # 添加限流信息
        remaining = self._get_remaining(client_id, request.url.path, max_requests)
        response.headers["X-RateLimit-Limit"] = str(max_requests)
        response.headers["X-RateLimit-Remaining"] = str(remaining)
        response.headers["X-RateLimit-Window"] = str(window)

        return response

    def _get_client_id(self, request: Request) -> str:
        """获取客户端标识（优先使用用户 ID，否则使用 IP）"""
        user_id = getattr(request.state, "user_id", None)
        if user_id:
            return f"user_{user_id}"
        return f"ip_{request.client.host}"

    def _get_rate_limit_config(self, request: Request) -> tuple:
        """获取限流配置"""
        # 1. 检查用户级别限流
        user_plan = getattr(request.state, "user_plan", None)
        if user_plan and user_plan in self.user_limits:
            config = self.user_limits[user_plan]
            return config["max_requests"], config["window"]

        # 2. 检查路径级别限流
        path = request.url.path
        if path in self.path_limits:
            config = self.path_limits[path]
            return config["max_requests"], config["window"]

        # 3. 使用默认限流
        return self.default_limit, self.default_window

    def _check_rate_limit(
        self, client_id: str, path: str, max_requests: int, window: int
    ) -> tuple:
        """检查是否超过限流"""
        now = time.time()

        # 清理过期记录
        self.rate_limit_store[client_id][path] = [
            ts for ts in self.rate_limit_store[client_id][path]
            if now - ts < window
        ]

        # 检查是否超过限制
        if len(self.rate_limit_store[client_id][path]) >= max_requests:
            oldest_timestamp = self.rate_limit_store[client_id][path][0]
            retry_after = int(window - (now - oldest_timestamp))
            return False, retry_after

        return True, 0

    def _record_request(self, client_id: str, path: str):
        """记录请求"""
        self.rate_limit_store[client_id][path].append(time.time())

    def _get_remaining(self, client_id: str, path: str, max_requests: int) -> int:
        """获取剩余请求数"""
        return max(0, max_requests - len(self.rate_limit_store[client_id][path]))

    def _rate_limit_response(
        self, max_requests: int, window: int, retry_after: int, path: str
    ) -> JSONResponse:
        """返回限流响应"""
        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Max {max_requests} requests per {window} seconds for {path}",
                "retry_after": retry_after,
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)},
        )

# 使用中间件
app.add_middleware(
    RateLimitMiddleware,
    default_limit=60,
    default_window=60,
    path_limits={
        "/api/agent/chat": {"max_requests": 10, "window": 60},
        "/api/expensive": {"max_requests": 5, "window": 60},
    },
    user_limits={
        "free": {"max_requests": 10, "window": 60},
        "pro": {"max_requests": 100, "window": 60},
    },
    enabled=True,
)

@app.get("/")
async def root():
    return {"message": "Hello World"}

@app.get("/api/agent/chat")
async def chat(message: str):
    return {"response": f"Echo: {message}"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 7. 在 AI Agent 后端中的应用

### 7.1 AI Agent 限流中间件

```python
"""
AI Agent 后端限流中间件
演示：保护 LLM API 调用，防止滥用
"""

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import time
from collections import defaultdict

app = FastAPI()

# AI Agent 限流配置
AGENT_RATE_LIMITS = {
    "free": {"max_requests": 10, "window": 3600, "max_tokens": 10000},
    "pro": {"max_requests": 100, "window": 3600, "max_tokens": 100000},
    "enterprise": {"max_requests": 1000, "window": 3600, "max_tokens": 1000000},
}

rate_limit_store = defaultdict(lambda: {"requests": [], "tokens": 0, "reset_time": time.time() + 3600})

@app.middleware("http")
async def ai_agent_rate_limit(request: Request, call_next):
    # 只对 Agent API 进行限流
    if not request.url.path.startswith("/api/agent/"):
        return await call_next(request)

    # 获取用户信息
    user_id = getattr(request.state, "user_id", None)
    user_plan = getattr(request.state, "user_plan", "free")

    if not user_id:
        return JSONResponse(
            {"error": "Unauthorized"},
            status_code=401
        )

    # 获取限流配置
    config = AGENT_RATE_LIMITS.get(user_plan, AGENT_RATE_LIMITS["free"])
    max_requests = config["max_requests"]
    max_tokens = config["max_tokens"]
    window = config["window"]

    now = time.time()
    record = rate_limit_store[user_id]

    # 检查窗口是否过期
    if now >= record["reset_time"]:
        record["requests"] = []
        record["tokens"] = 0
        record["reset_time"] = now + window

    # 清理过期请求
    record["requests"] = [
        ts for ts in record["requests"]
        if now - ts < window
    ]

    # 检查请求数限流
    if len(record["requests"]) >= max_requests:
        retry_after = int(record["reset_time"] - now)
        return JSONResponse(
            {
                "error": "Rate limit exceeded",
                "message": f"Max {max_requests} requests per hour for {user_plan} plan",
                "retry_after": retry_after,
                "plan": user_plan
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 检查 token 数限流
    if record["tokens"] >= max_tokens:
        retry_after = int(record["reset_time"] - now)
        return JSONResponse(
            {
                "error": "Token limit exceeded",
                "message": f"Max {max_tokens} tokens per hour for {user_plan} plan",
                "retry_after": retry_after,
                "plan": user_plan
            },
            status_code=429,
            headers={"Retry-After": str(retry_after)}
        )

    # 记录请求
    record["requests"].append(now)

    # 处理请求
    response = await call_next(request)

    # 从响应中获取 token 使用情况（假设在响应头中）
    tokens_used = int(response.headers.get("X-Tokens-Used", "0"))
    record["tokens"] += tokens_used

    # 添加限流信息
    response.headers["X-RateLimit-Requests-Limit"] = str(max_requests)
    response.headers["X-RateLimit-Requests-Remaining"] = str(
        max_requests - len(record["requests"])
    )
    response.headers["X-RateLimit-Tokens-Limit"] = str(max_tokens)
    response.headers["X-RateLimit-Tokens-Remaining"] = str(
        max(0, max_tokens - record["tokens"])
    )
    response.headers["X-RateLimit-Reset"] = str(int(record["reset_time"]))

    return response

@app.post("/api/agent/chat")
async def chat(request: Request, message: str):
    # 模拟 LLM API 调用
    tokens_used = len(message.split()) * 2  # 简化计算

    response = JSONResponse({
        "response": f"Echo: {message}",
        "tokens_used": tokens_used
    })

    response.headers["X-Tokens-Used"] = str(tokens_used)

    return response

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 总结

**限流中间件的核心要点：**

1. **固定窗口**：简单但有突发流量问题
2. **滑动窗口**：更精确，避免突发流量
3. **令牌桶**：允许突发流量，长期平均速率受限
4. **用户级别限流**：不同用户不同配置
5. **路径级别限流**：不同 API 端点不同配置
6. **生产级限流**：完整的限流功能，支持多种策略
7. **AI Agent 应用**：保护 LLM API，防止滥用和控制成本

**最佳实践：**
- 使用滑动窗口算法（更精确）
- 根据用户套餐设置不同限流
- 昂贵的操作设置更严格的限流
- 返回清晰的限流信息（剩余次数、重试时间）
- 在 AI Agent 后端中同时限制请求数和 token 数

**下一步学习：**
- 实战代码 5：错误处理中间件
