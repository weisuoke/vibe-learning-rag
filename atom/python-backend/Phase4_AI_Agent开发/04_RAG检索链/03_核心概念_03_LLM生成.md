# RAG检索链 - 核心概念3：LLM生成

> 基于检索到的文档，让 LLM 生成准确的答案

---

## 一句话定义

**LLM生成是将检索到的文档注入到 Prompt 上下文中，让 LLM 理解文档内容并生成符合用户问题的自然语言答案的过程。**

---

## 为什么需要上下文注入？

### 问题：LLM 不知道外部知识

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI()

# 直接提问（没有上下文）
question = "我们公司的休假政策是什么？"
answer = llm.invoke(question)

print(answer.content)
# 输出："我无法回答关于您公司的具体政策，因为我没有这些信息。"
# 或者更糟：编造一个看似合理的答案（幻觉）
```

### 解决方案：注入上下文

```python
# 检索相关文档
documents = retriever.search(question)
context = "\n".join([doc.content for doc in documents])

# 构造带上下文的 Prompt
prompt = f"""
基于以下文档回答问题。如果文档中没有相关信息，请说"我不知道"。

文档：
{context}

问题：{question}

答案：
"""

# LLM 基于上下文生成答案
answer = llm.invoke(prompt)
print(answer.content)
# 输出："根据公司政策，员工每年有15天带薪年假..."
```

**关键洞察**：
- LLM 只能基于它"看到"的信息回答
- 上下文注入让 LLM "看到"外部知识
- Prompt 设计决定了 LLM 如何使用这些知识

---

## 上下文注入策略

### 1. 基础注入：直接拼接

```python
def basic_context_injection(question: str, documents: list[str]) -> str:
    """最简单的上下文注入"""
    context = "\n\n".join(documents)

    prompt = f"""
请基于以下文档回答问题：

{context}

问题：{question}
答案：
"""
    return prompt

# 使用
documents = [
    "Python 是一门编程语言，由 Guido van Rossum 创建。",
    "Python 的设计哲学强调代码可读性。"
]
prompt = basic_context_injection("谁创建了 Python？", documents)
```

**优点**：
- ✅ 简单直接
- ✅ 容易理解

**缺点**：
- ❌ 没有明确指令（LLM 可能不遵循文档）
- ❌ 没有处理"文档中没有答案"的情况
- ❌ 没有引用来源

### 2. 结构化注入：带编号和元数据

```python
def structured_context_injection(question: str, documents: list[dict]) -> str:
    """结构化的上下文注入"""
    # 构造文档列表（带编号和元数据）
    context_parts = []
    for i, doc in enumerate(documents, 1):
        context_parts.append(f"""
文档 {i}（来源：{doc['source']}，页码：{doc['page']}）：
{doc['content']}
""")

    context = "\n".join(context_parts)

    prompt = f"""
你是一个专业的问答助手。请严格基于以下文档回答问题。

规则：
1. 只使用文档中的信息回答
2. 如果文档中没有相关信息，明确说"根据提供的文档，我无法回答这个问题"
3. 引用文档时，请注明文档编号（如"根据文档1..."）

文档：
{context}

问题：{question}

答案：
"""
    return prompt

# 使用
documents = [
    {
        "content": "Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。",
        "source": "Python历史.pdf",
        "page": 1
    },
    {
        "content": "Python 的设计哲学强调代码可读性和简洁性。",
        "source": "Python设计.pdf",
        "page": 3
    }
]
prompt = structured_context_injection("谁创建了 Python？", documents)
```

**优点**：
- ✅ 明确的指令和规则
- ✅ 支持引用来源
- ✅ 处理"无答案"情况

**缺点**：
- ❌ Prompt 较长，消耗更多 token

### 3. Few-shot 注入：提供示例

```python
def fewshot_context_injection(question: str, documents: list[str]) -> str:
    """带示例的上下文注入"""
    context = "\n\n".join(documents)

    prompt = f"""
你是一个专业的问答助手。请基于文档回答问题。

示例1：
文档：FastAPI 是一个现代、快速的 Web 框架。
问题：什么是 FastAPI？
答案：FastAPI 是一个现代、快速的 Web 框架。

示例2：
文档：Python 支持多种编程范式。
问题：Java 支持哪些编程范式？
答案：根据提供的文档，我无法回答关于 Java 的问题。

现在请回答：
文档：
{context}

问题：{question}
答案：
"""
    return prompt
```

**优点**：
- ✅ 通过示例引导 LLM 行为
- ✅ 提升答案质量和一致性

**缺点**：
- ❌ Prompt 更长
- ❌ 需要精心设计示例

### 4. 分层注入：重要性排序

```python
def hierarchical_context_injection(
    question: str,
    documents: list[dict]  # 包含 content 和 relevance_score
) -> str:
    """按相关性分层注入"""
    # 按相关性排序
    sorted_docs = sorted(
        documents,
        key=lambda x: x['relevance_score'],
        reverse=True
    )

    # 构造分层上下文
    high_relevance = [
        doc['content'] for doc in sorted_docs
        if doc['relevance_score'] > 0.8
    ]
    medium_relevance = [
        doc['content'] for doc in sorted_docs
        if 0.6 < doc['relevance_score'] <= 0.8
    ]

    prompt = f"""
请基于以下文档回答问题。文档按相关性分为两个层次：

【高相关性文档】（重点参考）：
{chr(10).join(high_relevance)}

【中等相关性文档】（辅助参考）：
{chr(10).join(medium_relevance)}

问题：{question}
答案：
"""
    return prompt
```

**优点**：
- ✅ 突出重要文档
- ✅ 帮助 LLM 聚焦关键信息

**缺点**：
- ❌ 需要准确的相关性评分

---

## Prompt 模板设计

### 1. LangChain PromptTemplate

```python
from langchain.prompts import PromptTemplate

# 定义模板
template = """
你是一个专业的问答助手。请严格基于以下文档回答问题。

规则：
1. 只使用文档中的信息
2. 如果文档中没有答案，说"我不知道"
3. 引用文档时注明来源

文档：
{context}

问题：{question}

答案：
"""

prompt = PromptTemplate(
    template=template,
    input_variables=["context", "question"]
)

# 使用
formatted_prompt = prompt.format(
    context="Python 是一门编程语言",
    question="什么是 Python？"
)
```

### 2. ChatPromptTemplate（对话格式）

```python
from langchain.prompts import ChatPromptTemplate

# 定义对话模板
prompt = ChatPromptTemplate.from_messages([
    ("system", """
你是一个专业的问答助手。请严格基于提供的文档回答问题。

规则：
- 只使用文档中的信息
- 如果文档中没有答案，明确说明
- 保持回答简洁准确
"""),
    ("human", """
文档：
{context}

问题：{question}
""")
])

# 使用
messages = prompt.format_messages(
    context="Python 是一门编程语言",
    question="什么是 Python？"
)
```

### 3. 动态模板：根据文档数量调整

```python
def create_dynamic_prompt(question: str, documents: list[str]) -> str:
    """根据文档数量动态调整 Prompt"""
    num_docs = len(documents)

    if num_docs == 0:
        return f"问题：{question}\n答案：我没有相关文档来回答这个问题。"

    elif num_docs == 1:
        # 单文档：简单模板
        return f"""
基于以下文档回答问题：

{documents[0]}

问题：{question}
答案：
"""

    else:
        # 多文档：结构化模板
        context = "\n\n".join([
            f"文档 {i+1}：\n{doc}"
            for i, doc in enumerate(documents)
        ])
        return f"""
基于以下 {num_docs} 个文档回答问题。如果文档之间有冲突，请综合考虑。

{context}

问题：{question}
答案：
"""
```

---

## 生成参数调优

### 1. Temperature（创造性）

```python
from langchain_openai import ChatOpenAI

# Temperature = 0：确定性输出（推荐 RAG）
llm_deterministic = ChatOpenAI(temperature=0)
answer1 = llm_deterministic.invoke(prompt)
answer2 = llm_deterministic.invoke(prompt)
# answer1 == answer2（每次输出相同）

# Temperature = 0.7：平衡创造性和准确性
llm_balanced = ChatOpenAI(temperature=0.7)

# Temperature = 1.0：高创造性（不推荐 RAG）
llm_creative = ChatOpenAI(temperature=1.0)
```

**RAG 推荐**：
- ✅ `temperature=0`：事实性问答（如"谁创建了 Python？"）
- ⚠️ `temperature=0.3-0.5`：需要一定创造性（如"总结这篇文章"）
- ❌ `temperature>0.7`：不推荐（容易偏离文档）

### 2. Max Tokens（输出长度）

```python
# 短答案
llm_short = ChatOpenAI(max_tokens=100)
answer = llm_short.invoke(prompt)
# 输出：简短的答案（约 100 tokens）

# 长答案
llm_long = ChatOpenAI(max_tokens=500)
answer = llm_long.invoke(prompt)
# 输出：详细的答案（最多 500 tokens）
```

**选择建议**：
```python
def choose_max_tokens(question_type: str) -> int:
    if question_type == "factoid":  # 事实性问题
        return 100  # "谁创建了 Python？" → "Guido van Rossum"
    elif question_type == "explanation":  # 解释性问题
        return 300  # "什么是 RAG？" → 详细解释
    elif question_type == "summary":  # 总结性问题
        return 500  # "总结这篇文章" → 长文本
    else:
        return 200  # 默认值
```

### 3. Top-P（核采样）

```python
# Top-P = 0.1：只考虑最可能的 token（确定性）
llm_focused = ChatOpenAI(top_p=0.1)

# Top-P = 0.9：考虑更多可能的 token（多样性）
llm_diverse = ChatOpenAI(top_p=0.9)
```

**RAG 推荐**：
- ✅ `top_p=0.1-0.3`：事实性问答
- ⚠️ `top_p=0.5-0.7`：需要一定多样性
- ❌ `top_p>0.9`：不推荐（输出不稳定）

### 4. 参数组合建议

```python
# 事实性问答（推荐）
llm_factual = ChatOpenAI(
    temperature=0,
    top_p=0.1,
    max_tokens=200
)

# 创意生成（不推荐 RAG）
llm_creative = ChatOpenAI(
    temperature=0.8,
    top_p=0.9,
    max_tokens=500
)

# 平衡模式
llm_balanced = ChatOpenAI(
    temperature=0.3,
    top_p=0.5,
    max_tokens=300
)
```

---

## 处理特殊情况

### 1. 文档中没有答案

```python
def handle_no_answer(question: str, documents: list[str]) -> str:
    """处理文档中没有答案的情况"""
    context = "\n\n".join(documents)

    prompt = f"""
基于以下文档回答问题。

重要：如果文档中没有相关信息，请明确回答：
"根据提供的文档，我无法回答这个问题。"

不要编造答案，不要使用文档之外的知识。

文档：
{context}

问题：{question}
答案：
"""
    return prompt

# 示例
documents = ["Python 是一门编程语言"]
question = "Java 的特点是什么？"
# 预期输出："根据提供的文档，我无法回答这个问题。"
```

### 2. 文档之间有冲突

```python
def handle_conflicting_docs(question: str, documents: list[dict]) -> str:
    """处理文档冲突"""
    context_parts = []
    for i, doc in enumerate(documents, 1):
        context_parts.append(f"""
文档 {i}（来源：{doc['source']}，日期：{doc['date']}）：
{doc['content']}
""")

    context = "\n".join(context_parts)

    prompt = f"""
基于以下文档回答问题。

注意：如果文档之间有冲突，请：
1. 指出冲突的内容
2. 优先使用日期更新的文档
3. 说明你的判断依据

文档：
{context}

问题：{question}
答案：
"""
    return prompt

# 示例
documents = [
    {
        "content": "Python 3.9 是最新版本",
        "source": "doc1.pdf",
        "date": "2020-10-05"
    },
    {
        "content": "Python 3.13 是最新版本",
        "source": "doc2.pdf",
        "date": "2024-10-01"
    }
]
# 预期输出："根据更新的文档2（2024年），Python 3.13 是最新版本。"
```

### 3. 上下文窗口溢出

```python
def handle_context_overflow(
    question: str,
    documents: list[str],
    max_context_tokens: int = 3000
) -> str:
    """处理上下文窗口溢出"""
    from tiktoken import encoding_for_model

    enc = encoding_for_model("gpt-3.5-turbo")

    # 计算每个文档的 token 数
    doc_tokens = [
        (doc, len(enc.encode(doc)))
        for doc in documents
    ]

    # 选择文档，直到达到 token 限制
    selected_docs = []
    total_tokens = 0

    for doc, tokens in doc_tokens:
        if total_tokens + tokens <= max_context_tokens:
            selected_docs.append(doc)
            total_tokens += tokens
        else:
            break

    context = "\n\n".join(selected_docs)

    prompt = f"""
基于以下文档回答问题：

{context}

问题：{question}
答案：
"""
    return prompt
```

### 4. 多语言支持

```python
def multilingual_prompt(
    question: str,
    documents: list[str],
    language: str = "zh"
) -> str:
    """多语言 Prompt"""
    instructions = {
        "zh": "请用中文回答问题",
        "en": "Please answer in English",
        "ja": "日本語で答えてください"
    }

    context = "\n\n".join(documents)

    prompt = f"""
{instructions.get(language, instructions["en"])}

文档：
{context}

问题：{question}
答案：
"""
    return prompt
```

---

## 完整的 RAG 生成流程

### 使用 LangChain RetrievalQA

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# 1. 准备向量库
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(
    texts=[
        "Python 是一门编程语言，由 Guido van Rossum 于 1991 年创建。",
        "Python 的设计哲学强调代码可读性和简洁性。",
        "Python 支持多种编程范式，包括面向对象、函数式和过程式编程。"
    ],
    embedding=embeddings
)

# 2. 定义 Prompt 模板
prompt_template = """
你是一个专业的 Python 问答助手。请基于以下文档回答问题。

规则：
1. 只使用文档中的信息
2. 如果文档中没有答案，说"我不知道"
3. 保持回答简洁准确

文档：
{context}

问题：{question}

答案：
"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

# 3. 创建 RAG 链
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0),
    retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=True  # 返回引用来源
)

# 4. 提问
result = qa_chain.invoke({"query": "谁创建了 Python？"})

print(f"问题: {result['query']}")
print(f"答案: {result['result']}")
print(f"\n引用来源:")
for i, doc in enumerate(result['source_documents'], 1):
    print(f"文档 {i}: {doc.page_content[:100]}...")
```

### 手写简化版 RAG 生成

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

class SimpleRAG:
    """简化版 RAG（理解原理）"""

    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = None
        self.llm = ChatOpenAI(temperature=0)

    def add_documents(self, documents: list[str]):
        """添加文档到向量库"""
        self.vectorstore = Chroma.from_texts(
            texts=documents,
            embedding=self.embeddings
        )

    def query(self, question: str, k: int = 3) -> dict:
        """RAG 查询"""
        # 1. 检索相关文档
        docs = self.vectorstore.similarity_search(question, k=k)

        # 2. 构造上下文
        context = "\n\n".join([doc.page_content for doc in docs])

        # 3. 构造 Prompt
        prompt = f"""
基于以下文档回答问题。如果文档中没有答案，说"我不知道"。

文档：
{context}

问题：{question}

答案：
"""

        # 4. LLM 生成答案
        answer = self.llm.invoke(prompt)

        return {
            "question": question,
            "answer": answer.content,
            "source_documents": [doc.page_content for doc in docs]
        }

# 使用
rag = SimpleRAG()

# 添加文档
rag.add_documents([
    "Python 是一门编程语言，由 Guido van Rossum 创建。",
    "FastAPI 是一个现代、快速的 Web 框架。",
    "RAG 是检索增强生成技术。"
])

# 查询
result = rag.query("谁创建了 Python？")
print(f"答案: {result['answer']}")
print(f"引用: {result['source_documents'][0][:50]}...")
```

---

## 评估生成质量

### 1. 人工评估

```python
def evaluate_answer(
    question: str,
    answer: str,
    ground_truth: str
) -> dict:
    """人工评估答案质量"""
    return {
        "question": question,
        "answer": answer,
        "ground_truth": ground_truth,
        "评分": {
            "准确性": 5,  # 1-5分
            "完整性": 4,
            "简洁性": 5,
            "引用来源": 3
        }
    }
```

### 2. 自动评估：RAGAS

```python
from ragas import evaluate
from ragas.metrics import (
    faithfulness,  # 忠实度：答案是否基于文档
    answer_relevancy,  # 相关性：答案是否回答问题
    context_precision,  # 上下文精度：检索的文档是否相关
    context_recall  # 上下文召回：是否检索到所有相关文档
)

# 准备评估数据
eval_data = {
    "question": ["谁创建了 Python？"],
    "answer": ["Guido van Rossum 创建了 Python"],
    "contexts": [["Python 是一门编程语言，由 Guido van Rossum 创建。"]],
    "ground_truth": ["Guido van Rossum"]
}

# 评估
results = evaluate(
    eval_data,
    metrics=[
        faithfulness,
        answer_relevancy,
        context_precision,
        context_recall
    ]
)

print(results)
# {
#   "faithfulness": 0.95,  # 答案忠实于文档
#   "answer_relevancy": 0.98,  # 答案相关
#   "context_precision": 1.0,  # 上下文精准
#   "context_recall": 1.0  # 召回完整
# }
```

### 3. A/B 测试

```python
def ab_test_prompts(
    question: str,
    documents: list[str],
    prompt_a: str,
    prompt_b: str
) -> dict:
    """对比两个 Prompt 的效果"""
    llm = ChatOpenAI(temperature=0)

    # 测试 Prompt A
    answer_a = llm.invoke(prompt_a.format(
        context="\n".join(documents),
        question=question
    ))

    # 测试 Prompt B
    answer_b = llm.invoke(prompt_b.format(
        context="\n".join(documents),
        question=question
    ))

    return {
        "prompt_a_answer": answer_a.content,
        "prompt_b_answer": answer_b.content,
        # 人工评分或自动评分
    }
```

---

## 常见问题

### Q1: 如何防止 LLM 编造答案？

**A**: 在 Prompt 中明确指令。

```python
# ❌ 弱指令
prompt = f"基于文档回答：{context}\n问题：{question}"

# ✅ 强指令
prompt = f"""
严格规则：
1. 只使用文档中的信息
2. 如果文档中没有答案，必须说"我不知道"
3. 不要使用你的背景知识
4. 不要推测或编造

文档：{context}
问题：{question}
答案：
"""
```

### Q2: 如何让 LLM 引用来源？

**A**: 在 Prompt 中要求引用。

```python
prompt = f"""
请回答问题，并引用文档编号。

示例：
问题：什么是 Python？
答案：根据文档1，Python 是一门编程语言。

文档：
{context}

问题：{question}
答案：
"""
```

### Q3: 如何处理长文档？

**A**: 分块 + 多轮检索。

```python
# 方法1：分块后只检索相关块
chunks = split_document(long_document, chunk_size=500)
relevant_chunks = retriever.search(question, chunks, k=3)

# 方法2：多轮检索
# 第一轮：粗检索
candidates = retriever.search(question, k=20)
# 第二轮：精检索（ReRank）
final_docs = rerank(candidates, k=3)
```

---

## 总结

**LLM生成的核心价值**：
1. 理解文档内容
2. 生成自然语言答案
3. 保持答案的准确性和可追溯性

**在 RAG 中的作用**：
- 将检索到的文档转化为用户友好的答案
- 决定 RAG 的最终输出质量
- 需要精心设计 Prompt 和参数

**最佳实践**：
- 使用结构化 Prompt（明确指令、规则、示例）
- 设置 `temperature=0` 保证确定性
- 要求 LLM 引用来源
- 处理"无答案"情况
- 评估生成质量

---

**下一步**：学习 [07_实战代码_01_基础RAG链](./07_实战代码_01_基础RAG链.md)，动手实现完整的 RAG 系统。
