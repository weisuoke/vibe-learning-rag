# RunnableParallel并行执行 - 核心概念2：结果合并策略

> 深入理解并行执行结果的合并机制和策略

---

## 概述

本文档深入讲解 RunnableParallel 的结果合并机制：
1. **字典合并策略**：基础的键值对合并
2. **列表合并策略**：数组结果的合并
3. **自定义合并逻辑**：复杂场景的处理
4. **键冲突处理**：重复键名的解决方案

**学习目标**：
- 理解字典合并的原理
- 掌握不同的合并策略
- 能够处理键冲突问题
- 能够手写结果合并器

---

## 第一部分：字典合并原理

### 1.1 基础字典合并

**RunnableParallel 默认使用字典合并结果**

```python
# 基础示例
from langchain_core.runnables import RunnableParallel, RunnableLambda

parallel = RunnableParallel(
    task1=RunnableLambda(lambda x: x + 1),
    task2=RunnableLambda(lambda x: x * 2),
    task3=RunnableLambda(lambda x: x ** 2)
)

result = parallel.invoke(5)
print(result)
# 输出: {"task1": 6, "task2": 10, "task3": 25}
```

**合并过程**：
```
1. 执行 task1 → 6
2. 执行 task2 → 10
3. 执行 task3 → 25
4. 合并结果 → {"task1": 6, "task2": 10, "task3": 25}
```

---

### 1.2 字典合并的实现

**源码分析**（简化版）：

```python
class RunnableParallel:
    async def ainvoke(self, input):
        # 1. 执行所有任务
        tasks = {
            key: runnable.ainvoke(input)
            for key, runnable in self.steps.items()
        }
        results = await asyncio.gather(*tasks.values())

        # 2. 合并结果（字典推导）
        return dict(zip(tasks.keys(), results))
        # 等价于:
        # return {
        #     key: result
        #     for key, result in zip(tasks.keys(), results)
        # }
```

**关键机制**：
- 使用 `dict(zip(keys, values))` 合并
- 保持键名和结果的对应关系
- 返回新的字典对象

---

### 1.3 嵌套字典合并

**支持嵌套的并行执行**

```python
# 嵌套并行
parallel = RunnableParallel(
    analysis=RunnableParallel(
        sentiment=sentiment_chain,
        topic=topic_chain
    ),
    metadata=RunnableParallel(
        author=author_chain,
        date=date_chain
    )
)

result = parallel.invoke({"text": "..."})
# 输出:
# {
#     "analysis": {
#         "sentiment": "positive",
#         "topic": "AI"
#     },
#     "metadata": {
#         "author": "John",
#         "date": "2026-02-18"
#     }
# }
```

**嵌套合并过程**：
```
1. 外层并行执行 analysis 和 metadata
2. analysis 内部并行执行 sentiment 和 topic
3. metadata 内部并行执行 author 和 date
4. 内层结果合并为字典
5. 外层结果合并为嵌套字典
```

---

## 第二部分：列表合并策略

### 2.1 列表结果的处理

**当任务返回列表时的合并**

```python
# 场景：多个检索器返回文档列表
from langchain_core.runnables import RunnableParallel

parallel = RunnableParallel(
    vector=vector_retriever,    # 返回: [doc1, doc2, doc3]
    kg=kg_retriever,            # 返回: [doc4, doc5]
    search=search_retriever     # 返回: [doc6, doc7, doc8]
)

result = parallel.invoke({"query": "..."})
# 输出:
# {
#     "vector": [doc1, doc2, doc3],
#     "kg": [doc4, doc5],
#     "search": [doc6, doc7, doc8]
# }
```

**问题**：结果是嵌套的字典，不是扁平的列表

---

### 2.2 扁平化列表合并

**使用 RunnableLambda 扁平化结果**

```python
from langchain_core.runnables import RunnableParallel, RunnableLambda

def flatten_results(data):
    """扁平化字典中的列表"""
    all_docs = []
    for docs in data.values():
        all_docs.extend(docs)
    return all_docs

# 并行检索 + 扁平化
chain = (
    RunnableParallel(
        vector=vector_retriever,
        kg=kg_retriever,
        search=search_retriever
    )
    | RunnableLambda(flatten_results)
)

result = chain.invoke({"query": "..."})
# 输出: [doc1, doc2, doc3, doc4, doc5, doc6, doc7, doc8]
```

---

### 2.3 去重合并

**处理重复文档**

```python
def deduplicate_docs(data):
    """去重并合并文档"""
    seen = set()
    unique_docs = []

    for docs in data.values():
        for doc in docs:
            # 使用文档内容作为唯一标识
            doc_id = hash(doc.page_content)
            if doc_id not in seen:
                seen.add(doc_id)
                unique_docs.append(doc)

    return unique_docs

# 并行检索 + 去重
chain = (
    RunnableParallel(
        vector=vector_retriever,
        kg=kg_retriever,
        search=search_retriever
    )
    | RunnableLambda(deduplicate_docs)
)
```

---

### 2.4 加权合并

**根据来源给文档打分**

```python
def weighted_merge(data):
    """加权合并文档"""
    weights = {
        "vector": 1.0,   # 向量检索权重最高
        "kg": 0.8,       # 知识图谱次之
        "search": 0.6    # 搜索引擎最低
    }

    weighted_docs = []
    for source, docs in data.items():
        weight = weights.get(source, 0.5)
        for doc in docs:
            doc.metadata["score"] = weight
            weighted_docs.append(doc)

    # 按分数排序
    weighted_docs.sort(key=lambda d: d.metadata["score"], reverse=True)
    return weighted_docs

# 并行检索 + 加权合并
chain = (
    RunnableParallel(
        vector=vector_retriever,
        kg=kg_retriever,
        search=search_retriever
    )
    | RunnableLambda(weighted_merge)
)
```

---

## 第三部分：自定义合并逻辑

### 3.1 条件合并

**根据条件选择性合并**

```python
def conditional_merge(data):
    """条件合并：只保留高质量结果"""
    result = {}

    # 情感分析：只保留置信度 > 0.8 的结果
    if data["sentiment"]["confidence"] > 0.8:
        result["sentiment"] = data["sentiment"]["label"]

    # 主题提取：只保留非空结果
    if data["topic"]:
        result["topic"] = data["topic"]

    # 实体识别：只保留至少有1个实体的结果
    if len(data["entities"]) > 0:
        result["entities"] = data["entities"]

    return result

# 使用
chain = (
    RunnableParallel(
        sentiment=sentiment_chain,
        topic=topic_chain,
        entities=entity_chain
    )
    | RunnableLambda(conditional_merge)
)
```

---

### 3.2 聚合合并

**将多个结果聚合为单一值**

```python
def aggregate_scores(data):
    """聚合多个模型的评分"""
    scores = [
        data["gpt4"]["score"],
        data["claude"]["score"],
        data["gemini"]["score"]
    ]

    return {
        "average": sum(scores) / len(scores),
        "max": max(scores),
        "min": min(scores),
        "consensus": sum(1 for s in scores if s > 0.7) >= 2
    }

# 多模型评分 + 聚合
chain = (
    RunnableParallel(
        gpt4=gpt4_scorer,
        claude=claude_scorer,
        gemini=gemini_scorer
    )
    | RunnableLambda(aggregate_scores)
)
```

---

### 3.3 格式转换

**将字典转换为其他格式**

```python
def dict_to_markdown(data):
    """将字典转换为 Markdown 格式"""
    lines = ["# 分析结果\n"]

    for key, value in data.items():
        lines.append(f"## {key.title()}")
        lines.append(f"{value}\n")

    return "\n".join(lines)

# 并行分析 + Markdown 输出
chain = (
    RunnableParallel(
        sentiment=sentiment_chain,
        topic=topic_chain,
        summary=summary_chain
    )
    | RunnableLambda(dict_to_markdown)
)

result = chain.invoke({"text": "..."})
# 输出:
# # 分析结果
#
# ## Sentiment
# positive
#
# ## Topic
# AI
#
# ## Summary
# ...
```

---

## 第四部分：键冲突处理

### 4.1 键冲突的问题

**当键名重复时会发生什么？**

```python
# ❌ 错误：键名冲突
parallel = RunnableParallel(
    result=chain1,  # 输出: "A"
    result=chain2   # 输出: "B"
)
# Python 会报错：SyntaxError: duplicate argument 'result'
```

**问题根源**：
- Python 字典不允许重复键
- 后面的值会覆盖前面的值

---

### 4.2 解决方案1：使用不同的键名

**最简单的解决方案**

```python
# ✅ 正确：使用不同的键名
parallel = RunnableParallel(
    result1=chain1,
    result2=chain2,
    result3=chain3
)

result = parallel.invoke(input)
# {"result1": "A", "result2": "B", "result3": "C"}
```

---

### 4.3 解决方案2：嵌套字典

**使用嵌套结构避免冲突**

```python
# ✅ 正确：嵌套字典
parallel = RunnableParallel(
    model1=RunnableParallel(
        result=chain1,
        metadata=metadata1
    ),
    model2=RunnableParallel(
        result=chain2,
        metadata=metadata2
    )
)

result = parallel.invoke(input)
# {
#     "model1": {"result": "A", "metadata": {...}},
#     "model2": {"result": "B", "metadata": {...}}
# }
```

---

### 4.4 解决方案3：后处理合并

**执行后手动处理冲突**

```python
def resolve_conflicts(data):
    """解决键冲突：保留所有值"""
    resolved = {}

    for key, value in data.items():
        if key in resolved:
            # 冲突：转换为列表
            if not isinstance(resolved[key], list):
                resolved[key] = [resolved[key]]
            resolved[key].append(value)
        else:
            resolved[key] = value

    return resolved

# 使用
parallel = RunnableParallel(
    result_1=chain1,
    result_2=chain2
)
chain = parallel | RunnableLambda(resolve_conflicts)
```

---

## 第五部分：手写结果合并器

### 5.1 基础合并器

```python
from typing import Dict, Any, List, Callable

class ResultMerger:
    """结果合并器"""

    def __init__(self, strategy: str = "dict"):
        """
        Args:
            strategy: 合并策略
                - "dict": 字典合并（默认）
                - "list": 列表合并
                - "flatten": 扁平化列表
        """
        self.strategy = strategy

    def merge(self, results: Dict[str, Any]) -> Any:
        """合并结果"""
        if self.strategy == "dict":
            return self._merge_dict(results)
        elif self.strategy == "list":
            return self._merge_list(results)
        elif self.strategy == "flatten":
            return self._merge_flatten(results)
        else:
            raise ValueError(f"Unknown strategy: {self.strategy}")

    def _merge_dict(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """字典合并"""
        return results

    def _merge_list(self, results: Dict[str, Any]) -> List[Any]:
        """列表合并"""
        return list(results.values())

    def _merge_flatten(self, results: Dict[str, Any]) -> List[Any]:
        """扁平化列表合并"""
        flattened = []
        for value in results.values():
            if isinstance(value, list):
                flattened.extend(value)
            else:
                flattened.append(value)
        return flattened

# 使用示例
merger = ResultMerger(strategy="flatten")

results = {
    "task1": [1, 2, 3],
    "task2": [4, 5],
    "task3": [6, 7, 8]
}

merged = merger.merge(results)
print(merged)  # [1, 2, 3, 4, 5, 6, 7, 8]
```

---

### 5.2 高级合并器

```python
class AdvancedMerger:
    """高级结果合并器"""

    def __init__(
        self,
        dedup: bool = False,
        filter_fn: Callable = None,
        transform_fn: Callable = None
    ):
        """
        Args:
            dedup: 是否去重
            filter_fn: 过滤函数
            transform_fn: 转换函数
        """
        self.dedup = dedup
        self.filter_fn = filter_fn
        self.transform_fn = transform_fn

    def merge(self, results: Dict[str, Any]) -> Any:
        """合并结果"""
        # 1. 扁平化
        items = []
        for value in results.values():
            if isinstance(value, list):
                items.extend(value)
            else:
                items.append(value)

        # 2. 过滤
        if self.filter_fn:
            items = [item for item in items if self.filter_fn(item)]

        # 3. 去重
        if self.dedup:
            seen = set()
            unique_items = []
            for item in items:
                item_id = hash(str(item))
                if item_id not in seen:
                    seen.add(item_id)
                    unique_items.append(item)
            items = unique_items

        # 4. 转换
        if self.transform_fn:
            items = [self.transform_fn(item) for item in items]

        return items

# 使用示例
merger = AdvancedMerger(
    dedup=True,
    filter_fn=lambda x: x > 5,
    transform_fn=lambda x: x * 2
)

results = {
    "task1": [1, 2, 3, 6, 7],
    "task2": [4, 5, 6, 8],
    "task3": [7, 8, 9]
}

merged = merger.merge(results)
print(merged)  # [12, 14, 16, 18] (去重、过滤、转换后)
```

---

### 5.3 加权合并器

```python
class WeightedMerger:
    """加权合并器"""

    def __init__(self, weights: Dict[str, float]):
        """
        Args:
            weights: 每个来源的权重
        """
        self.weights = weights

    def merge(self, results: Dict[str, Any]) -> List[tuple]:
        """加权合并"""
        weighted_items = []

        for source, items in results.items():
            weight = self.weights.get(source, 0.5)

            if isinstance(items, list):
                for item in items:
                    weighted_items.append((item, weight, source))
            else:
                weighted_items.append((items, weight, source))

        # 按权重排序
        weighted_items.sort(key=lambda x: x[1], reverse=True)

        return weighted_items

# 使用示例
merger = WeightedMerger(weights={
    "vector": 1.0,
    "kg": 0.8,
    "search": 0.6
})

results = {
    "vector": ["doc1", "doc2"],
    "kg": ["doc3"],
    "search": ["doc4", "doc5"]
}

merged = merger.merge(results)
# [
#     ("doc1", 1.0, "vector"),
#     ("doc2", 1.0, "vector"),
#     ("doc3", 0.8, "kg"),
#     ("doc4", 0.6, "search"),
#     ("doc5", 0.6, "search")
# ]
```

---

## 第六部分：实际应用场景

### 6.1 RAG 多路检索合并

```python
from langchain_core.runnables import RunnableParallel, RunnableLambda

# 定义合并策略
def merge_retrieval_results(data):
    """合并多路检索结果"""
    # 1. 收集所有文档
    all_docs = []
    for source, docs in data.items():
        for doc in docs:
            doc.metadata["source"] = source
            all_docs.append(doc)

    # 2. 去重（基于内容）
    seen = set()
    unique_docs = []
    for doc in all_docs:
        content_hash = hash(doc.page_content)
        if content_hash not in seen:
            seen.add(content_hash)
            unique_docs.append(doc)

    # 3. 按相关性排序
    unique_docs.sort(
        key=lambda d: d.metadata.get("score", 0),
        reverse=True
    )

    # 4. 返回 top-k
    return unique_docs[:10]

# RAG 检索链
retrieval_chain = (
    RunnableParallel(
        vector=vector_retriever,
        kg=kg_retriever,
        search=search_retriever
    )
    | RunnableLambda(merge_retrieval_results)
)
```

---

### 6.2 多模型结果聚合

```python
def aggregate_model_outputs(data):
    """聚合多个模型的输出"""
    outputs = [
        data["gpt4"],
        data["claude"],
        data["gemini"]
    ]

    # 1. 投票机制
    from collections import Counter
    votes = Counter(outputs)
    consensus = votes.most_common(1)[0][0]

    # 2. 置信度计算
    confidence = votes[consensus] / len(outputs)

    return {
        "result": consensus,
        "confidence": confidence,
        "all_outputs": outputs
    }

# 多模型链
multi_model_chain = (
    RunnableParallel(
        gpt4=gpt4_chain,
        claude=claude_chain,
        gemini=gemini_chain
    )
    | RunnableLambda(aggregate_model_outputs)
)
```

---

### 6.3 内容生成管道

```python
def format_blog_post(data):
    """格式化博客文章"""
    return {
        "title": data["title"],
        "content": data["article"],
        "metadata": {
            "tags": data["tags"],
            "seo_keywords": data["seo"],
            "image_prompt": data["image_prompt"],
            "estimated_reading_time": len(data["article"].split()) // 200
        }
    }

# 博客生成链
blog_chain = (
    RunnableParallel(
        title=title_generator,
        article=article_generator,
        tags=tag_generator,
        seo=seo_generator,
        image_prompt=image_prompt_generator
    )
    | RunnableLambda(format_blog_post)
)
```

---

## 学习检查清单

- [ ] 理解字典合并的基本原理
- [ ] 掌握列表结果的处理方法
- [ ] 能够实现自定义合并逻辑
- [ ] 知道如何处理键冲突
- [ ] 能够手写结果合并器
- [ ] 理解实际应用场景

---

## 参考资料

[来源: How to Use RunnableParallel in LCEL for Parallel Processing - https://medium.com/@mustafa_akca/how-to-use-runnableparallel-in-lcel-for-parallel-processing-631209bcf2bb, 访问日期: 2026-02-18]

[来源: Building Production-Ready AI Pipelines with LangChain Runnables - https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557, 访问日期: 2026-02-18]

---

**版本**: v1.0
**最后更新**: 2026-02-18
**行数**: 约480行
