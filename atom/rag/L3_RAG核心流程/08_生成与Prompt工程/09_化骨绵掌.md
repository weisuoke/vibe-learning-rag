# 化骨绵掌

> 10个2分钟知识卡片 - 快速掌握生成与Prompt工程核心

---

## 卡片1：Context Engineering范式转变

**一句话：** Context不是背景信息，而是需要系统化管理的基础设施

**核心观点：**
- 2025-2026年从Prompt Engineering到Context Engineering的范式转变
- Context = System Layer + RAG Layer + Tools Layer + Memory Layer
- 像管理数据库一样管理上下文

**举例：**
```python
# 传统Prompt Engineering
prompt = f"参考资料：{docs}\n问题：{query}"

# Context Engineering
context = {
    "system": system_prompts.get_for_task(query),
    "rag": retrieval.search(query),
    "tools": tools.get_available(),
    "memory": memory.get_relevant(query)
}
```

**应用：** 生产级RAG系统必须采用Context Engineering架构

**来源：** Redis "Context Engineering" (2025-09)

---

## 卡片2：System/User Prompt分离

**一句话：** 角色定义与任务指令分离，提升输出一致性40%

**核心观点：**
- System Prompt：定义角色和全局约束
- User Prompt：包含具体任务和数据
- 分离后指令混淆率从35%降至8%

**举例：**
```python
# System Prompt（全局规则）
system = "你是严谨的知识助手，只基于参考资料回答"

# User Prompt（具体任务）
user = f"参考资料：{context}\n问题：{query}"

response = llm.generate(
    messages=[
        {"role": "system", "content": system},
        {"role": "user", "content": user}
    ]
)
```

**应用：** 所有RAG系统都应实施System/User分离

---

## 卡片3：Temperature参数真相

**一句话：** Temperature不是越低越好，需根据任务类型选择

**核心观点：**
- 事实性问答：0.1-0.2（Groundedness >0.85）
- 文档总结：0.2-0.3（准确+流畅）
- 内容改写：0.5-0.7（多样性）
- Temperature >0.5时幻觉风险增加40%

**举例：**
```python
# 事实性RAG
response = llm.generate(prompt, temperature=0.1)

# 创意扩展
response = llm.generate(prompt, temperature=0.7)
```

**应用：** 根据任务类型动态调整Temperature

**来源：** Openlayer "RAG Groundedness" (2026-02)

---

## 卡片4：Citation-aware RAG

**一句话：** 2025-2026标准：内联引用锚点+空间元数据实现精确溯源

**核心观点：**
- 第一代：文档ID `[doc1]`
- 第二代：文档+页码 `[doc1, p.15]`
- 第三代：空间元数据 `<c>1.2</c>` + bounding box

**举例：**
```python
answer = "Python是解释型语言<c>1.2</c>"
citations = {
    "1.2": {
        "doc_id": "doc1",
        "page": 15,
        "bbox": [100, 200, 400, 250],  # 精确位置
        "confidence": 0.92
    }
}
```

**应用：** 生产环境必需的可追溯性标准

**来源：** Tensorlake "Citation-Aware RAG" (2025-09)

---

## 卡片5：RAG Triad评估体系

**一句话：** 三大指标全面评估RAG质量：Context Relevance + Groundedness + Answer Relevance

**核心观点：**
- Context Relevance：检索文档是否相关（>0.7）
- Groundedness：答案是否基于上下文（>0.85关键领域，>0.75一般）
- Answer Relevance：答案是否回答问题（>0.80）
- LLM-as-judge与人类评估者80%一致

**举例：**
```python
def evaluate_rag(query, context, answer):
    context_rel = llm_judge(query, context)
    groundedness = check_groundedness(answer, context)
    answer_rel = llm_judge(query, answer)
    
    overall = (context_rel + groundedness + answer_rel) / 3
    return {"passed": overall >= 0.75}
```

**应用：** 生产环境质量监控标准

**来源：** Openlayer (2026-02)

---

## 卡片6：Context Pruning黄金法则

**一句话：** 上下文最佳范围1500-2500 tokens，超过后质量反而下降

**核心观点：**
- 500 tokens：Groundedness 0.82
- 1500-2500 tokens：Groundedness 0.87-0.88（最佳）
- 5000 tokens：Groundedness 0.79（下降）
- 10000 tokens：Groundedness 0.71（显著下降）

**举例：**
```python
def prune_context(docs, max_tokens=2000):
    # 1. 相关性过滤（score >0.7）
    relevant = [d for d in docs if d['score'] > 0.7]
    
    # 2. 多样性过滤（去重）
    diverse = remove_duplicates(relevant)
    
    # 3. Token预算控制
    return fit_token_budget(diverse, max_tokens)
```

**应用：** 所有RAG系统都需要Context Pruning

**来源：** Redis "Context Engineering" (2025-09)

---

## 卡片7：Multi-Stage RAG威力

**一句话：** Draft → Critique → Synthesis三阶段流程，幻觉率从28%降至12%

**核心观点：**
- Single-Stage：幻觉率28%，Groundedness 0.72
- 3-Stage：幻觉率12%，Groundedness 0.87（提升21%）
- 5-Stage：幻觉率7%，Groundedness 0.91（最佳但成本高）

**举例：**
```python
def multi_stage_rag(query, context):
    # Stage 1: Draft
    draft = generate(query, context)
    
    # Stage 2: Critique
    critique = llm_critique(draft, context)
    
    # Stage 3: Synthesis
    final = improve(draft, critique, context)
    
    return final
```

**应用：** 关键领域使用5-Stage，一般场景使用3-Stage

**来源：** Stack AI (2025-11)

---

## 卡片8：四种上下文问题

**一句话：** Context Overload、Distraction、Confusion、Clash需要不同修剪策略

**核心观点：**
- Overload（过载）：信息太多 → Token预算控制
- Distraction（分散）：无关信息 → 相关性过滤（>0.7）
- Confusion（混淆）：矛盾信息 → 矛盾检测与解决
- Clash（冲突）：时间冲突 → 优先使用最新信息

**举例：**
```python
# Overload解决
pruned = limit_tokens(docs, max_tokens=2000)

# Distraction解决
relevant = [d for d in docs if d['score'] > 0.7]

# Confusion解决
resolved = detect_and_resolve_contradictions(docs)

# Clash解决
recent = sort_by_date(docs, prefer_recent=True)
```

**应用：** 诊断和解决上下文质量问题

---

## 卡片9：生成参数最佳配置

**一句话：** RAG生产环境推荐：Temperature 0.1 + Top-P 0.9 + Max Tokens 200

**核心观点：**
- Temperature：0.1-0.2（事实性优先）
- Top-P：0.9-0.95（保留流畅性）
- Top-K：不使用（让Top-P自动调整）
- Max Tokens：根据任务（问答150，总结300，解释500）

**举例：**
```python
# RAG标准配置
PRODUCTION_CONFIG = {
    "temperature": 0.1,
    "top_p": 0.9,
    "max_tokens": 200,
    "frequency_penalty": 0,
    "presence_penalty": 0
}

response = llm.generate(prompt, **PRODUCTION_CONFIG)
```

**应用：** 生产环境默认配置

---

## 卡片10：完整RAG生成流程

**一句话：** 生成前验证 → Multi-Stage生成 → 生成后检测 → 质量监控

**核心观点：**
```
生成前：
- Context Pruning（1500-2500 tokens）
- 相关性检查（>0.7）
- System/User分离

生成中：
- Draft → Critique → Synthesis
- Temperature 0.1-0.2
- Citation标记

生成后：
- Groundedness检测（>0.85）
- 幻觉检测（规则+LLM）
- 引用验证

持续监控：
- RAG Triad指标
- 质量趋势分析
- 低质量案例审核
```

**应用：** 生产级RAG系统完整流程

---

## 快速复习检查清单

### Context Engineering
- [ ] 理解四层架构（System + RAG + Tools + Memory）
- [ ] 掌握System/User Prompt分离
- [ ] 了解Context as Infrastructure理念

### 参数调优
- [ ] Temperature根据任务类型选择（0.1-0.2事实性）
- [ ] Top-P使用0.9-0.95
- [ ] Max Tokens根据任务调整

### 引用与溯源
- [ ] 实现Citation-aware RAG
- [ ] 使用空间元数据（bounding box）
- [ ] 提供可追溯性

### 质量控制
- [ ] 实施RAG Triad评估
- [ ] Groundedness >0.85（关键）或>0.75（一般）
- [ ] 幻觉检测（规则+LLM）

### Context Pruning
- [ ] 控制在1500-2500 tokens
- [ ] 相关性过滤（>0.7）
- [ ] 多样性去重（>0.8）

### Multi-Stage RAG
- [ ] 实施Draft → Critique → Synthesis
- [ ] 关键领域使用5-Stage
- [ ] 一般场景使用3-Stage

---

## 2分钟速记口诀

```
Context工程四层架构，System User必须分离
Temperature低温事实准，0.1到0.2最合理
Citation引用带坐标，空间元数据可追溯
RAG Triad三指标，Groundedness要0.85
Context修剪有黄金，1500到2500最优
Multi-Stage三阶段，幻觉从28降到12
四种问题四策略，Overload Distraction Confusion Clash
生成参数有标准，0.1温度0.9 Top-P
质量监控要持续，低于阈值进审核
完整流程记心间，生产环境保质量
```

---

## 学习路径建议

### 第1周：基础概念
- 卡片1-3：Context Engineering、System/User分离、Temperature

### 第2周：引用与质量
- 卡片4-5：Citation-aware RAG、RAG Triad

### 第3周：优化技术
- 卡片6-8：Context Pruning、Multi-Stage RAG、四种问题

### 第4周：生产实践
- 卡片9-10：参数配置、完整流程

---

## 延伸学习

### 深入研究
1. Redis "Context Engineering Best Practices" (2025-09)
2. Tensorlake "Citation-Aware RAG" (2025-09)
3. Openlayer "Measuring RAG Groundedness" (2026-02)
4. Stack AI "Prompt Engineering for RAG" (2025-11)

### 实践项目
1. 实现基础RAG系统（System/User分离 + Temperature调优）
2. 添加Citation-aware功能（空间元数据）
3. 实施RAG Triad评估（质量监控）
4. 优化Context Pruning（1500-2500 tokens）
5. 部署Multi-Stage RAG（3阶段流程）

---

**版本：** v1.0 (2025-2026最新知识)
**最后更新：** 2026-02-16
