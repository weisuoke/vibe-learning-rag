# å®æˆ˜ä»£ç  - åœºæ™¯ 2: Planning Agent å®ç°

## åœºæ™¯æè¿°

**ç›®æ ‡**: ä½¿ç”¨ LangGraph æ„å»º Plan-and-Execute é£æ ¼çš„è§„åˆ’ä»£ç†,å®ç°å¤æ‚æŸ¥è¯¢çš„ä»»åŠ¡åˆ†è§£å’Œé€æ­¥æ‰§è¡Œ

**éš¾ç‚¹**:
- å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡
- ç®¡ç†ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
- æ ¹æ®æ‰§è¡Œç»“æœåŠ¨æ€è°ƒæ•´è®¡åˆ’

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ LangGraph çŠ¶æ€å›¾å®ç°è§„åˆ’ã€æ‰§è¡Œã€åæ€å¾ªç¯

---

## ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
uv add langgraph langchain langchain-openai python-dotenv
```

---

## å®Œæ•´ä»£ç 

```python
"""
Planning Agent - Plan-and-Execute å®ç°
æ¼”ç¤º: å¤æ‚æŸ¥è¯¢çš„ä»»åŠ¡åˆ†è§£å’Œæ‰§è¡Œ

æŠ€æœ¯æ ˆ:
- LangGraph: 0.2.0+
- LangChain: 0.1.0+
- OpenAI: 1.0.0+
"""

import os
from typing import TypedDict, List, Annotated
from dotenv import load_dotenv
import operator

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ===== 1. åˆå§‹åŒ– LLM =====
print("åˆå§‹åŒ– LLM...")

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    api_key=os.getenv("OPENAI_API_KEY")
)

# ===== 2. å®šä¹‰çŠ¶æ€ =====

class AgentState(TypedDict):
    """ä»£ç†çŠ¶æ€"""
    query: str                                    # åŸå§‹æŸ¥è¯¢
    plan: List[str]                               # ä»»åŠ¡è®¡åˆ’
    current_task_index: int                       # å½“å‰ä»»åŠ¡ç´¢å¼•
    task_results: Annotated[List[str], operator.add]  # ä»»åŠ¡ç»“æœåˆ—è¡¨
    final_answer: str                             # æœ€ç»ˆç­”æ¡ˆ
    iteration: int                                # è¿­ä»£æ¬¡æ•°

# ===== 3. è§„åˆ’èŠ‚ç‚¹ =====

def plan_node(state: AgentState) -> AgentState:
    """ç”Ÿæˆä»»åŠ¡è®¡åˆ’"""
    query = state["query"]

    print(f"\n{'='*60}")
    print(f"ğŸ“‹ è§„åˆ’é˜¶æ®µ")
    print(f"{'='*60}")
    print(f"æŸ¥è¯¢: {query}\n")

    # ç”Ÿæˆè®¡åˆ’
    plan_prompt = f"""
å°†ä»¥ä¸‹æŸ¥è¯¢åˆ†è§£ä¸º 3-5 ä¸ªå¯æ‰§è¡Œçš„å­ä»»åŠ¡ã€‚
æ¯ä¸ªä»»åŠ¡åº”è¯¥ç‹¬ç«‹ã€å…·ä½“ã€å¯æ‰§è¡Œã€‚

æŸ¥è¯¢: {query}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›ä»»åŠ¡åˆ—è¡¨(æ¯è¡Œä¸€ä¸ªä»»åŠ¡):
1. ä»»åŠ¡æè¿°
2. ä»»åŠ¡æè¿°
3. ä»»åŠ¡æè¿°
"""

    response = llm.invoke([HumanMessage(content=plan_prompt)])
    plan_text = response.content

    # è§£æä»»åŠ¡
    tasks = []
    for line in plan_text.split("\n"):
        line = line.strip()
        if line and (line[0].isdigit() or line.startswith("-")):
            # ç§»é™¤ç¼–å·
            task = line.split(".", 1)[-1].strip()
            if task:
                tasks.append(task)

    print("ç”Ÿæˆçš„è®¡åˆ’:")
    for i, task in enumerate(tasks, 1):
        print(f"  {i}. {task}")

    return {
        "plan": tasks,
        "current_task_index": 0,
        "iteration": state.get("iteration", 0) + 1
    }

# ===== 4. æ‰§è¡ŒèŠ‚ç‚¹ =====

def execute_node(state: AgentState) -> AgentState:
    """æ‰§è¡Œå½“å‰ä»»åŠ¡"""
    plan = state["plan"]
    current_index = state["current_task_index"]
    task_results = state.get("task_results", [])

    if current_index >= len(plan):
        return state

    current_task = plan[current_index]

    print(f"\n{'='*60}")
    print(f"âš™ï¸  æ‰§è¡Œé˜¶æ®µ - ä»»åŠ¡ {current_index + 1}/{len(plan)}")
    print(f"{'='*60}")
    print(f"ä»»åŠ¡: {current_task}\n")

    # æ‰§è¡Œä»»åŠ¡(æ¨¡æ‹Ÿ)
    execute_prompt = f"""
æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡å¹¶è¿”å›ç»“æœ:

ä»»åŠ¡: {current_task}

å·²æœ‰ä¸Šä¸‹æ–‡:
{chr(10).join(task_results) if task_results else "æ— "}

è¯·æä¾›ç®€æ´çš„æ‰§è¡Œç»“æœ:
"""

    response = llm.invoke([HumanMessage(content=execute_prompt)])
    result = response.content.strip()

    print(f"ç»“æœ: {result}\n")

    return {
        "current_task_index": current_index + 1,
        "task_results": [f"ä»»åŠ¡ {current_index + 1}: {result}"]
    }

# ===== 5. åæ€èŠ‚ç‚¹ =====

def reflect_node(state: AgentState) -> AgentState:
    """åæ€æ‰§è¡Œç»“æœ"""
    query = state["query"]
    task_results = state.get("task_results", [])

    print(f"\n{'='*60}")
    print(f"ğŸ¤” åæ€é˜¶æ®µ")
    print(f"{'='*60}\n")

    # è¯„ä¼°ç»“æœ
    reflect_prompt = f"""
è¯„ä¼°ä»¥ä¸‹ä»»åŠ¡æ‰§è¡Œç»“æœæ˜¯å¦è¶³ä»¥å›ç­”åŸå§‹æŸ¥è¯¢:

åŸå§‹æŸ¥è¯¢: {query}

æ‰§è¡Œç»“æœ:
{chr(10).join(task_results)}

è¯„ä¼°:
1. ä¿¡æ¯æ˜¯å¦å®Œæ•´? (æ˜¯/å¦)
2. æ˜¯å¦éœ€è¦è¡¥å……? (æ˜¯/å¦)

åªè¿”å›: å®Œæ•´ æˆ– ä¸å®Œæ•´
"""

    response = llm.invoke([HumanMessage(content=reflect_prompt)])
    evaluation = response.content.strip()

    print(f"è¯„ä¼°ç»“æœ: {evaluation}\n")

    return state

# ===== 6. ç”ŸæˆèŠ‚ç‚¹ =====

def generate_node(state: AgentState) -> AgentState:
    """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
    query = state["query"]
    task_results = state.get("task_results", [])

    print(f"\n{'='*60}")
    print(f"ğŸ“ ç”Ÿæˆé˜¶æ®µ")
    print(f"{'='*60}\n")

    # ç”Ÿæˆç­”æ¡ˆ
    generate_prompt = f"""
åŸºäºä»¥ä¸‹ä»»åŠ¡æ‰§è¡Œç»“æœ,ç”Ÿæˆå¯¹åŸå§‹æŸ¥è¯¢çš„å®Œæ•´ç­”æ¡ˆ:

æŸ¥è¯¢: {query}

æ‰§è¡Œç»“æœ:
{chr(10).join(task_results)}

æœ€ç»ˆç­”æ¡ˆ:
"""

    response = llm.invoke([HumanMessage(content=generate_prompt)])
    final_answer = response.content.strip()

    print(f"æœ€ç»ˆç­”æ¡ˆ:\n{final_answer}\n")

    return {"final_answer": final_answer}

# ===== 7. å†³ç­–å‡½æ•° =====

def should_continue(state: AgentState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œä»»åŠ¡"""
    current_index = state["current_task_index"]
    plan = state["plan"]

    if current_index < len(plan):
        return "execute"  # ç»§ç»­æ‰§è¡Œ
    else:
        return "generate"  # ç”Ÿæˆç­”æ¡ˆ

# ===== 8. æ„å»ºå›¾ =====

def create_planning_agent():
    """åˆ›å»ºè§„åˆ’ä»£ç†"""
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("plan", plan_node)
    workflow.add_node("execute", execute_node)
    workflow.add_node("reflect", reflect_node)
    workflow.add_node("generate", generate_node)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("plan")

    # æ·»åŠ è¾¹
    workflow.add_edge("plan", "execute")

    # æ¡ä»¶è¾¹: æ‰§è¡Œåå†³å®šç»§ç»­æˆ–ç”Ÿæˆ
    workflow.add_conditional_edges(
        "execute",
        should_continue,
        {
            "execute": "execute",  # ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡
            "generate": "reflect"  # æ‰€æœ‰ä»»åŠ¡å®Œæˆ,è¿›å…¥åæ€
        }
    )

    workflow.add_edge("reflect", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()

# ===== 9. æµ‹è¯• =====

def main():
    """ä¸»å‡½æ•°"""
    agent = create_planning_agent()

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹",
        "è§£é‡Š Transformer çš„å·¥ä½œåŸç†å¹¶ä¸¾ä¾‹è¯´æ˜",
        "ä»€ä¹ˆæ˜¯ RAG? å®ƒå¦‚ä½•å·¥ä½œ?"
    ]

    for query in test_queries:
        print(f"\n{'#'*60}")
        print(f"# æŸ¥è¯¢: {query}")
        print(f"{'#'*60}\n")

        # æ‰§è¡Œ
        result = agent.invoke({
            "query": query,
            "plan": [],
            "current_task_index": 0,
            "task_results": [],
            "final_answer": "",
            "iteration": 0
        })

        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆ")
        print(f"{'='*60}")
        print(f"æœ€ç»ˆç­”æ¡ˆ:\n{result['final_answer']}")
        print(f"\nè¿­ä»£æ¬¡æ•°: {result['iteration']}")
        print(f"æ‰§è¡Œä»»åŠ¡æ•°: {len(result['task_results'])}")
        print()

if __name__ == "__main__":
    main()
```

---

## è¿è¡Œè¾“å‡º

```
åˆå§‹åŒ– LLM...

############################################################
# æŸ¥è¯¢: æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹
############################################################

============================================================
ğŸ“‹ è§„åˆ’é˜¶æ®µ
============================================================
æŸ¥è¯¢: æ¯”è¾ƒ BERT å’Œ GPT çš„ä¼˜ç¼ºç‚¹

ç”Ÿæˆçš„è®¡åˆ’:
  1. æ£€ç´¢ BERT çš„æŠ€æœ¯ç‰¹ç‚¹å’Œä¼˜ç¼ºç‚¹
  2. æ£€ç´¢ GPT çš„æŠ€æœ¯ç‰¹ç‚¹å’Œä¼˜ç¼ºç‚¹
  3. å¯¹æ¯” BERT å’Œ GPT çš„æ¶æ„å·®å¼‚
  4. æ€»ç»“ä¸¤è€…çš„é€‚ç”¨åœºæ™¯

============================================================
âš™ï¸  æ‰§è¡Œé˜¶æ®µ - ä»»åŠ¡ 1/4
============================================================
ä»»åŠ¡: æ£€ç´¢ BERT çš„æŠ€æœ¯ç‰¹ç‚¹å’Œä¼˜ç¼ºç‚¹

ç»“æœ: BERT æ˜¯åŒå‘ç¼–ç å™¨,ä½¿ç”¨ Masked LM é¢„è®­ç»ƒã€‚
ä¼˜ç‚¹: æ“…é•¿ç†è§£ä»»åŠ¡,ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›å¼º
ç¼ºç‚¹: ä¸é€‚åˆç”Ÿæˆä»»åŠ¡

============================================================
âš™ï¸  æ‰§è¡Œé˜¶æ®µ - ä»»åŠ¡ 2/4
============================================================
ä»»åŠ¡: æ£€ç´¢ GPT çš„æŠ€æœ¯ç‰¹ç‚¹å’Œä¼˜ç¼ºç‚¹

ç»“æœ: GPT æ˜¯å•å‘è§£ç å™¨,ä½¿ç”¨è‡ªå›å½’é¢„è®­ç»ƒã€‚
ä¼˜ç‚¹: æ“…é•¿ç”Ÿæˆä»»åŠ¡,æ–‡æœ¬ç”Ÿæˆæµç•…
ç¼ºç‚¹: ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹

============================================================
âš™ï¸  æ‰§è¡Œé˜¶æ®µ - ä»»åŠ¡ 3/4
============================================================
ä»»åŠ¡: å¯¹æ¯” BERT å’Œ GPT çš„æ¶æ„å·®å¼‚

ç»“æœ: BERT ä½¿ç”¨åŒå‘ Transformer ç¼–ç å™¨,GPT ä½¿ç”¨å•å‘ Transformer è§£ç å™¨ã€‚
BERT å¯ä»¥çœ‹åˆ°å®Œæ•´ä¸Šä¸‹æ–‡,GPT åªèƒ½çœ‹åˆ°å‰æ–‡ã€‚

============================================================
âš™ï¸  æ‰§è¡Œé˜¶æ®µ - ä»»åŠ¡ 4/4
============================================================
ä»»åŠ¡: æ€»ç»“ä¸¤è€…çš„é€‚ç”¨åœºæ™¯

ç»“æœ: BERT é€‚åˆåˆ†ç±»ã€é—®ç­”ã€å‘½åå®ä½“è¯†åˆ«ç­‰ç†è§£ä»»åŠ¡ã€‚
GPT é€‚åˆæ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ã€æ‘˜è¦ç­‰ç”Ÿæˆä»»åŠ¡ã€‚

============================================================
ğŸ¤” åæ€é˜¶æ®µ
============================================================

è¯„ä¼°ç»“æœ: å®Œæ•´

============================================================
ğŸ“ ç”Ÿæˆé˜¶æ®µ
============================================================

æœ€ç»ˆç­”æ¡ˆ:
BERT å’Œ GPT æ˜¯ä¸¤ç§ä¸åŒçš„ Transformer æ¶æ„:

**BERT (åŒå‘ç¼–ç å™¨)**
- ä¼˜ç‚¹: å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›,æ“…é•¿ç†è§£ä»»åŠ¡
- ç¼ºç‚¹: ä¸é€‚åˆç”Ÿæˆä»»åŠ¡
- é€‚ç”¨åœºæ™¯: åˆ†ç±»ã€é—®ç­”ã€NER

**GPT (å•å‘è§£ç å™¨)**
- ä¼˜ç‚¹: æµç•…çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›,æ“…é•¿ç”Ÿæˆä»»åŠ¡
- ç¼ºç‚¹: ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹
- é€‚ç”¨åœºæ™¯: æ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ã€æ‘˜è¦

æ ¸å¿ƒå·®å¼‚: BERT åŒå‘ç†è§£,GPT å•å‘ç”Ÿæˆã€‚

============================================================
âœ… å®Œæˆ
============================================================
æœ€ç»ˆç­”æ¡ˆ:
BERT å’Œ GPT æ˜¯ä¸¤ç§ä¸åŒçš„ Transformer æ¶æ„:

**BERT (åŒå‘ç¼–ç å™¨)**
- ä¼˜ç‚¹: å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›,æ“…é•¿ç†è§£ä»»åŠ¡
- ç¼ºç‚¹: ä¸é€‚åˆç”Ÿæˆä»»åŠ¡
- é€‚ç”¨åœºæ™¯: åˆ†ç±»ã€é—®ç­”ã€NER

**GPT (å•å‘è§£ç å™¨)**
- ä¼˜ç‚¹: æµç•…çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›,æ“…é•¿ç”Ÿæˆä»»åŠ¡
- ç¼ºç‚¹: ä¸Šä¸‹æ–‡ç†è§£ä¸å¦‚åŒå‘æ¨¡å‹
- é€‚ç”¨åœºæ™¯: æ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ã€æ‘˜è¦

æ ¸å¿ƒå·®å¼‚: BERT åŒå‘ç†è§£,GPT å•å‘ç”Ÿæˆã€‚

è¿­ä»£æ¬¡æ•°: 1
æ‰§è¡Œä»»åŠ¡æ•°: 4
```

---

## ä»£ç è§£æ

### å…³é”®ç‚¹ 1: çŠ¶æ€å®šä¹‰

```python
class AgentState(TypedDict):
    """ä»£ç†çŠ¶æ€"""
    query: str                                    # åŸå§‹æŸ¥è¯¢
    plan: List[str]                               # ä»»åŠ¡è®¡åˆ’
    current_task_index: int                       # å½“å‰ä»»åŠ¡ç´¢å¼•
    task_results: Annotated[List[str], operator.add]  # ä»»åŠ¡ç»“æœåˆ—è¡¨
    final_answer: str                             # æœ€ç»ˆç­”æ¡ˆ
    iteration: int                                # è¿­ä»£æ¬¡æ•°
```

**è¦ç‚¹**:
- ä½¿ç”¨ `TypedDict` å®šä¹‰çŠ¶æ€ç»“æ„
- `Annotated[List[str], operator.add]` å®ç°ç»“æœç´¯åŠ 
- çŠ¶æ€åœ¨èŠ‚ç‚¹é—´ä¼ é€’å’Œæ›´æ–°

### å…³é”®ç‚¹ 2: çŠ¶æ€å›¾æ„å»º

```python
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("plan", plan_node)
workflow.add_node("execute", execute_node)
workflow.add_node("reflect", reflect_node)
workflow.add_node("generate", generate_node)

# æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "execute",
    should_continue,
    {
        "execute": "execute",  # å¾ªç¯æ‰§è¡Œ
        "generate": "reflect"  # å®Œæˆååæ€
    }
)
```

**è¦ç‚¹**:
- æ¸…æ™°çš„èŠ‚ç‚¹å®šä¹‰
- æ¡ä»¶è¾¹å®ç°å¾ªç¯æ‰§è¡Œ
- çŠ¶æ€é©±åŠ¨çš„æµç¨‹æ§åˆ¶

### å…³é”®ç‚¹ 3: ä»»åŠ¡æ‰§è¡Œå¾ªç¯

```python
def should_continue(state: AgentState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œä»»åŠ¡"""
    current_index = state["current_task_index"]
    plan = state["plan"]

    if current_index < len(plan):
        return "execute"  # ç»§ç»­æ‰§è¡Œ
    else:
        return "generate"  # ç”Ÿæˆç­”æ¡ˆ
```

**è¦ç‚¹**:
- åŸºäºçŠ¶æ€çš„å†³ç­–é€»è¾‘
- è‡ªåŠ¨å¾ªç¯æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
- å®Œæˆåè‡ªåŠ¨è¿›å…¥ä¸‹ä¸€é˜¶æ®µ

---

## æ‰©å±•æ€è€ƒ

### å¦‚ä½•ä¼˜åŒ–?

**1. æ·»åŠ åŠ¨æ€é‡è§„åˆ’**
```python
def replan_node(state: AgentState) -> AgentState:
    """æ ¹æ®æ‰§è¡Œç»“æœé‡æ–°è§„åˆ’"""
    task_results = state["task_results"]
    original_plan = state["plan"]

    # è¯„ä¼°æ˜¯å¦éœ€è¦è°ƒæ•´è®¡åˆ’
    if needs_adjustment(task_results):
        new_plan = generate_new_plan(original_plan, task_results)
        return {"plan": new_plan, "current_task_index": 0}

    return state
```

**2. æ·»åŠ å¹¶è¡Œæ‰§è¡Œ**
```python
def identify_parallel_tasks(plan: List[str]) -> List[List[int]]:
    """è¯†åˆ«å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡"""
    # åˆ†æä»»åŠ¡ä¾èµ–å…³ç³»
    dependencies = analyze_dependencies(plan)

    # åˆ†ç»„ç‹¬ç«‹ä»»åŠ¡
    parallel_groups = group_independent_tasks(dependencies)

    return parallel_groups

async def execute_parallel(tasks: List[str]):
    """å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡"""
    results = await asyncio.gather(*[
        execute_task_async(task) for task in tasks
    ])
    return results
```

**3. æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§**
```python
def prioritize_tasks(plan: List[str]) -> List[str]:
    """ä»»åŠ¡ä¼˜å…ˆçº§æ’åº"""
    # è¯„ä¼°æ¯ä¸ªä»»åŠ¡çš„é‡è¦æ€§
    priorities = [evaluate_priority(task) for task in plan]

    # æŒ‰ä¼˜å…ˆçº§æ’åº
    sorted_plan = [task for _, task in sorted(zip(priorities, plan), reverse=True)]

    return sorted_plan
```

### å¦‚ä½•æ‰©å±•?

**1. æ”¯æŒå¤šè½®è§„åˆ’**
```python
def multi_round_planning(state: AgentState) -> AgentState:
    """å¤šè½®è§„åˆ’"""
    max_rounds = 3
    current_round = state.get("planning_round", 0)

    if current_round < max_rounds:
        # åŸºäºå‰ä¸€è½®ç»“æœé‡æ–°è§„åˆ’
        refined_plan = refine_plan(state["plan"], state["task_results"])
        return {
            "plan": refined_plan,
            "planning_round": current_round + 1
        }

    return state
```

**2. æ”¯æŒå­ä»»åŠ¡åˆ†è§£**
```python
def decompose_task(task: str) -> List[str]:
    """å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡"""
    if is_complex(task):
        subtasks = llm.invoke(f"å°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡: {task}")
        return parse_subtasks(subtasks)

    return [task]

def execute_with_decomposition(state: AgentState) -> AgentState:
    """æ”¯æŒå­ä»»åŠ¡åˆ†è§£çš„æ‰§è¡Œ"""
    current_task = state["plan"][state["current_task_index"]]

    # åˆ†è§£ä»»åŠ¡
    subtasks = decompose_task(current_task)

    # æ‰§è¡Œå­ä»»åŠ¡
    results = [execute_subtask(st) for st in subtasks]

    # èšåˆç»“æœ
    aggregated_result = aggregate_results(results)

    return {"task_results": [aggregated_result]}
```

### ç”Ÿäº§çº§æ”¹è¿›

**1. é”™è¯¯å¤„ç†å’Œé‡è¯•**
```python
def execute_with_retry(state: AgentState, max_retries: int = 3) -> AgentState:
    """å¸¦é‡è¯•çš„ä»»åŠ¡æ‰§è¡Œ"""
    current_task = state["plan"][state["current_task_index"]]

    for attempt in range(max_retries):
        try:
            result = execute_task(current_task)

            # éªŒè¯ç»“æœ
            if is_valid_result(result):
                return {"task_results": [result]}

        except Exception as e:
            if attempt == max_retries - 1:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥,è®°å½•é”™è¯¯
                return {"task_results": [f"ä»»åŠ¡å¤±è´¥: {e}"]}

            # é‡è¯•å‰ç­‰å¾…
            time.sleep(2 ** attempt)

    return state
```

**2. æ€§èƒ½ç›‘æ§**
```python
import time

def execute_with_metrics(state: AgentState) -> AgentState:
    """å¸¦æ€§èƒ½ç›‘æ§çš„æ‰§è¡Œ"""
    start_time = time.time()

    # æ‰§è¡Œä»»åŠ¡
    result = execute_task(state)

    # è®°å½•æŒ‡æ ‡
    execution_time = time.time() - start_time

    metrics = {
        "task_index": state["current_task_index"],
        "execution_time": execution_time,
        "result_length": len(result.get("task_results", []))
    }

    print(f"ğŸ“Š æŒ‡æ ‡: {metrics}")

    return result
```

**3. çŠ¶æ€æŒä¹…åŒ–**
```python
import json

def save_state(state: AgentState, filename: str):
    """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶"""
    with open(filename, "w") as f:
        json.dump(state, f, indent=2)

def load_state(filename: str) -> AgentState:
    """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€"""
    with open(filename, "r") as f:
        return json.load(f)

def execute_with_checkpoint(state: AgentState) -> AgentState:
    """å¸¦æ£€æŸ¥ç‚¹çš„æ‰§è¡Œ"""
    # æ‰§è¡Œå‰ä¿å­˜çŠ¶æ€
    save_state(state, f"checkpoint_{state['current_task_index']}.json")

    try:
        result = execute_task(state)
        return result
    except Exception as e:
        # å¤±è´¥æ—¶å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤
        print(f"æ‰§è¡Œå¤±è´¥,å¯ä»æ£€æŸ¥ç‚¹æ¢å¤: checkpoint_{state['current_task_index']}.json")
        raise
```

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- LangGraph Plan-and-Execute: https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/
- LangGraph State Graphs: https://langchain-ai.github.io/langgraph/

### ç›¸å…³åšå®¢
- "Building an Agentic RAG System with LangGraph" (Medium, 2025)
- "Plan-and-Execute Agent Design Pattern" (LangChain Blog, 2026)

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-17
**ä»£ç è¡Œæ•°**: ~200 è¡Œ
