# 03_核心概念_08_生产级架构模式

## 2026年生产级ReRank架构

**标准三阶段管道：**
```
BM25初检 → 向量检索 → RRF融合 → Cross-Encoder ReRank → LLM生成
```

**核心指标：**
- 端到端延迟：<2秒
- NDCG@10：>0.85
- 成本：<$0.05/query
- 可用性：99.9%

---

## 架构模式1：标准生产架构

### 架构图

```
┌─────────────┐
│   用户Query  │
└──────┬──────┘
       │
       ├──────────────┬──────────────┐
       │              │              │
   ┌───▼───┐     ┌───▼───┐     ┌───▼───┐
   │ BM25  │     │Vector │     │Cache  │
   │Search │     │Search │     │Check  │
   └───┬───┘     └───┬───┘     └───┬───┘
       │              │              │
       └──────┬───────┴──────────────┘
              │
         ┌────▼────┐
         │   RRF   │
         │ Fusion  │
         └────┬────┘
              │
         ┌────▼────┐
         │Cross-   │
         │Encoder  │
         │ReRank   │
         └────┬────┘
              │
         ┌────▼────┐
         │   LLM   │
         │Generate │
         └────┬────┘
              │
         ┌────▼────┐
         │ Response│
         └─────────┘
```

### 实现代码

```python
from sentence_transformers import CrossEncoder, SentenceTransformer
import chromadb
from rank_bm25 import BM25Okapi
import numpy as np

class ProductionRAGPipeline:
    def __init__(self):
        # 初始化组件
        self.embedding_model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
        self.reranker = CrossEncoder('BAAI/bge-reranker-v2-m3', device='cuda')
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.get_or_create_collection("docs")
        self.bm25 = None  # 需要从文档构建
        
    def search(self, query, top_k=5):
        """标准三阶段检索"""
        # 阶段1：BM25初检
        bm25_results = self._bm25_search(query, top_k=50)
        
        # 阶段2：向量检索
        vector_results = self._vector_search(query, top_k=50)
        
        # 阶段3：RRF融合
        merged = self._rrf_fusion(bm25_results, vector_results, top_k=50)
        
        # 阶段4：Cross-Encoder ReRank
        reranked = self._rerank(query, merged, top_k=top_k)
        
        return reranked
    
    def _bm25_search(self, query, top_k):
        """BM25检索"""
        scores = self.bm25.get_scores(query.split())
        top_indices = np.argsort(scores)[::-1][:top_k]
        return [(self.documents[i], scores[i]) for i in top_indices]
    
    def _vector_search(self, query, top_k):
        """向量检索"""
        query_emb = self.embedding_model.encode([query])
        results = self.collection.query(
            query_embeddings=query_emb.tolist(),
            n_results=top_k
        )
        return [(doc, score) for doc, score in zip(
            results['documents'][0],
            results['distances'][0]
        )]
    
    def _rrf_fusion(self, bm25_results, vector_results, top_k, k=60):
        """RRF融合"""
        scores = {}
        
        # BM25分数
        for rank, (doc, _) in enumerate(bm25_results):
            scores[doc] = scores.get(doc, 0) + 1 / (k + rank + 1)
        
        # 向量分数
        for rank, (doc, _) in enumerate(vector_results):
            scores[doc] = scores.get(doc, 0) + 1 / (k + rank + 1)
        
        # 排序
        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [doc for doc, _ in sorted_docs[:top_k]]
    
    def _rerank(self, query, documents, top_k):
        """Cross-Encoder重排序"""
        scores = self.reranker.predict(
            [(query, doc) for doc in documents],
            batch_size=16
        )
        ranked_indices = np.argsort(scores)[::-1]
        return [documents[i] for i in ranked_indices[:top_k]]
```

---

## 架构模式2：高可用架构

### 核心特性

1. **负载均衡**：多实例部署
2. **缓存层**：Redis语义缓存
3. **降级策略**：超时降级
4. **监控告警**：实时监控

### 实现代码

```python
import redis
import hashlib
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

# Redis缓存
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# 多个ReRank实例（负载均衡）
rerankers = [
    CrossEncoder('BAAI/bge-reranker-v2-m3', device='cuda:0'),
    CrossEncoder('BAAI/bge-reranker-v2-m3', device='cuda:1'),
]
current_reranker = 0

class SearchRequest(BaseModel):
    query: str
    top_k: int = 5

@app.post("/search")
async def search(request: SearchRequest):
    """高可用搜索API"""
    try:
        # 1. 检查缓存
        cache_key = hashlib.md5(request.query.encode()).hexdigest()
        cached_result = redis_client.get(cache_key)
        
        if cached_result:
            return {"results": eval(cached_result), "from_cache": True}
        
        # 2. 执行检索（带超时）
        results = await asyncio.wait_for(
            _search_with_rerank(request.query, request.top_k),
            timeout=2.0  # 2秒超时
        )
        
        # 3. 缓存结果
        redis_client.setex(cache_key, 3600, str(results))
        
        return {"results": results, "from_cache": False}
        
    except asyncio.TimeoutError:
        # 降级：返回初检结果
        return {"results": _fallback_search(request.query), "degraded": True}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def _search_with_rerank(query, top_k):
    """带ReRank的检索"""
    global current_reranker
    
    # 负载均衡：轮询选择reranker
    reranker = rerankers[current_reranker]
    current_reranker = (current_reranker + 1) % len(rerankers)
    
    # 执行检索
    pipeline = ProductionRAGPipeline()
    return pipeline.search(query, top_k)

def _fallback_search(query):
    """降级搜索（仅初检）"""
    pipeline = ProductionRAGPipeline()
    return pipeline._vector_search(query, top_k=5)
```

---

## 架构模式3：多模态架构

### 核心特性

1. **图文混合检索**
2. **多模态ReRank**
3. **视觉文档支持**

### 实现代码

```python
from jina import Client

class MultimodalRAGPipeline:
    def __init__(self):
        self.text_reranker = CrossEncoder('BAAI/bge-reranker-v2-m3')
        self.multimodal_reranker = Client('jinaai/jina-reranker-m0')
    
    def search(self, query, documents, top_k=5):
        """多模态检索"""
        # 判断是否包含图像
        has_images = any('image' in doc for doc in documents)
        
        if has_images:
            # 使用多模态reranker
            return self._multimodal_rerank(query, documents, top_k)
        else:
            # 使用文本reranker
            return self._text_rerank(query, documents, top_k)
    
    def _multimodal_rerank(self, query, documents, top_k):
        """多模态重排序"""
        results = self.multimodal_reranker.rerank(
            query=query,
            documents=documents,
            modality="multimodal",
            top_k=top_k
        )
        return results
    
    def _text_rerank(self, query, documents, top_k):
        """文本重排序"""
        scores = self.text_reranker.predict(
            [(query, doc['text']) for doc in documents]
        )
        ranked_indices = np.argsort(scores)[::-1]
        return [documents[i] for i in ranked_indices[:top_k]]
```

---

## 性能优化策略

### 1. 批处理优化

```python
# 批处理多个query
async def batch_search(queries, top_k=5):
    """批处理搜索"""
    tasks = [_search_with_rerank(q, top_k) for q in queries]
    results = await asyncio.gather(*tasks)
    return results
```

### 2. 异步处理

```python
# 异步ReRank
async def async_rerank(query, documents):
    """异步重排序"""
    loop = asyncio.get_event_loop()
    scores = await loop.run_in_executor(
        None,
        reranker.predict,
        [(query, doc) for doc in documents]
    )
    return scores
```

### 3. 语义缓存

```python
# Redis语义缓存
def semantic_cache_search(query):
    """语义缓存搜索"""
    # 查找相似query
    query_emb = embedding_model.encode([query])
    similar_queries = find_similar_cached_queries(query_emb)
    
    if similar_queries:
        # 返回缓存结果
        return redis_client.get(similar_queries[0])
    
    # 执行新搜索
    results = search_with_rerank(query)
    
    # 缓存结果
    cache_key = hashlib.md5(query.encode()).hexdigest()
    redis_client.setex(cache_key, 3600, str(results))
    
    return results
```

---

## 监控与告警

### 关键指标

```python
from prometheus_client import Counter, Histogram

# 定义指标
search_requests = Counter('search_requests_total', 'Total search requests')
search_latency = Histogram('search_latency_seconds', 'Search latency')
rerank_latency = Histogram('rerank_latency_seconds', 'ReRank latency')
cache_hits = Counter('cache_hits_total', 'Cache hits')

@app.post("/search")
async def search(request: SearchRequest):
    """带监控的搜索"""
    search_requests.inc()
    
    with search_latency.time():
        # 检查缓存
        if cached_result:
            cache_hits.inc()
            return cached_result
        
        # 执行ReRank
        with rerank_latency.time():
            results = await _search_with_rerank(request.query)
        
        return results
```

---

## 关键要点速记

### 架构模式
1. **标准架构**：BM25 + 向量 + RRF + ReRank
2. **高可用架构**：负载均衡 + 缓存 + 降级
3. **多模态架构**：图文混合 + 多模态ReRank

### 性能优化
4. **批处理**：并发处理多个query
5. **异步处理**：非阻塞ReRank
6. **语义缓存**：降低重复请求成本68.8%

### 监控告警
7. **关键指标**：延迟、NDCG、成本、缓存命中率
8. **降级策略**：超时返回初检结果
9. **负载均衡**：多实例轮询

---

## 参考资料

- [Building Production RAG Systems in 2026](https://brlikhon.engineer/blog/building-production-rag-systems-in-2026-complete-architecture-guide)
- [RAG at Scale](https://redis.io/blog/rag-at-scale) - Redis, 2026
- [RAG Pipeline from Scratch in 2026](https://www.kapa.ai/blog/how-to-build-a-rag-pipeline-from-scratch-in-2026)

---

**版本：** v1.0 (2026年标准)
**最后更新：** 2026-02-16
