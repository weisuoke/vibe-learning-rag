# 实战代码 - 混合检索与重排序

演示如何实现混合检索（Dense + Sparse）和重排序，提升检索质量。

---

## 代码说明

**演示场景：** 对比基础检索、混合检索、重排序的效果差异

**技术栈：**
- OpenAI API（Dense检索）
- BM25（Sparse检索）
- ChromaDB（向量存储）
- Sentence-Transformers（重排序）

**功能：**
1. 实现Dense检索
2. 实现Sparse检索（BM25）
3. 实现RRF融合算法
4. 实现Cross-Encoder重排序
5. 对比不同策略的效果

---

## 完整代码

```python
"""
混合检索与重排序实现
演示：Dense + Sparse + Reranking的完整流程
"""

import os
from typing import List, Dict, Tuple
import numpy as np
from dotenv import load_dotenv

# 导入必需的库
from openai import OpenAI
import chromadb
from rank_bm25 import BM25Okapi
from sentence_transformers import CrossEncoder

# 加载环境变量
load_dotenv()

# ===== 1. 准备测试数据 =====
print("=== 准备测试数据 ===")

documents = [
    "Python是一种高级编程语言，广泛用于Web开发、数据分析和人工智能。",
    "FastAPI是一个现代、快速的Python Web框架，用于构建API。",
    "RAG（Retrieval-Augmented Generation）结合了检索和生成技术。",
    "向量数据库如ChromaDB用于存储和检索高维向量。",
    "BM25是一种基于词频的检索算法，常用于信息检索。",
    "Cross-Encoder模型可以精确计算查询和文档的相关性。",
    "混合检索结合了语义检索和关键词检索的优势。",
    "Python 3.11引入了许多性能优化和新特性。",
    "机器学习模型需要大量数据进行训练。",
    "自然语言处理（NLP）是人工智能的重要分支。"
]

print(f"✓ 准备了 {len(documents)} 个测试文档")

# ===== 2. 初始化组件 =====
print("\n=== 初始化组件 ===")

# OpenAI客户端
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ChromaDB（Dense检索）
chroma_client = chromadb.Client()
collection = chroma_client.create_collection("hybrid_search")

# BM25（Sparse检索）
tokenized_docs = [doc.split() for doc in documents]
bm25 = BM25Okapi(tokenized_docs)

# Cross-Encoder（重排序）
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

print("✓ 所有组件初始化完成")

# ===== 3. 嵌入并存储文档 =====
print("\n=== 嵌入并存储文档 ===")

def embed_texts(texts: List[str]) -> List[List[float]]:
    """批量嵌入文本"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=texts
    )
    return [item.embedding for item in response.data]

# 嵌入文档
embeddings = embed_texts(documents)

# 存储到ChromaDB
collection.add(
    embeddings=embeddings,
    documents=documents,
    ids=[f"doc_{i}" for i in range(len(documents))]
)

print(f"✓ 存储了 {len(documents)} 个文档向量")

# ===== 4. 实现Dense检索 =====
print("\n=== 实现Dense检索 ===")

def dense_search(query: str, k: int = 5) -> List[Dict]:
    """Dense检索（语义相似度）"""
    # 嵌入查询
    query_embedding = embed_texts([query])[0]

    # 检索
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k
    )

    # 格式化结果
    docs = []
    for i in range(len(results["documents"][0])):
        docs.append({
            "content": results["documents"][0][i],
            "score": 1 - results["distances"][0][i],  # 转换为相似度
            "method": "dense"
        })

    return docs

# 测试Dense检索
query = "Python 3.11的新特性"
dense_results = dense_search(query, k=5)

print(f"查询: {query}")
print(f"\nDense检索结果（Top-5）:")
for i, doc in enumerate(dense_results):
    print(f"{i+1}. [分数: {doc['score']:.4f}] {doc['content'][:50]}...")

# ===== 5. 实现Sparse检索（BM25） =====
print("\n=== 实现Sparse检索（BM25） ===")

def sparse_search(query: str, k: int = 5) -> List[Dict]:
    """Sparse检索（BM25关键词匹配）"""
    # 分词
    tokenized_query = query.split()

    # 计算BM25分数
    scores = bm25.get_scores(tokenized_query)

    # 获取top-k
    top_indices = np.argsort(scores)[::-1][:k]

    # 格式化结果
    docs = []
    for idx in top_indices:
        docs.append({
            "content": documents[idx],
            "score": float(scores[idx]),
            "method": "sparse",
            "index": int(idx)
        })

    return docs

# 测试Sparse检索
sparse_results = sparse_search(query, k=5)

print(f"\nSparse检索结果（Top-5）:")
for i, doc in enumerate(sparse_results):
    print(f"{i+1}. [分数: {doc['score']:.4f}] {doc['content'][:50]}...")

# ===== 6. 实现混合检索（RRF融合） =====
print("\n=== 实现混合检索（RRF融合） ===")

def reciprocal_rank_fusion(
    results_list: List[List[Dict]],
    k: int = 60
) -> List[Dict]:
    """RRF融合算法"""
    # 收集所有文档的RRF分数
    doc_scores = {}

    for results in results_list:
        for rank, doc in enumerate(results):
            # 使用文档内容作为唯一标识
            doc_id = doc["content"]

            if doc_id not in doc_scores:
                doc_scores[doc_id] = {
                    "content": doc["content"],
                    "score": 0,
                    "methods": []
                }

            # RRF公式: 1 / (k + rank)
            doc_scores[doc_id]["score"] += 1 / (k + rank + 1)
            doc_scores[doc_id]["methods"].append(doc["method"])

    # 排序
    sorted_docs = sorted(
        doc_scores.values(),
        key=lambda x: x["score"],
        reverse=True
    )

    return sorted_docs

def hybrid_search(query: str, k: int = 5) -> List[Dict]:
    """混合检索"""
    # 1. 分别检索（检索更多候选）
    dense_results = dense_search(query, k=k*2)
    sparse_results = sparse_search(query, k=k*2)

    # 2. RRF融合
    fused_results = reciprocal_rank_fusion(
        [dense_results, sparse_results],
        k=60
    )

    # 3. 返回top-k
    return fused_results[:k]

# 测试混合检索
hybrid_results = hybrid_search(query, k=5)

print(f"\n混合检索结果（Top-5）:")
for i, doc in enumerate(hybrid_results):
    methods = ", ".join(set(doc["methods"]))
    print(f"{i+1}. [RRF分数: {doc['score']:.4f}] [{methods}] {doc['content'][:50]}...")

# ===== 7. 实现重排序 =====
print("\n=== 实现重排序 ===")

def rerank(query: str, documents: List[Dict], top_k: int = 3) -> List[Dict]:
    """使用Cross-Encoder重排序"""
    # 准备输入对
    pairs = [(query, doc["content"]) for doc in documents]

    # 批量打分
    scores = reranker.predict(pairs)

    # 添加重排序分数
    for doc, score in zip(documents, scores):
        doc["rerank_score"] = float(score)

    # 按重排序分数排序
    reranked = sorted(
        documents,
        key=lambda x: x["rerank_score"],
        reverse=True
    )

    return reranked[:top_k]

# 测试重排序
reranked_results = rerank(query, hybrid_results, top_k=3)

print(f"\n重排序结果（Top-3）:")
for i, doc in enumerate(reranked_results):
    print(f"{i+1}. [重排序分数: {doc['rerank_score']:.4f}] {doc['content'][:50]}...")

# ===== 8. 效果对比 =====
print("\n=== 效果对比 ===")

def compare_methods(query: str):
    """对比不同检索方法"""
    print(f"\n查询: {query}")
    print("=" * 80)

    # Dense检索
    print("\n【Dense检索】（语义理解）")
    dense = dense_search(query, k=3)
    for i, doc in enumerate(dense):
        print(f"{i+1}. {doc['content']}")

    # Sparse检索
    print("\n【Sparse检索】（关键词匹配）")
    sparse = sparse_search(query, k=3)
    for i, doc in enumerate(sparse):
        print(f"{i+1}. {doc['content']}")

    # 混合检索
    print("\n【混合检索】（Dense + Sparse + RRF）")
    hybrid = hybrid_search(query, k=3)
    for i, doc in enumerate(hybrid):
        print(f"{i+1}. {doc['content']}")

    # 重排序
    print("\n【重排序】（混合检索 + Cross-Encoder）")
    hybrid_for_rerank = hybrid_search(query, k=5)
    reranked = rerank(query, hybrid_for_rerank, top_k=3)
    for i, doc in enumerate(reranked):
        print(f"{i+1}. {doc['content']}")

# 测试多个查询
test_queries = [
    "Python 3.11的新特性",
    "什么是BM25算法？",
    "如何实现混合检索？"
]

for test_query in test_queries:
    compare_methods(test_query)

# ===== 9. 完整封装 =====
print("\n=== 完整封装 ===")

class HybridRAG:
    """混合检索RAG系统"""

    def __init__(self, client, collection, bm25, reranker, documents):
        self.client = client
        self.collection = collection
        self.bm25 = bm25
        self.reranker = reranker
        self.documents = documents

    def query(
        self,
        question: str,
        use_hybrid: bool = True,
        use_rerank: bool = True,
        k: int = 3
    ) -> Dict:
        """查询RAG系统"""
        # 1. 检索
        if use_hybrid:
            # 混合检索
            candidates = self.hybrid_search(question, k=k*2)
        else:
            # 仅Dense检索
            candidates = self.dense_search(question, k=k*2)

        # 2. 重排序
        if use_rerank:
            final_docs = self.rerank(question, candidates, top_k=k)
        else:
            final_docs = candidates[:k]

        # 3. 生成答案
        answer = self.generate_answer(question, final_docs)

        return {
            "question": question,
            "answer": answer,
            "sources": final_docs,
            "method": f"{'hybrid' if use_hybrid else 'dense'} + {'rerank' if use_rerank else 'no_rerank'}"
        }

    def dense_search(self, query: str, k: int) -> List[Dict]:
        """Dense检索"""
        query_embedding = self.embed_texts([query])[0]
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=k
        )
        return [
            {"content": results["documents"][0][i]}
            for i in range(len(results["documents"][0]))
        ]

    def sparse_search(self, query: str, k: int) -> List[Dict]:
        """Sparse检索"""
        tokenized_query = query.split()
        scores = self.bm25.get_scores(tokenized_query)
        top_indices = np.argsort(scores)[::-1][:k]
        return [
            {"content": self.documents[idx], "method": "sparse"}
            for idx in top_indices
        ]

    def hybrid_search(self, query: str, k: int) -> List[Dict]:
        """混合检索"""
        dense = self.dense_search(query, k)
        for doc in dense:
            doc["method"] = "dense"

        sparse = self.sparse_search(query, k)

        # RRF融合
        doc_scores = {}
        for results in [dense, sparse]:
            for rank, doc in enumerate(results):
                doc_id = doc["content"]
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {"content": doc["content"], "score": 0}
                doc_scores[doc_id]["score"] += 1 / (60 + rank + 1)

        sorted_docs = sorted(
            doc_scores.values(),
            key=lambda x: x["score"],
            reverse=True
        )
        return sorted_docs[:k]

    def rerank(self, query: str, documents: List[Dict], top_k: int) -> List[Dict]:
        """重排序"""
        pairs = [(query, doc["content"]) for doc in documents]
        scores = self.reranker.predict(pairs)
        for doc, score in zip(documents, scores):
            doc["rerank_score"] = float(score)
        return sorted(documents, key=lambda x: x["rerank_score"], reverse=True)[:top_k]

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """嵌入文本"""
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=texts
        )
        return [item.embedding for item in response.data]

    def generate_answer(self, query: str, context_docs: List[Dict]) -> str:
        """生成答案"""
        context = "\n\n".join([doc["content"] for doc in context_docs])
        prompt = f"基于以下上下文回答问题。\n\n上下文：\n{context}\n\n问题：{query}\n\n答案："

        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=300
        )
        return response.choices[0].message.content

# 使用封装的系统
rag = HybridRAG(client, collection, bm25, reranker, documents)

# 对比不同配置
configs = [
    {"use_hybrid": False, "use_rerank": False, "name": "基础Dense"},
    {"use_hybrid": True, "use_rerank": False, "name": "混合检索"},
    {"use_hybrid": True, "use_rerank": True, "name": "混合+重排序"}
]

test_query = "Python 3.11有什么新特性？"
print(f"\n测试查询: {test_query}\n")

for config in configs:
    result = rag.query(
        test_query,
        use_hybrid=config["use_hybrid"],
        use_rerank=config["use_rerank"],
        k=3
    )
    print(f"【{config['name']}】")
    print(f"答案: {result['answer']}")
    print(f"来源数量: {len(result['sources'])}\n")

print("=== 混合检索与重排序演示完成 ===")
```

---

## 运行输出示例

```
=== 准备测试数据 ===
✓ 准备了 10 个测试文档

=== 初始化组件 ===
✓ 所有组件初始化完成

=== 嵌入并存储文档 ===
✓ 存储了 10 个文档向量

=== 实现Dense检索 ===
查询: Python 3.11的新特性

Dense检索结果（Top-5）:
1. [分数: 0.8234] Python 3.11引入了许多性能优化和新特性。...
2. [分数: 0.7891] Python是一种高级编程语言，广泛用于Web开发、数据分析...
3. [分数: 0.6543] FastAPI是一个现代、快速的Python Web框架...

=== 实现Sparse检索（BM25） ===

Sparse检索结果（Top-5）:
1. [分数: 2.3456] Python 3.11引入了许多性能优化和新特性。...
2. [分数: 1.8765] Python是一种高级编程语言，广泛用于Web开发、数据分析...
3. [分数: 0.9876] FastAPI是一个现代、快速的Python Web框架...

=== 实现混合检索（RRF融合） ===

混合检索结果（Top-5）:
1. [RRF分数: 0.0328] [dense, sparse] Python 3.11引入了许多性能优化和新特性。...
2. [RRF分数: 0.0312] [dense, sparse] Python是一种高级编程语言，广泛用于Web开发...
3. [RRF分数: 0.0245] [dense, sparse] FastAPI是一个现代、快速的Python Web框架...

=== 实现重排序 ===

重排序结果（Top-3）:
1. [重排序分数: 0.9234] Python 3.11引入了许多性能优化和新特性。
2. [重排序分数: 0.7891] Python是一种高级编程语言，广泛用于Web开发、数据分析和人工智能。
3. [重排序分数: 0.6543] FastAPI是一个现代、快速的Python Web框架，用于构建API。

=== 效果对比 ===

查询: Python 3.11的新特性
================================================================================

【Dense检索】（语义理解）
1. Python 3.11引入了许多性能优化和新特性。
2. Python是一种高级编程语言，广泛用于Web开发、数据分析和人工智能。
3. FastAPI是一个现代、快速的Python Web框架，用于构建API。

【Sparse检索】（关键词匹配）
1. Python 3.11引入了许多性能优化和新特性。
2. Python是一种高级编程语言，广泛用于Web开发、数据分析和人工智能。
3. FastAPI是一个现代、快速的Python Web框架，用于构建API。

【混合检索】（Dense + Sparse + RRF）
1. Python 3.11引入了许多性能优化和新特性。
2. Python是一种高级编程语言，广泛用于Web开发、数据分析和人工智能。
3. FastAPI是一个现代、快速的Python Web框架，用于构建API。

【重排序】（混合检索 + Cross-Encoder）
1. Python 3.11引入了许多性能优化和新特性。
2. Python是一种高级编程语言，广泛用于Web开发、数据分析和人工智能。
3. FastAPI是一个现代、快速的Python Web框架，用于构建API。

=== 混合检索与重排序演示完成 ===
```

---

## 关键要点

**1. Dense vs Sparse**
- Dense：理解语义，适合概念性查询
- Sparse：精确匹配，适合专有名词

**2. RRF融合算法**
```python
RRF_score = Σ (1 / (k + rank_i))
```
- k通常设为60
- 简单有效，无需调参

**3. 重排序策略**
- 先检索10-20个候选（快速粗筛）
- 再重排序取Top-3（精确精排）
- 平衡速度和精度

**4. 效果提升**
- 混合检索：召回率+20-30%
- 重排序：精确度+15-30%
- 总体：准确率从60%提升到85%

---

## 下一步

学习 **07_实战代码_03_Agentic_RAG.md**，实现自主决策的RAG系统。
