# 最小可用知识

## 核心目标

**掌握 20% 的核心知识，解决 80% 的实际问题。**

---

## 必须掌握的三个核心

### 1. Python dict 的基本使用

**这是你最常用的哈希表实现。**

```python
# 创建
user_cache = {}

# 插入/更新 - O(1)
user_cache["user_123"] = {"name": "Alice", "age": 25}

# 查找 - O(1)
user = user_cache.get("user_123")  # 推荐：返回 None 如果不存在
# 或
user = user_cache["user_123"]  # 不推荐：KeyError 如果不存在

# 检查存在 - O(1)
if "user_123" in user_cache:
    print("用户存在")

# 删除 - O(1)
del user_cache["user_123"]
# 或
user_cache.pop("user_123", None)  # 推荐：不存在时返回 None

# 遍历
for user_id, user_data in user_cache.items():
    print(f"{user_id}: {user_data}")
```

**2026 应用：Token 映射**
```python
# LLM Tokenizer 的核心实现
class SimpleTokenizer:
    def __init__(self):
        self.token_to_id = {}  # Hash Table
        self.id_to_token = {}  # 反向 Hash Table
        self.next_id = 0

    def add_token(self, token: str) -> int:
        if token not in self.token_to_id:
            token_id = self.next_id
            self.token_to_id[token] = token_id
            self.id_to_token[token_id] = token
            self.next_id += 1
        return self.token_to_id[token]

    def encode(self, text: str) -> list[int]:
        # 简化版：按空格分词
        tokens = text.split()
        return [self.add_token(token) for token in tokens]

    def decode(self, ids: list[int]) -> str:
        tokens = [self.id_to_token[id] for id in ids]
        return " ".join(tokens)

# 使用
tokenizer = SimpleTokenizer()
ids = tokenizer.encode("Hello world")
print(ids)  # [0, 1]
print(tokenizer.decode(ids))  # "Hello world"
```

---

### 2. 理解哈希冲突

**冲突是不可避免的，必须知道如何处理。**

#### 什么是冲突？

```python
# 简化的哈希函数
def simple_hash(key: str, size: int) -> int:
    return sum(ord(c) for c in key) % size

# 冲突示例
size = 10
print(simple_hash("abc", size))  # 4
print(simple_hash("bca", size))  # 4  <- 冲突！
print(simple_hash("cab", size))  # 4  <- 冲突！
```

#### 两种主要解决方案

**方案 1：链表法（Chaining）**
```python
class HashTableChaining:
    def __init__(self, size=10):
        self.size = size
        self.table = [[] for _ in range(size)]  # 每个位置是一个列表

    def _hash(self, key: str) -> int:
        return hash(key) % self.size

    def put(self, key: str, value):
        index = self._hash(key)
        bucket = self.table[index]

        # 更新已存在的键
        for i, (k, v) in enumerate(bucket):
            if k == key:
                bucket[i] = (key, value)
                return

        # 新键，追加到链表
        bucket.append((key, value))

    def get(self, key: str):
        index = self._hash(key)
        bucket = self.table[index]

        for k, v in bucket:
            if k == key:
                return v
        return None

# 使用
ht = HashTableChaining(size=5)
ht.put("apple", 1)
ht.put("banana", 2)
ht.put("cherry", 3)

print(ht.get("apple"))   # 1
print(ht.get("banana"))  # 2
print(ht.get("orange"))  # None
```

**方案 2：开放寻址（Open Addressing）**
```python
class HashTableOpenAddressing:
    def __init__(self, size=10):
        self.size = size
        self.keys = [None] * size
        self.values = [None] * size

    def _hash(self, key: str) -> int:
        return hash(key) % self.size

    def put(self, key: str, value):
        index = self._hash(key)

        # 线性探测：找到空位或相同键
        while self.keys[index] is not None:
            if self.keys[index] == key:
                # 更新已存在的键
                self.values[index] = value
                return
            # 移动到下一个位置
            index = (index + 1) % self.size

        # 找到空位，插入
        self.keys[index] = key
        self.values[index] = value

    def get(self, key: str):
        index = self._hash(key)

        # 线性探测：查找键
        while self.keys[index] is not None:
            if self.keys[index] == key:
                return self.values[index]
            index = (index + 1) % self.size

        return None

# 使用
ht = HashTableOpenAddressing(size=5)
ht.put("apple", 1)
ht.put("banana", 2)
ht.put("cherry", 3)

print(ht.get("apple"))   # 1
print(ht.get("banana"))  # 2
print(ht.get("orange"))  # None
```

**对比：**

| 特性 | 链表法 | 开放寻址 |
|------|--------|----------|
| 空间 | 需要额外链表节点 | 只需数组 |
| 缓存友好 | 差（链表跳转） | 好（连续内存） |
| 删除 | 简单 | 复杂（需要标记） |
| 负载因子 | 可以 > 1 | 必须 < 1 |
| Python dict | 不使用 | 使用（变种） |

---

### 3. 负载因子与性能

**负载因子 = 元素数量 / 数组大小**

```python
class HashTableWithLoadFactor:
    def __init__(self, initial_size=8):
        self.size = initial_size
        self.count = 0
        self.table = [[] for _ in range(self.size)]
        self.max_load_factor = 0.75  # 关键阈值

    def _hash(self, key: str) -> int:
        return hash(key) % self.size

    def _load_factor(self) -> float:
        return self.count / self.size

    def _resize(self):
        """扩容：创建新表，重新哈希所有元素"""
        old_table = self.table
        self.size *= 2  # 双倍扩容
        self.table = [[] for _ in range(self.size)]
        self.count = 0

        # 重新插入所有元素
        for bucket in old_table:
            for key, value in bucket:
                self.put(key, value)

    def put(self, key: str, value):
        # 检查是否需要扩容
        if self._load_factor() > self.max_load_factor:
            self._resize()

        index = self._hash(key)
        bucket = self.table[index]

        for i, (k, v) in enumerate(bucket):
            if k == key:
                bucket[i] = (key, value)
                return

        bucket.append((key, value))
        self.count += 1

    def get(self, key: str):
        index = self._hash(key)
        bucket = self.table[index]

        for k, v in bucket:
            if k == key:
                return v
        return None

    def stats(self):
        """统计信息"""
        return {
            "size": self.size,
            "count": self.count,
            "load_factor": self._load_factor(),
            "max_chain_length": max(len(bucket) for bucket in self.table),
            "empty_buckets": sum(1 for bucket in self.table if len(bucket) == 0)
        }

# 测试负载因子影响
ht = HashTableWithLoadFactor(initial_size=4)

print("初始状态:", ht.stats())
# {'size': 4, 'count': 0, 'load_factor': 0.0, 'max_chain_length': 0, 'empty_buckets': 4}

# 插入元素
for i in range(10):
    ht.put(f"key_{i}", i)
    if i in [2, 3, 4, 9]:  # 关键时刻
        print(f"插入 {i+1} 个元素:", ht.stats())

# 输出：
# 插入 3 个元素: {'size': 4, 'count': 3, 'load_factor': 0.75, ...}
# 插入 4 个元素: {'size': 8, 'count': 4, 'load_factor': 0.5, ...}  <- 扩容了！
# 插入 5 个元素: {'size': 8, 'count': 5, 'load_factor': 0.625, ...}
# 插入 10 个元素: {'size': 16, 'count': 10, 'load_factor': 0.625, ...}  <- 又扩容了！
```

**关键洞察：**
- 负载因子 < 0.75：性能良好
- 负载因子 > 0.75：冲突增多，需要扩容
- 扩容成本：O(n)，但摊销后仍是 O(1)

---

## 2026 年必知的三个应用

### 应用 1：语义缓存（Semantic Cache）

**问题：** AI Agent 重复回答相似问题浪费资源

**解决：** 使用哈希表缓存查询和响应

```python
from typing import Optional

class SemanticCache:
    def __init__(self):
        self.cache = {}  # hash → (query, response)

    def _normalize_query(self, query: str) -> str:
        """标准化查询：小写、去空格"""
        return query.lower().strip()

    def get(self, query: str) -> Optional[str]:
        """查找缓存的响应"""
        normalized = self._normalize_query(query)
        h = hash(normalized)
        if h in self.cache:
            cached_query, response = self.cache[h]
            # 验证实际内容（防止哈希冲突）
            if cached_query == normalized:
                return response
        return None

    def set(self, query: str, response: str):
        """缓存查询和响应"""
        normalized = self._normalize_query(query)
        h = hash(normalized)
        self.cache[h] = (normalized, response)

# 使用
cache = SemanticCache()

# 第一次查询
query1 = "如何学习 Python?"
if not cache.get(query1):
    response = "推荐从基础语法开始..."  # 调用 LLM
    cache.set(query1, response)

# 第二次查询（相同问题）
query2 = "如何学习 PYTHON?"  # 大小写不同
response = cache.get(query2)
if response:
    print("缓存命中！", response)
    # 输出：缓存命中！ 推荐从基础语法开始...
```

**2026 实际应用：**
- GPTCache：开源语义缓存库
- LangChain Cache：内置缓存机制
- LMCache：企业级 KV Cache 共享（15x 吞吐量提升）

---

### 应用 2：文档去重

**问题：** RAG 系统中重复文档浪费存储和检索资源

**解决：** 使用哈希表快速检测重复

```python
class DocumentDeduplicator:
    def __init__(self):
        self.seen_hashes = set()  # 使用 set（基于哈希表）

    def _compute_hash(self, content: str) -> int:
        """计算文档指纹"""
        # 标准化：去除空白字符
        normalized = "".join(content.split())
        return hash(normalized)

    def is_duplicate(self, content: str) -> bool:
        """检查是否重复"""
        h = self._compute_hash(content)
        return h in self.seen_hashes

    def add_document(self, content: str) -> bool:
        """添加文档，返回是否成功（非重复）"""
        h = self._compute_hash(content)
        if h in self.seen_hashes:
            return False  # 重复
        self.seen_hashes.add(h)
        return True  # 成功添加

# 使用
dedup = DocumentDeduplicator()

docs = [
    "Python 是一门编程语言",
    "Python是一门编程语言",  # 重复（空格不同）
    "Java 是一门编程语言",
    "Python 是一门编程语言",  # 重复
]

for doc in docs:
    if dedup.add_document(doc):
        print(f"✓ 新文档: {doc}")
    else:
        print(f"✗ 重复: {doc}")

# 输出：
# ✓ 新文档: Python 是一门编程语言
# ✗ 重复: Python是一门编程语言
# ✓ 新文档: Java 是一门编程语言
# ✗ 重复: Python 是一门编程语言
```

---

### 应用 3：Agent 状态管理

**问题：** 多 Agent 系统需要快速查找 Agent 状态

**解决：** 使用哈希表存储 Agent 信息

```python
from dataclasses import dataclass
from typing import Optional
from datetime import datetime

@dataclass
class AgentState:
    agent_id: str
    status: str  # "idle", "busy", "offline"
    current_task: Optional[str]
    last_active: datetime

class AgentRegistry:
    def __init__(self):
        self.agents = {}  # agent_id → AgentState

    def register(self, agent_id: str):
        """注册新 Agent"""
        self.agents[agent_id] = AgentState(
            agent_id=agent_id,
            status="idle",
            current_task=None,
            last_active=datetime.now()
        )

    def get_agent(self, agent_id: str) -> Optional[AgentState]:
        """查找 Agent - O(1)"""
        return self.agents.get(agent_id)

    def update_status(self, agent_id: str, status: str, task: Optional[str] = None):
        """更新 Agent 状态 - O(1)"""
        if agent_id in self.agents:
            agent = self.agents[agent_id]
            agent.status = status
            agent.current_task = task
            agent.last_active = datetime.now()

    def find_idle_agent(self) -> Optional[str]:
        """找到空闲 Agent - O(n)"""
        for agent_id, agent in self.agents.items():
            if agent.status == "idle":
                return agent_id
        return None

# 使用
registry = AgentRegistry()

# 注册 Agents
registry.register("agent_001")
registry.register("agent_002")
registry.register("agent_003")

# 分配任务
idle_agent = registry.find_idle_agent()
if idle_agent:
    registry.update_status(idle_agent, "busy", "处理用户查询")
    print(f"任务分配给: {idle_agent}")

# 查询状态
agent = registry.get_agent("agent_001")
print(f"Agent 状态: {agent.status}, 任务: {agent.current_task}")
```

**2026 实际应用：**
- **Internet of Agents**：Kademlia DHT 实现 Agent 发现
- **CrewAI**：Agent 协调和任务分配
- **AutoGPT**：Agent 状态持久化

---

## 性能对比：为什么要用哈希表？

```python
import time

# 测试数据
data = {f"key_{i}": i for i in range(10000)}
target_key = "key_9999"

# 方法 1：列表遍历 - O(n)
data_list = list(data.items())
start = time.time()
for _ in range(1000):
    for k, v in data_list:
        if k == target_key:
            result = v
            break
list_time = time.time() - start

# 方法 2：哈希表查找 - O(1)
start = time.time()
for _ in range(1000):
    result = data.get(target_key)
dict_time = time.time() - start

print(f"列表遍历: {list_time:.4f}s")
print(f"哈希表查找: {dict_time:.4f}s")
print(f"速度提升: {list_time / dict_time:.1f}x")

# 典型输出：
# 列表遍历: 2.3456s
# 哈希表查找: 0.0012s
# 速度提升: 1954.7x
```

---

## 最小可用检查清单

掌握以下内容，你就能应对 80% 的实际场景：

- [ ] 会使用 Python dict 的基本操作（增删改查）
- [ ] 理解哈希冲突的概念
- [ ] 知道链表法和开放寻址两种解决方案
- [ ] 理解负载因子对性能的影响
- [ ] 能实现简单的语义缓存
- [ ] 能实现文档去重系统
- [ ] 知道哈希表比列表快在哪里

**如果以上都掌握了，你已经具备了使用哈希表解决实际问题的能力！**

---

## 进阶方向（可选）

如果你想深入学习，可以探索：

1. **高级哈希函数**：SipHash、MurmurHash、xxHash
2. **分布式哈希表**：Consistent Hashing、Kademlia DHT
3. **语义哈希**：LSH（Locality-Sensitive Hashing）
4. **Python dict 内部实现**：Compact Hash Table
5. **并发哈希表**：Lock-free Hash Table

但记住：**先掌握基础，再追求进阶。**
