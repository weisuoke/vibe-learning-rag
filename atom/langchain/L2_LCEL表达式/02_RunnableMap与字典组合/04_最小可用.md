# 最小可用知识

> **20%核心知识解决80%问题**

---

## 学习目标

掌握本文档后，你将能够：
- ✅ 使用字典语法创建并行链
- ✅ 理解输入分发和输出映射机制
- ✅ 与 RunnablePassthrough 结合使用
- ✅ 处理基本的错误场景
- ✅ 实现 RAG 基础检索链
- ✅ 进行多模型对比

**学习时长**: 30-45 分钟
**前置知识**: Runnable 接口、管道操作符 `|`

---

## 核心知识点

### 1. 字典字面量语法（最重要）

**这是你最常用的写法，必须掌握！**

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4")

# 字典语法 = 自动创建 RunnableParallel
chain = {
    "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
    "keywords": ChatPromptTemplate.from_template("关键词: {text}") | model,
}

# 调用
result = chain.invoke({"text": "LangChain 是一个强大的 AI 框架"})
print(result)
# {
#     "summary": AIMessage(content="LangChain 框架简介..."),
#     "keywords": AIMessage(content="AI, 框架, LangChain...")
# }
```

**关键点**：
- 字典的键名（`"summary"`, `"keywords"`）会成为输出字典的键
- 字典的值必须是 Runnable 对象
- 所有分支接收相同的输入 `{"text": "..."}`
- 自动并行执行，无需额外配置

---

### 2. 与管道操作符结合

**并行执行后继续串行处理**

```python
from langchain_core.runnables import RunnableLambda

# 并行执行 → 串行处理
chain = {
    "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
    "keywords": ChatPromptTemplate.from_template("关键词: {text}") | model,
} | RunnableLambda(lambda x: f"总结: {x['summary'].content}\n关键词: {x['keywords'].content}")

result = chain.invoke({"text": "LangChain 让 AI 开发更简单"})
print(result)
# 总结: LangChain 简化 AI 开发...
# 关键词: LangChain, AI, 开发...
```

**关键点**：
- 并行部分返回字典
- 后续步骤接收字典作为输入
- 可以继续链式组合

---

### 3. RunnablePassthrough 保持上下文

**最常用的模式：并行处理 + 保持原始输入**

```python
from langchain_core.runnables import RunnablePassthrough

# 保持原始问题 + 生成摘要
chain = {
    "question": RunnablePassthrough(),  # 透传输入
    "summary": ChatPromptTemplate.from_template("总结: {text}") | model,
}

result = chain.invoke({"text": "LangChain 是什么？"})
print(result)
# {
#     "question": {"text": "LangChain 是什么？"},
#     "summary": AIMessage(content="LangChain 是...")
# }
```

**关键点**：
- `RunnablePassthrough()` 将输入原样传递到输出
- 常用于保持上下文信息
- RAG 中最常见的模式

---

### 4. RunnablePassthrough.assign() 扩展字典

**在原有字典基础上添加新字段**

```python
# 输入已经是字典，想添加新字段
chain = RunnablePassthrough.assign(
    summary=ChatPromptTemplate.from_template("总结: {text}") | model
)

result = chain.invoke({"text": "LangChain 很强大", "user": "Alice"})
print(result)
# {
#     "text": "LangChain 很强大",
#     "user": "Alice",
#     "summary": AIMessage(content="LangChain 功能强大...")
# }
```

**关键点**：
- 保留原有字典的所有字段
- 添加新字段（`summary`）
- 不会覆盖已有字段

---

## 必会的4个模式

### 模式1: 基础并行执行

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4")

# 同时执行多个独立任务
chain = {
    "task1": ChatPromptTemplate.from_template("任务1: {input}") | model,
    "task2": ChatPromptTemplate.from_template("任务2: {input}") | model,
    "task3": ChatPromptTemplate.from_template("任务3: {input}") | model,
}

result = chain.invoke({"input": "测试数据"})
# 3个任务并行执行，返回字典
```

**使用场景**：
- 多个独立的分析任务
- 多模型对比
- 多角度评估

---

### 模式2: RAG 检索链

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# 假设已有向量存储
vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

# RAG 链：保持问题 + 检索上下文
rag_chain = {
    "context": retriever,  # 检索相关文档
    "question": RunnablePassthrough(),  # 保持原始问题
} | ChatPromptTemplate.from_template(
    "根据上下文回答问题\n\n上下文: {context}\n\n问题: {question}"
) | model

# 使用
answer = rag_chain.invoke("LangChain 是什么？")
```

**关键点**：
- `retriever` 接收字符串输入，返回文档列表
- `RunnablePassthrough()` 保持原始问题
- 两者并行执行后传递给 Prompt

---

### 模式3: 上下文扩展

```python
# 在已有字典基础上添加新信息
chain = (
    RunnablePassthrough.assign(
        context=retriever
    )
    | RunnablePassthrough.assign(
        answer=ChatPromptTemplate.from_template(
            "根据上下文回答: {context}\n问题: {question}"
        ) | model
    )
)

result = chain.invoke({"question": "LangChain 是什么？"})
# {
#     "question": "LangChain 是什么？",
#     "context": [...],  # 检索结果
#     "answer": AIMessage(...)  # 生成答案
# }
```

**关键点**：
- 逐步扩展字典
- 每一步都保留之前的所有字段
- 适合需要保留中间结果的场景

---

### 模式4: 多模型对比

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# 同时调用多个模型
comparison_chain = {
    "gpt4": ChatPromptTemplate.from_template("{prompt}") | ChatOpenAI(model="gpt-4"),
    "claude": ChatPromptTemplate.from_template("{prompt}") | ChatAnthropic(model="claude-3-opus"),
}

results = comparison_chain.invoke({"prompt": "解释量子计算"})
print("GPT-4:", results["gpt4"].content)
print("Claude:", results["claude"].content)
```

**使用场景**：
- 模型效果对比
- 多模型投票
- 结果验证

---

## 完整可运行示例

### 示例1: 文本多维度分析

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 并行分析：摘要、关键词、情感
analysis_chain = {
    "summary": ChatPromptTemplate.from_template(
        "用一句话总结以下文本:\n\n{text}"
    ) | model,
    "keywords": ChatPromptTemplate.from_template(
        "提取3-5个关键词:\n\n{text}"
    ) | model,
    "sentiment": ChatPromptTemplate.from_template(
        "分析情感倾向（积极/中性/消极）:\n\n{text}"
    ) | model,
} | RunnableLambda(lambda x: {
    "summary": x["summary"].content,
    "keywords": x["keywords"].content,
    "sentiment": x["sentiment"].content,
})

# 测试
text = """
LangChain 是一个强大的框架，让开发者能够轻松构建 AI 应用。
它提供了丰富的组件和工具，大大简化了开发流程。
社区活跃，文档完善，是 AI 应用开发的首选工具。
"""

result = analysis_chain.invoke({"text": text})
print("摘要:", result["summary"])
print("关键词:", result["keywords"])
print("情感:", result["sentiment"])
```

**运行结果**：
```
摘要: LangChain 是一个简化 AI 应用开发的强大框架
关键词: LangChain, AI应用, 开发框架, 社区, 工具
情感: 积极
```

---

### 示例2: 简化版 RAG

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document
from dotenv import load_dotenv

load_dotenv()

# 1. 准备知识库
docs = [
    Document(page_content="LangChain 是一个用于构建 AI 应用的框架"),
    Document(page_content="LCEL 是 LangChain 的表达式语言"),
    Document(page_content="RunnableParallel 用于并行执行多个任务"),
]

vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=OpenAIEmbeddings()
)
retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# 2. 构建 RAG 链
model = ChatOpenAI(model="gpt-4")

rag_chain = (
    {
        "context": retriever,
        "question": RunnablePassthrough(),
    }
    | ChatPromptTemplate.from_template(
        "根据以下上下文回答问题。如果上下文中没有相关信息，请说不知道。\n\n"
        "上下文:\n{context}\n\n"
        "问题: {question}\n\n"
        "答案:"
    )
    | model
)

# 3. 测试
questions = [
    "LangChain 是什么？",
    "什么是 LCEL？",
    "RunnableParallel 的作用是什么？",
]

for q in questions:
    answer = rag_chain.invoke(q)
    print(f"Q: {q}")
    print(f"A: {answer.content}\n")
```

**关键点**：
- `retriever` 自动接收字符串输入
- `RunnablePassthrough()` 保持原始问题
- 并行执行检索和问题传递

---

### 示例3: 带上下文保持的完整流程

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model="gpt-4")

# 模拟检索器
def mock_retriever(query: str) -> list[str]:
    """模拟文档检索"""
    return [
        "LangChain 是一个 AI 应用开发框架",
        "它提供了 LCEL 表达式语言",
    ]

# 完整链：保持所有中间结果
chain = (
    # 步骤1: 添加检索结果
    RunnablePassthrough.assign(
        context=RunnableLambda(lambda x: mock_retriever(x["question"]))
    )
    # 步骤2: 生成答案
    | RunnablePassthrough.assign(
        answer=ChatPromptTemplate.from_template(
            "根据上下文回答问题\n\n上下文: {context}\n\n问题: {question}"
        ) | model
    )
    # 步骤3: 格式化输出
    | RunnableLambda(lambda x: {
        "question": x["question"],
        "context": x["context"],
        "answer": x["answer"].content,
        "metadata": {
            "context_count": len(x["context"]),
            "answer_length": len(x["answer"].content),
        }
    })
)

# 测试
result = chain.invoke({"question": "LangChain 是什么？"})
print("问题:", result["question"])
print("上下文:", result["context"])
print("答案:", result["answer"])
print("元数据:", result["metadata"])
```

---

## 常见错误与解决

### 错误1: 键名冲突

```python
# ❌ 错误：键名重复
chain = {
    "result": task1,
    "result": task2,  # 会覆盖第一个
}

# ✅ 正确：使用不同的键名
chain = {
    "result1": task1,
    "result2": task2,
}
```

---

### 错误2: 输入格式不匹配

```python
# ❌ 错误：retriever 期望字符串，但收到字典
chain = {
    "context": retriever,  # retriever 需要字符串输入
}
chain.invoke({"question": "..."})  # 传入字典

# ✅ 正确：使用 itemgetter 提取字段
from operator import itemgetter

chain = {
    "context": itemgetter("question") | retriever,
    "question": RunnablePassthrough(),
}
chain.invoke({"question": "..."})
```

---

### 错误3: 忘记保持上下文

```python
# ❌ 错误：后续步骤无法访问原始问题
chain = {
    "context": retriever,
} | prompt | model

# ✅ 正确：使用 RunnablePassthrough 保持问题
chain = {
    "context": retriever,
    "question": RunnablePassthrough(),
} | prompt | model
```

---

## 性能对比

### 串行 vs 并行

```python
import time
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

model = ChatOpenAI(model="gpt-4")

# 串行执行
start = time.time()
result1 = (ChatPromptTemplate.from_template("任务1: {input}") | model).invoke({"input": "test"})
result2 = (ChatPromptTemplate.from_template("任务2: {input}") | model).invoke({"input": "test"})
result3 = (ChatPromptTemplate.from_template("任务3: {input}") | model).invoke({"input": "test"})
serial_time = time.time() - start

# 并行执行
start = time.time()
results = {
    "task1": ChatPromptTemplate.from_template("任务1: {input}") | model,
    "task2": ChatPromptTemplate.from_template("任务2: {input}") | model,
    "task3": ChatPromptTemplate.from_template("任务3: {input}") | model,
}.invoke({"input": "test"})
parallel_time = time.time() - start

print(f"串行: {serial_time:.2f}秒")
print(f"并行: {parallel_time:.2f}秒")
print(f"提升: {(1 - parallel_time/serial_time) * 100:.1f}%")
```

**典型结果**：
```
串行: 6.2秒
并行: 2.3秒
提升: 62.9%
```

---

## 快速参考

### 基础语法

```python
# 字典语法
chain = {"key": runnable}

# 显式构造
from langchain_core.runnables import RunnableParallel
chain = RunnableParallel(key=runnable)

# 与管道结合
chain = {"key": runnable} | next_step

# 保持上下文
chain = {
    "new_field": runnable,
    "original": RunnablePassthrough(),
}

# 扩展字典
chain = RunnablePassthrough.assign(new_field=runnable)
```

---

### 输入输出

```python
# 输入：字典
chain.invoke({"key": "value"})

# 输出：字典
result = {"key1": result1, "key2": result2}
```

---

### 常用组合

```python
# RAG 模式
{
    "context": retriever,
    "question": RunnablePassthrough(),
}

# 多模型对比
{
    "model1": chain1,
    "model2": chain2,
}

# 多任务分析
{
    "task1": analysis1,
    "task2": analysis2,
    "task3": analysis3,
}
```

---

## 学习检查清单

完成以下任务，确保你已掌握最小可用知识：

- [ ] 使用字典语法创建一个并行链
- [ ] 理解输入如何分发到所有分支
- [ ] 理解输出如何映射为字典
- [ ] 使用 RunnablePassthrough 保持上下文
- [ ] 使用 RunnablePassthrough.assign() 扩展字典
- [ ] 实现一个简单的 RAG 检索链
- [ ] 实现多模型对比
- [ ] 理解串行和并行的性能差异

---

## 下一步学习

掌握最小可用知识后，你可以：

1. **深入核心概念** → 学习字典式并行执行、键值映射、结果合并策略
2. **实战代码** → 学习更复杂的 RAG 场景、多任务处理、上下文保持
3. **第一性原理** → 理解为什么需要并行执行
4. **面试准备** → 学习常见面试问题和出彩回答

---

## 参考资源

**官方文档**：
- [RunnableParallel API Reference](https://reference.langchain.com/v0.3/python/core/runnables/langchain_core.runnables.base.RunnableParallel.html)
- [LCEL Primitives](https://reference.langchain.com/python/langchain_core/runnables)

**2025-2026 最佳实践**：
- [Building Production-Ready AI Pipelines](https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557)
- [LangChain Best Practices](https://www.swarnendu.de/blog/langchain-best-practices)

---

**版本**: v1.0
**最后更新**: 2026-02-19
**适用**: LangChain 0.3+, Python 3.13+
