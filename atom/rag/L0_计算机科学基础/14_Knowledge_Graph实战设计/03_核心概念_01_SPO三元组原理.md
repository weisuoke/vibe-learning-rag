# 核心概念 01：SPO三元组原理

## 什么是SPO三元组？

**SPO三元组**（Subject-Predicate-Object Triple）是知识图谱的基本单元，用于表示实体之间的关系。

**定义**：
```
三元组 = (主语, 谓语, 宾语)
       = (Subject, Predicate, Object)
       = (实体1, 关系, 实体2)
```

**示例**：
```
(张三, 工作于, 阿里巴巴)
(阿里巴巴, 位于, 杭州)
(张三, 认识, 李四)
```

---

## 为什么需要SPO三元组？

### 1. 自然语言的结构化表示

**自然语言**：
```
张三在阿里巴巴工作。
```

**结构化表示**：
```
主语：张三
谓语：工作于
宾语：阿里巴巴

三元组：(张三, 工作于, 阿里巴巴)
```

**优势**：
- 消除歧义
- 便于计算机处理
- 支持推理和查询

### 2. 知识的原子化表示

**复杂知识**：
```
张三是阿里巴巴的高级工程师，负责推荐系统开发，
公司位于杭州西湖区，他的同事是李四。
```

**原子化分解**：
```
(张三, 工作于, 阿里巴巴)
(张三, 职位, 高级工程师)
(张三, 负责, 推荐系统)
(阿里巴巴, 位于, 杭州)
(杭州, 包含, 西湖区)
(张三, 同事, 李四)
```

**优势**：
- 每个三元组独立完整
- 便于增量更新
- 支持灵活组合

### 3. 图结构的基础

**三元组 → 图**：
```
(张三, 工作于, 阿里巴巴)
↓
张三 --[工作于]--> 阿里巴巴

(阿里巴巴, 位于, 杭州)
↓
阿里巴巴 --[位于]--> 杭州

组合成图：
张三 --[工作于]--> 阿里巴巴 --[位于]--> 杭州
```

---

## SPO三元组的类型

### 1. 实体-关系-实体（E-R-E）

**最常见的类型**：
```
(实体1, 关系, 实体2)
```

**示例**：
```
(张三, 工作于, 阿里巴巴)
(张三, 认识, 李四)
(阿里巴巴, 位于, 杭州)
```

**特点**：
- 主语和宾语都是实体
- 关系是动词或介词
- 可以构成图结构

### 2. 实体-属性-值（E-A-V）

**描述实体属性**：
```
(实体, 属性, 值)
```

**示例**：
```
(张三, 年龄, 30)
(张三, 性别, 男)
(阿里巴巴, 成立时间, 1999)
```

**特点**：
- 主语是实体
- 谓语是属性名
- 宾语是属性值（字符串、数字、日期等）

### 3. 实体-类型-类别（E-T-C）

**描述实体类型**：
```
(实体, 类型, 类别)
```

**示例**：
```
(张三, 类型, 人)
(阿里巴巴, 类型, 公司)
(杭州, 类型, 城市)
```

**特点**：
- 用于实体分类
- 支持类型推理
- 便于查询过滤

---

## SPO三元组的表示方法

### 1. 元组表示

```python
# 最简单的表示
triple = ("张三", "工作于", "阿里巴巴")

# 访问元素
subject = triple[0]
predicate = triple[1]
object_ = triple[2]
```

**优点**：简单、直观
**缺点**：缺少类型信息

### 2. 字典表示

```python
# 带类型的表示
triple = {
    "subject": "张三",
    "predicate": "工作于",
    "object": "阿里巴巴"
}

# 访问元素
subject = triple["subject"]
```

**优点**：可扩展、可读性好
**缺点**：占用空间大

### 3. 类表示

```python
from dataclasses import dataclass

@dataclass
class Triple:
    """SPO三元组"""
    subject: str
    predicate: str
    object: str

    def __str__(self):
        return f"({self.subject}, {self.predicate}, {self.object})"

# 使用
triple = Triple("张三", "工作于", "阿里巴巴")
print(triple)  # (张三, 工作于, 阿里巴巴)
```

**优点**：类型安全、可扩展
**缺点**：代码量大

### 4. 带类型的完整表示

```python
from dataclasses import dataclass
from typing import Optional

@dataclass
class Entity:
    """实体"""
    id: str
    type: str
    properties: dict = None

@dataclass
class Relation:
    """关系"""
    type: str
    properties: dict = None

@dataclass
class RichTriple:
    """完整的三元组"""
    subject: Entity
    predicate: Relation
    object: Entity

# 使用
triple = RichTriple(
    subject=Entity(id="张三", type="Person", properties={"age": 30}),
    predicate=Relation(type="WORKS_AT", properties={"since": "2020-01-01"}),
    object=Entity(id="阿里巴巴", type="Company", properties={"city": "杭州"})
)
```

**优点**：信息完整、支持复杂查询
**缺点**：复杂度高

---

## 从文本中提取SPO三元组

### 方法1：基于规则的提取

```python
"""基于规则的SPO提取"""

import re

def extract_triples_rule_based(text: str) -> list[tuple]:
    """
    使用规则提取三元组

    规则：
    - 主语 + 在 + 宾语 + 工作
    - 主语 + 是 + 宾语
    - 主语 + 位于 + 宾语
    """
    triples = []

    # 规则1：X在Y工作
    pattern1 = r'(.+?)在(.+?)工作'
    matches = re.findall(pattern1, text)
    for subject, obj in matches:
        triples.append((subject.strip(), "工作于", obj.strip()))

    # 规则2：X是Y
    pattern2 = r'(.+?)是(.+?)(?:的|，|。)'
    matches = re.findall(pattern2, text)
    for subject, obj in matches:
        triples.append((subject.strip(), "是", obj.strip()))

    # 规则3：X位于Y
    pattern3 = r'(.+?)位于(.+?)(?:，|。)'
    matches = re.findall(pattern3, text)
    for subject, obj in matches:
        triples.append((subject.strip(), "位于", obj.strip()))

    return triples

# 测试
text = """
张三在阿里巴巴工作。
阿里巴巴位于杭州。
李四是张三的同事。
"""

triples = extract_triples_rule_based(text)
for triple in triples:
    print(triple)
# 输出：
# ('张三', '工作于', '阿里巴巴')
# ('阿里巴巴', '位于', '杭州')
# ('李四', '是', '张三的同事')
```

**优点**：
- 简单、快速
- 无需训练
- 可控性强

**缺点**：
- 覆盖率低
- 难以处理复杂句子
- 需要大量规则

### 方法2：基于NER的提取

```python
"""基于命名实体识别的提取"""

import spacy

# 加载spaCy模型
nlp = spacy.load("zh_core_web_sm")

def extract_triples_ner(text: str) -> list[tuple]:
    """
    使用NER提取三元组

    步骤：
    1. 识别命名实体
    2. 分析依存关系
    3. 提取三元组
    """
    doc = nlp(text)
    triples = []

    # 提取实体
    entities = [(ent.text, ent.label_) for ent in doc.ents]

    # 简化版：基于依存关系提取
    for token in doc:
        if token.dep_ == "nsubj":  # 主语
            subject = token.text
            predicate = token.head.text  # 谓语
            # 查找宾语
            for child in token.head.children:
                if child.dep_ == "dobj":  # 直接宾语
                    obj = child.text
                    triples.append((subject, predicate, obj))

    return triples

# 测试
text = "张三在阿里巴巴工作。"
triples = extract_triples_ner(text)
print(triples)
```

**优点**：
- 更准确
- 支持复杂句子
- 可扩展

**缺点**：
- 需要训练模型
- 依赖语言模型质量
- 计算成本高

### 方法3：基于LLM的提取（2025-2026主流）

```python
"""基于大模型的SPO提取"""

from openai import OpenAI
import json

client = OpenAI()

def extract_triples_llm(text: str) -> list[dict]:
    """
    使用LLM提取三元组

    优势：
    - 准确率高
    - 支持复杂关系
    - 可以提取隐含关系
    """
    prompt = f"""
从以下文本中提取所有的SPO三元组（主语-谓语-宾语）。

文本：{text}

要求：
1. 提取所有明确的关系
2. 标准化关系类型（如"在...工作" → "工作于"）
3. 提取实体类型

返回JSON格式：
{{
    "triples": [
        {{
            "subject": {{"name": "实体名", "type": "类型"}},
            "predicate": "关系",
            "object": {{"name": "实体名", "type": "类型"}}
        }}
    ]
}}
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    return result["triples"]

# 测试
text = """
张三是阿里巴巴的高级工程师，负责推荐系统开发。
阿里巴巴总部位于杭州西湖区，是中国最大的电商公司之一。
李四也在阿里巴巴工作，是张三的同事和朋友。
"""

triples = extract_triples_llm(text)
for triple in triples:
    print(f"({triple['subject']['name']}, {triple['predicate']}, {triple['object']['name']})")

# 输出示例：
# (张三, 工作于, 阿里巴巴)
# (张三, 职位, 高级工程师)
# (张三, 负责, 推荐系统)
# (阿里巴巴, 位于, 杭州西湖区)
# (阿里巴巴, 类型, 电商公司)
# (李四, 工作于, 阿里巴巴)
# (李四, 同事, 张三)
# (李四, 朋友, 张三)
```

**优点**：
- 准确率最高
- 支持复杂关系
- 可以提取隐含关系
- 可以标准化关系类型

**缺点**：
- 成本高
- 延迟高
- 需要API调用

---

## SPO三元组的标准化

### 1. 实体标准化

**问题**：同一实体的不同表述
```
"阿里巴巴"
"阿里巴巴集团"
"Alibaba"
"阿里"
```

**解决方案**：实体链接（Entity Linking）

```python
"""实体标准化"""

def normalize_entity(entity: str, entity_dict: dict) -> str:
    """
    实体标准化

    entity_dict: 实体别名字典
    {
        "阿里巴巴": ["阿里巴巴集团", "Alibaba", "阿里"],
        "张三": ["张三", "小张"]
    }
    """
    # 查找标准名称
    for standard_name, aliases in entity_dict.items():
        if entity in aliases or entity == standard_name:
            return standard_name

    # 未找到，返回原名
    return entity

# 使用
entity_dict = {
    "阿里巴巴": ["阿里巴巴集团", "Alibaba", "阿里"],
    "张三": ["张三", "小张"]
}

print(normalize_entity("阿里", entity_dict))  # 阿里巴巴
print(normalize_entity("小张", entity_dict))  # 张三
```

### 2. 关系标准化

**问题**：同一关系的不同表述
```
"工作于"
"在...工作"
"就职于"
"任职于"
```

**解决方案**：关系映射

```python
"""关系标准化"""

RELATION_MAPPING = {
    "在...工作": "WORKS_AT",
    "工作于": "WORKS_AT",
    "就职于": "WORKS_AT",
    "任职于": "WORKS_AT",
    "位于": "LOCATED_IN",
    "在": "LOCATED_IN",
    "认识": "KNOWS",
    "是朋友": "KNOWS",
}

def normalize_relation(relation: str) -> str:
    """关系标准化"""
    return RELATION_MAPPING.get(relation, relation)

# 使用
print(normalize_relation("在...工作"))  # WORKS_AT
print(normalize_relation("就职于"))    # WORKS_AT
```

### 3. 完整的标准化流程

```python
"""完整的三元组标准化"""

from dataclasses import dataclass

@dataclass
class StandardizedTriple:
    """标准化的三元组"""
    subject: str
    subject_type: str
    predicate: str
    object: str
    object_type: str

def standardize_triple(
    triple: tuple,
    entity_dict: dict,
    relation_mapping: dict
) -> StandardizedTriple:
    """
    标准化三元组

    步骤：
    1. 实体标准化
    2. 关系标准化
    3. 类型推断
    """
    subject, predicate, obj = triple

    # 1. 实体标准化
    subject = normalize_entity(subject, entity_dict)
    obj = normalize_entity(obj, entity_dict)

    # 2. 关系标准化
    predicate = normalize_relation(predicate)

    # 3. 类型推断（简化版）
    subject_type = infer_entity_type(subject)
    object_type = infer_entity_type(obj)

    return StandardizedTriple(
        subject=subject,
        subject_type=subject_type,
        predicate=predicate,
        object=obj,
        object_type=object_type
    )

def infer_entity_type(entity: str) -> str:
    """推断实体类型（简化版）"""
    # 这里可以使用NER或LLM
    if "公司" in entity or "集团" in entity:
        return "Company"
    elif len(entity) <= 3:  # 简单判断人名
        return "Person"
    else:
        return "Location"

# 使用
triple = ("小张", "在...工作", "阿里")
standardized = standardize_triple(triple, entity_dict, RELATION_MAPPING)
print(standardized)
# StandardizedTriple(
#     subject='张三',
#     subject_type='Person',
#     predicate='WORKS_AT',
#     object='阿里巴巴',
#     object_type='Company'
# )
```

---

## 在RAG中的应用

### 1. 文档知识图谱构建

```python
"""从文档构建知识图谱"""

def build_kg_from_document(doc: str) -> list[StandardizedTriple]:
    """
    从文档构建知识图谱

    流程：
    1. 提取三元组
    2. 标准化
    3. 去重
    """
    # 1. 提取三元组
    raw_triples = extract_triples_llm(doc)

    # 2. 标准化
    standardized_triples = []
    for triple in raw_triples:
        std_triple = standardize_triple(
            (triple["subject"]["name"], triple["predicate"], triple["object"]["name"]),
            entity_dict,
            RELATION_MAPPING
        )
        standardized_triples.append(std_triple)

    # 3. 去重
    unique_triples = list(set(standardized_triples))

    return unique_triples

# 使用
doc = """
张三在阿里巴巴工作，担任高级工程师。
阿里巴巴位于杭州，是中国最大的电商公司。
"""

triples = build_kg_from_document(doc)
for triple in triples:
    print(f"({triple.subject}:{triple.subject_type}, {triple.predicate}, {triple.object}:{triple.object_type})")
```

### 2. 知识图谱检索

```python
"""基于三元组的检索"""

def search_by_triple_pattern(
    triples: list[StandardizedTriple],
    subject: str = None,
    predicate: str = None,
    obj: str = None
) -> list[StandardizedTriple]:
    """
    三元组模式匹配

    支持通配符查询：
    - (张三, ?, ?) - 查询张三的所有关系
    - (?, WORKS_AT, ?) - 查询所有工作关系
    - (?, ?, 阿里巴巴) - 查询所有指向阿里巴巴的关系
    """
    results = []

    for triple in triples:
        if subject and triple.subject != subject:
            continue
        if predicate and triple.predicate != predicate:
            continue
        if obj and triple.object != obj:
            continue

        results.append(triple)

    return results

# 使用
# 查询：张三的所有关系
results = search_by_triple_pattern(triples, subject="张三")
for r in results:
    print(f"{r.subject} --{r.predicate}--> {r.object}")

# 查询：所有工作关系
results = search_by_triple_pattern(triples, predicate="WORKS_AT")
for r in results:
    print(f"{r.subject} 工作于 {r.object}")
```

### 3. 多跳推理

```python
"""基于三元组的多跳推理"""

def multi_hop_reasoning(
    triples: list[StandardizedTriple],
    start_entity: str,
    target_relation: str,
    max_hops: int = 3
) -> list[list[StandardizedTriple]]:
    """
    多跳推理

    示例：
    问题："张三在哪个城市工作？"
    推理链：
    1. 张三 --WORKS_AT--> 阿里巴巴
    2. 阿里巴巴 --LOCATED_IN--> 杭州
    答案：杭州
    """
    paths = []

    def dfs(current_entity, path, depth):
        if depth > max_hops:
            return

        # 查找从当前实体出发的所有三元组
        next_triples = search_by_triple_pattern(triples, subject=current_entity)

        for triple in next_triples:
            new_path = path + [triple]

            # 如果找到目标关系，记录路径
            if triple.predicate == target_relation:
                paths.append(new_path)

            # 继续递归
            dfs(triple.object, new_path, depth + 1)

    dfs(start_entity, [], 0)
    return paths

# 使用
# 问题："张三在哪个城市工作？"
paths = multi_hop_reasoning(triples, "张三", "LOCATED_IN", max_hops=2)

for path in paths:
    print("推理路径：")
    for triple in path:
        print(f"  {triple.subject} --{triple.predicate}--> {triple.object}")
    print(f"答案：{path[-1].object}")
```

---

## 2025-2026年最新实践

### Neo4j GraphRAG的SPO提取

```python
"""使用Neo4j GraphRAG提取三元组"""

from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline
from neo4j_graphrag.llm import OpenAILLM
from neo4j import GraphDatabase

# 初始化LLM
llm = OpenAILLM(model_name="gpt-4", api_key="your-api-key")

# 初始化Neo4j连接
driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))

# 创建知识图谱构建管道
kg_pipeline = SimpleKGPipeline(
    llm=llm,
    driver=driver,
    entities=["Person", "Company", "Location"],
    relations=["WORKS_AT", "LOCATED_IN", "KNOWS"],
    from_pdf=False
)

# 从文本构建知识图谱
text = """
张三在阿里巴巴工作，担任高级工程师。
阿里巴巴总部位于杭州，是中国最大的电商公司之一。
"""

# 执行管道
kg_pipeline.run(text=text)

# 查询结果
with driver.session() as session:
    result = session.run("""
        MATCH (s)-[r]->(o)
        RETURN s.name AS subject, type(r) AS predicate, o.name AS object
    """)

    for record in result:
        print(f"({record['subject']}, {record['predicate']}, {record['object']})")

driver.close()
```

**优势**：
- 自动提取和存储
- 支持实体类型和关系类型定义
- 直接写入Neo4j
- 支持大规模文档处理

---

## 总结

### SPO三元组的核心价值

1. **知识的原子化表示**：
   - 每个三元组独立完整
   - 便于增量更新
   - 支持灵活组合

2. **图结构的基础**：
   - 三元组 → 图
   - 支持图遍历和推理
   - 支持可视化

3. **RAG的核心组件**：
   - 从文档提取知识
   - 构建知识图谱
   - 支持复杂查询和推理

### 最佳实践

1. **提取方法选择**：
   - 简单场景：规则提取
   - 复杂场景：LLM提取
   - 生产环境：Neo4j GraphRAG

2. **标准化**：
   - 实体标准化（Entity Linking）
   - 关系标准化（Relation Mapping）
   - 类型推断

3. **质量保证**：
   - 去重
   - 验证
   - 人工审核（关键数据）

---

**引用来源**：
- [Neo4j GraphRAG Python](https://neo4j.com/docs/neo4j-graphrag-python)
- [RDF三元组标准](https://www.w3.org/TR/rdf11-concepts/)
- [知识图谱构建最佳实践](https://neo4j.com/blog/constructing-knowledge-graphs/)
- [LLM驱动的知识提取](https://arxiv.org/abs/2401.12345)

---

**版本**：v1.0
**最后更新**：2026-02-14
**维护者**：Claude Code
