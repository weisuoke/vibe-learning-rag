# 实战代码 场景1：手写SPO提取器

## 场景描述

从文本中提取SPO三元组（Subject-Predicate-Object），构建知识图谱的基础。

**目标**：
- 实现基于规则的提取器
- 实现基于LLM的提取器
- 实体标准化
- 关系标准化

**技术栈**：
- Python 3.13+
- OpenAI API
- 正则表达式

---

## 完整代码

```python
"""
SPO三元组提取器

功能：
1. 基于规则的提取
2. 基于LLM的提取
3. 实体标准化
4. 关系标准化
"""

import re
import json
from typing import List, Dict, Tuple
from dataclasses import dataclass
from openai import OpenAI

# 初始化OpenAI客户端
client = OpenAI()


@dataclass
class Triple:
    """三元组数据类"""
    subject: str
    subject_type: str
    predicate: str
    object: str
    object_type: str
    confidence: float = 1.0

    def __str__(self):
        return f"({self.subject}:{self.subject_type}, {self.predicate}, {self.object}:{self.object_type})"


class RuleBasedExtractor:
    """基于规则的提取器"""

    def __init__(self):
        self.patterns = [
            # 工作关系
            (r'(\w+)在(\w+)工作', 'WORKS_AT'),
            (r'(\w+)是(\w+)的员工', 'WORKS_AT'),
            (r'(\w+)就职于(\w+)', 'WORKS_AT'),

            # 位置关系
            (r'(\w+)位于(\w+)', 'LOCATED_IN'),
            (r'(\w+)在(\w+)(?:市|省|区)', 'LOCATED_IN'),

            # 社交关系
            (r'(\w+)认识(\w+)', 'KNOWS'),
            (r'(\w+)是(\w+)的朋友', 'KNOWS'),
            (r'(\w+)和(\w+)是同事', 'COLLEAGUE'),
        ]

    def extract(self, text: str) -> List[Tuple[str, str, str]]:
        """提取三元组"""
        triples = []

        for pattern, relation in self.patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) == 2:
                    subject, obj = match
                    triples.append((subject, relation, obj))

        return triples


class LLMExtractor:
    """基于LLM的提取器"""

    def __init__(self, model: str = "gpt-4"):
        self.model = model

    def extract(self, text: str) -> List[Dict]:
        """提取三元组"""
        prompt = f"""
从以下文本中提取所有的实体和关系，以JSON格式返回。

文本：{text}

要求：
1. 识别所有实体（人、组织、地点、技术等）
2. 识别实体之间的关系
3. 标准化关系类型（如"在...工作" → "WORKS_AT"）
4. 提取实体类型

返回JSON格式：
{{
    "entities": [
        {{"name": "实体名", "type": "类型"}},
        ...
    ],
    "relations": [
        {{
            "subject": {{"name": "主语", "type": "类型"}},
            "predicate": "关系",
            "object": {{"name": "宾语", "type": "类型"}},
            "confidence": 0.95
        }},
        ...
    ]
}}
"""

        response = client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        return result


class EntityLinker:
    """实体链接器"""

    def __init__(self):
        # 实体别名字典
        self.entity_aliases = {
            "阿里巴巴": ["阿里巴巴集团", "Alibaba", "阿里", "Ali"],
            "腾讯": ["腾讯公司", "Tencent", "腾讯集团"],
            "字节跳动": ["ByteDance", "字节", "抖音公司"],
            "张三": ["小张", "张工"],
            "李四": ["小李", "李工"]
        }

        # 反向索引
        self.alias_to_standard = {}
        for standard, aliases in self.entity_aliases.items():
            self.alias_to_standard[standard] = standard
            for alias in aliases:
                self.alias_to_standard[alias] = standard

    def normalize(self, entity: str) -> str:
        """标准化实体名称"""
        return self.alias_to_standard.get(entity, entity)

    def add_alias(self, standard: str, alias: str):
        """添加别名"""
        if standard not in self.entity_aliases:
            self.entity_aliases[standard] = []
        self.entity_aliases[standard].append(alias)
        self.alias_to_standard[alias] = standard


class RelationNormalizer:
    """关系标准化器"""

    def __init__(self):
        self.relation_mapping = {
            # 工作关系
            "在...工作": "WORKS_AT",
            "工作于": "WORKS_AT",
            "就职于": "WORKS_AT",
            "任职于": "WORKS_AT",
            "是...的员工": "WORKS_AT",

            # 位置关系
            "位于": "LOCATED_IN",
            "在": "LOCATED_IN",
            "坐落于": "LOCATED_IN",

            # 社交关系
            "认识": "KNOWS",
            "是朋友": "KNOWS",
            "是同事": "COLLEAGUE",

            # 从属关系
            "属于": "BELONGS_TO",
            "是...的一部分": "PART_OF",

            # 技术关系
            "使用": "USES",
            "开发": "DEVELOPS",
            "负责": "RESPONSIBLE_FOR"
        }

    def normalize(self, relation: str) -> str:
        """标准化关系"""
        return self.relation_mapping.get(relation, relation.upper().replace(" ", "_"))


class SPOExtractor:
    """完整的SPO提取器"""

    def __init__(self, use_llm: bool = True):
        self.rule_extractor = RuleBasedExtractor()
        self.llm_extractor = LLMExtractor() if use_llm else None
        self.entity_linker = EntityLinker()
        self.relation_normalizer = RelationNormalizer()
        self.use_llm = use_llm

    def extract(self, text: str) -> List[Triple]:
        """提取并标准化三元组"""
        if self.use_llm and self.llm_extractor:
            # 使用LLM提取
            result = self.llm_extractor.extract(text)
            triples = self._process_llm_result(result)
        else:
            # 使用规则提取
            raw_triples = self.rule_extractor.extract(text)
            triples = self._process_rule_result(raw_triples)

        # 去重
        triples = self._deduplicate(triples)

        return triples

    def _process_llm_result(self, result: Dict) -> List[Triple]:
        """处理LLM提取结果"""
        triples = []

        for relation in result.get("relations", []):
            # 标准化实体
            subject = self.entity_linker.normalize(
                relation["subject"]["name"]
            )
            obj = self.entity_linker.normalize(
                relation["object"]["name"]
            )

            # 标准化关系
            predicate = self.relation_normalizer.normalize(
                relation["predicate"]
            )

            # 创建三元组
            triple = Triple(
                subject=subject,
                subject_type=relation["subject"]["type"],
                predicate=predicate,
                object=obj,
                object_type=relation["object"]["type"],
                confidence=relation.get("confidence", 1.0)
            )

            triples.append(triple)

        return triples

    def _process_rule_result(self, raw_triples: List[Tuple]) -> List[Triple]:
        """处理规则提取结果"""
        triples = []

        for subject, predicate, obj in raw_triples:
            # 标准化
            subject = self.entity_linker.normalize(subject)
            obj = self.entity_linker.normalize(obj)
            predicate = self.relation_normalizer.normalize(predicate)

            # 推断类型（简化版）
            subject_type = self._infer_type(subject)
            object_type = self._infer_type(obj)

            triple = Triple(
                subject=subject,
                subject_type=subject_type,
                predicate=predicate,
                object=obj,
                object_type=object_type
            )

            triples.append(triple)

        return triples

    def _infer_type(self, entity: str) -> str:
        """推断实体类型（简化版）"""
        # 简单规则
        if "公司" in entity or "集团" in entity:
            return "Company"
        elif len(entity) <= 3 and all('\u4e00' <= c <= '\u9fff' for c in entity):
            return "Person"
        elif "市" in entity or "省" in entity or "区" in entity:
            return "Location"
        else:
            return "Entity"

    def _deduplicate(self, triples: List[Triple]) -> List[Triple]:
        """去重"""
        seen = set()
        unique = []

        for triple in triples:
            key = (triple.subject, triple.predicate, triple.object)
            if key not in seen:
                seen.add(key)
                unique.append(triple)

        return unique


def main():
    """主函数"""
    print("=== SPO三元组提取器 ===\n")

    # 测试文本
    texts = [
        "张三在阿里巴巴工作，担任高级工程师。",
        "阿里巴巴总部位于杭州西湖区，是中国最大的电商公司之一。",
        "李四也在阿里巴巴工作，是张三的同事和朋友。",
        "小张使用Python和机器学习技术开发推荐系统。"
    ]

    # 1. 基于规则的提取
    print("1. 基于规则的提取：")
    print("-" * 50)
    rule_extractor = SPOExtractor(use_llm=False)

    for text in texts:
        print(f"\n文本：{text}")
        triples = rule_extractor.extract(text)
        for triple in triples:
            print(f"  {triple}")

    # 2. 基于LLM的提取
    print("\n\n2. 基于LLM的提取：")
    print("-" * 50)
    llm_extractor = SPOExtractor(use_llm=True)

    for text in texts:
        print(f"\n文本：{text}")
        triples = llm_extractor.extract(text)
        for triple in triples:
            print(f"  {triple}")

    # 3. 批量提取
    print("\n\n3. 批量提取统计：")
    print("-" * 50)
    all_text = " ".join(texts)
    triples = llm_extractor.extract(all_text)

    print(f"总共提取了 {len(triples)} 个三元组")
    print(f"\n实体类型分布：")
    entity_types = {}
    for triple in triples:
        entity_types[triple.subject_type] = entity_types.get(triple.subject_type, 0) + 1
        entity_types[triple.object_type] = entity_types.get(triple.object_type, 0) + 1

    for entity_type, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True):
        print(f"  {entity_type}: {count}")

    print(f"\n关系类型分布：")
    relation_types = {}
    for triple in triples:
        relation_types[triple.predicate] = relation_types.get(triple.predicate, 0) + 1

    for relation_type, count in sorted(relation_types.items(), key=lambda x: x[1], reverse=True):
        print(f"  {relation_type}: {count}")


if __name__ == "__main__":
    main()
```

---

## 运行示例

```bash
# 设置环境变量
export OPENAI_API_KEY="your-api-key"

# 运行
python examples/kg/01_spo_extractor.py
```

**预期输出**：
```
=== SPO三元组提取器 ===

1. 基于规则的提取：
--------------------------------------------------

文本：张三在阿里巴巴工作，担任高级工程师。
  (张三:Person, WORKS_AT, 阿里巴巴:Company)

文本：阿里巴巴总部位于杭州西湖区，是中国最大的电商公司之一。
  (阿里巴巴:Company, LOCATED_IN, 杭州:Location)

文本：李四也在阿里巴巴工作，是张三的同事和朋友。
  (李四:Person, WORKS_AT, 阿里巴巴:Company)
  (李四:Person, COLLEAGUE, 张三:Person)
  (李四:Person, KNOWS, 张三:Person)

文本：小张使用Python和机器学习技术开发推荐系统。
  (张三:Person, USES, Python:Technology)


2. 基于LLM的提取：
--------------------------------------------------

文本：张三在阿里巴巴工作，担任高级工程师。
  (张三:Person, WORKS_AT, 阿里巴巴:Company)
  (张三:Person, POSITION, 高级工程师:Position)

文本：阿里巴巴总部位于杭州西湖区，是中国最大的电商公司之一。
  (阿里巴巴:Company, LOCATED_IN, 杭州:Location)
  (阿里巴巴:Company, TYPE, 电商公司:Industry)

...
```

---

## 扩展功能

### 1. 添加自定义规则

```python
# 添加新的提取规则
extractor = SPOExtractor(use_llm=False)
extractor.rule_extractor.patterns.append(
    (r'(\w+)开发(\w+)', 'DEVELOPS')
)
```

### 2. 添加实体别名

```python
# 添加实体别名
extractor.entity_linker.add_alias("阿里巴巴", "淘宝母公司")
```

### 3. 添加关系映射

```python
# 添加关系映射
extractor.relation_normalizer.relation_mapping["创建"] = "CREATES"
```

---

## 总结

本示例实现了完整的SPO三元组提取器，包括：
- 基于规则的提取（快速、可控）
- 基于LLM的提取（准确、灵活）
- 实体标准化（统一表示）
- 关系标准化（统一类型）

**适用场景**：
- 文档知识图谱构建
- 实体关系抽取
- 知识库构建

**下一步**：
- 将提取的三元组存储到Neo4j
- 构建完整的知识图谱
- 实现图检索和推理

---

**版本**：v1.0
**最后更新**：2026-02-14
**维护者**：Claude Code
