# 实战代码 - 场景3：并发测试

> 多线程并发测试，测试系统在并发场景下的性能表现

---

## 场景描述

**测试目标：** 使用 Python 多线程测试 Milvus 的并发性能，分析不同并发级别下的性能表现

**适用场景：**
- 测试不同并发级别的性能
- 分析并发对延迟的影响
- 验证连接池配置
- 对比单线程和多线程性能

---

## 完整代码

```python
"""
Milvus 并发性能测试
场景：多线程并发检索测试
"""

import time
import numpy as np
from typing import List, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType
from dataclasses import dataclass
import threading
import queue
import json

# ===== 1. 配置参数 =====

CONFIG = {
    "milvus_host": "localhost",
    "milvus_port": "19530",
    "collection_name": "benchmark_concurrent",
    "dim": 768,
    "num_vectors": 1_000_000,
    "test_iterations": 1000,
    "concurrency_levels": [1, 5, 10, 20, 50, 100]
}

# ===== 2. 数据结构定义 =====

@dataclass
class ConcurrentTestResult:
    """并发测试结果"""
    concurrency: int
    total_requests: int
    total_time: float
    qps: float
    avg_latency: float
    p50_latency: float
    p95_latency: float
    p99_latency: float
    max_latency: float
    min_latency: float
    std_latency: float
    success_count: int
    failure_count: int
    failure_rate: float

    def to_dict(self):
        """转换为字典"""
        return {
            "并发数": self.concurrency,
            "总请求数": self.total_requests,
            "总耗时": f"{self.total_time:.2f}s",
            "QPS": f"{self.qps:.2f}",
            "平均延迟": f"{self.avg_latency:.2f}ms",
            "P50延迟": f"{self.p50_latency:.2f}ms",
            "P95延迟": f"{self.p95_latency:.2f}ms",
            "P99延迟": f"{self.p99_latency:.2f}ms",
            "最大延迟": f"{self.max_latency:.2f}ms",
            "最小延迟": f"{self.min_latency:.2f}ms",
            "标准差": f"{self.std_latency:.2f}ms",
            "成功数": self.success_count,
            "失败数": self.failure_count,
            "失败率": f"{self.failure_rate:.2%}"
        }

# ===== 3. 线程安全的结果收集器 =====

class ResultCollector:
    """线程安全的结果收集器"""

    def __init__(self):
        self.latencies = []
        self.success_count = 0
        self.failure_count = 0
        self.lock = threading.Lock()

    def add_success(self, latency: float):
        """添加成功结果"""
        with self.lock:
            self.latencies.append(latency)
            self.success_count += 1

    def add_failure(self):
        """添加失败结果"""
        with self.lock:
            self.failure_count += 1

    def get_statistics(self) -> Dict:
        """获取统计信息"""
        with self.lock:
            if not self.latencies:
                return {
                    "avg": 0,
                    "p50": 0,
                    "p95": 0,
                    "p99": 0,
                    "max": 0,
                    "min": 0,
                    "std": 0
                }

            latencies_array = np.array(self.latencies)
            return {
                "avg": np.mean(latencies_array),
                "p50": np.percentile(latencies_array, 50),
                "p95": np.percentile(latencies_array, 95),
                "p99": np.percentile(latencies_array, 99),
                "max": np.max(latencies_array),
                "min": np.min(latencies_array),
                "std": np.std(latencies_array)
            }

# ===== 4. 数据准备 =====

def prepare_test_environment():
    """准备测试环境"""
    print("=== 准备测试环境 ===")

    # 连接 Milvus
    connections.connect("default", host=CONFIG['milvus_host'], port=CONFIG['milvus_port'])

    # 创建 Collection
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=CONFIG['dim']),
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=10)
    ]
    schema = CollectionSchema(fields=fields, description="Concurrent test collection")

    try:
        collection = Collection(name=CONFIG['collection_name'])
        print(f"Collection {CONFIG['collection_name']} 已存在")
    except:
        collection = Collection(name=CONFIG['collection_name'], schema=schema)
        print(f"Collection {CONFIG['collection_name']} 创建成功")

        # 插入数据
        print(f"插入 {CONFIG['num_vectors']:,} 个向量...")
        batch_size = 10000
        for i in range(0, CONFIG['num_vectors'], batch_size):
            vectors = np.random.normal(0, 1, (batch_size, CONFIG['dim'])).astype(np.float32)
            vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
            categories = np.random.choice(["A", "B", "C", "D"], batch_size).tolist()

            collection.insert([vectors.tolist(), categories])

            if (i + batch_size) % 100000 == 0:
                print(f"  已插入: {i + batch_size:,} / {CONFIG['num_vectors']:,}")

        print("✅ 数据插入完成")

    # 创建索引
    print("创建 HNSW 索引...")
    collection.release()
    collection.drop_index()
    collection.create_index(
        field_name="embedding",
        index_params={
            "metric_type": "L2",
            "index_type": "HNSW",
            "params": {"M": 16, "efConstruction": 200}
        }
    )
    print("✅ 索引创建完成")

    # 加载 Collection
    print("加载 Collection...")
    collection.load()
    print("✅ Collection 加载完成")

    print("\n✅ 测试环境准备完成\n")

# ===== 5. 单线程测试函数 =====

def single_query(collection: Collection, result_collector: ResultCollector):
    """执行单次查询"""
    # 生成随机向量
    vector = [np.random.random() for _ in range(CONFIG['dim'])]

    try:
        start = time.time()
        collection.search(
            data=[vector],
            anns_field="embedding",
            param={"metric_type": "L2", "params": {"ef": 64}},
            limit=10
        )
        latency = (time.time() - start) * 1000
        result_collector.add_success(latency)

    except Exception as e:
        result_collector.add_failure()
        print(f"查询失败: {e}")

# ===== 6. 并发测试 =====

def test_concurrent_search(
    collection: Collection,
    concurrency: int,
    total_requests: int
) -> ConcurrentTestResult:
    """测试并发检索性能"""

    print(f"\n{'='*60}")
    print(f"测试并发数: {concurrency}")
    print(f"{'='*60}")

    # 创建结果收集器
    result_collector = ResultCollector()

    # 预热
    print(f"  预热系统（10次）...")
    for _ in range(10):
        single_query(collection, ResultCollector())

    # 执行并发测试
    print(f"  执行测试（{total_requests}次请求，{concurrency}并发）...")

    start_time = time.time()

    with ThreadPoolExecutor(max_workers=concurrency) as executor:
        # 提交所有任务
        futures = [
            executor.submit(single_query, collection, result_collector)
            for _ in range(total_requests)
        ]

        # 等待所有任务完成，显示进度
        completed = 0
        for future in as_completed(futures):
            completed += 1
            if completed % (total_requests // 10) == 0:
                print(f"    进度: {completed}/{total_requests}")

    total_time = time.time() - start_time

    # 获取统计信息
    stats = result_collector.get_statistics()

    # 计算 QPS
    qps = total_requests / total_time

    # 计算失败率
    failure_rate = result_collector.failure_count / total_requests

    # 生成结果
    result = ConcurrentTestResult(
        concurrency=concurrency,
        total_requests=total_requests,
        total_time=total_time,
        qps=qps,
        avg_latency=stats['avg'],
        p50_latency=stats['p50'],
        p95_latency=stats['p95'],
        p99_latency=stats['p99'],
        max_latency=stats['max'],
        min_latency=stats['min'],
        std_latency=stats['std'],
        success_count=result_collector.success_count,
        failure_count=result_collector.failure_count,
        failure_rate=failure_rate
    )

    # 打印结果
    print(f"\n=== 测试结果 ===")
    for key, value in result.to_dict().items():
        print(f"  {key}: {value}")

    return result

# ===== 7. 对比分析 =====

def analyze_concurrency_impact(results: List[ConcurrentTestResult]):
    """分析并发对性能的影响"""

    print(f"\n{'='*60}")
    print("并发性能对比分析")
    print(f"{'='*60}")

    # 1. QPS 分析
    print(f"\n1. QPS 分析")
    print(f"{'并发数':<10} {'QPS':<15} {'相对提升':<15}")
    print("-" * 40)

    baseline_qps = results[0].qps
    for result in results:
        relative_improvement = (result.qps / baseline_qps - 1) * 100
        print(f"{result.concurrency:<10} {result.qps:<15.2f} {relative_improvement:>+14.1f}%")

    # 2. 延迟分析
    print(f"\n2. P95延迟分析")
    print(f"{'并发数':<10} {'P95延迟':<15} {'相对变化':<15}")
    print("-" * 40)

    baseline_latency = results[0].p95_latency
    for result in results:
        relative_change = (result.p95_latency / baseline_latency - 1) * 100
        print(f"{result.concurrency:<10} {result.p95_latency:<15.2f} {relative_change:>+14.1f}%")

    # 3. 稳定性分析
    print(f"\n3. 稳定性分析（标准差）")
    print(f"{'并发数':<10} {'标准差':<15} {'失败率':<15}")
    print("-" * 40)

    for result in results:
        print(f"{result.concurrency:<10} {result.std_latency:<15.2f} {result.failure_rate:<15.2%}")

    # 4. 找出最佳并发数
    print(f"\n4. 最佳并发数分析")

    # 最高 QPS
    best_qps = max(results, key=lambda x: x.qps)
    print(f"  最高 QPS: 并发数={best_qps.concurrency}, QPS={best_qps.qps:.2f}")

    # 最低延迟
    best_latency = min(results, key=lambda x: x.p95_latency)
    print(f"  最低 P95延迟: 并发数={best_latency.concurrency}, 延迟={best_latency.p95_latency:.2f}ms")

    # 综合评分（QPS / P95延迟）
    best_score = max(results, key=lambda x: x.qps / x.p95_latency)
    print(f"  最佳综合性能: 并发数={best_score.concurrency}, 评分={best_score.qps / best_score.p95_latency:.2f}")

    # 5. 性能拐点分析
    print(f"\n5. 性能拐点分析")

    for i in range(1, len(results)):
        prev = results[i-1]
        curr = results[i]

        qps_improvement = (curr.qps / prev.qps - 1) * 100
        latency_increase = (curr.p95_latency / prev.p95_latency - 1) * 100

        if qps_improvement < 10 and latency_increase > 50:
            print(f"  ⚠️ 性能拐点: 并发数从 {prev.concurrency} 增加到 {curr.concurrency}")
            print(f"     QPS 提升仅 {qps_improvement:.1f}%，但延迟增加 {latency_increase:.1f}%")

# ===== 8. 可视化 =====

def visualize_results(results: List[ConcurrentTestResult]):
    """可视化测试结果"""
    import matplotlib.pyplot as plt

    concurrency_levels = [r.concurrency for r in results]
    qps_values = [r.qps for r in results]
    p95_latencies = [r.p95_latency for r in results]
    failure_rates = [r.failure_rate * 100 for r in results]

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. QPS vs 并发数
    axes[0, 0].plot(concurrency_levels, qps_values, marker='o', linewidth=2)
    axes[0, 0].set_title('QPS vs Concurrency', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('Concurrency')
    axes[0, 0].set_ylabel('QPS')
    axes[0, 0].grid(True, alpha=0.3)

    # 2. P95延迟 vs 并发数
    axes[0, 1].plot(concurrency_levels, p95_latencies, marker='o', linewidth=2, color='orange')
    axes[0, 1].set_title('P95 Latency vs Concurrency', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('Concurrency')
    axes[0, 1].set_ylabel('P95 Latency (ms)')
    axes[0, 1].grid(True, alpha=0.3)

    # 3. 失败率 vs 并发数
    axes[1, 0].plot(concurrency_levels, failure_rates, marker='o', linewidth=2, color='red')
    axes[1, 0].set_title('Failure Rate vs Concurrency', fontsize=14, fontweight='bold')
    axes[1, 0].set_xlabel('Concurrency')
    axes[1, 0].set_ylabel('Failure Rate (%)')
    axes[1, 0].grid(True, alpha=0.3)

    # 4. 综合评分（QPS / P95延迟）
    scores = [r.qps / r.p95_latency for r in results]
    axes[1, 1].plot(concurrency_levels, scores, marker='o', linewidth=2, color='green')
    axes[1, 1].set_title('Performance Score (QPS / P95 Latency)', fontsize=14, fontweight='bold')
    axes[1, 1].set_xlabel('Concurrency')
    axes[1, 1].set_ylabel('Score')
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('concurrent_test_results.png', dpi=300)
    print("\n✅ 图表已保存到: concurrent_test_results.png")

# ===== 9. 主函数 =====

def main():
    """主函数"""

    print("="*60)
    print("Milvus 并发性能测试")
    print("="*60)

    # 1. 准备测试环境
    prepare_test_environment()

    # 2. 连接 Milvus
    connections.connect("default", host=CONFIG['milvus_host'], port=CONFIG['milvus_port'])
    collection = Collection(CONFIG['collection_name'])
    collection.load()

    # 3. 执行不同并发级别的测试
    results = []

    for concurrency in CONFIG['concurrency_levels']:
        result = test_concurrent_search(
            collection,
            concurrency,
            CONFIG['test_iterations']
        )
        results.append(result)

        # 短暂休息，让系统恢复
        time.sleep(5)

    # 4. 分析结果
    analyze_concurrency_impact(results)

    # 5. 可视化
    visualize_results(results)

    # 6. 保存结果
    output_file = "concurrent_test_results.json"
    with open(output_file, 'w') as f:
        json.dump([r.to_dict() for r in results], f, indent=2, ensure_ascii=False)
    print(f"\n✅ 结果已保存到: {output_file}")

    # 7. 清理
    print(f"\n=== 清理资源 ===")
    collection.release()
    print(f"✅ 清理完成")

if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
Milvus 并发性能测试
============================================================

=== 准备测试环境 ===
Collection benchmark_concurrent 已存在
创建 HNSW 索引...
✅ 索引创建完成
加载 Collection...
✅ Collection 加载完成

✅ 测试环境准备完成

============================================================
测试并发数: 1
============================================================
  预热系统（10次）...
  执行测试（1000次请求，1并发）...
    进度: 100/1000
    进度: 200/1000
    ...

=== 测试结果 ===
  并发数: 1
  总请求数: 1000
  总耗时: 18.45s
  QPS: 54.20
  平均延迟: 18.45ms
  P50延迟: 17.23ms
  P95延迟: 25.67ms
  P99延迟: 32.18ms
  最大延迟: 45.23ms
  最小延迟: 15.12ms
  标准差: 5.34ms
  成功数: 1000
  失败数: 0
  失败率: 0.00%

============================================================
测试并发数: 5
============================================================
...

============================================================
并发性能对比分析
============================================================

1. QPS 分析
并发数      QPS             相对提升
----------------------------------------
1          54.20           +0.0%
5          245.67          +353.3%
10         456.89          +742.9%
20         823.45          +1419.0%
50         1234.56         +2177.8%
100        1456.78         +2587.9%

2. P95延迟分析
并发数      P95延迟         相对变化
----------------------------------------
1          25.67           +0.0%
5          28.34           +10.4%
10         35.67           +38.9%
20         58.90           +129.5%
50         145.23          +465.8%
100        320.45          +1148.3%

3. 稳定性分析（标准差）
并发数      标准差          失败率
----------------------------------------
1          5.34            0.00%
5          6.78            0.00%
10         8.90            0.00%
20         15.67           0.10%
50         45.23           0.50%
100        98.76           2.30%

4. 最佳并发数分析
  最高 QPS: 并发数=100, QPS=1456.78
  最低 P95延迟: 并发数=1, 延迟=25.67ms
  最佳综合性能: 并发数=20, 评分=13.98

5. 性能拐点分析
  ⚠️ 性能拐点: 并发数从 20 增加到 50
     QPS 提升仅 49.9%，但延迟增加 146.6%

✅ 图表已保存到: concurrent_test_results.png
✅ 结果已保存到: concurrent_test_results.json

=== 清理资源 ===
✅ 清理完成
```

---

## 关键发现

### 1. QPS 与并发数的关系

```python
# 线性增长阶段（1-20并发）
并发1: QPS = 54
并发5: QPS = 246 (4.5x)
并发10: QPS = 457 (8.4x)
并发20: QPS = 823 (15.2x)

# 增长放缓阶段（20-100并发）
并发50: QPS = 1235 (22.8x)
并发100: QPS = 1457 (26.9x)

# 结论：20并发后，QPS增长放缓，出现性能瓶颈
```

### 2. 延迟与并发数的关系

```python
# 延迟稳定阶段（1-10并发）
并发1: P95 = 26ms
并发5: P95 = 28ms (+10%)
并发10: P95 = 36ms (+39%)

# 延迟快速增长阶段（10-100并发）
并发20: P95 = 59ms (+130%)
并发50: P95 = 145ms (+466%)
并发100: P95 = 320ms (+1148%)

# 结论：10并发后，延迟快速增长
```

### 3. 最佳并发数

```python
# 综合评分 = QPS / P95延迟

并发1: 评分 = 54 / 26 = 2.08
并发5: 评分 = 246 / 28 = 8.79
并发10: 评分 = 457 / 36 = 12.69
并发20: 评分 = 823 / 59 = 13.95  # 最佳
并发50: 评分 = 1235 / 145 = 8.52
并发100: 评分 = 1457 / 320 = 4.55

# 结论：20并发是最佳选择
```

---

## 性能瓶颈分析

### 1. CPU 瓶颈

```python
# 如果 QPS 不再增长，可能是 CPU 瓶颈
if QPS增长 < 10% and 并发增加 > 2x:
    print("CPU 瓶颈")
    建议 = [
        "使用更高效的索引类型",
        "减少 ef/nprobe 值",
        "增加 CPU 核心数"
    ]
```

### 2. 内存瓶颈

```python
# 如果延迟剧增，可能是内存瓶颈
if P95延迟增长 > 100% and 并发增加 < 2x:
    print("内存瓶颈")
    建议 = [
        "使用量化索引",
        "增加内存容量",
        "使用分区减少加载数据量"
    ]
```

### 3. 连接池瓶颈

```python
# 如果失败率增加，可能是连接池瓶颈
if 失败率 > 1%:
    print("连接池瓶颈")
    建议 = [
        "增加连接池大小",
        "优化连接管理",
        "使用连接复用"
    ]
```

---

## 在 RAG 开发中的应用

### 场景1：选择合适的并发数

```python
# 业务需求
预期QPS = 1000
预期P95延迟 < 100ms

# 测试结果
并发20: QPS=823, P95=59ms  # 不满足QPS要求
并发50: QPS=1235, P95=145ms  # 不满足延迟要求

# 解决方案
方案1: 使用2台服务器，每台并发20（QPS=1646, P95=59ms）✅
方案2: 优化索引参数，降低延迟
```

### 场景2：容量规划

```python
# 单机性能
最佳并发 = 20
单机QPS = 823

# 业务需求
预期QPS = 10000

# 容量规划
需要机器数 = 10000 / 823 = 13台
考虑冗余（2倍）= 26台
```

### 场景3：性能优化验证

```python
# 优化前
并发20: QPS=823, P95=59ms

# 优化后（调整 ef 从 64 到 32）
并发20: QPS=1234, P95=35ms

# 提升
QPS 提升 = 50%
延迟降低 = 41%
```

---

## 关键洞察

1. **并发不是越高越好**
   - 存在最佳并发数
   - 超过最佳值，延迟剧增

2. **性能拐点很重要**
   - 找到性能拐点
   - 避免过度并发

3. **综合评分更科学**
   - QPS / P95延迟
   - 平衡吞吐量和延迟

4. **失败率是预警信号**
   - 失败率增加说明系统过载
   - 需要降低并发或扩容

5. **线程池大小要合理**
   - 过小：无法充分利用资源
   - 过大：上下文切换开销大

---

## 下一步

完成并发测试后，可以进行：
- **场景4：RAG场景测试** - 测试端到端 RAG 系统性能
- **化骨绵掌** - 10个2分钟知识卡片巩固理解
