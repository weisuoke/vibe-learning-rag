# 09_化骨绵掌

## 知识卡片1：ReRank的本质

**一句话：** ReRank是RAG的二轮面试官，用Cross-Encoder深度评估候选文档，把真正相关的排到前面。

**记忆点：**
- 初检 = 简历筛选（快速粗筛）
- ReRank = 技术面试（深度评估）
- LLM = CEO面试（最终决策）

**应用场景：** 所有需要高精度排序的RAG系统

---

## 知识卡片2：Cross-Encoder vs Bi-Encoder

**一句话：** Cross-Encoder联合编码query+doc，Bi-Encoder分别编码。

**对比表：**
| 维度 | Bi-Encoder | Cross-Encoder |
|------|-----------|--------------|
| 编码方式 | 分别编码 | 联合编码 |
| 交互深度 | 无交互 | 深度注意力 |
| 精度 | 中等 | 高（+15-48%） |
| 延迟 | 10-50ms | 200ms-2s |
| 适用 | 初检 | 精排 |

**记忆点：** Cross = 交叉 = 深度交互

---

## 知识卡片3：候选集大小50-75

**一句话：** 候选集50-75是最佳平衡点，超过后边际收益递减。

**数据支撑：**
- 50候选：召回率90%，NDCG@10 = 0.85
- 75候选：召回率93%，NDCG@10 = 0.87
- 100候选：召回率95%，NDCG@10 = 0.87（不再提升）

**记忆点：** 50-75 = 黄金区间

---

## 知识卡片4：NDCG@10是金标准

**一句话：** NDCG@10同时考虑位置和相关性，是排序质量的金标准。

**公式：**
```
DCG@K = Σ(rel_i / log2(i+1))
NDCG@K = DCG@K / IDCG@K
```

**记忆点：**
- 位置越靠前，权重越高（log2折损）
- 归一化到[0,1]，便于比较

---

## 知识卡片5：主流Reranker选择

**一句话：** Cohere最准，BGE最划算，ZeroEntropy最快。

**决策树：**
```
有预算限制？
├─ 是 → BGE reranker-v2-m3（开源，$0.025/M）
└─ 否 → 需要极致性能？
    ├─ 是 → ZeroEntropy zerank-1（60ms延迟）
    └─ 否 → Cohere Rerank 4（最高精度0.90）
```

**记忆点：** 生产环境首选BGE

---

## 知识卡片6：成本对比

**一句话：** Cross-Encoder比LLM reranking便宜60倍，快12倍。

**数据对比：**
| 方法 | 成本/M tokens | 延迟（50文档） | NDCG@10 |
|------|--------------|---------------|---------|
| Cross-Encoder | $0.025 | 200ms | 0.85 |
| LLM Pointwise | $0.50 | 2500ms | 0.89 |
| LLM Listwise | $1.00 | 3000ms | 0.92 |

**记忆点：** LLM精度仅高5%，成本高60倍

---

## 知识卡片7：两阶段策略必然性

**一句话：** 全量ReRank延迟3分钟，成本$1000/query，商业不可行。

**计算：**
```
100万文档 × 0.2ms = 200秒 = 3.3分钟
100万文档 × $0.001 = $1000/query

两阶段策略：
初检50ms + ReRank 200ms = 250ms ✅
成本$0.0001 + $0.001 = $0.0011 ✅
```

**记忆点：** 两阶段降低成本和延迟99.9%

---

## 知识卡片8：批处理加速5倍

**一句话：** 批处理比逐个处理快5倍。

**代码对比：**
```python
# 逐个处理：50文档 × 20ms = 1000ms
for doc in candidates:
    score = reranker.predict([(query, doc)])

# 批处理：200ms（5倍加速）
scores = reranker.predict(
    [(query, doc) for doc in candidates],
    batch_size=16
)
```

**记忆点：** 批处理batch_size=16最佳

---

## 知识卡片9：语义缓存降低成本68.8%

**一句话：** Redis语义缓存降低重复请求成本68.8%。

**实现：**
```python
# 检查缓存
cache_key = hash(query)
if cache_key in redis_cache:
    return redis_cache[cache_key]

# 执行ReRank
results = reranker.rerank(query, candidates)

# 缓存结果（TTL 1小时）
redis_cache.setex(cache_key, 3600, results)
```

**记忆点：** 缓存命中率60-80%

---

## 知识卡片10：生产架构三阶段

**一句话：** BM25 + 向量 + RRF + ReRank = 标准生产架构。

**流程图：**
```
BM25初检（10ms）
    ↓
向量检索（50ms）
    ↓
RRF融合（5ms）
    ↓
Cross-Encoder ReRank（200ms）
    ↓
LLM生成（1s）
---
总计：1.3秒 ✅
```

**记忆点：** 端到端延迟<2秒

---

## 快速复习清单

### 核心概念（5个）
- [ ] ReRank = 二轮面试官
- [ ] Cross-Encoder = 联合编码 + 深度交互
- [ ] 候选集50-75 = 最佳平衡点
- [ ] NDCG@10 = 排序质量金标准
- [ ] 两阶段策略 = 必然选择

### 技术细节（5个）
- [ ] Bi-Encoder vs Cross-Encoder区别
- [ ] NDCG公式：DCG / IDCG
- [ ] 批处理加速5倍
- [ ] 语义缓存降低成本68.8%
- [ ] 生产架构三阶段管道

### 实战经验（5个）
- [ ] BGE reranker-v2-m3 = 生产首选
- [ ] Cohere Rerank 4 = 最高精度
- [ ] ZeroEntropy zerank-1 = 最快延迟
- [ ] LLM reranking = 成本高60倍，不推荐
- [ ] 端到端延迟目标<2秒

### 常见误区（5个）
- [ ] ❌ 候选集越大越好 → ✅ 50-75最佳
- [ ] ❌ LLM reranking更准 → ✅ 精度仅高5%，成本高60倍
- [ ] ❌ ReRank能召回遗漏文档 → ✅ 只能重排序
- [ ] ❌ 分数可设全局阈值 → ✅ 分数是相对的
- [ ] ❌ 模型越大越好 → ✅ 中等大小最佳平衡

### 性能指标（5个）
- [ ] NDCG@10目标：>0.85
- [ ] P95延迟目标：<500ms
- [ ] 成本目标：<$0.05/M tokens
- [ ] 召回率目标：>90%
- [ ] 精度提升：15-48%

---

## 一分钟速记口诀

**ReRank口诀：**
```
二轮面试选人才（ReRank = 二轮面试）
Cross深度看本质（Cross-Encoder深度交互）
五十七五最平衡（候选集50-75）
NDCG金标看排序（NDCG@10金标准）
BGE开源最划算（BGE生产首选）
批处理缓存降成本（批处理+缓存优化）
两阶段策略是必然（初检+精排）
端到端两秒内（延迟<2秒）
```

---

## 面试速答模板

**Q: 什么是ReRank？**
A: ReRank是RAG的二次精排模块，使用Cross-Encoder对初检返回的候选文档进行深度语义评分和重新排序，NDCG@10提升15-48%。

**Q: 为什么需要ReRank？**
A: 初检（BM25/向量检索）速度快但精度有限，全量深度评估成本和延迟不可接受，两阶段策略是平衡成本、延迟、精度的最优解。

**Q: Cross-Encoder和Bi-Encoder的区别？**
A: Bi-Encoder分别编码query和doc，无交互；Cross-Encoder联合编码，深度Transformer注意力，精度高15-48%，但延迟高10-20倍。

**Q: 候选集大小如何选择？**
A: 50-75是最佳平衡点，召回率90-93%，NDCG@10达0.85-0.87，超过后边际收益递减。

**Q: 主流Reranker如何选择？**
A: 生产环境推荐BGE reranker-v2-m3（开源，成本低，精度0.85）；企业级推荐Cohere Rerank 4（最高精度0.90）；性能优先推荐ZeroEntropy zerank-1（延迟60ms）。

---

## 参考资料

- [Cross-Encoder Reranking Improves RAG Accuracy by 40%](https://app.ailog.fr/en/blog/news/reranking-cross-encoders-study) - MIT, 2026
- [Databricks Reranking Research](https://www.databricks.com/blog/reranking-mosaic-ai-vector-search-faster-smarter-retrieval-rag-agents)
- [Ultimate Guide to Choosing the Best Reranking Model in 2026](https://www.zeroentropy.dev/articles/ultimate-guide-to-choosing-the-best-reranking-model-in-2025)

---

**版本：** v1.0 (2026年标准)
**最后更新：** 2026-02-16
