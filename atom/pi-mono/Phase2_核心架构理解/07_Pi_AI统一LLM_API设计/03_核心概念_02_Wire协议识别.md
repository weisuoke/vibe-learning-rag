# 核心概念2：Wire 协议识别

> 理解如何自动识别和适配不同 LLM Provider 的通信协议

---

## 概念定义

**Wire 协议识别**是指自动检测和适配不同 LLM Provider 使用的通信协议格式，使系统能够无缝切换不同的 API 规范而无需手动配置。

**核心价值：**
- **自动适配**：无需手动指定协议类型
- **降低配置**：减少用户配置负担
- **提高兼容性**：支持更多 Provider
- **简化集成**：新 Provider 自动识别协议

---

## 第一性原理

### 问题的本质

**核心问题：** 不同 LLM Provider 使用不同的 API 协议，如何自动识别？

**4 种主流 Wire 协议：**

1. **OpenAI 协议**
   - 使用者：OpenAI、Azure OpenAI、Together AI、Groq
   - 特点：`/v1/chat/completions` 端点
   - 消息格式：`{ role, content }`

2. **Anthropic 协议**
   - 使用者：Anthropic Claude
   - 特点：`/v1/messages` 端点
   - 消息格式：`{ role, content: [{ type, text }] }`

3. **Google 协议**
   - 使用者：Google Gemini
   - 特点：`/v1beta/models/{model}:generateContent` 端点
   - 消息格式：`{ parts: [{ text }] }`

4. **Ollama 协议**
   - 使用者：Ollama（本地模型）
   - 特点：`/api/chat` 端点
   - 消息格式：`{ role, content }`（类似 OpenAI 但有差异）

### 识别策略

**方法1：基于 Provider 名称**
```typescript
function detectProtocol(provider: string): WireProtocol {
  if (provider === 'openai' || provider === 'azure' || provider === 'groq') {
    return 'openai';
  } else if (provider === 'anthropic') {
    return 'anthropic';
  } else if (provider === 'google') {
    return 'google';
  } else if (provider === 'ollama') {
    return 'ollama';
  }
  throw new Error(`Unknown provider: ${provider}`);
}
```

**方法2：基于 API 端点**
```typescript
function detectProtocolFromEndpoint(endpoint: string): WireProtocol {
  if (endpoint.includes('/chat/completions')) {
    return 'openai';
  } else if (endpoint.includes('/messages')) {
    return 'anthropic';
  } else if (endpoint.includes(':generateContent')) {
    return 'google';
  } else if (endpoint.includes('/api/chat')) {
    return 'ollama';
  }
  throw new Error(`Unknown endpoint: ${endpoint}`);
}
```

**方法3：基于响应格式**（运行时检测）
```typescript
function detectProtocolFromResponse(response: any): WireProtocol {
  if (response.choices && response.choices[0]?.message) {
    return 'openai';
  } else if (response.content && Array.isArray(response.content)) {
    return 'anthropic';
  } else if (response.candidates && response.candidates[0]?.content) {
    return 'google';
  }
  throw new Error('Unknown response format');
}
```

---

## 核心实现

### 1. Wire 协议类型定义

```typescript
/**
 * 支持的 Wire 协议类型
 */
type WireProtocol = 'openai' | 'anthropic' | 'google' | 'ollama';

/**
 * 协议配置
 */
interface ProtocolConfig {
  protocol: WireProtocol;
  endpoint: string;
  requestFormat: 'openai' | 'anthropic' | 'google' | 'ollama';
  responseFormat: 'openai' | 'anthropic' | 'google' | 'ollama';
  streamingSupport: boolean;
  toolCallingSupport: boolean;
}

/**
 * Provider 到协议的映射
 */
const PROVIDER_PROTOCOL_MAP: Record<string, WireProtocol> = {
  // OpenAI 协议
  'openai': 'openai',
  'azure': 'openai',
  'groq': 'openai',
  'together': 'openai',
  'deepseek': 'openai',
  'openrouter': 'openai',

  // Anthropic 协议
  'anthropic': 'anthropic',

  // Google 协议
  'google': 'google',
  'gemini': 'google',

  // Ollama 协议
  'ollama': 'ollama',
  'lmstudio': 'ollama'
};
```

### 2. 协议检测器

```typescript
/**
 * Wire 协议检测器
 */
class ProtocolDetector {
  /**
   * 基于 Provider 名称检测协议
   */
  detectByProvider(provider: string): WireProtocol {
    const protocol = PROVIDER_PROTOCOL_MAP[provider.toLowerCase()];
    if (!protocol) {
      throw new Error(`Unknown provider: ${provider}`);
    }
    return protocol;
  }

  /**
   * 基于 API 端点检测协议
   */
  detectByEndpoint(endpoint: string): WireProtocol {
    if (endpoint.includes('/chat/completions')) {
      return 'openai';
    } else if (endpoint.includes('/v1/messages')) {
      return 'anthropic';
    } else if (endpoint.includes(':generateContent')) {
      return 'google';
    } else if (endpoint.includes('/api/chat') || endpoint.includes('/api/generate')) {
      return 'ollama';
    }

    throw new Error(`Cannot detect protocol from endpoint: ${endpoint}`);
  }

  /**
   * 基于响应格式检测协议（运行时）
   */
  detectByResponse(response: any): WireProtocol {
    // OpenAI 格式
    if (response.choices && Array.isArray(response.choices)) {
      if (response.choices[0]?.message) {
        return 'openai';
      }
    }

    // Anthropic 格式
    if (response.content && Array.isArray(response.content)) {
      if (response.content[0]?.type === 'text') {
        return 'anthropic';
      }
    }

    // Google 格式
    if (response.candidates && Array.isArray(response.candidates)) {
      if (response.candidates[0]?.content?.parts) {
        return 'google';
      }
    }

    // Ollama 格式
    if (response.message && response.model) {
      return 'ollama';
    }

    throw new Error('Cannot detect protocol from response format');
  }

  /**
   * 综合检测（优先级：Provider > Endpoint > Response）
   */
  detect(options: {
    provider?: string;
    endpoint?: string;
    response?: any;
  }): WireProtocol {
    // 1. 优先使用 Provider 名称
    if (options.provider) {
      try {
        return this.detectByProvider(options.provider);
      } catch (error) {
        // 继续尝试其他方法
      }
    }

    // 2. 尝试使用 Endpoint
    if (options.endpoint) {
      try {
        return this.detectByEndpoint(options.endpoint);
      } catch (error) {
        // 继续尝试其他方法
      }
    }

    // 3. 最后尝试使用 Response
    if (options.response) {
      return this.detectByResponse(options.response);
    }

    throw new Error('Cannot detect protocol: insufficient information');
  }
}
```

### 3. 协议适配器工厂

```typescript
/**
 * 协议适配器工厂
 * 根据检测到的协议创建对应的适配器
 */
class ProtocolAdapterFactory {
  private detector = new ProtocolDetector();

  /**
   * 创建适配器
   */
  createAdapter(options: {
    provider?: string;
    endpoint?: string;
    apiKey: string;
  }): ProviderAdapter {
    // 1. 检测协议
    const protocol = this.detector.detect({
      provider: options.provider,
      endpoint: options.endpoint
    });

    // 2. 根据协议创建适配器
    switch (protocol) {
      case 'openai':
        return new OpenAIAdapter({
          apiKey: options.apiKey,
          baseURL: options.endpoint
        });

      case 'anthropic':
        return new AnthropicAdapter({
          apiKey: options.apiKey,
          baseURL: options.endpoint
        });

      case 'google':
        return new GoogleAdapter({
          apiKey: options.apiKey
        });

      case 'ollama':
        return new OllamaAdapter({
          baseURL: options.endpoint || 'http://localhost:11434'
        });

      default:
        throw new Error(`Unsupported protocol: ${protocol}`);
    }
  }
}
```

### 4. 协议转换器

```typescript
/**
 * 协议转换器
 * 在不同协议之间转换消息格式
 */
class ProtocolConverter {
  /**
   * 转换为目标协议格式
   */
  convert(
    message: Message,
    fromProtocol: WireProtocol,
    toProtocol: WireProtocol
  ): any {
    // 1. 先转换为统一格式（Pi AI 格式）
    const piMessage = this.toPiFormat(message, fromProtocol);

    // 2. 再转换为目标协议格式
    return this.fromPiFormat(piMessage, toProtocol);
  }

  /**
   * 转换为 Pi AI 统一格式
   */
  private toPiFormat(message: any, protocol: WireProtocol): Message {
    switch (protocol) {
      case 'openai':
        return {
          role: message.role,
          content: typeof message.content === 'string'
            ? message.content
            : message.content.map((block: any) => ({
                type: block.type === 'text' ? 'text' : 'image',
                text: block.text,
                source: block.image_url ? { url: block.image_url.url } : undefined
              }))
        };

      case 'anthropic':
        return {
          role: message.role,
          content: message.content.map((block: any) => ({
            type: block.type,
            text: block.text,
            source: block.source
          }))
        };

      case 'google':
        return {
          role: message.role === 'model' ? 'assistant' : 'user',
          content: message.parts.map((part: any) => ({
            type: 'text',
            text: part.text
          }))
        };

      case 'ollama':
        return {
          role: message.role,
          content: message.content
        };

      default:
        throw new Error(`Unsupported protocol: ${protocol}`);
    }
  }

  /**
   * 从 Pi AI 格式转换为目标协议格式
   */
  private fromPiFormat(message: Message, protocol: WireProtocol): any {
    switch (protocol) {
      case 'openai':
        return {
          role: message.role,
          content: typeof message.content === 'string'
            ? message.content
            : message.content.map(block => {
                if (block.type === 'text') {
                  return { type: 'text', text: block.text };
                } else if (block.type === 'image') {
                  return {
                    type: 'image_url',
                    image_url: { url: block.source.url }
                  };
                }
                return block;
              })
        };

      case 'anthropic':
        return {
          role: message.role,
          content: typeof message.content === 'string'
            ? [{ type: 'text', text: message.content }]
            : message.content.map(block => ({
                type: block.type,
                text: block.text,
                source: block.source
              }))
        };

      case 'google':
        return {
          role: message.role === 'assistant' ? 'model' : 'user',
          parts: typeof message.content === 'string'
            ? [{ text: message.content }]
            : message.content.map(block => ({ text: block.text }))
        };

      case 'ollama':
        return {
          role: message.role,
          content: typeof message.content === 'string'
            ? message.content
            : message.content.map(block => block.text).join('\n')
        };

      default:
        throw new Error(`Unsupported protocol: ${protocol}`);
    }
  }
}
```

---

## 在 AI Agent 中的应用

### 场景1：自动切换兼容 Provider

```typescript
/**
 * 自动选择兼容的 Provider
 * 如果主 Provider 不可用，自动切换到使用相同协议的备用 Provider
 */
class SmartProviderSelector {
  private factory = new ProtocolAdapterFactory();
  private detector = new ProtocolDetector();

  async selectProvider(
    preferredProvider: string,
    fallbackProviders: string[]
  ): Promise<ProviderAdapter> {
    // 1. 尝试主 Provider
    try {
      return this.factory.createAdapter({
        provider: preferredProvider,
        apiKey: process.env[`${preferredProvider.toUpperCase()}_API_KEY`]!
      });
    } catch (error) {
      console.error(`Primary provider ${preferredProvider} failed:`, error);
    }

    // 2. 检测主 Provider 的协议
    const primaryProtocol = this.detector.detectByProvider(preferredProvider);

    // 3. 查找使用相同协议的备用 Provider
    for (const fallback of fallbackProviders) {
      try {
        const fallbackProtocol = this.detector.detectByProvider(fallback);

        // 优先选择相同协议的 Provider（无需格式转换）
        if (fallbackProtocol === primaryProtocol) {
          console.log(`Switching to ${fallback} (same protocol: ${primaryProtocol})`);
          return this.factory.createAdapter({
            provider: fallback,
            apiKey: process.env[`${fallback.toUpperCase()}_API_KEY`]!
          });
        }
      } catch (error) {
        continue;
      }
    }

    // 4. 如果没有相同协议的，选择任意可用的
    for (const fallback of fallbackProviders) {
      try {
        console.log(`Switching to ${fallback} (different protocol)`);
        return this.factory.createAdapter({
          provider: fallback,
          apiKey: process.env[`${fallback.toUpperCase()}_API_KEY`]!
        });
      } catch (error) {
        continue;
      }
    }

    throw new Error('All providers failed');
  }
}

// 使用示例
const selector = new SmartProviderSelector();
const adapter = await selector.selectProvider('openai', ['groq', 'together', 'anthropic']);
```

### 场景2：自定义 Provider 自动识别

```typescript
/**
 * 支持自定义 Provider（如企业内部 LLM）
 * 自动识别其使用的协议
 */
async function addCustomProvider(config: {
  name: string;
  endpoint: string;
  apiKey: string;
}): Promise<ProviderAdapter> {
  const factory = new ProtocolAdapterFactory();

  // 1. 尝试通过端点检测协议
  try {
    return factory.createAdapter({
      endpoint: config.endpoint,
      apiKey: config.apiKey
    });
  } catch (error) {
    console.error('Cannot detect protocol from endpoint');
  }

  // 2. 发送测试请求，通过响应检测协议
  const testResponse = await fetch(`${config.endpoint}/v1/models`, {
    headers: { 'Authorization': `Bearer ${config.apiKey}` }
  });

  const detector = new ProtocolDetector();
  const protocol = detector.detectByResponse(await testResponse.json());

  console.log(`Detected protocol: ${protocol}`);

  // 3. 创建适配器
  return factory.createAdapter({
    provider: protocol,  // 使用检测到的协议
    endpoint: config.endpoint,
    apiKey: config.apiKey
  });
}

// 使用示例
const customAdapter = await addCustomProvider({
  name: 'my-company-llm',
  endpoint: 'https://llm.mycompany.com',
  apiKey: process.env.COMPANY_API_KEY!
});
```

### 场景3：协议兼容性检查

```typescript
/**
 * 检查 Provider 是否支持特定功能
 * 基于协议类型判断
 */
class ProtocolCapabilityChecker {
  private detector = new ProtocolDetector();

  /**
   * 检查是否支持工具调用
   */
  supportsToolCalling(provider: string): boolean {
    const protocol = this.detector.detectByProvider(provider);

    switch (protocol) {
      case 'openai':
      case 'anthropic':
        return true;  // 支持工具调用

      case 'google':
        return true;  // Gemini 支持 function calling

      case 'ollama':
        return false;  // Ollama 不支持工具调用

      default:
        return false;
    }
  }

  /**
   * 检查是否支持流式响应
   */
  supportsStreaming(provider: string): boolean {
    const protocol = this.detector.detectByProvider(provider);

    // 所有主流协议都支持流式响应
    return ['openai', 'anthropic', 'google', 'ollama'].includes(protocol);
  }

  /**
   * 检查是否支持多模态（图片输入）
   */
  supportsVision(provider: string): boolean {
    const protocol = this.detector.detectByProvider(provider);

    switch (protocol) {
      case 'openai':
        return true;  // GPT-4 Vision

      case 'anthropic':
        return true;  // Claude 3 支持图片

      case 'google':
        return true;  // Gemini 支持多模态

      case 'ollama':
        return false;  // 大多数本地模型不支持

      default:
        return false;
    }
  }
}

// 使用示例
const checker = new ProtocolCapabilityChecker();

if (checker.supportsToolCalling('openai')) {
  console.log('OpenAI supports tool calling');
}

if (!checker.supportsVision('ollama')) {
  console.log('Ollama does not support vision, falling back to text-only');
}
```

---

## 协议对比

### 请求格式对比

| 协议 | 端点 | 消息格式 | 工具调用 |
|------|------|---------|---------|
| **OpenAI** | `/v1/chat/completions` | `{ role, content }` | `tools: [{ type: 'function', function: {...} }]` |
| **Anthropic** | `/v1/messages` | `{ role, content: [{ type, text }] }` | `tools: [{ name, description, input_schema }]` |
| **Google** | `/{model}:generateContent` | `{ parts: [{ text }] }` | `tools: [{ functionDeclarations: [...] }]` |
| **Ollama** | `/api/chat` | `{ role, content }` | 不支持 |

### 响应格式对比

| 协议 | 响应结构 | Token 统计 | 流式事件 |
|------|---------|-----------|---------|
| **OpenAI** | `{ choices: [{ message }] }` | `usage: { prompt_tokens, completion_tokens }` | `data: {...}\n\n` |
| **Anthropic** | `{ content: [{ type, text }] }` | `usage: { input_tokens, output_tokens }` | `event: content_block_delta\ndata: {...}\n\n` |
| **Google** | `{ candidates: [{ content }] }` | `usageMetadata: { promptTokenCount, candidatesTokenCount }` | JSON 流 |
| **Ollama** | `{ message: { role, content } }` | 不提供 | JSON 流 |

---

## 实际案例（2025-2026）

### 案例1：Vercel AI SDK 的协议检测

**背景：** Vercel AI SDK 支持 10+ Provider，自动检测协议

**实现：**
```typescript
import { createOpenAI } from '@ai-sdk/openai';
import { createAnthropic } from '@ai-sdk/anthropic';

// 自动检测 OpenAI 兼容的 Provider
const groq = createOpenAI({
  baseURL: 'https://api.groq.com/openai/v1',
  apiKey: process.env.GROQ_API_KEY
});

const together = createOpenAI({
  baseURL: 'https://api.together.xyz/v1',
  apiKey: process.env.TOGETHER_API_KEY
});
```

**特点：**
- 基于端点自动检测协议
- 支持 OpenAI 兼容的 Provider
- 无需手动配置协议类型

**来源：** [Vercel AI SDK Docs](https://sdk.vercel.ai/docs/providers) (2026-01-20)

---

### 案例2：LiteLLM 的统一协议

**背景：** LiteLLM (Python) 支持 100+ Provider，统一为 OpenAI 协议

**实现：**
```python
import litellm

# 所有 Provider 都使用 OpenAI 格式
response = litellm.completion(
    model="gpt-4",  # OpenAI
    messages=[{"role": "user", "content": "Hello"}]
)

response = litellm.completion(
    model="claude-3-opus",  # Anthropic
    messages=[{"role": "user", "content": "Hello"}]  # 相同格式
)

response = litellm.completion(
    model="gemini-pro",  # Google
    messages=[{"role": "user", "content": "Hello"}]  # 相同格式
)
```

**特点：**
- 所有 Provider 统一为 OpenAI 协议
- 自动处理协议转换
- 支持 100+ Provider

**来源：** [LiteLLM Docs](https://docs.litellm.ai/) (2026-02-15)

---

### 案例3：OpenRouter 的协议代理

**背景：** OpenRouter 提供统一的 OpenAI 兼容接口，代理 50+ Provider

**实现：**
```typescript
import OpenAI from 'openai';

const openrouter = new OpenAI({
  baseURL: 'https://openrouter.ai/api/v1',
  apiKey: process.env.OPENROUTER_API_KEY
});

// 使用 OpenAI 格式调用任意模型
const response = await openrouter.chat.completions.create({
  model: 'anthropic/claude-3-opus',  // Anthropic 模型
  messages: [{ role: 'user', content: 'Hello' }]  // OpenAI 格式
});
```

**特点：**
- 统一的 OpenAI 协议接口
- 支持 50+ Provider 的模型
- 自动处理协议转换

**来源：** [OpenRouter Docs](https://openrouter.ai/docs) (2026-02-10)

---

## 设计权衡

### 优点

1. **自动化**
   - 无需手动配置协议类型
   - 降低用户配置负担

2. **兼容性**
   - 支持更多 Provider
   - 自动识别自定义 Provider

3. **灵活性**
   - 可以在运行时切换协议
   - 支持协议转换

### 缺点

1. **检测失败**
   - 某些自定义 Provider 可能无法识别
   - 需要提供手动指定协议的选项

2. **维护成本**
   - 新协议需要添加检测逻辑
   - 协议变更需要更新检测器

3. **性能开销**
   - 协议检测有轻微开销
   - 但远小于网络延迟

---

## 学习检查清单

完成本概念学习后，你应该能够：

- [ ] 理解 4 种主流 Wire 协议的差异
- [ ] 理解协议检测的 3 种方法
- [ ] 能够实现协议检测器
- [ ] 能够实现协议转换器
- [ ] 理解协议适配器工厂模式
- [ ] 能够添加自定义 Provider 支持
- [ ] 能够检查协议兼容性
- [ ] 理解设计权衡

---

## 参考资源

### 官方文档
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference) - OpenAI 协议
- [Anthropic API Reference](https://docs.anthropic.com/claude/reference) - Anthropic 协议
- [Google AI API](https://ai.google.dev/api) - Google 协议
- [Ollama API](https://github.com/ollama/ollama/blob/main/docs/api.md) - Ollama 协议

### 相关项目
- [Vercel AI SDK](https://sdk.vercel.ai/) - TypeScript 多协议支持
- [LiteLLM](https://docs.litellm.ai/) - Python 统一协议
- [OpenRouter](https://openrouter.ai/) - 协议代理服务

### 行业实践
- [Unified LLM Spec](https://github.com/strongdm/attractor/blob/main/unified-llm-spec.md) - 统一协议规范 (2026-02-09)

---

**版本：** v1.0
**最后更新：** 2026-02-19
