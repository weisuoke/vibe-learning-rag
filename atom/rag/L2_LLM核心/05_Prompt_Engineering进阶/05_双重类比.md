# 双重类比：Prompt Engineering进阶

## 类比1：前端开发视角

### Few-shot Learning = 组件示例库

**前端场景：**

```javascript
// 没有示例：开发者不知道如何使用组件
<Button />  // 怎么用？什么属性？

// 有示例：清晰明了
// 示例1：基础用法
<Button text="提交" onClick={handleSubmit} />

// 示例2：带图标
<Button text="删除" icon="trash" variant="danger" />

// 现在你知道怎么用了
<Button text="保存" icon="save" variant="primary" />
```

**Prompt类比：**

```python
# 没有示例：模型不知道输出格式
prompt = "提取姓名和年龄"
# 输出：可能是"姓名：张三，年龄：30"

# 有示例：格式统一
prompt = """
示例1：
输入：李四，25岁
输出：{"name": "李四", "age": 25}

示例2：
输入：王五，35岁
输出：{"name": "王五", "age": 35}

现在处理：
输入：张三，30岁
输出：
"""
# 输出：{"name": "张三", "age": 30}
```

---

### Chain-of-Thought = 调试日志

**前端场景：**

```javascript
// 没有日志：出错了不知道哪里错
function processData(data) {
    const result = transform(data);
    return result;  // 如果错了，不知道是哪一步
}

// 有日志：每一步都可见
function processData(data) {
    console.log('1. 原始数据:', data);
    const validated = validate(data);
    console.log('2. 验证后:', validated);
    const transformed = transform(validated);
    console.log('3. 转换后:', transformed);
    return transformed;
}
```

**Prompt类比：**

```python
# 没有推理过程：出错了不知道哪里错
prompt = "23 * 47 = ?"
# 输出：1081（可能错，无法验证）

# 有推理过程：每一步都可见
prompt = """
计算 23 * 47

让我们一步步计算：
1. 23 * 40 = 920
2. 23 * 7 = 161
3. 920 + 161 = 1081
"""
# 可以验证每一步
```

---

### Self-Consistency = A/B测试

**前端场景：**

```javascript
// 单次测试：不可靠
const result = testFeature();  // 可能偶然成功或失败

// 多次测试：更可靠
const results = [];
for (let i = 0; i < 10; i++) {
    results.push(testFeature());
}
const successRate = results.filter(r => r.success).length / 10;
// 成功率80%，更可信
```

**Prompt类比：**

```python
# 单次生成：不可靠
answer = llm.generate(prompt)

# 多次生成投票：更可靠
answers = []
for i in range(5):
    answers.append(llm.generate(prompt, temperature=0.7))
final_answer = most_common(answers)  # 投票选择
```

---

### Tree of Thoughts = 路由策略

**前端场景：**

```javascript
// 单一路由：只有一条路径
/api/data → 直接查询数据库

// 多策略路由：探索多条路径
/api/data → 策略1：查缓存
         → 策略2：查数据库
         → 策略3：查备份
         → 选择最快的
```

**Prompt类比：**

```python
# 单一推理：只有一条路径
answer = llm.generate(prompt)

# 多路径探索：尝试多种方法
strategies = [
    "直接回答",
    "先分析再回答",
    "先举例再回答"
]
results = [llm.generate(prompt, strategy=s) for s in strategies]
best_answer = evaluate_and_select(results)
```

---

### ReAct = API轮询

**前端场景：**

```javascript
// 静态请求：一次性获取
const data = await fetch('/api/data');
// 如果数据不完整，无法补救

// 动态轮询：根据响应决定下一步
let data = await fetch('/api/data');
while (!data.complete) {
    // 根据当前数据决定下一步
    const nextEndpoint = determineNext(data);
    const moreData = await fetch(nextEndpoint);
    data = merge(data, moreData);
}
```

**Prompt类比：**

```python
# 静态RAG：一次性检索
docs = retriever.search(query)
answer = llm.generate(f"文档：{docs}\n问题：{query}")

# 动态RAG (ReAct)：根据推理决定是否继续检索
context = retriever.search(query)
while not is_sufficient(context):
    thought = llm.generate(f"当前信息：{context}\n还需要什么？")
    new_docs = retriever.search(extract_need(thought))
    context += new_docs
answer = llm.generate(f"完整信息：{context}\n问题：{query}")
```

---

### Structured Output = TypeScript类型

**前端场景：**

```typescript
// JavaScript：没有类型约束
function getUser(id) {
    return fetch(`/api/user/${id}`);
}
// 返回什么？不知道，可能是对象、可能是null

// TypeScript：类型约束
interface User {
    name: string;
    age: number;
    email: string;
}

function getUser(id: string): Promise<User> {
    return fetch(`/api/user/${id}`).then(r => r.json());
}
// 返回什么？明确是User类型
```

**Prompt类比：**

```python
# 自然语言输出：没有约束
response = llm.generate("提取用户信息")
# 输出："用户叫张三，30岁"（难以解析）

# Structured Output：类型约束
response = llm.generate(
    "提取用户信息",
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "user",
            "schema": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "age": {"type": "number"}
                }
            }
        }
    }
)
# 输出：{"name": "张三", "age": 30}（易于解析）
```

---

### Query Decomposition = 微服务拆分

**前端场景：**

```javascript
// 单体请求：一个接口做所有事
GET /api/complex-data
// 返回用户信息、订单、评论...（慢、难维护）

// 微服务拆分：拆分为多个小请求
const user = await fetch('/api/user');
const orders = await fetch('/api/orders');
const comments = await fetch('/api/comments');
// 并行请求，更快、更灵活
```

**Prompt类比：**

```python
# 复杂查询：一次性处理
query = "比较Python和JavaScript在异步编程、类型系统、性能方面的差异"
answer = llm.generate(query)  # 可能答不全

# 查询分解：拆分为子查询
sub_queries = [
    "Python的异步编程机制",
    "JavaScript的异步编程机制",
    "Python的类型系统",
    "JavaScript的类型系统",
    "Python的性能特点",
    "JavaScript的性能特点"
]
results = [llm.generate(q) for q in sub_queries]
final_answer = synthesize(results)  # 综合答案
```

---

### RAT = 懒加载

**前端场景：**

```javascript
// 一次性加载：加载所有数据
const allData = await fetch('/api/all-data');  // 慢

// 懒加载：按需加载
let data = await fetch('/api/initial-data');
if (needMore(data)) {
    const moreData = await fetch('/api/more-data');
    data = merge(data, moreData);
}
```

**Prompt类比：**

```python
# 静态RAG：一次性检索
docs = retriever.search(query, top_k=10)
answer = llm.generate(f"文档：{docs}\n问题：{query}")

# RAT：按需迭代检索
context = retriever.search(query, top_k=3)
for iteration in range(3):
    answer = llm.generate(f"信息：{context}\n问题：{query}")
    if is_sufficient(answer):
        break
    # 根据当前答案决定需要什么信息
    need = extract_need(answer)
    new_docs = retriever.search(need)
    context += new_docs
```

---

### Meta Prompting = 代码生成器

**前端场景：**

```javascript
// 手写代码：每次都要写
function createButton(text, onClick) {
    return `<button onclick="${onClick}">${text}</button>`;
}

// 代码生成器：生成代码的代码
function generateComponent(type, props) {
    const template = getTemplate(type);
    return template.replace('{props}', JSON.stringify(props));
}
```

**Prompt类比：**

```python
# 手写提示词：每次都要写
prompt = "你是一个专家，请分析..."

# Meta Prompting：让模型生成提示词
meta_prompt = f"""
任务：{task}
目标：{goal}

请生成一个最优的提示词来完成这个任务。
"""
generated_prompt = llm.generate(meta_prompt)
final_answer = llm.generate(generated_prompt)
```

---

### Active Prompting = 智能推荐

**前端场景：**

```javascript
// 固定推荐：所有用户看到相同内容
const recommendations = getTopProducts();

// 智能推荐：根据用户行为推荐
const userHistory = getUserHistory(userId);
const recommendations = getRecommendations(userHistory);
// 每个用户看到不同的推荐
```

**Prompt类比：**

```python
# 固定示例：所有查询用相同示例
examples = [example1, example2, example3]
prompt = build_prompt(examples, query)

# 动态示例：根据查询选择最相关示例
similarities = [compute_sim(query, ex) for ex in example_pool]
top_examples = select_top_k(similarities, k=3)
prompt = build_prompt(top_examples, query)
```

---

## 类比2：日常生活视角

### Few-shot Learning = 学做菜看菜谱

**场景：**

```
没有菜谱：
"做一道红烧肉"
→ 不知道步骤、调料、火候

有菜谱（示例）：
示例1：红烧排骨
1. 排骨焯水
2. 炒糖色
3. 加调料炖煮

示例2：红烧鱼
1. 鱼煎至两面金黄
2. 加调料
3. 小火炖煮

现在做：红烧肉
→ 知道了：先处理食材、炒糖色、加调料炖煮
```

---

### Chain-of-Thought = 数学考试写步骤

**场景：**

```
不写步骤：
23 × 47 = 1081
→ 老师不知道你是怎么算的，可能是蒙的

写步骤：
23 × 47
= 23 × (40 + 7)
= 23 × 40 + 23 × 7
= 920 + 161
= 1081
→ 老师看到推理过程，知道你真的会
```

---

### Self-Consistency = 多人投票

**场景：**

```
一个人决定：
"这家餐厅好吃吗？"
张三说：好吃
→ 可能是个人口味

多人投票：
张三：好吃
李四：好吃
王五：一般
赵六：好吃
钱七：好吃
→ 5个人中4个说好吃，更可信
```

---

### Tree of Thoughts = 旅游规划

**场景：**

```
单一路线：
北京 → 上海 → 杭州
→ 如果上海天气不好，整个计划泡汤

多路线探索：
方案A：北京 → 上海 → 杭州
方案B：北京 → 西安 → 成都
方案C：北京 → 青岛 → 南京
→ 评估每个方案（天气、价格、景点）
→ 选择最优方案
```

---

### ReAct = 问路

**场景：**

```
一次性问路：
"请问去火车站怎么走？"
"直走500米，左转，再走300米"
→ 如果中途迷路了，不知道怎么办

边走边问（ReAct）：
1. 问："去火车站怎么走？"
   答："直走到红绿灯"
   行动：走到红绿灯

2. 问："到红绿灯了，下一步？"
   答："左转走到超市"
   行动：左转走到超市

3. 问："到超市了，下一步？"
   答："火车站就在前面"
   行动：到达火车站
```

---

### Structured Output = 填表格

**场景：**

```
自由描述：
"我叫张三，30岁，住在北京，是工程师"
→ 信息混在一起，难以整理

填表格：
姓名：张三
年龄：30
城市：北京
职业：工程师
→ 结构清晰，易于处理
```

---

### Query Decomposition = 大扫除分工

**场景：**

```
一个人做所有事：
"打扫整个房子"
→ 累、慢、可能做不完

分工合作：
张三：打扫客厅
李四：打扫卧室
王五：打扫厨房
赵六：打扫卫生间
→ 并行工作，更快完成
```

---

### RAT = 查资料写论文

**场景：**

```
一次性查资料：
去图书馆借10本书
→ 可能有些书不相关，浪费时间

边写边查（RAT）：
1. 先查基础资料，写第一稿
2. 发现缺少数据支撑，再查数据
3. 发现需要案例，再查案例
4. 逐步完善论文
→ 按需查资料，更高效
```

---

### Meta Prompting = 请教专家如何提问

**场景：**

```
直接提问：
"医生，我不舒服"
→ 医生不知道问什么

先问如何提问：
"医生，我想描述症状，应该说哪些信息？"
医生："说清楚哪里不舒服、什么时候开始、有什么症状"

然后按建议提问：
"我头痛，从昨天开始，伴有发烧"
→ 医生能更好地诊断
```

---

### Active Prompting = 智能推荐

**场景：**

```
固定推荐：
所有人都推荐同样的电影
→ 可能不符合你的口味

智能推荐：
根据你看过的电影推荐
你喜欢科幻片 → 推荐《星际穿越》
你喜欢爱情片 → 推荐《泰坦尼克号》
→ 更符合你的喜好
```

---

## 对照表

| 技术 | 前端类比 | 日常生活类比 | 核心相似点 |
|------|----------|--------------|-----------|
| Few-shot | 组件示例库 | 看菜谱学做菜 | 通过示例学习模式 |
| CoT | 调试日志 | 数学考试写步骤 | 展示推理过程 |
| Self-Consistency | A/B测试 | 多人投票 | 多次验证提升可靠性 |
| ToT | 路由策略 | 旅游规划 | 探索多条路径 |
| ReAct | API轮询 | 边走边问路 | 推理与行动交替 |
| Structured Output | TypeScript类型 | 填表格 | 结构化约束 |
| Query Decomposition | 微服务拆分 | 大扫除分工 | 复杂任务拆分 |
| RAT | 懒加载 | 边写边查资料 | 按需迭代获取信息 |
| Meta Prompting | 代码生成器 | 请教如何提问 | 生成生成器 |
| Active Prompting | 智能推荐 | 个性化推荐 | 动态选择最优 |

---

## 记忆口诀

```
Few-shot像菜谱，示例教你做
CoT像写步骤，推理要说清
Self-Consistency像投票，多次更可靠
ToT像旅游规划，多路径探索
ReAct像问路，边走边调整
Structured像表格，格式要统一
Query Decomposition像分工，任务要拆分
RAT像查资料，按需再补充
Meta像请教，先问怎么问
Active像推荐，动态选最优
```

---

## 参考资源

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Lakera AI Guide 2026](https://www.lakera.ai/blog/prompt-engineering-guide)

---

**下一步：** 阅读 `06_反直觉点.md` 了解常见误区
