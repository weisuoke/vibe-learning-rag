# 反直觉点

ReRank 最容易犯的 3 个错误，以及为什么人们容易这样错。

---

## 误区1：ReRank 分数越高，答案越正确 ❌

### 错误观点

"ReRank 分数 0.95 的文档，一定比 0.85 的更能回答问题"

### 为什么错？

**ReRank 衡量的是"相关性"，不是"正确性"**

```python
query = "地球是平的吗？"

documents = [
    "地球是平的，这是显而易见的事实",  # 相关但错误
    "地球是一个近似球体",              # 相关且正确
    "今天天气很好",                    # 不相关
]

# ReRank 可能给出的分数
scores = [0.92, 0.88, 0.05]

# 第一个文档分数最高，但内容是错的！
```

**关键区别：**

| 概念 | 含义 | ReRank 能判断吗？ |
|------|------|------------------|
| 相关性 | 文档是否在讨论这个话题 | ✅ 能 |
| 正确性 | 文档内容是否事实正确 | ❌ 不能 |
| 有用性 | 文档是否能帮助回答问题 | 部分能 |

### 为什么人们容易这样错？

1. **直觉混淆**：日常生活中，"相关"和"正确"经常同时出现
2. **分数误导**：高分给人"权威"的感觉
3. **过度信任模型**：认为 AI 模型能判断一切

### 正确理解

```python
# ReRank 只是检索优化的一环，不是事实核查
def rag_pipeline(query):
    # 1. 检索 + ReRank（找到相关文档）
    relevant_docs = retrieve_and_rerank(query)

    # 2. LLM 生成（需要 LLM 判断内容正确性）
    answer = llm.generate(query, relevant_docs)

    # 3. 可选：事实核查（额外的验证步骤）
    verified_answer = fact_check(answer, relevant_docs)

    return verified_answer
```

**记住：ReRank 提升的是"找到相关文档"的能力，不是"判断文档正确性"的能力。**

---

## 误区2：ReRank 候选越多越好 ❌

### 错误观点

"向量检索返回 1000 个候选，ReRank 后效果一定比 100 个好"

### 为什么错？

**候选太多会带来三个问题：**

#### 问题1：延迟急剧增加

```python
# Cross-Encoder 的时间复杂度是 O(N)
# N = 候选数量

# 100 个候选：~100ms
# 500 个候选：~500ms
# 1000 个候选：~1000ms（1秒！）

import time

def benchmark_rerank(reranker, query, candidates):
    start = time.time()
    pairs = [(query, doc) for doc in candidates]
    scores = reranker.predict(pairs)
    return time.time() - start

# 实测结果
# 100 candidates: 0.12s
# 500 candidates: 0.58s
# 1000 candidates: 1.15s
```

#### 问题2：噪声增加

```
候选数量增加，低质量文档也会增加：

Top 50：大部分是相关文档
Top 100：开始出现边缘相关的文档
Top 500：很多不相关的文档混入
Top 1000：噪声可能超过信号
```

#### 问题3：边际收益递减

```
召回率提升曲线：

Top 50:  召回率 85%
Top 100: 召回率 92%  (+7%)
Top 200: 召回率 95%  (+3%)
Top 500: 召回率 97%  (+2%)
Top 1000: 召回率 98% (+1%)

候选数量翻倍，召回率提升却越来越小
```

### 为什么人们容易这样错？

1. **"多多益善"心理**：直觉认为选择越多越好
2. **忽视成本**：只看效果，不看延迟和资源消耗
3. **过度优化**：追求 100% 召回率，忽视实际需求

### 正确理解

```python
# 最佳实践：根据场景选择候选数量

def get_optimal_top_n(scenario):
    """
    根据场景选择合适的候选数量
    """
    if scenario == "实时问答":
        return 50   # 延迟敏感，少一点
    elif scenario == "文档搜索":
        return 100  # 平衡选择
    elif scenario == "离线分析":
        return 200  # 可以多一点
    else:
        return 100  # 默认值

# 推荐范围：50-100，最多不超过 200
```

**记住：候选数量是速度和精度的权衡，不是越多越好。**

---

## 误区3：有了 ReRank 就不需要优化向量检索 ❌

### 错误观点

"反正有 ReRank 兜底，向量检索差一点也没关系"

### 为什么错？

**ReRank 只能重排，不能召回**

```
场景：用户问 "Python 异步编程"

向量检索返回的 Top 100：
- 60 篇关于 Python 基础的文档
- 30 篇关于 JavaScript 异步的文档
- 10 篇关于 Python 异步的文档（真正相关）

问题：真正相关的文档只有 10 篇！

ReRank 能做的：
- 把这 10 篇排到最前面 ✅

ReRank 不能做的：
- 召回更多关于 Python 异步的文档 ❌
- 如果 Top 100 里没有相关文档，ReRank 也无能为力 ❌
```

**关键公式：**

```
最终效果 = 召回质量 × 排序质量

如果召回质量 = 50%（漏掉一半相关文档）
即使排序质量 = 100%（完美排序）
最终效果 = 50%（仍然很差）
```

### 为什么人们容易这样错？

1. **过度依赖后处理**：认为后面的步骤能弥补前面的不足
2. **忽视召回率**：只关注精确率，忽视召回率
3. **系统思维缺失**：没有把 RAG 看作一个整体

### 正确理解

```python
# 正确的优化顺序

def optimize_rag_system():
    """
    RAG 系统优化的正确顺序
    """
    # 1. 首先优化向量检索（召回）
    optimize_embedding_model()      # 选择更好的 Embedding 模型
    optimize_chunking_strategy()    # 优化分块策略
    add_hybrid_search()             # 添加混合检索

    # 2. 然后添加 ReRank（精排）
    add_reranker()                  # 添加 Cross-Encoder

    # 3. 最后优化生成
    optimize_prompt()               # 优化 Prompt
    add_citation()                  # 添加引用

# 向量检索是基础，ReRank 是锦上添花
```

**记住：ReRank 是"精选"，不是"补救"。向量检索的质量决定了 ReRank 的上限。**

---

## 总结：三个误区的共同根源

| 误区 | 根源 | 正确认知 |
|------|------|----------|
| 分数高 = 正确 | 混淆相关性和正确性 | ReRank 只判断相关性 |
| 候选越多越好 | 忽视成本和边际收益 | 50-100 是最佳范围 |
| ReRank 能兜底 | 过度依赖后处理 | 召回质量是基础 |

---

## 避免误区的检查清单

- [ ] 我是否把 ReRank 分数当作"正确性"指标？
- [ ] 我的候选数量是否超过 200？
- [ ] 我是否因为有 ReRank 而忽视了向量检索的优化？
- [ ] 我是否理解 ReRank 只能重排，不能召回？

---

**下一步：** [07_实战代码](./07_实战代码.md) - 一个完整可运行的 ReRank 示例
