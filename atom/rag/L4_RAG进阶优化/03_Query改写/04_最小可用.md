# 最小可用知识

> 掌握20%的核心知识，解决80%的Query改写问题

---

## 核心理念

**最小可用知识（Minimum Viable Knowledge）**：提炼出最关键的知识点，让你快速上手Query改写，在实际项目中立即见效。

**学习目标：**
- 30分钟内掌握Query改写的核心概念
- 能够在RAG系统中实现基础Query改写
- 理解何时使用哪种改写策略

---

## 必须掌握的5个核心知识点

### 4.1 Multi-Query：通用场景的标配策略

**核心原理：** 生成3-5个查询变体，扩大召回范围

**为什么是标配？**
- 2026年85%的生产RAG系统使用
- 实现简单，效果显著（+30%准确率）
- 适用于所有场景

**最小实现：**

```python
from openai import OpenAI

client = OpenAI()

def multi_query_rewrite(query: str, num_variants: int = 3) -> list[str]:
    """
    生成多个查询变体

    Args:
        query: 原始查询
        num_variants: 变体数量（默认3个）

    Returns:
        查询变体列表（包含原始查询）
    """
    prompt = f"""
请为以下查询生成{num_variants}个不同的表达变体，用于检索相关文档。

原始查询：{query}

要求：
1. 保持原始查询的核心意图
2. 使用不同的表达方式和关键词
3. 每个变体独立成句
4. 直接输出变体，每行一个

变体：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7  # 增加多样性
    )

    variants = response.choices[0].message.content.strip().split('\n')
    variants = [v.strip() for v in variants if v.strip()]

    # 添加原始查询
    return [query] + variants

# 使用示例
query = "RAG系统如何优化？"
variants = multi_query_rewrite(query)

print("原始查询：", query)
print("\n查询变体：")
for i, v in enumerate(variants[1:], 1):
    print(f"{i}. {v}")
```

**输出示例：**
```
原始查询： RAG系统如何优化？

查询变体：
1. 如何提升RAG检索准确率？
2. RAG系统性能优化方法有哪些？
3. 检索增强生成的优化策略
```

**在RAG中使用：**

```python
from typing import List

def rag_with_multi_query(query: str, vector_store) -> str:
    """
    使用Multi-Query的RAG系统
    """
    # 1. 生成查询变体
    variants = multi_query_rewrite(query)

    # 2. 分别检索
    all_docs = []
    for variant in variants:
        docs = vector_store.similarity_search(variant, k=5)
        all_docs.extend(docs)

    # 3. 去重（基于文档ID或内容）
    unique_docs = list({doc.page_content: doc for doc in all_docs}.values())

    # 4. 取Top 5
    top_docs = unique_docs[:5]

    # 5. LLM生成答案
    context = "\n\n".join([doc.page_content for doc in top_docs])

    prompt = f"""
基于以下文档回答问题：

{context}

问题：{query}

答案：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
```

**关键要点：**
- ✅ 生成3-5个变体（不要太多，增加成本）
- ✅ 保持原始查询意图
- ✅ 去重避免重复文档
- ✅ 控制最终文档数量

---

### 4.2 HyDE：处理语义鸿沟

**核心原理：** 生成假设文档，用文档检索文档

**何时使用？**
- 用户查询与文档表达方式差异大
- 用户查询过于简短或口语化
- 需要更高的语义匹配度

**最小实现：**

```python
def hyde_rewrite(query: str) -> str:
    """
    生成假设文档

    Args:
        query: 原始查询

    Returns:
        假设文档内容
    """
    prompt = f"""
请根据以下问题，生成一个假设性的答案文档（150-200字）。

问题：{query}

要求：
1. 使用技术文档的表达方式
2. 包含相关的技术术语和关键词
3. 结构清晰，逻辑连贯
4. 不需要完全准确，重点是表达方式

假设文档：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5
    )

    return response.choices[0].message.content.strip()

# 使用示例
query = "Python异步编程怎么用？"
hypothetical_doc = hyde_rewrite(query)

print("原始查询：", query)
print("\n假设文档：")
print(hypothetical_doc)
```

**输出示例：**
```
原始查询： Python异步编程怎么用？

假设文档：
Python异步编程使用asyncio库实现。通过async/await关键字定义协程函数，
使用asyncio.run()运行异步任务。异步编程适用于I/O密集型场景，如网络请求、
文件读写、数据库操作等。相比多线程，异步编程开销更小，性能更高。
常见的异步库包括aiohttp（异步HTTP客户端）、aiofiles（异步文件操作）等。
```

**在RAG中使用：**

```python
def rag_with_hyde(query: str, vector_store) -> str:
    """
    使用HyDE的RAG系统
    """
    # 1. 生成假设文档
    hypothetical_doc = hyde_rewrite(query)

    # 2. 用假设文档检索
    docs = vector_store.similarity_search(hypothetical_doc, k=5)

    # 3. LLM生成答案
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""
基于以下文档回答问题：

{context}

问题：{query}

答案：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
```

**关键要点：**
- ✅ 假设文档长度150-200字（不要太长）
- ✅ 使用技术文档的表达方式
- ✅ 包含相关技术术语
- ✅ 适用于语义鸿沟大的场景

---

### 4.3 Query Expansion：增强BM25检索

**核心原理：** 添加同义词、相关词、领域术语

**何时使用？**
- 使用BM25关键词检索
- 用户查询缺少关键术语
- 需要扩大关键词覆盖范围

**最小实现：**

```python
def query_expansion(query: str) -> str:
    """
    扩展查询关键词

    Args:
        query: 原始查询

    Returns:
        扩展后的查询（用OR连接）
    """
    prompt = f"""
请为以下查询添加同义词、相关词和领域术语，用于BM25关键词检索。

原始查询：{query}

要求：
1. 添加同义词（如：优化 → 提升、改进）
2. 添加相关词（如：API → 接口、服务）
3. 添加领域术语（如：异步 → asyncio、协程）
4. 用 OR 连接所有词
5. 保持简洁，不超过10个词

扩展查询：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    return response.choices[0].message.content.strip()

# 使用示例
query = "API加速"
expanded = query_expansion(query)

print("原始查询：", query)
print("扩展查询：", expanded)
```

**输出示例：**
```
原始查询： API加速
扩展查询： API加速 OR 接口优化 OR 性能提升 OR 响应时间 OR 缓存 OR 异步处理 OR 并发优化
```

**在RAG中使用：**

```python
def rag_with_expansion(query: str, bm25_index) -> str:
    """
    使用Query Expansion的RAG系统（BM25检索）
    """
    # 1. 扩展查询
    expanded_query = query_expansion(query)

    # 2. BM25检索
    docs = bm25_index.search(expanded_query, k=5)

    # 3. LLM生成答案
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""
基于以下文档回答问题：

{context}

问题：{query}

答案：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
```

**关键要点：**
- ✅ 用OR连接关键词
- ✅ 控制扩展词数量（5-10个）
- ✅ 适用于BM25检索
- ✅ 可与向量检索混合使用

---

### 4.4 Query Decomposition：处理复杂查询

**核心原理：** 将复杂查询拆分为多个子查询

**何时使用？**
- 查询包含多个信息需求
- 对比分析类问题
- 多跳推理问题

**最小实现：**

```python
def query_decomposition(query: str) -> List[str]:
    """
    拆分复杂查询为子查询

    Args:
        query: 原始复杂查询

    Returns:
        子查询列表
    """
    prompt = f"""
请将以下复杂查询拆分为多个简单的子查询。

复杂查询：{query}

要求：
1. 每个子查询独立完整
2. 子查询之间有逻辑关系
3. 覆盖原始查询的所有信息需求
4. 每行一个子查询

子查询：
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    sub_queries = response.choices[0].message.content.strip().split('\n')
    sub_queries = [q.strip() for q in sub_queries if q.strip()]

    return sub_queries

# 使用示例
complex_query = "对比Python和Go的并发模型，并说明各自适用场景"
sub_queries = query_decomposition(complex_query)

print("复杂查询：", complex_query)
print("\n子查询：")
for i, sq in enumerate(sub_queries, 1):
    print(f"{i}. {sq}")
```

**输出示例：**
```
复杂查询： 对比Python和Go的并发模型，并说明各自适用场景

子查询：
1. Python的并发模型是什么？
2. Go的并发模型是什么？
3. Python并发模型的优缺点
4. Go并发模型的优缺点
5. Python并发适用场景
6. Go并发适用场景
```

**在RAG中使用：**

```python
def rag_with_decomposition(query: str, vector_store) -> str:
    """
    使用Query Decomposition的RAG系统
    """
    # 1. 拆分查询
    sub_queries = query_decomposition(query)

    # 2. 迭代检索
    all_answers = []
    for sub_query in sub_queries:
        # 检索
        docs = vector_store.similarity_search(sub_query, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        # 生成子答案
        prompt = f"""
基于以下文档回答问题：

{context}

问题：{sub_query}

答案（简洁）：
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        all_answers.append({
            "question": sub_query,
            "answer": response.choices[0].message.content
        })

    # 3. 综合答案
    synthesis_prompt = f"""
原始问题：{query}

子问题和答案：
{chr(10).join([f"Q: {a['question']}\nA: {a['answer']}\n" for a in all_answers])}

请综合以上信息，回答原始问题：
"""

    final_response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": synthesis_prompt}]
    )

    return final_response.choices[0].message.content
```

**关键要点：**
- ✅ 拆分为3-6个子查询
- ✅ 每个子查询独立检索
- ✅ 最后综合所有答案
- ✅ 适用于复杂、多跳问题

---

### 4.5 策略选择决策树

**如何选择合适的改写策略？**

```python
def choose_rewrite_strategy(query: str) -> str:
    """
    根据查询特征选择改写策略

    Returns:
        策略名称：'multi_query', 'hyde', 'expansion', 'decomposition'
    """
    # 简单规则判断
    query_length = len(query)
    has_comparison = any(word in query for word in ['对比', '比较', 'vs', '区别'])
    has_multiple_questions = query.count('？') > 1 or query.count('?') > 1
    is_short = query_length < 20

    # 决策逻辑
    if has_comparison or has_multiple_questions:
        return 'decomposition'  # 复杂查询 → 拆分
    elif is_short:
        return 'hyde'  # 简短查询 → HyDE
    else:
        return 'multi_query'  # 默认 → Multi-Query

# 使用示例
queries = [
    "RAG优化",
    "对比Python和Go的并发模型",
    "如何提升API性能？有哪些缓存策略？",
    "FastAPI异步路由怎么写？"
]

for q in queries:
    strategy = choose_rewrite_strategy(q)
    print(f"查询：{q}")
    print(f"策略：{strategy}\n")
```

**输出示例：**
```
查询：RAG优化
策略：hyde

查询：对比Python和Go的并发模型
策略：decomposition

查询：如何提升API性能？有哪些缓存策略？
策略：decomposition

查询：FastAPI异步路由怎么写？
策略：multi_query
```

---

## 实施优先级

### 第一阶段：立即实施（1天）

**实现Multi-Query**
- 最简单，效果最好
- 适用于所有场景
- 立即提升20-30%准确率

```python
# 最小实现（10行代码）
def simple_multi_query(query: str) -> list[str]:
    prompt = f"为查询'{query}'生成3个不同表达的变体，每行一个："
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return [query] + response.choices[0].message.content.split('\n')
```

### 第二阶段：优化提升（3天）

**添加HyDE和Query Expansion**
- HyDE处理语义鸿沟
- Query Expansion增强BM25检索
- 组合使用提升40-50%

### 第三阶段：进阶功能（1周）

**实现Query Decomposition**
- 处理复杂查询
- 多跳推理
- 对比分析

---

## 快速集成到现有RAG系统

### 方案1：最小侵入（推荐）

```python
# 原有RAG系统
def original_rag(query: str) -> str:
    docs = vector_store.similarity_search(query, k=5)
    # ... 生成答案
    return answer

# 添加Multi-Query（只改1行）
def improved_rag(query: str) -> str:
    # 添加这一行
    variants = multi_query_rewrite(query)

    # 其他代码不变
    all_docs = []
    for variant in variants:
        docs = vector_store.similarity_search(variant, k=5)
        all_docs.extend(docs)

    unique_docs = list({doc.page_content: doc for doc in all_docs}.values())[:5]
    # ... 生成答案
    return answer
```

### 方案2：自适应改写

```python
def adaptive_rag(query: str) -> str:
    """
    根据查询自动选择改写策略
    """
    strategy = choose_rewrite_strategy(query)

    if strategy == 'multi_query':
        variants = multi_query_rewrite(query)
        docs = search_with_variants(variants)
    elif strategy == 'hyde':
        hypothetical_doc = hyde_rewrite(query)
        docs = vector_store.similarity_search(hypothetical_doc, k=5)
    elif strategy == 'decomposition':
        return rag_with_decomposition(query, vector_store)
    else:
        docs = vector_store.similarity_search(query, k=5)

    # 生成答案
    return generate_answer(query, docs)
```

---

## 成本估算

### LLM调用成本（2026年价格）

| 策略 | 每次查询成本 | 1000次查询成本 |
|------|-------------|---------------|
| Multi-Query | $0.01-0.02 | $10-20 |
| HyDE | $0.01-0.02 | $10-20 |
| Query Expansion | $0.005-0.01 | $5-10 |
| Query Decomposition | $0.03-0.05 | $30-50 |

**成本优化建议：**
- 使用GPT-3.5-turbo代替GPT-4（成本降低10倍）
- 缓存常见查询的改写结果
- 批量处理降低API调用次数

---

## 效果评估

### 简单评估方法

```python
def evaluate_rewrite_strategy(test_queries: List[str],
                               ground_truth: List[str]) -> dict:
    """
    评估改写策略效果

    Args:
        test_queries: 测试查询列表
        ground_truth: 正确答案列表

    Returns:
        评估指标
    """
    correct = 0
    total = len(test_queries)

    for query, truth in zip(test_queries, ground_truth):
        # 使用改写策略
        answer = adaptive_rag(query)

        # 简单匹配（实际应使用更复杂的评估）
        if truth.lower() in answer.lower():
            correct += 1

    accuracy = correct / total

    return {
        "accuracy": accuracy,
        "correct": correct,
        "total": total
    }

# 使用示例
test_queries = [
    "RAG系统如何优化？",
    "Python异步编程怎么用？",
    # ... 更多测试查询
]

ground_truth = [
    "混合检索、ReRank、Query改写",
    "asyncio、async/await",
    # ... 对应的正确答案
]

results = evaluate_rewrite_strategy(test_queries, ground_truth)
print(f"准确率：{results['accuracy']:.2%}")
```

---

## 常见问题

### Q1: Multi-Query会增加多少延迟？

**A:**
- 生成变体：+100-200ms（LLM调用）
- 多次检索：+50-100ms（并行检索可优化）
- 总延迟：+150-300ms
- 可通过缓存和并行优化到+100ms以内

### Q2: 如何避免生成的变体质量差？

**A:**
- 使用更好的Prompt（参考实战代码）
- 设置合适的temperature（0.5-0.7）
- 添加示例（Few-shot）
- 人工审核和优化Prompt

### Q3: 什么时候不需要Query改写？

**A:**
- 用户查询已经很精确
- 文档库很小（<1000个文档）
- 对延迟要求极高（<100ms）
- 成本预算极低

---

## 学习检查清单

### 理解层面
- [ ] 理解Multi-Query的核心原理
- [ ] 理解HyDE的适用场景
- [ ] 理解Query Expansion的作用
- [ ] 理解Query Decomposition的价值
- [ ] 理解策略选择的决策逻辑

### 实践层面
- [ ] 能实现Multi-Query
- [ ] 能实现HyDE
- [ ] 能实现Query Expansion
- [ ] 能实现Query Decomposition
- [ ] 能根据场景选择策略

### 集成层面
- [ ] 能集成到现有RAG系统
- [ ] 能评估改写效果
- [ ] 能优化成本和延迟
- [ ] 能处理常见问题

---

## 下一步学习

### 深入学习
1. **阅读核心概念** - 深入理解6大策略的原理
2. **阅读实战代码** - 学习完整的生产级实现
3. **阅读反直觉点** - 避免常见误区

### 实战练习
1. **实现基础Multi-Query** - 在自己的RAG系统中实现
2. **对比效果** - 评估改写前后的准确率提升
3. **优化策略** - 根据实际场景调整策略

### 进阶方向
1. **混合策略** - 组合多种改写技术
2. **自适应改写** - 根据查询类型自动选择
3. **学习型改写** - 根据用户反馈优化

---

## 总结

**这些知识足以：**
- ✅ 在30分钟内理解Query改写
- ✅ 在1天内实现Multi-Query
- ✅ 在1周内掌握所有核心策略
- ✅ 在实际项目中提升20-35%准确率

**记住：**
- Multi-Query是标配，优先实现
- HyDE处理语义鸿沟
- Query Expansion增强BM25
- Query Decomposition处理复杂查询
- 根据场景选择合适策略

---

**版本：** v1.0 (2026年标准)
**最后更新：** 2026-02-16
**适用场景：** RAG开发、信息检索、查询优化
