# å®žæˆ˜é¡¹ç›®ç»„åˆ

**çŸ¥è¯†ç‚¹æ•°**: 8ä¸ª | **å­¦ä¹ æ—¶é•¿**: 2å‘¨ | **ä¼˜å…ˆçº§**: P2

---

## æ¦‚è§ˆ

**é€‚åˆäººç¾¤**: æ±‚èŒå‡†å¤‡ã€ä¸ªäººå“ç‰Œå»ºè®¾

**å­¦ä¹ è·¯å¾„**: é¡¹ç›®æ¡ˆä¾‹ï¼ˆ4ä¸ªï¼‰â†’ é¢è¯•å‡†å¤‡ï¼ˆ4ä¸ªï¼‰

---

## L1_é¡¹ç›®æ¡ˆä¾‹ï¼ˆ4ä¸ªçŸ¥è¯†ç‚¹ï¼‰

### 01_æ™ºèƒ½å®¢æœç³»ç»Ÿ

**é¡¹ç›®æ¦‚è¿°**: ä¼ä¸šçº§AIå®¢æœç³»ç»Ÿï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€çŸ¥è¯†åº“æ£€ç´¢ã€äººå·¥è½¬æŽ¥ã€‚

**æŠ€æœ¯æ ˆ**:
- åŽç«¯: FastAPI + LangChain + PostgreSQL
- å‰ç«¯: Next.js + Vercel AI SDK
- å‘é‡æ•°æ®åº“: Pinecone
- éƒ¨ç½²: Docker + Kubernetes

**æ ¸å¿ƒåŠŸèƒ½**:
```python
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.memory import ConversationBufferMemory
from langchain.tools import Tool

class CustomerServiceAgent:
    def __init__(self):
        self.memory = ConversationBufferMemory()
        self.tools = [
            Tool(
                name="search_knowledge_base",
                func=self.search_kb,
                description="Search company knowledge base"
            ),
            Tool(
                name="check_order_status",
                func=self.check_order,
                description="Check order status by order ID"
            ),
            Tool(
                name="escalate_to_human",
                func=self.escalate,
                description="Transfer to human agent"
            )
        ]
        self.agent = create_openai_functions_agent(
            llm=ChatOpenAI(model="gpt-4"),
            tools=self.tools,
            memory=self.memory
        )

    async def handle_query(self, user_id: str, query: str):
        response = await self.agent.arun(query)

        # è®°å½•å¯¹è¯
        await self.log_conversation(user_id, query, response)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
        if self.needs_human_intervention(response):
            await self.notify_human_agent(user_id)

        return response
```

**é¡¹ç›®äº®ç‚¹**:
- å¤šè½®å¯¹è¯è®°å¿†ç®¡ç†
- çŸ¥è¯†åº“å®žæ—¶æ›´æ–°
- äººå·¥è½¬æŽ¥æœºåˆ¶
- å®Œæ•´çš„ç›‘æŽ§å’Œæ—¥å¿—
- A/Bæµ‹è¯•ä¸åŒPrompt

**GitHubä»“åº“ç»“æž„**:
```
customer-service-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ components/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ service.yaml
â””â”€â”€ README.md
```

---

### 02_æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

**é¡¹ç›®æ¦‚è¿°**: RAGé©±åŠ¨çš„ä¼ä¸šæ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ã€‚

**æŠ€æœ¯æ ˆ**:
- RAGæ¡†æž¶: LlamaIndex
- å‘é‡æ•°æ®åº“: Qdrant
- æ–‡æ¡£è§£æž: Unstructured
- è¯„ä¼°: Ragas

**æ ¸å¿ƒåŠŸèƒ½**:
```python
from llama_index import VectorStoreIndex, ServiceContext
from llama_index.vector_stores import QdrantVectorStore
from llama_index.embeddings import OpenAIEmbedding

class DocumentQASystem:
    def __init__(self):
        self.vector_store = QdrantVectorStore(
            client=QdrantClient("localhost", port=6333),
            collection_name="documents"
        )

        self.service_context = ServiceContext.from_defaults(
            embed_model=OpenAIEmbedding()
        )

        self.index = VectorStoreIndex.from_vector_store(
            self.vector_store,
            service_context=self.service_context
        )

    async def ingest_document(self, file_path: str):
        """æ–‡æ¡£æ‘„å–"""
        # è§£æžæ–‡æ¡£
        documents = self.parse_document(file_path)

        # åˆ†å—
        chunks = self.chunk_documents(documents)

        # ç”ŸæˆEmbeddingå¹¶å­˜å‚¨
        await self.index.insert_nodes(chunks)

        return {"status": "success", "chunks": len(chunks)}

    async def query(self, question: str, top_k: int = 5):
        """æŸ¥è¯¢"""
        query_engine = self.index.as_query_engine(
            similarity_top_k=top_k,
            response_mode="compact"
        )

        response = await query_engine.aquery(question)

        return {
            "answer": response.response,
            "sources": [node.text for node in response.source_nodes],
            "confidence": self.calculate_confidence(response)
        }

    def evaluate(self, test_cases: list):
        """è¯„ä¼°ç³»ç»Ÿæ€§èƒ½"""
        from ragas import evaluate
        from ragas.metrics import faithfulness, answer_relevancy

        results = evaluate(
            dataset=test_cases,
            metrics=[faithfulness, answer_relevancy]
        )

        return results
```

**é¡¹ç›®äº®ç‚¹**:
- æ”¯æŒPDFã€Wordã€Markdownç­‰å¤šç§æ ¼å¼
- æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰
- è‡ªåŠ¨è¯„ä¼°å’Œä¼˜åŒ–
- å¼•ç”¨æº¯æº
- å¢žé‡æ›´æ–°

---

### 03_ä»£ç åŠ©æ‰‹

**é¡¹ç›®æ¦‚è¿°**: AIé©±åŠ¨çš„ä»£ç ç”Ÿæˆã€å®¡æŸ¥ã€æµ‹è¯•åŠ©æ‰‹ã€‚

**æŠ€æœ¯æ ˆ**:
- Agentæ¡†æž¶: Autogen
- ä»£ç æ‰§è¡Œ: Dockeræ²™ç®±
- ä»£ç åˆ†æž: Tree-sitter
- CI/CD: GitHub Actions

**æ ¸å¿ƒåŠŸèƒ½**:
```python
from autogen import AssistantAgent, UserProxyAgent, GroupChat

class CodeAssistant:
    def __init__(self):
        self.coder = AssistantAgent(
            name="coder",
            system_message="You are an expert programmer",
            llm_config={"model": "gpt-4"}
        )

        self.reviewer = AssistantAgent(
            name="reviewer",
            system_message="You are a code reviewer",
            llm_config={"model": "gpt-4"}
        )

        self.tester = AssistantAgent(
            name="tester",
            system_message="You write comprehensive tests",
            llm_config={"model": "gpt-4"}
        )

        self.executor = UserProxyAgent(
            name="executor",
            code_execution_config={
                "work_dir": "coding",
                "use_docker": True
            }
        )

    async def generate_code(self, requirement: str):
        """ç”Ÿæˆä»£ç """
        groupchat = GroupChat(
            agents=[self.coder, self.reviewer, self.tester, self.executor],
            messages=[],
            max_round=10
        )

        manager = GroupChatManager(groupchat=groupchat)

        await self.executor.initiate_chat(
            manager,
            message=f"Implement: {requirement}"
        )

        return self.extract_code(groupchat.messages)

    async def review_code(self, code: str):
        """ä»£ç å®¡æŸ¥"""
        review = await self.reviewer.generate_reply(
            messages=[{"role": "user", "content": f"Review this code:\n{code}"}]
        )

        return {
            "issues": self.parse_issues(review),
            "suggestions": self.parse_suggestions(review),
            "score": self.calculate_score(review)
        }
```

**é¡¹ç›®äº®ç‚¹**:
- å¤šAgentåä½œï¼ˆç¼–ç ã€å®¡æŸ¥ã€æµ‹è¯•ï¼‰
- å®‰å…¨çš„ä»£ç æ‰§è¡ŒçŽ¯å¢ƒ
- è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
- ä»£ç è´¨é‡è¯„åˆ†
- Gité›†æˆ

---

### 04_å¤šAgentåä½œç³»ç»Ÿ

**é¡¹ç›®æ¦‚è¿°**: å¤æ‚ä»»åŠ¡çš„å¤šAgentåä½œè§£å†³æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ ˆ**:
- æ¡†æž¶: CrewAI
- å·¥ä½œæµ: LangGraph
- ç›‘æŽ§: LangSmith
- éƒ¨ç½²: Kubernetes

**æ ¸å¿ƒåŠŸèƒ½**:
```python
from crewai import Agent, Task, Crew, Process

class ResearchWritingCrew:
    def __init__(self):
        self.researcher = Agent(
            role="Researcher",
            goal="Find accurate and relevant information",
            backstory="Expert researcher with deep knowledge",
            tools=[search_tool, scrape_tool]
        )

        self.analyst = Agent(
            role="Analyst",
            goal="Analyze and synthesize information",
            backstory="Data analyst with critical thinking",
            tools=[analysis_tool]
        )

        self.writer = Agent(
            role="Writer",
            goal="Write engaging and accurate content",
            backstory="Professional writer",
            tools=[grammar_tool]
        )

    async def execute(self, topic: str):
        """æ‰§è¡Œç ”ç©¶å†™ä½œä»»åŠ¡"""
        # å®šä¹‰ä»»åŠ¡
        research_task = Task(
            description=f"Research about {topic}",
            agent=self.researcher,
            expected_output="Comprehensive research findings"
        )

        analysis_task = Task(
            description="Analyze the research findings",
            agent=self.analyst,
            expected_output="Key insights and patterns"
        )

        writing_task = Task(
            description="Write an article based on analysis",
            agent=self.writer,
            expected_output="Well-written article"
        )

        # åˆ›å»ºCrew
        crew = Crew(
            agents=[self.researcher, self.analyst, self.writer],
            tasks=[research_task, analysis_task, writing_task],
            process=Process.sequential
        )

        # æ‰§è¡Œ
        result = await crew.kickoff()

        return result
```

**é¡¹ç›®äº®ç‚¹**:
- å¤šAgentè§’è‰²åˆ†å·¥
- ä»»åŠ¡ä¾èµ–ç®¡ç†
- æµç¨‹å¯è§†åŒ–
- å®Œæ•´çš„è¿½è¸ªå’Œè°ƒè¯•
- å¯æ‰©å±•çš„å·¥å…·ç³»ç»Ÿ

---

## L2_é¢è¯•å‡†å¤‡ï¼ˆ4ä¸ªçŸ¥è¯†ç‚¹ï¼‰

### 01_æŠ€æœ¯é¢è¯•é¢˜åº“

**LLMåŸºç¡€**:
- Q: ä»€ä¹ˆæ˜¯Temperatureå‚æ•°ï¼Ÿå¦‚ä½•å½±å“è¾“å‡ºï¼Ÿ
- Q: Tokenæ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•è®¡ç®—æˆæœ¬ï¼Ÿ
- Q: ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡çª—å£ï¼Ÿå¦‚ä½•å¤„ç†è¶…é•¿æ–‡æœ¬ï¼Ÿ
- Q: Few-shot vs Zero-shotçš„åŒºåˆ«ï¼Ÿ

**Agentæž¶æž„**:
- Q: ReActæ¨¡å¼æ˜¯ä»€ä¹ˆï¼Ÿ
- Q: å¦‚ä½•è®¾è®¡Agentçš„å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Ÿ
- Q: å¦‚ä½•å¤„ç†Agentçš„æ— é™å¾ªçŽ¯ï¼Ÿ
- Q: å¤šAgentåä½œçš„å¸¸è§æ¨¡å¼ï¼Ÿ

**RAGç³»ç»Ÿ**:
- Q: RAGçš„æ ¸å¿ƒæµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ
- Q: å¦‚ä½•ä¼˜åŒ–æ£€ç´¢å‡†ç¡®çŽ‡ï¼Ÿ
- Q: Chunkingç­–ç•¥æœ‰å“ªäº›ï¼Ÿ
- Q: å¦‚ä½•è¯„ä¼°RAGç³»ç»Ÿè´¨é‡ï¼Ÿ

**ç”Ÿäº§è¿ç»´**:
- Q: å¦‚ä½•ç›‘æŽ§LLMåº”ç”¨ï¼Ÿ
- Q: å¦‚ä½•å¤„ç†æ¨¡åž‹æ¼‚ç§»ï¼Ÿ
- Q: å¦‚ä½•ä¼˜åŒ–Tokenæˆæœ¬ï¼Ÿ
- Q: å¦‚ä½•å®žçŽ°ç°åº¦å‘å¸ƒï¼Ÿ

---

### 02_ç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹

**æ¡ˆä¾‹1: è®¾è®¡ä¸€ä¸ªæ™ºèƒ½å®¢æœç³»ç»Ÿ**

**éœ€æ±‚åˆ†æž**:
- æ”¯æŒ10ä¸‡+å¹¶å‘ç”¨æˆ·
- å¤šè½®å¯¹è¯è®°å¿†
- çŸ¥è¯†åº“å®žæ—¶æ›´æ–°
- äººå·¥è½¬æŽ¥
- å¤šè¯­è¨€æ”¯æŒ

**æž¶æž„è®¾è®¡**:
```
ç”¨æˆ· â†’ APIç½‘å…³ â†’ è´Ÿè½½å‡è¡¡
                    â†“
        [AgentæœåŠ¡é›†ç¾¤] (æ°´å¹³æ‰©å±•)
                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“           â†“           â†“
    PostgreSQL   Redis      Pinecone
    (å¯¹è¯åŽ†å²)   (ç¼“å­˜)    (çŸ¥è¯†åº“)
```

**æŠ€æœ¯é€‰åž‹**:
- Agentæ¡†æž¶: LangChain (ç”Ÿæ€å®Œå–„)
- å‘é‡æ•°æ®åº“: Pinecone (æ‰˜ç®¡æœåŠ¡)
- ç¼“å­˜: Redis (é«˜æ€§èƒ½)
- æ¶ˆæ¯é˜Ÿåˆ—: Kafka (å¼‚æ­¥ä»»åŠ¡)

**æƒè¡¡åˆ†æž**:
- æˆæœ¬ vs æ€§èƒ½: ä½¿ç”¨ç¼“å­˜å‡å°‘LLMè°ƒç”¨
- å‡†ç¡®çŽ‡ vs å»¶è¿Ÿ: æ··åˆæ£€ç´¢æå‡å‡†ç¡®çŽ‡
- å¯æ‰©å±•æ€§ vs å¤æ‚åº¦: å¾®æœåŠ¡æž¶æž„

---

### 03_ä»£ç è´¨é‡æ ‡å‡†

**ä»£ç è§„èŒƒ**:
```python
# âœ… å¥½çš„ä»£ç 
async def query_agent(
    query: str,
    user_id: str,
    max_tokens: int = 1000
) -> AgentResponse:
    """æŸ¥è¯¢Agentå¹¶è¿”å›žå“åº”

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        user_id: ç”¨æˆ·ID
        max_tokens: æœ€å¤§Tokenæ•°

    Returns:
        AgentResponse: Agentå“åº”

    Raises:
        ValueError: æŸ¥è¯¢ä¸ºç©º
        RateLimitError: è¶…è¿‡é€ŸçŽ‡é™åˆ¶
    """
    if not query:
        raise ValueError("Query cannot be empty")

    # æ£€æŸ¥é€ŸçŽ‡é™åˆ¶
    if not rate_limiter.check(user_id):
        raise RateLimitError(f"Rate limit exceeded for {user_id}")

    # æŸ¥è¯¢Agent
    response = await agent.arun(query, max_tokens=max_tokens)

    # è®°å½•æ—¥å¿—
    logger.info("agent_query", user_id=user_id, query_length=len(query))

    return response

# âŒ ä¸å¥½çš„ä»£ç 
def query(q, u):
    r = agent.run(q)  # æ²¡æœ‰é”™è¯¯å¤„ç†
    return r  # æ²¡æœ‰ç±»åž‹æ³¨è§£
```

**æµ‹è¯•è¦†ç›–**:
```python
@pytest.mark.asyncio
async def test_query_agent():
    # æ­£å¸¸æƒ…å†µ
    response = await query_agent("test", "user1")
    assert response.answer is not None

    # è¾¹ç•Œæƒ…å†µ
    with pytest.raises(ValueError):
        await query_agent("", "user1")

    # å¼‚å¸¸æƒ…å†µ
    with pytest.raises(RateLimitError):
        for _ in range(100):
            await query_agent("test", "user1")
```

---

### 04_å¼€æºè´¡çŒ®æŒ‡å—

**é€‰æ‹©é¡¹ç›®**:
- â­ 5k+ stars (æ´»è·ƒç¤¾åŒº)
- ðŸ“ æ¸…æ™°çš„è´¡çŒ®æŒ‡å—
- ðŸ› æ ‡è®°ä¸º"good first issue"çš„Issue
- ðŸ”„ æœ€è¿‘æœ‰åˆå¹¶çš„PR

**è´¡çŒ®æµç¨‹**:
```bash
# 1. Forké¡¹ç›®
gh repo fork langchain-ai/langchain

# 2. åˆ›å»ºåˆ†æ”¯
git checkout -b fix-memory-leak

# 3. ä¿®æ”¹ä»£ç 
# ... ç¼–å†™ä»£ç å’Œæµ‹è¯•

# 4. æäº¤
git commit -m "fix: resolve memory leak in ConversationBufferMemory"

# 5. æŽ¨é€
git push origin fix-memory-leak

# 6. åˆ›å»ºPR
gh pr create --title "Fix memory leak in ConversationBufferMemory" \
  --body "Fixes #1234. This PR resolves the memory leak by..."
```

**PRæœ€ä½³å®žè·µ**:
- æ¸…æ™°çš„æ ‡é¢˜å’Œæè¿°
- å…³è”ç›¸å…³Issue
- æ·»åŠ æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°æ–‡æ¡£
- å“åº”Code Review

**ç¤ºä¾‹PRæè¿°**:
```markdown
## Summary
Fixes memory leak in ConversationBufferMemory when handling long conversations.

## Changes
- Added automatic memory cleanup after 100 messages
- Implemented memory compression for old messages
- Added tests for memory management

## Testing
- Unit tests: `pytest tests/memory/test_buffer.py`
- Integration tests: `pytest tests/integration/test_memory.py`
- Manual testing with 1000+ message conversations

## Related Issues
Fixes #1234
Related to #5678
```

---

## æ ¸å¿ƒ20%ï¼ˆ2ä¸ªçŸ¥è¯†ç‚¹ï¼‰

1. â­â­â­ **æ™ºèƒ½å®¢æœç³»ç»Ÿ**
2. â­â­â­ **ç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹**

---

## é¡¹ç›®ç»„åˆå»ºè®®

### æœ€å°ç»„åˆï¼ˆæ±‚èŒå¿…å¤‡ï¼‰
1. **RAGåº”ç”¨** - å±•ç¤ºæ£€ç´¢å’Œç”Ÿæˆèƒ½åŠ›
2. **å¤šAgentç³»ç»Ÿ** - å±•ç¤ºæž¶æž„è®¾è®¡èƒ½åŠ›
3. **å¼€æºè´¡çŒ®** - å±•ç¤ºç¤¾åŒºå‚ä¸Ž

### æŽ¨èç»„åˆï¼ˆç«žäº‰åŠ›å¼ºï¼‰
1. RAGåº”ç”¨ + å®Œæ•´ç›‘æŽ§
2. å¤šAgentç³»ç»Ÿ + ç”Ÿäº§éƒ¨ç½²
3. 2-3ä¸ªå¼€æºPR
4. æŠ€æœ¯åšå®¢ 3-5ç¯‡

### å®Œæ•´ç»„åˆï¼ˆæŠ€æœ¯ä¸“å®¶ï¼‰
1. 3-4ä¸ªå®Œæ•´é¡¹ç›®
2. 5-10ä¸ªå¼€æºPR
3. æŠ€æœ¯åšå®¢ 10+ç¯‡
4. å¼€æºé¡¹ç›®ç»´æŠ¤è€…

---

## é¡¹ç›®å±•ç¤ºæŠ€å·§

### GitHub READMEæ¨¡æ¿
```markdown
# Project Name

> One-line description

![Demo](demo.gif)

## Features
- âœ¨ Feature 1
- ðŸš€ Feature 2
- ðŸ“Š Feature 3

## Tech Stack
- Backend: FastAPI + LangChain
- Frontend: Next.js + Vercel AI SDK
- Database: PostgreSQL + Pinecone
- Deployment: Docker + Kubernetes

## Quick Start
\`\`\`bash
docker-compose up
\`\`\`

## Architecture
[Architecture diagram]

## Performance
- Latency: < 100ms
- Throughput: 1000 QPS
- Accuracy: 95%+

## Demo
[Live demo link]

## License
MIT
```

### æŠ€æœ¯åšå®¢ä¸»é¢˜
1. "æž„å»ºç”Ÿäº§çº§RAGç³»ç»Ÿçš„10ä¸ªæœ€ä½³å®žè·µ"
2. "å¤šAgentåä½œï¼šä»Žç†è®ºåˆ°å®žè·µ"
3. "LLMåº”ç”¨ç›‘æŽ§ï¼šæˆ‘ä»¬å¦‚ä½•é™ä½Žæˆæœ¬50%"
4. "æ·±å…¥ç†è§£LangChainçš„LCELè¡¨è¾¾å¼"
5. "Agentæ— é™å¾ªçŽ¯é—®é¢˜çš„5ç§è§£å†³æ–¹æ¡ˆ"

---

## å­¦ä¹ èµ„æº

- [GitHubå¼€æºæŒ‡å—](https://opensource.guide/)
- [ç³»ç»Ÿè®¾è®¡é¢è¯•](https://github.com/donnemartin/system-design-primer)
- [LeetCode](https://leetcode.com/)

---

## å¸¸è§è¯¯åŒº

1. âŒ "é¡¹ç›®è¶Šå¤šè¶Šå¥½" â†’ âœ… è´¨é‡ä¼˜äºŽæ•°é‡
2. âŒ "åªå±•ç¤ºæˆåŠŸæ¡ˆä¾‹" â†’ âœ… å¤±è´¥ç»éªŒä¹Ÿæœ‰ä»·å€¼
3. âŒ "ä¸éœ€è¦æ–‡æ¡£" â†’ âœ… å¥½çš„æ–‡æ¡£æ˜¯åŠ åˆ†é¡¹

---

**ç‰ˆæœ¬**: v1.0 | **æœ€åŽæ›´æ–°**: 2026-02-12
