# 核心概念 01：查询理解 (Query Understanding)

## 概述

查询理解是查询处理的第一步，也是最基础的环节。它的目标是**理解用户查询的真实意图**，为后续的查询转换和检索提供基础。

---

## 什么是查询理解？

**定义：** 查询理解是分析用户原始查询，识别其意图、实体、上下文和隐含信息的过程。

**核心任务：**

1. **意图识别**：判断用户想要什么类型的信息
2. **实体提取**：识别查询中的关键实体和概念
3. **歧义消解**：处理多义词和指代消解
4. **上下文补充**：补充隐含的上下文信息

---

## 为什么查询理解重要？

### 问题：用户查询的模糊性

用户的自然语言查询往往存在以下问题：

1. **意图不明确**："Python 性能"（想了解原理？还是优化方法？）
2. **实体模糊**："GIL"（是 Python 的 GIL？还是其他领域的 GIL？）
3. **上下文缺失**："怎么优化？"（优化什么？在什么场景下？）
4. **表达多样**：同一意图有多种表达方式

**示例：**

```
查询 1："Python 怎么跑得快？"
- 意图：性能优化
- 实体：Python
- 隐含信息：代码执行速度、优化方法

查询 2："Python 性能优化"
- 意图：性能优化
- 实体：Python
- 隐含信息：优化方法、最佳实践

查询 3："提升 Python 速度"
- 意图：性能优化
- 实体：Python
- 隐含信息：执行速度、加速技术
```

这三个查询表达不同，但意图相同。查询理解需要识别这种一致性。

---

## 查询理解的核心组件

### 1. 意图识别 (Intent Detection)

**目标：** 判断用户查询的类型和目的

**常见意图类型：**

| 意图类型 | 描述 | 示例 |
|----------|------|------|
| 概念解释 | 理解某个概念 | "什么是 RAG？" |
| 操作指导 | 如何完成某个任务 | "如何安装 LangChain？" |
| 问题诊断 | 解决某个问题 | "为什么 RAG 不准？" |
| 对比分析 | 比较多个选项 | "LangChain vs LlamaIndex" |
| 事实查询 | 获取具体事实 | "Python 3.13 发布日期" |
| 探索式搜索 | 不确定具体要找什么 | "RAG 优化方法" |

**意图识别方法：**

#### 方法 1：基于规则的意图识别

```python
def detect_intent_rule_based(query: str) -> str:
    """基于规则的意图识别"""
    query_lower = query.lower()

    # 概念解释
    if any(kw in query_lower for kw in ["什么是", "是什么", "定义", "概念"]):
        return "concept"

    # 操作指导
    if any(kw in query_lower for kw in ["如何", "怎么", "怎样", "方法"]):
        return "how-to"

    # 问题诊断
    if any(kw in query_lower for kw in ["为什么", "原因", "错误", "问题"]):
        return "troubleshooting"

    # 对比分析
    if any(kw in query_lower for kw in ["对比", "比较", "vs", "区别", "优缺点"]):
        return "comparison"

    # 事实查询
    if any(kw in query_lower for kw in ["什么时候", "哪里", "谁", "多少"]):
        return "fact"

    # 默认：探索式搜索
    return "exploratory"
```

**优点：**
- 快速、低成本
- 可解释性强
- 适合简单场景

**缺点：**
- 规则难以覆盖所有情况
- 无法处理复杂查询
- 需要人工维护规则

---

#### 方法 2：基于 LLM 的意图识别

```python
from openai import OpenAI

client = OpenAI()

INTENT_DETECTION_PROMPT = """你是一个查询意图识别专家。请分析以下查询的意图类型。

意图类型：
- concept: 概念解释（理解某个概念）
- how-to: 操作指导（如何完成某个任务）
- troubleshooting: 问题诊断（解决某个问题）
- comparison: 对比分析（比较多个选项）
- fact: 事实查询（获取具体事实）
- exploratory: 探索式搜索（不确定具体要找什么）

查询：{query}

请只输出意图类型，不要解释。
"""

def detect_intent_llm(query: str) -> str:
    """基于 LLM 的意图识别"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": INTENT_DETECTION_PROMPT.format(query=query)}
        ],
        temperature=0.1
    )
    return response.choices[0].message.content.strip()
```

**优点：**
- 准确率高
- 可以处理复杂查询
- 无需人工维护规则

**缺点：**
- 成本较高
- 延迟较高
- 可解释性较差

---

#### 方法 3：混合方法（推荐）

```python
def detect_intent_hybrid(query: str) -> str:
    """混合方法：先用规则，规则无法判断时用 LLM"""
    # 1. 尝试规则匹配
    rule_intent = detect_intent_rule_based(query)

    # 2. 如果规则有明确结果（非 exploratory），直接返回
    if rule_intent != "exploratory":
        return rule_intent

    # 3. 否则使用 LLM
    return detect_intent_llm(query)
```

**优点：**
- 平衡成本和准确率
- 简单查询用规则（快速、低成本）
- 复杂查询用 LLM（准确率高）

---

### 2. 实体提取 (Entity Extraction)

**目标：** 识别查询中的关键实体和概念

**实体类型：**

| 实体类型 | 描述 | 示例 |
|----------|------|------|
| 技术栈 | 编程语言、框架、库 | Python, LangChain, FastAPI |
| 概念 | 技术概念、术语 | RAG, Embedding, Transformer |
| 操作 | 动作、任务 | 安装, 优化, 部署 |
| 属性 | 特征、指标 | 性能, 准确性, 速度 |
| 场景 | 应用场景、领域 | 文档问答, 代码搜索 |

**实体提取方法：**

#### 方法 1：基于 NER 的实体提取

```python
# 使用 spaCy 进行实体提取
import spacy

nlp = spacy.load("zh_core_web_sm")

def extract_entities_ner(query: str) -> list[dict]:
    """基于 NER 的实体提取"""
    doc = nlp(query)

    entities = []
    for ent in doc.ents:
        entities.append({
            "text": ent.text,
            "label": ent.label_,
            "start": ent.start_char,
            "end": ent.end_char
        })

    return entities
```

**优点：**
- 快速
- 适合通用实体（人名、地名、组织等）

**缺点：**
- 对技术领域实体识别效果差
- 需要训练领域特定模型

---

#### 方法 2：基于 LLM 的实体提取

```python
ENTITY_EXTRACTION_PROMPT = """你是一个实体提取专家。请从以下查询中提取关键实体。

实体类型：
- 技术栈：编程语言、框架、库
- 概念：技术概念、术语
- 操作：动作、任务
- 属性：特征、指标
- 场景：应用场景、领域

查询：{query}

请以 JSON 格式输出，格式如下：
{{
  "entities": [
    {{"text": "实体文本", "type": "实体类型"}}
  ]
}}
"""

def extract_entities_llm(query: str) -> list[dict]:
    """基于 LLM 的实体提取"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": ENTITY_EXTRACTION_PROMPT.format(query=query)}
        ],
        temperature=0.1,
        response_format={"type": "json_object"}
    )

    import json
    result = json.loads(response.choices[0].message.content)
    return result.get("entities", [])
```

**优点：**
- 准确率高
- 适合技术领域
- 可以识别复杂实体

**缺点：**
- 成本较高
- 延迟较高

---

### 3. 歧义消解 (Ambiguity Resolution)

**目标：** 处理查询中的多义词和指代消解

**常见歧义类型：**

1. **多义词**："Python"（编程语言 vs 蟒蛇）
2. **缩写**："GIL"（Global Interpreter Lock vs 其他）
3. **指代**："它"、"这个"、"那个"
4. **上下文依赖**："怎么优化？"（优化什么？）

**歧义消解方法：**

#### 方法 1：基于上下文的歧义消解

```python
def resolve_ambiguity_context(query: str, context: dict) -> str:
    """基于上下文消解歧义"""
    # 如果查询包含指代词，使用上下文替换
    pronouns = ["它", "这个", "那个", "这", "那"]

    for pronoun in pronouns:
        if pronoun in query:
            # 从上下文中获取最近提到的实体
            if "last_entity" in context:
                query = query.replace(pronoun, context["last_entity"])

    return query
```

#### 方法 2：基于领域知识的歧义消解

```python
# 领域知识库
DOMAIN_KNOWLEDGE = {
    "GIL": "Global Interpreter Lock (Python)",
    "RAG": "Retrieval-Augmented Generation",
    "LLM": "Large Language Model",
    "API": "Application Programming Interface"
}

def resolve_ambiguity_domain(query: str) -> str:
    """基于领域知识消解歧义"""
    for abbr, full_name in DOMAIN_KNOWLEDGE.items():
        if abbr in query:
            # 如果查询中包含缩写，补充完整名称
            query = query.replace(abbr, f"{abbr} ({full_name})")

    return query
```

---

### 4. 上下文补充 (Context Enrichment)

**目标：** 补充查询中隐含的上下文信息

**上下文类型：**

1. **领域上下文**：查询所属的技术领域
2. **任务上下文**：用户正在进行的任务
3. **历史上下文**：用户之前的查询历史
4. **环境上下文**：用户的技术栈、经验水平

**上下文补充方法：**

```python
def enrich_context(query: str, user_context: dict) -> dict:
    """补充查询上下文"""
    enriched = {
        "original_query": query,
        "domain": user_context.get("domain", "general"),
        "task": user_context.get("current_task", "unknown"),
        "history": user_context.get("query_history", []),
        "tech_stack": user_context.get("tech_stack", []),
        "experience_level": user_context.get("experience", "intermediate")
    }

    return enriched
```

---

## 2025-2026 创新：UniRAG 统一查询理解框架

### UniRAG 简介

**UniRAG** 是 ACL 2025 提出的统一查询理解框架，支持多模态查询（文本、图像、音频）的统一理解。

**核心思想：**

1. **统一表示**：将不同模态的查询映射到统一语义空间
2. **跨模态检索**：支持文本查询检索图像文档，反之亦然
3. **意图对齐**：确保查询意图在模态转换中保持一致

**架构：**

```
用户查询（文本/图像/音频）
    ↓
模态编码器（Text/Image/Audio Encoder）
    ↓
统一语义空间（Unified Semantic Space）
    ↓
意图理解模块（Intent Understanding）
    ↓
查询表示（Query Representation）
```

**引用来源：**
- [UniRAG: Universal Retrieval Augmentation](https://arxiv.org/abs/2405.10311) - ACL 2025

---

### UniRAG 在 RAG 中的应用

**场景 1：图文混合查询**

用户上传一张架构图，问："这个架构如何优化？"

```python
# 伪代码
def unirag_query_understanding(text_query: str, image: Image) -> dict:
    """UniRAG 查询理解"""
    # 1. 编码文本和图像
    text_embedding = text_encoder(text_query)
    image_embedding = image_encoder(image)

    # 2. 融合到统一语义空间
    unified_embedding = fuse(text_embedding, image_embedding)

    # 3. 意图理解
    intent = intent_detector(unified_embedding)

    # 4. 生成查询表示
    query_representation = {
        "text": text_query,
        "image": image,
        "unified_embedding": unified_embedding,
        "intent": intent
    }

    return query_representation
```

**场景 2：跨模态检索**

用户用文本查询："Transformer 架构图"，检索图像文档。

```python
# 伪代码
def cross_modal_retrieval(text_query: str, image_docs: list) -> list:
    """跨模态检索"""
    # 1. 文本查询编码
    text_embedding = text_encoder(text_query)

    # 2. 图像文档编码
    image_embeddings = [image_encoder(img) for img in image_docs]

    # 3. 在统一语义空间中计算相似度
    similarities = [
        cosine_similarity(text_embedding, img_emb)
        for img_emb in image_embeddings
    ]

    # 4. 返回最相似的图像
    return sorted(zip(image_docs, similarities), key=lambda x: x[1], reverse=True)
```

---

## 查询理解的完整流程

### 流程图

```
用户原始查询
    ↓
1. 意图识别
    ↓
2. 实体提取
    ↓
3. 歧义消解
    ↓
4. 上下文补充
    ↓
查询理解结果
```

### 完整实现

```python
from dataclasses import dataclass
from typing import List, Dict, Optional

@dataclass
class QueryUnderstanding:
    """查询理解结果"""
    original_query: str
    intent: str
    entities: List[Dict[str, str]]
    resolved_query: str
    context: Dict[str, any]

def understand_query(
    query: str,
    user_context: Optional[Dict] = None
) -> QueryUnderstanding:
    """完整的查询理解流程"""
    if user_context is None:
        user_context = {}

    # 1. 意图识别
    intent = detect_intent_hybrid(query)

    # 2. 实体提取
    entities = extract_entities_llm(query)

    # 3. 歧义消解
    resolved_query = resolve_ambiguity_domain(query)
    resolved_query = resolve_ambiguity_context(resolved_query, user_context)

    # 4. 上下文补充
    enriched_context = enrich_context(resolved_query, user_context)

    # 5. 构建查询理解结果
    understanding = QueryUnderstanding(
        original_query=query,
        intent=intent,
        entities=entities,
        resolved_query=resolved_query,
        context=enriched_context
    )

    return understanding
```

---

## 查询理解在 RAG 中的应用

### 应用 1：根据意图选择检索策略

```python
def select_retrieval_strategy(understanding: QueryUnderstanding) -> str:
    """根据意图选择检索策略"""
    intent = understanding.intent

    if intent == "concept":
        return "hyde"  # 概念解释用 HyDE
    elif intent == "how-to":
        return "rewrite"  # 操作指导用查询改写
    elif intent == "comparison":
        return "decompose"  # 对比分析用查询分解
    elif intent == "fact":
        return "direct"  # 事实查询直接检索
    else:
        return "multi-query"  # 探索式搜索用多查询生成
```

### 应用 2：根据实体过滤文档

```python
def filter_docs_by_entities(
    docs: List[Document],
    entities: List[Dict[str, str]]
) -> List[Document]:
    """根据实体过滤文档"""
    entity_texts = [e["text"] for e in entities]

    filtered_docs = []
    for doc in docs:
        # 如果文档包含任何实体，保留
        if any(entity in doc.page_content for entity in entity_texts):
            filtered_docs.append(doc)

    return filtered_docs
```

### 应用 3：根据上下文调整检索参数

```python
def adjust_retrieval_params(understanding: QueryUnderstanding) -> dict:
    """根据上下文调整检索参数"""
    params = {"k": 5}  # 默认返回 5 个文档

    # 如果是探索式搜索，增加返回数量
    if understanding.intent == "exploratory":
        params["k"] = 10

    # 如果是事实查询，减少返回数量
    if understanding.intent == "fact":
        params["k"] = 3

    # 如果用户经验水平高，返回更技术性的文档
    if understanding.context.get("experience_level") == "expert":
        params["filter"] = {"level": "advanced"}

    return params
```

---

## 评估查询理解的效果

### 评估指标

1. **意图识别准确率**：正确识别意图的比例
2. **实体提取 F1 分数**：实体提取的准确率和召回率
3. **歧义消解准确率**：正确消解歧义的比例
4. **端到端检索质量**：查询理解后的检索效果

### 评估方法

```python
def evaluate_query_understanding(
    test_queries: List[Dict],
    understanding_func
) -> Dict[str, float]:
    """评估查询理解效果"""
    correct_intent = 0
    total_queries = len(test_queries)

    for test_case in test_queries:
        query = test_case["query"]
        expected_intent = test_case["intent"]

        understanding = understanding_func(query)

        if understanding.intent == expected_intent:
            correct_intent += 1

    intent_accuracy = correct_intent / total_queries

    return {
        "intent_accuracy": intent_accuracy
    }
```

---

## 总结

### 关键要点

1. **查询理解是基础**：是查询处理的第一步，为后续优化提供基础
2. **四大核心任务**：意图识别、实体提取、歧义消解、上下文补充
3. **混合方法最优**：规则 + LLM，平衡成本和准确率
4. **2025-2026 创新**：UniRAG 支持多模态查询理解
5. **RAG 应用广泛**：根据理解结果选择检索策略、过滤文档、调整参数

### 实战建议

1. **从简单开始**：先实现基于规则的意图识别
2. **逐步优化**：根据实际效果决定是否引入 LLM
3. **关注成本**：LLM 调用成本较高，优先用于复杂查询
4. **持续评估**：定期评估查询理解的准确率，持续优化

---

**记住：** 查询理解不是孤立的技术，而是整个查询处理流程的基础。好的查询理解能够显著提升后续查询转换和检索的效果。

---

**引用来源汇总：**
- [UniRAG: Universal Retrieval Augmentation](https://arxiv.org/abs/2405.10311) - ACL 2025
