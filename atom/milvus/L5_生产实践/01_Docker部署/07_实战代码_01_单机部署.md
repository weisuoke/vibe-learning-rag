# 实战代码1：单机部署

> 完整的 Milvus 单机部署示例，包含配置、启动、验证和测试

---

## 概述

本文提供完整的单机部署示例，适合：
- 本地开发环境
- 小规模生产环境（< 100万向量，QPS < 1000）
- 原型验证和测试

---

## 1. 完整的 docker-compose.yml

```yaml
version: '3.8'

services:
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: milvus-etcd
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - etcd_data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - milvus
    restart: unless-stopped

  minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    container_name: milvus-minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - milvus
    restart: unless-stopped

  milvus:
    image: milvusdb/milvus:v2.4.0
    container_name: milvus-standalone
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
      LOG_LEVEL: info
      CACHE_SIZE: 4
    volumes:
      - milvus_data:/var/lib/milvus
      - ./logs:/var/log/milvus
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 90s
    networks:
      - milvus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

networks:
  milvus:
    driver: bridge

volumes:
  etcd_data:
    driver: local
  minio_data:
    driver: local
  milvus_data:
    driver: local
```

---

## 2. 部署步骤

### 2.1 准备工作

```bash
# 1. 创建项目目录
mkdir -p ~/milvus-standalone
cd ~/milvus-standalone

# 2. 创建日志目录
mkdir -p logs

# 3. 保存 docker-compose.yml
# 将上面的配置保存为 docker-compose.yml

# 4. 验证配置文件
docker-compose config
```

### 2.2 启动服务

```bash
# 启动所有服务
docker-compose up -d

# 查看启动日志
docker-compose logs -f

# 等待服务就绪（约 60-90 秒）
# 看到 "Milvus Proxy successfully started" 表示启动成功
```

### 2.3 验证部署

```bash
# 查看服务状态
docker-compose ps

# 预期输出：
# NAME                COMMAND                  STATUS
# milvus-etcd         "etcd -advertise-cli…"   Up (healthy)
# milvus-minio        "/usr/bin/docker-ent…"   Up (healthy)
# milvus-standalone   "milvus run standalone"  Up (healthy)

# 查看 Milvus 日志
docker-compose logs milvus | tail -20

# 检查端口监听
netstat -an | grep 19530
# 或
lsof -i :19530
```

---

## 3. Python 验证脚本

### 3.1 安装依赖

```bash
# 安装 pymilvus
pip install pymilvus

# 或使用 uv
uv add pymilvus
```

### 3.2 连接测试

```python
"""
验证 Milvus 连接
"""
from pymilvus import connections, utility

def test_connection():
    """测试 Milvus 连接"""
    try:
        # 连接到 Milvus
        connections.connect(
            alias="default",
            host="localhost",
            port="19530"
        )

        # 获取服务器版本
        version = utility.get_server_version()
        print(f"✅ 连接成功！")
        print(f"Milvus 版本: {version}")

        # 断开连接
        connections.disconnect("default")

        return True

    except Exception as e:
        print(f"❌ 连接失败: {e}")
        return False

if __name__ == "__main__":
    test_connection()
```

**运行测试**：

```bash
python test_connection.py

# 预期输出：
# ✅ 连接成功！
# Milvus 版本: v2.4.0
```

---

## 4. 完整的 RAG 示例

### 4.1 创建 Collection

```python
"""
创建 Milvus Collection 用于 RAG
"""
from pymilvus import (
    connections,
    Collection,
    CollectionSchema,
    FieldSchema,
    DataType,
    utility
)

def create_rag_collection():
    """创建 RAG Collection"""

    # 1. 连接到 Milvus
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    # 2. 定义 Collection schema
    collection_name = "rag_documents"

    # 检查 Collection 是否已存在
    if utility.has_collection(collection_name):
        print(f"Collection '{collection_name}' 已存在，删除后重建")
        utility.drop_collection(collection_name)

    # 定义字段
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384),
        FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=512),
    ]

    # 创建 schema
    schema = CollectionSchema(
        fields=fields,
        description="RAG document collection"
    )

    # 3. 创建 Collection
    collection = Collection(
        name=collection_name,
        schema=schema
    )

    print(f"✅ Collection '{collection_name}' 创建成功")
    print(f"字段: {[field.name for field in fields]}")

    return collection

if __name__ == "__main__":
    collection = create_rag_collection()
```

### 4.2 插入数据

```python
"""
插入文档数据到 Milvus
"""
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import numpy as np

def insert_documents():
    """插入文档数据"""

    # 1. 连接到 Milvus
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    # 2. 获取 Collection
    collection = Collection("rag_documents")

    # 3. 准备文档数据
    documents = [
        {
            "text": "Milvus 是一个开源的向量数据库，专为 AI 应用设计。",
            "source": "milvus_intro.txt"
        },
        {
            "text": "Docker 是一个容器化平台，可以快速部署应用。",
            "source": "docker_intro.txt"
        },
        {
            "text": "RAG 是检索增强生成，结合了检索和生成两种技术。",
            "source": "rag_intro.txt"
        },
        {
            "text": "向量检索是通过计算向量相似度来查找相关文档。",
            "source": "vector_search.txt"
        },
        {
            "text": "Embedding 是将文本转换为向量的技术。",
            "source": "embedding.txt"
        }
    ]

    # 4. 生成 embeddings
    print("生成 embeddings...")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    texts = [doc["text"] for doc in documents]
    embeddings = model.encode(texts)

    # 5. 准备插入数据
    data = [
        texts,
        embeddings.tolist(),
        [doc["source"] for doc in documents]
    ]

    # 6. 插入数据
    print("插入数据...")
    insert_result = collection.insert(data)

    # 7. 刷新数据（确保数据持久化）
    collection.flush()

    print(f"✅ 插入 {len(documents)} 条文档")
    print(f"插入的 ID: {insert_result.primary_keys[:5]}...")

    return collection

if __name__ == "__main__":
    insert_documents()
```

### 4.3 创建索引

```python
"""
为 Collection 创建索引
"""
from pymilvus import connections, Collection

def create_index():
    """创建向量索引"""

    # 1. 连接到 Milvus
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    # 2. 获取 Collection
    collection = Collection("rag_documents")

    # 3. 定义索引参数
    index_params = {
        "metric_type": "L2",
        "index_type": "IVF_FLAT",
        "params": {"nlist": 128}
    }

    # 4. 创建索引
    print("创建索引...")
    collection.create_index(
        field_name="embedding",
        index_params=index_params
    )

    print("✅ 索引创建成功")

    # 5. 加载 Collection 到内存
    print("加载 Collection...")
    collection.load()

    print("✅ Collection 已加载到内存")

    return collection

if __name__ == "__main__":
    create_index()
```

### 4.4 向量检索

```python
"""
执行向量检索
"""
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer

def search_documents(query_text, top_k=3):
    """检索相关文档"""

    # 1. 连接到 Milvus
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    # 2. 获取 Collection
    collection = Collection("rag_documents")

    # 3. 生成查询向量
    print(f"查询: {query_text}")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    query_embedding = model.encode([query_text])

    # 4. 定义搜索参数
    search_params = {
        "metric_type": "L2",
        "params": {"nprobe": 10}
    }

    # 5. 执行搜索
    results = collection.search(
        data=query_embedding.tolist(),
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["text", "source"]
    )

    # 6. 输出结果
    print(f"\n找到 {len(results[0])} 个相关文档：\n")

    for i, hit in enumerate(results[0]):
        print(f"--- 结果 {i+1} ---")
        print(f"相似度分数: {hit.distance:.4f}")
        print(f"文本: {hit.entity.get('text')}")
        print(f"来源: {hit.entity.get('source')}")
        print()

    return results

if __name__ == "__main__":
    # 测试查询
    search_documents("什么是向量数据库？")
    search_documents("如何部署应用？")
```

### 4.5 完整的 RAG 流程

```python
"""
完整的 RAG 流程示例
"""
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import openai
import os

def rag_query(question, top_k=3):
    """RAG 查询流程"""

    # 1. 连接到 Milvus
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    # 2. 获取 Collection
    collection = Collection("rag_documents")

    # 3. 向量检索
    print(f"问题: {question}\n")
    print("步骤1: 向量检索...")

    model = SentenceTransformer('all-MiniLM-L6-v2')
    query_embedding = model.encode([question])

    search_params = {
        "metric_type": "L2",
        "params": {"nprobe": 10}
    }

    results = collection.search(
        data=query_embedding.tolist(),
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["text", "source"]
    )

    # 4. 提取上下文
    contexts = []
    for hit in results[0]:
        contexts.append(hit.entity.get('text'))

    context_text = "\n".join(contexts)
    print(f"检索到 {len(contexts)} 个相关文档\n")

    # 5. 构建 Prompt
    prompt = f"""基于以下上下文回答问题：

上下文：
{context_text}

问题：{question}

回答："""

    print("步骤2: 生成回答...")

    # 6. 调用 LLM（需要配置 OpenAI API Key）
    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "你是一个helpful的助手。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        answer = response.choices[0].message.content

        print(f"\n回答:\n{answer}\n")

        # 7. 输出引用来源
        print("引用来源:")
        for i, hit in enumerate(results[0]):
            print(f"{i+1}. {hit.entity.get('source')} (相似度: {hit.distance:.4f})")

        return answer

    except Exception as e:
        print(f"LLM 调用失败: {e}")
        print("返回检索到的上下文:")
        return context_text

if __name__ == "__main__":
    # 设置 OpenAI API Key
    # export OPENAI_API_KEY=your_key_here

    # 测试 RAG 查询
    rag_query("Milvus 是什么？")
```

---

## 5. 管理脚本

### 5.1 启动脚本

```bash
#!/bin/bash
# start_milvus.sh

echo "启动 Milvus 单机部署..."

# 检查 Docker 是否运行
if ! docker info > /dev/null 2>&1; then
    echo "❌ Docker 未运行，请先启动 Docker"
    exit 1
fi

# 启动服务
docker-compose up -d

# 等待服务就绪
echo "等待服务启动..."
sleep 30

# 检查服务状态
docker-compose ps

# 检查健康状态
echo ""
echo "检查服务健康状态..."
for service in etcd minio milvus; do
    health=$(docker inspect --format='{{.State.Health.Status}}' milvus-$service 2>/dev/null || echo "no healthcheck")
    echo "$service: $health"
done

echo ""
echo "✅ Milvus 启动完成！"
echo "gRPC 端口: 19530"
echo "Metrics 端口: 9091"
echo "MinIO Console: http://localhost:9001"
```

### 5.2 停止脚本

```bash
#!/bin/bash
# stop_milvus.sh

echo "停止 Milvus..."

# 停止服务
docker-compose stop

echo "✅ Milvus 已停止"
echo "数据已保留在 volumes 中"
echo ""
echo "如需完全删除（包括数据），运行："
echo "docker-compose down -v"
```

### 5.3 备份脚本

```bash
#!/bin/bash
# backup_milvus.sh

BACKUP_DIR="./backups"
DATE=$(date +%Y%m%d_%H%M%S)

echo "备份 Milvus 数据..."

# 创建备份目录
mkdir -p $BACKUP_DIR

# 停止 Milvus（可选，确保数据一致性）
echo "停止 Milvus..."
docker-compose stop milvus

# 备份 etcd
echo "备份 etcd..."
docker run --rm \
  -v milvus-standalone_etcd_data:/data \
  -v $(pwd)/$BACKUP_DIR:/backup \
  ubuntu tar czf /backup/etcd_$DATE.tar.gz /data

# 备份 MinIO
echo "备份 MinIO..."
docker run --rm \
  -v milvus-standalone_minio_data:/data \
  -v $(pwd)/$BACKUP_DIR:/backup \
  ubuntu tar czf /backup/minio_$DATE.tar.gz /data

# 备份 Milvus
echo "备份 Milvus..."
docker run --rm \
  -v milvus-standalone_milvus_data:/data \
  -v $(pwd)/$BACKUP_DIR:/backup \
  ubuntu tar czf /backup/milvus_$DATE.tar.gz /data

# 重启 Milvus
echo "重启 Milvus..."
docker-compose start milvus

echo "✅ 备份完成！"
echo "备份文件位置: $BACKUP_DIR"
ls -lh $BACKUP_DIR/*$DATE*
```

### 5.4 监控脚本

```bash
#!/bin/bash
# monitor_milvus.sh

echo "Milvus 监控信息"
echo "================"
echo ""

# 服务状态
echo "1. 服务状态:"
docker-compose ps
echo ""

# 资源使用
echo "2. 资源使用:"
docker stats --no-stream milvus-standalone milvus-etcd milvus-minio
echo ""

# 磁盘使用
echo "3. 磁盘使用:"
docker system df -v | grep milvus
echo ""

# 日志最后 10 行
echo "4. 最近日志:"
docker-compose logs --tail=10 milvus
echo ""

# Metrics
echo "5. Milvus Metrics:"
curl -s http://localhost:9091/metrics | grep -E "milvus_proxy_req_count|milvus_query_node_search_latency"
```

---

## 6. 故障排查

### 6.1 常见问题

**问题1：Milvus 启动失败**

```bash
# 查看日志
docker-compose logs milvus

# 常见原因：
# 1. etcd 或 MinIO 未就绪
# 2. 端口被占用
# 3. 内存不足
```

**解决方案**：

```bash
# 检查依赖服务
docker-compose logs etcd
docker-compose logs minio

# 检查端口
lsof -i :19530
lsof -i :9000

# 检查内存
free -h
```

**问题2：连接被拒绝**

```bash
# 错误信息
# Connection refused: localhost:19530
```

**解决方案**：

```bash
# 1. 检查 Milvus 是否启动
docker-compose ps milvus

# 2. 检查健康状态
docker inspect milvus-standalone | grep Health -A 10

# 3. 等待更长时间（首次启动需要 90 秒）
sleep 60
```

**问题3：数据丢失**

```bash
# 检查 volumes 是否存在
docker volume ls | grep milvus

# 检查 volumes 数据
docker volume inspect milvus-standalone_milvus_data
```

### 6.2 调试命令

```bash
# 进入 Milvus 容器
docker-compose exec milvus bash

# 查看 Milvus 配置
docker-compose exec milvus cat /milvus/configs/milvus.yaml

# 查看进程
docker-compose exec milvus ps aux

# 查看网络
docker network inspect milvus-standalone_milvus

# 测试网络连通性
docker-compose exec milvus ping etcd
docker-compose exec milvus ping minio
```

---

## 7. 性能测试

### 7.1 基准测试脚本

```python
"""
Milvus 性能基准测试
"""
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import time
import numpy as np

def benchmark_insert(collection, num_vectors=10000):
    """测试插入性能"""
    print(f"测试插入 {num_vectors} 个向量...")

    # 生成随机数据
    model = SentenceTransformer('all-MiniLM-L6-v2')
    texts = [f"Document {i}" for i in range(num_vectors)]

    start = time.time()

    # 批量插入
    batch_size = 1000
    for i in range(0, num_vectors, batch_size):
        batch_texts = texts[i:i+batch_size]
        embeddings = model.encode(batch_texts)

        data = [
            batch_texts,
            embeddings.tolist(),
            [f"source_{j}" for j in range(len(batch_texts))]
        ]

        collection.insert(data)

    collection.flush()
    elapsed = time.time() - start

    print(f"✅ 插入完成")
    print(f"总时间: {elapsed:.2f}s")
    print(f"吞吐量: {num_vectors / elapsed:.2f} vectors/s")

def benchmark_search(collection, num_queries=1000):
    """测试检索性能"""
    print(f"\n测试检索 {num_queries} 次...")

    model = SentenceTransformer('all-MiniLM-L6-v2')
    query_texts = [f"Query {i}" for i in range(num_queries)]
    query_embeddings = model.encode(query_texts)

    search_params = {
        "metric_type": "L2",
        "params": {"nprobe": 10}
    }

    latencies = []

    for embedding in query_embeddings:
        start = time.time()

        collection.search(
            data=[embedding.tolist()],
            anns_field="embedding",
            param=search_params,
            limit=10
        )

        latency = (time.time() - start) * 1000  # ms
        latencies.append(latency)

    latencies = np.array(latencies)

    print(f"✅ 检索完成")
    print(f"平均延迟: {latencies.mean():.2f}ms")
    print(f"P50 延迟: {np.percentile(latencies, 50):.2f}ms")
    print(f"P95 延迟: {np.percentile(latencies, 95):.2f}ms")
    print(f"P99 延迟: {np.percentile(latencies, 99):.2f}ms")
    print(f"QPS: {1000 / latencies.mean():.2f}")

if __name__ == "__main__":
    connections.connect(host="localhost", port="19530")
    collection = Collection("rag_documents")

    benchmark_insert(collection, num_vectors=10000)
    benchmark_search(collection, num_queries=1000)
```

---

## 8. 清理和重置

### 8.1 清理脚本

```bash
#!/bin/bash
# cleanup_milvus.sh

echo "清理 Milvus..."

# 停止并删除容器
docker-compose down

# 删除 volumes（⚠️ 会删除所有数据）
read -p "是否删除所有数据？(y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    docker-compose down -v
    echo "✅ 数据已删除"
else
    echo "✅ 数据已保留"
fi

# 清理日志
rm -rf logs/*

echo "✅ 清理完成"
```

---

## 关键要点

1. **完整的配置文件**
   - 包含健康检查
   - 配置资源限制
   - 使用 Named Volumes

2. **完整的 RAG 流程**
   - 创建 Collection
   - 插入数据
   - 创建索引
   - 向量检索
   - LLM 生成

3. **管理脚本**
   - 启动/停止脚本
   - 备份脚本
   - 监控脚本

4. **故障排查**
   - 常见问题和解决方案
   - 调试命令

5. **性能测试**
   - 插入性能
   - 检索性能
   - 延迟分析

---

## 下一步

完成单机部署后，可以学习：
- **实战代码2**：分布式部署
- **实战代码3**：生产环境配置
