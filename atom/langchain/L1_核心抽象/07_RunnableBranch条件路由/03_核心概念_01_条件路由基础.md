# 核心概念1：条件路由基础

深入理解 RunnableBranch 的条件路由机制。

---

## 1.1 什么是条件路由？

### 定义

**条件路由（Conditional Routing）**：根据输入的特征或状态，动态选择不同的处理路径。

在编程中，条件路由是**控制流**的一种形式：
- **顺序执行**：代码按顺序执行（A → B → C）
- **条件执行**：根据条件选择路径（if A then B else C）
- **循环执行**：重复执行代码（while/for）

RunnableBranch 实现的是**条件执行**。

### 在 AI Agent 中的作用

AI Agent 需要处理多样化的输入：
- 用户查询："帮我写一段 Python 代码"
- 用户查询："今天天气怎么样？"
- 用户查询："我想退款"

每种查询需要不同的处理器：
- 代码问题 → 代码生成器
- 天气问题 → 天气 API 调用
- 退款问题 → 客服流程

**条件路由**让 Agent 能够智能地选择合适的处理器。

---

## 1.2 RunnableBranch 类定义

### 类签名

```python
from langchain_core.runnables import RunnableBranch
from typing import Callable, Union, Sequence, Tuple

class RunnableBranch(RunnableSerializable[Input, Output]):
    """
    根据条件动态路由到不同的 Runnable

    继承自 RunnableSerializable，支持：
    - invoke/ainvoke：单次执行
    - batch/abatch：批量执行
    - stream/astream：流式执行
    - 序列化/反序列化
    """

    def __init__(
        self,
        *branches: Union[
            Tuple[
                Union[Callable[[Input], bool], Runnable[Input, bool]],
                Runnable[Input, Output]
            ],
            Runnable[Input, Output]
        ]
    ):
        """
        初始化 RunnableBranch

        参数：
            *branches: 可变参数，包含：
                - 多个 (condition, runnable) 元组
                - 最后一个参数是默认 runnable
        """
        ...
```

### 类型参数

- **Input**：输入类型（泛型）
- **Output**：输出类型（泛型）

```python
# 示例：明确类型
from langchain_core.runnables import RunnableBranch, RunnableLambda

# Input = str, Output = str
branch: RunnableBranch[str, str] = RunnableBranch(
    (lambda x: "code" in x, RunnableLambda(lambda x: f"Code: {x}")),
    (lambda x: "math" in x, RunnableLambda(lambda x: f"Math: {x}")),
    RunnableLambda(lambda x: f"General: {x}")
)
```

### 继承关系

```
Runnable (抽象基类)
    ↓
RunnableSerializable (支持序列化)
    ↓
RunnableBranch (条件路由)
```

**继承的能力**：
- ✅ 支持 LCEL 管道操作符 `|`
- ✅ 支持 `invoke`/`ainvoke`
- ✅ 支持 `batch`/`abatch`
- ✅ 支持 `stream`/`astream`
- ✅ 支持 `RunnableConfig` 传递
- ✅ 支持序列化（保存/加载）

---

## 1.3 初始化参数详解

### 参数结构

```python
RunnableBranch(
    (condition1, branch1),  # 第一个条件-分支对
    (condition2, branch2),  # 第二个条件-分支对
    ...                     # 更多条件-分支对
    default_branch          # 默认分支（必须）
)
```

### 条件（Condition）

**类型**：`Union[Callable[[Input], bool], Runnable[Input, bool]]`

**两种形式**：

#### 形式1：Lambda 函数

```python
# 简单条件
condition = lambda x: "urgent" in x.lower()

# 复杂条件
condition = lambda x: (
    "urgent" in x.lower() and
    len(x) > 10 and
    x.startswith("HELP")
)

# 使用
branch = RunnableBranch(
    (condition, urgent_handler),
    default_handler
)
```

#### 形式2：Runnable

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

# 使用 LLM 作为条件
classifier = (
    ChatPromptTemplate.from_template(
        "Is this message urgent? Answer only 'yes' or 'no': {text}"
    )
    | ChatOpenAI(model="gpt-4o-mini")
    | RunnableLambda(lambda x: "yes" in x.content.lower())
)

# 使用
branch = RunnableBranch(
    (classifier, urgent_handler),
    default_handler
)
```

**何时使用 Runnable 条件**：
- 需要 LLM 判断（语义分类）
- 需要外部 API 调用（数据库查询）
- 需要复杂的预处理

### 分支（Branch）

**类型**：`Runnable[Input, Output]`

**可以是任何 Runnable**：

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnableParallel

# 1. ChatModel
branch1 = ChatOpenAI(model="gpt-4")

# 2. Chain
branch2 = ChatPromptTemplate.from_template("...") | ChatOpenAI()

# 3. Lambda
branch3 = RunnableLambda(lambda x: process(x))

# 4. 嵌套 Branch
branch4 = RunnableBranch(...)

# 5. Parallel
branch5 = RunnableParallel(...)

# 使用
branch = RunnableBranch(
    (condition1, branch1),
    (condition2, branch2),
    branch3  # 默认
)
```

### 默认分支（Default Branch）

**必须提供**：最后一个参数必须是默认分支

```python
# ✅ 正确
branch = RunnableBranch(
    (condition1, branch1),
    (condition2, branch2),
    default_branch  # 必须
)

# ❌ 错误：缺少默认分支
branch = RunnableBranch(
    (condition1, branch1),
    (condition2, branch2)
)  # TypeError: RunnableBranch requires a default branch
```

**默认分支的作用**：
- 兜底处理：所有条件都不匹配时执行
- 错误处理：捕获意外情况
- 通用处理：处理常规情况

**最佳实践**：

```python
# 方案1：通用处理器
default_branch = general_handler

# 方案2：错误处理
default_branch = RunnableLambda(
    lambda x: {"error": "No matching condition", "input": x}
)

# 方案3：日志 + 兜底
def default_handler(x):
    logger.warning(f"No condition matched for input: {x}")
    return fallback_response(x)

default_branch = RunnableLambda(default_handler)
```

---

## 1.4 条件函数设计

### 设计原则

#### 原则1：返回布尔值

```python
# ✅ 正确：返回 bool
condition = lambda x: "urgent" in x

# ❌ 错误：返回字符串
condition = lambda x: "urgent" if "urgent" in x else "normal"

# ❌ 错误：返回 None
condition = lambda x: print("checking...")
```

#### 原则2：无副作用（推荐）

```python
# ✅ 推荐：纯函数
condition = lambda x: x["score"] > 0.8

# ⚠️ 不推荐：有副作用
def condition_with_side_effect(x):
    logger.info(f"Checking: {x}")  # 副作用
    return x["score"] > 0.8

# 副作用会在每次评估时触发，可能导致意外行为
```

#### 原则3：快速执行

```python
# ✅ 快速：简单判断
condition = lambda x: x["type"] == "urgent"

# ⚠️ 慢：复杂计算
def slow_condition(x):
    # 避免在条件中做复杂计算
    result = expensive_computation(x)
    return result > threshold

# 建议：预先计算，条件只做判断
preprocessor = RunnableLambda(lambda x: {
    **x,
    "computed_score": expensive_computation(x)
})

condition = lambda x: x["computed_score"] > threshold

chain = preprocessor | RunnableBranch(
    (condition, handler),
    default_handler
)
```

### 常见条件模式

#### 模式1：关键词匹配

```python
# 单关键词
condition = lambda x: "urgent" in x.lower()

# 多关键词（任一匹配）
keywords = ["urgent", "emergency", "critical"]
condition = lambda x: any(kw in x.lower() for kw in keywords)

# 多关键词（全部匹配）
condition = lambda x: all(kw in x.lower() for kw in keywords)
```

#### 模式2：类型检查

```python
# 类型判断
condition = lambda x: isinstance(x, dict)

# 字段存在性
condition = lambda x: "user_id" in x

# 字段值判断
condition = lambda x: x.get("role") == "admin"
```

#### 模式3：阈值判断

```python
# 数值阈值
condition = lambda x: x["score"] > 0.8

# 长度阈值
condition = lambda x: len(x["text"]) > 1000

# 时间阈值
from datetime import datetime, timedelta
condition = lambda x: (
    datetime.now() - x["created_at"] < timedelta(hours=1)
)
```

#### 模式4：正则表达式

```python
import re

# 邮箱格式
email_pattern = re.compile(r'^[\w\.-]+@[\w\.-]+\.\w+$')
condition = lambda x: bool(email_pattern.match(x))

# URL 格式
url_pattern = re.compile(r'^https?://')
condition = lambda x: bool(url_pattern.match(x))
```

#### 模式5：组合条件

```python
# AND 组合
condition = lambda x: (
    "urgent" in x.lower() and
    x.get("priority") == "high" and
    len(x["text"]) > 10
)

# OR 组合
condition = lambda x: (
    "urgent" in x.lower() or
    x.get("priority") == "high" or
    x.get("user_role") == "vip"
)

# 复杂组合
condition = lambda x: (
    ("urgent" in x.lower() or x.get("priority") == "high") and
    x.get("user_role") in ["admin", "vip"]
)
```

---

## 1.5 默认分支处理

### 默认分支的三种策略

#### 策略1：通用处理器

```python
# 使用通用 LLM 处理
default_branch = ChatOpenAI(model="gpt-4o-mini")

# 使用通用 Chain
default_branch = (
    ChatPromptTemplate.from_template("Answer: {question}")
    | ChatOpenAI()
)
```

#### 策略2：错误处理

```python
# 返回错误信息
default_branch = RunnableLambda(
    lambda x: {
        "error": "No matching handler found",
        "input": x,
        "suggestion": "Please rephrase your question"
    }
)

# 抛出异常
def error_handler(x):
    raise ValueError(f"No handler for input: {x}")

default_branch = RunnableLambda(error_handler)
```

#### 策略3：降级处理

```python
# 使用更便宜的模型
default_branch = ChatOpenAI(model="gpt-4o-mini")  # 便宜

# 使用缓存的响应
def cached_handler(x):
    # 尝试从缓存获取
    cached = cache.get(x)
    if cached:
        return cached
    # 否则使用简单处理
    return simple_response(x)

default_branch = RunnableLambda(cached_handler)
```

### 默认分支的最佳实践

```python
# ✅ 推荐：记录日志 + 兜底处理
import logging

logger = logging.getLogger(__name__)

def smart_default_handler(x):
    # 1. 记录日志
    logger.warning(
        f"No specific handler matched",
        extra={"input": x, "timestamp": datetime.now()}
    )

    # 2. 尝试通用处理
    try:
        return general_handler.invoke(x)
    except Exception as e:
        # 3. 失败时返回友好错误
        logger.error(f"Default handler failed: {e}")
        return {
            "error": "Unable to process request",
            "message": "Please try again or contact support"
        }

default_branch = RunnableLambda(smart_default_handler)
```

---

## 1.6 类型系统

### 泛型约束

```python
from typing import TypeVar
from langchain_core.runnables import RunnableBranch

# 定义类型变量
Input = TypeVar('Input')
Output = TypeVar('Output')

# 类型安全的 Branch
branch: RunnableBranch[dict, str] = RunnableBranch(
    (lambda x: x["type"] == "A", handler_a),  # handler_a: Runnable[dict, str]
    (lambda x: x["type"] == "B", handler_b),  # handler_b: Runnable[dict, str]
    default_handler                            # default_handler: Runnable[dict, str]
)

# 类型检查
result: str = branch.invoke({"type": "A", "data": "..."})
```

### 类型不匹配的处理

```python
# ❌ 类型不匹配
branch: RunnableBranch[str, str] = RunnableBranch(
    (lambda x: "code" in x, code_handler),  # code_handler: Runnable[str, dict]
    default_handler                          # default_handler: Runnable[str, str]
)
# 问题：code_handler 返回 dict，但期望 str

# ✅ 解决方案1：统一输出类型
code_handler_wrapped = code_handler | RunnableLambda(lambda x: str(x))

branch: RunnableBranch[str, str] = RunnableBranch(
    (lambda x: "code" in x, code_handler_wrapped),
    default_handler
)

# ✅ 解决方案2：使用 Union 类型
from typing import Union

branch: RunnableBranch[str, Union[str, dict]] = RunnableBranch(
    (lambda x: "code" in x, code_handler),
    default_handler
)
```

---

## 1.7 在 LangChain 架构中的位置

### 架构层次

```
LangChain 架构
├── 核心抽象层 (langchain-core)
│   ├── Runnable 协议
│   ├── RunnableSerializable
│   ├── RunnableBranch ← 这里
│   ├── RunnableParallel
│   └── RunnableLambda
├── 组件层 (langchain)
│   ├── ChatModel
│   ├── PromptTemplate
│   └── OutputParser
└── 应用层
    ├── Chain
    ├── Agent
    └── LangGraph
```

### 与其他 Runnable 的关系

```python
# RunnableBranch 可以与其他 Runnable 组合

# 1. 与 RunnableParallel 组合
from langchain_core.runnables import RunnableParallel

parallel_branch = RunnableParallel(
    route1=RunnableBranch(...),
    route2=RunnableBranch(...),
)

# 2. 与 RunnableLambda 组合
preprocessor = RunnableLambda(lambda x: preprocess(x))
branch = RunnableBranch(...)
postprocessor = RunnableLambda(lambda x: postprocess(x))

chain = preprocessor | branch | postprocessor

# 3. 与 ChatModel 组合
classifier = ChatPromptTemplate.from_template("...") | ChatOpenAI()
router = RunnableBranch(...)

chain = classifier | router
```

---

## 1.8 实际应用场景

### 场景1：意图识别路由

```python
from langchain_core.runnables import RunnableBranch
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 定义不同意图的处理器
greeting_handler = ChatPromptTemplate.from_template(
    "Respond warmly to: {text}"
) | ChatOpenAI()

question_handler = ChatPromptTemplate.from_template(
    "Answer the question: {text}"
) | ChatOpenAI()

command_handler = ChatPromptTemplate.from_template(
    "Execute command: {text}"
) | ChatOpenAI()

# 意图路由
intent_router = RunnableBranch(
    (lambda x: any(w in x["text"].lower() for w in ["hi", "hello", "hey"]),
     greeting_handler),
    (lambda x: x["text"].strip().endswith("?"),
     question_handler),
    (lambda x: x["text"].lower().startswith(("do", "create", "delete")),
     command_handler),
    question_handler  # 默认当作问题处理
)

# 使用
result = intent_router.invoke({"text": "Hello there!"})
```

### 场景2：优先级路由

```python
# 根据优先级选择不同的处理策略
priority_router = RunnableBranch(
    # 高优先级：使用最好的模型
    (lambda x: x.get("priority") == "high",
     ChatOpenAI(model="gpt-4")),
    # 中优先级：使用标准模型
    (lambda x: x.get("priority") == "medium",
     ChatOpenAI(model="gpt-4o")),
    # 低优先级：使用便宜模型
    ChatOpenAI(model="gpt-4o-mini")
)
```

### 场景3：语言检测路由

```python
# 根据语言选择不同的处理器
language_router = RunnableBranch(
    (lambda x: detect_language(x["text"]) == "zh",
     chinese_handler),
    (lambda x: detect_language(x["text"]) == "en",
     english_handler),
    (lambda x: detect_language(x["text"]) == "ja",
     japanese_handler),
    multilingual_handler  # 默认多语言处理
)
```

### 场景4：内容类型路由

```python
# 根据内容类型选择处理器
content_router = RunnableBranch(
    (lambda x: "```" in x["text"],
     code_handler),  # 包含代码块
    (lambda x: re.search(r'\d+[\+\-\*/]\d+', x["text"]),
     math_handler),  # 包含数学表达式
    (lambda x: len(x["text"]) > 1000,
     long_text_handler),  # 长文本
    general_handler  # 默认通用处理
)
```

---

## 1.9 小结

**RunnableBranch 的核心要素**：

1. **条件函数**：返回布尔值，决定是否执行分支
2. **分支 Runnable**：条件为 True 时执行的处理器
3. **默认分支**：所有条件都不匹配时的兜底处理
4. **顺序评估**：从上到下检查条件，第一个匹配就执行
5. **类型安全**：支持泛型约束，保证类型一致性
6. **可组合性**：与其他 Runnable 无缝集成

**设计原则**：

- ✅ 条件函数简单快速
- ✅ 条件从具体到通用排序
- ✅ 必须提供默认分支
- ✅ 保持类型一致性
- ✅ 记录日志便于调试

**下一步**：学习如何设计复杂的分支条件（核心概念2）。
