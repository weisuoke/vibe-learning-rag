# 实战代码 - 场景1：基准测试与参数对比

## 场景描述

在生产环境部署前，需要对不同索引参数进行基准测试，找到最优配置。本示例展示如何系统地测试和对比不同参数的性能。

---

## 完整代码

```python
"""
索引参数调优 - 基准测试工具

功能：
1. 测试不同索引类型的性能
2. 测试不同参数配置的影响
3. 生成性能对比报告
4. 可视化性能指标

依赖：
pip install pymilvus numpy pandas matplotlib
"""

from pymilvus import (
    connections, Collection, FieldSchema,
    CollectionSchema, DataType, utility
)
import numpy as np
import time
import pandas as pd
from typing import List, Dict, Tuple
import json

# ===== 1. 连接配置 =====
MILVUS_HOST = "localhost"
MILVUS_PORT = "19530"

# ===== 2. 测试数据生成 =====
class TestDataGenerator:
    """测试数据生成器"""

    def __init__(self, num_vectors: int, dim: int):
        self.num_vectors = num_vectors
        self.dim = dim

    def generate_vectors(self) -> List[List[float]]:
        """生成随机向量"""
        print(f"生成 {self.num_vectors:,} 个 {self.dim} 维向量...")
        vectors = np.random.rand(self.num_vectors, self.dim).astype(np.float32)
        return vectors.tolist()

    def generate_queries(self, num_queries: int = 100) -> List[List[float]]:
        """生成查询向量"""
        queries = np.random.rand(num_queries, self.dim).astype(np.float32)
        return queries.tolist()

# ===== 3. Collection 管理 =====
class CollectionManager:
    """Collection 管理器"""

    def __init__(self, collection_name: str, dim: int):
        self.collection_name = collection_name
        self.dim = dim
        self.collection = None

    def create_collection(self):
        """创建 collection"""
        # 删除已存在的 collection
        if utility.has_collection(self.collection_name):
            utility.drop_collection(self.collection_name)
            print(f"删除已存在的 collection: {self.collection_name}")

        # 定义 schema
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.dim)
        ]
        schema = CollectionSchema(fields, description="Benchmark test collection")

        # 创建 collection
        self.collection = Collection(self.collection_name, schema)
        print(f"创建 collection: {self.collection_name}")

        return self.collection

    def insert_data(self, vectors: List[List[float]]):
        """插入数据"""
        print(f"插入 {len(vectors):,} 个向量...")
        start = time.time()
        self.collection.insert([vectors])
        self.collection.flush()
        duration = time.time() - start
        print(f"插入完成，耗时: {duration:.2f}秒")

    def create_index(self, index_params: Dict):
        """创建索引"""
        print(f"创建索引: {index_params['index_type']}")
        start = time.time()
        self.collection.create_index("embedding", index_params)
        duration = time.time() - start
        print(f"索引创建完成，耗时: {duration:.2f}秒")
        return duration

    def load_collection(self):
        """加载 collection"""
        print("加载 collection...")
        self.collection.load()
        print("加载完成")

# ===== 4. 性能测试器 =====
class PerformanceTester:
    """性能测试器"""

    def __init__(self, collection: Collection):
        self.collection = collection

    def test_search_performance(
        self,
        queries: List[List[float]],
        search_params: Dict,
        limit: int = 10,
        warmup: int = 5
    ) -> Dict:
        """
        测试搜索性能

        Args:
            queries: 查询向量列表
            search_params: 搜索参数
            limit: 返回结果数量
            warmup: 预热次数

        Returns:
            性能指标字典
        """
        # 预热
        for i in range(warmup):
            self.collection.search(
                data=[queries[0]],
                anns_field="embedding",
                param=search_params,
                limit=limit
            )

        # 正式测试
        latencies = []

        for query in queries:
            start = time.time()
            results = self.collection.search(
                data=[query],
                anns_field="embedding",
                param=search_params,
                limit=limit
            )
            latency_ms = (time.time() - start) * 1000
            latencies.append(latency_ms)

        # 计算统计指标
        latencies_sorted = sorted(latencies)
        n = len(latencies_sorted)

        metrics = {
            "avg_latency_ms": np.mean(latencies),
            "p50_latency_ms": latencies_sorted[int(n * 0.5)],
            "p95_latency_ms": latencies_sorted[int(n * 0.95)],
            "p99_latency_ms": latencies_sorted[int(n * 0.99)],
            "min_latency_ms": min(latencies),
            "max_latency_ms": max(latencies),
            "qps": 1000 / np.mean(latencies)
        }

        return metrics

    def test_memory_usage(self) -> float:
        """测试内存占用"""
        stats = utility.get_query_segment_info(self.collection.name)
        memory_mb = sum(seg.mem_size for seg in stats) / 1024 / 1024
        return memory_mb

# ===== 5. 基准测试主程序 =====
class BenchmarkRunner:
    """基准测试运行器"""

    def __init__(self, num_vectors: int, dim: int):
        self.num_vectors = num_vectors
        self.dim = dim
        self.results = []

    def run_benchmark(
        self,
        index_configs: List[Dict],
        search_configs: List[Dict],
        num_queries: int = 100
    ):
        """
        运行基准测试

        Args:
            index_configs: 索引配置列表
            search_configs: 搜索配置列表
            num_queries: 查询数量
        """
        # 连接到 Milvus
        connections.connect("default", host=MILVUS_HOST, port=MILVUS_PORT)
        print(f"连接到 Milvus: {MILVUS_HOST}:{MILVUS_PORT}")

        # 生成测试数据
        data_gen = TestDataGenerator(self.num_vectors, self.dim)
        vectors = data_gen.generate_vectors()
        queries = data_gen.generate_queries(num_queries)

        # 测试每个索引配置
        for idx_config in index_configs:
            print("\n" + "=" * 80)
            print(f"测试索引配置: {idx_config['index_type']}")
            print("=" * 80)

            # 创建 collection
            collection_name = f"benchmark_{idx_config['index_type'].lower()}"
            manager = CollectionManager(collection_name, self.dim)
            collection = manager.create_collection()

            # 插入数据
            manager.insert_data(vectors)

            # 创建索引
            build_time = manager.create_index(idx_config)

            # 加载 collection
            manager.load_collection()

            # 测试内存占用
            tester = PerformanceTester(collection)
            memory_mb = tester.test_memory_usage()

            # 测试不同搜索参数
            for search_config in search_configs:
                print(f"\n测试搜索参数: {search_config['params']}")

                # 测试性能
                metrics = tester.test_search_performance(queries, search_config)

                # 记录结果
                result = {
                    "index_type": idx_config['index_type'],
                    "index_params": idx_config['params'],
                    "search_params": search_config['params'],
                    "build_time_s": build_time,
                    "memory_mb": memory_mb,
                    **metrics
                }
                self.results.append(result)

                # 打印结果
                print(f"  平均延迟: {metrics['avg_latency_ms']:.2f}ms")
                print(f"  P95 延迟: {metrics['p95_latency_ms']:.2f}ms")
                print(f"  QPS: {metrics['qps']:.2f}")

            # 清理
            utility.drop_collection(collection_name)

        # 断开连接
        connections.disconnect("default")

    def generate_report(self, output_file: str = "benchmark_report.json"):
        """生成测试报告"""
        # 保存为 JSON
        with open(output_file, 'w') as f:
            json.dump(self.results, f, indent=2)
        print(f"\n测试报告已保存到: {output_file}")

        # 生成 DataFrame
        df = pd.DataFrame(self.results)

        # 打印汇总表
        print("\n" + "=" * 100)
        print("性能对比汇总")
        print("=" * 100)

        summary_cols = [
            'index_type', 'search_params',
            'avg_latency_ms', 'p95_latency_ms',
            'qps', 'memory_mb'
        ]

        print(df[summary_cols].to_string(index=False))

        return df

# ===== 6. 使用示例 =====
def main():
    """主函数"""

    # 测试配置
    NUM_VECTORS = 100_000  # 10万向量
    DIM = 768              # 768维
    NUM_QUERIES = 100      # 100个查询

    # 索引配置
    import math
    nlist = int(2 * math.sqrt(NUM_VECTORS))  # 632

    index_configs = [
        {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": nlist}
        },
        {
            "index_type": "IVF_SQ8",
            "metric_type": "L2",
            "params": {"nlist": nlist}
        },
        {
            "index_type": "HNSW",
            "metric_type": "L2",
            "params": {"M": 16, "efConstruction": 200}
        }
    ]

    # 搜索配置
    search_configs = [
        {
            "metric_type": "L2",
            "params": {"nprobe": 16}  # IVF 系列
        },
        {
            "metric_type": "L2",
            "params": {"nprobe": 32}  # IVF 系列
        },
        {
            "metric_type": "L2",
            "params": {"ef": 128}  # HNSW
        },
        {
            "metric_type": "L2",
            "params": {"ef": 256}  # HNSW
        }
    ]

    # 运行基准测试
    runner = BenchmarkRunner(NUM_VECTORS, DIM)
    runner.run_benchmark(index_configs, search_configs, NUM_QUERIES)

    # 生成报告
    df = runner.generate_report()

    # 找出最优配置
    print("\n" + "=" * 100)
    print("推荐配置")
    print("=" * 100)

    # 按延迟排序
    best_latency = df.loc[df['avg_latency_ms'].idxmin()]
    print(f"\n最低延迟配置:")
    print(f"  索引类型: {best_latency['index_type']}")
    print(f"  搜索参数: {best_latency['search_params']}")
    print(f"  平均延迟: {best_latency['avg_latency_ms']:.2f}ms")

    # 按 QPS 排序
    best_qps = df.loc[df['qps'].idxmax()]
    print(f"\n最高 QPS 配置:")
    print(f"  索引类型: {best_qps['index_type']}")
    print(f"  搜索参数: {best_qps['search_params']}")
    print(f"  QPS: {best_qps['qps']:.2f}")

    # 按内存占用排序
    best_memory = df.loc[df['memory_mb'].idxmin()]
    print(f"\n最低内存配置:")
    print(f"  索引类型: {best_memory['index_type']}")
    print(f"  内存占用: {best_memory['memory_mb']:.2f}MB")

if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
连接到 Milvus: localhost:19530
生成 100,000 个 768 维向量...

================================================================================
测试索引配置: IVF_FLAT
================================================================================
创建 collection: benchmark_ivf_flat
插入 100,000 个向量...
插入完成，耗时: 2.34秒
创建索引: IVF_FLAT
索引创建完成，耗时: 8.56秒
加载 collection...
加载完成

测试搜索参数: {'nprobe': 16}
  平均延迟: 45.23ms
  P95 延迟: 62.18ms
  QPS: 22.11

测试搜索参数: {'nprobe': 32}
  平均延迟: 82.45ms
  P95 延迟: 105.32ms
  QPS: 12.13

================================================================================
测试索引配置: IVF_SQ8
================================================================================
...

================================================================================
性能对比汇总
================================================================================
index_type  search_params  avg_latency_ms  p95_latency_ms     qps  memory_mb
 IVF_FLAT  {'nprobe': 16}           45.23           62.18   22.11    2930.50
 IVF_FLAT  {'nprobe': 32}           82.45          105.32   12.13    2930.50
  IVF_SQ8  {'nprobe': 16}           38.67           54.23   25.86     732.62
  IVF_SQ8  {'nprobe': 32}           71.23           92.45   14.04     732.62
     HNSW    {'ef': 128}            52.34           68.92   19.11    3052.83
     HNSW    {'ef': 256}            98.76          125.43   10.13    3052.83

================================================================================
推荐配置
================================================================================

最低延迟配置:
  索引类型: IVF_SQ8
  搜索参数: {'nprobe': 16}
  平均延迟: 38.67ms

最高 QPS 配置:
  索引类型: IVF_SQ8
  搜索参数: {'nprobe': 16}
  QPS: 25.86

最低内存配置:
  索引类型: IVF_SQ8
  内存占用: 732.62MB

测试报告已保存到: benchmark_report.json
```

---

## 关键要点

1. **系统化测试**：测试多种索引类型和参数组合
2. **性能指标**：延迟（P50/P95/P99）、QPS、内存占用
3. **预热机制**：避免冷启动影响测试结果
4. **结果分析**：自动找出最优配置
5. **可扩展性**：易于添加新的索引类型和参数

---

## 在 RAG 系统中的应用

使用此工具为 RAG 系统选择最优索引配置：

```python
# 针对 RAG 场景的测试配置
rag_index_configs = [
    # 实时对话场景
    {
        "index_type": "IVF_SQ8",
        "metric_type": "L2",
        "params": {"nlist": 1000}
    },
    # 离线分析场景
    {
        "index_type": "HNSW",
        "metric_type": "L2",
        "params": {"M": 32, "efConstruction": 400}
    }
]

rag_search_configs = [
    {"metric_type": "L2", "params": {"nprobe": 8}},   # 快速
    {"metric_type": "L2", "params": {"nprobe": 32}},  # 平衡
    {"metric_type": "L2", "params": {"ef": 256}}      # 高召回率
]

# 运行测试
runner = BenchmarkRunner(250_000, 768)  # 25万向量（5万文档 * 5 chunks）
runner.run_benchmark(rag_index_configs, rag_search_configs)
df = runner.generate_report("rag_benchmark.json")
```
