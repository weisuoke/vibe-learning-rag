# 最小可用知识

> 掌握以下内容，就能在 RAG 系统中正确使用 Milvus 一致性级别

---

## 4.1 理解三种级别的本质区别

**核心：数据同步等待时间**

```python
from pymilvus import Collection

collection = Collection("my_collection")
query_embedding = [0.1, 0.2, 0.3, ...]

# Strong: 等待所有节点同步完成
results_strong = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Strong"  # 延迟最高，数据最新
)

# Bounded: 等待部分节点同步
import time
results_bounded = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Bounded",
    guarantee_timestamp=int(time.time() - 10)  # 容忍10秒延迟
)

# Eventually: 不等待，立即返回
results_eventually = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Eventually"  # 延迟最低，可能旧数据
)
```

**记住：**
- **Strong** = 写入后立即可见（等待所有节点）
- **Bounded** = 写入后几秒可见（等待部分节点或有限时间）
- **Eventually** = 写入后不确定何时可见（不等待）

---

## 4.2 根据场景选择一致性级别

### 决策树

```
用户刚上传文档，立即提问？
├─ 是 → Strong（必须检索到新文档）
└─ 否 → 继续判断
    │
    查询历史数据（很少更新）？
    ├─ 是 → Eventually（性能优先）
    └─ 否 → Bounded（平衡选择）
```

### 快速选择表

| 场景 | 推荐级别 | 理由 | 占比 |
|------|---------|------|------|
| 文档刚上传 | Strong | 用户期望立即可查 | 20% |
| 日常检索 | Bounded | 平衡性能和准确性 | 60% |
| 批量分析 | Eventually | 追求最高吞吐量 | 20% |
| 实时聊天 | Strong | 对话上下文必须最新 | - |
| 推荐系统 | Eventually | 容忍延迟 | - |
| 金融/医疗 | Strong | 准确性要求极高 | - |

**记住：Bounded 是 80% 场景的最佳选择！**

---

## 4.3 在代码中设置一致性级别

### 基础用法

```python
from pymilvus import Collection, connections

# 连接 Milvus
connections.connect("default", host="localhost", port="19530")
collection = Collection("my_collection")

# 方法1：在 search 时指定
results = collection.search(
    data=[[0.1, 0.2, 0.3, ...]],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Strong"  # 指定一致性级别
)

# 方法2：在 query 时指定
results = collection.query(
    expr="id in [1, 2, 3]",
    output_fields=["id", "text"],
    consistency_level="Bounded"
)
```

### RAG 场景完整示例

```python
from pymilvus import Collection, connections
from sentence_transformers import SentenceTransformer

# 初始化
connections.connect("default", host="localhost", port="19530")
collection = Collection("knowledge_base")
model = SentenceTransformer('all-MiniLM-L6-v2')

# ===== 场景1：用户上传新文档 =====
def upload_document(text: str):
    """上传文档并确保立即可查"""
    # 1. 生成 Embedding
    embedding = model.encode(text).tolist()

    # 2. 插入 Milvus
    collection.insert([[embedding], [text]])

    # 3. 刷新（确保数据持久化）
    collection.flush()

    print("✅ 文档上传成功")

# ===== 场景2：立即查询（使用 Strong）=====
def search_immediately(query: str):
    """文档上传后立即查询，必须用 Strong"""
    query_embedding = model.encode(query).tolist()

    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param={"metric_type": "COSINE", "params": {"nprobe": 10}},
        limit=5,
        consistency_level="Strong"  # 保证能检索到刚上传的文档
    )

    return results

# ===== 场景3：日常查询（使用 Bounded）=====
def search_normal(query: str):
    """日常查询，使用 Bounded 平衡性能"""
    query_embedding = model.encode(query).tolist()

    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param={"metric_type": "COSINE", "params": {"nprobe": 10}},
        limit=5,
        consistency_level="Bounded"  # 平衡性能
    )

    return results

# ===== 场景4：批量分析（使用 Eventually）=====
def batch_analysis(queries: list):
    """批量查询，使用 Eventually 提升性能"""
    results = []

    for query in queries:
        query_embedding = model.encode(query).tolist()

        result = collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param={"metric_type": "COSINE", "params": {"nprobe": 10}},
            limit=5,
            consistency_level="Eventually"  # 最高性能
        )

        results.append(result)

    return results

# 使用示例
upload_document("Milvus 支持三种一致性级别")
results = search_immediately("一致性级别")  # Strong
print(f"找到 {len(results[0])} 个结果")
```

---

## 4.4 性能影响量化

### 性能对比（相对于 Strong）

| 一致性级别 | 查询延迟 | 吞吐量 | 适用场景占比 |
|-----------|---------|--------|-------------|
| Strong | 基准 (150ms) | 基准 (130 QPS) | 20% |
| Bounded | **-46%** (80ms) | **+85%** (240 QPS) | **60%** |
| Eventually | **-73%** (40ms) | **+265%** (475 QPS) | 20% |

### 实际影响

**场景：日均 100 万次查询的 RAG 系统**

```
使用 Strong：
- 总耗时：100万 / 130 QPS = 2.14 小时
- 资源消耗：高

使用 Bounded：
- 总耗时：100万 / 240 QPS = 1.16 小时
- 节省时间：46%
- 资源消耗：中

使用 Eventually：
- 总耗时：100万 / 475 QPS = 0.58 小时
- 节省时间：73%
- 资源消耗：低
```

**结论：**
- Bounded 是大多数场景的最佳选择（60%）
- Strong 仅用于必须实时的场景（20%）
- Eventually 用于性能敏感的批量场景（20%）

---

## 4.5 常见错误避免

### 错误1：所有查询都用 Strong ❌

```python
# ❌ 错误：不分场景，全部用 Strong
def search(query: str):
    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10,
        consistency_level="Strong"  # 盲目使用 Strong
    )
    return results
```

**问题：**
- 性能浪费 50-80%
- 系统吞吐量降低
- 资源消耗过高

**正确做法：**
```python
# ✅ 正确：根据场景选择
def search(query: str, just_uploaded: bool = False):
    # 根据场景选择一致性级别
    if just_uploaded:
        consistency_level = "Strong"
    else:
        consistency_level = "Bounded"  # 默认选择

    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"nprobe": 10}},
        limit=10,
        consistency_level=consistency_level
    )
    return results
```

---

### 错误2：忽略 flush() 操作 ❌

```python
# ❌ 错误：插入后立即查询，但没有 flush
collection.insert(data)
results = collection.search(..., consistency_level="Strong")
# 可能检索不到刚插入的数据（数据还在缓冲区）
```

**问题：**
- 即使使用 Strong，也可能查不到刚插入的数据
- 原因：数据还在客户端缓冲区，未发送到服务器

**正确做法：**
```python
# ✅ 正确：插入后先 flush
collection.insert(data)
collection.flush()  # 确保数据写入完成
results = collection.search(..., consistency_level="Strong")
# 现在一定能查到
```

---

### 错误3：不理解 Bounded 的时间窗口 ❌

```python
# ❌ 错误：使用 Bounded 但不设置 guarantee_timestamp
results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Bounded"
    # 缺少 guarantee_timestamp
)
# 默认行为可能不符合预期
```

**问题：**
- 不知道容忍多少延迟
- 行为不可预测

**正确做法：**
```python
# ✅ 正确：明确设置时间窗口
import time

results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Bounded",
    guarantee_timestamp=int(time.time() - 10)  # 容忍 10 秒延迟
)
```

**时间窗口选择建议：**
| 场景 | 推荐窗口 | 理由 |
|------|---------|------|
| 实时聊天 | 1-2 秒 | 用户期望快速响应 |
| 文档检索 | 5-10 秒 | 平衡性能和准确性 |
| 批量分析 | 30-60 秒 | 性能优先 |

---

### 错误4：误以为 Eventually 会丢数据 ❌

```python
# ❌ 错误理解：Eventually 不安全，数据可能丢失
# 因此避免使用 Eventually
```

**问题：**
- 误解了 Eventually 的含义
- Eventually 只影响可见性，不影响持久性
- 数据不会丢失，只是同步需要时间

**正确理解：**
```python
# ✅ 正确：Eventually 安全，适合批量场景
def batch_import(documents: list):
    """批量导入文档，使用 Eventually 提升性能"""
    for doc in documents:
        embedding = model.encode(doc).tolist()
        collection.insert([[embedding], [doc]])

    collection.flush()  # 数据已持久化，不会丢失

    # 使用 Eventually 查询（性能最高）
    # 数据最终会同步，不会丢失
    results = collection.query(
        expr="id > 0",
        consistency_level="Eventually"
    )
    return results
```

---

### 错误5：不考虑 Milvus 不支持 UPDATE ❌

```python
# ❌ 错误：尝试更新向量
collection.update(ids=[1, 2, 3], data=new_embeddings)
# 报错：Milvus 不支持 UPDATE
```

**问题：**
- Milvus 不支持原地 UPDATE
- 必须使用 DELETE + INSERT

**正确做法：**
```python
# ✅ 正确：DELETE + INSERT
def update_vectors(ids: list, new_embeddings: list, new_texts: list):
    """更新向量数据"""
    # 1. 删除旧数据
    expr = f"id in {ids}"
    collection.delete(expr)

    # 2. 插入新数据
    collection.insert([new_embeddings, new_texts, ids])

    # 3. 刷新（如果需要立即可见）
    collection.flush()

    # 4. 验证更新（使用 Strong）
    results = collection.query(
        expr=expr,
        output_fields=["*"],
        consistency_level="Strong"  # 保证能查到新数据
    )
    return results
```

---

## 这些知识足以

掌握以上内容，你就能：

✅ **在 RAG 系统中正确选择一致性级别**
- 文档上传场景用 Strong
- 日常查询用 Bounded
- 批量分析用 Eventually

✅ **在代码中正确设置一致性级别**
- 使用 `consistency_level` 参数
- 配合 `flush()` 确保数据写入
- Bounded 要设置 `guarantee_timestamp`

✅ **理解性能影响**
- Strong 最慢但最准确（~150ms）
- Eventually 最快但可能旧（~40ms）
- Bounded 是平衡选择（~80ms）

✅ **避免常见错误**
- 不盲目使用 Strong
- 插入后记得 flush
- Bounded 要设置时间窗口
- Eventually 不会丢数据
- Milvus 不支持 UPDATE

---

## 快速参考卡

### 场景1：文档刚上传，立即查询

```python
# 上传文档
collection.insert(data)
collection.flush()  # 必须 flush

# 立即查询（Strong）
results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "COSINE", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Strong"  # 保证能查到
)
```

### 场景2：日常查询（推荐）

```python
import time

results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "COSINE", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Bounded",
    guarantee_timestamp=int(time.time() - 10)  # 容忍10秒
)
```

### 场景3：批量分析

```python
results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param={"metric_type": "COSINE", "params": {"nprobe": 10}},
    limit=10,
    consistency_level="Eventually"  # 最高性能
)
```

---

## 决策流程图

```
开始查询
   ↓
是否刚上传文档？
   ├─ 是 → Strong
   └─ 否 ↓
         ↓
是否批量分析/历史数据？
   ├─ 是 → Eventually
   └─ 否 ↓
         ↓
默认 → Bounded
```

---

## 性能优化建议

### 1. 监控使用分布

**目标分布：**
- Strong: 20%
- Bounded: 60%
- Eventually: 20%

**如果 Strong > 30%：**
- 检查是否过度使用
- 优化为 Bounded

### 2. 根据 QPS 调整

| 当前 QPS | 建议 |
|---------|------|
| < 200 | Strong 可接受 |
| 200-500 | 使用 Bounded |
| > 500 | 考虑 Eventually |

### 3. 根据延迟要求调整

| 延迟要求 | 建议 |
|---------|------|
| < 50ms | 必须 Eventually |
| 50-100ms | 使用 Bounded |
| > 100ms | Strong 可接受 |

---

## 实战检查清单

在使用一致性级别前，检查：

- [ ] 我理解三种级别的本质区别（等待时间）
- [ ] 我根据场景选择了合适的级别（不是盲目用 Strong）
- [ ] 我在插入后使用了 flush()（如果需要立即可见）
- [ ] 我为 Bounded 设置了 guarantee_timestamp
- [ ] 我理解 Eventually 不会丢数据（只是延迟可见）
- [ ] 我知道 Milvus 不支持 UPDATE（使用 DELETE + INSERT）
- [ ] 我监控了各级别的使用分布（Strong < 20%）

---

## 下一步学习

完成最小可用知识后，建议：

1. **实践练习**
   - 运行实战代码场景1：基础使用
   - 对比三种级别的性能差异
   - 在自己的 RAG 项目中应用

2. **深入理解**
   - 阅读"双重类比"（理解类比）
   - 阅读"反直觉点"（避免误区）
   - 阅读"面试必问"（深入原理）

3. **相关知识点**
   - L1_快速入门/04_Milvus架构概览
   - L3_高级特性/05_数据一致性与持久化
   - L4_性能优化/02_查询优化
