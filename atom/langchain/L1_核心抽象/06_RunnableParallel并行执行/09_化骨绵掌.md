# RunnableParallel并行执行 - 化骨绵掌

> 10个2分钟知识卡片，深度掌握 RunnableParallel

---

## 使用说明

**化骨绵掌**：武侠小说中的内功心法，通过持续修炼将功力融入骨髓，达到深度掌握的境界。

**学习方式**：
- 每个卡片 2 分钟内可看完
- 每天学习 2-3 个卡片
- 重复阅读，加深理解
- 结合实践，融会贯通

---

## 卡片1：直觉理解 - 并行执行的本质

**一句话**：并行执行就是"同时做多件事"，将总耗时从"求和"变为"求最大值"。

**举例**：
```python
# 串行：做饭
煮饭（30分钟）→ 炒菜（20分钟）→ 煲汤（40分钟）
总耗时：90分钟

# 并行：做饭
煮饭（30分钟）
炒菜（20分钟）  } 同时进行
煲汤（40分钟）
总耗时：40分钟（最慢的任务）
```

**代码**：
```python
# 串行
result1 = chain1.invoke(input)  # 1.5秒
result2 = chain2.invoke(input)  # 1.5秒
result3 = chain3.invoke(input)  # 1.5秒
# 总耗时：4.5秒

# 并行
parallel = RunnableParallel(
    r1=chain1, r2=chain2, r3=chain3
)
results = parallel.invoke(input)  # 1.5秒
```

**应用**：在 AI Agent 中，多模型调用、多数据源检索、多维度分析都适合并行执行。

**关键洞察**：并行不是"更快地做事"，而是"同时做多件事"。

---

## 卡片2：形式化定义 - 数学表达

**一句话**：RunnableParallel 是一个函数映射，将单个输入映射到多个输出的字典。

**数学定义**：
```
RunnableParallel: Input → Dict[str, Output]

parallel = {k1: f1, k2: f2, k3: f3}
parallel(x) = {k1: f1(x), k2: f2(x), k3: f3(x)}
```

**类型签名**：
```python
class RunnableParallel(Generic[Input, Output]):
    steps: Dict[str, Runnable[Input, Any]]

    def invoke(self, input: Input) -> Dict[str, Output]:
        ...
```

**举例**：
```python
# 定义
parallel = RunnableParallel(
    sentiment=sentiment_chain,  # str → str
    topic=topic_chain,          # str → str
    entities=entity_chain       # str → List[str]
)

# 类型
# parallel: Runnable[str, Dict[str, Any]]

# 调用
result = parallel.invoke("LangChain is great!")
# result: {
#     "sentiment": "positive",
#     "topic": "LangChain",
#     "entities": ["LangChain"]
# }
```

**应用**：理解类型系统有助于编写类型安全的代码。

**关键洞察**：RunnableParallel 保持了 Runnable 协议的类型约束。

---

## 卡片3：执行机制 - asyncio vs threading

**一句话**：RunnableParallel 支持两种并行模式：asyncio（协程）和 threading（线程池）。

**对比**：
```python
# 异步模式（ainvoke）
async def ainvoke(self, input):
    tasks = [r.ainvoke(input) for r in self.steps.values()]
    results = await asyncio.gather(*tasks)
    return dict(zip(self.steps.keys(), results))

# 同步模式（invoke）
def invoke(self, input):
    with ThreadPoolExecutor() as executor:
        futures = [executor.submit(r.invoke, input)
                   for r in self.steps.values()]
        results = [f.result() for f in futures]
    return dict(zip(self.steps.keys(), results))
```

**性能对比**：
| 特性 | asyncio | threading |
|------|---------|-----------|
| 内存 | 低（<1KB/协程） | 高（1-8MB/线程） |
| 并发数 | 高（10000+） | 低（<100） |
| 适用 | 异步库 | 同步库 |

**应用**：
- 使用 `langchain-openai`（异步）→ 用 `ainvoke`
- 使用 `requests`（同步）→ 用 `invoke`

**关键洞察**：选择模式取决于使用的库，而非个人偏好。

---

## 卡片4：结果合并 - 字典映射

**一句话**：RunnableParallel 将多个输出合并为字典，键名对应任务名。

**合并策略**：
```python
# 基础合并
parallel = RunnableParallel(
    task1=chain1,  # 输出: "result1"
    task2=chain2   # 输出: "result2"
)
result = parallel.invoke(input)
# {"task1": "result1", "task2": "result2"}

# 嵌套合并
parallel = RunnableParallel(
    analysis=RunnableParallel(
        sentiment=sentiment_chain,
        topic=topic_chain
    ),
    metadata=metadata_chain
)
result = parallel.invoke(input)
# {
#     "analysis": {
#         "sentiment": "...",
#         "topic": "..."
#     },
#     "metadata": "..."
# }
```

**键冲突处理**：
```python
# 问题：键名冲突
parallel = RunnableParallel(
    result=chain1,  # 输出: {"result": "A"}
    result=chain2   # 输出: {"result": "B"}
)
# Python 会报错：重复的键名

# 解决：使用不同的键名
parallel = RunnableParallel(
    result1=chain1,
    result2=chain2
)
```

**应用**：使用有意义的键名，便于后续访问结果。

**关键洞察**：字典比数组更适合并行执行的结果组织。

---

## 卡片5：错误传播 - 失败模式

**一句话**：默认情况下，一个任务失败会导致整体失败，需要使用 `with_fallback` 容错。

**失败模式**：
```python
# 模式1：全部失败（默认）
parallel = RunnableParallel(
    task1=chain1,  # 成功
    task2=chain2,  # 失败 ❌
    task3=chain3   # 成功
)
result = parallel.invoke(input)
# 抛出异常，整体失败

# 模式2：部分容错
parallel = RunnableParallel(
    task1=chain1,
    task2=chain2.with_fallback([default_value]),
    task3=chain3
)
result = parallel.invoke(input)
# task2 失败 → 使用 default_value
# 整体成功
```

**容错策略**：
```python
# 策略1：默认值
chain.with_fallback([RunnableLambda(lambda _: "default")])

# 策略2：备用链
chain.with_fallback([backup_chain])

# 策略3：多级容错
chain.with_fallback([backup1, backup2, backup3])
```

**应用**：生产环境必须为每个外部调用添加容错。

**关键洞察**：容错是生产环境的必备机制，不是可选项。

---

## 卡片6：性能优化 - 并发控制

**一句话**：并发不是越多越好，需要根据 API 限流、内存、成本设置合理的并发数。

**并发控制**：
```python
# LangGraph 中设置 max_concurrency
from langgraph.graph import StateGraph

graph = StateGraph(State)
graph.add_node(
    "parallel_tasks",
    parallel_node,
    max_concurrency=5  # 最多5个并发
)

# 手动控制（asyncio）
import asyncio

semaphore = asyncio.Semaphore(5)

async def limited_invoke(input):
    async with semaphore:
        return await parallel.ainvoke(input)
```

**最优并发数**：
```python
max_concurrency = min(
    API_LIMIT / 2,           # OpenAI: 500 RPM → 250
    MEMORY / TASK_MEMORY,    # 8GB / 100MB → 80
    BANDWIDTH / TASK_BW,     # 100Mbps / 1Mbps → 100
    COST_BUDGET / TASK_COST  # $100 / $0.01 → 10000
)
# 取最小值
```

**应用**：
- OpenAI API → 建议 250 并发
- 内存受限 → 建议 50-100 并发
- 成本敏感 → 使用批处理

**关键洞察**：过多并发会触发限流、内存溢出、成本失控。

---

## 卡片7：LCEL 组合 - 管道集成

**一句话**：RunnableParallel 可以与其他 Runnable 无缝组合，形成复杂的数据流。

**组合模式**：
```python
# 模式1：并行 → 后处理
chain = parallel | post_processor

# 模式2：前处理 → 并行
chain = pre_processor | parallel

# 模式3：完整管道
chain = (
    pre_processor
    | RunnableParallel(
        path1=chain1,
        path2=chain2
    )
    | post_processor
)

# 模式4：嵌套并行
chain = RunnableParallel(
    analysis=RunnableParallel(
        sentiment=sentiment_chain,
        topic=topic_chain
    ),
    generation=generation_chain
)
```

**数据流转换**：
```python
# 问题：并行输出是字典，后续处理需要特定格式
parallel = RunnableParallel(
    sentiment=sentiment_chain,
    topic=topic_chain
)
# 输出: {"sentiment": "...", "topic": "..."}

# 解决：使用 RunnableLambda 转换
def format_output(data):
    return f"Sentiment: {data['sentiment']}, Topic: {data['topic']}"

chain = parallel | RunnableLambda(format_output)
```

**应用**：构建复杂的 AI Agent 数据流。

**关键洞察**：LCEL 的组合性是其核心优势。

---

## 卡片8：成本优化 - 批处理策略

**一句话**：使用 langasync 批处理可以降低 50% 的 LLM 调用成本。

**批处理原理**：
```python
# 原理：批处理 API 提供 50% 折扣
# OpenAI Batch API: $0.005/1K tokens（标准：$0.01/1K）
# Anthropic Batch API: 50% 折扣

# 使用 langasync
from langasync import wrap_chain

# 原始并行链
parallel = RunnableParallel(
    task1=chain1,
    task2=chain2
)

# 包装为批处理模式
async_parallel = wrap_chain(parallel, batch_size=10)

# 批量执行
inputs = [{"text": f"text{i}"} for i in range(100)]
results = await async_parallel.abatch(inputs)

# 成本对比
# 标准模式：100 × $0.01 = $1.00
# 批处理模式：100 × $0.005 = $0.50
# 节省：50%
```

**适用场景**：
- ✅ 批量评估和测试
- ✅ 数据标注任务
- ✅ 离线分析
- ❌ 实时对话（需要即时响应）

**应用**：非实时任务优先使用批处理。

**关键洞察**：批处理是成本优化的最有效手段。

---

## 卡片9：LangGraph 集成 - 动态并行

**一句话**：LangGraph 支持动态并行（Send），可以在运行时决定并行任务数量。

**动态并行**：
```python
from langgraph.graph import StateGraph
from langgraph.types import Send

class State(TypedDict):
    documents: list[str]
    results: list[dict]

def fan_out(state: State):
    """动态生成并行任务"""
    return [
        Send("process", {"doc": doc})
        for doc in state["documents"]
    ]

def process(state):
    """处理单个文档"""
    return {"result": analyze(state["doc"])}

# 构建图
graph = StateGraph(State)
graph.add_conditional_edges("start", fan_out)
graph.add_node("process", process, max_concurrency=10)

# 执行（动态并行）
result = graph.invoke({
    "documents": [doc1, doc2, ..., doc100]
})
# 自动并行处理100个文档，最多10个并发
```

**对比**：
| 特性 | RunnableParallel | LangGraph Send |
|------|-----------------|----------------|
| 任务数量 | 编译时确定 | 运行时确定 |
| 并发控制 | 手动实现 | 内置 max_concurrency |
| 状态管理 | 无 | 有（State） |

**应用**：动态数量的并行任务（如批量处理）使用 LangGraph。

**关键洞察**：LangGraph 是 RunnableParallel 的超集。

---

## 卡片10：源码阅读 - 深入理解

**一句话**：阅读 LangChain 源码可以深入理解 RunnableParallel 的设计决策。

**源码位置**：
```
langchain-core/langchain_core/runnables/base.py
- class RunnableParallel
```

**核心实现**（简化版）：
```python
class RunnableParallel(Runnable[Input, Dict[str, Any]]):
    steps: Dict[str, Runnable[Input, Any]]

    def invoke(self, input: Input) -> Dict[str, Any]:
        """同步执行"""
        with ThreadPoolExecutor() as executor:
            # 提交所有任务
            futures = {
                key: executor.submit(runnable.invoke, input)
                for key, runnable in self.steps.items()
            }
            # 等待所有任务完成
            return {
                key: future.result()
                for key, future in futures.items()
            }

    async def ainvoke(self, input: Input) -> Dict[str, Any]:
        """异步执行"""
        # 创建所有任务
        tasks = {
            key: runnable.ainvoke(input)
            for key, runnable in self.steps.items()
        }
        # 并发执行
        results = await asyncio.gather(*tasks.values())
        # 合并结果
        return dict(zip(tasks.keys(), results))
```

**设计亮点**：
1. **统一接口**：invoke/ainvoke 提供一致的 API
2. **类型安全**：使用泛型保持类型约束
3. **错误传播**：默认传播异常，可配置容错
4. **可组合性**：实现 Runnable 协议，可与其他组件组合

**阅读建议**：
1. 先理解 Runnable 协议
2. 再看 RunnableParallel 实现
3. 对比 RunnableSequence 理解差异
4. 查看测试用例理解使用场景

**应用**：理解源码有助于调试和优化。

**关键洞察**：源码是最好的文档。

---

## 深度掌握技巧

### 技巧1：手写简化版

**目标**：通过手写实现加深理解

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Callable

class SimpleParallel:
    """简化版 RunnableParallel"""

    def __init__(self, **steps: Callable):
        self.steps = steps

    def invoke(self, input: Any) -> Dict[str, Any]:
        """同步并行执行"""
        with ThreadPoolExecutor() as executor:
            futures = {
                key: executor.submit(func, input)
                for key, func in self.steps.items()
            }
            return {
                key: future.result()
                for key, future in futures.items()
            }

    async def ainvoke(self, input: Any) -> Dict[str, Any]:
        """异步并行执行"""
        tasks = {
            key: asyncio.create_task(
                asyncio.to_thread(func, input)
            )
            for key, func in self.steps.items()
        }
        results = await asyncio.gather(*tasks.values())
        return dict(zip(tasks.keys(), results))

# 使用
def task1(x): return x + 1
def task2(x): return x * 2
def task3(x): return x ** 2

parallel = SimpleParallel(
    add=task1,
    multiply=task2,
    power=task3
)

result = parallel.invoke(5)
print(result)  # {"add": 6, "multiply": 10, "power": 25}
```

---

### 技巧2：性能基准测试

**目标**：量化并行执行的性能提升

```python
import time
import asyncio
from langchain_core.runnables import RunnableParallel, RunnableLambda

def slow_task(x):
    """模拟慢速任务"""
    time.sleep(1)
    return x

# 创建3个任务
parallel = RunnableParallel(
    task1=RunnableLambda(slow_task),
    task2=RunnableLambda(slow_task),
    task3=RunnableLambda(slow_task)
)

# 测试串行执行
start = time.time()
r1 = slow_task(1)
r2 = slow_task(2)
r3 = slow_task(3)
serial_time = time.time() - start
print(f"串行: {serial_time:.2f}秒")  # ~3秒

# 测试并行执行
start = time.time()
result = parallel.invoke(1)
parallel_time = time.time() - start
print(f"并行: {parallel_time:.2f}秒")  # ~1秒

# 计算加速比
speedup = serial_time / parallel_time
print(f"加速比: {speedup:.2f}x")  # ~3x
```

---

### 技巧3：调试并行执行

**目标**：学会调试并行执行中的问题

```python
from langchain_core.runnables import RunnableParallel
from langsmith import trace

# 使用 LangSmith 追踪
@trace
def debug_parallel(input):
    parallel = RunnableParallel(
        task1=chain1,
        task2=chain2,
        task3=chain3
    )
    return parallel.invoke(input)

# 添加日志
import logging
logging.basicConfig(level=logging.DEBUG)

# 查看执行顺序
def logged_task(name):
    def task(x):
        print(f"[{name}] 开始")
        result = process(x)
        print(f"[{name}] 完成")
        return result
    return task

parallel = RunnableParallel(
    task1=RunnableLambda(logged_task("task1")),
    task2=RunnableLambda(logged_task("task2")),
    task3=RunnableLambda(logged_task("task3"))
)
```

---

### 技巧4：压力测试

**目标**：测试并发限制和稳定性

```python
import asyncio
from langchain_core.runnables import RunnableParallel

async def stress_test(parallel, num_requests=1000):
    """压力测试"""
    tasks = [
        parallel.ainvoke({"text": f"request{i}"})
        for i in range(num_requests)
    ]

    start = time.time()
    results = await asyncio.gather(*tasks, return_exceptions=True)
    duration = time.time() - start

    # 统计
    success = sum(1 for r in results if not isinstance(r, Exception))
    failed = len(results) - success

    print(f"总请求: {num_requests}")
    print(f"成功: {success}")
    print(f"失败: {failed}")
    print(f"耗时: {duration:.2f}秒")
    print(f"QPS: {num_requests / duration:.2f}")

# 运行压力测试
asyncio.run(stress_test(parallel))
```

---

### 技巧5：成本分析

**目标**：分析并优化成本

```python
from langsmith import Client

client = Client()

# 获取运行统计
runs = client.list_runs(
    project_name="my-project",
    filter='eq(name, "parallel_analysis")'
)

# 分析成本
total_cost = 0
total_tokens = 0

for run in runs:
    if run.outputs:
        total_cost += run.outputs.get("cost", 0)
        total_tokens += run.outputs.get("tokens", 0)

print(f"总成本: ${total_cost:.2f}")
print(f"总 tokens: {total_tokens}")
print(f"平均成本/请求: ${total_cost / len(runs):.4f}")
```

---

## 学习检查清单

完成10个卡片学习后，检查掌握程度：

- [ ] 卡片1：能够直观解释并行执行
- [ ] 卡片2：理解形式化定义和类型系统
- [ ] 卡片3：区分 asyncio 和 threading
- [ ] 卡片4：理解结果合并机制
- [ ] 卡片5：掌握错误处理策略
- [ ] 卡片6：能够设置合理的并发数
- [ ] 卡片7：掌握 LCEL 组合模式
- [ ] 卡片8：理解批处理优化
- [ ] 卡片9：了解 LangGraph 动态并行
- [ ] 卡片10：能够阅读源码

---

## 进阶学习路径

### 路径1：源码深入
1. 阅读 `RunnableParallel` 源码
2. 阅读 `RunnableSequence` 对比
3. 阅读 `RunnableBranch` 理解条件路由
4. 理解 Runnable 协议设计

### 路径2：性能优化
1. 学习 asyncio 事件循环
2. 学习线程池原理
3. 学习批处理 API
4. 学习成本优化策略

### 路径3：生产实践
1. 实现容错机制
2. 实现并发控制
3. 实现监控追踪
4. 实现成本分析

---

## 参考资料

[来源: RunnableParallel — LangChain documentation - https://reference.langchain.com/v0.3/python/core/runnables/langchain_core.runnables.base.RunnableParallel.html, 访问日期: 2026-02-18]

[来源: Building Production-Ready AI Pipelines with LangChain Runnables - https://medium.com/@sajo02/building-production-ready-ai-pipelines-with-langchain-runnables-a-complete-lcel-guide-2f9b27f6d557, 访问日期: 2026-02-18]

---

**版本**: v1.0
**最后更新**: 2026-02-18
**卡片数量**: 10个（每个2分钟）
