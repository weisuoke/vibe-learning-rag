# 核心概念 3: 相似度检索

## 什么是相似度检索?

**相似度检索（Similarity Search）** 是向量数据库的核心功能，通过计算向量之间的距离或相似度，找到与查询向量最相似的 Top-K 个结果。

### 核心定义

```python
# 相似度检索的本质
results = collection.search(
    data=[query_vector],           # 查询向量
    anns_field="embedding",        # 向量字段名
    param=search_params,           # 检索参数
    limit=10,                      # 返回 Top-K 结果
    expr="category == 'tech'",     # 标量过滤条件（可选）
    output_fields=["text", "doc_id"]  # 返回的字段
)
```

**类比理解**:
- **前端类比**: 就像 Elasticsearch 的全文搜索，但搜索的是语义相似度
- **日常类比**: 就像在图书馆找"与这本书相似的其他书"

---

## 检索的核心参数

### 1. data（查询向量）

查询向量是检索的输入，必须与 Collection 中的向量维度一致。

```python
# 单个查询向量
query_vector = [0.1, 0.2, 0.3, ...]  # 384 维
results = collection.search(
    data=[query_vector],  # 注意：必须是列表
    anns_field="embedding",
    param=search_params,
    limit=10
)

# 批量查询（多个查询向量）
query_vectors = [
    [0.1, 0.2, ...],  # 查询 1
    [0.3, 0.4, ...],  # 查询 2
    [0.5, 0.6, ...]   # 查询 3
]
results = collection.search(
    data=query_vectors,  # 批量查询
    anns_field="embedding",
    param=search_params,
    limit=10
)
# 返回 3 组结果，每组 10 个
```

**RAG 场景示例**:
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

# 用户问题
question = "什么是向量数据库？"

# 向量化问题
query_vector = model.encode(question).tolist()

# 检索相似文档
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "COSINE", "params": {"ef": 64}},
    limit=5
)
```

---

### 2. anns_field（向量字段名）

指定要检索的向量字段。

```python
# Schema 定义
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384),
    FieldSchema(name="image_embedding", dtype=DataType.FLOAT_VECTOR, dim=512),
]

# 检索文本向量
results = collection.search(
    data=[query_vector],
    anns_field="embedding",  # 检索文本向量
    param=search_params,
    limit=10
)

# 检索图像向量
results = collection.search(
    data=[image_query_vector],
    anns_field="image_embedding",  # 检索图像向量
    param=search_params,
    limit=10
)
```

---

### 3. param（检索参数）

包含相似度度量方式和索引特定参数。

```python
# HNSW 索引的检索参数
search_params = {
    "metric_type": "COSINE",  # 相似度度量方式
    "params": {"ef": 64}      # HNSW 特定参数
}

# IVF_FLAT 索引的检索参数
search_params = {
    "metric_type": "L2",
    "params": {"nprobe": 10}  # IVF_FLAT 特定参数
}
```

**参数详解**:
- `metric_type`: 相似度度量方式（L2, IP, COSINE）
- `params`: 索引特定参数
  - HNSW: `ef`（搜索深度，越大越精确）
  - IVF_FLAT: `nprobe`（搜索的聚类数量）

---

### 4. limit（返回结果数量）

控制返回 Top-K 结果的数量。

```python
# 返回 Top-5
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=5  # 返回最相似的 5 个结果
)

# 返回 Top-20
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=20  # 返回最相似的 20 个结果
)
```

**RAG 场景建议**:
- 初始检索: `limit=20-50`（召回更多候选）
- ReRank 后: 取 Top-5（精选最相关）

---

### 5. expr（标量过滤表达式）

在向量检索的基础上，添加标量字段的过滤条件。

```python
# 单条件过滤
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category == 'technology'"  # 只检索技术类文档
)

# 多条件组合
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category == 'technology' and timestamp > 1640000000"
)

# IN 操作符
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category in ['tech', 'science', 'ai']"
)
```

**expr 表达式语法**:
- 比较: `==`, `!=`, `>`, `<`, `>=`, `<=`
- 逻辑: `and`, `or`, `not`
- 成员: `in`, `not in`
- 字符串: 需要用单引号 `'value'`

---

### 6. output_fields（返回字段）

指定返回结果中包含的标量字段。

```python
# 返回所有字段
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    output_fields=["text", "doc_id", "category", "timestamp"]
)

# 只返回文本
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    output_fields=["text"]
)

# 不返回任何字段（只返回 ID 和相似度）
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
    # 不指定 output_fields
)
```

**注意**: 向量字段不能通过 `output_fields` 返回（向量太大）。

---

## 相似度度量方式

Milvus 支持三种主要的相似度度量方式。

### 1. L2（欧氏距离）

**定义**: 计算两个向量之间的欧氏距离。

```python
# L2 距离公式
distance = sqrt(sum((a[i] - b[i])^2))

# 使用 L2
search_params = {"metric_type": "L2", "params": {"ef": 64}}
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

**特点**:
- 距离越小，越相似
- 范围: [0, +∞)
- 适合: 未归一化的向量

**示例**:
```python
# 向量 A: [1, 2, 3]
# 向量 B: [4, 5, 6]
# L2 距离 = sqrt((1-4)^2 + (2-5)^2 + (3-6)^2) = sqrt(27) ≈ 5.196
```

---

### 2. IP（内积）

**定义**: 计算两个向量的内积（点积）。

```python
# IP 公式
similarity = sum(a[i] * b[i])

# 使用 IP
search_params = {"metric_type": "IP", "params": {"ef": 64}}
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

**特点**:
- 值越大，越相似
- 范围: (-∞, +∞)
- 适合: 归一化的向量（等价于 COSINE）

**示例**:
```python
# 向量 A: [1, 2, 3]
# 向量 B: [4, 5, 6]
# IP = 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32
```

---

### 3. COSINE（余弦相似度）

**定义**: 计算两个向量之间的余弦相似度。

```python
# COSINE 公式
similarity = sum(a[i] * b[i]) / (sqrt(sum(a[i]^2)) * sqrt(sum(b[i]^2)))

# 使用 COSINE
search_params = {"metric_type": "COSINE", "params": {"ef": 64}}
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
)
```

**特点**:
- 值越大，越相似
- 范围: [-1, 1]
- 适合: 文本向量（最常用）

**示例**:
```python
# 向量 A: [1, 2, 3]
# 向量 B: [4, 5, 6]
# COSINE = 32 / (sqrt(14) * sqrt(77)) ≈ 0.9746
```

---

### 相似度度量对比

| 度量方式 | 值越大/小 | 范围 | 适用场景 | RAG 推荐 |
|---------|----------|------|---------|---------|
| L2 | 越小越相似 | [0, +∞) | 未归一化向量 | ❌ |
| IP | 越大越相似 | (-∞, +∞) | 归一化向量 | ⚠️ |
| COSINE | 越大越相似 | [-1, 1] | 文本向量 | ✅ |

**RAG 场景推荐**: **COSINE**
- 大多数 Embedding 模型输出归一化向量
- COSINE 只关注方向，不关注长度
- 更符合语义相似度的直觉

---

## 基础检索示例

### 完整代码示例

```python
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import numpy as np

# 1. 连接 Milvus
connections.connect(host="localhost", port="19530")

# 2. 获取 Collection
collection = Collection("rag_documents")

# 3. 确保 Collection 已加载
collection.load()

# 4. 初始化 Embedding 模型
model = SentenceTransformer('all-MiniLM-L6-v2')

# 5. 用户问题
question = "什么是向量数据库？"

# 6. 向量化问题
query_vector = model.encode(question).tolist()

# 7. 定义检索参数
search_params = {
    "metric_type": "COSINE",
    "params": {"ef": 64}
}

# 8. 执行检索
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=5,
    output_fields=["text", "doc_id"]
)

# 9. 处理结果
print(f"检索到 {len(results[0])} 个结果:\n")
for i, hit in enumerate(results[0]):
    print(f"结果 {i+1}:")
    print(f"  ID: {hit.id}")
    print(f"  相似度: {hit.score:.4f}")
    print(f"  文档ID: {hit.entity.get('doc_id')}")
    print(f"  文本: {hit.entity.get('text')[:100]}...")
    print()
```

**输出示例**:
```
检索到 5 个结果:

结果 1:
  ID: 12345
  相似度: 0.8923
  文档ID: doc_001
  文本: 向量数据库是一种专门用于存储和检索高维向量数据的数据库系统...

结果 2:
  ID: 23456
  相似度: 0.8567
  文档ID: doc_045
  文本: Milvus 是一个开源的向量数据库，支持大规模向量数据的存储和检索...

结果 3:
  ID: 34567
  相似度: 0.8234
  文档ID: doc_089
  文本: 向量检索技术是实现语义搜索的核心，通过计算向量相似度...

结果 4:
  ID: 45678
  相似度: 0.8102
  文档ID: doc_123
  文本: 在 RAG 系统中，向量数据库用于存储文档的向量表示...

结果 5:
  ID: 56789
  相似度: 0.7998
  文档ID: doc_156
  文本: 向量数据库的核心优势是能够进行高效的相似度检索...
```

---

## 标量过滤检索

### expr 表达式语法

#### 1. 比较操作符

```python
# 等于
expr="category == 'technology'"

# 不等于
expr="category != 'sports'"

# 大于
expr="timestamp > 1640000000"

# 小于
expr="score < 0.8"

# 大于等于
expr="views >= 1000"

# 小于等于
expr="price <= 100"
```

#### 2. 逻辑操作符

```python
# AND（与）
expr="category == 'tech' and timestamp > 1640000000"

# OR（或）
expr="category == 'tech' or category == 'science'"

# NOT（非）
expr="not (category == 'sports')"

# 复杂组合
expr="(category == 'tech' or category == 'science') and timestamp > 1640000000"
```

#### 3. 成员操作符

```python
# IN（包含）
expr="category in ['tech', 'science', 'ai']"

# NOT IN（不包含）
expr="category not in ['sports', 'entertainment']"

# 数值 IN
expr="doc_id in [1, 2, 3, 4, 5]"
```

---

### 标量过滤示例

#### 示例 1: 单条件过滤

```python
# 只检索技术类文档
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category == 'technology'",
    output_fields=["text", "category"]
)

print("技术类文档检索结果:")
for hit in results[0]:
    print(f"  相似度: {hit.score:.4f}, 分类: {hit.entity.get('category')}")
```

#### 示例 2: 时间范围过滤

```python
import time

# 只检索最近 7 天的文档
seven_days_ago = int(time.time()) - 7 * 24 * 3600

results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr=f"timestamp > {seven_days_ago}",
    output_fields=["text", "timestamp"]
)

print("最近 7 天的文档:")
for hit in results[0]:
    print(f"  相似度: {hit.score:.4f}, 时间戳: {hit.entity.get('timestamp')}")
```

#### 示例 3: 多条件组合

```python
# 检索技术类且评分高于 0.8 的文档
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category == 'technology' and score > 0.8",
    output_fields=["text", "category", "score"]
)

print("高质量技术文档:")
for hit in results[0]:
    print(f"  相似度: {hit.score:.4f}, 评分: {hit.entity.get('score')}")
```

#### 示例 4: IN 操作符

```python
# 检索多个分类的文档
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10,
    expr="category in ['tech', 'science', 'ai']",
    output_fields=["text", "category"]
)

print("科技相关文档:")
for hit in results[0]:
    print(f"  相似度: {hit.score:.4f}, 分类: {hit.entity.get('category')}")
```

---

## 在 RAG 中的应用

### RAG 检索的完整流程

```python
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# 1. 初始化组件
connections.connect(host="localhost", port="19530")
collection = Collection("rag_knowledge_base")
collection.load()

embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
llm_client = OpenAI()

# 2. RAG 检索函数
def rag_retrieve(question, top_k=5, category_filter=None):
    """
    RAG 检索函数

    Args:
        question: 用户问题
        top_k: 返回结果数量
        category_filter: 分类过滤（可选）

    Returns:
        检索到的文档列表
    """
    # 向量化问题
    query_vector = embedding_model.encode(question).tolist()

    # 构建检索参数
    search_params = {"metric_type": "COSINE", "params": {"ef": 64}}

    # 构建过滤表达式
    expr = None
    if category_filter:
        expr = f"category == '{category_filter}'"

    # 执行检索
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        expr=expr,
        output_fields=["text", "doc_id", "category"]
    )

    # 提取文档
    documents = []
    for hit in results[0]:
        documents.append({
            "id": hit.id,
            "score": hit.score,
            "text": hit.entity.get("text"),
            "doc_id": hit.entity.get("doc_id"),
            "category": hit.entity.get("category")
        })

    return documents

# 3. RAG 生成函数
def rag_generate(question, documents):
    """
    RAG 生成函数

    Args:
        question: 用户问题
        documents: 检索到的文档

    Returns:
        生成的答案
    """
    # 构建上下文
    context = "\n\n".join([doc["text"] for doc in documents])

    # 构建 Prompt
    prompt = f"""基于以下上下文回答问题。如果上下文中没有相关信息，请说"我不知道"。

上下文:
{context}

问题: {question}

答案:"""

    # 调用 LLM
    response = llm_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    return response.choices[0].message.content

# 4. 完整的 RAG 流程
def rag_pipeline(question, top_k=5, category_filter=None):
    """
    完整的 RAG 流程
    """
    print(f"问题: {question}\n")

    # 检索
    print("正在检索相关文档...")
    documents = rag_retrieve(question, top_k, category_filter)

    print(f"检索到 {len(documents)} 个相关文档:\n")
    for i, doc in enumerate(documents):
        print(f"{i+1}. 相似度: {doc['score']:.4f}, 分类: {doc['category']}")
        print(f"   文本: {doc['text'][:100]}...\n")

    # 生成
    print("正在生成答案...")
    answer = rag_generate(question, documents)

    print(f"答案: {answer}")

    return answer

# 5. 测试 RAG 系统
question = "什么是向量数据库？"
answer = rag_pipeline(question, top_k=5)
```

---

## 检索结果处理

### 结果结构

```python
# 检索结果是一个二维列表
results = collection.search(...)

# results[0] 是第一个查询的结果列表
for hit in results[0]:
    print(f"ID: {hit.id}")              # 主键 ID
    print(f"距离/相似度: {hit.distance}")  # 或 hit.score
    print(f"实体: {hit.entity}")         # 包含 output_fields 的字段
```

### 提取字段值

```python
# 方式 1: 使用 get()
text = hit.entity.get("text")
doc_id = hit.entity.get("doc_id")

# 方式 2: 使用字典访问
text = hit.entity["text"]
doc_id = hit.entity["doc_id"]

# 方式 3: 使用属性访问（不推荐）
# text = hit.entity.text  # 可能不工作
```

### 批量查询结果

```python
# 批量查询
query_vectors = [[0.1, ...], [0.2, ...], [0.3, ...]]
results = collection.search(
    data=query_vectors,
    anns_field="embedding",
    param=search_params,
    limit=5
)

# 处理每个查询的结果
for i, query_results in enumerate(results):
    print(f"\n查询 {i+1} 的结果:")
    for hit in query_results:
        print(f"  ID: {hit.id}, 相似度: {hit.score:.4f}")
```

---

## 常见错误与解决方案

### 错误 1: Collection 未加载

```python
# 错误信息
# "collection not loaded"

# 解决方案：检索前必须 load()
collection.load()
results = collection.search(...)
```

### 错误 2: 维度不匹配

```python
# 错误信息
# "dimension mismatch"

# 解决方案：确保查询向量维度与 Schema 一致
print(f"Schema 维度: 384")
print(f"查询向量维度: {len(query_vector)}")

# 如果不一致，检查 Embedding 模型
model = SentenceTransformer('all-MiniLM-L6-v2')
print(f"模型输出维度: {model.get_sentence_embedding_dimension()}")
```

### 错误 3: expr 语法错误

```python
# 错误示例
expr="category = 'tech'"  # 错误：应该用 ==

# 正确示例
expr="category == 'tech'"

# 字符串必须用单引号
expr="category == 'tech'"  # 正确
expr='category == "tech"'  # 错误
```

### 错误 4: ef < limit

```python
# 错误信息
# "ef should be larger than limit"

# 解决方案：确保 ef >= limit
search_params = {"metric_type": "COSINE", "params": {"ef": 64}}
results = collection.search(..., param=search_params, limit=10)  # ef=64 >= limit=10
```

---

## 总结

### 核心要点

1. **COSINE 度量**: 文本向量推荐使用 COSINE
2. **limit 控制 Top-K**: 根据场景选择合适的 K 值
3. **expr 实现混合检索**: 向量检索 + 标量过滤
4. **output_fields 控制返回**: 只返回需要的字段
5. **必须先 load()**: 检索前必须加载 Collection

### RAG 应用建议

- 使用 COSINE 相似度度量
- 初始检索 Top-20-50，ReRank 后取 Top-5
- 使用 expr 实现分类、时间等过滤
- 返回原始文本用于生成答案
- 监控检索延迟和召回率

### 下一步

学习 **最小可用知识**，掌握数据插入与查询的最小可用操作集。
