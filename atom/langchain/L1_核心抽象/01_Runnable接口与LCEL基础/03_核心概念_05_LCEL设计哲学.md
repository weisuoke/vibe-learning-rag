# 核心概念 05: LCEL 设计哲学

> 理解 LangChain Expression Language 的声明式编程理念

---

## 什么是 LCEL？

**LCEL (LangChain Expression Language) 是基于 Runnable 协议的声明式编程语言，使用管道操作符 `|` 组合 AI 组件。**

### 一句话定义

LCEL 让开发者描述"应该发生什么"而非"如何发生"，框架自动优化执行。

---

## 声明式 vs 命令式

### 命令式编程（传统方式）

```python
# ❌ 命令式：告诉计算机"如何做"
prompt_value = prompt.format(text="你好")
llm_output = llm.invoke(prompt_value)
parsed_result = parser.parse(llm_output)
```

### 声明式编程（LCEL）

```python
# ✅ 声明式：告诉计算机"做什么"
chain = prompt | llm | parser
result = chain.invoke({"text": "你好"})
```

### 核心区别

| 维度 | 命令式 | 声明式（LCEL） |
|------|--------|----------------|
| **关注点** | 如何执行 | 执行什么 |
| **控制流** | 显式控制 | 框架控制 |
| **优化** | 手动优化 | 自动优化 |
| **可读性** | 步骤详细 | 意图清晰 |

---

## 管道操作符实现

### `|` 操作符的魔法

```python
from langchain_core.runnables import Runnable

class MyRunnable(Runnable):
    def __or__(self, other):
        """重载 | 操作符"""
        return RunnableSequence(self, other)

# 使用
chain = runnable1 | runnable2 | runnable3
# 等价于
chain = RunnableSequence(runnable1, runnable2, runnable3)
```

### 类型推断

```python
from langchain_core.runnables import Runnable

# 类型自动推断
prompt: Runnable[dict, PromptValue]
llm: Runnable[PromptValue, AIMessage]
parser: Runnable[AIMessage, str]

# 组合后的类型
chain: Runnable[dict, str] = prompt | llm | parser
```

---

## LCEL 的自动优化

### 优化 1: 并行执行

**LCEL 自动识别可并行的步骤**[^1]：

```python
from langchain_core.runnables import RunnableParallel

# 声明式：自动并行
parallel_chain = RunnableParallel(
    task1=chain1,
    task2=chain2,
    task3=chain3
)

# 框架自动并发执行 task1, task2, task3
result = parallel_chain.invoke(input)
```

### 优化 2: 流式传输

**LCEL 默认支持流式，无需手动实现**[^2]：

```python
# 自动支持流式
chain = prompt | llm | parser

# 无需修改代码，直接流式输出
for chunk in chain.stream(input):
    print(chunk, end="", flush=True)
```

### 优化 3: 异步执行

**LCEL 自动支持异步**：

```python
# 同步执行
result = chain.invoke(input)

# 异步执行（无需修改链定义）
result = await chain.ainvoke(input)
```

---

## 与传统 Chain 的对比

### 传统 Chain API（已过时）

```python
from langchain.chains import LLMChain

# ❌ 传统方式：固定结构
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(input)

# 缺点：
# 1. 不灵活：难以组合和修改
# 2. 不统一：不同 Chain 有不同 API
# 3. 不优化：无法自动并行和流式
```

### LCEL（推荐）

```python
# ✅ LCEL：灵活组合
chain = prompt | llm | parser

# 优点：
# 1. 灵活：任意组合 Runnable
# 2. 统一：所有组件都是 Runnable
# 3. 优化：自动并行、流式、异步
```

### 性能对比

根据 2025-2026 年的实际测试[^1][^2]：

| 场景 | 传统 Chain | LCEL | 提升 |
|------|-----------|------|------|
| **简单串行** | 1.0x | 1.0x | 相同 |
| **并行任务** | 1.0x | 2-3x | 2-3倍 |
| **流式输出** | 需手动实现 | 自动支持 | - |
| **异步执行** | 需手动实现 | 自动支持 | - |

---

## LCEL 的组合模式

### 模式 1: 串行组合

```python
# 数据依次流动
chain = step1 | step2 | step3
```

### 模式 2: 并行组合

```python
from langchain_core.runnables import RunnableParallel

# 多个任务同时执行
parallel = RunnableParallel(
    path1=chain1,
    path2=chain2
)
```

### 模式 3: 条件路由

```python
from langchain_core.runnables import RunnableBranch

# 根据条件选择路径
router = RunnableBranch(
    (condition1, chain1),
    (condition2, chain2),
    default_chain
)
```

### 模式 4: 混合组合

```python
# 串行 + 并行 + 条件
complex_chain = (
    preprocess
    | RunnableParallel(
        analysis=analyze_chain,
        summary=summarize_chain
    )
    | merge_results
    | RunnableBranch(
        (needs_refinement, refine_chain),
        final_output
    )
)
```

---

## 实战示例

### 示例 1: RAG 管道

```python
"""
RAG 管道示例
演示 LCEL 在实际应用中的使用
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_core.output_parsers import StrOutputParser

# ===== 1. 定义组件 =====
# 向量存储
vectorstore = Chroma(
    embedding_function=OpenAIEmbeddings(),
    persist_directory="./chroma_db"
)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# 提示词模板
template = """基于以下上下文回答问题：

上下文:
{context}

问题: {question}

回答:"""
prompt = ChatPromptTemplate.from_template(template)

# LLM
llm = ChatOpenAI(model="gpt-4o-mini")

# 解析器
parser = StrOutputParser()

# ===== 2. LCEL 组合 =====
# 方式 1: 简单组合
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | parser
)

# 方式 2: 并行优化
rag_chain_parallel = (
    RunnableParallel(
        context=retriever | format_docs,
        question=RunnablePassthrough()
    )
    | prompt
    | llm
    | parser
)

# ===== 3. 使用 =====
question = "什么是 Runnable？"

# 同步执行
answer = rag_chain.invoke(question)
print(f"回答: {answer}")

# 流式执行
print("\n流式回答: ", end="")
for chunk in rag_chain.stream(question):
    print(chunk, end="", flush=True)
print()
```

### 示例 2: 多步推理

```python
"""
多步推理示例
演示复杂工作流的 LCEL 实现
"""

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda, RunnableParallel

llm = ChatOpenAI(model="gpt-4o-mini")

# ===== 步骤 1: 分解问题 =====
decompose_prompt = ChatPromptTemplate.from_template(
    "将以下复杂问题分解为3个子问题:\n\n{question}"
)
decompose_chain = decompose_prompt | llm

# ===== 步骤 2: 并行回答子问题 =====
answer_prompt = ChatPromptTemplate.from_template(
    "回答以下问题:\n\n{subquestion}"
)
answer_chain = answer_prompt | llm

def parse_subquestions(llm_output):
    """解析子问题"""
    content = llm_output.content
    # 简化：假设每行一个子问题
    return [line.strip() for line in content.split('\n') if line.strip()]

# ===== 步骤 3: 合成最终答案 =====
synthesize_prompt = ChatPromptTemplate.from_template(
    """基于以下子问题的答案，回答原始问题:

原始问题: {original_question}

子问题答案:
{subanswers}

最终答案:"""
)
synthesize_chain = synthesize_prompt | llm

# ===== LCEL 组合 =====
def answer_subquestions(subquestions):
    """并行回答所有子问题"""
    answers = []
    for sq in subquestions:
        answer = answer_chain.invoke({"subquestion": sq})
        answers.append(f"Q: {sq}\nA: {answer.content}")
    return "\n\n".join(answers)

multi_step_chain = (
    {
        "subquestions": decompose_chain | RunnableLambda(parse_subquestions),
        "original_question": RunnablePassthrough()
    }
    | RunnableLambda(lambda x: {
        "subanswers": answer_subquestions(x["subquestions"]),
        "original_question": x["original_question"]
    })
    | synthesize_chain
)

# 使用
question = "如何构建一个生产级的 RAG 应用？"
answer = multi_step_chain.invoke(question)
print(answer.content)
```

---

## 为什么 LCEL 不慢？

### 常见误解

**误解**: "LCEL 增加了抽象层，所以比直接调用慢"

**事实**: LCEL 通过优化执行计划，通常比手动实现更快[^1][^2]。

### 性能优势来源

1. **自动并行**: 识别独立步骤并并发执行
2. **流式优化**: 默认支持流式传输
3. **执行引擎**: LangChain 1.0 优化了执行引擎
4. **避免重复**: 智能缓存中间结果

### 实测数据

```python
import time

# 场景：两个独立的 LLM 调用

# ❌ 手动顺序执行
start = time.time()
result1 = llm.invoke("任务1")
result2 = llm.invoke("任务2")
print(f"顺序执行: {time.time() - start:.2f}秒")  # 约 4 秒

# ✅ LCEL 自动并行
parallel_chain = RunnableParallel(
    task1=llm,
    task2=llm
)
start = time.time()
results = parallel_chain.invoke({"task1": "任务1", "task2": "任务2"})
print(f"LCEL 并行: {time.time() - start:.2f}秒")  # 约 2 秒
```

---

## 2025-2026 最佳实践

### 1. 优先使用 LCEL

```python
# ✅ 新项目使用 LCEL
chain = prompt | llm | parser

# ❌ 避免使用传统 Chain
from langchain.chains import LLMChain
chain = LLMChain(llm=llm, prompt=prompt)
```

### 2. 利用并行优化

```python
# ✅ 识别可并行的步骤
chain = (
    preprocess
    | RunnableParallel(
        task1=independent_task1,
        task2=independent_task2
    )
    | merge_results
)
```

### 3. 保持链的简洁

```python
# ✅ 简洁清晰
chain = prompt | llm | parser

# ❌ 过度复杂
chain = (
    step1 | step2 | step3 | step4 | step5
    | step6 | step7 | step8 | step9 | step10
)
# 建议：拆分为多个子链
```

### 4. 使用类型注解

```python
# ✅ 明确类型
from langchain_core.runnables import Runnable

chain: Runnable[dict, str] = prompt | llm | parser
```

---

## 总结

### LCEL 的核心价值

1. **声明式**: 描述"做什么"而非"如何做"
2. **可组合**: 任意组合 Runnable 组件
3. **自动优化**: 并行、流式、异步自动支持
4. **类型安全**: 泛型确保类型正确

### 设计哲学

```
简单 > 复杂
声明 > 命令
组合 > 继承
优化 > 手动
```

### 何时使用 LCEL

- ✅ 多步骤 AI 工作流
- ✅ 需要可观测性的生产应用
- ✅ 团队协作和代码复用
- ❌ 极简单的单次调用（直接用 SDK）

---

## 参考资料

[^1]: [LangChain Expression Language Performance](https://www.linkedin.com/pulse/langchain-expression-language-lcel-modern-approach-building-patil-v2k5f) - LinkedIn, 2025
[^2]: [How to Make LangChain Apps 10x Faster](https://medium.com/@vinodkrane/langchain-in-production-performance-security-and-cost-optimization-d5e0b44a26fd) - Medium, 2025

### 官方文档
- [LCEL Concepts](https://python.langchain.com/docs/concepts/lcel) - LangChain, 2025-2026
- [LCEL Cookbook](https://python.langchain.com/docs/how_to/#langchain-expression-language-lcel) - 2025-2026

---

**完成 Stage 2**: 继续阅读 Stage 3 和 Stage 4 文档深入学习
