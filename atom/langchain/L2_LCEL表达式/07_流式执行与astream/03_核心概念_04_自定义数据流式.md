# 核心概念 04：自定义数据流式

## 概述

深入理解 `stream_mode="custom"` 模式，掌握如何在工具函数中发送自定义进度数据。

---

## 核心原理

### 上下文变量机制

```python
# langgraph/config.py（简化）
from contextvars import ContextVar

_stream_writer: ContextVar[Optional[StreamWriter]] = ContextVar(
    "_stream_writer", default=None
)

def get_stream_writer(config: Optional[RunnableConfig] = None) -> StreamWriter:
    """从上下文获取 writer"""
    writer = _stream_writer.get()
    if writer is None:
        raise RuntimeError("No stream writer in context")
    return writer
```

**为什么使用 ContextVar**：
- 线程安全：每个线程有独立的上下文
- 异步安全：每个异步任务有独立的上下文
- 自动传播：Python 3.11+ 自动传播到子函数

---

### StreamWriter 实现

```python
class StreamWriter:
    def __init__(self, queue: asyncio.Queue):
        self.queue = queue

    def __call__(self, data: Any) -> None:
        """写入数据到流"""
        self.queue.put_nowait(data)
```

---

## 基础使用

### 简单示例

```python
from langchain.agents import create_agent
from langgraph.config import get_stream_writer

def process_items(items: list[str]) -> str:
    """处理项目并发送进度"""
    writer = get_stream_writer()

    writer(f"开始处理 {len(items)} 个项目")

    for i, item in enumerate(items):
        # 处理逻辑
        result = process_single_item(item)

        # 发送进度
        progress = (i + 1) / len(items) * 100
        writer({
            "type": "progress",
            "current": i + 1,
            "total": len(items),
            "percentage": progress,
            "item": item
        })

    writer("处理完成")
    return "Done"

agent = create_agent(model="gpt-4o-mini", tools=[process_items])

# 接收自定义数据
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "处理数据"}]},
    stream_mode="custom"
):
    print(chunk)
```

---

## 数据类型

### 1. 字符串消息

```python
def my_tool(query: str) -> str:
    writer = get_stream_writer()
    writer("步骤 1: 初始化")
    writer("步骤 2: 处理")
    writer("步骤 3: 完成")
    return "Done"
```

### 2. 结构化数据

```python
def my_tool(query: str) -> str:
    writer = get_stream_writer()

    writer({
        "type": "status",
        "message": "开始处理",
        "timestamp": time.time()
    })

    writer({
        "type": "progress",
        "percentage": 50,
        "current": 5,
        "total": 10
    })

    return "Done"
```

### 3. 复杂对象

```python
from dataclasses import dataclass

@dataclass
class ProcessingStatus:
    stage: str
    progress: float
    details: dict

def my_tool(query: str) -> str:
    writer = get_stream_writer()

    status = ProcessingStatus(
        stage="processing",
        progress=0.5,
        details={"items_processed": 50}
    )
    writer(status)

    return "Done"
```

---

## 实战场景

### 场景 1：文件处理进度

```python
import os

def batch_process_files(directory: str) -> str:
    """批量处理文件"""
    writer = get_stream_writer()

    files = [f for f in os.listdir(directory) if f.endswith('.txt')]
    writer(f"发现 {len(files)} 个文件")

    for i, filename in enumerate(files):
        writer({
            "type": "file_progress",
            "filename": filename,
            "index": i + 1,
            "total": len(files),
            "percentage": (i + 1) / len(files) * 100
        })

        # 处理文件
        process_file(os.path.join(directory, filename))

    writer("所有文件处理完成")
    return f"处理了 {len(files)} 个文件"
```

---

### 场景 2：API 调用监控

```python
import requests

def fetch_multiple_apis(urls: list[str]) -> str:
    """调用多个 API"""
    writer = get_stream_writer()

    results = []
    for i, url in enumerate(urls):
        writer({
            "type": "api_call",
            "url": url,
            "status": "calling",
            "index": i + 1,
            "total": len(urls)
        })

        try:
            response = requests.get(url, timeout=10)
            writer({
                "type": "api_call",
                "url": url,
                "status": "success",
                "status_code": response.status_code
            })
            results.append(response.json())

        except Exception as e:
            writer({
                "type": "api_call",
                "url": url,
                "status": "error",
                "error": str(e)
            })

    return f"完成 {len(results)}/{len(urls)} 个 API 调用"
```

---

### 场景 3：数据库操作进度

```python
def bulk_insert_records(records: list[dict]) -> str:
    """批量插入记录"""
    writer = get_stream_writer()

    batch_size = 100
    total_batches = (len(records) + batch_size - 1) // batch_size

    writer(f"开始插入 {len(records)} 条记录，分 {total_batches} 批")

    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min((batch_num + 1) * batch_size, len(records))
        batch = records[start_idx:end_idx]

        writer({
            "type": "batch_progress",
            "batch": batch_num + 1,
            "total_batches": total_batches,
            "records_in_batch": len(batch),
            "total_inserted": end_idx
        })

        # 插入批次
        db.insert_many(batch)

    writer("插入完成")
    return f"成功插入 {len(records)} 条记录"
```

---

### 场景 4：机器学习训练进度

```python
def train_model(data: dict) -> str:
    """训练模型"""
    writer = get_stream_writer()

    epochs = 10
    writer(f"开始训练，共 {epochs} 个 epoch")

    for epoch in range(epochs):
        writer({
            "type": "training",
            "epoch": epoch + 1,
            "total_epochs": epochs,
            "status": "training"
        })

        # 训练逻辑
        loss = train_one_epoch(data)

        writer({
            "type": "training",
            "epoch": epoch + 1,
            "total_epochs": epochs,
            "status": "completed",
            "loss": loss
        })

    writer("训练完成")
    return "模型训练成功"
```

---

## Python < 3.11 兼容性

### 问题

Python < 3.11 的 `contextvars` 不会自动传播到子函数。

### 解决方案

```python
from langchain_core.runnables import RunnableConfig

# Python < 3.11：手动传递 config
def my_tool(query: str, config: RunnableConfig) -> str:
    writer = get_stream_writer(config)  # 传递 config
    writer("Processing...")
    return "Done"

# Python 3.11+：自动传播
def my_tool(query: str) -> str:
    writer = get_stream_writer()  # 无需传递 config
    writer("Processing...")
    return "Done"
```

### 检测 Python 版本

```python
import sys

def my_tool(query: str, config: RunnableConfig = None) -> str:
    """兼容多版本的工具"""
    if sys.version_info < (3, 11):
        if config is None:
            raise ValueError("Python < 3.11 requires config parameter")
        writer = get_stream_writer(config)
    else:
        writer = get_stream_writer()

    writer("Processing...")
    return "Done"
```

---

## 高级技巧

### 技巧 1：分级进度

```python
def hierarchical_progress(data: dict) -> str:
    """分级进度报告"""
    writer = get_stream_writer()

    # 主任务进度
    writer({"level": "main", "message": "开始主任务"})

    for i in range(3):
        writer({"level": "main", "step": i+1, "total": 3})

        # 子任务进度
        for j in range(5):
            writer({
                "level": "sub",
                "parent_step": i+1,
                "step": j+1,
                "total": 5
            })

    writer({"level": "main", "message": "主任务完成"})
    return "Done"
```

---

### 技巧 2：实时日志

```python
import logging

def tool_with_logging(query: str) -> str:
    """带日志的工具"""
    writer = get_stream_writer()

    # 自定义日志处理器
    class StreamLogHandler(logging.Handler):
        def emit(self, record):
            writer({
                "type": "log",
                "level": record.levelname,
                "message": record.getMessage(),
                "timestamp": record.created
            })

    logger = logging.getLogger(__name__)
    handler = StreamLogHandler()
    logger.addHandler(handler)

    logger.info("开始处理")
    # 处理逻辑
    logger.warning("发现潜在问题")
    logger.info("处理完成")

    return "Done"
```

---

### 技巧 3：错误报告

```python
def tool_with_error_reporting(items: list) -> str:
    """带错误报告的工具"""
    writer = get_stream_writer()

    errors = []
    for i, item in enumerate(items):
        try:
            process_item(item)
            writer({
                "type": "success",
                "item": item,
                "index": i
            })
        except Exception as e:
            error_info = {
                "type": "error",
                "item": item,
                "index": i,
                "error": str(e)
            }
            errors.append(error_info)
            writer(error_info)

    if errors:
        writer({
            "type": "summary",
            "total": len(items),
            "success": len(items) - len(errors),
            "errors": len(errors)
        })

    return f"处理完成，{len(errors)} 个错误"
```

---

### 技巧 4：性能监控

```python
import time

def tool_with_performance_monitoring(data: dict) -> str:
    """带性能监控的工具"""
    writer = get_stream_writer()

    start_time = time.time()

    for i, step in enumerate(["init", "process", "finalize"]):
        step_start = time.time()

        # 执行步骤
        execute_step(step, data)

        step_duration = time.time() - step_start

        writer({
            "type": "performance",
            "step": step,
            "duration": step_duration,
            "total_elapsed": time.time() - start_time
        })

    return "Done"
```

---

## 最佳实践

### 1. 结构化数据

```python
# ✅ 推荐：使用结构化数据
writer({
    "type": "progress",
    "percentage": 50,
    "message": "处理中"
})

# ❌ 不推荐：纯字符串
writer("50% 处理中")
```

### 2. 一致的数据格式

```python
# ✅ 推荐：统一格式
def send_progress(writer, current, total):
    writer({
        "type": "progress",
        "current": current,
        "total": total,
        "percentage": current / total * 100
    })

# ❌ 不推荐：格式不一致
writer({"progress": 50})
writer({"current": 5, "total": 10})
```

### 3. 错误处理

```python
# ✅ 推荐：捕获错误
def safe_tool(query: str) -> str:
    try:
        writer = get_stream_writer()
        writer("Processing...")
        return "Done"
    except RuntimeError:
        # 不在 LangGraph 上下文中
        return "Done"

# ❌ 不推荐：不处理错误
def unsafe_tool(query: str) -> str:
    writer = get_stream_writer()  # 可能抛出异常
    writer("Processing...")
    return "Done"
```

---

## 性能考虑

### 开销分析

```python
# custom 模式开销：~1%
- 队列操作：~0.5%
- 序列化：~0.3%
- 上下文查找：~0.2%
```

### 优化建议

```python
# 1. 减少发送频率
# ❌ 不推荐：每次迭代都发送
for i in range(1000):
    writer(f"处理 {i}")

# ✅ 推荐：批量发送
for i in range(1000):
    if i % 100 == 0:
        writer(f"处理 {i}/1000")

# 2. 避免大对象
# ❌ 不推荐：发送大对象
writer({"data": large_dataframe})

# ✅ 推荐：只发送摘要
writer({"rows": len(large_dataframe), "columns": len(large_dataframe.columns)})
```

---

## 调试技巧

### 技巧 1：检查上下文

```python
def debug_tool(query: str) -> str:
    """调试工具"""
    try:
        writer = get_stream_writer()
        writer("✅ 在 LangGraph 上下文中")
    except RuntimeError:
        print("❌ 不在 LangGraph 上下文中")

    return "Done"
```

### 技巧 2：日志所有消息

```python
def logged_tool(query: str) -> str:
    """记录所有消息的工具"""
    writer = get_stream_writer()

    messages = []

    def logged_write(data):
        messages.append(data)
        writer(data)

    logged_write("步骤 1")
    logged_write("步骤 2")

    print(f"发送了 {len(messages)} 条消息")
    return "Done"
```

---

## 总结

### 核心要点

1. **custom 模式通过 `get_stream_writer()` 发送自定义数据**
2. **只能在 LangGraph 执行上下文中使用**
3. **Python < 3.11 需要手动传递 config**
4. **适用于进度追踪、日志、错误报告等场景**
5. **性能开销 ~1%，非常轻量**

### 使用场景

- ✅ 文件处理进度
- ✅ API 调用监控
- ✅ 数据库操作进度
- ✅ 机器学习训练进度
- ✅ 实时日志和错误报告

### 避免误区

- ❌ 在工具外部使用（会抛出异常）
- ❌ 发送过于频繁（影响性能）
- ❌ 发送大对象（增加序列化开销）
- ❌ 格式不一致（难以处理）

---

## 参考资源

- **官方文档**: https://docs.langchain.com/oss/python/langgraph/streaming
- **源码位置**: `langgraph/config.py` - get_stream_writer 实现
- **相关知识点**:
  - 03_核心概念_01 - Stream 模式详解
  - 07_实战代码 - 完整代码示例

---

**版本**: LangChain 0.3.x (2025-2026)
**最后更新**: 2026-02-21
