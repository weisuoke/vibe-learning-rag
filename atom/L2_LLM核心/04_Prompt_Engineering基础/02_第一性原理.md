# 第一性原理

### 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题

### RAG Prompt 的第一性原理

#### 1. 最基础的定义

**RAG Prompt = 让 LLM 基于外部知识回答问题的指令**

仅此而已！没有更基础的了。

把它拆开：
- **LLM**：一个能理解和生成文本的模型
- **外部知识**：检索到的文档片段（不是 LLM 训练时学到的）
- **指令**：告诉 LLM 该做什么、怎么做

#### 2. 为什么需要 RAG Prompt？

**核心问题：LLM 默认会"自由发挥"**

LLM 的本质是一个"文本续写器"——给它一个开头，它会续写下去。但这带来几个问题：

| 问题 | 表现 |
|------|------|
| **幻觉** | LLM 会编造看起来合理但实际错误的信息 |
| **过时** | LLM 的知识停留在训练数据的截止日期 |
| **无边界** | LLM 不知道什么该说、什么不该说 |
| **格式随意** | LLM 可能用各种格式回答，不可控 |

**RAG Prompt 的作用**：给 LLM 设定边界和规则

```
没有 RAG Prompt：
用户："公司的退款政策是什么？"
LLM："一般来说，退款政策包括..."（编造通用答案）

有 RAG Prompt：
用户："公司的退款政策是什么？"
LLM："根据提供的文档，贵公司的退款政策是..."（基于检索内容）
```

#### 3. RAG Prompt 的三层价值

##### 价值1：约束信息来源

告诉 LLM："只能用我给你的内容回答，不能自己编"

```python
# 约束信息来源的 Prompt 片段
system_prompt = """
你是一个问答助手。
请仅基于以下提供的文档内容回答问题。
如果文档中没有相关信息，请明确说"根据提供的文档，我无法回答这个问题"。
不要使用你自己的知识来补充或推测。
"""
```

##### 价值2：控制输出格式

告诉 LLM："按照我要求的格式输出"

```python
# 控制输出格式的 Prompt 片段
format_instruction = """
请按以下格式回答：
1. 直接回答（1-2句话）
2. 依据来源（引用文档中的具体内容）
3. 补充说明（如有必要）
"""
```

##### 价值3：处理边界情况

告诉 LLM："遇到特殊情况怎么办"

```python
# 处理边界情况的 Prompt 片段
boundary_instruction = """
特殊情况处理：
- 如果问题与文档内容无关，回复"这个问题超出了我的知识范围"
- 如果文档内容相互矛盾，指出矛盾并说明无法确定
- 如果问题需要最新信息，提醒用户文档可能不是最新的
"""
```

#### 4. 从第一性原理推导 RAG Prompt 设计

**推理链：**

```
1. LLM 是文本续写器，会自由发挥
   ↓
2. RAG 需要 LLM 基于检索内容回答
   ↓
3. 必须通过 Prompt 告诉 LLM 这个约束
   ↓
4. Prompt 需要包含：角色、约束、内容、问题
   ↓
5. 还需要处理边界情况（无内容、内容矛盾等）
   ↓
6. 最终形成：系统提示词 + 上下文注入 + 用户问题
```

#### 5. 一句话总结第一性原理

**RAG Prompt 的本质是"给 LLM 设定游戏规则"——告诉它信息从哪来、怎么用、怎么输出。**

---

## 与其他概念的关系

```
┌─────────────────────────────────────────────────────┐
│                    RAG 系统                          │
├─────────────────────────────────────────────────────┤
│                                                      │
│   用户问题 ──→ 检索器 ──→ 相关文档                    │
│                              ↓                       │
│                         RAG Prompt ←── 这里！        │
│                              ↓                       │
│                           LLM                        │
│                              ↓                       │
│                          最终回答                     │
│                                                      │
└─────────────────────────────────────────────────────┘
```

RAG Prompt 是连接"检索结果"和"LLM 生成"的桥梁。

---

**下一步：** [03_核心概念](./03_核心概念.md) - 深入理解系统提示词、上下文注入、用户问题模板
