# Compaction 压缩机制 - 概览

> **知识点编号：** 12
> **所属阶段：** Phase 2 - 核心架构理解
> **学习时长：** 1小时
> **难度等级：** ⭐⭐⭐ (中等)

---

## 这个知识点是什么？

**Compaction（压缩机制）** 是 Pi-mono 中用于管理 LLM 上下文窗口的核心机制。当对话历史接近上下文窗口限制时，它会自动将旧的对话消息压缩为结构化摘要，保留最近的对话内容，从而实现无限长的对话能力。

**一句话核心：**
> **Compaction 是 Pi-mono 的上下文压缩机制，通过自动总结历史对话来突破 LLM 上下文窗口限制，实现长期对话。**

---

## 为什么要学这个？

### 1. 理解 AI Agent 的核心挑战

LLM 的上下文窗口是有限的：
- Claude Opus 4: ~200K tokens
- GPT-4: ~128K tokens
- 实际对话可能远超这个限制

**没有 Compaction 会怎样？**
- ❌ 对话超过上限后无法继续
- ❌ 必须手动清理历史
- ❌ Agent 无法长期运行
- ❌ 用户体验差

**有了 Compaction：**
- ✅ 自动管理上下文
- ✅ 无限长对话
- ✅ 保留关键信息
- ✅ 无感知压缩

### 2. 掌握长期运行 Agent 的关键技术

如果你要构建：
- **长期运行的 Coding Agent**（如 Pi Coding Agent）
- **客服机器人**（需要记住长对话历史）
- **个人助理**（需要跨会话记忆）
- **多轮对话系统**（复杂任务需要多次交互）

那么 Compaction 是**必须掌握**的核心技术。

### 3. 学习 2025-2026 最新实践

> **2025-2026 Industry Practice**: Context Engineering 已成为 AI Agent 开发的核心学科，Compaction 是其中的关键技术之一。
> ([langchain-ai/context_engineering](https://github.com/langchain-ai/context_engineering))

---

## 你将学到什么？

### 核心知识（必学）

#### 1. 自动压缩触发机制
- Token 计算公式
- 触发条件判断
- 使用量追踪
- 默认阈值配置

#### 2. 压缩策略与切点算法
- 向后查找算法
- 有效切点规则
- 分割回合处理
- 摘要生成格式
- 文件操作追踪

#### 3. 手动压缩与自定义指令
- `/compact` 命令
- Extension 钩子
- 自定义压缩模型
- 自定义摘要提示词

### 实战技能（必练）

- ✅ 配置压缩阈值
- ✅ 监控 token 使用
- ✅ 实现自定义压缩扩展
- ✅ 使用更便宜的模型进行压缩
- ✅ 调试压缩问题

### 2025-2026 前沿技术

- **SimpleMem**: 30x 压缩率的语义管道
- **Agent Cognitive Compressor (ACC)**: 模式驱动的压缩
- **RL-based Compression**: 强化学习优化压缩策略
- **Cost Optimization**: 使用 Gemini Flash 等便宜模型

---

## 学习路径

### 推荐学习顺序

```
01. 30字核心 (2分钟)
    ↓
02. 第一性原理 (10分钟)
    ↓
03. 核心概念 (30分钟)
    ├─ 01. 自动压缩触发机制
    ├─ 02. 压缩策略与切点算法
    └─ 03. 手动压缩与自定义指令
    ↓
04. 最小可用 (5分钟)
    ↓
05. 双重类比 (5分钟)
    ↓
06. 反直觉点 (5分钟)
    ↓
07. 实战代码 (20分钟)
    ├─ 01. 基础压缩配置
    ├─ 02. 自定义压缩扩展
    ├─ 03. 压缩监控与调试
    └─ 04. 分支总结实现
    ↓
08. 面试必问 (5分钟)
    ↓
09. 化骨绵掌 (10分钟)
    ↓
10. 一句话总结 (1分钟)
```

**总学习时长：** 约 1 小时

### 快速上手路径（20分钟）

如果时间有限，按以下顺序学习：
1. **01_30字核心** - 理解核心概念
2. **04_最小可用** - 掌握基本使用
3. **07_实战代码_01** - 运行基础示例
4. **05_双重类比** - 加深理解

---

## 前置知识

### 必须掌握
- ✅ **Session 存储与树形结构** (知识点 11)
  - 理解 JSONL 格式
  - 理解消息树形结构
  - 理解分支管理

- ✅ **LLM 基础知识**
  - 理解 Token 概念
  - 理解上下文窗口
  - 理解 LLM API 调用

### 建议掌握
- TypeScript/Node.js 基础
- Pi-mono 基本使用
- Agent Core 运行时机制 (知识点 08)

---

## 与其他知识点的关系

```
Phase 2: 核心架构理解
├─ 07. Pi AI 统一 LLM API 设计
├─ 08. Agent Core 运行时机制
├─ 09. 工具调用与状态管理
├─ 10. 消息队列与流式响应
├─ 11. Session 存储与树形结构 ← 前置知识
└─ 12. Compaction 压缩机制 ← 你在这里
        ↓
Phase 3: 定制化开发
├─ 13. Prompt Templates 模板系统 ← 可用于定制压缩提示词
├─ 14. Skills 技能包开发
└─ 15. Extensions 扩展开发基础 ← 可实现自定义压缩扩展
```

---

## 学习检查清单

完成本知识点后，你应该能够：

### 理解层面
- [ ] 理解为什么需要 Compaction
- [ ] 理解自动压缩的触发条件
- [ ] 理解切点查找算法
- [ ] 理解压缩摘要的生成过程
- [ ] 理解手动压缩的使用场景

### 应用层面
- [ ] 能够配置压缩阈值
- [ ] 能够监控 token 使用情况
- [ ] 能够实现自定义压缩扩展
- [ ] 能够调试压缩相关问题
- [ ] 能够优化压缩成本

### 源码层面
- [ ] 能够阅读 `compaction.ts` 源码
- [ ] 理解 `findCutPoint()` 算法
- [ ] 理解 `estimateContextTokens()` 实现
- [ ] 理解 Extension 钩子机制

---

## 实际应用场景

### 场景 1：长期运行的 Coding Agent
```typescript
// Pi Coding Agent 在长时间编码会话中
// 自动压缩历史对话，保持上下文清晰
```

### 场景 2：客服机器人
```typescript
// 客服对话可能很长
// Compaction 确保机器人始终能响应
```

### 场景 3：成本优化
```typescript
// 使用 Gemini Flash 进行压缩
// 降低 LLM API 调用成本
```

---

## 参考资源

### Pi-mono 源码
- `packages/coding-agent/src/core/compaction/compaction.ts` (810 lines)
- `packages/coding-agent/docs/compaction.md` (391 lines)
- `packages/coding-agent/examples/extensions/custom-compaction.ts` (115 lines)

### 2025-2026 研究
- [Context Engineering](https://github.com/langchain-ai/context_engineering)
- [Awesome Context Engineering](https://github.com/yzfly/awesome-context-engineering)
- [SimpleMem: 30x Compression](https://arxiv.org/abs/2501.xxxxx)
- [Agent Cognitive Compressor](https://arxiv.org/abs/2501.xxxxx)

### 社区讨论
- Reddit: "LLM Summarization is Costing Me Thousands"
- Reddit: "Anthropic's Context Compaction in Claude"

---

## 开始学习

准备好了吗？让我们从 **30字核心** 开始！

**下一步：** → `01_30字核心.md`

---

**版本：** v1.0
**最后更新：** 2026-02-20
**维护者：** Claude Code
