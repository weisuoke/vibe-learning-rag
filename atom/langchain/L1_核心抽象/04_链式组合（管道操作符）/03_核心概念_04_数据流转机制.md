# 核心概念4：数据流转机制

## 概述

数据流转机制定义了数据如何在管道中从一个组件流向下一个组件，包括类型匹配、数据转换、错误处理等。

**一句话定义**：数据流转是管道中前一个组件的输出自动成为后一个组件的输入的过程，要求类型严格匹配。

---

## 1. 基础数据流

### 1.1 线性数据流

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("讲个笑话")
model = ChatOpenAI()
parser = StrOutputParser()

chain = prompt | model | parser

# 数据流:
# {"topic": "AI"} → prompt → ChatPromptValue → model → AIMessage → parser → str
```

**可视化**：
```
输入: dict
  ↓ (prompt.invoke)
ChatPromptValue
  ↓ (model.invoke)
AIMessage
  ↓ (parser.invoke)
str (输出)
```

### 1.2 数据流的本质

```python
# 管道执行等价于嵌套函数调用
result = chain.invoke(input)

# 等价于
result = parser.invoke(
    model.invoke(
        prompt.invoke(input)
    )
)

# 数据流: input → prompt → model → parser → result
```

---

## 2. 类型匹配规则

### 2.1 严格类型匹配

```python
# 每个 Runnable 都有明确的输入输出类型
class Runnable[Input, Output]:
    def invoke(self, input: Input) -> Output:
        ...

# 组合时必须类型匹配
runnable1: Runnable[A, B]  # A → B
runnable2: Runnable[B, C]  # B → C
chain = runnable1 | runnable2  # A → C (✅ B 匹配)

runnable3: Runnable[D, E]  # D → E
chain = runnable1 | runnable3  # ❌ B ≠ D (类型不匹配)
```

### 2.2 常见类型流转

```python
# LangChain 组件的类型签名
ChatPromptTemplate: dict → ChatPromptValue
ChatModel: ChatPromptValue → AIMessage
StrOutputParser: AIMessage → str
JsonOutputParser: AIMessage → dict
RunnableLambda: Any → Any (自定义)
RunnablePassthrough: T → T (原样传递)

# 正确的类型链
chain = (
    ChatPromptTemplate  # dict → ChatPromptValue
    | ChatModel         # ChatPromptValue → AIMessage
    | StrOutputParser   # AIMessage → str
)
# 最终类型: dict → str
```

### 2.3 类型不匹配的错误

```python
# ❌ 错误示例1: 跳过中间步骤
chain = prompt | parser  # ChatPromptValue → StrOutputParser (不匹配)

try:
    result = chain.invoke({"topic": "AI"})
except TypeError as e:
    print(e)
    # StrOutputParser expected AIMessage, got ChatPromptValue

# ❌ 错误示例2: 顺序错误
chain = parser | model | prompt  # 完全错误的顺序

# ✅ 正确示例
chain = prompt | model | parser  # 类型匹配
```

---

## 3. 数据转换

### 3.1 自动类型转换

```python
# LangChain 会自动进行一些类型转换
from langchain_core.runnables import RunnableLambda

# 字符串自动转换为 PromptValue
prompt = ChatPromptTemplate.from_template("{text}")
chain = prompt | model

# 输入字符串会自动转换
result = chain.invoke("Hello")  # 自动转换为 {"text": "Hello"}
```

### 3.2 显式类型转换

```python
# 使用 RunnableLambda 进行显式转换
def convert_to_dict(text: str) -> dict:
    """将字符串转换为字典"""
    return {"text": text}

chain = (
    RunnableLambda(convert_to_dict)  # str → dict
    | prompt                          # dict → ChatPromptValue
    | model                           # ChatPromptValue → AIMessage
    | parser                          # AIMessage → str
)

result = chain.invoke("Hello")
```

### 3.3 复杂数据转换

```python
from langchain_core.runnables import RunnableLambda

# 转换1: 提取字段
def extract_content(message: AIMessage) -> str:
    return message.content

# 转换2: 格式化输出
def format_output(text: str) -> dict:
    return {
        "answer": text,
        "length": len(text),
        "words": len(text.split())
    }

chain = (
    prompt
    | model
    | RunnableLambda(extract_content)  # AIMessage → str
    | RunnableLambda(format_output)    # str → dict
)

result = chain.invoke({"topic": "AI"})
# result = {"answer": "...", "length": 100, "words": 20}
```

---

## 4. 多路数据流

### 4.1 字典分发数据

```python
from langchain_core.runnables import RunnablePassthrough

# 字典可以将数据分发到多个路径
chain = (
    {
        "context": retriever,           # 路径1: 检索上下文
        "question": RunnablePassthrough()  # 路径2: 传递原始问题
    }
    | prompt
    | model
    | parser
)

# 数据流:
# "什么是AI？"
#   ↓ (分发)
#   ├─ retriever.invoke("什么是AI？") → context
#   └─ RunnablePassthrough.invoke("什么是AI？") → question
#   ↓ (合并)
# {"context": [...], "question": "什么是AI？"}
#   ↓
# prompt → model → parser
```

### 4.2 RunnableParallel 并行数据流

```python
from langchain_core.runnables import RunnableParallel

# 并行处理同一个输入
parallel_chain = RunnableParallel(
    summary=summarizer,      # 路径1: 生成摘要
    translation=translator,  # 路径2: 翻译
    sentiment=analyzer       # 路径3: 情感分析
)

result = parallel_chain.invoke("长文本...")

# 数据流:
# "长文本..."
#   ↓ (复制到3个路径)
#   ├─ summarizer.invoke("长文本...") → summary
#   ├─ translator.invoke("长文本...") → translation
#   └─ analyzer.invoke("长文本...") → sentiment
#   ↓ (合并)
# {"summary": "...", "translation": "...", "sentiment": "positive"}
```

### 4.3 嵌套数据流

```python
# 复杂的嵌套数据流
chain = (
    {
        "context": (
            RunnableParallel(
                vector=vector_retriever,
                keyword=keyword_retriever
            )
            | merge_results
        ),
        "question": RunnablePassthrough()
    }
    | prompt
    | model
    | parser
)

# 数据流:
# "问题"
#   ↓
#   ├─ context 路径:
#   │   "问题"
#   │     ↓ (并行)
#   │     ├─ vector_retriever → vector_results
#   │     └─ keyword_retriever → keyword_results
#   │     ↓ (合并)
#   │   merge_results → context
#   │
#   └─ question 路径:
#       "问题" → question
#   ↓ (合并)
# {"context": [...], "question": "问题"}
#   ↓
# prompt → model → parser
```

---

## 5. 数据传递模式

### 5.1 透传模式（RunnablePassthrough）

```python
from langchain_core.runnables import RunnablePassthrough

# RunnablePassthrough 原样传递输入
passthrough = RunnablePassthrough()

result = passthrough.invoke("test")
print(result)  # "test"

# 在管道中使用
chain = (
    {
        "original": RunnablePassthrough(),  # 保留原始输入
        "processed": processor               # 处理输入
    }
    | next_step
)
```

### 5.2 赋值模式（RunnablePassthrough.assign）

```python
# 添加新字段而不覆盖原有字段
chain = (
    RunnablePassthrough.assign(
        summary=summarizer,      # 添加 summary 字段
        translation=translator   # 添加 translation 字段
    )
    | next_step
)

# 数据流:
# {"text": "原文"}
#   ↓
# {
#     "text": "原文",           # 保留原有字段
#     "summary": "摘要",        # 新增字段
#     "translation": "译文"     # 新增字段
# }
```

### 5.3 选择模式（itemgetter）

```python
from operator import itemgetter

# 从字典中选择特定字段
chain = (
    {
        "context": itemgetter("documents"),  # 选择 documents 字段
        "question": itemgetter("query")      # 选择 query 字段
    }
    | prompt
    | model
    | parser
)

# 数据流:
# {"documents": [...], "query": "问题", "other": "..."}
#   ↓
# {"context": [...], "question": "问题"}  # 只保留选择的字段
```

---

## 6. 数据流的控制

### 6.1 条件数据流（RunnableBranch）

```python
from langchain_core.runnables import RunnableBranch

# 根据条件选择不同的数据流路径
conditional_chain = RunnableBranch(
    (lambda x: len(x) < 10, short_handler),   # 条件1: 短文本
    (lambda x: len(x) < 100, medium_handler), # 条件2: 中等文本
    long_handler                               # 默认: 长文本
)

# 数据流:
# input
#   ↓ (判断条件)
#   ├─ len < 10 → short_handler
#   ├─ len < 100 → medium_handler
#   └─ 其他 → long_handler
```

### 6.2 循环数据流

```python
from langchain_core.runnables import RunnableLambda

def iterative_refine(max_iterations=3):
    """迭代优化数据流"""
    def _refine(input):
        result = input
        for i in range(max_iterations):
            result = refiner.invoke(result)
            if is_good_enough(result):
                break
        return result
    return RunnableLambda(_refine)

chain = (
    initial_processor
    | iterative_refine(max_iterations=5)
    | final_processor
)
```

### 6.3 错误恢复数据流

```python
from langchain_core.runnables import RunnableLambda

def with_fallback(primary, fallback):
    """带降级的数据流"""
    def _invoke(input):
        try:
            return primary.invoke(input)
        except Exception as e:
            print(f"主路径失败: {e}，使用降级路径")
            return fallback.invoke(input)
    return RunnableLambda(_invoke)

chain = (
    preprocessor
    | with_fallback(expensive_model, cheap_model)
    | postprocessor
)
```

---

## 7. 数据流的可观测性

### 7.1 追踪数据流

```python
from langchain_core.runnables import RunnableLambda

def trace_step(name):
    """追踪数据流的步骤"""
    def _trace(input):
        print(f"[{name}] 输入: {input}")
        return input
    return RunnableLambda(_trace)

chain = (
    trace_step("开始")
    | prompt
    | trace_step("Prompt后")
    | model
    | trace_step("Model后")
    | parser
    | trace_step("结束")
)

result = chain.invoke({"topic": "AI"})
# 输出:
# [开始] 输入: {'topic': 'AI'}
# [Prompt后] 输入: ChatPromptValue(...)
# [Model后] 输入: AIMessage(...)
# [结束] 输入: AI 笑话...
```

### 7.2 使用回调追踪

```python
from langchain.callbacks.base import BaseCallbackHandler

class DataFlowTracer(BaseCallbackHandler):
    """数据流追踪器"""

    def on_chain_start(self, serialized, inputs, **kwargs):
        print(f"链开始: {inputs}")

    def on_chain_end(self, outputs, **kwargs):
        print(f"链结束: {outputs}")

    def on_llm_start(self, serialized, prompts, **kwargs):
        print(f"LLM 开始: {prompts}")

    def on_llm_end(self, response, **kwargs):
        print(f"LLM 结束: {response}")

# 使用
tracer = DataFlowTracer()
chain = prompt | model | parser

result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [tracer]}
)
```

### 7.3 LangSmith 追踪

```python
import os

# 配置 LangSmith
os.environ["LANGSMITH_API_KEY"] = "your_key"
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_PROJECT"] = "my_project"

# 自动追踪数据流
chain = prompt | model | parser
result = chain.invoke({"topic": "AI"})

# 在 LangSmith UI 中查看完整的数据流
```

---

## 8. 数据流的性能优化

### 8.1 批处理优化

```python
# 批处理会自动优化数据流
chain = prompt | model | parser

# 单次调用: 3次网络请求
for input in inputs:
    result = chain.invoke(input)

# 批量调用: 1次网络请求（如果 LLM 支持批处理）
results = chain.batch(inputs)

# 数据流:
# [input1, input2, input3]
#   ↓ (批量)
# prompt.batch([input1, input2, input3])
#   ↓ (批量)
# model.batch([...])  # 一次 API 调用
#   ↓ (批量)
# parser.batch([...])
#   ↓
# [result1, result2, result3]
```

### 8.2 流式优化

```python
# 流式执行只在最后一步流式
chain = prompt | model | parser

for chunk in chain.stream({"topic": "AI"}):
    print(chunk, end="")

# 数据流:
# {"topic": "AI"}
#   ↓ (同步)
# prompt.invoke(...)
#   ↓ (同步)
# model.invoke(...)
#   ↓ (流式)
# parser.stream(...)  # 只有最后一步流式
#   ↓
# 逐块输出
```

### 8.3 并行优化

```python
# 并行执行可以显著提升性能
from langchain_core.runnables import RunnableParallel

# 串行: 3秒
chain_serial = step1 | step2 | step3

# 并行: 1秒
chain_parallel = RunnableParallel(
    result1=step1,
    result2=step2,
    result3=step3
)

# 数据流:
# input
#   ↓ (并行)
#   ├─ step1.invoke(input) [1秒]
#   ├─ step2.invoke(input) [1秒]
#   └─ step3.invoke(input) [1秒]
#   ↓ (合并)
# {"result1": ..., "result2": ..., "result3": ...}
```

---

## 9. 在 AI Agent 中的应用

### 9.1 RAG 数据流

```python
# RAG 的完整数据流
rag_chain = (
    {
        "context": retriever | format_docs,  # 检索并格式化
        "question": RunnablePassthrough()     # 传递问题
    }
    | prompt
    | model
    | parser
)

# 数据流:
# "什么是向量数据库？"
#   ↓ (分发)
#   ├─ retriever → [doc1, doc2] → format_docs → "doc1\ndoc2"
#   └─ RunnablePassthrough → "什么是向量数据库？"
#   ↓ (合并)
# {"context": "doc1\ndoc2", "question": "什么是向量数据库？"}
#   ↓
# prompt → ChatPromptValue
#   ↓
# model → AIMessage
#   ↓
# parser → "向量数据库是..."
```

### 9.2 多步推理数据流

```python
# 多步推理的数据流
reasoning_chain = (
    {"question": RunnablePassthrough()}
    | RunnablePassthrough.assign(analysis=analyzer)  # 添加分析
    | RunnablePassthrough.assign(plan=planner)       # 添加计划
    | RunnablePassthrough.assign(answer=executor)    # 添加答案
)

# 数据流:
# "复杂问题"
#   ↓
# {"question": "复杂问题"}
#   ↓ (添加 analysis)
# {"question": "复杂问题", "analysis": "分析结果"}
#   ↓ (添加 plan)
# {"question": "复杂问题", "analysis": "分析结果", "plan": "执行计划"}
#   ↓ (添加 answer)
# {"question": "复杂问题", "analysis": "分析结果", "plan": "执行计划", "answer": "最终答案"}
```

### 9.3 对话系统数据流

```python
# 对话系统的数据流
conversation_chain = (
    {"history": load_history, "input": RunnablePassthrough()}
    | build_prompt
    | model
    | RunnablePassthrough.assign(saved=save_history)  # 保存历史
    | format_response
)

# 数据流:
# "用户消息"
#   ↓
# {"history": [...], "input": "用户消息"}
#   ↓
# build_prompt → ChatPromptValue
#   ↓
# model → AIMessage
#   ↓
# RunnablePassthrough.assign(saved=save_history)
# → {"content": AIMessage, "saved": True}
#   ↓
# format_response → "格式化的回复"
```

---

## 10. 数据流的调试

### 10.1 打印中间结果

```python
from langchain_core.runnables import RunnableLambda

def debug_print(label):
    """打印中间结果"""
    def _print(x):
        print(f"[{label}] {type(x).__name__}: {x}")
        return x
    return RunnableLambda(_print)

chain = (
    debug_print("输入")
    | prompt
    | debug_print("Prompt后")
    | model
    | debug_print("Model后")
    | parser
    | debug_print("输出")
)

result = chain.invoke({"topic": "AI"})
```

### 10.2 检查类型

```python
def check_type(expected_type):
    """检查数据类型"""
    def _check(x):
        if not isinstance(x, expected_type):
            raise TypeError(f"期望 {expected_type}，得到 {type(x)}")
        return x
    return RunnableLambda(_check)

chain = (
    prompt
    | check_type(ChatPromptValue)
    | model
    | check_type(AIMessage)
    | parser
    | check_type(str)
)
```

### 10.3 记录数据流

```python
class DataFlowLogger:
    """数据流日志记录器"""

    def __init__(self):
        self.log = []

    def log_step(self, name):
        def _log(x):
            self.log.append({
                "step": name,
                "type": type(x).__name__,
                "value": str(x)[:100]  # 只记录前100个字符
            })
            return x
        return RunnableLambda(_log)

# 使用
logger = DataFlowLogger()

chain = (
    logger.log_step("输入")
    | prompt
    | logger.log_step("Prompt后")
    | model
    | logger.log_step("Model后")
    | parser
    | logger.log_step("输出")
)

result = chain.invoke({"topic": "AI"})

# 查看日志
import json
print(json.dumps(logger.log, indent=2))
```

---

## 11. 常见数据流模式

### 11.1 扇出模式（Fan-out）

```python
# 一个输入分发到多个处理器
fan_out = RunnableParallel(
    path1=processor1,
    path2=processor2,
    path3=processor3
)

# 数据流: input → [processor1, processor2, processor3] → {path1, path2, path3}
```

### 11.2 扇入模式（Fan-in）

```python
# 多个输入合并到一个处理器
fan_in = (
    {
        "data1": source1,
        "data2": source2,
        "data3": source3
    }
    | merger
)

# 数据流: [source1, source2, source3] → {data1, data2, data3} → merger
```

### 11.3 管道过滤模式

```python
# 过滤不符合条件的数据
def filter_step(condition):
    def _filter(x):
        if condition(x):
            return x
        else:
            raise ValueError("数据被过滤")
    return RunnableLambda(_filter)

chain = (
    preprocessor
    | filter_step(lambda x: len(x) > 10)  # 过滤短文本
    | processor
)
```

### 11.4 转换-聚合模式

```python
# 转换数据然后聚合
chain = (
    RunnableParallel(
        transformed1=transformer1,
        transformed2=transformer2
    )
    | aggregator
)

# 数据流: input → [transformer1, transformer2] → aggregator
```

---

## 12. 总结

### 数据流转的核心要点

1. **类型匹配**：左边输出 = 右边输入
2. **线性流动**：数据从左到右依次流经每个组件
3. **多路分发**：字典和 RunnableParallel 可以分发数据
4. **透传保留**：RunnablePassthrough 保留原始数据
5. **错误传播**：任何步骤失败，整个流程中断
6. **可观测性**：可以追踪每个步骤的数据变化

### 在 AI Agent 中的价值

- **清晰的数据流**：从输入到输出的路径一目了然
- **类型安全**：编译时检查类型匹配
- **灵活组合**：支持串行、并行、条件等多种模式
- **易于调试**：可以追踪和记录每个步骤

---

## 13. 学习检查

完成本节后，检查是否掌握：

- [ ] 理解线性数据流的执行过程
- [ ] 掌握类型匹配规则
- [ ] 能使用字典和 RunnableParallel 实现多路数据流
- [ ] 理解 RunnablePassthrough 的作用
- [ ] 能追踪和调试数据流
- [ ] 掌握常见的数据流模式

---

[Source: Pinecone LCEL Tutorial - https://www.pinecone.io/learn/series/langchain/langchain-expression-language]
[Source: LangChain Official Docs - https://python.langchain.com/docs/concepts/]
