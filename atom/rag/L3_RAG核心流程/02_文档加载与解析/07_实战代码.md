# 实战代码

> 完整可运行的文档加载与解析示例

---

## 运行环境准备

```bash
# 安装依赖
pip install langchain langchain-community pypdf python-docx beautifulsoup4 chardet
```

---

## 完整示例代码

```python
"""
文档加载与解析 实战示例
演示：5种核心格式的加载、预处理、批量处理
"""

import os
import re
from pathlib import Path
from typing import List, Optional
from dataclasses import dataclass

# ===== 1. 定义 Document 数据结构 =====
print("=== 1. Document 数据结构 ===")

@dataclass
class Document:
    """统一的文档对象"""
    page_content: str
    metadata: dict

    def __repr__(self):
        preview = self.page_content[:50] + "..." if len(self.page_content) > 50 else self.page_content
        return f"Document(content='{preview}', source='{self.metadata.get('source', 'unknown')}')"

# 示例
doc = Document(
    page_content="这是文档内容示例",
    metadata={"source": "example.txt", "page": 1}
)
print(f"创建的文档: {doc}")
print(f"内容: {doc.page_content}")
print(f"来源: {doc.metadata['source']}")
print()

# ===== 2. 各格式 Loader 实现 =====
print("=== 2. 各格式 Loader 实现 ===")

class TextLoader:
    """纯文本加载器"""

    def __init__(self, file_path: str, encoding: str = None):
        self.file_path = file_path
        self.encoding = encoding

    def load(self) -> List[Document]:
        # 自动检测编码
        if self.encoding is None:
            import chardet
            with open(self.file_path, 'rb') as f:
                raw = f.read()
            detected = chardet.detect(raw)
            self.encoding = detected['encoding'] or 'utf-8'

        with open(self.file_path, 'r', encoding=self.encoding) as f:
            content = f.read()

        return [Document(
            page_content=content,
            metadata={
                "source": self.file_path,
                "file_type": "txt",
                "encoding": self.encoding
            }
        )]

class PDFLoader:
    """PDF 加载器（使用 pypdf）"""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def load(self) -> List[Document]:
        from pypdf import PdfReader

        reader = PdfReader(self.file_path)
        documents = []

        for i, page in enumerate(reader.pages):
            text = page.extract_text() or ""
            if text.strip():  # 跳过空页
                documents.append(Document(
                    page_content=text,
                    metadata={
                        "source": self.file_path,
                        "page": i + 1,
                        "total_pages": len(reader.pages),
                        "file_type": "pdf"
                    }
                ))

        return documents

class DocxLoader:
    """Word 文档加载器"""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def load(self) -> List[Document]:
        from docx import Document as DocxDocument

        doc = DocxDocument(self.file_path)
        paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]
        full_text = "\n\n".join(paragraphs)

        return [Document(
            page_content=full_text,
            metadata={
                "source": self.file_path,
                "file_type": "docx",
                "paragraph_count": len(paragraphs)
            }
        )]

class HTMLLoader:
    """HTML 加载器"""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def load(self) -> List[Document]:
        from bs4 import BeautifulSoup

        with open(self.file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()

        soup = BeautifulSoup(html_content, 'html.parser')

        # 移除不需要的标签
        for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']):
            tag.decompose()

        # 提取文本
        text = soup.get_text(separator='\n', strip=True)

        # 提取标题
        title = soup.title.string if soup.title else ""

        return [Document(
            page_content=text,
            metadata={
                "source": self.file_path,
                "title": title,
                "file_type": "html"
            }
        )]

class MarkdownLoader:
    """Markdown 加载器"""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def load(self) -> List[Document]:
        with open(self.file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # 提取标题（第一个 # 开头的行）
        title = ""
        for line in content.split('\n'):
            if line.startswith('# '):
                title = line[2:].strip()
                break

        return [Document(
            page_content=content,
            metadata={
                "source": self.file_path,
                "title": title,
                "file_type": "markdown"
            }
        )]

print("已定义 5 种 Loader: TextLoader, PDFLoader, DocxLoader, HTMLLoader, MarkdownLoader")
print()

# ===== 3. 统一加载接口 =====
print("=== 3. 统一加载接口 ===")

def get_loader(file_path: str):
    """根据文件扩展名返回对应的 Loader"""
    ext = Path(file_path).suffix.lower()

    loader_map = {
        '.txt': TextLoader,
        '.pdf': PDFLoader,
        '.docx': DocxLoader,
        '.html': HTMLLoader,
        '.htm': HTMLLoader,
        '.md': MarkdownLoader,
        '.markdown': MarkdownLoader,
    }

    if ext not in loader_map:
        raise ValueError(f"不支持的文件格式: {ext}")

    return loader_map[ext](file_path)

def load_document(file_path: str) -> List[Document]:
    """加载单个文档"""
    try:
        loader = get_loader(file_path)
        return loader.load()
    except FileNotFoundError:
        print(f"文件不存在: {file_path}")
        return []
    except Exception as e:
        print(f"加载失败 {file_path}: {e}")
        return []

print("统一加载接口已定义")
print()

# ===== 4. 文档预处理 =====
print("=== 4. 文档预处理 ===")

def preprocess_document(doc: Document) -> Optional[Document]:
    """预处理文档内容"""
    text = doc.page_content

    # 1. 清理多余空白
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()

    # 2. 移除常见的页眉页脚模式
    text = re.sub(r'第\s*\d+\s*页.*?共\s*\d+\s*页', '', text)
    text = re.sub(r'Page\s*\d+\s*of\s*\d+', '', text, flags=re.IGNORECASE)

    # 3. 移除特殊字符
    text = text.replace('\x00', '')  # 空字符
    text = text.replace('\ufeff', '')  # BOM

    # 4. 检查内容是否有效
    if len(text) < 10:
        return None

    return Document(
        page_content=text,
        metadata=doc.metadata
    )

# 示例
raw_doc = Document(
    page_content="  这是   一段   有很多   空格的   文本   第 1 页 / 共 10 页  ",
    metadata={"source": "test.txt"}
)
processed = preprocess_document(raw_doc)
print(f"预处理前: '{raw_doc.page_content}'")
print(f"预处理后: '{processed.page_content}'")
print()

# ===== 5. 批量加载目录 =====
print("=== 5. 批量加载目录 ===")

def load_directory(dir_path: str, recursive: bool = True) -> List[Document]:
    """批量加载目录下的所有文档"""
    supported_extensions = {'.txt', '.pdf', '.docx', '.html', '.htm', '.md', '.markdown'}
    all_documents = []

    # 选择遍历方式
    if recursive:
        files = Path(dir_path).rglob('*')
    else:
        files = Path(dir_path).glob('*')

    for file_path in files:
        if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
            try:
                docs = load_document(str(file_path))
                # 预处理
                for doc in docs:
                    processed = preprocess_document(doc)
                    if processed:
                        all_documents.append(processed)
                print(f"✓ 加载成功: {file_path.name}")
            except Exception as e:
                print(f"✗ 加载失败: {file_path.name} - {e}")

    return all_documents

print("批量加载函数已定义")
print()

# ===== 6. RAG 开发应用示例 =====
print("=== 6. RAG 开发应用示例 ===")

def build_knowledge_base(docs_dir: str) -> dict:
    """
    构建知识库的完整流程
    这是 RAG 系统离线索引阶段的第一步
    """
    print(f"开始构建知识库，文档目录: {docs_dir}")

    # Step 1: 加载所有文档
    documents = load_directory(docs_dir)
    print(f"加载了 {len(documents)} 个文档块")

    # Step 2: 统计信息
    stats = {
        "total_documents": len(documents),
        "by_type": {},
        "total_characters": 0
    }

    for doc in documents:
        file_type = doc.metadata.get("file_type", "unknown")
        stats["by_type"][file_type] = stats["by_type"].get(file_type, 0) + 1
        stats["total_characters"] += len(doc.page_content)

    print(f"文档类型分布: {stats['by_type']}")
    print(f"总字符数: {stats['total_characters']}")

    # Step 3: 返回结果（后续传给分块器）
    return {
        "documents": documents,
        "stats": stats
    }

# 模拟使用（实际使用时替换为真实目录）
print("\n模拟知识库构建流程:")
print("knowledge_base = build_knowledge_base('./docs/')")
print("# 然后将 documents 传给 TextSplitter 进行分块")
print("# chunks = text_splitter.split_documents(knowledge_base['documents'])")
print()

# ===== 7. 使用 LangChain 的简化版本 =====
print("=== 7. 使用 LangChain（推荐） ===")

langchain_example = '''
# 实际项目中推荐使用 LangChain，代码更简洁

from langchain_community.document_loaders import (
    PyPDFLoader,
    Docx2txtLoader,
    UnstructuredHTMLLoader,
    UnstructuredMarkdownLoader,
    TextLoader,
    DirectoryLoader
)

# 单文件加载
loader = PyPDFLoader("policy.pdf")
docs = loader.load()

# 批量加载目录
loader = DirectoryLoader(
    "./docs/",
    glob="**/*.pdf",
    loader_cls=PyPDFLoader
)
docs = loader.load()

# 多格式混合加载
from langchain_community.document_loaders import DirectoryLoader

loaders = [
    DirectoryLoader("./docs/", glob="**/*.pdf", loader_cls=PyPDFLoader),
    DirectoryLoader("./docs/", glob="**/*.txt", loader_cls=TextLoader),
    DirectoryLoader("./docs/", glob="**/*.docx", loader_cls=Docx2txtLoader),
]

all_docs = []
for loader in loaders:
    all_docs.extend(loader.load())

print(f"总共加载 {len(all_docs)} 个文档")
'''

print(langchain_example)
print()

print("=== 示例运行完成 ===")
```

---

## 运行输出示例

```
=== 1. Document 数据结构 ===
创建的文档: Document(content='这是文档内容示例', source='example.txt')
内容: 这是文档内容示例
来源: example.txt

=== 2. 各格式 Loader 实现 ===
已定义 5 种 Loader: TextLoader, PDFLoader, DocxLoader, HTMLLoader, MarkdownLoader

=== 3. 统一加载接口 ===
统一加载接口已定义

=== 4. 文档预处理 ===
预处理前: '  这是   一段   有很多   空格的   文本   第 1 页 / 共 10 页  '
预处理后: '这是 一段 有很多 空格的 文本'

=== 5. 批量加载目录 ===
批量加载函数已定义

=== 6. RAG 开发应用示例 ===
模拟知识库构建流程:
knowledge_base = build_knowledge_base('./docs/')
# 然后将 documents 传给 TextSplitter 进行分块
# chunks = text_splitter.split_documents(knowledge_base['documents'])

=== 7. 使用 LangChain（推荐） ===
[LangChain 示例代码]

=== 示例运行完成 ===
```

---

## 代码要点总结

| 模块 | 作用 | 关键代码 |
|-----|------|---------|
| Document | 统一数据结构 | `page_content` + `metadata` |
| Loader | 格式解析 | `load() -> List[Document]` |
| get_loader | 自动选择 | 根据扩展名映射 |
| preprocess | 清理噪音 | 正则替换 + 长度检查 |
| load_directory | 批量处理 | `Path.rglob()` + 异常处理 |

---

**下一步：** [08_面试必问](./08_面试必问.md) - 准备文档加载相关的面试问题
