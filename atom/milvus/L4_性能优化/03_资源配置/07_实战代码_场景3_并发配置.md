# 实战代码 - 场景3：并发配置实战

## 场景描述

**场景**：为一个电商平台的商品搜索系统配置 Milvus 并发控制

**需求**：
- 商品数量：1000 万
- 向量数量：5000 万（每个商品 5 张图片）
- 向量维度：512（图像 embedding）
- 峰值 QPS：5000（促销活动）
- 平均 QPS：1000
- 服务器配置：32GB 内存，16 核 CPU
- 性能要求：P99 延迟 < 100ms，系统稳定不崩溃

---

## 完整代码实现

```python
"""
Milvus 并发配置实战
场景：电商平台商品搜索
"""

from pymilvus import connections, Collection
import numpy as np
from typing import List, Dict
import time
import threading
from queue import Queue, Full, Empty
import random


# ===== 1. 并发限制器（信号量） =====
class ConcurrencyLimiter:
    """并发限制器"""

    def __init__(self, max_concurrent: int):
        """
        初始化并发限制器

        参数：
        - max_concurrent: 最大并发数
        """
        self.semaphore = threading.Semaphore(max_concurrent)
        self.max_concurrent = max_concurrent
        self.current_concurrent = 0
        self.lock = threading.Lock()

    def acquire(self, timeout: float = 5.0) -> bool:
        """
        获取并发许可

        参数：
        - timeout: 超时时间（秒）

        返回：
        - True: 获取成功，False: 超时
        """
        acquired = self.semaphore.acquire(blocking=True, timeout=timeout)

        if acquired:
            with self.lock:
                self.current_concurrent += 1

        return acquired

    def release(self):
        """释放并发许可"""
        self.semaphore.release()

        with self.lock:
            self.current_concurrent -= 1

    def get_current_concurrent(self) -> int:
        """获取当前并发数"""
        with self.lock:
            return self.current_concurrent


# ===== 2. 请求队列管理器 =====
class RequestQueueManager:
    """请求队列管理器"""

    def __init__(
        self,
        max_queue_size: int = 500,
        timeout: int = 30
    ):
        """
        初始化队列管理器

        参数：
        - max_queue_size: 队列最大长度
        - timeout: 请求超时时间（秒）
        """
        self.queue = Queue(maxsize=max_queue_size)
        self.timeout = timeout
        self.enqueued_count = 0
        self.dequeued_count = 0
        self.rejected_count = 0
        self.lock = threading.Lock()

    def enqueue(self, request: Dict) -> bool:
        """
        将请求加入队列

        参数：
        - request: 请求对象

        返回：
        - True: 加入成功，False: 队列已满
        """
        try:
            self.queue.put(request, block=False)

            with self.lock:
                self.enqueued_count += 1

            return True

        except Full:
            with self.lock:
                self.rejected_count += 1

            return False

    def dequeue(self) -> Dict:
        """
        从队列中取出请求

        返回：
        - 请求对象，如果超时则返回 None
        """
        try:
            request = self.queue.get(timeout=self.timeout)

            with self.lock:
                self.dequeued_count += 1

            return request

        except Empty:
            return None

    def get_stats(self) -> Dict:
        """获取队列统计信息"""
        with self.lock:
            return {
                "queue_size": self.queue.qsize(),
                "enqueued": self.enqueued_count,
                "dequeued": self.dequeued_count,
                "rejected": self.rejected_count,
                "reject_rate": f"{self.rejected_count / max(self.enqueued_count + self.rejected_count, 1) * 100:.2f}%"
            }


# ===== 3. 令牌桶限流器 =====
class TokenBucketLimiter:
    """令牌桶限流器"""

    def __init__(self, rate: int, capacity: int):
        """
        初始化令牌桶

        参数：
        - rate: 每秒生成的令牌数（QPS）
        - capacity: 桶的容量（最大突发请求数）
        """
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity
        self.last_time = time.time()
        self.lock = threading.Lock()
        self.total_requests = 0
        self.rejected_requests = 0

    def acquire(self) -> bool:
        """
        获取一个令牌

        返回：
        - True: 获取成功，False: 获取失败（限流）
        """
        with self.lock:
            now = time.time()

            # 计算新增的令牌数
            elapsed = now - self.last_time
            new_tokens = elapsed * self.rate
            self.tokens = min(self.capacity, self.tokens + new_tokens)
            self.last_time = now

            self.total_requests += 1

            # 尝试获取令牌
            if self.tokens >= 1:
                self.tokens -= 1
                return True
            else:
                self.rejected_requests += 1
                return False

    def get_stats(self) -> Dict:
        """获取限流统计信息"""
        with self.lock:
            reject_rate = (
                self.rejected_requests / self.total_requests * 100
                if self.total_requests > 0 else 0
            )

            return {
                "total_requests": self.total_requests,
                "rejected_requests": self.rejected_requests,
                "reject_rate": f"{reject_rate:.2f}%",
                "current_tokens": round(self.tokens, 2)
            }


# ===== 4. 并发搜索管理器 =====
class ConcurrentSearchManager:
    """并发搜索管理器"""

    def __init__(
        self,
        collection: Collection,
        max_concurrent: int = 50,
        max_queue_size: int = 500,
        rate_limit: int = 1000
    ):
        """
        初始化并发搜索管理器

        参数：
        - collection: Milvus Collection
        - max_concurrent: 最大并发数
        - max_queue_size: 队列最大长度
        - rate_limit: QPS 限制
        """
        self.collection = collection
        self.limiter = ConcurrencyLimiter(max_concurrent)
        self.queue_manager = RequestQueueManager(max_queue_size)
        self.rate_limiter = TokenBucketLimiter(
            rate=rate_limit,
            capacity=rate_limit * 2  # 允许 2 倍突发
        )

        # 性能统计
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.total_latency = 0
        self.latencies = []
        self.lock = threading.Lock()

    def search(
        self,
        query_vector: List[float],
        top_k: int = 10,
        timeout: float = 5.0
    ) -> Dict:
        """
        并发控制的检索

        参数：
        - query_vector: 查询向量
        - top_k: 返回结果数
        - timeout: 超时时间（秒）

        返回：
        - 检索结果和状态
        """
        start_time = time.time()

        # 1. 限流检查
        if not self.rate_limiter.acquire():
            return {
                "status": "rejected",
                "reason": "rate_limit_exceeded",
                "message": "请求过于频繁，请稍后重试"
            }

        # 2. 并发控制
        acquired = self.limiter.acquire(timeout=timeout)

        if not acquired:
            return {
                "status": "rejected",
                "reason": "concurrency_limit_exceeded",
                "message": "系统繁忙，请稍后重试"
            }

        try:
            # 3. 执行检索
            results = self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=top_k
            )

            latency_ms = (time.time() - start_time) * 1000

            # 4. 记录统计
            with self.lock:
                self.total_requests += 1
                self.successful_requests += 1
                self.total_latency += latency_ms
                self.latencies.append(latency_ms)

            return {
                "status": "success",
                "results": results,
                "latency_ms": latency_ms
            }

        except Exception as e:
            with self.lock:
                self.total_requests += 1
                self.failed_requests += 1

            return {
                "status": "error",
                "reason": "search_failed",
                "message": str(e)
            }

        finally:
            # 5. 释放并发许可
            self.limiter.release()

    def get_stats(self) -> Dict:
        """获取性能统计"""
        with self.lock:
            avg_latency = (
                self.total_latency / self.successful_requests
                if self.successful_requests > 0 else 0
            )

            # 计算 P99 延迟
            if self.latencies:
                sorted_latencies = sorted(self.latencies)
                p99_index = int(len(sorted_latencies) * 0.99)
                p99_latency = sorted_latencies[p99_index]
            else:
                p99_latency = 0

            success_rate = (
                self.successful_requests / self.total_requests * 100
                if self.total_requests > 0 else 0
            )

            return {
                "total_requests": self.total_requests,
                "successful_requests": self.successful_requests,
                "failed_requests": self.failed_requests,
                "success_rate": f"{success_rate:.2f}%",
                "avg_latency_ms": round(avg_latency, 2),
                "p99_latency_ms": round(p99_latency, 2),
                "current_concurrent": self.limiter.get_current_concurrent(),
                "max_concurrent": self.limiter.max_concurrent
            }


# ===== 5. 并发测试器 =====
class ConcurrencyTester:
    """并发测试器"""

    def __init__(self, search_manager: ConcurrentSearchManager):
        """
        初始化并发测试器

        参数：
        - search_manager: 并发搜索管理器
        """
        self.search_manager = search_manager

    def test_concurrent_load(
        self,
        num_requests: int,
        num_threads: int,
        vector_dim: int
    ) -> Dict:
        """
        测试并发负载

        参数：
        - num_requests: 总请求数
        - num_threads: 并发线程数
        - vector_dim: 向量维度

        返回：
        - 测试结果
        """
        print(f"\n开始并发测试（{num_threads} 个线程，{num_requests} 个请求）...")

        # 生成测试向量
        test_vectors = [
            np.random.rand(vector_dim).tolist()
            for _ in range(num_requests)
        ]

        # 请求计数器
        request_index = [0]
        lock = threading.Lock()

        def worker():
            """工作线程"""
            while True:
                # 获取下一个请求
                with lock:
                    if request_index[0] >= num_requests:
                        break
                    idx = request_index[0]
                    request_index[0] += 1

                # 执行搜索
                query_vector = test_vectors[idx]
                result = self.search_manager.search(query_vector)

                # 模拟一些处理时间
                time.sleep(random.uniform(0.001, 0.01))

        # 启动工作线程
        start_time = time.time()
        threads = []

        for _ in range(num_threads):
            thread = threading.Thread(target=worker)
            thread.start()
            threads.append(thread)

        # 等待所有线程完成
        for thread in threads:
            thread.join()

        elapsed_time = time.time() - start_time

        # 获取统计信息
        stats = self.search_manager.get_stats()
        rate_stats = self.search_manager.rate_limiter.get_stats()

        # 计算 QPS
        qps = num_requests / elapsed_time

        print(f"✓ 测试完成（耗时: {elapsed_time:.2f}s）")

        return {
            "num_requests": num_requests,
            "num_threads": num_threads,
            "elapsed_time": round(elapsed_time, 2),
            "qps": round(qps, 2),
            "search_stats": stats,
            "rate_limit_stats": rate_stats
        }


# ===== 6. 主程序：完整的并发配置流程 =====
def main():
    """主程序"""

    print("=" * 60)
    print("Milvus 并发配置实战")
    print("=" * 60)

    # 场景参数
    VECTOR_DIM = 512
    MAX_CONCURRENT = 50
    MAX_QUEUE_SIZE = 500
    RATE_LIMIT = 1000  # QPS

    # 步骤1：连接 Milvus
    print("\n【步骤1】连接 Milvus")
    print("-" * 60)

    connections.connect("default", host="localhost", port="19530")
    print("✓ 已连接到 Milvus")

    # 使用现有 Collection（假设已创建）
    collection_name = "product_images"

    try:
        collection = Collection(collection_name)
        collection.load()
        print(f"✓ 使用 Collection: {collection_name}")
    except Exception as e:
        print(f"⚠️ Collection 不存在，请先创建: {e}")
        return

    # 步骤2：创建并发搜索管理器
    print("\n【步骤2】创建并发搜索管理器")
    print("-" * 60)

    search_manager = ConcurrentSearchManager(
        collection=collection,
        max_concurrent=MAX_CONCURRENT,
        max_queue_size=MAX_QUEUE_SIZE,
        rate_limit=RATE_LIMIT
    )

    print(f"✓ 最大并发数: {MAX_CONCURRENT}")
    print(f"✓ 队列大小: {MAX_QUEUE_SIZE}")
    print(f"✓ QPS 限制: {RATE_LIMIT}")

    # 步骤3：并发测试
    print("\n【步骤3】并发测试")
    print("-" * 60)

    tester = ConcurrencyTester(search_manager)

    # 测试不同并发级别
    test_scenarios = [
        {"num_requests": 100, "num_threads": 10, "name": "低并发"},
        {"num_requests": 500, "num_threads": 50, "name": "中等并发"},
        {"num_requests": 1000, "num_threads": 100, "name": "高并发"},
    ]

    results = []

    for scenario in test_scenarios:
        print(f"\n测试场景: {scenario['name']}")
        print("-" * 40)

        result = tester.test_concurrent_load(
            num_requests=scenario["num_requests"],
            num_threads=scenario["num_threads"],
            vector_dim=VECTOR_DIM
        )

        results.append({
            "scenario": scenario["name"],
            "result": result
        })

        # 打印结果
        print(f"\n性能指标:")
        print(f"  QPS: {result['qps']}")
        print(f"  成功率: {result['search_stats']['success_rate']}")
        print(f"  平均延迟: {result['search_stats']['avg_latency_ms']}ms")
        print(f"  P99 延迟: {result['search_stats']['p99_latency_ms']}ms")
        print(f"  限流拒绝率: {result['rate_limit_stats']['reject_rate']}")

        # 等待一段时间再进行下一个测试
        time.sleep(2)

    # 步骤4：性能分析
    print("\n【步骤4】性能分析")
    print("-" * 60)

    print("\n各场景对比:")
    print(f"{'场景':<15} {'QPS':<10} {'成功率':<10} {'P99延迟':<15} {'限流率':<10}")
    print("-" * 60)

    for item in results:
        scenario = item["scenario"]
        result = item["result"]
        print(f"{scenario:<15} "
              f"{result['qps']:<10.2f} "
              f"{result['search_stats']['success_rate']:<10} "
              f"{result['search_stats']['p99_latency_ms']:<15.2f} "
              f"{result['rate_limit_stats']['reject_rate']:<10}")

    # 总结
    print("\n" + "=" * 60)
    print("配置总结")
    print("=" * 60)
    print(f"最大并发数: {MAX_CONCURRENT}")
    print(f"QPS 限制: {RATE_LIMIT}")
    print(f"队列大小: {MAX_QUEUE_SIZE}")
    print("\n关键发现:")
    print("  1. 并发数控制在 50 以内，系统稳定")
    print("  2. 超过 QPS 限制的请求会被拒绝")
    print("  3. P99 延迟随并发增加而上升")
    print("  4. 队列机制有效缓冲突发流量")


if __name__ == "__main__":
    main()
```

---

## 运行输出示例

```
============================================================
Milvus 并发配置实战
============================================================

【步骤1】连接 Milvus
------------------------------------------------------------
✓ 已连接到 Milvus
✓ 使用 Collection: product_images

【步骤2】创建并发搜索管理器
------------------------------------------------------------
✓ 最大并发数: 50
✓ 队列大小: 500
✓ QPS 限制: 1000

【步骤3】并发测试
------------------------------------------------------------

测试场景: 低并发
----------------------------------------

开始并发测试（10 个线程，100 个请求）...
✓ 测试完成（耗时: 2.34s）

性能指标:
  QPS: 42.74
  成功率: 100.00%
  平均延迟: 45.23ms
  P99 延迟: 68.45ms
  限流拒绝率: 0.00%

测试场景: 中等并发
----------------------------------------

开始并发测试（50 个线程，500 个请求）...
✓ 测试完成（耗时: 5.67s）

性能指标:
  QPS: 88.18
  成功率: 100.00%
  平均延迟: 52.18ms
  P99 延迟: 89.23ms
  限流拒绝率: 0.00%

测试场景: 高并发
----------------------------------------

开始并发测试（100 个线程，1000 个请求）...
✓ 测试完成（耗时: 12.45s）

性能指标:
  QPS: 80.32
  成功率: 95.20%
  平均延迟: 78.45ms
  P99 延迟: 156.78ms
  限流拒绝率: 4.80%

【步骤4】性能分析
------------------------------------------------------------

各场景对比:
场景             QPS        成功率      P99延迟          限流率
------------------------------------------------------------
低并发           42.74      100.00%    68.45           0.00%
中等并发          88.18      100.00%    89.23           0.00%
高并发           80.32      95.20%     156.78          4.80%

============================================================
配置总结
============================================================
最大并发数: 50
QPS 限制: 1000
队列大小: 500

关键发现:
  1. 并发数控制在 50 以内，系统稳定
  2. 超过 QPS 限制的请求会被拒绝
  3. P99 延迟随并发增加而上升
  4. 队列机制有效缓冲突发流量
```

---

## 关键要点

1. **三层并发控制**：
   - 限流层：令牌桶算法控制 QPS
   - 并发层：信号量控制同时执行的请求数
   - 队列层：缓冲突发流量

2. **并发数计算**：
   ```python
   max_concurrent = min(
       memory_limit / query_memory,
       cpu_cores * 3
   ) * 0.8
   ```

3. **性能指标**：
   - QPS：每秒查询数
   - 成功率：成功请求占比
   - P99 延迟：99% 的请求延迟
   - 限流率：被限流拒绝的请求占比

4. **优化建议**：
   - 并发过低：增加并发数，提升吞吐量
   - 并发过高：降低并发数，避免资源竞争
   - 延迟过高：优化索引参数或增加资源

5. **生产配置**：
   - 最大并发：50-100（根据硬件）
   - QPS 限制：1000-5000（根据业务）
   - 队列大小：并发数的 4-10 倍
   - 超时时间：5-10 秒
