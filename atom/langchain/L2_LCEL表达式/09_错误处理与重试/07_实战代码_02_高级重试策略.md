# 实战代码2：高级重试策略

## 概述

本文提供高级重试策略的完整可运行示例，涵盖：
- 指数退避重试
- 异常类型过滤
- 自定义重试条件
- 重试回调和日志
- 生产级配置

所有代码都可以直接复制运行。

---

## 示例1：指数退避与随机抖动

**场景：** 避免"雪崩效应"，分散重试时间

```python
"""
指数退避与随机抖动
演示：wait_exponential_jitter 的实际效果
"""

from langchain_openai import ChatOpenAI
from openai import RateLimitError
from dotenv import load_dotenv
import time

load_dotenv()

# ===== 1. 模拟速率限制场景 =====
print("=== 指数退避重试 ===\n")

# 创建带指数退避的 LLM
llm = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=5,
    wait_exponential_jitter=True  # 启用指数退避 + 随机抖动
)

# ===== 2. 测试重试行为 =====
print("测试重试行为（如果触发速率限制）:\n")

start_time = time.time()

try:
    response = llm.invoke("你好")
    elapsed = time.time() - start_time
    print(f"✅ 成功")
    print(f"总耗时: {elapsed:.2f} 秒")
    print(f"响应: {response.content[:50]}...")
except RateLimitError as e:
    elapsed = time.time() - start_time
    print(f"❌ 速率限制（重试5次后仍失败）")
    print(f"总耗时: {elapsed:.2f} 秒")

# ===== 3. 解释指数退避 =====
print("\n=== 指数退避时间表 ===")
print("如果每次都失败，等待时间如下:")
print("第1次失败: 等待 ~1 秒 (1 ± jitter)")
print("第2次失败: 等待 ~2 秒 (2 ± jitter)")
print("第3次失败: 等待 ~4 秒 (4 ± jitter)")
print("第4次失败: 等待 ~8 秒 (8 ± jitter)")
print("第5次失败: 抛出异常")
print("\n总等待时间: ~15 秒")
print("jitter (抖动): ±20% 随机变化，避免同时重试")
```

---

## 示例2：自定义等待策略

**场景：** 根据业务需求自定义等待时间

```python
"""
自定义等待策略
演示：使用 tenacity 库的高级配置
"""

from langchain_openai import ChatOpenAI
from openai import RateLimitError, APIError
from tenacity import wait_exponential, wait_fixed, wait_random, wait_combine
from dotenv import load_dotenv

load_dotenv()

print("=== 自定义等待策略 ===\n")

# ===== 策略1：标准指数退避 =====
print("--- 策略1: 标准指数退避 ---")
llm1 = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=4,
    wait=wait_exponential(
        multiplier=1,  # 基础乘数
        min=1,         # 最小等待时间
        max=60         # 最大等待时间
    )
)
print("等待时间: 1s, 2s, 4s, 8s")

# ===== 策略2: 激进的指数退避（速率限制专用）=====
print("\n--- 策略2: 激进的指数退避 ---")
llm2 = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=5,
    wait=wait_exponential(
        multiplier=2,  # 更大的乘数
        min=2,         # 更长的最小等待
        max=120        # 更长的最大等待
    ),
    retry_if_exception_type=(RateLimitError,)
)
print("等待时间: 2s, 4s, 8s, 16s, 32s")
print("适用场景: 严重的速率限制")

# ===== 策略3: 固定等待 =====
print("\n--- 策略3: 固定等待 ---")
llm3 = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait=wait_fixed(2)  # 每次等待 2 秒
)
print("等待时间: 2s, 2s, 2s")
print("适用场景: 简单的重试，不需要指数退避")

# ===== 策略4: 随机等待 =====
print("\n--- 策略4: 随机等待 ---")
llm4 = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait=wait_random(min=1, max=5)  # 随机等待 1-5 秒
)
print("等待时间: 1-5s (随机), 1-5s (随机), 1-5s (随机)")
print("适用场景: 避免同步重试")

# ===== 策略5: 组合等待 =====
print("\n--- 策略5: 组合等待 ---")
llm5 = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait=wait_combine(
        wait_fixed(1),      # 固定 1 秒
        wait_random(0, 2)   # + 随机 0-2 秒
    )
)
print("等待时间: 1-3s, 1-3s, 1-3s")
print("适用场景: 固定基础时间 + 随机抖动")

# ===== 测试 =====
print("\n=== 测试策略1（标准指数退避）===")
try:
    response = llm1.invoke("测试")
    print(f"✅ 成功: {response.content[:30]}...")
except Exception as e:
    print(f"❌ 失败: {type(e).__name__}")
```

---

## 示例3：异常类型过滤

**场景：** 只对特定类型的错误进行重试

```python
"""
异常类型过滤
演示：retry_if_exception_type 的使用
"""

from langchain_openai import ChatOpenAI
from openai import (
    RateLimitError,
    APIError,
    Timeout,
    APIConnectionError,
    AuthenticationError,
    InvalidRequestError
)
from dotenv import load_dotenv

load_dotenv()

print("=== 异常类型过滤 ===\n")

# ===== 1. 定义可重试的错误 =====
RETRYABLE_ERRORS = (
    RateLimitError,        # 速率限制
    APIError,              # API 服务器错误
    Timeout,               # 超时
    APIConnectionError,    # 连接错误
)

NON_RETRYABLE_ERRORS = (
    AuthenticationError,   # 认证错误
    InvalidRequestError,   # 请求参数错误
)

print("可重试的错误:")
for error in RETRYABLE_ERRORS:
    print(f"  - {error.__name__}")

print("\n不可重试的错误:")
for error in NON_RETRYABLE_ERRORS:
    print(f"  - {error.__name__}")

# ===== 2. 创建带异常过滤的 LLM =====
print("\n=== 创建 LLM ===")

llm = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True,
    retry_if_exception_type=RETRYABLE_ERRORS
)

print("✅ LLM 创建成功")
print("配置: 只重试 RateLimitError, APIError, Timeout, APIConnectionError")

# ===== 3. 测试不同错误类型 =====
print("\n=== 测试场景 ===")

# 场景1: 正常调用
print("\n场景1: 正常调用")
try:
    response = llm.invoke("你好")
    print(f"✅ 成功: {response.content[:30]}...")
except Exception as e:
    print(f"❌ 失败: {type(e).__name__}")

# 场景2: 模拟认证错误（不会重试）
print("\n场景2: 认证错误（不会重试）")
print("说明: AuthenticationError 不在重试列表中")
print("预期行为: 立即失败，不重试")

# 场景3: 模拟速率限制（会重试）
print("\n场景3: 速率限制（会重试）")
print("说明: RateLimitError 在重试列表中")
print("预期行为: 重试最多 3 次")

# ===== 4. 实际应用建议 =====
print("\n=== 实际应用建议 ===")
print("1. 临时错误（可重试）:")
print("   - RateLimitError: 速率限制")
print("   - APIError: API 服务器错误")
print("   - Timeout: 超时")
print("   - APIConnectionError: 连接错误")
print("\n2. 永久错误（不可重试）:")
print("   - AuthenticationError: API key 错误")
print("   - InvalidRequestError: 请求参数错误")
print("   - NotFoundError: 资源不存在")
print("\n3. 快速失败原则:")
print("   永久错误应该立即失败，不浪费时间重试")
```

---

## 示例4：重试回调与日志

**场景：** 监控重试过程，记录日志

```python
"""
重试回调与日志
演示：before_sleep 和 after 回调的使用
"""

from langchain_openai import ChatOpenAI
from openai import RateLimitError, APIError
from tenacity import before_sleep_log, after_log
from dotenv import load_dotenv
import logging

# ===== 1. 配置日志 =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

load_dotenv()

print("=== 重试回调与日志 ===\n")

# ===== 2. 创建带日志的 LLM =====
llm = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True,
    retry_if_exception_type=(RateLimitError, APIError),
    before_sleep=before_sleep_log(logger, logging.WARNING),  # 重试前记录
    after=after_log(logger, logging.INFO)  # 重试后记录
)

print("✅ LLM 创建成功（带日志）\n")

# ===== 3. 测试 =====
test_prompts = [
    "什么是 Python？",
    "什么是 JavaScript？",
    "什么是 Go？"
]

for i, prompt in enumerate(test_prompts):
    logger.info(f"[{i+1}/{len(test_prompts)}] 处理: {prompt}")
    try:
        response = llm.invoke(prompt)
        logger.info(f"成功，响应长度: {len(response.content)} 字符")
        print(f"✅ [{i+1}] {prompt[:20]}...")
    except Exception as e:
        logger.error(f"失败: {type(e).__name__}: {e}")
        print(f"❌ [{i+1}] {prompt[:20]}...")

print("\n=== 日志说明 ===")
print("- INFO: 正常信息")
print("- WARNING: 重试前的警告（包含等待时间）")
print("- ERROR: 最终失败的错误")
```

---

## 示例5：自定义重试条件

**场景：** 根据错误内容决定是否重试

```python
"""
自定义重试条件
演示：retry 参数的高级用法
"""

from langchain_openai import ChatOpenAI
from tenacity import retry_if_exception, retry_if_exception_type
from openai import APIError
from dotenv import load_dotenv

load_dotenv()

print("=== 自定义重试条件 ===\n")

# ===== 1. 自定义重试条件函数 =====
def should_retry_on_api_error(exception):
    """
    自定义重试条件：只对特定的 API 错误重试
    """
    if not isinstance(exception, APIError):
        return False

    # 检查错误消息
    error_message = str(exception).lower()

    # 可重试的错误消息关键词
    retryable_keywords = [
        "rate limit",
        "timeout",
        "temporarily unavailable",
        "service unavailable",
        "internal server error"
    ]

    # 检查是否包含可重试的关键词
    for keyword in retryable_keywords:
        if keyword in error_message:
            print(f"  检测到可重试错误: {keyword}")
            return True

    print(f"  检测到不可重试错误: {error_message[:50]}")
    return False

# ===== 2. 创建带自定义条件的 LLM =====
llm = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=3,
    wait_exponential_jitter=True,
    retry=retry_if_exception(should_retry_on_api_error)
)

print("✅ LLM 创建成功（自定义重试条件）\n")

# ===== 3. 测试 =====
print("=== 测试 ===")
try:
    response = llm.invoke("你好")
    print(f"✅ 成功: {response.content[:30]}...")
except Exception as e:
    print(f"❌ 失败: {type(e).__name__}: {e}")

# ===== 4. 说明 =====
print("\n=== 自定义条件说明 ===")
print("可重试的错误消息关键词:")
print("  - 'rate limit'")
print("  - 'timeout'")
print("  - 'temporarily unavailable'")
print("  - 'service unavailable'")
print("  - 'internal server error'")
print("\n其他错误消息: 不重试，立即失败")
```

---

## 示例6：多层重试策略

**场景：** 不同组件使用不同的重试策略

```python
"""
多层重试策略
演示：为不同组件配置不同的重试策略
"""

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from openai import RateLimitError, APIError, Timeout
from dotenv import load_dotenv

load_dotenv()

print("=== 多层重试策略 ===\n")

# ===== 1. Embedding 层（快速失败）=====
print("--- 第1层: Embedding（快速失败）---")
embeddings = OpenAIEmbeddings().with_retry(
    stop_after_attempt=2,  # 只重试 2 次
    wait_exponential_jitter=True,
    retry_if_exception_type=(Timeout,)  # 只重试超时
)
print("配置: 重试2次，只重试超时错误")

# ===== 2. LLM 层（关键组件，更多重试）=====
print("\n--- 第2层: LLM（关键组件）---")
llm = ChatOpenAI(model="gpt-4").with_retry(
    stop_after_attempt=5,  # 重试 5 次
    wait_exponential_jitter=True,
    retry_if_exception_type=(RateLimitError, APIError, Timeout)
)
print("配置: 重试5次，重试多种错误")

# ===== 3. Parser 层（基础重试）=====
print("\n--- 第3层: Parser（基础重试）---")
parser = JsonOutputParser().with_retry(
    stop_after_attempt=2  # 重试 2 次
)
print("配置: 重试2次，重试所有错误")

# ===== 4. 构建链 =====
print("\n=== 构建链 ===")
prompt = ChatPromptTemplate.from_template(
    "以 JSON 格式返回: {query}\n"
    "格式: {{\"answer\": \"...\", \"confidence\": 0.0-1.0}}"
)

chain = prompt | llm | parser
print("✅ 链构建成功")

# ===== 5. 测试 =====
print("\n=== 测试 ===")
try:
    result = chain.invoke({"query": "什么是 LangChain？"})
    print(f"✅ 成功")
    print(f"结果: {result}")
except Exception as e:
    print(f"❌ 失败: {type(e).__name__}: {e}")

# ===== 6. 策略说明 =====
print("\n=== 策略说明 ===")
print("1. Embedding: 快速失败（2次重试）")
print("   原因: 非关键组件，失败影响小")
print("\n2. LLM: 关键保护（5次重试）")
print("   原因: 核心组件，失败影响大")
print("\n3. Parser: 基础重试（2次重试）")
print("   原因: 轻量级组件，快速重试")
```

---

## 示例7：生产级重试配置模板

**场景：** 可复用的生产级配置

```python
"""
生产级重试配置模板
演示：可复用的配置函数
"""

from langchain_openai import ChatOpenAI
from openai import RateLimitError, APIError, Timeout, APIConnectionError
from tenacity import wait_exponential, before_sleep_log, after_log
from dotenv import load_dotenv
import logging

# ===== 1. 配置日志 =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

load_dotenv()

print("=== 生产级重试配置模板 ===\n")

# ===== 2. 定义可重试的错误 =====
RETRYABLE_ERRORS = (
    RateLimitError,
    APIError,
    Timeout,
    APIConnectionError
)

# ===== 3. 创建配置函数 =====
def create_production_llm(
    model="gpt-4",
    max_retries=5,
    timeout=30,
    log_level=logging.WARNING
):
    """
    创建生产级 LLM

    参数:
        model: 模型名称
        max_retries: 最大重试次数
        timeout: 超时时间（秒）
        log_level: 日志级别
    """
    return ChatOpenAI(
        model=model,
        timeout=timeout
    ).with_retry(
        stop_after_attempt=max_retries,
        wait=wait_exponential(
            multiplier=1,
            min=1,
            max=60
        ),
        retry_if_exception_type=RETRYABLE_ERRORS,
        before_sleep=before_sleep_log(logger, log_level),
        after=after_log(logger, logging.INFO)
    )

# ===== 4. 使用模板 =====
print("--- 创建不同配置的 LLM ---\n")

# 配置1: 标准生产配置
llm_standard = create_production_llm(
    model="gpt-4",
    max_retries=5,
    timeout=30
)
print("✅ 标准配置: GPT-4, 5次重试, 30秒超时")

# 配置2: 快速失败配置
llm_fast_fail = create_production_llm(
    model="gpt-3.5-turbo",
    max_retries=2,
    timeout=10
)
print("✅ 快速失败: GPT-3.5, 2次重试, 10秒超时")

# 配置3: 高可用配置
llm_high_availability = create_production_llm(
    model="gpt-4",
    max_retries=7,
    timeout=60
)
print("✅ 高可用: GPT-4, 7次重试, 60秒超时")

# ===== 5. 测试 =====
print("\n=== 测试标准配置 ===")
try:
    response = llm_standard.invoke("你好")
    print(f"✅ 成功: {response.content[:30]}...")
except Exception as e:
    print(f"❌ 失败: {type(e).__name__}")

# ===== 6. 配置建议 =====
print("\n=== 配置建议 ===")
print("1. 标准配置（推荐）:")
print("   - 重试次数: 5")
print("   - 超时时间: 30秒")
print("   - 适用场景: 大多数生产应用")
print("\n2. 快速失败:")
print("   - 重试次数: 2-3")
print("   - 超时时间: 10-15秒")
print("   - 适用场景: 非关键服务、实时应用")
print("\n3. 高可用:")
print("   - 重试次数: 7-10")
print("   - 超时时间: 60秒")
print("   - 适用场景: 关键业务、批量处理")
```

---

## 运行环境要求

### 依赖安装

```bash
uv add langchain langchain-openai python-dotenv tenacity
```

### 环境变量配置

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

---

## 最佳实践总结

### 1. 等待策略选择

| 场景 | 推荐策略 | 配置 |
|------|----------|------|
| 速率限制 | 激进指数退避 | multiplier=2, max=120 |
| 网络超时 | 标准指数退避 | multiplier=1, max=10 |
| 通用场景 | 指数退避+jitter | wait_exponential_jitter=True |

### 2. 异常过滤原则

- **可重试**: RateLimitError, APIError, Timeout, APIConnectionError
- **不可重试**: AuthenticationError, InvalidRequestError, NotFoundError

### 3. 日志记录

- **生产环境**: 必须添加 before_sleep_log 和 after_log
- **日志级别**: WARNING（重试前）, INFO（重试后）

### 4. 重试次数

- **临时故障**: 3-5 次
- **速率限制**: 5-7 次
- **关键服务**: 7-10 次

---

**记住：高级重试策略是生产级应用的核心竞争力。**
