# 限流中间件 - 最小可用知识

> 掌握以下内容，就能在 AI Agent 项目中实现基本的限流功能

---

## 核心理念

**20%的核心知识解决80%的限流需求**

对于大多数 AI Agent 项目，你只需要：
1. 理解一种限流算法（令牌桶）
2. 会用 Redis 存储限流状态
3. 能在 FastAPI 中集成限流中间件

---

## 4.1 最小必知：令牌桶算法

### 为什么选令牌桶？

在4种常见限流算法中，令牌桶是最实用的：
- ✅ 支持突发流量（桶里有余量）
- ✅ 实现简单（只需要记录令牌数和时间）
- ✅ 适合 API 限流（大多数场景）

**核心原理：**
```
桶里有令牌，每个请求消耗一个令牌
令牌以固定速率生成（如每秒10个）
桶满了就不再生成
没有令牌就拒绝请求
```

### 最简实现（30行代码）

```python
import time
from typing import Optional

class TokenBucket:
    """令牌桶限流器"""

    def __init__(self, rate: float, capacity: float):
        """
        Args:
            rate: 令牌生成速率（个/秒）
            capacity: 桶容量（最多存储多少令牌）
        """
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity  # 初始令牌数
        self.last_time = time.time()

    def acquire(self, tokens: int = 1) -> bool:
        """
        尝试获取令牌

        Args:
            tokens: 需要的令牌数

        Returns:
            True: 获取成功
            False: 令牌不足
        """
        now = time.time()
        elapsed = now - self.last_time

        # 生成新令牌
        self.tokens = min(
            self.capacity,
            self.tokens + elapsed * self.rate
        )
        self.last_time = now

        # 检查令牌是否足够
        if self.tokens >= tokens:
            self.tokens -= tokens
            return True
        return False


# 使用示例
limiter = TokenBucket(rate=10, capacity=10)  # 每秒10个请求

if limiter.acquire():
    print("请求通过")
else:
    print("请求被限流")
```

**这30行代码就是限流的核心！**

---

## 4.2 最小必会：Redis 存储

### 为什么需要 Redis？

单机内存限流有问题：
- ❌ 多个服务器实例无法共享状态
- ❌ 服务重启后限流状态丢失
- ❌ 无法实现分布式限流

**Redis 解决方案：**
```python
import redis
import time

class RedisTokenBucket:
    """基于 Redis 的令牌桶"""

    def __init__(self, redis_client: redis.Redis, key: str, rate: float, capacity: float):
        self.redis = redis_client
        self.key = key
        self.rate = rate
        self.capacity = capacity

    def acquire(self, tokens: int = 1) -> bool:
        """尝试获取令牌"""
        now = time.time()

        # Lua 脚本保证原子性
        lua_script = """
        local key = KEYS[1]
        local rate = tonumber(ARGV[1])
        local capacity = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        local requested = tonumber(ARGV[4])

        -- 获取当前状态
        local state = redis.call('HMGET', key, 'tokens', 'last_time')
        local tokens = tonumber(state[1]) or capacity
        local last_time = tonumber(state[2]) or now

        -- 生成新令牌
        local elapsed = now - last_time
        tokens = math.min(capacity, tokens + elapsed * rate)

        -- 检查令牌是否足够
        if tokens >= requested then
            tokens = tokens - requested
            redis.call('HMSET', key, 'tokens', tokens, 'last_time', now)
            redis.call('EXPIRE', key, 3600)  -- 1小时过期
            return 1
        else
            return 0
        end
        """

        result = self.redis.eval(
            lua_script,
            1,  # 1个key
            self.key,
            self.rate,
            self.capacity,
            now,
            tokens
        )

        return result == 1


# 使用示例
redis_client = redis.Redis(host='localhost', port=6379, db=0)
limiter = RedisTokenBucket(
    redis_client=redis_client,
    key="user:123:rate_limit",
    rate=10,
    capacity=10
)

if limiter.acquire():
    print("请求通过")
else:
    print("请求被限流")
```

**为什么用 Lua 脚本？**
- 保证原子性（读取、计算、写入是一个事务）
- 减少网络往返（一次调用完成所有操作）

---

## 4.3 最小必做：FastAPI 集成

### 方式1：依赖注入（推荐）

```python
from fastapi import FastAPI, Depends, HTTPException
from typing import Annotated
import redis

app = FastAPI()
redis_client = redis.Redis(host='localhost', port=6379, db=0)


async def rate_limit(user_id: str = "anonymous"):
    """限流依赖"""
    limiter = RedisTokenBucket(
        redis_client=redis_client,
        key=f"user:{user_id}:rate_limit",
        rate=10,  # 每秒10个请求
        capacity=10
    )

    if not limiter.acquire():
        raise HTTPException(
            status_code=429,
            detail="Too many requests. Please try again later."
        )


@app.post("/chat")
async def chat(
    message: str,
    _: None = Depends(rate_limit)  # 限流检查
):
    return {"response": f"Echo: {message}"}
```

**优点：**
- ✅ 代码清晰（限流逻辑独立）
- ✅ 可复用（多个端点共享）
- ✅ 易测试（可以 mock 依赖）

---

### 方式2：装饰器

```python
from functools import wraps

def rate_limit_decorator(rate: float, capacity: float):
    """限流装饰器"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # 从请求中获取用户ID
            user_id = kwargs.get("user_id", "anonymous")

            limiter = RedisTokenBucket(
                redis_client=redis_client,
                key=f"user:{user_id}:rate_limit",
                rate=rate,
                capacity=capacity
            )

            if not limiter.acquire():
                raise HTTPException(status_code=429, detail="Too many requests")

            return await func(*args, **kwargs)
        return wrapper
    return decorator


@app.post("/chat")
@rate_limit_decorator(rate=10, capacity=10)
async def chat(message: str, user_id: str = "anonymous"):
    return {"response": f"Echo: {message}"}
```

---

## 4.4 最小必懂：多维度限流

### 场景：不同用户等级有不同配额

```python
from enum import Enum

class UserTier(str, Enum):
    FREE = "free"
    BASIC = "basic"
    PRO = "pro"


# 限流配置
RATE_LIMITS = {
    UserTier.FREE: {"rate": 1, "capacity": 10},      # 每秒1个，最多10个
    UserTier.BASIC: {"rate": 10, "capacity": 100},   # 每秒10个，最多100个
    UserTier.PRO: {"rate": 100, "capacity": 1000},   # 每秒100个，最多1000个
}


async def get_rate_limiter(user_id: str, user_tier: UserTier):
    """根据用户等级获取限流器"""
    limits = RATE_LIMITS[user_tier]

    limiter = RedisTokenBucket(
        redis_client=redis_client,
        key=f"user:{user_id}:rate_limit",
        rate=limits["rate"],
        capacity=limits["capacity"]
    )

    if not limiter.acquire():
        raise HTTPException(
            status_code=429,
            detail=f"Rate limit exceeded for {user_tier} tier"
        )


@app.post("/chat")
async def chat(
    message: str,
    user_id: str,
    user_tier: UserTier,
    _: None = Depends(lambda: get_rate_limiter(user_id, user_tier))
):
    return {"response": f"Echo: {message}"}
```

---

## 4.5 最小必测：验证限流是否生效

### 测试脚本

```python
import asyncio
import httpx

async def test_rate_limit():
    """测试限流"""
    async with httpx.AsyncClient() as client:
        # 发送20个请求（限流是10个/秒）
        tasks = []
        for i in range(20):
            task = client.post(
                "http://localhost:8000/chat",
                json={"message": f"Hello {i}"}
            )
            tasks.append(task)

        responses = await asyncio.gather(*tasks, return_exceptions=True)

        # 统计结果
        success = sum(1 for r in responses if isinstance(r, httpx.Response) and r.status_code == 200)
        rate_limited = sum(1 for r in responses if isinstance(r, httpx.Response) and r.status_code == 429)

        print(f"成功: {success}")
        print(f"被限流: {rate_limited}")


if __name__ == "__main__":
    asyncio.run(test_rate_limit())
```

**预期结果：**
```
成功: 10
被限流: 10
```

---

## 这些知识足以

掌握以上内容，你就能：

### ✅ 能做什么

1. **保护 AI Agent API**
   - 防止用户刷接口
   - 控制 LLM API 调用频率
   - 避免成本失控

2. **实现差异化服务**
   - 免费用户：每天10次
   - 付费用户：每天1000次
   - VIP用户：无限制

3. **应对突发流量**
   - 令牌桶支持短时间突发
   - 不会因为瞬间流量拒绝所有请求

### ✅ 适用场景

- 中小型 AI Agent 项目（日活 < 10万）
- 单一 LLM 提供商（OpenAI、Anthropic）
- 简单的用户等级系统（免费/付费）

### ✅ 为后续学习打基础

- 理解了令牌桶，其他算法（固定窗口、滑动窗口、漏桶）很容易理解
- 掌握了 Redis Lua 脚本，可以实现更复杂的限流策略
- 熟悉了 FastAPI 依赖注入，可以扩展到其他中间件

---

## 快速上手检查清单

完成以下步骤，你就掌握了最小可用知识：

- [ ] 理解令牌桶算法的核心原理（桶、令牌、速率）
- [ ] 能手写一个简单的令牌桶实现（30行代码）
- [ ] 知道为什么需要 Redis（分布式、持久化）
- [ ] 会用 Lua 脚本实现 Redis 令牌桶
- [ ] 能在 FastAPI 中集成限流（依赖注入或装饰器）
- [ ] 能实现多维度限流（按用户等级）
- [ ] 能写测试脚本验证限流是否生效

---

## 常见问题

### Q1: 为什么不用固定窗口？更简单啊

**A:** 固定窗口有"窗口边界问题"：
```
时间: 0:59秒 → 100个请求 ✅
时间: 1:00秒 → 100个请求 ✅
实际: 1秒内200个请求！❌
```

令牌桶没有这个问题，因为令牌是连续生成的。

---

### Q2: Lua 脚本看起来很复杂，能不能不用？

**A:** 可以，但会有并发问题：
```python
# 不用 Lua（有并发问题）
tokens = redis.get("tokens")  # 读取
tokens += 1                   # 计算
redis.set("tokens", tokens)   # 写入

# 问题：两个请求同时读取到 tokens=9
# 都认为可以通过，实际超过限制
```

Lua 脚本保证原子性，避免并发问题。

---

### Q3: 限流后用户体验不好，怎么办？

**A:** 三种策略：

1. **拒绝（推荐）**
   ```python
   raise HTTPException(status_code=429, detail="Too many requests")
   ```

2. **排队等待**
   ```python
   while not limiter.acquire():
       await asyncio.sleep(0.1)  # 等待100ms
   ```

3. **降级服务**
   ```python
   if not limiter.acquire():
       return {"response": "服务繁忙，请稍后再试"}  # 返回缓存结果
   ```

对于 AI Agent，推荐"拒绝"策略，因为 LLM 调用很慢，排队会导致超时。

---

### Q4: 如何选择 rate 和 capacity？

**经验值：**

| 场景 | rate | capacity | 说明 |
|------|------|----------|------|
| 免费用户 | 1 | 10 | 每秒1个，最多突发10个 |
| 付费用户 | 10 | 100 | 每秒10个，最多突发100个 |
| 内部服务 | 100 | 1000 | 每秒100个，最多突发1000个 |

**调优方法：**
1. 先设置保守值（如 rate=1, capacity=10）
2. 监控实际流量
3. 根据服务器负载和成本调整

---

## 下一步学习

掌握了最小可用知识后，可以深入学习：

1. **其他算法**
   - 固定窗口（最简单）
   - 滑动窗口（最精确）
   - 漏桶（流量整形）

2. **高级特性**
   - 动态调整限流策略
   - 多维度限流（用户+IP+端点）
   - 限流监控和告警

3. **生产优化**
   - Redis 集群
   - 限流降级策略
   - 性能优化

---

## 实战练习

### 练习1：实现一个简单的限流 API

**要求：**
- 使用令牌桶算法
- 每秒最多10个请求
- 超过限制返回 429 错误

**提示：**
```python
from fastapi import FastAPI, HTTPException
import time

app = FastAPI()
limiter = TokenBucket(rate=10, capacity=10)

@app.get("/api/data")
async def get_data():
    if not limiter.acquire():
        raise HTTPException(status_code=429, detail="Too many requests")
    return {"data": "Hello"}
```

---

### 练习2：实现按用户限流

**要求：**
- 每个用户独立限流
- 免费用户：每秒1个请求
- 付费用户：每秒10个请求

**提示：**
```python
@app.get("/api/data")
async def get_data(user_id: str, user_tier: str):
    rate = 1 if user_tier == "free" else 10
    limiter = RedisTokenBucket(
        redis_client=redis_client,
        key=f"user:{user_id}:rate_limit",
        rate=rate,
        capacity=rate * 10
    )
    # ...
```

---

### 练习3：测试限流是否生效

**要求：**
- 写一个测试脚本
- 发送20个并发请求
- 验证只有10个成功

**提示：**
```python
import asyncio
import httpx

async def test():
    async with httpx.AsyncClient() as client:
        tasks = [client.get("http://localhost:8000/api/data") for _ in range(20)]
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        # 统计成功和失败的数量
```

---

## 总结

**最小可用知识 = 令牌桶 + Redis + FastAPI 集成**

这三个核心知识点，就能解决80%的限流需求。

**记住：**
- 令牌桶是最实用的算法（支持突发流量）
- Redis 是分布式限流的必备（共享状态）
- FastAPI 依赖注入是最优雅的集成方式（代码清晰）

掌握了这些，你就可以在 AI Agent 项目中实现基本的限流功能，保护服务稳定性，控制成本，提供差异化服务。
