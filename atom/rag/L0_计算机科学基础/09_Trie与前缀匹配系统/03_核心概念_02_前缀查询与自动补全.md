# 前缀查询与自动补全

## 核心概念

**前缀查询 = 找到前缀节点 + DFS/BFS 收集所有子节点**

前缀查询是 Trie 最强大的功能，也是它区别于 Hash Table 的核心优势。

---

## 1. 前缀匹配原理

### 1.1 什么是前缀匹配？

**定义：** 找到所有以给定字符串开头的单词。

**示例：**
```python
# 词典：["cat", "car", "card", "dog"]
# 前缀："ca"
# 结果：["cat", "car", "card"]
```

**为什么 Trie 天然支持前缀匹配？**

因为 Trie 的结构就是按前缀组织的：
- 共享前缀的单词共享路径
- 找到前缀节点后，所有子节点都是匹配结果

---

### 1.2 前缀匹配算法

```python
def get_words_with_prefix(self, prefix: str) -> list:
    """
    获取所有以 prefix 开头的单词
    时间复杂度：O(m + k)
    - m: 前缀长度
    - k: 结果数量
    """
    # 步骤 1：找到前缀节点
    node = self.root
    for char in prefix:
        if char not in node.children:
            return []  # 前缀不存在
        node = node.children[char]

    # 步骤 2：DFS 收集所有单词
    results = []
    self._dfs(node, prefix, results)
    return results

def _dfs(self, node, path, results):
    """DFS 遍历子树"""
    if node.is_end:
        results.append(path)

    for char, child in node.children.items():
        self._dfs(child, path + char, results)
```

**算法步骤：**
1. **定位前缀节点**：O(m)
2. **DFS 遍历子树**：O(k)
3. **总时间复杂度**：O(m + k)

---

### 1.3 可视化示例

**Trie 结构：**
```
        root
       /    \
      c      d
      |      |
      a      o
     /|\     |
    t r d    g
   (E)(E)|  (E)
          d
         (E)
```

**查询 "ca"：**

```
步骤 1：定位到节点 'a'
        root
         |
         c
         |
         a  ← 前缀节点
        /|\
       t r d

步骤 2：DFS 遍历
- 访问 't' → is_end=True → 收集 "cat"
- 访问 'r' → is_end=True → 收集 "car"
- 访问 'd' → 继续
  - 访问 'd' → is_end=True → 收集 "card"

结果：["cat", "car", "card"]
```

---

## 2. 自动补全系统

### 2.1 自动补全的核心需求

**场景：** 搜索框实时补全

**需求：**
1. **实时性**：用户每输入一个字符，立即显示补全
2. **排序**：按相关性或频率排序
3. **限制数量**：只显示前 N 个结果
4. **高亮**：高亮匹配的前缀

---

### 2.2 基础自动补全实现

```python
class AutoComplete:
    """自动补全系统"""

    def __init__(self):
        self.trie = Trie()

    def add_word(self, word: str, frequency: int = 1):
        """添加单词及其频率"""
        self.trie.insert(word, value=frequency)

    def suggest(self, prefix: str, limit: int = 10) -> list:
        """
        获取自动补全建议
        返回：[(word, frequency), ...]
        """
        # 1. 找到前缀节点
        node = self.trie.root
        for char in prefix:
            if char not in node.children:
                return []
            node = node.children[char]

        # 2. DFS 收集所有单词及频率
        results = []
        self._collect_words(node, prefix, results)

        # 3. 按频率排序
        results.sort(key=lambda x: x[1], reverse=True)

        # 4. 返回前 N 个
        return results[:limit]

    def _collect_words(self, node, path, results):
        """收集单词及频率"""
        if node.is_end:
            results.append((path, node.value or 0))

        for char, child in node.children.items():
            self._collect_words(child, path + char, results)


# ===== 使用示例 =====
ac = AutoComplete()

# 添加单词及频率
ac.add_word("python", frequency=1000)
ac.add_word("pytorch", frequency=800)
ac.add_word("pandas", frequency=600)
ac.add_word("numpy", frequency=500)

# 自动补全
suggestions = ac.suggest("py", limit=3)
print(suggestions)
# 输出：[('python', 1000), ('pytorch', 800)]
```

---

### 2.3 优化：Top-K 堆

**问题：** 如果匹配结果很多（如 10 万个），全部收集再排序效率低。

**优化：** 使用最小堆维护 Top-K。

```python
import heapq

def suggest_optimized(self, prefix: str, limit: int = 10) -> list:
    """
    优化的自动补全（使用堆）
    时间复杂度：O(m + n log k)
    - m: 前缀长度
    - n: 匹配结果数量
    - k: limit
    """
    node = self.trie.root
    for char in prefix:
        if char not in node.children:
            return []
        node = node.children[char]

    # 使用最小堆维护 Top-K
    heap = []
    self._collect_topk(node, prefix, heap, limit)

    # 返回结果（按频率降序）
    return sorted(heap, key=lambda x: x[1], reverse=True)

def _collect_topk(self, node, path, heap, limit):
    """收集 Top-K 单词"""
    if node.is_end:
        freq = node.value or 0
        if len(heap) < limit:
            heapq.heappush(heap, (path, freq))
        elif freq > heap[0][1]:
            heapq.heapreplace(heap, (path, freq))

    for char, child in node.children.items():
        self._collect_topk(child, path + char, heap, limit)
```

**优势：**
- 空间复杂度：O(k) 而非 O(n)
- 时间复杂度：O(n log k) 而非 O(n log n)

---

## 3. 通配符匹配

### 3.1 单字符通配符（.）

**需求：** 匹配任意单个字符

**示例：**
```python
# 词典：["cat", "car", "bat", "bar"]
# 模式："ca."
# 结果：["cat", "car"]
```

**实现：**

```python
def search_with_wildcard(self, pattern: str) -> list:
    """
    支持 '.' 通配符的搜索
    '.' 匹配任意单个字符
    """
    results = []
    self._search_wildcard(self.root, pattern, 0, "", results)
    return results

def _search_wildcard(self, node, pattern, index, path, results):
    """递归搜索"""
    # 递归终止条件
    if index == len(pattern):
        if node.is_end:
            results.append(path)
        return

    char = pattern[index]

    if char == '.':
        # 通配符：尝试所有子节点
        for c, child in node.children.items():
            self._search_wildcard(child, pattern, index + 1, path + c, results)
    else:
        # 普通字符：精确匹配
        if char in node.children:
            self._search_wildcard(
                node.children[char], pattern, index + 1, path + char, results
            )


# ===== 测试 =====
trie = Trie()
trie.insert("cat")
trie.insert("car")
trie.insert("bat")
trie.insert("bar")

print(trie.search_with_wildcard("ca."))  # ['cat', 'car']
print(trie.search_with_wildcard("ba."))  # ['bat', 'bar']
print(trie.search_with_wildcard("..."))  # ['cat', 'car', 'bat', 'bar']
```

---

### 3.2 多字符通配符（*）

**需求：** 匹配任意长度的字符序列

**示例：**
```python
# 词典：["cat", "catch", "car"]
# 模式："ca*"
# 结果：["cat", "catch", "car"]
```

**实现：**

```python
def search_with_star(self, pattern: str) -> list:
    """
    支持 '*' 通配符的搜索
    '*' 匹配任意长度的字符序列
    """
    results = []
    self._search_star(self.root, pattern, 0, "", results)
    return results

def _search_star(self, node, pattern, index, path, results):
    """递归搜索（支持 *）"""
    # 递归终止条件
    if index == len(pattern):
        if node.is_end:
            results.append(path)
        return

    char = pattern[index]

    if char == '*':
        # 通配符：尝试匹配 0 到 n 个字符
        # 1. 匹配 0 个字符（跳过 *）
        self._search_star(node, pattern, index + 1, path, results)

        # 2. 匹配 1+ 个字符（递归所有子节点）
        for c, child in node.children.items():
            self._search_star(child, pattern, index, path + c, results)
    else:
        # 普通字符：精确匹配
        if char in node.children:
            self._search_star(
                node.children[char], pattern, index + 1, path + char, results
            )
```

---

## 4. 模糊查询

### 4.1 编辑距离匹配

**需求：** 找到与查询字符串编辑距离 ≤ k 的所有单词

**应用场景：** 拼写纠错

**示例：**
```python
# 词典：["cat", "car", "bat"]
# 查询："cot"（编辑距离 ≤ 1）
# 结果：["cat", "car"]（"cat" 距离 1，"car" 距离 1）
```

**实现（简化版）：**

```python
def fuzzy_search(self, query: str, max_distance: int = 1) -> list:
    """
    模糊搜索（编辑距离 ≤ max_distance）
    """
    results = []
    self._fuzzy_search(self.root, query, 0, "", 0, max_distance, results)
    return results

def _fuzzy_search(self, node, query, index, path, distance, max_distance, results):
    """递归模糊搜索"""
    # 剪枝：距离已超过阈值
    if distance > max_distance:
        return

    # 递归终止条件
    if index == len(query):
        if node.is_end:
            results.append((path, distance))
        # 继续尝试插入操作
        for char, child in node.children.items():
            self._fuzzy_search(
                child, query, index, path + char, distance + 1, max_distance, results
            )
        return

    char = query[index]

    # 1. 匹配（距离不变）
    if char in node.children:
        self._fuzzy_search(
            node.children[char], query, index + 1, path + char, distance, max_distance, results
        )

    # 2. 替换（距离 +1）
    for c, child in node.children.items():
        if c != char:
            self._fuzzy_search(
                child, query, index + 1, path + c, distance + 1, max_distance, results
            )

    # 3. 删除（距离 +1）
    self._fuzzy_search(node, query, index + 1, path, distance + 1, max_distance, results)

    # 4. 插入（距离 +1）
    for c, child in node.children.items():
        self._fuzzy_search(
            child, query, index, path + c, distance + 1, max_distance, results
        )
```

---

## 5. 在 AI Agent 中的应用

### 5.1 意图识别

**场景：** 用户输入模糊，需要匹配最相似的意图

```python
class IntentMatcher:
    """AI Agent 意图匹配器"""

    def __init__(self):
        self.trie = Trie()

    def add_intent(self, keywords: list, intent: str):
        """添加意图及其关键词"""
        for keyword in keywords:
            self.trie.insert(keyword, value=intent)

    def match(self, user_input: str) -> str:
        """匹配用户意图"""
        # 1. 提取关键词（简化：按空格分词）
        words = user_input.split()

        # 2. 在 Trie 中查找匹配
        matched_intents = []
        for word in words:
            # 前缀匹配
            matches = self.trie.get_words_with_prefix(word)
            for match in matches:
                node = self.trie._get_node(match)
                if node and node.value:
                    matched_intents.append(node.value)

        # 3. 返回最频繁的意图
        if matched_intents:
            from collections import Counter
            return Counter(matched_intents).most_common(1)[0][0]

        return "unknown"


# ===== 使用示例 =====
matcher = IntentMatcher()

# 添加意图
matcher.add_intent(["查询", "查看", "搜索"], intent="search")
matcher.add_intent(["天气", "气温", "温度"], intent="weather")
matcher.add_intent(["时间", "几点", "现在"], intent="time")

# 匹配意图
print(matcher.match("查询今天的天气"))  # weather
print(matcher.match("现在几点了"))      # time
```

**来源：** "Real-World Applications of Trie Data Structure" (Medium 2025)
https://medium.com/@kvaibhaw300/real-world-applications-of-trie-data-structure-187a68417cbb

---

### 5.2 实时搜索建议

**场景：** 用户输入时实时显示建议

```python
class SearchSuggestion:
    """实时搜索建议系统"""

    def __init__(self):
        self.trie = Trie()

    def index_documents(self, documents: list):
        """索引文档"""
        for doc_id, content in enumerate(documents):
            # 提取关键词（简化：按空格分词）
            words = content.lower().split()
            for word in words:
                # 存储文档 ID
                node = self.trie._get_node(word)
                if node:
                    if node.value is None:
                        node.value = set()
                    node.value.add(doc_id)
                else:
                    self.trie.insert(word, value={doc_id})

    def suggest(self, prefix: str, limit: int = 5) -> list:
        """实时搜索建议"""
        # 1. 前缀匹配
        matches = self.trie.get_words_with_prefix(prefix.lower())

        # 2. 按文档数量排序
        suggestions = []
        for word in matches:
            node = self.trie._get_node(word)
            if node and node.value:
                doc_count = len(node.value)
                suggestions.append((word, doc_count))

        # 3. 返回 Top-K
        suggestions.sort(key=lambda x: x[1], reverse=True)
        return [word for word, _ in suggestions[:limit]]


# ===== 使用示例 =====
search = SearchSuggestion()

# 索引文档
documents = [
    "Python programming tutorial",
    "Python data science",
    "PyTorch deep learning",
    "Pandas data analysis",
]
search.index_documents(documents)

# 实时建议
print(search.suggest("py"))   # ['python', 'pytorch']
print(search.suggest("pyt"))  # ['python', 'pytorch']
```

---

## 6. 性能优化

### 6.1 BFS vs DFS

**DFS（深度优先）：**
- 优点：实现简单，空间复杂度 O(h)
- 缺点：结果无序

**BFS（广度优先）：**
- 优点：结果按长度排序
- 缺点：空间复杂度 O(w)，w 是最大宽度

```python
from collections import deque

def get_words_bfs(self, prefix: str) -> list:
    """BFS 收集单词"""
    node = self.root
    for char in prefix:
        if char not in node.children:
            return []
        node = node.children[char]

    results = []
    queue = deque([(node, prefix)])

    while queue:
        current, path = queue.popleft()

        if current.is_end:
            results.append(path)

        for char, child in current.children.items():
            queue.append((child, path + char))

    return results
```

---

### 6.2 缓存优化

**问题：** 频繁查询相同前缀

**优化：** 使用 LRU 缓存

```python
from functools import lru_cache

class CachedTrie(Trie):
    """带缓存的 Trie"""

    @lru_cache(maxsize=1000)
    def get_words_with_prefix(self, prefix: str) -> tuple:
        """缓存前缀查询结果"""
        results = super().get_words_with_prefix(prefix)
        return tuple(results)  # 转为 tuple 以支持缓存
```

---

## 7. 完整示例

```python
"""
自动补全系统完整实现
演示：实时搜索建议、排序、限制数量
"""

class AutoCompleteSystem:
    """生产级自动补全系统"""

    def __init__(self):
        self.trie = Trie()

    def add_word(self, word: str, frequency: int = 1):
        """添加单词及频率"""
        self.trie.insert(word.lower(), value=frequency)

    def suggest(self, prefix: str, limit: int = 10) -> list:
        """获取自动补全建议"""
        if not prefix:
            return []

        # 1. 前缀匹配
        node = self.trie.root
        for char in prefix.lower():
            if char not in node.children:
                return []
            node = node.children[char]

        # 2. 收集所有匹配
        results = []
        self._collect_words(node, prefix.lower(), results)

        # 3. 按频率排序
        results.sort(key=lambda x: x[1], reverse=True)

        # 4. 返回 Top-K
        return [word for word, _ in results[:limit]]

    def _collect_words(self, node, path, results):
        """收集单词及频率"""
        if node.is_end:
            results.append((path, node.value or 0))

        for char, child in node.children.items():
            self._collect_words(child, path + char, results)


# ===== 测试 =====
if __name__ == "__main__":
    ac = AutoCompleteSystem()

    # 添加单词（模拟搜索历史）
    words = [
        ("python", 1000),
        ("pytorch", 800),
        ("pandas", 600),
        ("numpy", 500),
        ("programming", 400),
    ]

    for word, freq in words:
        ac.add_word(word, freq)

    # 测试自动补全
    print("=== 自动补全测试 ===")
    print(f"输入 'py': {ac.suggest('py', limit=3)}")
    print(f"输入 'pyt': {ac.suggest('pyt', limit=3)}")
    print(f"输入 'p': {ac.suggest('p', limit=5)}")
```

**预期输出：**
```
=== 自动补全测试 ===
输入 'py': ['python', 'pytorch']
输入 'pyt': ['pytorch']
输入 'p': ['python', 'pytorch', 'pandas', 'programming']
```

---

**版本**: v1.0
**最后更新**: 2026-02-14
**下一步**: 学习压缩 Trie 与 Radix Tree（`03_压缩Trie与Radix_Tree.md`）
