# 实战代码：错误处理与降级策略

> **场景**：主模型失败时自动切换到备用模型，保证系统可靠性
> **学习目标**：掌握错误处理和降级策略的实现
> **预计学习时长**：45分钟

---

## 场景说明

### 业务痛点

在生产环境中，LLM API 可能出现各种故障：
- **API 限额**：超过速率限制（Rate Limit）
- **超时**：网络延迟或服务响应慢
- **服务故障**：API 服务暂时不可用
- **模型错误**：模型返回错误或异常

如果没有降级策略，这些故障会导致：
- **系统不可用**：用户无法获得响应
- **用户体验差**：长时间等待或错误提示
- **业务损失**：关键功能无法使用

### 解决方案

通过多级降级策略，确保系统始终可用：
1. **主路径**：GPT-4（最优质量）
2. **降级路径1**：Claude（备用方案）
3. **降级路径2**：GPT-4o-mini（最终兜底）
4. **缓存响应**：常见问题的预设答案

### 预期效果

**系统可用性从 99% 提升到 99.99%+**

**参考资料**：
- RunnableWithFallbacks | LangChain documentation
- https://reference.langchain.com/javascript/classes/_langchain_core.runnables.RunnableWithFallbacks.html

---

## 架构设计

### 系统架构图

```
用户请求
    ↓
主路径：GPT-4
    ↓ 失败？
降级路径1：Claude
    ↓ 失败？
降级路径2：GPT-4o-mini
    ↓ 失败？
缓存响应（预设答案）
    ↓
返回结果
```

### 核心组件

1. **主模型**：GPT-4（最优质量）
2. **备用模型1**：Claude（第一备用）
3. **备用模型2**：GPT-4o-mini（第二备用）
4. **缓存系统**：常见问题的预设答案
5. **错误监控**：追踪每次降级事件

---

## 完整代码实现

```python
from langchain_core.runnables import RunnableBranch, RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import logging
from typing import Dict, Any
from datetime import datetime
import time

# 加载环境变量
load_dotenv()

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================
# 1. 错误监控器
# ============================================================

class ErrorMonitor:
    """错误监控器"""

    def __init__(self):
        self.errors = []
        self.fallback_counts = {
            "primary": 0,
            "fallback_1": 0,
            "fallback_2": 0,
            "cache": 0
        }

    def log_error(self, model: str, error: Exception):
        """记录错误"""
        error_info = {
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "error_type": type(error).__name__,
            "error_message": str(error)
        }
        self.errors.append(error_info)
        logger.error(f"Error in {model}: {error}")

    def log_fallback(self, from_model: str, to_model: str):
        """记录降级事件"""
        logger.warning(f"Fallback: {from_model} → {to_model}")

        # 更新计数
        if to_model == "fallback_1":
            self.fallback_counts["fallback_1"] += 1
        elif to_model == "fallback_2":
            self.fallback_counts["fallback_2"] += 1
        elif to_model == "cache":
            self.fallback_counts["cache"] += 1

    def report(self):
        """生成错误报告"""
        print("\n" + "="*70)
        print("错误和降级报告")
        print("="*70)

        # 错误统计
        print(f"\n总错误数: {len(self.errors)}")
        if self.errors:
            print("\n最近的错误:")
            for error in self.errors[-5:]:  # 显示最近5个错误
                print(f"  [{error['timestamp']}] {error['model']}: {error['error_type']}")

        # 降级统计
        print(f"\n降级统计:")
        total_fallbacks = sum(self.fallback_counts.values())
        for level, count in self.fallback_counts.items():
            if count > 0:
                percentage = (count / total_fallbacks) * 100 if total_fallbacks > 0 else 0
                print(f"  {level}: {count} ({percentage:.1f}%)")

        print("="*70)

# ============================================================
# 2. 缓存系统
# ============================================================

class ResponseCache:
    """响应缓存系统"""

    def __init__(self):
        self.cache = {
            "什么是Python?": "Python是一种高级编程语言，由Guido van Rossum于1991年创建。",
            "你好": "你好！我是AI助手，有什么可以帮助你的吗？",
            "谢谢": "不客气！很高兴能帮到你。",
        }

    def get(self, input_text: str) -> str:
        """获取缓存响应"""
        return self.cache.get(input_text)

    def has(self, input_text: str) -> bool:
        """检查是否有缓存"""
        return input_text in self.cache

# ============================================================
# 3. 可靠性路由器
# ============================================================

class ReliableRouter:
    """可靠性路由器（带降级策略）"""

    def __init__(self):
        self.monitor = ErrorMonitor()
        self.cache = ResponseCache()

        # 定义模型（带超时配置）
        self.primary_model = ChatOpenAI(
            model="gpt-4",
            temperature=0,
            request_timeout=10  # 10秒超时
        )

        self.fallback_1_model = ChatOpenAI(
            model="gpt-4",  # 实际应该是 Claude，这里用 GPT-4 模拟
            temperature=0,
            request_timeout=10
        )

        self.fallback_2_model = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            request_timeout=5  # 更短的超时
        )

        # 创建带降级的链
        self.chain_with_fallbacks = self.primary_model.with_fallbacks([
            self.fallback_1_model,
            self.fallback_2_model
        ])

    def invoke(self, input_text: str) -> Dict[str, Any]:
        """执行路由（带降级）"""
        start_time = time.time()

        # 检查缓存
        if self.cache.has(input_text):
            logger.info(f"Cache hit for: {input_text}")
            self.monitor.log_fallback("primary", "cache")
            return {
                "input": input_text,
                "output": self.cache.get(input_text),
                "model": "cache",
                "duration": time.time() - start_time
            }

        # 尝试执行（带降级）
        try:
            result = self.chain_with_fallbacks.invoke(input_text)
            duration = time.time() - start_time

            return {
                "input": input_text,
                "output": result.content,
                "model": "primary",  # 简化：实际应该追踪使用了哪个模型
                "duration": duration
            }

        except Exception as e:
            # 所有降级都失败，使用缓存或默认响应
            self.monitor.log_error("all_models", e)
            self.monitor.log_fallback("fallback_2", "cache")

            default_response = "抱歉，系统暂时无法处理您的请求，请稍后重试。"
            return {
                "input": input_text,
                "output": default_response,
                "model": "default",
                "duration": time.time() - start_time
            }

# ============================================================
# 4. 模拟故障的路由器（用于测试）
# ============================================================

class SimulatedFailureRouter:
    """模拟故障的路由器（用于测试降级策略）"""

    def __init__(self, failure_rate: float = 0.3):
        self.monitor = ErrorMonitor()
        self.cache = ResponseCache()
        self.failure_rate = failure_rate
        self.request_count = 0

        # 定义模型
        self.models = {
            "primary": ChatOpenAI(model="gpt-4o-mini", temperature=0),
            "fallback_1": ChatOpenAI(model="gpt-4o-mini", temperature=0),
            "fallback_2": ChatOpenAI(model="gpt-4o-mini", temperature=0)
        }

    def _should_fail(self) -> bool:
        """判断是否应该模拟失败"""
        import random
        return random.random() < self.failure_rate

    def invoke(self, input_text: str) -> Dict[str, Any]:
        """执行路由（模拟故障）"""
        self.request_count += 1
        start_time = time.time()

        # 检查缓存
        if self.cache.has(input_text):
            logger.info(f"Cache hit for: {input_text}")
            self.monitor.log_fallback("primary", "cache")
            return {
                "input": input_text,
                "output": self.cache.get(input_text),
                "model": "cache",
                "duration": time.time() - start_time
            }

        # 尝试主模型
        if not self._should_fail():
            logger.info("Primary model succeeded")
            result = self.models["primary"].invoke(input_text)
            return {
                "input": input_text,
                "output": result.content,
                "model": "primary",
                "duration": time.time() - start_time
            }

        # 主模型失败，尝试降级1
        self.monitor.log_error("primary", Exception("Simulated failure"))
        self.monitor.log_fallback("primary", "fallback_1")

        if not self._should_fail():
            logger.info("Fallback 1 succeeded")
            result = self.models["fallback_1"].invoke(input_text)
            return {
                "input": input_text,
                "output": result.content,
                "model": "fallback_1",
                "duration": time.time() - start_time
            }

        # 降级1失败，尝试降级2
        self.monitor.log_error("fallback_1", Exception("Simulated failure"))
        self.monitor.log_fallback("fallback_1", "fallback_2")

        if not self._should_fail():
            logger.info("Fallback 2 succeeded")
            result = self.models["fallback_2"].invoke(input_text)
            return {
                "input": input_text,
                "output": result.content,
                "model": "fallback_2",
                "duration": time.time() - start_time
            }

        # 所有模型都失败，使用默认响应
        self.monitor.log_error("fallback_2", Exception("Simulated failure"))
        self.monitor.log_fallback("fallback_2", "cache")

        default_response = "抱歉，系统暂时无法处理您的请求，请稍后重试。"
        return {
            "input": input_text,
            "output": default_response,
            "model": "default",
            "duration": time.time() - start_time
        }

# ============================================================
# 5. 测试系统
# ============================================================

def test_reliability():
    """测试可靠性路由"""
    router = SimulatedFailureRouter(failure_rate=0.3)

    # 测试用例
    test_cases = [
        "什么是Python?",
        "Python和Java有什么区别？",
        "如何学习编程？",
        "你好",
        "谢谢",
    ] * 20  # 100个请求

    print("="*70)
    print("可靠性路由测试（模拟30%故障率）")
    print("="*70)
    print(f"总测试用例数: {len(test_cases)}\n")

    # 执行测试
    results = []
    for i, input_text in enumerate(test_cases[:10], 1):  # 只显示前10个
        print(f"测试 {i}/10")
        print(f"输入: {input_text}")
        print("-"*70)

        result = router.invoke(input_text)

        print(f"模型: {result['model']}")
        print(f"耗时: {result['duration']:.3f}秒")
        print(f"输出: {result['output'][:80]}...")
        print("-"*70)
        print()

        results.append(result)

    # 执行剩余的测试（不显示输出）
    for input_text in test_cases[10:]:
        result = router.invoke(input_text)
        results.append(result)

    # 统计结果
    model_counts = {}
    for result in results:
        model = result["model"]
        model_counts[model] = model_counts.get(model, 0) + 1

    print("\n" + "="*70)
    print("模型使用统计")
    print("="*70)
    for model, count in model_counts.items():
        percentage = (count / len(results)) * 100
        print(f"{model}: {count} ({percentage:.1f}%)")

    # 生成错误报告
    router.monitor.report()

# ============================================================
# 6. 主程序
# ============================================================

if __name__ == "__main__":
    test_reliability()
```

---

## 运行示例和输出

### 测试输出（前3个）

```
======================================================================
可靠性路由测试（模拟30%故障率）
======================================================================
总测试用例数: 100

测试 1/10
输入: 什么是Python?
----------------------------------------------------------------------
模型: cache
耗时: 0.001秒
输出: Python是一种高级编程语言，由Guido van Rossum于1991年创建。
----------------------------------------------------------------------

测试 2/10
输入: Python和Java有什么区别？
----------------------------------------------------------------------
模型: fallback_1
耗时: 1.234秒
输出: Python和Java是两种流行的编程语言，它们在语法、性能、应用场景等方面有显著区别...
----------------------------------------------------------------------

测试 3/10
输入: 如何学习编程？
----------------------------------------------------------------------
模型: primary
耗时: 0.987秒
输出: 学习编程可以遵循以下步骤：1. 选择一门编程语言（如Python）2. 学习基础语法...
----------------------------------------------------------------------
```

---

## 可靠性分析

### 系统可用性计算

假设每个模型的可用性是 99%（故障率 1%）：

**无降级策略**：
```
可用性 = 99%
```

**一级降级**：
```
故障率 = 1% × 1% = 0.01%
可用性 = 99.99%
```

**二级降级**：
```
故障率 = 1% × 1% × 1% = 0.0001%
可用性 = 99.9999%
```

**三级降级（含缓存）**：
```
故障率 ≈ 0%（缓存几乎不会失败）
可用性 ≈ 100%
```

### 实际效果

| 降级级别 | 可用性 | 年度停机时间 |
|---------|--------|-------------|
| **无降级** | 99% | 3.65天 |
| **一级降级** | 99.99% | 52.6分钟 |
| **二级降级** | 99.9999% | 31.5秒 |
| **三级降级** | ~100% | <1秒 |

---

## 生产环境最佳实践

### 1. 超时配置

```python
# 不同模型使用不同的超时时间
primary_model = ChatOpenAI(
    model="gpt-4",
    request_timeout=10  # 主模型：10秒
)

fallback_model = ChatOpenAI(
    model="gpt-4o-mini",
    request_timeout=5  # 备用模型：5秒（更快）
)
```

### 2. 重试策略

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10)
)
def invoke_with_retry(model, input_text):
    """带重试的调用"""
    return model.invoke(input_text)
```

### 3. 断路器模式

```python
class CircuitBreaker:
    """断路器"""

    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half_open

    def call(self, func, *args, **kwargs):
        """执行调用"""
        if self.state == "open":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "half_open"
            else:
                raise Exception("Circuit breaker is open")

        try:
            result = func(*args, **kwargs)
            if self.state == "half_open":
                self.state = "closed"
                self.failure_count = 0
            return result

        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()

            if self.failure_count >= self.failure_threshold:
                self.state = "open"

            raise e
```

### 4. 监控和告警

```python
from prometheus_client import Counter, Histogram

# 定义指标
fallback_counter = Counter(
    'fallback_total',
    'Total fallback events',
    ['from_model', 'to_model']
)

error_counter = Counter(
    'error_total',
    'Total errors',
    ['model', 'error_type']
)

def monitored_invoke(router, input_text):
    """带监控的调用"""
    try:
        return router.invoke(input_text)
    except Exception as e:
        error_counter.labels(
            model="primary",
            error_type=type(e).__name__
        ).inc()
        raise
```

### 5. 降级决策优化

```python
class SmartFallbackRouter:
    """智能降级路由器"""

    def __init__(self):
        self.model_health = {
            "primary": 1.0,  # 健康度：0-1
            "fallback_1": 1.0,
            "fallback_2": 1.0
        }

    def update_health(self, model: str, success: bool):
        """更新模型健康度"""
        if success:
            self.model_health[model] = min(1.0, self.model_health[model] + 0.1)
        else:
            self.model_health[model] = max(0.0, self.model_health[model] - 0.2)

    def should_skip_model(self, model: str) -> bool:
        """判断是否应该跳过某个模型"""
        return self.model_health[model] < 0.3  # 健康度低于30%则跳过
```

---

## 总结

### 核心要点

1. **多级降级**：主模型 → 备用模型1 → 备用模型2 → 缓存
2. **错误监控**：追踪每次降级事件和错误
3. **可靠性提升**：从 99% 提升到 99.9999%+
4. **超时配置**：不同模型使用不同的超时时间

### 实际效果

- **可用性提升**：从 99% 提升到 99.9999%+
- **年度停机时间**：从 3.65天 降到 <1秒
- **用户体验**：始终能获得响应

### 下一步

- 阅读 `07_实战代码_04_多语言多地区路由.md` 学习国际化
- 阅读 `03_核心概念_01_RunnableBranch.md` 深入理解实现
- 阅读 `06_反直觉点.md` 了解常见误区
